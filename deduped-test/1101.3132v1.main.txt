##### Contents

-    1 Introduction
    -    1.1 Introduction
    -    1.2 Motivation
    -    1.3 Related work
-    2 Reactive valuations
    -    2.1 Introduction
    -    2.2 Reactive valuations
    -    2.3 Reactive valuation varieties
    -    2.4 Notation and conventions
    -    2.5 Free reactive valuations
        -    2.5.1 Soundness
        -    2.5.2 Completeness
    -    2.6 Repetition-proof valuations
        -    2.6.1 Soundness
        -    2.6.2 Completeness
    -    2.7 Contractive valuations
        -    2.7.1 Soundness
        -    2.7.2 Completeness
    -    2.8 Static valuations
        -    2.8.1 Soundness
        -    2.8.2 Completeness
-    3 @xmath -Completeness
    -    3.1 @xmath -Completeness of CP
    -    3.2 @xmath -Completeness of @xmath
-    4 Independence of the axioms
    -    4.1 Independence of CP
    -    4.2 Independence of @xmath
    -    4.3 Independence of @xmath
    -    4.4 Independence of @xmath
-    5 Conclusion
    -    5.1 Summary
    -    5.2 Open issues and future work
        -    5.2.1 Open issues
        -    5.2.2 Future work
-    A Characterization of CP+CP5
    -    A.1 Non-replicating valuations
    -    A.2 Soundness
-    B Term rewriting system
    -    B.1 Term rewriting for CP
    -    B.2 Theorem prover for CP

## Chapter 1 Introduction

### 1.1 Introduction

In sentential logic (also called propositional calculus), sentences are
build from atomic propositions, the constants true and false, and
connectives such as @xmath , @xmath , @xmath , etc. The truth of such a
sentence with respect to a model, is calculated using the interpretation
function associated with that model. This function not only assigns
meaning to the connectives and constants but also to the individual
atomic propositions.

In sentential logic the interpretation of connectives and constants is
given. Hence, a model in sentential logic is uniquely defined by the
interpretation of the individual atomic propositions. These atomic
propositions are assigned either the value true or the value false by
the interpretation, indicating whether they are true or false in the
model. Such an assignment is referred to as a valuation. In sentential
logic, these valuations entirely depend on the atomic propositions they
assign a value to and not on other external factors. Consequently, a
valuation will give an atomic proposition the same valuation no matter
its location within a sentence, and this valuation will never change.
These valuations are, in a manner of speaking, static.

This static behaviour can be considered a severe limitation of
sentential logic. For example, sentential logic is not sufficiently
expressive for modelling logical conjunction as implemented in most
programming languages because the conjunction in these cases is
non-commutative ¹ ¹ 1 We explain in the next section why this is the
case. . In order for us to effectively model these and other kinds of
connectives and sequential systems, we are required to extend our notion
of valuation.

This thesis is based on the work by Bergstra and Ponse in [ 5 ] . They
introduce a logic that uses reactive valuations instead of normal
valuations. Reactive valuations allow us to take previously evaluated
atomic propositions into account. Thus the valuations are in a sense
“reactive”. The use of reactive valuations necessitates the need for
expressions in this logic to be evaluated in some fixed order. Hence the
resulting logic has a sequential interpretation. The same atomic
proposition may have a different value depending on which atomic
propositions have previously been evaluated. The reactive valuations
have thus an additional dependence on a sequence of atomic propositions
representing the history of evaluation.

The signature of this logic consists of a finite set of atomic
propositions and the constants @xmath and @xmath plus a ternary operator
@xmath . The constants @xmath and @xmath denote true and false,
respectively. The ternary operator denotes conditional composition i.e.,
an if-then-else operator. For example, @xmath translates to if @xmath
then @xmath else @xmath . This then clues us to the order in which
expressions of this type are evaluated i.e., the antecedent is evaluated
first. The question which of the two consequents is then evaluated first
is irrelevant because their value depends only on the antecedent and not
on each other.

For example, take the expression

  -- -------- --
     @xmath   
  -- -------- --

The letters @xmath and @xmath represent atomic propositions. The above
reads thus if a then a else b . In sentential logic, it suffices to know
the value of @xmath and @xmath to know whether the sentence is true or
false, see the following table:

  -- -------- --
     @xmath   
  -- -------- --

However this is not the case if we are using reactive valuations.
Keeping the if-then-else interpretation in mind, we intuitively begin by
evaluating the middle @xmath , the antecedent. The act of evaluating
this @xmath can possibly have influence on the valuation of the
left-hand @xmath and the right-hand @xmath . We denote the value of
@xmath given a valuation @xmath as @xmath . Furthermore, the valuation
obtained after evaluating @xmath is denoted as @xmath . So @xmath can be
viewed as a function that maps reactive valuations to other reactive
valuations. The value @xmath is determined by the values of @xmath ,
@xmath and @xmath , as illustrated in the following table:

  -- -------- --
     @xmath   
  -- -------- --

Compared to sentential logic, we have an extra parameter because @xmath
. Note that it is not possible for the valuation of @xmath to influence
the valuation of either of the @xmath ’s. Nor is it possible that the
left-hand @xmath has influence on the valuation of the middle @xmath or
the right-hand @xmath .

There are other limitations to reactive valuations. For example, take
the expression @xmath . This has the following truth table:

  -- -------- --
     @xmath   
  -- -------- --

The value of @xmath is in this case just computed using two values
@xmath and @xmath . It is not possible to assign different values to the
left-hand @xmath and the right-hand @xmath using reactive valuations
because reactive valuations do not take into account the value of
previously observed atomic propositions. Only the act of evaluating
atomic propositions influences reactive valuations, regardless of what
those values might have been.

The class of all reactive valuations is referred to as the free reactive
valuations. We can construct different logics by constraining the type
of reactive valuations we allow. For example, if we take the class of
reactive valuations that ignore the sequence of previously evaluated
atomic propositions, we get the static valuations. Static valuations
coincide with the classical valuations in sentential logic i.e., they
always give the same value for an atomic proposition independent of
context.

Another example of a class of reactive valuations are the contractive
valuations. In these valuations the value of an atomic proposition, say
@xmath , remains the same as long as no atomic proposition other than
@xmath is evaluated. This is in contrast with the free reactive
valuation where each instance of atomic proposition @xmath in a sequence
of @xmath ’s can have a different value. For example, if we are using
free reactive valuations it is possible to assign different values to
the @xmath ’s in the expression @xmath . This is not possible if we are
using contractive valuations because between the first @xmath and the
second @xmath no other atomic proposition is evaluated, and thus the
valuation of @xmath must remain the same.

We can formalize the idea of creating new logics using classes of
reactive valuations. A class @xmath of reactive valuations gives rise to
an equivalence relation, @xmath -equivalence. Since reactive valuations
are sensitive to the context, this @xmath -equivalence is not
necessarily congruent i.e., equivalence of a term @xmath need not be
preserved when substituting equivalent subterms in the term @xmath . For
example, for every reactive valuation @xmath we have @xmath . It is
however not the case that @xmath because in the right-hand term the
valuation of @xmath depends on @xmath which is not the case in the
left-hand term. Since congruence is a necessary property, we therefore
introduce @xmath -congruence as the largest congruence contained in
@xmath -equivalence. @xmath -congruence thus represents our semantics.

Besides a semantical characterization, each logic can be equationally
specified using a number of axioms. For example, the axiom @xmath ,
where @xmath and @xmath are arbitrary terms, is an axiom shared by every
logic we present. Given these axiomatizations we can prove properties
such as soundness and completeness.

In the rest of this chapter we further motivate why reactive valuations
are relevant, and discuss some related work. In Chapter 2, a formal
introduction is given to reactive valuations. In addition, four
varieties are introduced and discussed. These varieties include the
varieties of free, contractive and static valuations we mentioned
earlier. This discussion includes proper axiomatizations and subsequent
proofs of completeness and soundness of these varieties. In Chapter 3 a
definition of @xmath -completeness is given, and we explain why @xmath
-completeness is a nice property of an axiomatization. Subsequently, a
proof of @xmath -completeness for the variety of free reactive
valuations and the variety of static valuations is presented. The
axiomatizations given in Chapter 2 might contain redundant axioms. In
Chapter 4, we show that this is mostly not the case. Finally, Chapter 5
contains a summary, and a few suggestions for further research.

### 1.2 Motivation

Static valuations, the type of valuations used in sentential logic, are
inadequate to model many sequential systems. However, we can model those
systems using different classes of reactive valuations.

Using reactive valuations we can model non-commutative logical
connectives. For example, @xmath is disjunction in which the right
argument is evaluated first (notation is taken from [ 2 ] ). So in the
signature of our logic @xmath is defined as @xmath . In similar fashion
@xmath is defined as @xmath . In sentential logic these two definitions
would coincide. This however is not the case if we use reactive
valuations i.e., this allows us to distinguish between @xmath and @xmath
. Hence, reactive valuations are suited for modelling non-commutative
connectives. One area where non-commutative connectives are commonplace,
is that of programming languages

In most programming languages, it is possible that a function, in
addition to producing a value, also does something else. It might for
example raise an exception or modify a global variable. This kind of
behaviour is called a side-effect of said function. Furthermore, it is
also possible that the return value of a function might depend on some
external factor. For example, a database or a random number generator.
Finally, expressions are evaluated sequentially. This means that if want
to evaluate @xmath , the interpreter has to decide whether to evaluate
@xmath first or @xmath first.

Combining these facts, we could get a situation in which the value of
the expression @xmath depends on whether @xmath is evaluated first or
@xmath because @xmath might influence the value of @xmath , and vice
versa. Admittedly it is limited to situations that can be translated to
boolean formulas, but this is the kind of behaviour we can model with
reactive valuations and not with sentential logic.

Short-circuit evaluation is a common feature of programming languages.
Short-circuit evaluation is usually limited to the evaluation of a few
specific operators. Using such evaluations only the arguments that have
to be evaluated, are actually evaluated. The operator
           &&           , logical conjunction, in C/C++ is an example of
a short-circuiting operator. Consider evaluating the expression
           x && y           . If            x           evaluates to
false, the second argument            y           is not evaluated
because regardless of its value            x && y           evaluates to
false. If @xmath and @xmath do not have any side-effects and their
values are limited to true and false, this operator is commutative.
However, in practice it is possible that @xmath and @xmath represent
some computation that does not necessarily terminate. Consequently, if
one of the arguments does not terminate, the value of a short-circuiting
operator like            &&           might be different depending on
which argument we decide to evaluate first. Hence, this is another
example of a non-commutative connective with a symmetric counterpart.

Arguably the programming language with the most direct connection with
reactive valuations is Prolog. Prolog is originally designed to model
language through computational models based on predicate logic. This
paradigm of programming in terms of predicate logic is called logic
programming. As a result, programs in Prolog almost read like logical
formulas, and are referred to as predicates. In the early days of logic
programming, the language did not have any instructions with explicit
side-effects. However, for Prolog to have some practical value extra
instructions are needed. For example, the database instructions assert
and retract . These instructions can, perhaps not surprisingly, assert
and retract facts to a Prolog program. Clearly, programs using these
instructions have side-effects that might influence whether predicates
evaluate to true or false. For example, predicate @xmath is true if fact
@xmath is true. In addition, predicate @xmath retracts fact @xmath .
Hence, if there is another predicate @xmath , which is true if @xmath is
true, and retracts @xmath , the predicates influence each others value
by their side-effects.

Staying within the field of computer science, the “reactive behaviour”
illustrated by the previous examples does not limit itself to
programming languages. On the more lower hardware level we have the term
“sequential logic” in circuit theory. Here sequential logic refers to
logic circuits that have a memory. The output of such a circuit does not
only depend on the input, but also on the history of inputs. These
circuits can be used to construct finite state machines such as Moore
and Mealy machines. The output of these machines depends on an internal
state, which in turn depends on the previous state and input.

In everyday reasoning, so called common-sense reasoning, the assertion
and retraction of facts is fairly common. For example, while it may be
true that Jack is at home in the evening, it certainly does not have to
be true that he is always at home. In addition, this is not limited to
the physical world but can also include the beliefs of agents. For
example, one might believe that all adult swans have white plumage,
until one travels to Australia and sees that there are swans with black
plumage, at which point the beliefs are revised. Ordinary classical
logic is not equipped to model these reactive processes i.e., the
validity of propositions remains the same.

Pragmatics is a subfield of linguistics in which the interaction between
utterances i.e., speech acts, is studied. One example of such
interaction is that of presupposition. Presupposition refers to implicit
assumptions in sentences. Take for example the sentence “Jack drives his
car to the mall”. This sentence presupposes that Jack has a car. So
modelling presupposition requires we are able to deal with side-effects
of posing a proposition, another example of reactive evaluation.

In this section we presented a number of processes that might be
modelled using reactive valuations as motivation why reactive valuations
are interesting. In the following section most of the aforementioned
examples will be examined once more except this time in the context of
related work i.e., we compare existing literature on these subjects with
reactive valuations.

### 1.3 Related work

One of the defining properties of our logic is that the valuation of the
atomic propositions changes depending on what atomic propositions have
been evaluated. In this section we discuss some other logics and
formalisms that also demonstrate this property.

As stated earlier in this thesis is based on the work done by Bergstra
and Ponse in [ 5 ] . In it they introduce reactive valuations and the
varieties which we will study in the next chapters. They discuss a
number of topics which will not be covered in this thesis. These topics
include a method of modelling a three-valued logic using reactive
valuations, expressivity results, the complexity of satisfiability, and
a study of the properties of infinite propositions.

Since reactive valuations are a relatively new invention with no clearly
defined predecessor, there is no related work that deals specifically
with reactive valuations besides the one by Bergstra and Ponse. There
is, however a very large body of literature dealing with sequential
reasoning. This literature ranges from computer science to philosophy
and linguistics. An exhaustive literature overview is however beyond the
scope of this thesis and would in all likelihood constitute a thesis all
on its own. This chapter, therefore, gives a very brief overview with a
few specific examples, which will hopefully offer a starting point for a
more detailed account of related work.

The previous section on motivation already gave a few examples of areas
where reactive valuations might be applied and hence literature dealing
with the phenomena described in that section can be considered related
to the theory of reactive valuations.

For example we mentioned common-sense reasoning i.e., the type of
reasoning we use in our daily lives. Common-sense reasoning has been
studied in many fields but it has enjoyed renewed attention the past
decades with the rise of the field of artificial intelligence where it
is mostly referred to as non-monotonic reasoning.

In classical logic when a statement @xmath logically follows from a set
@xmath of premises, it is the case that @xmath logically follows from a
superset @xmath of premises. Consequently, we call this logic monotonic.
This means that once something is true it will remain so. In
common-sense reasoning this is not the case. Hence this type of
reasoning is called non-monotonic. Similarly reactive valuations are
non-monotonic due to ever-changing valuations. See [ 17 ] and [ 1 ] for
an overview of non-monotonic reasoning.

Similarly in philosophy we have defeasible reasoning which deals with
arguments that might be true but can be refuted at a later point by
observing new facts, see [ 10 ] .

We can view the evaluation of an expression as the execution of a
program. The atomic propositions would then correspond to single
instructions or pieces of programs such as procedures or functions.
There are many formalisms that are designed for reasoning about
propositional properties of programs, e.g. Hoare logic, temporal logic
of actions and propositional dynamic logic (PDL).

For example, PDL (see [ 18 ] for an overview) can be effectively used to
model reactive valuations. In PDL we have a set of atomic propositions
@xmath , a set of basic actions @xmath , a set of states @xmath , and a
binary relation @xmath on @xmath . The connection between PDL and
reactive valuations becomes evident if for every atomic proposition in
@xmath there is a basic action in @xmath that signifies the evaluation
of the respective atomic proposition. Then the states @xmath correspond
to the various reactive valuations. In that context deterministic PDL
i.e., the class of frames characterized by @xmath , is of particular
interest because it illustrates one of the limitations of reactive
valuations. Namely, that in the previously mentioned example @xmath the
value of both @xmath ’s will have to be the same.

As mentioned in the previous section the programming language Prolog has
special instructions for the assertion and retraction of facts. Consider
the following Prolog program

        p(a) :- p(b), retract(p(b)).
        p(a) :- assert(p(b)), fail.

The statement            fail           is a reserved keyword that
automatically fails i.e., somewhat similar to the constant false. When
repeatedly asking the interpreter            p(a)           we get the
output sequence 0101010101…where 0 and 1 stand for
           no           and            yes           , respectively.

In [ 13 ] the expressive power of the side effects of the assert and
retract statements in Prolog is investigated. The authors main tool in
this analysis are these output sequences. Much the same as we consider
different varieties they consider different classes of output sequences
e.g., constant sequences that represent programs with no side effect and
ultimately periodic sequences where the sequence at some point starts to
repeat itself. For a complete denotational semantics of Prolog, see [ 15
] .

Reactive valuations give rise to directed versions of connectives such
as @xmath and @xmath . In Chapter 2 we define a number of these
connectives. The notation for these is taken from [ 2 ] , where a number
of many-valued logics are described. In [ 16 ] an axiomatization of
Belnap’s four-valued logic is given using conditional composition, which
as you might recall is the only connective in the signature of the logic
described in this thesis. The notation for conditional composition is
taken from a paper by Hoare, [ 8 ] . In this paper Hoare describes what
we call the variety with static valuations. This variety corresponds to
boolean algebra, as we shall show in Chapter 3.

In the previous section we briefly mentioned pragmatics, and more
specifically presupposition. The most commonly used formalism to
describe presupposition and its effects is discourse representation
theory (see [ 9 ] ). There are, however, different approaches. For
example, in [ 11 ] a many-valued logic with directed connectives is used
to investigate some of the main problems in presupposition.

Besides the ones we just mentioned, there are many other research areas
that deal with sequentiality that we did not mention here. For example,
temporal logic, substructural logics and non-commutative logics. As
mentioned before this section is but a brief overview, and we hope this
will prove to be a useful point of departure for a more thorough
investigation into related work.

Lastly, it took more than two years to write this thesis. This year a
new paper on the subject of reactive valuations by Bergstra and Ponse
appeared, see [ 4 ] . The new results in that paper are not discussed
here nor do the results in this thesis depend on those results.

## Chapter 2 Reactive valuations

This chapter represents the main body of the thesis. Reactive valuations
are formally introduced, which enables us to define a number of
different logics. Subsequently, some basic properties such as soundness
and completeness are proven.

### 2.1 Introduction

In this section we introduce a sequential propositional theory starting
with the language. The symbols of our language are as follows:

-   the constants @xmath and @xmath

-   the ternary operator @xmath , called conditional composition

-   a finite non-empty set @xmath of atomic propositions

-   an infinite set of variables @xmath

The notation @xmath for conditional composition was first introduced by
Hoare in [ 8 ] . We use the letters @xmath to denote the variables, and
the letters @xmath to denote atomic propositions i.e., members of @xmath
. Note that @xmath is finite and non-empty. These conditions on the set
of atomic propositions are relevant because they affect the validity of
certain theorems, particularly those dealing with independence and
@xmath -completeness as we shall see in the next chapter. We call this
signature @xmath .

The set @xmath of all terms over signature @xmath is defined as the
smallest set such that

-   @xmath

-   @xmath

-   @xmath

-   @xmath with @xmath

Subsequently, the set @xmath of all closed terms over signature @xmath
is defined as the largest subset of @xmath such that no term in @xmath
contains a variable. The letters @xmath are used to denote members of
@xmath whereas we use @xmath to denote closed terms i.e., members of
@xmath .

We postpone the discussion of the actual model construction until the
next two sections. For now it suffices to recall the interpretation we
offered in the introduction i.e., @xmath and @xmath are interpreted as
true and false, respectively, and @xmath is the if-then-else operator,
where the middle argument is the antecedent and the left-most and
right-most argument are the consequents.

Using the language we just introduced it is now possible to give the
following axiomatization:

  -- -------- --
     @xmath   
  -- -------- --

We call this set of axioms CP. Hence when @xmath , for terms @xmath and
@xmath from signature @xmath , can be derived from CP, we denote this as

  -- -------- --
     @xmath   
  -- -------- --

Henceforth we often omit the “ @xmath ” part except when it is not clear
from the context which set of axioms is used.

It is also important to note that the equality is in fact a congruence.
Consequently, equality has besides the usual properties of reflexivity,
symmetry, and transitivity

  -- -------- --
     @xmath   
  -- -------- --

also the congruence property, which in this case will have the following
form

  -- -------- --
     @xmath   
  -- -------- --

Using this axiomatization and its intended interpretation, we can define
versions of the classical connectives.

  -- -- --
        
  -- -- --

where @xmath . The notation of the operators is due to Bergstra, Bethke,
and Rodenburg in [ 2 ] . The circle in the connective indicates the
order in which the expression is evaluated e.g., @xmath indicates that
we evaluate @xmath before looking at @xmath . In the following sections
we show that although e.g. @xmath and @xmath have the same
interpretation in classical logic, they are not provably equal in CP.
Also properties such as idempotency, commutativity, distributivity and
absorption are not derivable in CP. However, there are some classical
properties that are derivable in CP. For example we have the following
property,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

which implies that

  -- -------- --
     @xmath   
  -- -------- --

Another example is based on De Morgan’s laws,

  -- -- -------- --
        @xmath   
        @xmath   
        @xmath   
        @xmath   
                 
  -- -- -------- --

Using conditional composition, we can create the notion of sequential
composition, denoted by @xmath i.e.,

  -- -------- --
     @xmath   
  -- -------- --

By axiom CP4 it follows that sequential composition is associative,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In the following sections we not only give a model for the discussed
axiomatization CP but also show that given the provided framework, it is
easy to create variations on this model.

### 2.2 Reactive valuations

In the classic case a valuation determines the value of all the atomic
propositions @xmath i.e., it assigns either true or false to each atomic
proposition. In the case of reactive valuations, this assignment can be
dependent on atomic propositions previously evaluated. In this section
we will formally define the notion of reactive valuations.

Let @xmath be the sort of boolean values with constants @xmath and
@xmath and @xmath be a sort of reactive valuations. Then for each @xmath
let there be a function

  -- -------- --
     @xmath   
  -- -------- --

This function is called the yield of @xmath and it allows us to look up
the value of @xmath using a specific reactive valuation. Furthermore,
for each @xmath there exists a function

  -- -------- --
     @xmath   
  -- -------- --

called the @xmath -derivative. With this function we can capture the
dynamic nature of reactive valuations i.e., when we evaluate an atomic
proposition @xmath the current reactive valuation can change. It is
important to note that the elements in @xmath do not just encode the
value of the individual atomic propositions but also keep a history of
atomic propositions previously evaluated. It is therefore possible that
two reactive valuations @xmath and @xmath assign the same values to each
atomic proposition but @xmath .

We define the signature @xmath to consist of the sorts @xmath , @xmath ,
functions @xmath and @xmath for each @xmath , and constants @xmath and
@xmath of sort @xmath .

A structure @xmath over @xmath is called a reactive valuation algebra
(RVA) if the following axioms are satisfied

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

for each @xmath . So the constants @xmath and @xmath assign either
@xmath to all the atomic propositions or @xmath to all the atomic
propositions, respectively. Furthermore, these two valuations do not
change while evaluating an expression.

The value of a proposition @xmath from signature @xmath according to a
reactive valuation @xmath in a RVA @xmath is denoted by

  -- -------- --
     @xmath   
  -- -------- --

This value is determined as follows: for @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath is a generalized notion of the function @xmath , and is
defined as follows

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

There are a number of observations to be made here.

The propositions @xmath and @xmath are always evaluated as true and
false, respectively, no matter which evaluation we use. Furthermore,
evaluating @xmath and @xmath will not change the current valuation. So,
it follows that @xmath .

Also important to note is that in e.g. the proposition @xmath the values
of @xmath and @xmath will not depend on @xmath as @xmath never gets
evaluated.

Finally, let us look at a few examples.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Note that if we know that @xmath then it does not necessarily follow
that @xmath is also true because the valuations @xmath and @xmath are
different. To emphasize this point, look at propositions @xmath and
@xmath . Although, it certainly is true that in a classical setting
these two are equivalent, it immediately follows that a valuation @xmath
exists such that @xmath .

The following example has instead of a constant or an atomic proposition
as a condition, another conditional statement.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

This example illustrates that the value of the leftmost @xmath does not
only depend on @xmath being evaluated but also on the actual value of
@xmath because this determines whether either @xmath or @xmath (the
occurrence of @xmath right next to @xmath in the expression) is
evaluated which in turn affects the value of the leftmost @xmath .

### 2.3 Reactive valuation varieties

In the previous section we introduced the notion of reactive valuation
algebra (RVA). In this section we define a number of specific classes of
RVAs. Since the signature of all RVAs is the same, we refer to these
classes as varieties. We define the following varieties of RVAs:

  Free reactive valuations  

    This variety of RVAs consist of all possible RVAs. So there are no
    requirements posed on the RVAs in this variety other than that they
    are RVAs. Every other variety will be a subvariety of this one.

  Repetition-proof valuations  

    The variety with repetition-proof valuations consists of all RVAs
    that satisfy

      -- -------- --
         @xmath   
      -- -------- --

    for all @xmath .

  Contractive valuations  

    The variety with contractive valuations is a subvariety of the
    variety with repetition-proof valuations i.e., every RVA in this
    variety will also be in the variety with repetition-proof
    valuations. In addition the RVAs here will satisfy

      -- -------- --
         @xmath   
      -- -------- --

    for all @xmath .

  Static valuations  

    The RVAs in the variety with static valuations satisfy the following
    equation

      -- -------- --
         @xmath   
      -- -------- --

    for all @xmath .

The definitions of these varieties were taken from [ 5 ] . In Appendix A
we define and examine an additional variety of our own.

Given a variety @xmath we say that propositions @xmath and @xmath are
@xmath -equivalent, which is denoted as

  -- -------- --
     @xmath   
  -- -------- --

if @xmath for all RVAs @xmath in the variety @xmath and valuations
@xmath . Using the relation @xmath we can define a congruence relation
over propositions. We say that @xmath and @xmath are @xmath -congruent,

  -- -------- --
     @xmath   
  -- -------- --

if @xmath is the largest congruence contained in @xmath .

Given the four varieties we defined earlier we will use the
abbreviations @xmath , @xmath , @xmath , @xmath for free,
repetition-proof, contractive and static varieties, respectively

Bergstra and Ponse prove the following proposition.

###### Proposition 2.1.

@xmath and @xmath for @xmath

The first part of this proposition and the differences between the
varieties will become apparent in the following sections. The second
part is best demonstrated using an example. If we take the term @xmath
then clearly

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and @xmath . However, it is not the case that for all
varieties @xmath the following holds

  -- -------- --
     @xmath   
  -- -------- --

because in the left-hand side the value of @xmath will depend on @xmath
but on the right-hand side this dependency is gone. This means that
although for all varieties @xmath we have @xmath , it does not follow
that @xmath . In the section on static valuations, we show that
congruence and equivalence do happen to coincide for that variety.

The following proposition clarifies the relationship between congruence
and equivalence for arbitrary variety @xmath .

###### Proposition 2.2.

If @xmath and for all @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume @xmath and @xmath , @xmath . Since @xmath is defined as the
largest congruence contained in @xmath , @xmath if for all closed terms
@xmath and @xmath the following three cases are true:

-   @xmath

-   @xmath

-   @xmath

We continue by proving these three cases.

Since @xmath , it follows that @xmath , @xmath . Consequently, @xmath .
Hence,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So case (1) is true. Furthermore, the argument for case (3) is symmetric
to the one give here. So case (3) is also true.

By assumption we know that @xmath and @xmath . Thus,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Consequently, case (2) also holds, and @xmath . ∎

In the following sections we will further discuss the varieties we
defined here. This discussion will include proper axiomatizations, and
proofs of soundness and completeness.

### 2.4 Notation and conventions

Before continuing with the in-depth discussion of the varieties, we
recap and introduce additional notation and conventions. We have
encountered the following equality relations thus far:

-   @xmath denotes semantic equivalence with respect to variety @xmath .

-   @xmath is the largest congruence contained in @xmath .

-   Plain @xmath is used to denote three different types of congruences.
    The first type is provable equality e.g. @xmath . However we often
    omit the “ @xmath ” part if it is clear from the context which
    axiomatization we use. We also use @xmath in the interpretation of
    terms given some valuation @xmath e.g. @xmath . Finally we use
    @xmath for equality between valuations e.g. @xmath . Note that no
    ambiguity arises from these three different interpretations because
    they deal with equality over three distinct classes of objects and
    it will be immediately clear from the arguments or the context how
    @xmath is used.

Absent from this list is syntactic equality. We therefore introduce the
symbol @xmath for syntactic equality ¹ ¹ 1 Often @xmath is used to
denote syntactic equality. However, since @xmath is already used for
semantic equivalence, we opted to use @xmath in order to avoid
confusion. .

We have the following conventions concerning symbols:

-   The letters @xmath denote atomic propositions. @xmath is the set of
    all atomic propositions.

-   The letters @xmath denote variables. @xmath is the set of all
    variables.

-   The capital letters @xmath denote closed terms. @xmath is the set of
    all closed terms from signature @xmath .

-   The letters @xmath denote terms that can possibly, but not
    necessarily, be open. @xmath is the set of all terms.

### 2.5 Free reactive valuations

@xmath -Congruence is axiomatized by CP. The variety with free reactive
valuations is the variety on which all other varieties are based. This
does not mean that there are no limitations. For example if we take the
term @xmath it is not possible to distinguish between the two @xmath ’s
i.e., we are forced to give them the same value no matter what valuation
we choose. This limitation can be found in the definition of RVA where
we define @xmath and @xmath as functions instead of relations.

#### 2.5.1 Soundness

We have claimed that @xmath -congruence is axiomatized by CP. We,
however, have not yet proven that the resulting theory is sound and
complete with respect to our model. In this section we will show that CP
is sound. Soundness of a theory with respect to a model means that
whatever we derive from the axiomatization of the theory is also true in
that model.

###### Theorem 2.3.

For all closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

It suffices to show that the four axioms CP1, CP2, CP3 and CP4 are sound
with respect to the variety with free reactive valuations. Let RVA
@xmath from the variety @xmath with valuation @xmath be given. Then,
starting with CP1 we proceed as follows.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

We use the semantics we defined in the previous sections to evaluate the
left-hand side of CP1 with an arbitrary valuation @xmath , and end up
with the right-hand side. In addition, observe that we do not pose any
requirements on @xmath . Consequently, the above derivation holds for
all RVAs @xmath and @xmath . Furthermore, we also have the following:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Thus, by Proposition 2.2 , we have proven that CP1 is sound.

Using the same strategy we prove that axioms CP2, CP3 and CP4 are sound.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Showing that axiom CP4 is sound, is a bit more complicated than the
previous three axioms because of the number of cases involved.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Since

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

it is possible to e.g. replace @xmath if @xmath , and @xmath if @xmath
by the expression @xmath . So continuing from where we left off,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So all axioms are sound with respect to @xmath . ∎

#### 2.5.2 Completeness

In this section we prove completeness. The axiomatization @xmath is
complete with respect to the variety with free reactive valuations, if
two closed terms are @xmath -congruent then these terms are also
provably equal in @xmath .

Before proving completeness we first introduce basic forms, which are a
class of closed terms. We will show that each closed term is provably
equal to a basic form. The primary reason for introducing these basic
forms is that they will greatly simplify most proofs by structural
induction on closed terms because their structure is less complicated.
This will be especially useful in proving completeness.

###### Definition 2.4.

The set of basic forms is defined as the smallest set such that @xmath ,
and if @xmath then @xmath for all atomic propositions @xmath .

So e.g. @xmath is not a basic form but @xmath is. Similarly, @xmath is
not a basic form but @xmath is. If conditional composition occurs in a
basic form, the antecedent is always an atomic proposition.

An alternative way of looking at basic forms is to view them as labeled
binary trees i.e., the basic form @xmath corresponds to the tree

  -- -- --
        
  -- -- --

where @xmath and @xmath are the binary trees corresponding to @xmath and
@xmath , respectively. Hence, the nodes of the tree consist of atomic
propositions and the leaves of either @xmath or @xmath . This
illustrates the simplicity of basic forms because if we would try to
similarly construct a binary tree for arbitrary closed terms, the nodes
themselves would have to be trees because the antecedent of conditional
composition occurring in such a term can itself be an arbitrary closed
term.

As mentioned before we will prove that for each closed term there exists
a basic form such that they are provably equal to each other.

###### Lemma 2.5.

For each closed term @xmath over signature @xmath there exists a term
@xmath such that @xmath .

###### Proof.

We proceed by structural induction on @xmath . Suppose @xmath is either
@xmath or @xmath then @xmath . Suppose @xmath for @xmath . ² ² 2 Recall
that @xmath is used for syntactic equality. Since @xmath and @xmath ,
@xmath exists. Suppose @xmath is @xmath . By the induction hypothesis
there exist terms @xmath such that @xmath , @xmath , and @xmath . By
congruence, it follows that @xmath . We show by structural induction on
@xmath that @xmath exists.

If @xmath , then @xmath , and @xmath is a basic form. Similarly, if
@xmath is @xmath , then @xmath , and @xmath . If @xmath for some @xmath
then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath and @xmath , @xmath . Clearly, @xmath . ∎

The following lemma is needed in the Lemma 2.7 that shows that syntactic
equality and @xmath -congruence coincide.

###### Lemma 2.6.

For @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We prove the contraposition. Then either @xmath or @xmath implies @xmath
. Assume without loss of generality that @xmath . Then the following two
cases can be distinguished.

In the first case, @xmath . Consequently, there exists an algebra @xmath
and valuation @xmath such that @xmath . Subsequently, we construct an
algebra @xmath with valuation @xmath such that @xmath and @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In the second case, @xmath . So the congruence property does not apply
to @xmath and @xmath . It follows that there are closed terms @xmath and
@xmath such that one of the following is the case:

-   @xmath

-   @xmath

-   @xmath

In each of the three the cases there is an algebra @xmath and valuation
@xmath such that the left-hand side and the right-hand side are not
equal using valuation @xmath . Using this valuation @xmath we know that
in case (1) the following applies:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Consequently, @xmath . However, this implies that @xmath . Since we
already assumed that @xmath , we have a contradiction. Hence, case (1)
cannot occur. Using a similar argument, we can show that this also
applies to case (2).

This leaves us with case (3). Let @xmath and @xmath be defined as
before. Then, similarly to the case where @xmath , we construct a new
algebra @xmath and valuation @xmath such that @xmath and @xmath .
Consequently,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So the congruence property does not hold for @xmath and @xmath , and
thus these terms are not congruent to each other, @xmath . ∎

It is perhaps interesting to observe that the other direction of the
previous lemma follows from congruence i.e., if we know that @xmath and
@xmath then @xmath .

The next lemma shows that syntactic equality and @xmath -congruence
coincide.

###### Lemma 2.7.

For @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The direction from syntactic equality to @xmath -congruence is trivial.
The other direction is proven by taking the contraposition and then
proceeding by structural induction on both @xmath and @xmath . So assume
@xmath . We omit the trivial cases and the cases that follow by
symmetry.

Suppose @xmath and @xmath for some @xmath . If @xmath then @xmath by
congruence. However,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Note that we can always construct an algebra @xmath and @xmath such that
neither @xmath nor @xmath .

Suppose @xmath and @xmath . Then we can assume without loss of
generality that @xmath . By I.H., it follows that @xmath . By Lemma 2.6
, @xmath .

Of course, if @xmath and @xmath , we can simply pick an algebra @xmath
and valuation @xmath such that @xmath . ∎

Now the stage has been set to prove completeness for not just basic
forms but for all closed terms.

###### Theorem 2.8.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath . By Lemma 2.5 , there exist terms @xmath such that @xmath
and @xmath . Furthermore, by soundness, it follows that @xmath and
@xmath , and thus @xmath . Finally, by Lemma 2.7 , we get @xmath which
implies that @xmath . ∎

### 2.6 Repetition-proof valuations

Recall that the variety with repetition-proof valuations is
characterized by the following equation:

  -- -------- --
     @xmath   
  -- -------- --

This restricts the type of valuations we allow in this variety. The
consequences of introducing this restriction are perhaps best explained
using an example. Take a look at the following evaluation of the term
@xmath using a repetition-proof valuation @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Observe that since @xmath it follows that the case where @xmath and
@xmath never occurs. Thus during the evaluation of @xmath the @xmath is
never evaluated, and thus we can replace @xmath with any term we like
which in this case is another atomic proposition @xmath . However, this
does not mean that @xmath because the evaluation of @xmath depends on
both @xmath ’s.

Similar to the free reactive valuations, we can define a corresponding
axiomatization. In this case, the axiomatization consists of CP plus the
following two axiom schemas,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

for all @xmath . We call the entire axiomatization @xmath . The axioms
@xmath and @xmath combined with CP tell us that the value of an atomic
proposition @xmath does not change unless there is another proposition
in between them.

An example of repetition-proof behaviour can be found in programming.
For example, an atomic proposition corresponds with a function that
updates a global variable but its output does not depend on this
variable.

As in the previous section we proceed by proving soundness and
completeness, starting with soundness.

#### 2.6.1 Soundness

###### Theorem 2.9.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

According to Proposition 2.1 , we know that @xmath . Since we already
checked the soundness of the axioms in CP in the proof for soundness of
free reactive valuations, it suffices to show soundness for @xmath and
@xmath , starting with CPrp1. Let @xmath be a RVA from variety @xmath
and valuation @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

By Proposition 2.2 CPrp1 is sound. Next we show soundness for CPrp2:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So CPrp2 is also sound. ∎

#### 2.6.2 Completeness

Similar to the previous section we define a set of basic forms for this
variety. Since we are working with a different variety the set of basic
forms needs to change. If we were to use the set i.e., the set of basic
forms as defined in the section on free reactive valuations, as the
basic forms of this variety then syntactic equality and @xmath
-congruence would not coincide. For example, let the terms @xmath and
@xmath be in and let @xmath then these terms are @xmath -congruent but
not syntactically equal. So we need to define a new set of basic forms.

###### Definition 2.10.

The set of repetition-proof basic forms is the smallest set @xmath such
that @xmath and if @xmath then

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

for all @xmath .

Clearly, the set @xmath is a subset of . The four cases mentioned in the
definition are based on the axioms @xmath and @xmath .

###### Lemma 2.11.

For each closed term @xmath there exists a term @xmath such that @xmath
.

###### Proof.

We prove this theorem by structural induction on @xmath . By Lemma 2.5
it follows that we can assume without loss of generality that @xmath is
a basic form as defined in the section on free reactive valuations i.e.,
@xmath .

If @xmath is @xmath or @xmath then @xmath . Suppose @xmath is @xmath .
By the induction hypothesis, there exist terms @xmath such that @xmath
and @xmath . Now suppose that @xmath and @xmath . Consequently,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

By definition of @xmath we have @xmath .

Using similar reasoning we can show that there exists such a term @xmath
for the remaining three cases:

-   @xmath and @xmath

-   @xmath and @xmath

-   @xmath and @xmath

∎

In the section on free reactive valuations we needed Lemmas 2.6 and 2.7
in order to prove completeness. Similarly, we would like to prove these
lemmas for this variety. However, observe that in the proofs of Lemmas
2.6 and 2.7 , we construct a new valuation algebra based on another
algebra. In the variety with free reactive valuations this is not a
problem, but in this variety we have some restrictions on our RVAs, and
thus cannot automatically assume that such a construction is possible.
Therefore, in the proofs of the following two lemmas we focus on showing
that such an algebra exists. We call an algebra from the variety with
repetition-proof valuations an rp-algebra.

###### Lemma 2.12.

For @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We prove the contraposition. We assume without loss of generality that
@xmath . Then either @xmath or @xmath .

Suppose @xmath . Then there exists an rp-algebra @xmath and valuation
@xmath such that @xmath . We show that @xmath holds whether @xmath or
@xmath . Consider the following four cases:

-   Suppose @xmath and @xmath . Since @xmath , it follows by definition
    of @xmath that @xmath and @xmath . Consequently, @xmath whether
    @xmath or @xmath .

-   Suppose @xmath and @xmath . By similar reasoning as before, we can
    conclude that @xmath . Furthermore, the value of @xmath does not
    depend on @xmath . Consequently, @xmath can be either @xmath or
    @xmath .

-   Suppose @xmath and @xmath . Argument is symmetric to the previous
    case.

-   Suppose @xmath and @xmath . Neither the value of @xmath nor that of
    @xmath depends on @xmath . Consequently, @xmath is independent of
    the value of @xmath .

Since @xmath regardless of whether @xmath or @xmath , we can assume
without loss of generality that @xmath . We construct an rp-algebra
@xmath with valuation @xmath such that @xmath . Since @xmath is an
rp-algebra we know that @xmath . Hence, it follows that @xmath because
if this were not the case then @xmath which is contrary to our
assumption. It follows that @xmath .

Suppose @xmath . Then the congruence property does not hold i.e., at
least one of the following three cases is true,

-   @xmath

-   @xmath

-   @xmath

for closed terms @xmath and @xmath . Using the same argument as in the
proof of Lemma 2.6 , it follows that cases (1) and (2) cannot occur. So
suppose case (3) is true. Then there exists an rp-algebra @xmath and
valuation @xmath such that @xmath . Using similar reasoning as in the
case for @xmath , we can assume without loss of generality that @xmath .
Thus we can construct an rp-algebra @xmath and valuation @xmath such
that @xmath and @xmath . Consequently, @xmath . Thus the congruence
property does not hold and @xmath . ∎

The following two lemmas have the perhaps odd condition that there are
at least two atomic propositions. At the end of this section we examine
what happens if there is only one atomic proposition. Note that by
definition there is at least one atomic proposition i.e., @xmath is
non-empty.

###### Lemma 2.13.

For @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We use the same argument as in the proof of Lemma 2.7 . However, in the
case of @xmath and @xmath , we claimed that we can always construct an
algebra @xmath and valuation @xmath such that neither @xmath nor @xmath
. This is not true in this variety. For example, take @xmath . Then
@xmath , and by definition of this variety, @xmath . We can solve this
by instead of taking @xmath and @xmath to show that @xmath and @xmath
are not congruent, we take @xmath and @xmath where the existence of
@xmath is guaranteed by the assumption that @xmath . Since it is
possible to construct an algebra and corresponding valuation @xmath such
that neither @xmath nor @xmath . ∎

The argument for completeness is exactly the same as in the previous
section, except that we use the lemmas proven in this section.

###### Theorem 2.14.

If @xmath then for closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Look at the following proposition to understand what happens when there
is only one atomic proposition i.e., @xmath .

###### Proposition 2.15.

If @xmath then for all @xmath , @xmath and for all @xmath , @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Proof by induction on @xmath . If @xmath is either @xmath or @xmath then
@xmath follows immediately.

Suppose @xmath then we proceed by induction on @xmath . If @xmath is
either @xmath or @xmath then it is trivial. If @xmath then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

If @xmath then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, @xmath for all @xmath and @xmath .

Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

This proposition implies for example that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In fact, Proposition 2.15 implies that for @xmath we lose any kind of
reactive behaviour, and we end up with static valuations. Furthermore,
this proposition is clearly true for every variety in which all
valuations are repetition-proof i.e., where @xmath is true. Hence, we
have the following corollary.

###### Corollary 2.16.

If @xmath and the valuations in variety @xmath satisfy the equation
@xmath then

  -- -------- --
     @xmath   
  -- -------- --

for all closed terms @xmath and @xmath .

This result will also be helpful in establishing completeness for the
variety with contractive valuations.

### 2.7 Contractive valuations

Recall that the variety with contractive valuations is characterized by
the following two equations:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The first equation should be familiar since we encountered it in the
previous section in the characterization of repetition-proof valuations.
The second equation tells us that valuations remain constant through
multiple @xmath -derivatives. Consider the following example,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In the first two steps we expand the expression using the standard free
reactive semantics. In the third step we replace @xmath with @xmath
using the definition of contractive valuations. Similarly, as in the
example given in the section on repetition valuations we can eliminate
the case where the example is equal to @xmath because @xmath must be
equal to @xmath .

By looking at the definition it becomes immediately apparent that the
variety with contractive valuations is a subvariety of the variety with
repetition-proof valuations i.e., if @xmath then @xmath , and similarly
if @xmath then @xmath . Of course both varieties are subvarieties of the
variety with free reactive valuations. This relation between the
different varieties was previously also stated in Proposition 2.1 .

@xmath -Congruence is axiomatized by CP and the following axiom schemas.

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The entire axiomatization is called @xmath . The axioms of @xmath and
@xmath allow us to eliminate consecutive atomic propositions in our
terms. So for example the terms @xmath and @xmath are provably equal.
This is of course a stronger version of what we have seen in the
previous section, which should not come as a surprise considering that
this variety is defined in terms of the repetition-proof variety.

The following two sections show soundness and completeness for this
variety.

#### 2.7.1 Soundness

###### Theorem 2.17.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Since the variety with contractive valuations is a subvariety of the
variety with free reactive valuations it suffices to show soundness for
@xmath and @xmath . Let algebra @xmath and valuation @xmath be given.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

By Proposition 2.2 , CPcr1 is sound. The proof of soundness for CPcr2 is
similar to that of CPcr1.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, CPcr2 is sound. ∎

#### 2.7.2 Completeness

As we are working with a new variety we are required to define a new set
of basic forms. Otherwise syntactic equality and @xmath -congruence will
not coincide.

###### Definition 2.18.

The set of contractive basic forms is the smallest set @xmath such that
@xmath and if @xmath then for all @xmath

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

-    if @xmath and @xmath then @xmath

This definition differs from the one for repetition-proof basic forms.
For example, @xmath is a valid repetition-proof basic form but it is not
a contractive basic form. In fact, @xmath is a subset of @xmath .

###### Proposition 2.19.

@xmath

###### Proof.

Let @xmath . Then by structural induction on @xmath we show that @xmath
. If @xmath , it follow immediately that @xmath .

Suppose @xmath . By definition, @xmath . Hence, by I.H., it follows that
@xmath . By definition of contractive basic forms, @xmath and @xmath .
Consequently, @xmath . ∎

The following lemma shows that the set @xmath is indeed the set of basic
forms we want.

###### Lemma 2.20.

For each closed term @xmath there exists a term @xmath such that @xmath
.

###### Proof.

By structural induction on @xmath . We can assume that @xmath because
Lemma 2.5 is applicable.

If @xmath is @xmath or @xmath then @xmath . Suppose @xmath is @xmath .
By the induction hypothesis, there exists terms @xmath such that @xmath
and @xmath . Now suppose that @xmath and @xmath . Consequently,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

By definition of @xmath we have @xmath .

Using similar reasoning we can show that there exists such a term @xmath
for the remaining three cases:

-   @xmath and @xmath

-   @xmath and @xmath

-   @xmath and @xmath

∎

The following two lemmas are needed for proving completeness for all
closed terms.

###### Lemma 2.21.

For @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We use a similar proof as the one for Lemma 2.6 . Note that the problems
that occurred in the variety with repetition-proof valuations from
having either @xmath or @xmath cannot occur here by construction of the
contractive basic forms i.e., if either @xmath or @xmath are
syntactically equal to those terms then @xmath would not be true. ∎

###### Lemma 2.22.

For @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We use a similar proof as the one for Lemma 2.13 . ∎

Similar to the previous varieties, now that we have proven these lemmas,
completeness for all closed terms follows.

###### Theorem 2.23.

If @xmath then for closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

By definition there is at least on atomic proposition. In the section on
repetition-proof valuation we proved Corollary 2.16 . Clearly, this
corollary also applies for this variety because @xmath is also true in
this variety. Hence, if @xmath , contractive congruence @xmath coincides
with static congruence @xmath .

### 2.8 Static valuations

Static valuations correspond with classical propositional logic. As such
the value of atomic propositions does not depend on other atomic
propositions.

@xmath -Congruence is axiomatized by CP and the following two axioms,
due to Hoare in [ 8 ] :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The first axiom @xmath tells us that the value of atomic propositions
remain the same despite their relative position in the term. The second
axiom @xmath is a generalization of the axioms for contractive
valuations in the previous section i.e., this axiom allows contraction
of not only atomic propositions but also for terms in general. We call
the axiomatization of @xmath -congruence @xmath .

The symmetric versions of the aforementioned axioms, listed below,
follow from @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The key in deriving @xmath and @xmath is the equality @xmath which we
proved in the free reactive valuation section. For example,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

One can prove @xmath using the same technique.

Looking at the axiomatization it might not be immediately clear that
this variety corresponds to classical propositional logic. One of the
major differences between classical propositional logic and the
varieties we have studied in the previous sections is the fact that the
values of atomic propositions in a given term do not change depending on
where they occur in the term. The following equality illustrates that
the variety with static valuations also has this property.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So appending an arbitrary term before @xmath will not change the value
of @xmath . In the next subsection we will prove its semantical
counterpart.

In the following subsections we show soundness and completeness for the
static valuations, and examine the relation between static valuations
and boolean algebras.

#### 2.8.1 Soundness

In contrast to the previous sections we cannot immediately start proving
soundness but first need the following lemma which will not only be
useful for proving soundness for this variety but also provides some
additional insight to the correspondence between this logic and
classical logic. It is worth noting that although this lemma can be
viewed as a generalization of the way this variety is defined i.e.,
@xmath , it in fact follows from the definition.

###### Lemma 2.24.

For all @xmath , @xmath and for all @xmath , @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Proof by structural induction on @xmath . If @xmath or @xmath then
@xmath is trivially true.

Suppose @xmath for @xmath . Then proceed by induction on @xmath . If
@xmath or @xmath then @xmath is trivially true. If @xmath for @xmath .
Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

This concludes the case for @xmath .

Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

The previous lemma shows that the valuation of terms is independent of
the context in which they appear. It is directly related to the equality
@xmath which we derived in the introduction to this section, in that it
similarly illustrates that the value of the atomic propositions is not
dependent on what other atomic propositions might have occurred during
the valuation of a term, and consequently it cannot change during the
valuation.

In the previously observed varieties there is a clear distinction
between equivalence and congruence. This difference was proven by using
the example where @xmath but @xmath for @xmath because @xmath . However,
as the previous lemma shows we cannot apply this example for the static
valuations. In fact the following lemma shows that in this variety
equivalence and congruence coincide.

###### Lemma 2.25.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Congruence is by definition an equivalence. So it will suffice to show
that the equivalence @xmath also has the congruence property. Suppose
@xmath , @xmath , and @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

At both the *-marked steps in the derivation we apply Lemma 2.24 . ∎

Note that the application of Lemma 2.24 in the previous proof is
necessary because otherwise @xmath and @xmath can only be replaced by
@xmath and @xmath at which point the expression cannot be further
reduced. So this line of reasoning will not work for the other varieties
where we do not have this lemma.

Now that we have proven these lemmas, soundness is relatively easy.

###### Theorem 2.26.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Lemma 2.25 , we only need to show that

  -- -------- --
     @xmath   
  -- -------- --

It suffices to show soundness for only @xmath and @xmath . Take note of
the frequent use of Lemma 2.24 in the derivations below.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus CPstat and CPcontr are sound. Soundness of the rest of the axioms
follows by the soundness of the variety with free reactive valuations. ∎

#### 2.8.2 Completeness

Proving completeness follows the same strategy as we have seen before
i.e., we define basic forms, and prove completeness for the basic forms.
However, the individual lemmas will differ significantly from what we
have seen up to this point because the construction of the static basic
forms is more complicated.

In order to define the static basic forms, we first need to enumerate
the members of @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Recall that a basic form i.e., a member of , corresponds to a labeled
binary tree. A static basic form is a member of , and is a full binary
tree with @xmath levels. At level @xmath only atomic proposition @xmath
occurs, and at level @xmath at each leaf there is either a @xmath or
@xmath . The resulting tree is pictured below:

  -- -- --
        
  -- -- --

So an atomic proposition @xmath occurs @xmath times and there are @xmath
leaves. The set of static basic forms is called @xmath .

The following two lemmas are needed to prove that there exists a static
basic form for each closed term.

###### Lemma 2.27.

For @xmath and @xmath , there exists a term @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We proceed by induction on the number of atomic propositions. Note that
since @xmath it follows that @xmath and @xmath with @xmath .

If @xmath then @xmath , and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

(*) is obtained by applying @xmath . Since @xmath is a static basic
form, we have shown the existence of @xmath .

Suppose @xmath and @xmath (if @xmath apply @xmath and @xmath ). Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Next take the left consequent,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath , @xmath , and both @xmath and @xmath are static basic
forms given the set of atomic propositions @xmath (but otherwise the
same enumeration). Note that since @xmath , we could use the I.H. in the
above derivation.

We can apply the same argument for the right consequent @xmath and
obtain @xmath and @xmath such that they are static basic forms for this
set, and @xmath and @xmath . Consequently,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Clearly, the term @xmath is a static basic form for the set @xmath . ∎

The rest of this section resembles the previous sections. So we start by
showing that there is a static basic form for each closed term.

###### Theorem 2.28.

For each term closed term @xmath there exists a @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By structural induction on @xmath . Since we already know that there
exists a provably equal basic form for each closed term @xmath (as
opposed to a static basic form), we can assume @xmath is a basic form.
If @xmath then simply construct a static basic forms where all the
leaves are either @xmath or @xmath . Suppose @xmath . By I.H. there
exist @xmath such that @xmath and @xmath . Then by the previous lemma we
know @xmath exists. ∎

Next we show that for static basic forms the congruence @xmath coincides
with syntactic equality.

###### Lemma 2.29.

For static basic forms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Since one direction is trivial, it suffices to prove that @xmath implies
@xmath . Assume @xmath for static basic forms @xmath and @xmath . By
definition of static basic forms, it follows that there is at least one
leaf that differs in value for @xmath and @xmath . For example the
leftmost leaf for @xmath has value @xmath and the leftmost leaf for
@xmath has value @xmath . It is then trivial to construct a static
valuation @xmath such that @xmath . In the example we just mentioned
this valuation would assign true to all atomic propositions. Since there
is a valuation @xmath such that @xmath , it follows that @xmath . Hence,
@xmath . ∎

Using the same reasoning as in the previous sections we obtain
completeness for all closed terms.

###### Theorem 2.30.

For closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

## Chapter 3 @xmath-Completeness

In this chapter we discuss @xmath -completeness of the different
axiomatizations we encountered thus far. The following definition of
@xmath -completeness is taken from [ 7 ] .

###### Definition 3.1.

An axiomatization @xmath over a signature @xmath is @xmath -complete if
an equation @xmath with @xmath can be derived from @xmath if @xmath can
be derived from @xmath for all closed substitutions @xmath .

The set @xmath is the set of all terms over signature @xmath . @xmath
-Completeness is also know as inductive completeness since we do not
need an additional induction theorem to prove that @xmath can be derived
if @xmath can be derived for all closed substitutions @xmath .

An example of an axiomatization that is not @xmath -complete is the
following axiomatization of the natural numbers with addition and
multiplication, taken from [ 3 ] :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

In this axiomatization every closed instance of e.g., @xmath can be
derived. However, the theorem itself cannot be derived from the above
axioms.

See [ 12 ] for a more thorough introduction to @xmath -completeness.

### 3.1 @xmath-Completeness of CP

We begin with proving @xmath -completeness for CP. First, however, it is
necessary to distinguish between a few unique cases based on the number
of elements in the set @xmath of atomic propositions. As it turns out CP
is not @xmath -complete for @xmath .

If the set @xmath is empty, and there are no atomic propositions, it
follows that every closed closed substitution @xmath replaces the
variables by terms build up from @xmath , @xmath and @xmath . Using
axioms CP1 and CP2, this is the same as replacing the variables by
either @xmath or @xmath . If we now consider the equation @xmath , we
see that for every closed substitution @xmath , @xmath follows from CP1
and CP2. However, @xmath cannot be derived from CP. If it could be
derived then it could also be derived in the case where @xmath because
the derivations are independent of the number of atomic propositions in
@xmath . So if this is the case then by soundness @xmath , which is
clearly not true.

Similarly, when there is only one atomic proposition i.e., @xmath , we
take the equation @xmath . For every closed substitution @xmath , @xmath
, where we can assume without loss of generality that @xmath replaces
variables either by @xmath , @xmath or a sequence of @xmath ’s i.e.,
@xmath . However, @xmath .

Therefore, in the remainder of the discussion of @xmath -completeness
for CP, we assume that @xmath has at least two atomic propositions,
usually referred to as @xmath and @xmath .

Similar to the sections where we showed completeness for the various
varieties, we define a set of basic forms. However, this time the basic
forms can also be open terms.

###### Definition 3.2.

Let the set of open basic forms @xmath be the smallest set such that
@xmath , and if @xmath then @xmath for all @xmath and @xmath for all
@xmath .

The set @xmath is the set of variables. The terminology “open basic
form” is a bit misleading because an open basic form can possibly be a
closed term. This definition differs from the one for the set of closed
basic forms in that terms of the form @xmath are also included. In
addition, observe that if we substitute all the variables by atomic
propositions in an arbitrary open basic form, the resulting term will be
a member of .

###### Lemma 3.3.

For all terms @xmath there exists an open basic form @xmath such that
@xmath .

###### Proof.

Proof by structural induction, very similar to the proof of Theorem 2.5
. ∎

The following lemma tells us that when dealing with open basic forms, it
suffices to use closed substitutions that map variables to atomic
propositions instead of arbitrary closed terms.

###### Lemma 3.4.

For open basic forms @xmath and @xmath , if for all closed substitutions
@xmath , ¹ ¹ 1 Note that with the notation @xmath we do not imply that
this substitution only works on variables but that the substitution
replaces the variables in a term with members of @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Then for all closed substitutions @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume there exists a closed substitution @xmath such that @xmath for
open basic forms @xmath and @xmath . We prove by induction on @xmath and
@xmath that there exists a closed substitution @xmath such that @xmath .
We omit the cases where both @xmath and @xmath are closed terms, which
are trivial, and the cases that follow by symmetry.

Suppose @xmath and @xmath or @xmath . Let @xmath be the substitution
that maps all variables to atomic proposition @xmath . Then @xmath , and
clearly @xmath . By Lemma 2.7 , @xmath .

Suppose @xmath and @xmath . Then it is trivial to see that no matter
what closed substitution @xmath we choose, @xmath . Similarly, we can
reduce the case where @xmath and @xmath , to this case by letting @xmath
and @xmath . Furthermore, the same argument can be used when one of the
terms starts with a variable and the other with an atomic proposition.

Suppose @xmath and @xmath . Since @xmath , we can assume without loss of
generality that @xmath . By the induction hypothesis, it follows that
there exists a closed substitution @xmath such that @xmath .
Consequently, by Lemma 2.6 , @xmath . We can use the same argument for
@xmath and @xmath . ∎

Note that this lemma is trivially true when @xmath . The above lemma
cannot be proven for @xmath . Take for example,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where we assume that @xmath . Then the only closed substitution @xmath
is the one that maps all variables to @xmath . Hence @xmath , and thus
@xmath . However, if we pick closed substitution @xmath such that @xmath
, then clearly @xmath .

###### Lemma 3.5.

For open basic forms @xmath and @xmath , if for all closed substitutions
@xmath , @xmath then @xmath .

###### Proof.

We prove the contraposition i.e., given that @xmath we show that there
exists a closed substitution @xmath such that @xmath . Note that if
@xmath and @xmath are closed terms then @xmath , the set of closed basic
forms. Since we already showed in Lemma 2.7 that for terms in @xmath
-congruence and syntactical equality coincide, we are done. We proceed
by induction on @xmath and @xmath , omitting the cases that follow by
symmetry.

Suppose one of the following cases,

-   @xmath and @xmath

-   @xmath and @xmath

-   @xmath and @xmath

-   @xmath and @xmath

-   @xmath and @xmath

Let @xmath be a closed substitution such that @xmath and @xmath .
Regardless of which case we pick, it follows that @xmath . Furthermore,
@xmath . Consequently, @xmath by Lemma 2.7 .

Suppose @xmath and @xmath . Since @xmath , we can assume without loss of
generality that @xmath . By the induction hypothesis, there exists a
closed substitution @xmath such that @xmath . Consequently, by Lemma 3.4
, there exists a closed substitution @xmath such that @xmath . Hence, by
Lemma 2.6 , @xmath . Using a similar argument, we can prove this for
@xmath and @xmath . ∎

The following theorem shows that CP is @xmath -complete.

###### Theorem 3.6.

Let @xmath and @xmath be open terms such that for all closed
substitutions @xmath , @xmath , then @xmath .

###### Proof.

Assume that @xmath . By Lemma 3.3 , there exist open basic forms @xmath
and @xmath such that @xmath . Hence, @xmath . By soundness, it follows
that @xmath . Consequently, by Lemma 3.5 , @xmath , and thus @xmath . It
follows that @xmath . ∎

We were not able to prove @xmath -completeness for @xmath and @xmath .
Instead we note that using the same examples as before, it follows that
both @xmath and @xmath are not @xmath -complete for @xmath .
Furthermore, proving @xmath -completeness for the case @xmath suggests
that we adjust the set of open basic forms accordingly and then prove
the same lemmas as before only this time using the altered set of open
basic forms.

### 3.2 @xmath-Completeness of @xmath

The proof of @xmath -completeness for the axiomatization @xmath is quite
different from the previous proof. We will use a back-and-forth
translation between @xmath and an axiomatization of boolean algebra of
which we know that it is @xmath -complete, to show @xmath -completeness
of @xmath .

In [ 3 ] a proof of @xmath -completeness for the axiomatization of an
@xmath -valued Post algebra is given. If we take @xmath the
axiomatization is that of a Boolean algebra. We obtain the following
axiomatization by taking @xmath , and removing some of the redundant
axioms.

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We call this axiomatization BA. The signature of BA consists of @xmath ,
@xmath , @xmath , @xmath and @xmath . Expanding the signature with a set
of atomic propositions @xmath does not affect the @xmath -completeness
of this axiomatization. We call the resulting signature @xmath . We use
the following two translations between @xmath and @xmath , starting with
the translation of @xmath to @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Note that @xmath which is perhaps more intuitive. The translation from
@xmath to @xmath looks as follows.

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Note that these are translations over all terms including open terms.
The next two lemmas show that the translations are sound i.e., if two
terms are provably equal in either @xmath or BA then their respective
translations are also provably equal.

###### Lemma 3.7.

For all terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

It suffices to show that the translations of axioms CP1-4, CPstat and
CPcontr can be derived in BA.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Using a truth table we can check that the translations of CP4, CPstat
and CPcontr are correct because BA is both sound and complete. ∎

###### Lemma 3.8.

For all terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We just need to check that the translations of axioms of BA are
derivable in @xmath . We omit the trivial derivations.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

The following two lemmas show that the translations are invariant for
each logic i.e., if a term @xmath is translated first to one logic and
then back to the original it is still provably equal to @xmath .

###### Lemma 3.9.

For all terms @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Proof by structural induction on @xmath . If @xmath then it is trivially
true. Suppose @xmath . By the induction hypothesis, it follows that

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

###### Lemma 3.10.

For all terms @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Proof by structural induction on @xmath . If @xmath then it is trivially
true. Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Suppose @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

The last lemma before proving @xmath -completeness of @xmath is a
variation of Lemma 3.4 .

###### Lemma 3.11.

If for all closed substitutions @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Then for all closed substitutions @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume that @xmath with @xmath closed substitutions. Let @xmath . Since
for all @xmath , @xmath , it follows that @xmath . Hence,

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be a closed substitution. Furthermore, define @xmath to be
the substitution such that @xmath for all @xmath . By Lemma 3.10 , it
follows that @xmath for all @xmath . Hence, @xmath and @xmath .
Consequently, by (*),

  -- -------- --
     @xmath   
  -- -------- --

Thus, @xmath . ∎

Having done the groundwork, it is now possible to prove that @xmath is
@xmath -complete.

###### Theorem 3.12.

Let @xmath and @xmath be terms over @xmath such that for all closed
substitutions @xmath , @xmath , then @xmath .

###### Proof.

Assume that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is closed. By Lemma 3.7 ,

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 3.11 ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is closed. By @xmath -completeness of BA,

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 3.8 ,

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 3.9

  -- -------- --
     @xmath   
  -- -------- --

∎

In this chapter we have shown @xmath -completeness for and @xmath .
@xmath -Completeness of the remaining two axiomatizations, @xmath and
@xmath , remains an open issue with the exception of the case where
there are less than two atomic propositions in which neither , @xmath
nor @xmath are @xmath -complete.

## Chapter 4 Independence of the axioms

In this chapter we prove that the axioms are independent from each
other. An axiom is independent with respect to a set of axioms if it
cannot be derived from the other axioms e.g., @xmath is independent in
CP if @xmath . This is a nice property for a set of axioms to have, as
it shows that there are no redundant axioms.

The standard strategy for proving that an axiom is independent consists
of constructing a model such that every axiom except the one we are
trying to prove independence for, is true in this model. In other words,
if we want to prove that CP1 is independent in CP, we show there is a
model @xmath and interpretation @xmath such that

-   @xmath implies that @xmath

-   @xmath

Hence, by contraposition of (1) it follows that @xmath . Note that this
only applies if @xmath is a model of equational logic i.e., reflexivity,
symmetry, transitivity and congruence are all true in @xmath .

In the following sections independence of axioms is shown for the
different varieties of RVAs.

### 4.1 Independence of CP

Recall that @xmath -congruence is axiomatized by the axioms in CP,
listed here again for the reader’s convenience:

  -- -------- --
     @xmath   
  -- -------- --

We start by proving independence of @xmath . In order to do this we need
to construct a model such that @xmath , @xmath and @xmath are true in
this model but @xmath is not. Take a look at the following model:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

for all @xmath with @xmath as in sentential logic and as domain @xmath .
Observe that this is a model of equational logic, in particular
congruence is true. The next step in proving independence for @xmath is
to show that @xmath does not hold under this interpretation. We do this
by giving a counterexample i.e., we take a specific instantiation of
this axiom and show that the left-hand and the right-hand side of @xmath
are not equal. If CP1 were true in this model then @xmath . However,
@xmath , and hence unequal to @xmath . Therefore, CP1 does not hold in
this model. Now we have to check whether CP2-4 do hold:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Since CP2-4 are true in this model but CP1 is not, we can conclude that
CP1 is independent with respect to CP.

Proving independence for the remaining axioms requires that we repeat
these steps for each axiom. So let us continue with proving independence
of axiom @xmath . This time we construct a model such that it models
@xmath , @xmath and @xmath but not @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

for all @xmath . Then we check whether @xmath does not hold. Since
@xmath , this is true. It is easy to see that @xmath and @xmath are true
in this model. That leaves us with checking @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So @xmath also holds under this interpretation, and thus we know that
@xmath is independent.

The previous two models looked quite similar, in particular the models
share the same domain i.e., @xmath . In proving the independence of
@xmath we will show that this is not always the case. The model we will
be constructing here has a finite set of natural numbers as domain, and
as a result differs quite a bit from the standard semantics.

The construction of this model requires that we first enumerate the
atomic propositions in the set @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Using this enumeration we can define our model:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Note that congruence is trivially true in this model. By definition
there is at least one atomic proposition i.e., @xmath . So, we can
always assume that @xmath exists. Observe that @xmath . Hence, @xmath
does not follow. Checking to see that @xmath and @xmath are true is
trivial. That leaves @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So @xmath is also independent.

Let @xmath . Take the following interpretation:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Clearly, congruence and CP1-3 are true in this model. Furthermore, it
follows that @xmath . Hence,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

However,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

So CP4 is not true using this interpretation. Hence axiom CP4 is also
independent with respect to CP. Since this is the last axiom in CP, we
have now shown independence for all the axioms in CP. Consequently,
there are no redundant axioms in CP. In the next section we will be
looking at an extension of CP i.e., the axiomatization of @xmath
-congruence.

### 4.2 Independence of @xmath

The axiomatization of @xmath -congruence is an extension of CP with the
following axioms:

  -- -------- --
     @xmath   
  -- -------- --

Note that these are actually axiom schemes i.e., for each @xmath we have
an axiom CPrp1 and CPrp2. Since we have a new set of axioms, we are
required, in addition to proving the independence of the two new axioms
@xmath and @xmath , to prove that CP1-4 is independent with respect to
this new set of axioms. Fortunately, it is possible to reuse the models
used in the previous section i.e., for the cases CP1-4 the same models
are taken. It then suffices for these cases to show that @xmath and
@xmath are true in these models.

We start by taking the same model as we did in the previous section for
proving the independence of axiom @xmath , and then checking if it
models @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Repeat this procedure for the models given for the independence-models
of @xmath , @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

We only show that @xmath holds in the model given for case @xmath
because the proof that @xmath is true in this model is symmetric to that
of @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The following shows that CP4 is also independent in @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The model for showing independence of CPrp1 is based on the reactive
valuation variety that satisfies

  -- -------- --
     @xmath   
  -- -------- --

We call this variety @xmath . By definition, this is a subvariety of the
variety with free reactive valuations. Thus, by soundness of free
reactive valuations, it follows that the resulting congruence @xmath
(constructed similarly as @xmath , @xmath , etc.) is a model for CP.
Hence, we do not have to check whether CP1-4 are true in this model.

If @xmath , it is possible that @xmath for some @xmath and @xmath .
Consequently,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, CPrp1 is not true. However, CPrp2 is.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Note that both @xmath and @xmath is impossible. Hence, we can replace
@xmath with @xmath in the above derivation.

The proof for showing independence of CPrp2 is symmetric to the one in
CPrp1, using the reactive valuation variety that satisfies

  -- -------- --
     @xmath   
  -- -------- --

We call this variety @xmath and we will use this variety in the next
section.

### 4.3 Independence of @xmath

The axiomatization of @xmath -congruence consists of CP and the
following axioms

  -- -------- --
     @xmath   
  -- -------- --

Like in the previous section, it is possible to reuse the models given
for CP, and just show that @xmath and @xmath are true in these models.
Starting with @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Similar to the previous section we omit the proof that @xmath is true in
the independence-model for @xmath as it is symmetric to that of @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Unfortunately, we have not been able to find a model that demonstrates
the independence of CP4 in @xmath . The model we used in previous
sections does not work in this variety. For example, we have the
following.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, CPcr1 is not true in the resulting model, and thus @xmath does
not suffice. The question whether CP4 is independent in @xmath remains
therefore open.

In order to construct the model that shows independence of CPcr1, we
take the variety of all algebras from variety @xmath that satisfy

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . We call this variety @xmath . It follows that there is
an @xmath and @xmath such that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Checking CPcr2:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

A proof of independence for CPcr2, starts by taking the variety of all
algebras from variety @xmath (see previous section) that satisfy

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . The proof for showing independence of CPcr2 using this
variety is symmetric to the previous proof of independence for CPcr1.

### 4.4 Independence of @xmath

In this section we show independence of the axioms CP2, CP3, CPstat and
CPcontr.

  -- -------- --
     @xmath   
  -- -------- --

The models we used in the previous sections to show independence of CP1
and CP4 cannot be used here because CPstat and CPcontr are not both true
in these models. We give two counterexamples to show this. The first
counterexample shows that CPstat is not true in the independence-model
for CP1. By CPstat the terms @xmath and @xmath should be equal. However,
this is not the case.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The second counterexample shows that CPcontr is not true in the model we
used for showing independence of CP4.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Proving independence for both CP1 and CP4 in @xmath remains an open
issue.

We can use the same models we used in the previous section for showing
independence of CP2 and CP3.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Showing independence of CPstat requires that we define the following
subvariety of @xmath which consists of all RVAs that satisfy

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Note that this is a generalization of the variety @xmath . We show that
CPstat is not true in this variety by constructing an algebra @xmath and
valuation @xmath such that @xmath , @xmath , @xmath and @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, CPstat is not true. Since this is a subvariety of @xmath , by
Theorem 2.3 it suffices to prove that CPcontr is true in this model.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

So by Proposition 2.2 CPcontr is true in this model. Since CP and
CPcontr are true and CPstat is not, it follows that CPstat is
independent in @xmath .

The model that shows independence of CPcontr has the integers as its
domain. Similar to the independence-model for CP3, we assume that the
set @xmath is enumerated i.e., @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

CPcontr is not true in this model:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The following derivations show that this is a model for CP1-4 and
CPstat. The first three derivations are easy.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Checking whether CP4 and CPstat are true in this model requires some
bookkeeping.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Since CP and CPstat are true in the model and CPcontr is not, CPcontr is
independent.

## Chapter 5 Conclusion

In this final chapter we give a short summary of the previous chapters,
thereby listing some of the main results. Furthermore, we discuss the
open issues mentioned in the previous chapters, and finally give some
suggestions for future work.

### 5.1 Summary

Sentential logic is limited by the static behaviour of its valuations.
In Chapter 1 we introduced the reader to reactive valuations. These
reactive valuations, first defined by Bergstra and Ponse in [ 5 ] , are
an extension of normal valuations because they allow us to take the
evaluation order of the expression into account. By means of a few
examples we illustrated the advantages of using reactive valuations
instead of normal valuations. Similarly, we also revealed some of the
limitations of using reactive valuations. At the end of the introduction
section, we showed that it is possible to define several classes of
reactive valuations depending on their behaviour.

As motivation for looking at reactive valuations we argued that these
are interesting because they can be used to model a variety of
sequential processes. In the section on motivation we provided a few
examples of sequential behaviour from e.g. computer science and
linguistics.

Since reactive valuations are a recent invention by Berstra and Ponse,
there is no directly related work on reactive valuations, besides the
main paper [ 5 ] . We, therefore, opted to list some broad areas which
might pertain to reactive valuations e.g., non-monotonic reasoning,
program semantics and many-valued logics, thereby giving a few specific
examples.

In Chapter 2 we defined the axiomatization of reactive valuation
congruence, called CP, and its semantics. The underlying semantics
consists of several parts. In the first part we described reactive
valuation algebras (RVAs). In the second part we showed how we can
compute the value of closed term @xmath , given an RVA @xmath and
reactive valuation @xmath . The value is denoted as @xmath . By imposing
limitations on the RVAs and their valuations we can define several
varieties of RVAs, namely the varieties with free reactive valuations,
repetition-proof valuations, contractive valuations and static
valuations. The signature of all these varieties is the same, and
consists of constants @xmath and @xmath , an infinite set of variables,
a finite set of atomic proposition symbols and the ternary operator
@xmath denoting conditional composition. Each variety has its own
axiomatization, where the axiomatization CP corresponds to the variety
with free reactive valuations. Given a variety @xmath , we say two
closed terms @xmath and @xmath are @xmath -equivalent if @xmath for RVAs
@xmath and valuations @xmath . Unfortunately, @xmath -equivalence does
not necessarily have the congruence property. We, therefore, define
@xmath -congruence as the largest congruence contained in the @xmath
-equivalence relation.

With the aim of showing soundness for the various varieties it sufficed
to show that each axiom is also true under semantical congruence. So if
@xmath is an axiom of variety @xmath , we need only show that @xmath and
@xmath are @xmath -congruent. In these proofs we took advantage of the
fact that if an axiom is sound with respect to a variety @xmath then the
axiom is also sound in all subvarieties of @xmath .

In order to show completeness we introduced basic forms, where each
sentence is provably equal to a unique basic form. The main advantage of
basic forms is that their syntactic structure is quite simple.
Consequently, structural induction on the set of basic forms is
relatively easy. By showing that for basic forms syntactical equality
and semantic congruence coincide we were able to prove completeness.
Each variety requires its own set of basic forms.

Given an axiomatization, if for all closed substitutions @xmath and
terms @xmath and @xmath we can derive @xmath , we can also derive @xmath
, we say that this axiomatization is @xmath -complete. In Chapter 3 we
discussed @xmath -completeness of CP and @xmath , the axiomatization of
@xmath -congruence.

Similar to the completeness proofs in Chapter 2, we defined a special
set of terms, namely the set of open basic forms. As opposed to the
various sets of basic forms used to prove completeness, the open basic
forms may contain variables. Using these open basic forms we were able
to prove @xmath -completeness for CP.

For @xmath , we used a different approach. This approach does not rely
on a set of open basic forms but on a translation between @xmath and a
specification of boolean algebra for which we know that it is @xmath
-complete. Using this translation we show that the @xmath -completeness
property transfers to @xmath . We did not show @xmath -completeness for
the other varieties.

Independence of an axiom with respect to a particular axiomatization
entails that the axiom is not redundant in that set of axioms i.e., it
is not derivable from the other axioms. In Chapter 4 we showed
independence of axioms with respect to the various axiomatizations.
Showing that an axiom @xmath is independent of a set @xmath of other
axioms requires that we construct a model such that @xmath is not true
in this model but the axioms in @xmath are. There were a few axioms for
which we did not succeed in proving that they were independent e.g., CP4
for contractive valuations.

### 5.2 Open issues and future work

In the past chapters several specific open issues were mentioned. We
will list and discuss these issues in this section. Afterwards, we give
some general suggestions for future work on the subject of reactive
valuations.

#### 5.2.1 Open issues

The first set of open issues is mentioned in the chapter on @xmath
-completeness. We were not able to establish @xmath -completeness for
@xmath and @xmath . In Chapter 3 we showed @xmath -completeness for CP
and @xmath using two different methods.

The method we used for @xmath involved a translation between an
equivalent @xmath -complete axiomatization and @xmath . Unfortunately,
this will not work for @xmath and @xmath because finding an equivalent
@xmath -complete axiomatization for these axiomatizations is unlikely.

Consequently, the best approach seems to be the one we used for CP,
where we used open basic forms. However, first attempts at using this
method failed to yield a positive result. The open basic forms as
defined in Definition 3.2 have the nice property that if we substitute
each variable in an open basic form with an atomic proposition we end up
with a closed basic form i.e., a member of (see Definition 2.4 ). We use
this property and the results we already have for in the lemmas leading
up to the @xmath -completeness theorem. The problems arise when we
define similar open basic forms for @xmath and @xmath . For example,
take the term

  -- -------- --
     @xmath   
  -- -------- --

At first glance this seems like an excellent candidate for the set of
open basic forms of both @xmath and @xmath . However, if we substitute
the @xmath with atomic proposition @xmath , the resulting term is
neither a member of @xmath nor of @xmath . Whether it is possible to
work around this problem remains to be seen. Additional tools for
proving @xmath -completeness can be found in [ 12 ] .

The second set of open issues concerns the independence of axioms. We
failed to show independence of CP4 in @xmath . For the axiomatization
@xmath we only showed independence of CP2, CP3, CPstat and CPcontr,
which leaves CP1 and CP4.

We showed the independence of an axiom with respect to a particular
axiomatization by constructing a model such that the axiom in question
is not true but the rest of the axioms in the axiomatization are.
Constructing such a model is regrettably a hit-or-miss affair and
becomes increasingly more difficult as the number of axioms multiply. We
can, however, eliminate some options. In Chapter 3 we used roughly three
methods of model constructions.

The first method involves using normal valuations as we know them from
sentential logic. The constants @xmath and @xmath are mapped to true and
false , and similarly the atomic propositions are mapped to either true
or false . Conditional composition is interpreted using a combination of
connectives, thereby ignoring evaluation order, e.g., @xmath is mapped
to @xmath . We used such a method to prove that CP1 and CP2 are
independent with respect to CP. Since there are only a small finite
number of interpretations of conditional composition it is easy to check
them all. We, therefore, wrote a small Prolog program that checks these
interpretations given a set of axioms to model and the one it should not
model. There were no interpretations that proved the independence of the
aforementioned axioms.

The second method relies on constructing a variety of RVAs. We used this
method to show independence of e.g. CPcr1 and CPcr2. The problem is that
such a variety is by definition a subvariety of @xmath . Since we proved
that the axioms in CP are sound in @xmath (see Theorem 2.3 ), they are
sound in all subvarieties of @xmath . The axioms for which we need to
prove independence are all in CP, and therefore this method will fail
automatically.

This leaves us with the third option of constructing an interpretation
in the natural numbers with the usual operations of addition and
multiplication. Whether or not this method will work remains an open
question. Of course, there are many other possibilities that are not
listed here e.g. an interpretation in an n-valued model that takes the
evaluation history into account.

#### 5.2.2 Future work

In Chapter 1 we discussed some possible application areas for reactive
valuations. However, we did not go into great detail as to the specifics
of such applications, and more importantly what is to be gained by the
use of reactive valuations. This search for specific applications might
also yield new and interesting varieties of RVAs.

Chapter 1 also contained a discussion on related work in which we
mentioned that besides the main reference [ 5 ] there is no related work
directly pertaining to reactive valuations. We, therefore, listed some
areas of interest with possible connections to reactive valuations.
These and other areas warrant a more in-depth study, which may involve
translations between varieties and other logics. For example, in
Chapter 3 we showed a translation between the variety with static
valuations and boolean algebra.

Proposition 2.2 was, despite its apparent simplicity and usefulness,
discovered towards the end of writing this thesis. This proposition
which given variety @xmath describes the relationship between @xmath
-equivalence and @xmath -congruence, is used extensively in the various
soundness proofs throughout this thesis. We, however, have not yet fully
taken advantage of this proposition in proving completeness. We feel
that this proposition will in all likelihood simplify the proofs of some
of the crucial lemmas we need for completeness.

Furthermore, we used basic forms to prove completeness. Alternatively,
we can define a term rewriting system with convenient normal forms for
each variety, and use that to prove completeness. In Appendix B we give
an example of such a term rewriting system.

In this thesis we gave some suggestions for future research. Of course,
these suggestions are not exhaustive as there are many other options for
further research not mentioned here e.g., results in expressivity and
complexity.

On a final note, during the writing of this thesis a new paper on
reactive valuations by Bergstra and Ponse appeared ¹ ¹ 1 In fact the
main reference [ 5 ] was a prior draft for this paper. , see [ 4 ] ,
which would be a fitting starting point for any future research.

## Appendix A Characterization of CP+CP5

### a.1 Non-replicating valuations

In this appendix we define an additional variety, which uses
non-replicating valuations. It is axiomatized by CP plus the CP5 axiom,

  -- -------- --
     @xmath   
  -- -------- --

The CP5 axiom is taken from the appendix of [ 5 ] . In that appendix
Bergstra and Ponse show that the symmetric version of this axiom can be
derived from CP+CP5:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

with @xmath .

The variety of RVAs with non-replicating valuations consists of all RVAs
that satisfy the equations:

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and @xmath . We call this variety @xmath .

The following lemmas show that the above equations imply their more
general versions. Note that the @xmath in the next lemma ranges over all
closed terms not just @xmath .

###### Lemma A.1.

For all closed terms @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By structural induction on @xmath :

-   If @xmath then @xmath follows directly from the definition of @xmath
    .

-   Suppose @xmath . Then

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

∎

###### Lemma A.2.

For all closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By structural induction on @xmath :

-   The case for @xmath or @xmath is trivial because @xmath and @xmath
    for any valuation @xmath .

-   Suppose @xmath for @xmath . Then by structural induction on @xmath .

    -   The case for @xmath follows directly from the definition of
        variety @xmath .

    -   Suppose @xmath . Then

          -- -------- -------- --
             @xmath   @xmath   
                      @xmath   
                      @xmath   
                      @xmath   
                      @xmath   
          -- -------- -------- --

        In the second step of this derivation Lemma A.1 is applied i.e.,
        we substitute @xmath with @xmath .

-   Suppose @xmath . Then

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
         @xmath   
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

    Note that sequential composition @xmath is defined in Chapter 2, and
    @xmath .

∎

###### Lemma A.3.

For all closed terms @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By structural induction on @xmath :

-   @xmath is @xmath or @xmath ; trivial.

-   @xmath ; see Lemma A.1 .

-   Suppose @xmath . Then

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

    Now it is not only possible to apply the induction hypothesis but
    also Lemma A.2 which will result in a reduction in the number of
    cases:

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

∎

These three lemmas will demonstrate their usefulness in the next section
where we will prove soundness.

### a.2 Soundness

###### Theorem A.4.

@xmath implies that @xmath .

###### Proof.

Since the axioms in CP are sound for the variety @xmath of RVAs with
free reactive valuations, and @xmath is a subvariety of @xmath , it
suffices to check CP5:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Now Lemma A.2 and Lemma A.3 can be applied:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Furthermore, we have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Hence, by Proposition 2.2 , CP5 is sound. ∎

## Appendix B Term rewriting system

### b.1 Term rewriting for CP

In this appendix we define a term rewriting system for CP and prove that
it is convergent. For more information on term rewriting see [ 6 ] . We
call the term rewriting system @xmath and it is defined as follows:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

In the following lemma we show that @xmath is terminating i.e., all
terms can be reduced to a normal form. Note that this in itself does not
guarantee that there is a unique normal form for each term.

###### Lemma B.1.

@xmath is terminating.

###### Proof.

In order to show that @xmath is terminating, we are required to prove
that an infinite derivation @xmath does not exist. First we define the
norm on terms as follows

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Subsequently, we show that for each rewrite rule the norm of the
left-hand side is strictly greater than the norm of the right-hand side.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Consequently, if @xmath using these rules, it follows that @xmath .

Suppose that there is an infinite rewrite sequence @xmath . Then we know
that if @xmath , @xmath . Since the norm is always positive and finite
(we do not allow terms with an infinite number of symbols), this
sequence must end. Hence, such an infinite rewrite sequence does not
exist and @xmath is terminating. ∎

The following lemma shows that @xmath is locally confluent. If there is
a term @xmath mutually derivable from terms @xmath and @xmath , we write
@xmath and say that @xmath and @xmath are joinable . A binary relation
@xmath is then locally confluent if for all terms @xmath , @xmath and
@xmath , if @xmath whenever @xmath and @xmath .

In order to prove local confluence, we first need to define the concept
of critical pair. Let @xmath and @xmath be two rewrite rules with
variables renamed such that they do not share variables. Furthermore,
let @xmath be the most general unifier of @xmath and a nonvariable
subterm @xmath of @xmath . A critical pair is then the term @xmath
combined with the term resulting from replacing @xmath with @xmath in
@xmath . A critical pair @xmath is joinable if @xmath and @xmath are
joinable.

###### Lemma B.2.

@xmath is locally confluent.

###### Proof.

@xmath is locally confluent if all its critical pairs are joinable (see
Lemma 5.15 in [ 6 ] ). We first rename the variables in the rules so
they are distinct:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then we identify the critical pairs and check whether they are joinable.

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves e.g., @xmath and
    @xmath . Then we have the following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable.

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable.

-   Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   The last critical pair requires that we rename the variables in the
    fourth rule a second time

      -- -------- --
         @xmath   
      -- -------- --

    Let @xmath be a substitution such that

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    and the rest of the variables map to themselves. Then we have the
    following critical pair

      -- -------- --
         @xmath   
      -- -------- --

    which is joinable

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

Since every critical pair is joinable, the rewrite system @xmath is
locally confluent. ∎

By Lemma 5.13 (the so called Diamond Lemma, see [ 14 ] ) in [ 6 ] , a
terminating binary relation is Church-Rosser iff it is locally
confluent. Hence, @xmath is Church-Rosser. Furthermore, by Theorem 5.4
in [ 6 ] a binary relation is confluent iff it is Church-Rosser.
Consequently, @xmath is also confluent, which leads us to the final
theorem.

###### Theorem B.3.

@xmath is convergent.

###### Proof.

By Definition 5.6 in [ 6 ] . ∎

This means that term rewriting system @xmath has unique normal forms. In
the next section, we list a program that uses this result to determine
whether two terms are provably equal in CP.

### b.2 Theorem prover for CP

In this section we list the code of a small theorem prover for CP based
on the term-rewriting system @xmath in the previous section. The program
is written in Prolog, and has been tested in the SWI-Prolog interpreter.

Within the program we use            1           and
           0           to denote @xmath and @xmath , respectively.
Atomic propositions have the same notation i.e. atomic proposition
@xmath is represented by            a           . Conditional
composition is represented as a three-place predicate
           c(_,_,_)           in which the middle argument is the
antecedent and the first and third argument are the left- and
right-consequent, respectively. So, for example, the term @xmath is
represented by the term            c(a, c(1, b, c), 0)           .

After loading the program in the Prolog interpreter we can check whether
two terms are equal as follows:

    -? equals(Term1, Term2).

where you should replace            Term1           and
           Term2           with two terms using the notation we just
discussed. The            equals           predicate will compute the
normal form of each term and determine if they are equal or not.

In the code below we see several other predicates. We now give a short
description of each of these predicates.

The            rule           predicate describes the term rewriting
rules i.e., in this case the rules of @xmath .

The            normal_form(+Term, -NormalForm)           predicate
computes the normal form            NormalForm           of the term
           Term           .

The            subterm(-Subterm, +Term)           predicate returns a
subterm            Subterm           of the term
           Term           .

The
           substitute(+Subterm1, +Subterm2, +Term1, -Term2)          
predicate replaces all occurrences of            Subterm1           in
           Term1           with            Subterm2           , and
returns the resulting term as            Term2           .

    rule(c(X, 1, _), X).
    rule(c(_, 0, Y), Y).
    rule(c(1, X, 0), X).
    rule(c(X, c(Y, Z, U), V), c(c(X, Y, V), Z, c(X, U, V))).

    normal_form(Term, Term) :-
       findall(Subterm, subterm(Subterm, Term), Subterms),
       forall(member(X, Subterms), \+ rule(X, _)).
    normal_form(Term1, NormalForm) :-
       subterm(Subterm1, Term1),
       rule(Subterm1, Subterm2),
       substitute(Subterm1, Subterm2, Term1, Term2),
       normal_form(Term2, NormalForm).

    subterm(T, T).
    subterm(T1, T2) :-
       T2 =.. [_|T],
       member(T3, T),
       subterm(T1, T3).

    substitute(Term1, Term2, Term1, Term2) :- !.
    substitute(_, _, Term, Term) :-
       Term \= c(_,_,_).
    substitute(Term1, Term2, c(X, Y, Z), c(NewX, NewY, NewZ)) :-
       substitute(Term1, Term2, X, NewX),
       substitute(Term1, Term2, Y, NewY),
       substitute(Term1, Term2, Z, NewZ).

    equal(Term1, Term2) :-
       normal_form(Term1, NormalForm),
       normal_form(Term2, NormalForm).