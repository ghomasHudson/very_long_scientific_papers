# Chapter 1 Introduction

The Standard Model (SM) combines the electroweak theory together with
Quantum Chromodynamics (QCD) of strong interactions and shows good
agreement with collider experiments. However the SM does not include
gravity and is expected to be an effective low-energy theory.

The Fermilab Tevatron is currently the high energy frontier of particle
physics and delivers proton-antiproton collisions at high luminosity.

The Run II of the Collider Dectector at Fermilab (CDF) continues the
precision measurements of hadron collider physics and the search for new
physics at and above the electroweak scale. With the precision
capability at the energy frontier, we can attack the open questions of
high energy physics from many complementary directions, including: the
properties of top quark, the precision electroweak measurements, e.g.
mass of the @xmath boson, the direct searches for new phenomena, the
tests of perturbative QCD at Next-to-Leading-Order and large @xmath ,
and the constraint of the CKM matrix with high statistics of the B
decays.

This thesis is about a direct search for new particles decaying to tau
pairs. The evidence for such new particles is that at accessible
energies the events with tau pairs deviate clearly and significantly
from the SM prediction.

In Run I CDF recorded an unusual event in which there were two very high
energy @xmath candidates nearly back-to-back in direction. Figure 1.1
shows a display of the event. This event was recorded in the data sample
from the missing transverse energy trigger, and was noticed in the
context of the Run I charged Higgs search [ 1 ] . In Run I, a posteriori
, it was not possible to estimate a probability for observing such an
event, though less than about 0.1 such events were expected from
backgrounds, including @xmath Drell-Yan ( @xmath ).

Various new physics processes can lead to very high-mass tau pairs, for
example, the new vector boson @xmath predicted in the extension to the
Standard Model by adding a new U(1) gauge symmetry and the pseudoscalar
Higgs boson @xmath predicted in the minimum supersymmetric extension of
the Standard Model (MSSM). The known backgrounds are from the high-mass
tail of Drell-Yan processes (mainly @xmath ) as well as jet @xmath fakes
from @xmath +jets, QCD di-jet, and mutli-jet events.

In this analysis we search for such signal processes by performing a
counting experiment. We select events with @xmath , @xmath , and @xmath
(here, “ @xmath ” means a @xmath hadronic decay). We construct an
invariant mass which we call @xmath using the four-vector sum of the
lepton, the tau, and the missing transverse energy vector (ignoring in
the latter the @xmath component). The region which has @xmath GeV/
@xmath is defined as the signal region, while the region which has
@xmath GeV/ @xmath is retained as a control region. We perform a blind
analysis in the signal region, i.e., we do not look at the data in the
signal region until we have precisely estimated the backgrounds. If
there is a significant excess over the known backgrounds, we have
discovered new physics; otherwise, we set limits on the possible signal
rates.

The thesis is organized as follows: theorectical models including the
SM, extensions of the SM, and high-mass tau pair phenomenology are
described in Chapter 2 . The experimental appratus including the
Fermilab Accelerator and CDF detector is introduced in Chapter 3 . We
discuss the logic behind the analysis in Chapter 4 . Particle
identifications for tau, electron and muon, and the study of missing
transverse energy are discussed in detail in Chapter 5 . The data
samples and event selection are discussed in Chapter 6 . The low-mass
control region background estimate, uncertainties, and the observed
events are discussed in Chapter 7 . The high-mass signal region, signal
acceptance, background estimate, and uncertainties are discussed in
Chapter 8 . The results of the observed events after opening the box,
and the method to extract limit are discussed in Chapter 9 . Finally,
the conclusion is presented in Chapter 10 .

## Chapter 2 Theoretical Model

The goal of elementary particle physics is to answer the following
fundamental questions:

-   What is the world made of?

-   How do the parts interact?

The Standard Model (SM) [ 2 ] of particle physics is a beautiful theory
which attempts to find the simplest model that quantitatively answer
these questions. The thousands of cross sections and decay widths listed
in the Particle Data Group (PDG) [ 3 ] , and all of the data from
collider experiments, are calculable and explained in the framework of
the SM, which is the bedrock of our understanding of Nature.

Building on the success of the SM, ambitious attempts have been made to
extend it. This thesis is concerned about a direct search for new
particles decaying to two taus. The phenomenology of tau pairs, namely
the production rates of intermediate bosons and the branching ratio of
their decays to tau pairs, in the framework of the SM and some of the
extensions will be presented in this chapter.

### 2.1 The Standard Model

The SM elementary particles include the fermion matter particles and the
force carriers. There are three generations of fermion matter particles:
leptons and quarks. The second and third generations have the same
quantum numbers of the first generation, but with heavier masses. The
masses of the leptons and quarks are listed in Table 2.1 . The force
carriers include the gluon for the strong interaction, and the photon,
the W and Z vector bosons for the electroweak interaction. The masses of
the force carriers are listed in Table 2.2 . The Higgs boson predicted
in the SM is a fundamental scalar particle and has special interaction
strength proportional to the mass of the elementary particles. Since it
is not discovered yet, it is not listed in Table 2.2 .

The SU(3) @xmath @xmath SU(2) @xmath @xmath U(1) @xmath structure of the
leptons and quarks is shown in Fig. 2.1 . The quarks are arranged in
triplets with respect to the color gauge group SU(3) @xmath , with
indices as red ( @xmath ), green ( @xmath ), and blue ( @xmath ).

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

The left- and right-handed fermions have different transformation
properties under the weak isospin group SU(2) @xmath . The left-handed
fermions are arranged in doublets, and the right-handed fermions are
arranged in singlets. There is no right-handed neutrino in the SM.

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

Table 2.3 lists the transformation properties, i.e., the quantum
numbers, of the fermions of the first generation under the gauge groups.
The hypercharge of U(1) @xmath is related to the electric charge by
@xmath . The assignments of the quantum numbers to the second and third
generations are the same. A brief review about how this structure
emerges is given in Appendix A .

The interactions are uniquely specified by the SU(3) @xmath @xmath SU(2)
@xmath @xmath U(1) @xmath gauge symmetries. All of the gauge bosons and
fermions acquire mass by the Higgs mechanism [ 4 ] . It introduces an
extra Higgs boson, and its physical vacuum is spontaneously broken in
the field space of the Higgs potential. The quark states in charged weak
interactions mediated by @xmath bosons are not the physical states, but
rather a quantum superposition of the physical states, described by the
CKM (Cabbibo-Kobayashi-Maskawa) matrix [ 5 ] .

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

The topic of this thesis is mostly related to the fermion couplings. The
couplings to fermions in the SM are listed in Table 2.4 . A very
detailed review with explicit derivations on these topics starting from
the gauge symmetry to the couplings to the fermions in the SM is given
in Appendix B .

In spite of its tremendous success in explaining collider results, there
are still many unexplained aspects in the SM. The set of group
representations and hypercharge it requires are quite bizarre, and there
are 18 free parameters which must be input from experiment: 3 gauge
couplings (usually traded as @xmath , @xmath and @xmath ), 2 Higgs
potential couplings (usually traded as @xmath and @xmath ), 9 fermion
masses, and 4 CKM mixing parameters. Do particle masses really originate
from a Higgs field? Can all the particle interactions be unified in a
simple gauge group? What is the origin of the CKM matrix? The ultimate
“theory of everything” should explain all of these parameters. The
imaginary goal, for example, is probably to express everything in terms
of the Planck constant @xmath , the speed of light @xmath , the
mathematical constant @xmath , and without any free parameters. That
would be an amazing accomplishment. There are still many things to do in
particle physics in the direction to find the simplest model and many
exciting challenges are ahead!

### 2.2 Extensions to the Standard Model

One interesting extension to the SM is to add a new U(1) gauge group.
This predicts a new @xmath gauge boson [ 6 ] at high energy scale. We
will use the @xmath as our model to calculate the signal acceptance for
any kind of new vector boson.

Another interesting extension is supersymmetry [ 7 ] , which is
motivated by the desire to unify fermions and bosons, shown in Fig. 2.2
.

For each fermion (lepton and quark) it predicts a bosonic super partner
(slepton and squark), and for each gauge boson it predicts a fermionic
super partner (gaugino). There is a divergence from scalar contributions
to radiative corrections for the Higgs mass in the SM, while the new
fermion loops appearing in supersymmetry have a negative sign relative
to the scalar contributions, thus cancel the divergence. We will use the
pseudoscalar Higgs particle @xmath , one of the Higgs particles
predicted in the minimal supersymmetric extension of the Standard Model
(MSSM) [ 8 ] as our model to calculate the signal acceptance for any
kind of new scalar boson.

### 2.3 High Mass Tau Pairs

At the Tevatron, the tau pair production in the SM is through the
Drell-Yan process, @xmath , as shown in Fig. 2.4 . The center-of-mass
energy of @xmath collisions at the Tevatron is 1.96 TeV. At the parton
level, one incoming quark from a proton and the other anti-quark from an
anti-proton collide via an intermediate boson which decays to two
outgoing taus. The details about how to calculate cross sections are
shown in Appendix C and the mass spectrum of the final two taus is shown
in Fig. 2.4 . We perform a direct search for new hypothetical particle
in high mass region by its decay to two taus @xmath . The low mass
region of the SM processes @xmath is the control region and its high
mass Drell-Yan tail is the major background for this search.

The two extensions described above are shown in Fig. 2.6 . For U(1)
extension, we consider the simplest model with the same interactions as
the @xmath boson in the SM, called the sequential @xmath , and the only
unknown parameter is the mass of the new gauge boson. The MSSM requires
two Higgs doublets and the ratio of the two Higgs expectation values is
defined as @xmath , which is undetermined and should be treated as a
free parameter. Thus the @xmath boson is governed by one more free
parameter in addition to its mass.

The couplings to fermions in the SM are listed in Table 2.4 . For each
mass point of the sequential @xmath , we can use the same couplings to
fermions as the @xmath boson in the SM and repeat the procedure to
calculate the cross section. The leading order cross section @xmath is
subject to a correction @xmath factor [ 9 ] such that the corrected
cross section @xmath . Including the @xmath factor, the predicted cross
section versus mass for the sequential @xmath is shown in Fig. 2.6 .

The SM requires one Higgs doublet with a coupling of the SM Higgs boson
to fermions as @xmath , where @xmath is the fermion mass and @xmath is
the vacuum expectation value of the SM Higgs boson, about 246 GeV.
Therefore Higgs boson prefers to couple to the fermions in the heaviest
generation. In the MSSM, at large @xmath , the coupling of @xmath and
@xmath are enhanced to @xmath , whereas the coupling of @xmath is
suppressed to @xmath when the top quark is kinematically available, i.e.
@xmath GeV/ @xmath . We use the programs H IGLU [ 10 ] and H DECAY [ 11
] to calculate the next-to-leading-order cross section of @xmath . They
are also shown in Fig. 2.6 .

## Chapter 3 The Tevatron Accelerator and the CDF Detector

Fermilab is the home of the highest energy particle accelerator in the
world, the Tevatron. The center-of-mass energy of proton-antiproton (
@xmath ) collision is @xmath TeV. We shall describe the Tevatron
accelerator and the Collider Detector at Fermilab (CDF) in this chapter.

### 3.1 Fermilab’s Accelerator Chain

Protons and antiprotons have equal and opposite electric charge. The
advantage of @xmath collider is that @xmath and @xmath travel in
opposite directions through the magnets and a @xmath collider can be
built with one ring of magnets instead of two. The disadvantage is that
it is difficult to produce and accumulate @xmath at a high efficiency.

The aerial view of Fermilab is shown in Fig. 3.2 . The Fermilab’s
accelerator chain is shown in Fig. 3.2 . It consists of the
Proton/Antiproton Sources (8 GeV), the Main Injector (150 GeV), the
Recycler, and the Tevatron (980 GeV).

The Proton Source includes the Cockcroft-Walton, the Linear Accelerator
(Linac), and the Booster. The Cockcroft-Walton uses DC power to
accelerate H @xmath ions to 750 KeV. The Linac uses Radio Frequency (RF)
power to accelerate H @xmath ions to 400 MeV. The electrons are stripped
off and the bare protons are injected into the Booster. The Booster uses
RF cavities to accelerate protons to 8 GeV.

The Anti-proton Source includes the Target Station, the Debuncher and
the Accumulator. A bunched beam of 120 GeV protons from the Main
Injector hits a Nickel Target to make anti-protons and other particles
as well. The particles are focused with a lithium lens and filtered
through a pulsed magnet acting as a charge-mass spectrometer to select
anti-protons. The antiproton beam is bunched since the beam from the
Main Injector is bunched and the antiprotons have a wide range of
energies, positions and angles. The transverse spread of the beam out of
the Target Station is “hot”, in terms analogous to temperature. Both RF
and stochastic cooling systems are used in the momentum stacking
process. The Debuncher exchanges the large energy spread and narrow time
spread into a narrow energy spread and large time spread. The
Accumulator stacks successive pulses of antiprotons from the Debuncher
over several hours or days. For every million protons that hit the
target, only about twenty 8 GeV anti-protons finally get stacked into
the Accumulator.

Protons at 8 GeV from the Booster are injected into the Main Injector.
They are accelerated to 120 GeV for fixed target experiments or 150 GeV
for injection into the Tevatron. Antiprotons at 8 GeV from either the
Accumulator or the Recycler are accelerated to 150 GeV in the Main
Injector and then injected into the Tevatron.

The Recycler is placed directly above the Main Injector beamline, near
the ceiling. One role of the Recycler is a post-Accumulator ring.
Another role, and by far the leading factor in the luminosity increase,
is to act as a recycler for the precious antiprotons left over at the
end of Tevatron stores. It is a ring of steel cases holding bricks of
“refrigerator” magnets (the same permanent magnet used in home
refrigerators). Permanent magnets do not need power supplies, cooling
water systems, or electrical safety systems. The Recycler is a highly
reliable storage ring for antiprotons.

The Tevatron was the world’s first superconducting synchrotron. A magnet
with superconducting coils has no electrical resistance, and consumes
minimal electrical power, except that is needed to keep the magnets
cold. The particles of a beam are guided around the closed path by
dipole magnetic field. The radius of the circle is 1000 meters. As the
beam energy is ramped up by RF cavities from 150 GeV to 980 GeV, the
bending magnetic field and the RF frequency must be synchronized to keep
the particles in the ring and this enables a stable longitudinal motion.
The stability of the transverse motion is achieved with a series
quadrupole magnets with alternating gradient.

Luminosity is a measure of the chance that a proton will collide with an
antiproton. To achieve high luminosity we place as many particles as
possible into as small a collision region as possible. At the
interaction point, the two beams of @xmath and @xmath are brought
together by special quadrupole magnets called Low Beta magnets, shown in
Fig. 3.3 .

The current status (at the writing of the thesis) of the luminosity is
shown in Fig. 3.5 , and the integrated luminosity delivered and to tape
is shown in Fig. 3.5 .

The design value for the peak instantaneous luminosity during Run II is
@xmath cm @xmath s @xmath . Typically a year allows 10 @xmath seconds of
running at the peak instantaneous luminosity. This is about one third of
the actual number of seconds in a year, which accounts both for the drop
in luminosity and for a normal amount of down-time. Using the conversion
constant @xmath , the design value corresponds to an integrated
luminosity about 2 fb @xmath per year. Ultimately it is hoped that an
integrated luminosity of 8 @xmath 10 fb @xmath can be attained in Run
II. The total number of events @xmath in a scattering process is
proportional to the luminosity and the cross section @xmath of the
process,

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

We can get a rough sense of the reach for new physics and the challenge
of enhancing signal and suppressing background by considering the
following examples. At a center-of-mass energy of 1.96 TeV, we have

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.2)
     @xmath   @xmath   @xmath      (3.3)
     @xmath   @xmath   @xmath      (3.4)
  -- -------- -------- -------- -- -------

### 3.2 The CDF Dectector

The CDF detector [ 12 ] is cylindrically symmetric around the beamline.
A solid cutaway view is shown in Fig. 3.7 , and an elevation view is
shown in Fig. 3.7 . It is a general-purpose solenoidal detector with
tracking system, calorimetry and muon detecion. The tracking system is
contained in a superconducting solenoid, 1.5 m in radius and 4.8 m in
length. The magnetic field is 1.4 T, parallel to the beamline. The
calorimetry and muon system are outside the solenoid. These sub-systems
will be described in more details below.

#### 3.2.1 CDF Coordinate System

The origin of the CDF detector is its geometric center. The luminous
region of the beam at the interaction point has Gaussian profiles with
@xmath cm. The @xmath collision point is not necessarily at the origin.

The CDF detector uses a right-handed coordinate system. The horizontal
direction pointing out of the ring of the Tevatron is the positive
@xmath -axis. The vertical direction pointing upwards is the positive
@xmath -axis. The proton beam direction pointing to the east is the
positive @xmath -axis.

A spherical coordinate system is also used. The radius @xmath is
measured from the center of the beamline. The polar angle @xmath is
taken from the positive @xmath -axis. The azimuthal angle @xmath is
taken anti-clockwise from the positive @xmath -axis.

At a @xmath collider, the production of any process starts from a
parton-parton interaction which has an unknown boost along the @xmath
-axis, but no significant momentum in the plane perpendicular to the
@xmath -axis, i.e. the transverse plane. This makes the transverse plane
an important plane in @xmath collision. Momentum conservation requires
the vector sum of the transverse energy and momentum of all of the final
particles to be zero. The transverse energy @xmath and transverse
momentum @xmath are defined by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.5)
     @xmath   @xmath   @xmath      (3.6)
  -- -------- -------- -------- -- -------

Hard @xmath head-on collisions produce significant momentum in the
transverse plane. The CDF detector has been optimized to measure these
events. On the other hand, the soft collisions such as elastic or
diffractive interactions or minimum-bias events, and by-products from
the spectator quarks from hard collisions, have most of their energy
directed along the beampipe, and will not be measured by the detector.

Pseudorapidity @xmath is used by high energy physicists and is defined
as

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

Consider occupancy in a sample of large amount of @xmath collision
events. Typically, particles in a @xmath collision event tend to be more
in the forward and backward regions than in the central region because
there is usually a boost along the @xmath -axis, which could be shown in
@xmath occupancy of the particles of the events in the sample. Now we
transform @xmath to @xmath . The derivative of @xmath is

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

A constant @xmath slice corresponds to variant @xmath slice which is
smaller in the forward and backward regions than in the central region.
This can make the @xmath occupancy more uniform than @xmath occupancy.
For example, calorimeters are constructed in @xmath slices, instead of
@xmath slices.

#### 3.2.2 Tracking

The tracking volume is surrounded by the solenoid magnet and the endplug
calorimeters as shown in Fig. 3.8 . The tracking system records the
paths of charged particles produced in the @xmath collisions. It
consists of a silicon microstrip system [ 13 ] with radius from @xmath
to 28 cm and @xmath , and an open-cell wire drift chamber called central
outer tracker (COT) [ 14 ] with radius from @xmath to 137 cm and @xmath
.

The silicon microstrip is made from Si with a p-n junction. When p-type
semiconductors and n-type semiconductors are brought together to form a
p-n junction, migration of holes and electrons leaves a region of net
charge of opposite sign on each side, called the depletion region
(depleted of free charge carriers). The p-n junction can be made at the
surface of a silicon wafer with the bulk being n-type (or the opposite
way). By applying a reverse-bias voltage we can increase the depletion
region to the full volume of the device. A charged particle moves
through this depletion region, creates electron-hole pairs which drift
and are collected at the surfaces. This induces a signal on metal strips
deposited on the surface, connected to readout amplifiers.

The silicon microstrip detector consists of three components: the
Layer 00, the Silicon VerteX detector II (SVX II), and the Intermediate
Silicon Layers (ISL). An end view is shown in Fig. 3.10 . Layer 00 is
physically mounted on and supported by the beam pipe. The sensors are
single-sided p-in-n silicon and have a pitch of 25 @xmath m. The next
five layers compose the SVX II and are double-sided detectors. The axial
side of each layer is used for @xmath - @xmath measurements and the
sensors have a strip pitch of about 60 @xmath m. The stereo side of each
layer is used for @xmath - @xmath measurements. Both 90 @xmath and
small-angle stereo sensors are used in the pattern (90, 90, @xmath 1.2,
90, +1.2) degrees and have a strip pitch of (141, 125.5, 60, 141, 60)
@xmath m from the innermost to outermost layers. The two outer layers
compose the ISL and are double-sided detectors with a strip pitch of 112
@xmath m on both the axial and the 1.2 @xmath stereo sides. This entire
system allows charged particle track reconstruction in three dimensions.
The impact parameter resolution of SVX II + ISL is 40 @xmath m including
30 @xmath m contribution from the beamline. The @xmath resolution of
SVX II + ISL is 70 @xmath m.

The COT is arranged in 8 superlayers shown in Fig. 3.10 . The
superlayers are alternately axial and @xmath 2 @xmath stereo, four axial
layers for @xmath - @xmath measurement and four stereo layers for @xmath
- @xmath measurement. Within each superlayer are cells which are tilted
about 30 @xmath to the radial direction to compensate for the Lorentz
angle of the drifting charged particles due to the solenoid magnet
field. Each cell consists of 12 layers of sense wires, thus total 8
@xmath 12 = 96 measurements per track.

The COT is filled with a mixture of argone:ethane = 50:50 which
determines the drift velocity @xmath . A charged particle enters gas,
ionizes gas and produces electrons. There is an electric field around
each sense wire. In the low electric field region, the ionization
electrons drift toward the sense wire. In the high electric field region
within a few radii of the sense wire, there is an avalanche
multiplication of charges by electron-atom collision. A signal is
induced via the motion of electrons. By measuring the drift time @xmath
(the arrival time of “first” electrons) at sense wire relative to
collision time @xmath , we can calculate the distance of the hit @xmath
.

A track is formed from a series of hits, fit to a helix. We can measure
the curvature of a track @xmath and then calculate transverse momentum
@xmath @xmath @xmath , with @xmath , @xmath and @xmath in the units GeV/
@xmath , m, and T, respectively. The hit position resolution is
approximately 140 @xmath m and the momentum resolution @xmath =
0.0015 (GeV/ @xmath ) @xmath .

#### 3.2.3 Calorimetry

The CDF electromagnetic and hadronic sampling calorimeters surround the
tracking system and measure the energy flow of interacting particles up
to @xmath . They are segmented in @xmath and @xmath with a projective
“tower” geometry, shown in Fig. 3.11 .

The energy measurement is done by sampling calorimeters which are
absorber and sampling scintillator sandwich with phototude readout. When
interacting with the absorber, electrons lose energy by ionization and
bremsstrahlung, and photons lose energy by the photoelectric effect,
Compton scattering and pair production. Both electrons and photons
develop electromagnetic shower cascades. The size of the longitudinal
shower cascade grows only logarithmically with energy. A very useful
cascade parameter is the radiation length @xmath which is the mean
distance for the @xmath to lose all but 1/e of its energy. For example,
for a 10 GeV electron in lead glass, the maximum electromagnetic shower
is at about 6 @xmath and the 95% containment depth is at about 16 @xmath
. Hadrons lose energy by nuclear interaction cascades which can have
charged pions, protons, kaons, neutrons, neutral pions, neutrinos, soft
photons, muons, etc. It is much more complicated than an electromagnetic
cascade and thus results in a large fluctuation in energy measurement.
In analogy to @xmath , a hadronic interaction length @xmath can be
defined. Hadronic showers are much longer than the electromagnetic ones.

The central calorimeters consist of the central electromagnetic
calorimeter (CEM) [ 15 ] , the central hadronic calorimeter (CHA) [ 16 ]
, and the end wall hadronic calorimeter (WHA). At approximately 6 @xmath
in depth in the CEM, at which electromagnetic showers typically reach
the maximum in their shower profile, is the central shower maximum
detector (CES). The CEM and CHA are constructed in wedges which span 15
@xmath in azimuth and extend about 250 cm in the positive and negative
@xmath direction, shown in Fig. 3.15 . There are thus 24 wedges on both
the @xmath and @xmath sides of the detector, for a total of 48. A wedge
contains ten towers, each of which covers a range 0.11 in
pseudorapidity. Thus each tower subtends @xmath in @xmath . CEM covers
@xmath , CHA covers @xmath , and WHA covers @xmath .

The CEM uses lead sheets interspersed with polysterene scintillator as
the active medium and employs phototube readout, approximately 19 @xmath
in depth, and has an energy resolution @xmath , where @xmath denotes
addition in quadrature. The CES uses proportional strip and wire
counters in a fine-grained array, as shown in Fig. 3.15 , to provide
precise position (about 2 mm resolution) and shape information for
electromagnetic cascades. The CHA and WHA use steel absorber
interspersed with acrylic scintillator as the active medium. They are
approximately 4.5 @xmath in depth, and have an energy resolution of
@xmath .

The plug calorimeters consist of the plug electromagnetic calorimeter
(PEM) [ 17 ] , and the plug hadronic calorimeter (PHA). At approximately
6 @xmath in depth in PEM is the plug shower maximum detector (PES). Fig.
3.15 shows the layout of the detector and coverage in polar angle @xmath
( @xmath ). Each plug wedge spans 15 @xmath in azimuth, however in the
range @xmath ( @xmath ) the segmentation in azimuth is doubled and each
tower spans only 7.5 @xmath .

The PEM is a lead-scintillator sampling calorimeter. It is approximately
21 @xmath in depth, and has an energy resolution of @xmath . The PES
consists of two layers of scintillating strips: U and V layers offset
from the radial direction by @xmath and @xmath respectively, as shown in
Fig. 3.15 . The position resolution of the PES is about 1 mm. The PHA is
a steel-scintillator sampling calorimeter. It is approximately 7 @xmath
in depth, and has an energy resolution of @xmath .

#### 3.2.4 Muon Chambers

The muon chambers are situated outside the calorimeters. In addition to
the calorimeters, the magnet return yoke and additional steel shielding
are used to stop electrons, photons and hadrons from entering the muon
chambers. The muon is a minimum ionizing particle which loses very
little energy in detector materials. The muon’s lifetime is long enough
to allow it to pass through all the detector components, reach the muon
chambers, and decay outside.

A muon chamber contains a stacked array of drift tubes and operates with
a gas mixture of argon:ethane = 50:50. The basic drift principle is the
same as that of the COT, but the COT is a multi-wire chamber, while at
the center of a muon drift tube there is only a single sense wire. The
sense wire is connected to a positive high voltage while the wall of the
tube is connected to a negative high voltage to produce a roughly
uniform time-to-distance relationship throughout the tube. The drift
time of a single hit gives the distance to the sense wire, and the
charge division at each end of a sense wire can in principle be used to
measure the longitudinal coordinate along the sense wire. The hits in
the muon chamber are linked together to form a short track segment
called a muon stub. If a muon stub is matched to an extrapolated track,
a muon is reconstructed. This is shown in Fig. 3.16 .

There are four independent muon detectors: the central muon detector
(CMU) [ 18 ] , the central muon upgrade (CMP), the central muon
extension (CMX), and the intermediate muon detector (IMU). The muon
coverage in @xmath space is shown in Fig. 3.17 .

The CMU is behind the central hadronic calorimeter and has four layers
of cylindrical drift chambers. The CMP is behind an additional 60 cm of
shielding steel outside the magnet return yoke. It consists of a second
set of four layers with a fixed length in @xmath and forms a box around
the central detector. Its psuedorapidity coverage thus varies with the
azimuth. A layer of scintillation counters (the CSP) is installed on the
outside surface of the CMP. The CMU and CMP each covers @xmath . The
maximum drift time of the CMU is longer than the @xmath bunch crossing
separation. This can cause an ambiguity in the Level 1 trigger
(described in the next section) about which bunch the muon belongs to.
By requiring CMP confirmation, this ambiguity is resolved by the CSP
scintillators.

The CMX has eight layers and covers @xmath . A layer of scintillation
counters (the CSX) is installed on both the inside and the outside
surfaces of the CMX. No additional steel was added for this detector
because the large angle through the hadron calorimeter, magnet yoke, and
steel of the detector end support structure provides more absorber
material than in the central muon detectors. The azimuthal coverage of
CMX has a 30 @xmath gap for the solenoid refrigerator.

The IMU consists of barrel chambers (the BMU) and scintillation counters
(the BSU), and covers the region @xmath .

### 3.3 Trigger and Data Acquisition System

The trigger system has a three-level architecture: level 1 (L1), level 2
(L2), and level 3 (L3). The data volume is reduced at each level which
allows more refined filtering at subsequent levels with minimal
deadtime. The trigger needs to be fast and accurate to record as many
interesting events as possible, while rejecting uninteresting events.

Each sub-detector generates primitives that we can “cut” on. The trigger
system block diagram is shown in Fig. 3.18 . The available trigger
primitives at L1 are

-   XFT tracks, with @xmath and @xmath provided by the eXtreme Fast
    Tracker using the hits in the axial layers of the COT,

-   electrons, based on XFT and HAD/EM which is the ratio of the
    hadronic energy and the electromagnetic energy of a calorimeter
    tower,

-   photons, based on HAD/EM ratio,

-   jets, based on EM+HAD,

-   muons, based on muon hits and XFT, and

-   missing @xmath and sum @xmath which are the negative of the vector
    sum and the scalar sum of the energies of all of the calorimeter
    towers, respectively.

The available trigger primitives at L2 are

-   SVT, the Silicon Vertex Tracker trigger based on the track impact
    parameter of displaced tracks,

-   jet clusters,

-   isolated clusters, and

-   EM ShowerMax which is the strip and wire clusters in the CES.

There are two important factors for trigger design: the time between
beam crossing and @xmath , the average number of overlapping
interactions in a given beam crossing.

We can have many bunches in the Tevatron to enhance the luminosity.
Since the radius of the ring is 1000 m, a proton (or an anti-proton) at
a speed very close to the speed of light circulates the ring once every
20 @xmath s. To accomodate 36 bunches, the maximum bunch separation
allowed is about 600 ns, and the Run IIa configuration is 396 ns. The
bunch separation defines an overall time constant for signal
integration, data acquisition and triggering.

Another key design input is the average number of overlapping
interactions @xmath , which is shown as a function of luminosity and the
number of bunches in Fig. 3.19 [ 19 ] . For example, with 36 bunches,
@xmath is about 1 at @xmath cm @xmath s @xmath and about 10 at @xmath cm
@xmath s @xmath . The trigger with fast axial tracking at L1 can handle
the former environment, but cannot handle the latter environment because
of the presence of too many fake tracks. To be able to handle @xmath cm
@xmath s @xmath we would need 108 bunches and even that seems not
enough, thus we will also need to upgrade the trigger to include, for
example, stereo tracking at L1 to suppress fake tracks.

The data flow in the trigger system is constrained by the processing
time, i.e. how fast a decision can be made to clear events at each level
and the tape writing speed for permanant storage at the end of the
triggering process. The implementation needs a sufficient buffer while
filtering because any overflow means deadtime. The “deadtimeless” design
for 132 ns crossing is shown in Fig. 3.20 .

The L1 decision occurs at a fixed time about 5.5 @xmath s after beam
collision. L1 is a synchronous hardware trigger. To process one event
every 132 ns, each detector element is pipelined to have local data
buffering for 42 beam crossings. The L1 accept rate is less than 50 KHz
which is limited by the L2 processing time.

The L2 decision time is about 20 @xmath s. L2 is a combination of
hardware and software triggers and is asynchronous. If an event is
accepted by L1, the front-end electronics moves the data to one of the
four onboard L2 buffers. This is sufficient to process a L1 50 KHz
accept rate and to average out the rate fluctuations. The L2 accept rate
is about 300 Hz which is limited by the speed of the event-builder in
L3.

L3 is purely a software trigger consisting of the event builder running
on a large PC farm. The event builder assembles event fragments from L1
and L2 into complete events, and then the PC farm runs a version of the
full offline reconstruction code. This means that fully reconstructed
three-dimensional tracks are available to the trigger decision. The L3
accept rate is about 75 Hz which is limited by tape writing speed for
permanent storage.

Once an event passes L3 it is delivered to the data-logger sub-system
which sends the event out to permanent storage for offline reprocess,
and to online monitors which verify the entire detector and trigger
systems are working properly.

The data used in this analysis were collected from March 2002 to
September 2003. It was for 396 ns with 36 bunches and for luminosity
about @xmath cm @xmath s @xmath . This means that the trigger (designed
for 132 ns) was sufficiently capable to handle the timing of bunch
crossing with no need to worry about multiple interactions in this
environment.

## Chapter 4 Search Strategy

This chapter describes the overall logic of the high-mass tau tau
search. There are three steps:

1.  Use @xmath events to cross check the @xmath identification
    efficiency.

2.  Use @xmath events to study the low-mass control region with @xmath
    120 GeV/ @xmath .

3.  Examine the high-mass signal region with @xmath 120 GeV/ @xmath for
    evidence of an excess signalling new physics.

Tau Hadronic Decays

The dominant decays of @xmath ’s are into leptons or into either one or
three charged hadrons, shown in Table 4.1 . The following short-hand
notations for @xmath and its decays are used,

  -- -------- -- -------- -- -------
     @xmath      @xmath      (4.1)
     @xmath      @xmath      (4.2)
     @xmath      @xmath      (4.3)
  -- -------- -- -------- -- -------

The leptonic decays cannot be distinguished from prompt leptons. So tau
identification requires a hadronic tau decay only, with a mass less than

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

The net charge of the charged tracks is @xmath 1. But we will not cut on
charge because for very high energy taus there is an ambiguity of charge
sign for very straight tracks.

The characteristic signature of hadronically decaying taus is the track
multiplicity distribution with an excess in the 1- and 3-track bins. The
excess, about 2:1 in these bins, is related to the tau hadronic
branching ratios to one or three charged pions. Quark or gluon jets from
QCD processes tend not to have such low charged track multiplicity, but
have a broader distribution peaking at higher multiplicities (3-5
charged tracks). Other final particles, namely photons, electrons, and
muons have mainly 0, 1, or 1 tracks, respectively, which are different
from tau hadronic decays too. Seeing the tau’s characteristic track
multiplicity signature is a very important indication that backgrounds
are under control.

Since @xmath is about ten times larger than @xmath [ 20 ] we will use
@xmath events to cross check the tau identification efficiency.

Di-Tau Visible Mass

There are six final states for tau pairs, shown in Table 4.2 . @xmath
and @xmath modes cannot be distinguished from the prompt @xmath or the
prompt @xmath , respectively. @xmath mode has a special signature, but
its branching ratio is small and its final particles tend to have low
energy. For this analysis, we will look for three golden final states
with at least one hadronic decay.

The high-mass tau pair search will be based on just counting the number
of events with some specified set of cuts. It is desirable to measure
for some variable a distribution which agrees with the Standard Model in
some range, but deviates from it in another, thus giving a more
convincing signal while also providing an estimate of the new particle’s
mass scale.

There are at least two missing neutrinos in the golden final states, and
therefore six unknown momentum components. With only two constraints
from the two components of the missing transverse energy and the two
constraints from two tau masses, there is at least a 2-fold ambiguity.
It is not possible to reconstruct the tau pair invariant mass in
general.

The mass of the sum of the two tau’s visible momentum and the missing
transverse energy @xmath with its @xmath -component set to zero is
called the visible mass,

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

The invariant mass of the irreducible @xmath background peaks at @xmath
91 GeV/ @xmath . The visible mass distribution will be broadened and
peak at somewhere less than 91 GeV/ @xmath . We will study the sample
with @xmath GeV/ @xmath for @xmath cross check. After all of the cuts,
we want the control sample to be dominated by @xmath background, with
jet background under control and other backgrounds negligible. A
successful cross check between data and MC in the low-mass region will
give us confidence to go further to the high-mass region.

Blind Analysis

If a new particle with high mass exists and the statistics are
sufficient, it will show up in the high-mass signal region. The strategy
we choose is a blind analysis. The data sample with @xmath GeV/ @xmath
will be put aside until all selection criteria are fixed and all
backgrounds are determined. The principle of a blind analysis is to
avoid human bias. If the selection cuts are decided by the distributions
of high mass region in the real data sample, there will be a strong bias
and the probabilities calculated are meaningless. Given good
understanding of backgrounds, there will be two possibilities after
examining the data in the signal region. Either one will observe a
number of events statistically consistent with the expected background
rate, or there will be an excess signalling new physics.

## Chapter 5 Particle Identification and Missing Transverse Energy

High energy @xmath collisions can produce a large number of particles.
As illustrated in Fig. 5.1 , the CDF detector with its tracking system,
calorimeter and muon chambers can identify the following particles by
the following patterns:

-   photon: cascade showering in electromagnetic calorimeter, but no
    associated charged tracks;

-   electron: a track, and cascade showering in electromagnetic
    calorimeter;

-   muon: a track, minimum ionization energy deposit in calorimeter, and
    hits in muon chambers;

-   jet: an object which cannot be identified as an isolated photon, or
    an isolated electron, or an isolated muon is identified as a jet;

-   missing transverse energy ( @xmath ): an imbalance of transverse
    energy in the whole calorimeter.

The final particles and the @xmath are reconstructed by CDF II offline
programs.

### 5.1 Monte Carlo Simulation

Often we need to predict the output in the detector including the final
reconstructed particles and the @xmath of a particular interesting
process and compare with data. Usually the phase space of an event of
the @xmath collision is too complicated to be calculated analytically.
In this case Monte Carlo (MC) simulation is used. It has become a
powerful tool used in many research areas including high energy physics.

A well-known MC example is the Buffon’s Needle. It involves dropping a
needle on a lined sheet of paper and determining the probability of the
needle crossing one of the lines on the page. The remarkable result is
that the probability is directly related to the value of the
mathematical @xmath . Suppose the length of the needle is one unit and
the distance between the lines is also one unit. There are two
variables, the angle @xmath at which the needle falls and the distance
@xmath from the center of the needle to the closest line. @xmath can
vary from 0 @xmath to 180 @xmath and is measured against a line parallel
to the lines on the paper. @xmath can never be more than half the
distance between the lines. The needle will hit the line if @xmath . How
often does this occur? The probability @xmath is @xmath by integrating
over @xmath . With a computer, we can generate a large sample of random
needle drops. The probability @xmath can be simply taken as the number
of hits divided by the number of drops, yielding @xmath .

Here we discuss the basic techniques of MC simulation. For a
one-dimensional integral, we can choose @xmath numbers @xmath randomly
with probability density uniform on the interval from @xmath to @xmath ,
and for each @xmath evaluate the function @xmath . The sum of these
function values, divided by @xmath , will converge to the expectation of
the function @xmath .

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

The central limit theorem tells us that the sum of a large number of
independent random variables is always normally distributed (i.e. a
Gaussian distribution), no matter how the individual random variables
are distributed. To understand this, we can test with uniformly
distributed random variable @xmath , @xmath , @xmath , @xmath , (a)
@xmath is a uniform distribution; (b) @xmath is a triangle distribution;
(c) @xmath is already close to a Gaussian distribution; (d) @xmath is
almost like the exact Gaussian distribution. Applying this theorem, we
know the MC method is particularly useful as we can also calculate an
error on the estimate by computing the standard deviation,

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

where @xmath and @xmath . The convergence for numerically evaluating the
integral goes as @xmath with the number of function evaluation, @xmath .
And obviously if the distribution @xmath is flatter, then the @xmath is
smaller for the same number of events in a sample generated. If there is
a peak in the distribution such as the distribution of a resonance
production, it is better to transform that variable to some other
variable with a flatter distribution in order to converge faster.

The generalisation to multi-dimensional integrals @xmath is
straightforward. We can choose @xmath numbers of grid @xmath randomly
with probability density uniform on the multi-dimensional phase space,
and for each grid evaluate the function @xmath . The sum of these
function values, divided by @xmath , will converge to the expectation of
the function @xmath . A nice feature is that it will always converge as
@xmath , even for very high dimensional integrals. This can make the
performance of the MC method on multi-dimensional integrals very
efficient.

In high energy physics, an event occurs with a probability in the phase
space of the kinematic variables. A MC simulation generates a large
number of random events according to the probability described by a
model. With a large sample, we can get the predictions of the model by
looking at the distributions of the kinematic variables and the derived
variables, and the correlations among the variables. By confronting the
predictions with real data, it is possible to tell if a model describes
Nature correctly.

For this analysis, we use PYTHIA 6.215 program [ 21 ] with CTEQ5L parton
density functions (PDF’s) [ 22 ] to generate the large samples of the
processes of @xmath collision, such as @xmath , @xmath , @xmath , and
use TAUOLA 2.6 [ 23 ] to simulate tau decays. We use GEANT 3 [ 24 ] to
simulate the response to the final particles in the CDF II detector.

### 5.2 Tau Identification

Tau leptons decay predominantly into charged and neutral pions and
suffer from large backgrounds from jet production. Hadronic tau decays
appear in the detector as narrow isolated jets. The most powerful cut to
suppress the jet background is in fact isolation, requiring no other
tracks or @xmath s near the tau cone. To do this we define a signal cone
and an isolation cone around the direction of the seed track (the track
with the highest @xmath ) and then require that there is no track or
@xmath between the signal cone and the isolation cone. This is shown in
Fig. 5.2 .

#### 5.2.1 Cone Size Definition

There are two useful cone size definitions. One is to construct a cone
in @xmath defined below which has relativity invariance under a boost
along the @xmath -axis. The other is to construct a cone in
three-dimensional separation angle, @xmath , which has geometry
invariance. Below we discuss why @xmath is chosen as cone size
definition for jet identification and why @xmath is chosen as cone size
definition for hadronic tau identification.

We start with the discussion on relativity invariance. For a particle
under a boost @xmath along the @xmath -axis and @xmath , its
four-momentum @xmath is transformed to

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

The @xmath and @xmath components in the transverse plane are not
changed, while the @xmath component and the energy are changed. Rapidity
is defined by

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

Using @xmath , it is easy to check that rapidity has a nice additive
property under the boost along the @xmath -axis,

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

For ultra-relativistic particle with @xmath , we have @xmath . Using
@xmath , the rapidity is well approximated by pseudorapidity @xmath ,

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

Particles in a jet deposits energy in the calorimeter towers. For the
traditional cone jet algorithm, we can call the tower with @xmath above
a seed threshold as the seed (abbreviated as @xmath ), and the other
towers with @xmath above a shoulder threshold as shoulders (abbreviated
as @xmath ). To identify a jet, we can put the seed at the center and
make a cone starting at a reconstructed interaction vertex point and
around the seed to include the shoulders. Since the transverse
components of a particle’s four-momentum are not changed under the
unknown boost @xmath of the parton-parton system along the @xmath -axis,
@xmath is not changed. For an ultra-relativistic particle, @xmath is a
good approximation of its rapidity. We have

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

The separations in @xmath and @xmath are not changed under the unknown
boost along the @xmath -axis,

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

Therefore the separation in @xmath which is constructed in the
combination of @xmath and @xmath is not changed under the unknown boost
along the @xmath -axis,

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

Given the @xmath and the configuration (shape) of a jet, whatever the
magnitude of the boost along the @xmath -axis of the parton-parton
system is, or, equivalently, whatever the direction of the seed of the
jet is, we can use the same cone to include or exclude a tower into the
jet by calculating its separation in @xmath to the seed. Thus @xmath is
a very useful shape variable for jet identification.

It also makes sence that there is a strong correlation between the two
variables @xmath and @xmath : a higher @xmath should give a smaller cone
in @xmath to include all of the final particles, e.g. of a jet. It is
very common that there are hundreds of final particles after a @xmath
collision. The problem is that the energy of a jet in real data cannot
be measured before a cone is actually constructed, otherwise there is no
constraint to tell which tower should be included or excluded. Jet
identification usually starts with a large and constant cone around a
seed. The towers with significant energy in the cluster may or may not
be contiguous. The energy of the jet is determined afterwards by summing
up the energies of all of the towers in the cluster.

Now consider hadronic tau identification with a narrow cone and small
number of final particles. The situation is quite different from jet
identification. Since there are only a small amount of final particles,
each final particle has significant energy. And since all of the final
particles are in a narrow cone, they make a narrow and contiguous
cluster with significant energy in each tower. This constraint of a
narrow and contiguous cluster with significant energy in each tower
tells us that we can determine energy first, and then construct a narrow
cone to include or exclude charged particles reconstructed in the
tracking system and/or neutral @xmath s reconstructed in the shower
maximum detector which is inside the electromagnetic calorimeter.

The question now is: is @xmath a good choice of cone size definition for
hadronic tau identification?

A @xmath cone has a relativity invariance under a boost along the @xmath
-axis. However a @xmath cone does not have geometry invariance. What
does a constant @xmath imply in geometry? The top plot of Fig. 5.3 shows
three constant isolation annulus at different @xmath in a uniform @xmath
- @xmath space; the bottom plot shows the same three isolation annulus
in a uniform @xmath - @xmath space after using the function @xmath to
map @xmath slices to @xmath slices. In the central region, the isolation
annulus is almost unchanged; outside the central region, they are
severely squeezed, thus @xmath doesn’t have geometry invariance. @xmath
doesn’t have geometry invariance either. Think of one step at the
Equator of the Earth and another step at the North Pole of the Earth,
the former is a tiny one in @xmath while the latter is a giant one in
@xmath . A constant @xmath cone with relativity invariance is not
expected to be a constant cone with geometry invariance.

Instead of @xmath and @xmath , we can use energy @xmath and
three-dimensional separation angle @xmath to construct a cone for
hadronic tau identification. There are two reasons.

First, consider a rotation of a solid cone; the geometry invariance of a
three-dimensional separation angle @xmath is easy to visualize. The
unknown boost of the parton-parton system along the @xmath -axis doesn’t
affect the energy measurement of the hadronic tau identification at all.
Under the known high energy boost, the final particles are flying
together in a narrow cone. In one case the boost is to the central
region, and in another case the boost is to somewhere forward or
backward. Are these two cones geometrically invariant? The answer is
yes.

Second, the correlation of @xmath and @xmath is very strong. The case
with the simplest phase space of final particles is calculable, see
Appendix D . Comparing with a constant cone, a variable cone determined
by this correlation can give extra power to suppress the jet background
for hadronic tau identification. This is described by the “shrinking”
cone algorithm for hadronic tau identification below.

#### 5.2.2 The “Shrinking” Cone

As shown in Fig. 5.2 , tau isolation cone, i.e., the outer cone, is a
constant 30 @xmath (0.525 rad) cone. For a particle with definite mass
like tau, the bigger the energy, the smaller the separation angle of its
decay daughters, hence a smaller signal cone which is the inner cone in
Fig. 5.2 .

The tau resonctruction algorithm [ 25 ] starts with a seed tower with
@xmath GeV. It adds all of the adjacent shoulder towers with @xmath GeV
to make a calorimeter cluster. The cluster is required to be narrow,
i.e., the number of towers @xmath . The visible energy, denoted as
@xmath , of the final particles of tau haronic decays is measured by the
energy of the calorimeter cluster, denoted as @xmath . Then the
algorithm asks a seed track with @xmath GeV/ @xmath to match with the
cluster. The matched seed track is a track with the highest @xmath in
the neighbor of the calorimeter cluster. The tau signal cone is
constructed around the direction of the seed track. The other tracks
with @xmath GeV/ @xmath , and the @xmath s with @xmath GeV/ @xmath which
are reconstructed by the strip and wire clusters in the CES detector,
are included in the tau candidate if they are inside the tau signal
cone. The size of the tau signal cone is determined by @xmath .

The phase space of tau hadronic decays is very complicated and the
energy dependence of the signal cone cannot easily be calculated
analytically. We use a large MC sample of @xmath to get this
correlation.

The concept of tau shrinking signal cone at generation level (without
underlying track or @xmath ) is shown in Fig. 5.4 . The cone starts out
at a constant 10 @xmath , and then, if the quantity (5 rad)/ @xmath is
less than 10 @xmath we use this angle, unless it is less than 50 mrad.

For reconstructed tracks a cone defined as that shown in Fig. 5.4 is
efficient and selective against jet backgrounds. However, for @xmath s,
the reconstructed angle can, at large visible energies, be larger than
50 mrad. Thus we relax the minimum to 100 mrad. With underlying track or
@xmath , the shrinking cone is shown in the left two plots of Fig. 5.5 .
Inside the tau isolation cone (the outer 0.525 rad cone), the separation
angle between the farthest track/ @xmath and the seed track is ploted. A
tau object between the tau isolation cone and the shrinking signal cone
is non-isolated and will be removed by isolation cut. The right two
plots of Fig. 5.5 show how the shrinking cone looks when applied to jets
reconstructed as tau objects. Comparing with a constant signal cone, the
shrinking signal cone, a natural consequence of the tau’s relativistic
boost, dramatically helps to reduce jet background in the high mass
search.

#### 5.2.3 Tau Identification Cuts

Now we can put the seed track in the center of the cone and include in
the tau candidate all tracks and @xmath s whose direction is within the
“shrinking” signal cone. Table 5.1 shows the list of tau identification
cuts using the information about calorimeter cluster, seed track,
shoulder tracks/ @xmath s of the tau candidate. The @xmath (tracks +
@xmath s) threshold is not listed because it is not an identification
cut and it should be chosen by looking at the trigger cuts applied and
by comparing tau identification efficiency with the jet @xmath
misidentification rate. We do not cut on charge because there is an
ambiguity in the charge for high @xmath tracks; we do not cut on track
multiplicity either because we will check track multiplicity to see
hadronic tau signature.

Electron Removal

Using the requirements discussed above, electrons can be reconstructed
as hadronic tau objects if they have a narrow calorimeter cluster and a
high @xmath seed track. To remove electrons we demand that the tau be
consistent with having only pions in the final state. We define the
variable @xmath as

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

Fig. 5.6 shows the tau object EM fraction ( @xmath ) versus E/p. The top
plot is for hadronic taus reconstructed as tau objects, and the bottom
plot is for electrons reconstructed as tau objects. For an ideal
hadronic tau and a perfect calorimeter, @xmath = 1. For an ideal
electron, @xmath = 0. However, the calorimeter is not perfect and there
can be a large background from @xmath events. To remove this background
we use a very tight cut, @xmath 0.2. The remaining background is
discussed below.

EM Calorimeter Isolation

The motivation for the EM calorimeter isolation cut is due to @xmath
reconstruction inefficiency, for example, some CES clusters are not
reconstructed as @xmath s if a track is nearby. This affects the power
of the @xmath isolation requirement. We add an EM calorimeter isolation
cut to deal with the remaining jet background. We calculate the EM
energy in a @xmath cone around the seed track, summing over all EM
towers which are not members of the tau cluster. Here @xmath is used to
calculate the distance between the centroid of a calorimeter tower and
the seed track because the calorimeter tower segmentation is fixed in
@xmath space, namely @xmath around the central region. Since the EM
calorimeter isolation cut is strongly correlated with other isolation
cuts, its marginal distribution is shown in Fig. 5.7 . The EM cal.
isolation energy versus cluster energy plots show that we do not need to
use a relative (fractional) cut, which is necessary if for high energy
tau objects there is significant energy leakage outside tau cluster. We
instead choose an abosolute cut, @xmath GeV.

Object Uniqueness

Though not listed in the summary table of tau identification cuts, we
note that all reconstructed objects in the event are required to be
unique. Thus we only apply the tau identification cuts to objects not
already reconstructed as a photon, electron, or muon. In practice, we
require that a tau object be 30 @xmath away from any identified photon,
electron, or muon.

Denominators

For various subsequent studies presented here we will use specific
subsets of the tau identification cuts listed in the summary table. The
cuts are in cumulative order which is important for calculating rates
and efficiencies. There are three different denominators in Table 5.1
corresponding to three different relative rates, which will be applied
on different data samples with consistent denominators later.

#### 5.2.4 Tau Identification Efficiency

Table 5.2 shows the procedure to measure the tau identification
efficiency, using different samples. For all of the generated taus, we
pick those taus decaying hadronically, and consider the central ones in
the pseudorapidity range @xmath which are able to be reconstructed as
tau object, called CdfTau in the table. We require the seed track of the
generated tau to match with the seed track of a reconstructed tau object
within 0.2 radian. Then we apply the tau identification cuts on the
reconstructed tau objects and calculate tau identification efficiency.

Fig. 5.8 shows the absolute tau identification efficiency, which
includes the effects of both reconstruction and identification, vs. tau
visible energy, using the @xmath sample which has a lot of high energy
taus.

#### 5.2.5 Jet@xmath Misidentification Rate

Table 5.3 shows the procedure to measure the jet @xmath
misidentification rate, using four different jet samples called JET20,
JET50, JET70, and JET100 samples collected with different trigger
thesholds. The L1 tower @xmath , L2 cluster @xmath and L3 jet @xmath
trigger thresholds in the unit of GeV for a triggered jet in each jet
sample are

-   JET20: 5, 15, 20

-   JET50: 5, 40, 50

-   JET70: 10, 60, 70

-   JET100: 10, 90, 100

We use the central jets with @xmath which may be reconstructed as tau
object, called CdfTau in the table. We require the central jet to match
with a reconstructed tau object by requiring that they share the seed
tower of the reconstructed tau object. Then we apply the tau
identification cuts on the reconstructed tau objects and calculate jet
@xmath misidentification rate.

Fig. 5.9 shows the absolute jet @xmath misidentification rate, which
includes the effects of both reconstruction and identification, vs. jet
cluster energy, using JET50 sample.

Discrepancies

To try to minimize trigger bias, we use non-triggered jet only. Based on
the L1 tower @xmath , L2 cluster @xmath and L3 jet @xmath trigger
thresholds in each sample, we find all of the jets which can satisfy the
trigger requirements. The choice of the triggered jets in an event in
the case of zero, one or more than one jet satisfying trigger
requirements are

-   If zero, throw away the event

-   If only one, choose that jet

-   If more than one, do not choose any as triggered

Non-triggered jets are just the jets not chosen as the triggered jet.
Even after trying to minimize trigger bias by using non-triggered jet
only, there are still discrepancies among jet @xmath misidentification
rates obtained from different jet samples, shown in Fig. 5.10 .

Two-Dimensional Parametrization

There is no doubt that the jet @xmath misidentification rate has a very
strong dependence on energy because the tau isolation annulus is a
function of energy. To resolve the discrepancies among the jet @xmath
rates, we add another parameter to make a two-dimensional
parametrization. The second parameter should not be correlated strongly
with energy, otherwise adding another parameter is meaningless. Given
the final particles, the transverse size of a jet depends on its boost:
jets with a bigger boost have smaller size and smaller size jets have
higher probability to survive tau identification. The relativistic boost
@xmath is

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

where @xmath is the energy of the jet which can be measured by its
cluster energy in calorimeter, and @xmath is the invariant mass of its
final particles. The mass @xmath is not easy to measure because some of
the final particles can be neutral and leave no track in tracking
system. We use cluster mass, which treats each tower in the cluster as a
massless photon and sums up the photons, as an approximation of @xmath .
The cluster mass has a strong correlation with energy, while the cluster
boost does not. This is shown in Fig. 5.12 . We choose cluster boost as
the second parameter.

In the one-dimensional jet @xmath misidentification rate what we see is
the average over all of the bins of cluster boost. Given the energy of a
jet, the average cluster boost is different in JET samples, shown in
Fig. 5.12 .

Now we plot the jet @xmath misidentification rate vs. energy, in each
boost slice, shown in Fig. 5.13 . With the new two-dimensional
parametrization, the overall discrepancy drops down to about 20%. Since
the discrepancies are not totally resolved, there are other unknown
effects.

#### 5.2.6 Jet@xmath Background Estimate

After applying the full set of tau identification cuts, there will be
some jet background left because of the huge production rate of jets in
@xmath collisions. The jet @xmath misidentification rate and tau
identification efficiency are very useful for estimating jet background.

To estimate the jet background, the starting point is not jets, or tau
candiates, but tau candidates with at least electron removal, with a
very tight @xmath 0.2 cut applied. Muons usually cannot have enough
energy to make a tau cluster in the calorimeter. We have two general
equations,

  -- -- -- -------- -- --------
           @xmath      (5.12)
           @xmath      (5.13)
  -- -- -- -------- -- --------

where @xmath is jet @xmath misidentification rate and @xmath is tau
identification efficiency. Both are relative in a sense that they are
relative to the starting point chosen as “Before full tau ID”. The
solution is

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

Fig. 5.14 is a demonstration of picking one bin and using the formula to
estimate jet background. This is only an example because the
parametrization of the relative rates is a one-dimensional function of
energy. For the jet @xmath misidentification rate there is a better
parametrization, i.e., the two-dimensional function of energy and boost.

Implementation

The actual implementation is done on an event-by-event basis. For a tau
object in an event under consideration, the knowns are: @xmath = 1,
@xmath , @xmath and whether this tau object passes the full set of the
tau identification cuts. If it does, @xmath = 1; otherwise, @xmath = 0.
For the two cases, the weight to be a jet is estimated as

  -- -- -- -------- -- --------
           @xmath      (5.15)
           @xmath      (5.16)
  -- -- -- -------- -- --------

In terms of coding, it means the rest of full tau identification cuts
are replaced by the weight @xmath . We sum up the weights of all the
events in the sample, and get the jet background estimate @xmath ,

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

Special Case

This method actually needs both the jet @xmath misidentification rate
@xmath and the tau identification efficiency @xmath . The main idea is
to remove the contribution from any real tau signal in jet background
estimate.

The special case is that if we start with a jet-dominated sample and
@xmath is much smaller than @xmath , then we can suppress signal by
replacing tau identification cuts with the jet @xmath misidentification
rate,

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

### 5.3 Tau Scale Factor Using @xmath

In this section, we apply tau identification cuts to select hadronic
taus in @xmath events, estimate jet @xmath misidentification background,
study tau identification scale factor and compare tau distributions in
data and MC simulation.

#### 5.3.1 Data/MC Scale Factor

The scale factor for a set of cuts quantifies and corrects for the
difference between data and MC simulation. It should be multiplied on MC
to get the scaled efficiency consistent with the efficiency in data.
Fig. 5.15 shows lepton flow in data and in MC, and lepton data/MC scale
factors.

Ratio of Efficiencies

A data/MC scale factor is defined as the ratio of efficiencies,

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

where @xmath is the efficiency in MC which is straightforward to obtain
because the MC simulation has the true information of particle identity,
and @xmath is the efficiency in data, which can be a challenge to
measure.

In the electron or muon case, we can use electron or muon pairs from the
Z boson peak, which gives us a pure sample with negligible background in
real data. This is so reliable that we can use it as “standard candle”
to calibrate detector and even measure luminosity. We select one leg to
satisfy the trigger requirements in data, and ask whether the second leg
passes the set of cuts, and thereby get the efficiency in data.

Ratio of Numbers

Due to the missing energy from the neutrino in tau decays, the tau pair
mass at the Z boson peak is severely broadened. Instead, we will use
@xmath to select a relatively clean tau sample. There is no second leg
to get efficiency data/MC. We use the method of absolute number data/MC,

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

where @xmath is the absolute number of @xmath events in MC normalized to
the luminosity of data, and @xmath is the number of @xmath events
observed in the data after subtracting backgrounds.

#### 5.3.2 @xmath Selection

We select @xmath events by using a data sample from the TAU_MET trigger
which requires:

-   level 1 trigger (L1) @xmath 25 GeV

-   level 3 trigger (L3) tau @xmath 20 GeV

where (a) L1 @xmath is based on a tower threshold of 1 GeV for a fast
calculation; (b) for L3 tau, the cuts @xmath 1, 10 @xmath track
isolation and m(tracks) @xmath 2 GeV/ @xmath are applied in the trigger.

The top plot of Fig. 5.16 shows that the integrated luminosity of the
good runs is 72 @xmath 4 pb @xmath , and the bottom plot shows the L3
cross section is reasonablly flat (no sudden drop to zero), thus all of
the good runs are present in the data file.

The offline selection cuts are:

-   Monojet

-   @xmath 30 GeV

-   Tau @xmath (tracks + @xmath s) @xmath 25 GeV/ @xmath

where (a) monojet selection requires one central cone 0.7 jet with
@xmath 1 and @xmath 25 GeV, no other jets with @xmath 5 GeV anywhere;
(b) offline @xmath is obtained from the vector sum of @xmath for towers
with @xmath GeV; (c) in addition to tau @xmath threshold, the whole set
of tau identification cuts under study will be applied on the offline
tau candidates.

The monojet cut dramatically helps clean up the data sample. But, to get
the estimated @xmath of @xmath events, we need to study the monojet cut
and the L1 @xmath 25 GeV trigger efficiency for monojet-type events.

Monojet Selection

The monojet selection essentially requires there is no other underlying
jet with @xmath 5 GeV. We select @xmath events, count the number of cone
0.7 jets with @xmath 5 GeV, no @xmath cut, and 0.7 radian in @xmath R
away from muons.

The @xmath selection cuts are: (a) cosmic veto [ 26 ] , (b) one tight
muon and one track with @xmath 20 GeV/ @xmath , (c) opposite charges,
(d) track @xmath 4 cm, and (e) @xmath GeV/ @xmath . We require one tight
muon and one track, instead of two tight muons to get higher statistics.
The track is required to be of minimum ionisation particle (MIP) type.
Both the tight muon and the track requires tau-like track isolation
which is to mimic the isolated tau in @xmath events.

We use a data sample from a trigger designed to select “muon plus track”
events which have @xmath with @xmath GeV/ @xmath plus another charged
track with @xmath GeV/ @xmath . We select 5799 events with negligible
background which is confirmed by the negligible number of same-charge
muon pair events. There are 2152 events in the zero jet bin. The
fraction of zero jet events in the data is 2152/5799 = 0.371.

We use about 500K MC events. 46297 events survived after the same
selection cuts as in data. There are 20149 events in the zero jet bin.
The fraction of zero jet events in the MC is 20149/46297 = 0.435.

The number of jets distribution in data and in MC are shown in Fig. 5.18
. So @xmath monojet data/MC scale factor is

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

The uncertainty is statistical only.

L1 @xmath 25 GeV

The TAU_MET trigger triggers directly on tau objects, and so there is no
marginal trigger efficiency from TAU side. But there is marginal trigger
efficiency from MET side: L1 @xmath uses a 1 GeV tower threshold, and
offline @xmath uses a 0.1 GeV tower threshold.

We use JET20 data to study this trigger efficiency. The event topology
is monojet-like, since here that is what we are interested in. The L1
@xmath 25 GeV trigger efficiency vs offline @xmath for monojet event is
shown in Fig. 5.18 . It is a slow turn-on due to a large tower
threshold. An offline @xmath 30 GeV cut is not fully efficient.

#### 5.3.3 Tau Scale Factor

After all of the above, we count the absolute number of @xmath events
@xmath and @xmath for total integrated luminosity 72 pb @xmath . Their
ratio will be the tau scale factor.

-   To get @xmath , we will use the data sample from the TAU_MET
    trigger. We apply the offline cuts to get the observed number of
    @xmath candidates, and subtract various backgrounds.

-   To get @xmath , we will use @xmath MC simulation. We apply the
    offline cuts, multiply the number of accepted events by the monojet
    scale factor and the trigger efficiency, and normalize to 72 pb
    @xmath .

The main source of backgrounds are @xmath , @xmath , @xmath , and jet
background.

We will use MC simulation to get @xmath , @xmath , and @xmath
backgrounds. We apply the offline cuts, multiply the number of accepted
events by the monojet scale factor and the trigger efficiency, and
normalize to 72 pb @xmath . For the normalization in MC, @xmath is
2700 pb [ 20 ] , and @xmath is 326 pb with @xmath GeV/ @xmath , which is
obtained from the measured value 250 pb [ 20 ] at the Z boson mass peak
with @xmath GeV/ @xmath and normalizing the @xmath mass spectrum
generated by PYTHIA.

The jet background will be estimated directly from the data by applying
the relative jet @xmath misidentification rate and the relative tau
identification efficiency. Since the cuts @xmath , 10 @xmath track
isolation and m(tracks) @xmath GeV/ @xmath are applied in the trigger,
we use the relative rates up to the denominator @xmath . Then we just
follow the implementation described in section 5.2.6 .

Table 5.4 shows the procedure to estimate the contributions from signal
and backgrounds estimated from MC, the jet background estimated from
data, and the observed number of events in data.

The uncertainties include

-   statistical uncertainty,

-   monojet scale factor: 2%,

-   luminosity: 6% [ 27 ] , and

-   @xmath and @xmath , 2%, aside from luminosity uncertainty [ 20 ] .

Since there are discrepancies among the jet @xmath misidentification
rates obtained from different jet samples, we use the average jet @xmath
misidentification rate to get a central value of 81.8 events. The
estimates using the individual jet @xmath misidentification rate from
JET20, JET50, JET70, and JET100 samples are 90.3, 67.1, 72.8, and 66.3,
respectively. We take the biggest difference as the the uncertainty for
jet background: @xmath (66.3-81.8)/81.8 @xmath = 18.9%.

The numbers and the uncertainties of each channel are summarized in
Table 5.5 . We now arrive at the tau scale factor as follows:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.22)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

with statistical uncertainty and all of the systematic uncertainties.

Lastly we put signal and background together, and show the @xmath
kinematic distributions in data and MC in Fig. 5.19 . The agreement
between data and MC is very good.

### 5.4 Electron Identification

Identification of electrons is based on the energy it deposits in the
calorimeter, its track in the COT, and its position in the CES. The
central electron reconstruction algorithm [ 28 ] starts with clusters in
the CEM detector. The electromagnetic towers are ordered in @xmath and
the highest @xmath tower that has not yet been clustered is taken as a
seed. The available shoulder towers are added to the cluster if they are
adjacent in @xmath to the seed, and the clusters are restricted to two
towers. The default threshods for seed towers and shoulder towers are
3.0 and 0.1 GeV, respectively. For the leading electrons used in our
analysis with @xmath channel, the threshods for seed towers and shoulder
towers are set to be 8 and 7.5 GeV, respectively. Then we associate
tracks with the candidate cluster. For all of the tracks associated, the
one with highest @xmath is chosen as the matched one. The CES strip and
wire clusters are associated with the CEM cluster if they are
reconstructed in the same wedge. The “best-matching” CES cluster is the
one seeded by the matched track.

#### 5.4.1 Electron Identification Cuts

The electron identification [ 29 ] cuts, and the conversion veto [ 30 ]
cuts to remove electrons from photon conversion, are listed in Table 5.6
. The @xmath and @xmath thresholds are not listed because they depend on
the process and trigger sample. The probe electron must be a fiducial
CEM electron and pass the vertex @xmath cut.

#### 5.4.2 Electron Scale Factor

The electron identification scale factor is the ratio of the efficiency
in data/MC. The data sample is from the TAU_ELE trigger which requires
an electron with @xmath 8 GeV, @xmath 8 GeV/ @xmath and an isolated
track with @xmath 5 GeV/ @xmath . We study the electron scale factor
versus @xmath .

-   For medium- @xmath (between 5 GeV and 20 GeV) electrons, the MC uses
    electrons from @xmath , and in the real data we use the second leg
    after selecting @xmath . We require the probe electrons have @xmath
    5 GeV and @xmath 5 GeV/ @xmath in both the real data and the MC.

-   For high- @xmath (above 20 GeV) electron, the MC uses electrons from
    @xmath , and in the real data we use the second leg after selecting
    @xmath . We require the probe electrons have @xmath 20 GeV and
    @xmath 10 GeV/ @xmath in both the real data and the MC.

The procedure to select @xmath events is:

-   Require a tight electron with @xmath 8 GeV, @xmath 8 GeV/ @xmath
    which are the trigger requirements and the electron identification
    cuts.

-   Require a probe electron with @xmath 5 GeV, @xmath 5 GeV/ @xmath .

-   Same-sign pair will be used later for fitting the slope of
    background and opposite-sign pair will be used later for fitting
    signal + background.

-   Require the invariance mass of the @xmath pair to lie in the range
    (0, 20) GeV/ @xmath .

The procedure to select @xmath events is:

-   Require a tight electron with @xmath 20 GeV, @xmath 10 GeV/ @xmath
    and the electron identification cuts.

-   Require a probe electron with @xmath 20 GeV, @xmath 10 GeV/ @xmath .

-   Require opposite sign.

-   Require the invariance mass of the @xmath pair to lie in the range
    (75, 105) GeV/ @xmath .

The procedure to select the second leg is:

-   Require exactly one @xmath or Z boson.

-   If there is one tight electron, the probe electron is the second
    leg.

-   If there are two tight electrons, both are used as second leg.

Then we apply the set of electron identification cuts under study on the
second leg electrons in data, and on the probe electrons in the MC. The
result of the procedure is shown in Table 5.7 .

For the @xmath selection in the real data, the backgrounds in the sample
with a tight electron plus a probe electron and in the sample with two
tight electrons are both negligible which is confirmed by the negligible
number of same-sign events in these two samples.

For the @xmath in the real data, the backgrounds in the sample with
tight electron plus probe electron and in the sample with two tight
electrons are both significant. The same-sign samples provide the shapes
of the invariant mass distribution of the backgrounds, which are taken
as the slopes of linear backgrounds. Then in the opposite sign samples
we fit the invariant mass distributions by the “Crystal Ball” function [
31 ] plus a linear background. The @xmath invariant mass distribution
has a Bremsstrahlung tail at lower mass side where at least one of the
electrons radiates. The “Crystal Ball” line-shape serves to model this
Gaussian core with a power-law tail. The yield of signal is obtained by
the entries in the histogram subtracted by the integral of the linear
background.

Up to this point, all of the @xmath candidates in the mass window
(0, 20) GeV/ @xmath are accepted. We then subtract background, as shown
in Fig. 5.21 . The plot only shows the mass window (4, 15.5) GeV/ @xmath
. The fit is performed in the mass window (5, 12.2) GeV/ @xmath . The
fitting result is N(e + probe) = 818.0, N(e + Id) = 644.4, efficiency =
78.8%.

Now we put everything together to get the electron scale factor vs.
@xmath and perform a fit in @xmath . This is shown in Fig. 5.21 . Data:
the medium @xmath electrons (5, 20) GeV are from the second leg of
@xmath ; the high @xmath electrons (30, 100) GeV are from the second leg
of @xmath ; there is a gap (20, 30) GeV which has very low statistics
and is not used. MC: the medium @xmath electrons (5, 20) GeV are from
the probe electrons of @xmath ; the high @xmath electrons (30, 100) GeV
are from the probe electrons of @xmath . In each @xmath bin, the
efficiency in data divided by the efficiency in MC gives scale factor in
that @xmath bin. For all of the @xmath bins, the scale factor is flat. A
fit by a polynomial of degree 0, which is exactly the same as the
weighted average, gives a scale factor @xmath .

There are two bins (45, 50) GeV and (50, 100) GeV with efficiency close
to 100%, in data and MC. The binomial uncertainty in this case is always
close to zero and underestimated. This propagates to the scale factors
in those two @xmath bins, and finally propagates to the weighted
average. There is also uncertainty in the (5, 20) GeV bin due to @xmath
background subtraction. This uncertainty is not estimated. We assign a
conservative 4% uncertainty for electron scale factor [ 32 ] :

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

### 5.5 Muon Identification

Muon reconstruction [ 33 ] uses information from tracking, the
calorimeters and the muon chambers. The momentum is measured by the
curvature of the muon trajectory bent by magnetic field in tracking
system. Muons behave as minimum ionizing particles and they are the only
charged particle that can travel through the large amount of material in
calorimeter with a very small energy loss. Muons are not stable, but
they are so long lived that they can reach the muon chamber, leave hits
there, and continue to travel and decay outside the detector. These
features allow a rather simple and clean muon identification.

#### 5.5.1 Muon Identification Cuts

The muon identification cuts [ 34 ] are listed in Table 5.8 . We use
COT-only tracks and add the beam constraint to the track. The @xmath and
@xmath thresholds are not listed because they depend on the process and
trigger. For data/MC scale factor studies, we require the track to be
fiducial which means that the track is headed in a direction that will
lead it to hit enough chambers for a stub to be reconstructed. All three
subdetectors CMU, CMP, and CMX which are used in this analysis require 3
hits in 3 different layers for a stub to be reconstructed. And we will
study two kinds of data/MC scale factors:

-   Muon identification scale factor. A fiducial stub muon and vertex
    @xmath cut are required for the probe muon for this study, called
    “Probe (Id)” in Table 5.8 .

-   Marginal muon reconstruction scale factor. We require a fiducial
    track and a stubless muon, which also has the information of energy
    loss in calorimeter, for the probe muon for this study, called
    “Probe (Rec)” in Table 5.8 . It is not necessary to have hits in the
    muon chambers. The vertex @xmath cut, calorimeter isolation cut, EM
    energy cut, and hadronic energy cut are required. Then we check if
    this track has a muon stub. The default track @xmath threshold to
    make a stubless muon is 10 GeV; we lower it to 5 GeV to allow more
    medium @xmath stubless muons.

#### 5.5.2 Muon Scale Factor

The muon identification scale factor is the ratio of the identification
efficiency in real data to that in MC. The muon marginal reconstruction
scale factor is the ratio of the marginal reconstruction efficiency in
data/MC. The data sample is from the TAU_CMU trigger which requires a
CMUP muon with @xmath 8 GeV/ @xmath and an isolated track with @xmath 5
GeV/ @xmath . (A CMUP muon is required to have stubs in both CMU and
CMP). We study the muon scale factors versus muon @xmath .

-   For medium @xmath (between 5 and 20 GeV/ @xmath ) muons, the MC uses
    muon from @xmath , data uses the second leg after selecting @xmath .
    We require the probe muons have @xmath 5 GeV/ @xmath in both the
    real data and the MC.

-   For high @xmath (above 20 GeV/ @xmath ) muons, the MC uses muon from
    @xmath , and for the data we use the second leg after selecting
    @xmath . We require the probe muons have @xmath 20 GeV/ @xmath in
    both the real data and the MC.

The procedure to select @xmath events is:

-   Cosmic veto [ 26 ] .

-   Require a tight CMUP muon with @xmath 8 GeV/ @xmath which are
    trigger requirements and the CMUP muon identification cuts.

-   Require a probe muon with @xmath 5 GeV/ @xmath .

-   Require @xmath 4 cm.

-   Require opposite sign.

-   Mass window (7, 13) GeV/ @xmath . We will use side band for
    background subtraction.

The procedure to select @xmath events is:

-   Cosmic veto.

-   Require a tight CMUP muon with @xmath 20 GeV/ @xmath and the CMUP
    muon identification cuts.

-   Require a probe muon with @xmath 20 GeV/ @xmath .

-   Require @xmath 4 cm.

-   Require opposite sign. The negligible number of same sign events
    confirms that background is negligible.

-   Mass window (80, 100) GeV/ @xmath .

The procedure to select the second leg is:

-   Require exactly one @xmath or Z boson.

-   If one tight muon, the probe muon is the second leg.

-   If two tight muons, both are used as second leg.

Muon Identification Scale Factor

In the muon identification scale factor study, we apply the set of muon
identification cuts under study on the second leg muons in data, and on
the probe muons in the MC. Table 5.9 shows the procedure in data and
Table 5.10 shows the procedure in MC.

Up to this point, all of the @xmath candidates in mass window (7, 13)
GeV/ @xmath are accepted. Now we break the probe into two @xmath bins 5
@xmath 10 GeV/ @xmath and 10 @xmath 20 GeV/ @xmath . Fig. 5.23 shows the
distributions of the pair mass of the first leg and the second leg in
each @xmath bin of the second leg, for CMUP probe. We see three clear
peaks at about 9.5, 10 and 10.3 GeV/ @xmath . This is the signature of
@xmath . Now we subtract the linear background. The signal mass window
is defined as (9.2, 10.6) GeV/ @xmath . We use a side-band method: yield
= entries in (9.2, 10.6) @xmath entries in (7.8, 8.5) @xmath entries in
(11.3, 12) GeV/ @xmath mass windows. In @xmath ( @xmath ) GeV/ @xmath
bin, N(muon + probe) = 410 (85), N(muon + Id) = 168 (56), we get
efficiency = 41.0% (65.9%). We put everything together to get the CMUP
muon identification scale factor vs. @xmath and perfom a fit in @xmath .
This is shown in Fig. 5.23 .

Fig. 5.25 shows the mass distribution of muon pair in each @xmath bin of
the second leg, for CMX probe. In @xmath ( @xmath ) GeV/ @xmath bin,
N(muon + probe) = 126 (32), N(muon + Id) = 57 (19), we get efficiency =
45.2% (59.4%). Fig. 5.25 shows the procedure to get the CMX muon
identification scale factor.

Analogous to the electron scale factor study, we assign a conservative
uncertainty of 4%. The resulting identification scale factors are @xmath
for CMUP muon, and @xmath for CMX muon.

Muon Reconstruction Scale Factor

In the reconstruction scale factor study, the probe is a stubless muon
which may or may not have a stub in the muon chamber associated with the
fiducial track. It must have passed the vertex @xmath cut, calorimeter
isolation, EM energy cut, and hadronic energy cut. For such a probe, we
check if it has a stub. Table 5.11 shows the procedure in data and Table
5.12 shows the procedure in MC.

We break the second leg muon into two @xmath bins: 5 @xmath 10 GeV/
@xmath and 10 @xmath 20 GeV/ @xmath . Fig. 5.27 shows the distributions
of the pair mass of the first leg and the second leg in each @xmath bin
of the second leg, for CMUP probe. We use the side-band method to do
background subtraction. In @xmath ( @xmath ) GeV/ @xmath bin, N(muon +
probe) = 307 (65), N(muon + stub) = 272 (59), we get efficiency = 88.6%
(90.8%). We put everything together to get the muon reconstruction scale
factor vs. @xmath and perform a fit in @xmath . This is shown in Fig.
5.27 .

Fig. 5.29 shows the mass distribution of muon pair in each @xmath bin of
the second leg, for CMX probe. In @xmath ( @xmath ) GeV/ @xmath bin,
N(muon + probe) = 92 (22), N(muon + stub) = 85 (21), we get efficiency =
92.4% (95.5%). Fig. 5.29 shows the procedure to get the CMX muon
reconstruction scale factor.

As in the electron scale factor study, we assign a conservative
systematic uncertainty of 4%. The results of the reconstruction scale
factors are @xmath for CMUP muon, and @xmath for CMX muon.

We summarize the muon reconstruction and identification scale factors
with uncertainties:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.24)
     @xmath   @xmath   @xmath      (5.25)
     @xmath   @xmath   @xmath      (5.26)
     @xmath   @xmath   @xmath      (5.27)
  -- -------- -------- -------- -- --------

### 5.6 Missing Transverse Energy

Weakly interacting particles such as neutrinos of the Standard Model and
the lightest supersymmetric particle (LSP) predicted in new physics,
deposit no energy in the calorimeters. Minimum ionizing particles such
as muons leave little energy in the calorimeters. When present these
cause a significant vector sum of the transverse energy of all of the
detected particles. The imbalance, i.e., the negative of the vector sum
in the transverse plane corresponds to the missing transverse energy (
@xmath ).

Since @xmath measures the vector sum of all of the momentum of particles
escaping detection in the calorimeters, there is no information on the
energy and direction of an individual particle or how many particles
escaped detection. With many such particles in an event there is also a
chance that their transverse momenta cancel each other.

There is an instrumental source of @xmath because the calorimeters are
not perfect. There are crack regions due to the support structures, and
the transition regions between components, for example from the central
calorimeters to the plug calorimeters. The probability that all the
energy of a particle is undetected is rather small. But QCD processes
have a large production rate. Some of the jets can have a lot of energy
undetected and make a significant @xmath .

In our high-mass tau pair analysis, we will use an @xmath cut and
several other kinematic cuts related to @xmath . To get the uncertainty
due to the instrumental @xmath , we should get the distributions in data
and MC, and compare the same variable.

In the real data, the physics processes @xmath and @xmath + jet, which
have zero true missing energy, can be used to study the effect of the
instrumental @xmath . The latter is a better choice for our purpose
because hadronic taus in the calorimeters are more like jets than
electrons. The inclusive photon sample is used to select @xmath + jet
events. Jets are required to be reconstructed as hadronic tau objects.
The true @xmath in this sample should be zero. The reconstructed @xmath
corresponds to the instrumental @xmath in data.

The simulation uses @xmath process and requires a tight electron and a
hadronic tau object. The difference between the reconstructed @xmath in
the simulation minus the @xmath from neutrinos corresponds to the
instrumental @xmath in MC.

Then the instrumental @xmath is projected to the direction of hadronic
tau object, shown in Fig. 5.30 . The distributions in data and MC are
different for the longitudinal component and the transverse component,
respectively.

To get the uncertainty due to the instrumental @xmath , we “smear” the
longitudinal component and the transverse component of the instrumental
@xmath in MC according to their differences between data and MC, then
add neutrinos back to get the smeared @xmath .

Now we can calculate the uncertainty of the cuts related to @xmath by
the effect with/without smearing the instrumental @xmath . Table 5.13
shows the effect in @xmath channel of @xmath sample and @xmath sample.
The uncertainties are (1191-1125)/1125 = 5.9% in @xmath sample and
(1875-1814)/1814 = 3.4% in @xmath sample. Taking the larger value, we
find that the uncertainty in acceptance due to @xmath .

## Chapter 6 Event Kinematic Selection

In this chapter we first discuss the trigger paths. Second, we discuss
the good run selections and the integrated luminosities. Third, in
addition to the particle identification, we add event kinematic cuts to
further suppress backgrounds. Since the kinematic cuts need to keep high
efficiency for the signals, optimization on the event kinematic cuts is
necessary. Fourth, there are thresholds in the triggers. The trigger
primitives are not exactly the same as the offline variables we cut on,
and so we need to evaluate the marginal trigger efficiencies for
selected events.

### 6.1 Trigger Path

For the @xmath selection, we use the “electron plus track” trigger
called TAU_ELE. It requires an electron in the CEM detector with @xmath
GeV, @xmath GeV/ @xmath and an isolated track with @xmath GeV/ @xmath .

For the @xmath selection, there are two “muon plus track” triggers
called TAU_CMU (TAU_CMX) which requires a CMUP (CMX) muon with @xmath
GeV/ @xmath and an isolated track with @xmath GeV/ @xmath .

For the @xmath selection, we use the “ @xmath plus tau” trigger called
TAU_MET. It requires L1 @xmath GeV and an L3 tau object with @xmath GeV,
track isolation and @xmath (tracks) @xmath GeV/ @xmath .

The TAU_ELE, TAU_CMU, and TAU_CMX triggers are cleaned up by requiring
an isolated track. The TAU_MET trigger requires only one isolated tau
object thus the other tau objects in this trigger are not necessarily
isolated.

The track isolation requirement in these triggers is that there is no
additional track in a 10 @xmath to 30 @xmath annulus. This track
isolation is looser than the offline tau track isolation with a
shrinking inner cone. The detailed descriptions of the tau triggers can
be found in Ref. [ 35 ] .

In addition to selecting the candidate events, there is also an
important issue regarding the jet @xmath misidentification background.
This fake background is not negligible because of the large production
rate of jets. Using MC simulation to model all the processes of the fake
background is not adequate. We estimate the contribution of these events
directly from real data.

For the purpose of estimating jet @xmath misidentification background,
it is better to use those triggers without the isolation requirement in
order to have a sample which has a larger statistics and is dominated by
jet background.

There is an ELECTRON_CENTRAL_8 (abbreviated as CELE8) trigger which has
the same requirement as TAU_ELE but without the track isolation
requirement. There is also a MUON_CMUP8 (abbreviated as CMUP8) trigger
which has the same requirement as TAU_CMU but without the track
isolation requirement. The CELE8 and the CMUP8 triggers are dynamically
prescaled. A prescale is imposed to reduce the rate of a trigger. A
fixed prescale under-utilizes the trigger bandwidth when the luminosity
falls during a run. A dynamic prescale is based on the availability of
the trigger bandwidth, and automatically reduce the prescales as the
luminosity falls.

There is not a corresponding trigger path available for the TAU_CMX
trigger. There is a prescaled trigger available for the TAU_MET trigger
but its prescale is 100 which is too big. Thus their jet @xmath fake
background estimates have to be done with the trigger itself.

### 6.2 Good Run Selection and Integrated Luminosity

We use the data samples collected in CDF from March 2002 to September
2003 for this analysis. The Good Run List [ 36 ] used in this analysis
is in the range of the run number 141544 @xmath 168889.

We use the online initial filtering and the offline periodic
classification to decide whether a run is good or bad. The former gets
rid of obviously bad runs where there are problems with the
sub-detectors or the triggers. The latter is based on the classification
using a large sample in a run, for example, of the @xmath events which
is expected to have a very narrow peak, or the photon plus jet events
which is expected to have very good energy balancing, etc.

The status of a trigger or a sub-detector is a single bit 1 or 0, which
means good or bad. The bit 1 or 0 of a trigger is based on whether the
deadtime is less than 5% and is set by the online run control shift
crew. The bit 1 or 0 of a sub-detector at the online stage is based on
the status of the high voltage, the calibration, the occupancy, etc. and
is set by the monitoring operator. The bit 1 or 0 of a sub-detector at
the offline stage is based on, for example, the reconctructed @xmath
mass which can tell possible problems in the tracking system, the
calorimeters or the muon chambers, and is set by the physics groups.

Here are the details of the requirements on a good run. There are
several run configurations (trigger tables) when the CDF detector is
taking data: test, calibration, cosmic, and physics. A good run must be
a physics run. At the online stage the losses of the beam should be low.
The “on-tape” luminosity should be greater than 10 nb @xmath . The bits
of the L1, L2, L3 triggers, the calorimeters, the CMU detector, the CES
detector should be 1. At the offline stage the bits of the calorimeters,
the COT detector, the CMU and CMP detectors should be 1. The runs after
150145 when the CMX trigger updated L1 hardware, in addition to the bits
above, are required to have the online and offline bits of the CMX
detector set to 1.

The total integrated luminosity in the included good runs in the run
number range 141544 @xmath 168889 is 195 pb @xmath . However, the good
run of the data sample from the TAU_CMX trigger starts from 150145 and
its integrated luminosity is 179 pb @xmath ; the good run number of the
data sample from the TAU_MET trigger stops at 156487 and its integrated
luminosity is 72 pb @xmath . The TAU_MET trigger was changed after run
156487 to include L2 two-dimensional track isolation which needs further
study. The uncertainty in the luminosity measurements is about 6% [ 27 ]
.

The integrated luminosity in the data sample from the CELE8 trigger,
which is dynamically prescaled, is 46 pb @xmath . It is calculated by
adding the isolated track requirement and comparing its survived number
of events with the total number of events in the data sample from the
TAU_ELE trigger whose luminosity is known. Analogously, the integrated
luminosity in the data sample from the CMUP8 trigger is found to be
38 pb @xmath .

There were duplicate events incorrectly processed and put in the data
samples that were later reprocessed. We reprocessed all of the events.
To avoid the duplicate events, we pick one of them and require that it
be a unique event.

### 6.3 Selection Criteria

The event kinematic cuts are designed to further suppress background
while to keep high signal efficiency. Table 6.1 shows the list of cuts
for event selection. We note several features of the requirements:

-   The @xmath threshold is 25 GeV/ @xmath because tau identification is
    fully efficient at about 25 GeV/ @xmath and it is a high threshold
    to reduce background.

-   The @xmath , @xmath , and @xmath thresholds are 10 GeV, 10 GeV/
    @xmath and 10 GeV/ @xmath , respectively. (The thresholds in the
    corresponding triggers are 8 GeV, 8 GeV/ @xmath and 8 GeV/ @xmath .)
    For @xmath , we require the second tau @xmath GeV/ @xmath .

-   The @xmath cut and the angle cut @xmath are designed to remove
    hadronic jet backgrounds. They are explained below.

-   We use @xmath 120 GeV/ @xmath cut to remove the “irreducible” @xmath
    background. The low mass region with @xmath 120 GeV/ @xmath is our
    control region.

-   For the @xmath selection, we have a cosmic veto [ 26 ] .

-   For the @xmath selection, we require the second tau has exactly one
    track to further clean up QCD backgrounds. We will check tau
    signature by track multilicity on the leading tau side.

The @xmath measured in @xmath channel needs a muon correction since
there is an effect of missing energy due to the fact that muons are
minimum ionizing partilces. The procedure of the muon correction is:
first, we subtract the @xmath of a tight muon; second, we add muon
energy deposits in the calorimeters to avoid counting the same energy
twice.

We require @xmath GeV for the @xmath and @xmath selections. For the
@xmath selection, we use data from the TAU_MET trigger and we require
@xmath GeV to match the 25 GeV @xmath trigger threshold. We could
suppress more backgrounds by requiring more significant @xmath .
However, for the signal processes, since there is at least one neutrino
at each side, there is a chance that the transverse momentum of the
neutrinos cancel each other, and hence raising @xmath thresholds can
reduce signal efficiency. We found those @xmath thresholds are at
optimzed points.

The @xmath cut requires that the significant @xmath should follow the
@xmath ( @xmath ) for the @xmath ( @xmath ) channels and follow the
lower @xmath tau object for the @xmath channel. The @xmath measured is
the vector sum of the neutrinos from the decays of the two taus. Here is
the example with the @xmath channel which has one neutrino associated
with @xmath and two neutrinos associated with @xmath . Thus this event
topology cut is able to get the most of the signals, and to strongly
suppress the backgrounds, especially the jet @xmath misidentified fake
backgrounds which mostly has a @xmath with a random topology.

### 6.4 Marginal Efficiency Correction

We need to include in our estimates of the signal and background rates
the effect of the triggers. We are concerned, however, only with the
effect of the triggers on those events passing the offline cuts: the
marginal efficiency.

The TAU_MET trigger for the @xmath analysis triggers directly on tau
object, thus there is no marginal trigger efficiency from the TAU side.
But there is a marginal trigger efficiency from the MET side which is
based on a 1 GeV tower threshold for a fast calculation at L1 while the
offline @xmath is based on a 0.1 GeV tower threshold. We use the JET20
data sample and mimic the @xmath event topology in the calorimeter by
requiring one central jet with @xmath GeV and at least another one
central jet with @xmath GeV. The L1 @xmath 25 GeV trigger efficiency vs.
offline @xmath for di-tau event is shown in Fig. 6.1 . The marginal
trigger efficiency of the TAU_MET trigger for the @xmath analysis is a
slow turn-on due to the large trigger tower threshold.

The marginal efficiencies of the TAU_ELE and TAU_CMU (TAU_CMX) triggers
for the @xmath and @xmath analyses are all at plateau,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (6.1)
     @xmath   @xmath   @xmath      (6.2)
     @xmath   @xmath   @xmath      (6.3)
  -- -------- -------- -------- -- -------

The trigger efficiencies of the electron part, the muon part and the
isolated track part are calculated by using conversion electrons from
@xmath , muons from @xmath , and tracks from jet samples, respectively.
The details can be found in Ref. [ 37 ] . The biggest uncertainty is
from the track provided by the XFT trigger, which uses the four axial
@xmath superlayers (no stereo @xmath superlayers) of the COT detector
with at least 10 hits (out of total 12 hits) in each axial superlayer.
In the event reconstruction, we require at least 3 axial superlayers
with at least 7 hits in each axial superlayer, and the same
configuration for the stereo superlayers. The marginal XFT track finding
trigger efficiency is found to be a function of @xmath , @xmath , the
number of prongs, and the different run ranges. The overall uncertainty
is about 3%.

## Chapter 7 Low Mass Control Region

The low-mass region with @xmath GeV/ @xmath is used as the control
region to test the event cuts and background determination. If we find
that the observed and predicted event rates agree in the control region,
we can proceed to unblind the signal region.

The main source of events in the control region is from @xmath . The
other backgrounds include @xmath , @xmath and jet @xmath misidentified
fake background. Top background @xmath and di-boson backgrounds such as
@xmath and @xmath are negligible because their cross sections are two
orders of magnitude smaller than Drell-Yan backgrounds and their event
topology is the opposite of the requirement that a significant @xmath
follows the lepton direction. The jet @xmath misidentified fake
background is not negligible because the dijet production cross section
is large.

For the jet @xmath misidentified fake background, rather than trying to
model all the processes that could produce fake events, we estimate the
contribution of these events from real data which includes any process
contributing to the fake background.

### 7.1 Drell-Yan Cross Section

The cross section times branching ratio of the Drell-Yan processes in
the mass window @xmath GeV/ @xmath at @xmath TeV is about 250 pb [ 20 ]
. Fig. 7.1 shows the mass spectrum and event counts in different mass
regions. The @xmath sample has 377143 events in the mass window @xmath
GeV/ @xmath which corresponds to a 250 pb production cross section. The
number of events in a mass window is proportional to the cross section
in that mass window. For example, the number of events 492000 in the
mass window @xmath GeV/ @xmath gives a cross section @xmath pb. By the
same algebra, we get the cross sections in different mass windows:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (7.1)
     @xmath   @xmath   @xmath      (7.2)
     @xmath   @xmath   @xmath      (7.3)
     @xmath   @xmath   @xmath      (7.4)
  -- -------- -------- -------- -- -------

### 7.2 Drell-Yan Background

The Drell-Yan backgrounds can be estimated from MC simulation with three
pieces:

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

We just discussed the production cross section, and we have discussed
the luminosity for each trigger path in Section 6.2 . Now we discuss the
acceptance and the estimate of the Drell-Yan backgrounds. Table 7.1
shows the Drell-Yan background acceptances, the application of the
trigger efficiencies, the application of the lepton data/MC scale
factors, and the normalization to the integrated luminosities of the
data samples from the triggers.

### 7.3 Fake Background

In a “fake” background event a jet is misidentified as a tau. This
background is not negligible because the dijet production cross section
is large. The relative jet @xmath misidentification rate and the
relative tau identification efficiency corresponding to the denominator
chosen is applied to the denominator tau objects to compute their weight
for being a jet. We sum up the weights of all the events to get jet
@xmath misidentified fake background estimate in the sample, as
described in Section 5.2.6 .

There is also a probability that, for example, for @xmath channel, a jet
is misidentified as an electron. But the jet @xmath misidentification
rate is an order of magnitude smaller than the jet @xmath
misidentification rate. Electron identification requires at most two
calorimeter towers with EM energy fraction greater than 0.95 and other
cuts. Tau identification requires at most six calorimeter towers with EM
energy fraction less than 0.8 corresponding to @xmath greater than 0.2
and other cuts. Naively assuming a flat distribution between 0 and 6 of
the number of towers of jet, and a flat distribution between 0.0 and 1.0
of jet EM energy fraction, we have

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

The electron side is much cleaner than the tau side. It is a good
approximation to estimate fakes from the tau side. The situation is the
same for @xmath channel.

There is a subtlety in the fake estimate for @xmath channel. In the data
sample from the TAU_MET trigger, we order the tau objects in each event
by their @xmath . To illustrate the subtlety, here we temporately call
the leading tau object with the highest @xmath as @xmath in the case it
is a true tau or jet @xmath in the case it is a true jet, and the second
tau object with a lower @xmath as @xmath or jet @xmath . The trigger
only requires one isolated tau object. We estimate the fake background
from the second tau object side which is not necessarily isolated. This
is able to cover the two cases (a) and (b) out of the total three cases
of the fake background sources: (a) @xmath + jet @xmath , (b) jet @xmath
+ jet @xmath , and (c) jet @xmath + @xmath . Jet @xmath has a lower
misidentification rate than jet @xmath because of its higher @xmath , so
we get @xmath and @xmath . The fake estimate from the second tau object
side is an approximation.

The procedure to estimate the jet fake background in the various
channels is shown in Table 7.2 . We need to define a specific
denominator according to data sample from the trigger path available,
and we need to find out the normalization factors of the dynamically
prescaled trigger paths.

The denominators @xmath which is up to the electron removal cut @xmath
and @xmath which is up to the 10 @xmath track isolation cut are
explained in Table 5.1 in Section 5.2.3 . Note that the relative jet
@xmath misidentification rate and the relative tau identification
efficiency for different denominator samples are different.

The available dynamically prescaled triggers are discussed in Section
6.1 , and their integrated luminosities are discussed in Section 6.2 .

-   The @xmath channel has a dynamically prescaled data sample from the
    CELE8 trigger path available. There is no trigger cut on the tau
    objects, so it is ideal for the fake background estimate. We apply
    the cuts up to the electron removal cut @xmath listed in Table 5.1
    on the tau objects and use the denominator @xmath to estimate the
    fakes. The integrated luminosity of this trigger path is 46 pb
    @xmath , thus the normalization factor to the integrated luminosity
    195 pb @xmath of the data sample from the TAU_ELE trigger is 195/46
    = 4.239.

-   The @xmath with CMUP muon channel has a dynamically prescaled data
    sample from the CMUP8 trigger path available. There is no trigger
    cut on the tau objects, and we use the denominator @xmath to
    estimate the fakes. The normalization factor is 195/38 = 5.132.

-   The @xmath with CMX muon channel has to use the TAU_CMX trigger
    itself for the fake background estimate. The tau objects have
    already been cleaned up by the 10 @xmath track isolation cut in the
    trigger. We apply the cuts up to the 10 @xmath track isolation cut
    listed in Table 5.1 on the tau objects and use the denominator
    @xmath to estimate the fakes.

-   The @xmath channel has to use the TAU_MET trigger itself. The
    leading tau object is cleaned up by track isolation, but the second
    tau object is not. We estimate the fake background from the second
    tau object side, and use the denominator @xmath .

For each event, we substitute the relative tau identification efficiency
and the relative jet @xmath misidentification rate corresponding to the
defined denominator into Eq. ( 5.15 ) if the tau object does not pass
the full set of the tau identification cuts, or into Eq. ( 5.16 ) if it
does, to calculate the weight to be a jet.

We sum up the weights of all the events in the sample to estimate the
jet background, using Eq. ( 5.17 ). We then apply the event kinematic
cuts and normalize the numbers to the luminosities of the data samples
of the tau trigger paths.

The event entries which are integers corresponding to the sum of weights
which are real numbers are also shown in Table 7.2 . The event entries
are used to estimate the statistical uncertainties.

There is a systematic uncertainty due to the uncertainty in the jet
@xmath misidentification fake rate. The rate used is the average fake
rate of the JET samples. We use the individual fake rate of the JET20,
JET50, JET70, and JET100 samples to estimate this uncertainty, shown in
Table 7.3 . For example, for the @xmath channel, using the average fake
rate we get an estimate of 3.83; while using the individual fake rates
from the JET20, JET50, JET70, and JET100 samples, we get estimates 4.43,
3.25, 3.03, and 2.94, respectively. We take the biggest difference, i.e.
@xmath as the systematic uncertainty. The fractional systematic
uncertainty for this channel is @xmath . The fractional systematic
uncertainties of other channels are about 20% too.

Combining in quadrature the statistical uncertainties in Table 7.2 and
the systematic uncertainties in Table 7.3 , we get

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (7.7)
     @xmath   @xmath   @xmath      (7.8)
     @xmath   @xmath   @xmath      (7.9)
     @xmath   @xmath   @xmath      (7.10)
  -- -------- -------- -------- -- --------

### 7.4 Cross Check Fake Background

We perform a cross check on the fake background estimate as follows:
relax the tau isolation and the lepton isolation, and apply all of the
other cuts. The tau isolation and the lepton isolation are uncorrelated,
thus we can extrapolate from the fake regions into the signal region.
For example, for @xmath channel, the signal region A and the background
regions B, C and D are defined as in Fig. 7.2 , and the fake backgrounds
in A extrapolated = @xmath .

Unfortunately, we can only cross check the fake background for @xmath
channel using the data sample from the CELE8 trigger path and possibly
for @xmath with CMUP muon channel using the data sample from the CMUP8
trigger path. Neither sample has isolation in the trigger. There is no
such sample for @xmath with CMX muon channel. There is a sample without
isolation for @xmath channel, but its prescale is 100 which is too large
for this exercise.

Due to the statistics in the region B, C and D, this cross check can
only be done for the @xmath channel in the low mass control region. The
numbers in region B, C and D are 12, 142 and 13, respectively. When we
extrapolate to region A, we find that

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

The normalization factor is 4.239, thus we get @xmath fake extroplated =
@xmath = 4.66. This is in good agreement with @xmath obtained by summing
up the weights of tau object being a jet. It does give us confidence in
the method of the jet @xmath misidentified fake background estimate.

### 7.5 Uncertainties in Control Region

The statistical uncertainty and the systematic uncertainty of Drell-Yan
background estimate include

-   statistical uncertainty,

-   @xmath uncertainty, 2%, aside from luminosity uncertainty (see Ref.
    [ 20 ] ),

-   trigger efficiencies (see Section 6.4 ),

-   lepton scale factors (see Section 5.3.3 for @xmath scale factor,
    Section 5.4.2 for @xmath scale factor, and Section 5.5.2 for @xmath
    scale factors),

-   @xmath uncertainty, 6% (see Section 5.6 ), and

-   luminosity, 6% (see Ref. [ 27 ] ).

The statistical uncertainty and systematic uncertainty of the jet @xmath
misidentified fake background estimate are discussed in Section 7.3 .

We combine the @xmath CMUP muon channel with a luminosity 195 pb @xmath
and the @xmath CMX muon channel with a luminosity 179 pb @xmath into one
channel, simply called the @xmath channel. The observed events in @xmath
, @xmath and @xmath channels are 46, 36 and 8, respectively.

Table 7.4 shows the summary of the control sample in low mass region for
195 pb @xmath (72 pb @xmath for @xmath ). The total background estimate
is @xmath , dominated by the source from @xmath as expected. The
observed number of events, 90, in the control region is in good
agreement with this prediction. Fig. 7.3 @xmath 7.5 show the
distributions of each channel in the low mass control region. The
observed distributions in the data are in good agreement with the
predicted distributions.

## Chapter 8 High Mass Signal Region

The high mass region with @xmath GeV/ @xmath is the signal region. First
we calculate signal acceptance, then we estimate the backgrounds. The
main backgrounds are @xmath , @xmath , @xmath which can be estimated
from MC simulation, and the jet @xmath misidentified fake background
which can be estimated from data, as in the control region.

### 8.1 Signal Acceptance

Table 8.1 shows the procedure to measure the signal acceptances in each
channel for the new vector particle decaying to two taus, using @xmath
events. For example, for the @xmath channel, we match the offline tau
object and electron object with the @xmath and @xmath by requiring the
separation angle be less than 0.2 radian, apply the event kinematic
cuts, multiply the number of accepted events by the trigger efficiency
and the lepton scale factors, and calculate the overall acceptance.
Since the mass of the @xmath is unknown, we calculate the signal
acceptance as a function of its mass. Only five mass points (120, 180,
300, 450, 600) GeV/ @xmath out of total twelve mass points (120, 140,
160, 180, 200, 250, 300, 350, 400, 450, 500, 600) GeV/ @xmath are shown
in Table 8.1 . The signal acceptances of the @xmath channel with a CMUP
muon and of the @xmath with a CMX muon are combined into one signal
acceptance for the @xmath channel. The total acceptance is a combination
of the acceptance of the @xmath , the @xmath , and the @xmath channels.
The signal acceptances are shown in in Fig. 8.2 .

Table 8.2 shows the procedure to measure the signal acceptances in each
channel for the new scalar particle decaying to two taus, using @xmath .
We set @xmath = 20 as a representative value of @xmath . Similarly,
since the mass of @xmath is unknown, we calculate the signal acceptances
as a function of mass, as shown in Fig. 8.2 .

### 8.2 Drell-Yan Background

The largest portion of the production cross section for the Drell-Yan
backgrounds is at the @xmath boson resonance peak, about 91 GeV/ @xmath
. However the events in the high mass signal region are mostly from the
high mass Drell-Yan tail. To model the high mass tail better, we need
more statistics in MC simulation at that region. To achieve this, we
break the generation level mass into two exclusively separated regions:
@xmath GeV/ @xmath and @xmath GeV/ @xmath , and simulate them
separately. The production cross sections in these two regions are about
315 pb and 11 pb, respectively (see Section 7.1 ). Therefore we have a
low-mass sample and a high-mass sample for each @xmath source.

Table 8.3 shows the procedure to estimate Drell-Yan backgrounds. We
apply the event kinematic cuts on the MC samples, multiply the number of
surviving events by the trigger efficiencies and the lepton scale
factors, normalize to the integrated luminosity 195 pb @xmath (179 pb
@xmath for the TAU_CMX trigger, 72 pb @xmath for the TAU_MET trigger),
and combine the estimate for the low-mass Drell-Yan sample and the
estimate for the high-mass Drell-Yan sample.

### 8.3 Fake Background

The procedure to estimate the jet @xmath fake background is similar to
what we have done for low mass control region in Section 7.3 . The
trigger path, the luminosity normalization factor, the denominator tau
object definition, and the sum of the weights of tau objects being a jet
in the high mass signal region are exactly the same as those in the low
mass control region. The only one difference is this cut: @xmath GeV/
@xmath for the low mass control region, while @xmath GeV/ @xmath for the
high mass signal region. Now we repeat the same procedure, as shown in
Table 8.4 . The event entries which are integers corresponding to the
sum of weights which are real numbers are also shown. The event entries
are used to estimate the statistical uncertainties.

There is a systematic uncertainty due to the uncertainty in the jet
@xmath fake rate. The rate used is the average fake rate of the JET
samples. We use the individual fake rate of the JET20, JET50, JET70, and
JET100 samples to estimate this uncertainty, as shown in Table 8.5 .

Combining in quadrature the statistical uncertainties in Table 8.4 and
the systematic uncertainties in Table 8.5 , we get

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (8.1)
     @xmath   @xmath   @xmath      (8.2)
     @xmath   @xmath   @xmath      (8.3)
     @xmath   @xmath   @xmath      (8.4)
  -- -------- -------- -------- -- -------

### 8.4 Uncertainties in Signal Region

We summarize all of the systematic uncertainties in the high mass signal
region in this section. Some of these are due to statistical
uncertainties on the various backgrounds due to limited Monte Carlo or
other statistics. Others come from separate external studies as
indicated. And in this section, we combine the @xmath with CMUP muon
channel and the @xmath with CMX muon channel into one single @xmath
channel.

The systematic uncertainty in the Drell-Yan and new particle signal
rates due to the imperfect knowledge of the parton density functions
(PDF’s) [ 22 ] is calculated by comparing the acceptance change ratio
for various PDF’s. The CTEQ5L is used in PYTHIA. We add in quadrature
the difference between MRST72 to CTEQ5L, MRST75 to MRST72, CTEQ6L1 to
CTEQ6L, and CTEQ6M to CTEQ5L PDF’s. The MRST72 and MRST75 compare the
effect of varying @xmath on the PDF. The CTEQ5L set is leading order,
and the CTEQ6M sets are next to leading order but at the same value of
@xmath . Using @xmath , this is shown in Table 8.6 . We take 8% as a
conservative number.

We are careful to identify the correlated and the uncorrelated
systematic uncertainties. The correlated uncertainties include the
uncertainties of the PDF, the integrated luminosity, the @xmath , @xmath
, @xmath scale factors, the @xmath , and the jet @xmath fake rate. Table
8.7 lists the uncertainties, their magnitude, and the affected channels.
(When uncertainties are correlated we assume a 100% correlation.)

The @xmath and @xmath signal acceptances and the systematic
uncertainties are listed in Table 8.8 @xmath 8.9 . The acceptance itself
reflects the effects of trigger efficiency and the lepton scale factors.
The uncertainties include the contributions from

-   statistical uncertainty (MC statistics),

-   PDF uncertainty (this Section),

-   trigger efficiencies (see Section 6.4 ),

-   lepton scale factors (see Section 5.3.3 for @xmath scale factor,
    Section 5.4.2 for @xmath scale factor, and Section 5.5.2 for @xmath
    scale factors), and

-   @xmath uncertainty (see Section 5.6 ).

The systematic uncertainties on the Drell-Yan backgrounds and the jet
@xmath misidentified fake backgrounds are listed in Table 8.10 . The
systematic uncertainties on the Drell-Yan backgrounds incorporate the
effects of

-   statistical uncertainty (MC statistics),

-   PDF uncertainty (this Section),

-   @xmath uncertainty, 2%, aside from luminosity uncertainty (see Ref.
    [ 20 ] ),

-   trigger efficiencies (see Section 6.4 ),

-   lepton scale factors (see Section 5.3.3 for @xmath scale factor,
    Section 5.4.2 for @xmath scale factor, and Section 5.5.2 for @xmath
    scale factors),

-   @xmath uncertainty (see Section 5.6 ), and

-   luminosity, 6% (see Ref. [ 27 ] ).

The systematic uncertainties on the jet @xmath misidentified fake
background incorporates the effects of

-   statistical uncertainty (see Section 8.3 ), and

-   systematic uncertainty due to jet @xmath misidentification rate (see
    Section 8.3 ).

## Chapter 9 Results

### 9.1 Observed Events

After unblinding the signal region, we observe four events in @xmath
channel, zero events in @xmath channel, and zero events in @xmath
channel. The numbers of background events estimated and observed are in
Table 9.1 . Fig. 9.1 shows the @xmath distribution. Fig. 9.2 @xmath 9.5
shows the event displays of the four events observed in @xmath channel.

### 9.2 Experimental Limits

Since we observe no excess, we proceed to calculate the 95% confidence
level (CL) upper limit on the cross section times branching ratio for
new particle production using a Bayesian procedure described in Ref. [
38 ] .

We need to combine multiple search channels and incorporate both
uncorrelated and correlated systematic uncertainties. For each channel
@xmath , the integrated luminosity, the signal acceptance, the expected
background events, and the observed events are denoted as @xmath ,
@xmath , @xmath , and @xmath , respectively; the uncorrelated
uncertainties of the signal acceptance and the expected background
events are denoted as @xmath and @xmath , respectively. The correlated
uncertainties of the integrated luminosity, the signal acceptance, and
the expected background events are denoted as @xmath , @xmath , and
@xmath , respectively. (Note that the @xmath factors carry @xmath
indices and the @xmath factors do not.) With a signal cross section
@xmath , the expected number of event @xmath in each channel can be
written as

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

where the @xmath and @xmath factors are in a form @xmath thus relative
systematic uncertainties. We define a likelihood which is the product of
the Poisson probabilities of observing @xmath events in each channel,

  -- -------- -- -------
     @xmath      (9.2)
  -- -------- -- -------

where the overbars indicate that the variables are arrays carrying an
@xmath index. We use a Monte Carlo method to convolute the effects of
the systematic uncertainties using Gaussian prior probability density
functions for the @xmath and @xmath factors. For an evaluating point of
the @xmath , we sample the @xmath and @xmath factors within their
Gaussian widths around a central value of zero, calculate the @xmath and
the @xmath for each channel, and average the resulting likelihood @xmath
. Using Bayes’ Theorem, we then construct a probability density function
for the signal cross section,

  -- -- -- -------
           (9.3)
  -- -- -- -------

with a prior probability density function @xmath which expresses the
subjective “degree of belief” for the value of the signal cross section.
The 95% CL upper limit @xmath is obtained by solving this integral
equation

  -- -------- -- -------
     @xmath      (9.4)
  -- -------- -- -------

We assume a uniform prior in the signal cross section up to some high
cutoff; the value of the cutoff has no significant influence on the 95%
CL upper limit.

We thereby extract the experimental 95% CL upper limit of @xmath for
models using vector boson and scalar boson, respectively. The results
are listed in Table 9.2 and shown in Fig. 9.6 . These are the generic
limits for @xmath and @xmath which can be interpreted in various models.

### 9.3 Exclusion Regions

Now we can put the theoretical predictions on high mass tau pair
production discussed in Section 2.3 and the experimental 95% CL upper
limits together. We take the region where the theoretical prediction is
bigger than the upper limit to be excluded at 95% CL.

For reference, this analysis would thus exclude at 95% CL a @xmath with
standard model couplings having a mass of less than 394 GeV/ @xmath , as
shown in Fig. 9.7 . For the MSSM pseudoscalar Higgs boson @xmath , this
analysis is not sensitive to exclude a region yet.

## Chapter 10 Conclusions

We have performed a blind search for high mass tau pairs using data
corresponding to 195 pb @xmath of integrated luminosity from Run II of
the Tevatron, using the CDF detector. In the high-mass region with
@xmath GeV/ @xmath , we expect @xmath events from known background
sources, and observe @xmath events in the data sample. Thus no
significant excess is observed, and we use the result to set upper
limits on the cross section times branching ratio to tau pairs of scalar
and vector particles as a function of mass, shown in Table 9.2 and
ploted in Fig. 9.6 .

## Appendix A The Structure of the Standard Model

The fundamental constituents of matter in Nature are fermions: leptons
and quarks, with interactions specified by the gauge symmetries SU(3)
@xmath @xmath SU(2) @xmath @xmath U(1) @xmath in the framework of the
Standard Model (SM).

Why are the fermions in an electroweak doublet? Why are left-handed
fermions in a doublet, and right-handed fermions in a singlet? What
tells us that quarks have color degrees-of-freedom? Why must quark
doublets be paired with lepton doublets? Here we come to a brief review
of how the structure of the SM emerged. A good introduction can be found
in Ref. [ 39 ] .

The relationships among the fermions are interpreted from the
interactions they experience, namely the cross sections and decay widths
measured, calculated, and measured … an interplay of experimental inputs
and theoretical constraints. The objective is to unify the different
interactions.

Charged Current

Let us recall Fermi’s theory [ 40 ] of charged current (CC) weak
interaction for four fermions, e.g. the crossed @xmath -decay, @xmath ,

[]

The amplitude (matrix element) of this process can be written as

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

where @xmath is Fermi’s constant and the charged currents for the
fermion fields are

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

The next advance came after the discovery that CC violates parity
maximally [ 41 ] and the V-A theory of the weak interaction [ 42 ] was
proposed. Only left-handed fermions, which are projected by a V-A
operator @xmath , appears in CC.

[]

  -- -------- -- -------
     @xmath      (A.3)
  -- -------- -- -------

  -- -------- -- -------
     @xmath      (A.4)
  -- -------- -- -------

After the introduction of quarks [ 43 ] for understanding the
classification of the hadrons, it was natural to re-write the hadronic
part of CC in terms of quark fields. The transition @xmath occurs via
CC, with the other two quarks in the nucleon being spectators.

[]

  -- -------- -- -------
     @xmath      (A.5)
  -- -------- -- -------

There was an inconsistency found in the value of the Fermi constant
@xmath as determined from @xmath -deay and the purely leptonic muon
decay. This lead Cabibbo to the hypothesis that the quark states in CC
are not the physical states (eigenstates of mass), but rather a quantum
superposition of the physical states.

  -- -------- -- -------
     @xmath      (A.6)
  -- -------- -- -------

where @xmath is Cabibbo angle, thus the Fermi constant is replaced by
@xmath . This idea was generalized to the case of three quark
generations in terms of the CKM (Cabbibo-Kobayashi-Maskawa) matrix [ 5 ]
,

  -- -------- -- -------
     @xmath      (A.7)
  -- -------- -- -------

Glashow proposed the intermediate vector boson model (IVB) in 1961 [ 44
] and the form has been incorportated in the SM. The basic idea is to
replace the four fermion interaction by the exchange of a massive
charged boson @xmath , e.g. @xmath , (a) four fermion interaction, (b)
the IVB model:

[]

The matrix element can be written as

  -- -- -- -------
           (A.8)
  -- -- -- -------

  -- -------- -- -------
     @xmath      (A.9)
  -- -------- -- -------

Comparing Eq. ( A.8 ) with Eq. ( A.9 ), substituting @xmath and @xmath ,
and using experimental values: @xmath , @xmath GeV @xmath , @xmath (
@xmath was first determined from the NC/CC cross section ratio in
neutrino scattering where NC is the neutral current interaction
explained below), this leads to the prediction for the W mass:

  -- -------- -- --------
     @xmath      (A.10)
  -- -------- -- --------

This may be compared with the experimental value [ 3 ] :

  -- -------- -- --------
     @xmath      (A.11)
  -- -------- -- --------

The interdediate @xmath bosons, along with the @xmath bosons explained
below, were discovered at CERN in 1983 [ 45 ] .

A Doublet in Weak Isospin Space

We write the left-handed leptons in a weak isospin SU(2) @xmath doublet
and the right-handed leptons in a singlet, for example,

  -- -------- -- --------
     @xmath      (A.12)
  -- -------- -- --------

The generators of the SU(2) @xmath transformations are @xmath , where
@xmath are Pauli matrices. The charge raising opertator @xmath , the
charge lowering operator @xmath , and the original @xmath are

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.13)
     @xmath   @xmath   @xmath      (A.14)
     @xmath   @xmath   @xmath      (A.15)
  -- -------- -------- -------- -- --------

The currents can be written as

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.16)
     @xmath   @xmath   @xmath      (A.17)
     @xmath   @xmath   @xmath      (A.18)
  -- -------- -------- -------- -- --------

These can be combined into an isospin triplet of currents

  -- -------- -- --------
     @xmath      (A.19)
  -- -------- -- --------

The weak isospin invariance implies that the SU(2) @xmath invariant
Lagrangian to describe the interaction between the @xmath bosons and the
current @xmath with a coupling @xmath is of the form

  -- -------- -- --------
     @xmath      (A.20)
  -- -------- -- --------

Hence a neutral IVB W @xmath should exist, coupling to @xmath . Since
the electromagnetic current @xmath is parity conserving,

  -- -------- -- --------
     @xmath      (A.21)
  -- -------- -- --------

Whereas @xmath has a V-A structure. @xmath cannot be directly identified
with the electromagnetic current, nor W @xmath with the photon.

Neutral Current

Next came the inputs from the neutral current (NC) interactions. NC were
discovered by the Gargamelle Collaboration at CERN in 1973 [ 46 ] ,
@xmath .

[]

The matrix element can be written as

  -- -------- -- --------
     @xmath      (A.22)
  -- -------- -- --------

with NC in the form

  -- -------- -- --------
     @xmath      (A.23)
  -- -------- -- --------

  -- -------- --
     @xmath   
  -- -------- --

The neutrino part has a V-A structure. The lepton/quark part has parity
violation ( @xmath ), but not maximally ( @xmath ). Universality of NC
and CC requires @xmath , later predicted in the SM.

We can write the NC interactions in terms of IVB, e.g. @xmath , (a) four
fermion interaction, (b) the IVB model:

[]

The matrix element can be written as

  -- -------- -- --------
     @xmath      (A.24)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (A.25)
  -- -------- -- --------

Comparing Eq. ( A.24 ) with Eq. ( A.25 ), and assuming universality of
the charged and neutral currents ( @xmath ), this gives the prediction
for Z mass:

  -- -------- -- --------
     @xmath      (A.26)
  -- -------- -- --------

This may be compared with the experimental value [ 3 ] :

  -- -------- -- --------
     @xmath      (A.27)
  -- -------- -- --------

Flavor Changing Neutral Current

The flavor changing neutral current (FCNC) interaction is strongly
suppressed [ 3 ] , (a) CC, (b) FCNC:

[]

  -- -------- -- --------
     @xmath      (A.28)
  -- -------- -- --------

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.29)
     @xmath   @xmath   @xmath      (A.30)
  -- -------- -------- -------- -- --------

The GIM (Glashow-Iliopoulos-Maiani) mechanism [ 47 ] proposed that
quarks must be paired in doublets. This naturally solved FCNC. In
addition, @xmath quark was predicted and later discovered [ 48 ] .

  -- -------- -- --------
     @xmath      (A.31)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (A.32)
  -- -------- -- --------

A Triplet in Quark Color Space

The quarks in the spin- @xmath baryons are in a symmetrical state of
space, spin and flavor degrees of freedom, e.g.

  -- -------- -- --------
     @xmath      (A.33)
  -- -------- -- --------

However the requirements of Fermi-Dirac statistics imply the total
antisymmetry of the wave function. The solution was the introduction of
the color degree of freedom, with indices as red ( @xmath ), green (
@xmath ), and blue ( @xmath ).

  -- -------- -- --------
     @xmath      (A.34)
  -- -------- -- --------

One of the tests of the number of charged fundamental constituents is
provided by

  -- -------- -- --------
     @xmath      (A.35)
  -- -------- -- --------

The virtual photon emitted by the @xmath annihilation will excite all
kinematically accessible @xmath pairs from the vacuum.

  -- -------- -- --------
     @xmath      (A.36)
  -- -------- -- --------

At low energy where only the @xmath , @xmath and @xmath quarks are
available, in the absense of color degree of freedom, we expect

  -- -------- -- --------
     @xmath      (A.37)
  -- -------- -- --------

If quarks have three colors,

  -- -------- -- --------
     @xmath      (A.38)
  -- -------- -- --------

For energies above 10 GeV, @xmath and @xmath quarks are available,

  -- -------- -- --------
     @xmath      (A.39)
  -- -------- -- --------

The color triplet model is excellently supported by data, see the “
@xmath and @xmath in @xmath Collisions” plots in the Section “Plots of
cross sections and related quantities (Rev.)” in PDG [ 3 ] .

Pair Quarks with Leptons

Some classical symmetries, known as anomalous symmetries [ 49 ] are
broken by quantum effects. The requirement for an anomaly-free theory [
50 ] is that:

  -- -------- -- --------
     @xmath      (A.40)
  -- -------- -- --------

where the sum is over all quarks and leptons. For example consider the
two doublets,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

  -- -------- -- --------
     @xmath      (A.41)
  -- -------- -- --------

Cancellation of anomalies requires that quark doublets must be paired
with lepton doublets. The SM identifies a generation in a natural way by
identifying the doublet containing the heaviest charged lepton with the
doublet containing the heaviest quarks (and so on), but one could in
principle associate any quark doublet with any lepton doublet and call
that a generation, because there are no interactions between quarks and
leptons in the SM. What needs to be guaranteed is that the number of
quark and lepton generations must be equal.

## Appendix B Gauge Symmetry & Spontaneous Symmetry Breaking

The interactions between the fermions and the vector bosons in the
Standard Model (SM) are uniquely specified by requiring the theory, i.e.
the SM Lagrangian, invariant under gauge transformations which are local
and involve transformations varying from point to point. Some of the
standard texts are listed in Ref. [ 51 ] .

A symmetry indicates a deeper relationship among the elementary
particles with a further unification of the interactions and makes the
form of a Lagrangian more compact. Symmetry dictates design and plays
the central role in the direction to find the simplest model .

Gauge Symmetry

Let us take electromagnetism as an example and consider the Lagrangian
for a free fermion field @xmath .

  -- -------- -- -------
     @xmath      (B.1)
  -- -------- -- -------

This is invariant under a global U(1) phase transformation which is
space-time independent and is illustrated in the left plot in Fig. B.1 ,

  -- -------- -- -------
     @xmath      (B.2)
  -- -------- -- -------

where @xmath is the charge or the U(1) quantum number of the fermion.
For example, the charge assignment for @xmath quark, @xmath quark,
@xmath , and @xmath are +2/3, -1/3, 0, and -1, respectively.

We are going to construct an invariant Lagrangian under a local, i.e.,
gauge, U(1) phase transformation which is space-time dependent and is
illustrated in the right plot in Fig. B.1 .

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

The partial derivative @xmath in Eq. ( B.1 ) spoils the invariance. We
need to form a gauge-covariant derivative @xmath which will have the
simple transformation property,

  -- -------- -- -------
     @xmath      (B.4)
  -- -------- -- -------

so that the combination @xmath is gauge invariant. To achieve this, we
enlarge the Lagrangian with a new vector gauge field @xmath and form the
covariant form as

  -- -------- -- -------
     @xmath      (B.5)
  -- -------- -- -------

where @xmath is a free parameter which eventually will be identified as
the coupling of the gauge field to the fermion field. The transformation
property in Eq. ( B.4 ) will be satisfied if the gauge field @xmath has
the transformation property

  -- -------- -- -------
     @xmath      (B.6)
  -- -------- -- -------

Note that the coupling of the gauge field (photon) to any fermion field
is determined by its transformation property under the symmetry group.
This is usually referred to as universality . Also note that photon is
massless because an @xmath term is not gauge invariant under this
transformation.

To make the photon field a truely dynamical variable we need to add a
kinetic term to the Lagrangian involving its derivatives. The simplest
gauge-invariant term with a conventional normalization is

  -- -------- -- -------
     @xmath      (B.7)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (B.8)
  -- -------- -- -------

Terms with higher powers are omitted in order that the theory be
renormalizable. We notice that photon does not have self-coupling
because it does not carry a charge.

Now we arrive at the gauge-invariant QED Lagrangian

  -- -------- -- -------
     @xmath      (B.9)
  -- -------- -- -------

Most remarkably, if one demands the symmetry be local, one is forced to
include the electromagnetic field, and hence, light. Recall that there
are four Maxwell equations. While here we just require “gauge symmetry”
and electromagnetism is determined. This illustrates how physics becomes
simpler.

Non-Abelian Gauge Symmetry

Yang and Mills extended the gauge principle to non-Abelian symmetry [ 52
] . Consider the simplest case isospin SU(2). Let the fermion field be
an isospin doublet,

  -- -------- -- --------
     @xmath      (B.10)
  -- -------- -- --------

The free Lagragian

  -- -------- -- --------
     @xmath      (B.11)
  -- -------- -- --------

is invariant under the global SU(2) transformation

  -- -------- -- --------
     @xmath      (B.12)
  -- -------- -- --------

where @xmath are the SU(2) transformation parameters and @xmath are the
SU(2) generators with @xmath the Pauli matrices satisfying

  -- -------- -- --------
     @xmath      (B.13)
  -- -------- -- --------

with @xmath the structure constants for SU(2).

It is easy to check that two successive SU(2) transformations do not
commute because the generators do not commute and this is why SU(2) is
called a non-Abelian symmetry, in contrast to an Abelian symmetry such
as U(1) where two successive U(1) transformations commute.

Under the local symmetry transformation

  -- -------- -- --------
     @xmath      (B.14)
  -- -------- -- --------

the partial derivative @xmath in Eq. ( B.11 ) spoils the invariance. To
construct a gauge-invariant Lagrangian we follow a procedure similar to
that of the Abelian case:

-   We form a gauge-covariant derivative

      -- -------- -- --------
         @xmath      (B.15)
      -- -------- -- --------

    by introducing vector gauge fields @xmath , @xmath (one for each
    group generator) and a coupling @xmath

      -- -------- -- --------
         @xmath      (B.16)
      -- -------- -- --------

    and defining the transformation property for the vector gauge fields
    as,

      -- -------- -- --------
         @xmath      (B.17)
      -- -------- -- --------

    The gauge fields are massless because an @xmath term is not gauge
    invariant, similar to an Abelian field. But, the second term is
    clearly the transformation for a triplet representation under SU(2),
    thus the @xmath fields carry charges.

-   Then we add a gauge invariant kinetic term for the gauge fields

      -- -------- -- --------
         @xmath      (B.18)
      -- -------- -- --------

    where

      -- -------- -- --------
         @xmath      (B.19)
      -- -------- -- --------

    The third term shows that the gauge fields have self-coupling
    because they carry charge, in contrast to an Abelian field.

We arrive at the complete gauge-invariant Lagrangian which describes the
interaction between the gauge fields @xmath and the SU(2) doublet
fields,

  -- -------- -- --------
     @xmath      (B.20)
  -- -------- -- --------

Generalization of the Yang-Mills theory to a higher group SU(N) with
@xmath is straightforward.

SU(3) @xmath @xmath SU(2) @xmath @xmath U(1) @xmath

The structure of the gauge symmetries in the SM is SU(3) @xmath @xmath
SU(2) @xmath @xmath U(1) @xmath . For a particular fermion @xmath , its
quantum field is a product of factors,

  -- -------- -- --------
     @xmath      (B.21)
  -- -------- -- --------

Each factor has some labels, coordinates, or indices. The orthonormality
of the quantum field holds separately for each factor. Since the gauge
bosons of one of the symmetry groups do not transform under the other
gauge symmetries in the product of groups, the gauge invariant
Lagrangian may be simply written as a sum of the terms of individual
groups. The gauge symmetric Lagrangian in the framework of Yang-Mills
theory is

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where the eight @xmath and @xmath , the three @xmath and @xmath , the
one B @xmath and @xmath are the gauge bosons and generators
corresponding to the SU(3) @xmath color, the SU(2) @xmath weak isospin,
and the U(1) @xmath hypercharge gauge symmetries, respectively; @xmath
are the gauge couplings; and

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (B.23)
     @xmath   @xmath   @xmath      (B.24)
     @xmath   @xmath   @xmath      (B.25)
  -- -------- -------- -------- -- --------

with @xmath and @xmath the structure constants for SU(2) and SU(3).

At this stage, all of the gauge bosons and fermions are massless. The
explicit mass terms break gauge invariance. For gauge bosons, the
exptected mass terms

  -- -------- -- --------
     @xmath      (B.26)
  -- -------- -- --------

plus similar terms for the others, are clearly not invariant under gauge
transformations @xmath . This is true for any gauge theory. For
fermions, using the left- and right-handed projection operator @xmath
and @xmath , the mass term can be written as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (B.27)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

In the SM, left-handed fermions are in SU(2) doublets and the
right-handed fermions are in SU(2) singlets, thus they transform
differently. The @xmath and @xmath terms are not SU(2) singlets and
would not give an SU(2) invariant Lagrangian.

However the description that all of the gauge bosons and fermions are
massless is not true in Nature. We need to

-   generate the masses of the leptons and quarks;

-   generate the masses of the @xmath , @xmath , and @xmath weak vector
    bosons;

-   but also keep the photon and gluon massless.

In other words, the SU(3) @xmath will be kept precise, and the gluon
will remain massless. We need to break SU(2) @xmath @xmath U(1) @xmath
down to U(1) @xmath , resulting in mixing between the @xmath and @xmath
fields, and non-zero masses for three of the gauge bosons ( @xmath and
@xmath ). The photon ( @xmath ) remain massless, due to a residual U(1)
@xmath gauge symmetry that remains unbroken.

Spontaneous Symmetry Breaking

The solution in the SM is to add a spontaneous symmetry breaking (SSB)
term into the symmetric Lagrangian “by hand”. The Lagrangian will remain
symmetric but the physical vacuum does not respect the symmetry. In this
case, the symmetry of the Lagrangian is said to be spontaneously broken.

  -- -------- -- --------
     @xmath      (B.28)
  -- -------- -- --------

The assumption to construct @xmath is that the universe is filled with a
scalar field, called Higgs field. One real scalar field could solve (a).
One complex field could solve (a) and create one massive vector boson.
To achieve (a), (b) and (c), the minimum requirement of the Higgs field
is two complex fields arranged in a doublet in the SU(2) space and
carries U(1) hypercharge +1 (electric charge @xmath is +1 and 0 for the
upper and lower component, respectively), but is a singlet in color
space.

  -- -------- -- --------
     @xmath      (B.29)
  -- -------- -- --------

Under a SU(2) @xmath @xmath U(1) @xmath gauge transformation, the
doublet transforms as

  -- -------- -- --------
     @xmath      (B.30)
  -- -------- -- --------

The scalar field can be given gauge invariant terms in @xmath : the
kinetic term required by gauge invariance, the Higgs potential including
a mass-like term and a self-interaction term, and the Yukawa coupling
between the doublet and a particular fermion @xmath .

  -- -------- -- --------
     @xmath      (B.31)
  -- -------- -- --------

with

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (B.32)
     @xmath   @xmath   @xmath      (B.33)
     @xmath   @xmath   @xmath      (B.34)
  -- -------- -------- -------- -- --------

Spontaneous symmetry breaking of the Higgs potential [ 4 ] is possible
by assuming @xmath (also a positive @xmath to possess a stable vacuum).
This is shown in Fig. B.2 .

The minimum of the Higgs potential shifts (in field space) from @xmath
to

  -- -------- -- --------
     @xmath      (B.35)
  -- -------- -- --------

The field thus acquires a non-zero vacuum expectation value (VEV).
Choosing @xmath , we expand about @xmath ,

  -- -------- -- --------
     @xmath      (B.36)
  -- -------- -- --------

with @xmath . Any SU(2) doublet can be written as

  -- -------- -- --------
     @xmath      (B.37)
  -- -------- -- --------

By applying the gauge symmetry of @xmath under the transformation of the
Higgs doublet in Eq. ( B.30 ), the algebra can be simplied by “gauging
away” three of the four real degrees of freedom of the Higgs doublet
with @xmath ,

  -- -------- -- --------
     @xmath      (B.38)
  -- -------- -- --------

This is called the unitary gauge. On the other hand, the physical
quantities are independent of the choice of gauge. This indicates these
degrees of freedom are unphysical.

Gauge Boson Mass

The generators of the SU(2) @xmath transformations are @xmath , where
@xmath are Pauli matrices.

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (B.39)
     @xmath   @xmath   @xmath      (B.40)
     @xmath   @xmath   @xmath      (B.41)
  -- -------- -------- -------- -- --------

We write explicitly

  -- -------- -- --------
     @xmath      (B.42)
  -- -------- -- --------

We then substitute Eq. ( B.38 ) and Eq. ( B.42 ) into the kinetic term
and the Higgs potential of @xmath in Eq. ( B.31 ). After some algebra
the tree-level mass terms for the @xmath field and the gauge bosons are
present. The unphysical scalars reappear as the longitudinal
polarizations of the weak bosons.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

and many other interaction terms. The fields @xmath are defined as the
electric charge eigenstates. The SSB has mixed the @xmath and @xmath
gauge bosons with the weak mixing angle @xmath .

  -- -------- -- --------
     @xmath      (B.46)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (B.47)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (B.48)
  -- -------- -- --------

Now we can read out the tree-level masses,

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (B.49)
     @xmath   @xmath   @xmath      (B.50)
     @xmath   @xmath   @xmath      (B.51)
     @xmath   @xmath   @xmath      (B.52)
  -- -------- -------- -------- -- --------

Using @xmath in Eq. ( A.10 ) with Fermi’s constant @xmath GeV @xmath ,
we can estimate the VEV of the Higgs field:

  -- -------- -- --------
     @xmath      (B.53)
  -- -------- -- --------

The quantity

  -- -------- -- --------
     @xmath      (B.54)
  -- -------- -- --------

is the universality parameter of the neutral current interactions and
the charged current interactions. It is predicted to be one at tree
level in the SM, thus provides a test of the SM realization of SSB
compared to other models. Any deviation from @xmath would be an
important signal of new physics.

Eletroweak Unification

Substituting the physical state of @xmath in Eq. ( B.46 ) and @xmath ,
@xmath in Eq. ( B.47 ) into the electroweak interaction in the covariant
derivative term in Eq. ( B ), and using @xmath , we can identify the
weak CC, weak NC, and electromagnetic interactions.

  -- -- -- -------- -------- --------
           @xmath            (B.55)
           @xmath   @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- --------

Comparing the electromagnetic part with the @xmath term of @xmath in
Eq. ( B.9 ), this implies the unification relation:

  -- -------- -- --------
     @xmath      (B.56)
  -- -------- -- --------

Yukawa Coupling

Now we check the fermion masses. The structure of the lepton fields, for
example, of the first generation is

  -- -------- -- --------
     @xmath      (B.57)
  -- -------- -- --------

The Higgs field is an SU(2) doublet. This makes it possible to write an
SU(2)-invariant interaction of the fermions with the Higgs field, i.e.,
the Yukawa coupling term in Eq. ( B.34 ), which can be written as

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Here @xmath is an SU(2) invariant. Multiplying by the @xmath does not
change the SU(2) invariance. The second term is the Hermitian conjugate
of the first. The coupling @xmath is arbitrary because it is not
specified by the gauge symmetry principle of the theory. After SSB by
substituting @xmath with Eq. ( B.38 ), and using @xmath , we get

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (B.59)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

We have identified the fermion mass as @xmath . Thus the theory can now
accommodate a non-zero fermion mass. The second term says that there is
a lepton-Higgs coupling @xmath . We notice that there is no mass term
occured for neutrinos, @xmath . By assumption the theory contains no
right-handed neutrino state @xmath , therefore a term analogous to Eq. (
B ) cannot be written that will lead to a mass term @xmath . And this
implies neutrinos do not interact with @xmath .

The structure of the quark fields, for example, of the first generation
is

  -- -------- -- --------
     @xmath      (B.60)
  -- -------- -- --------

Since the structure of the right-handed quark is different from the
lepton case, there is a subtlety in writing down the Yukawa coupling
term. We know @xmath is an SU(2) doublet, then so is

  -- -------- -- --------
     @xmath      (B.61)
  -- -------- -- --------

This is true for any SU(2) doublet. Since @xmath has hypercharge @xmath
, @xmath has @xmath , and for each state, @xmath is still satisfied.
After SSB, @xmath becomes

  -- -------- -- --------
     @xmath      (B.62)
  -- -------- -- --------

The SU(2)-invariant Yukawa coupling for the quarks can be written as

  -- -------- -- --------
     @xmath      (B.63)
  -- -------- -- --------

After SSB by substituting @xmath with Eq. ( B.38 ), @xmath with Eq. (
B.62 ), and using @xmath , we get

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (B.64)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Again the quark masses can be accommodated, but are arbitrary
parameters. They have to be provided by experiment. The last two terms
describe the interaction of @xmath and @xmath quarks with @xmath .

The procedure can be copied for the second and third generations with
@xmath and with @xmath and @xmath . Since @xmath interacts with a
coupling proportional to @xmath , it couples most strongly to the
heaviest generation.

CKM Matrix

The spaces we have been working on are an internal quantum phase space
called gauge space of fermions, and an internal field space of the Higgs
potential. The logic line is gauge symmetry @xmath SSB. Let us write
down the SM Lagrangian ( B.28 ) explicitly by combining Eq. ( B ) and
Eq. ( B.31 ). This time is not for a particular fermion @xmath only.
There are three generations of fermions in the SM. We will sum up all of
them. Once we do that, there is a new internal space: generation space.
The eigenstates of the fermions in gauge space could be not the
eigenstates of the fermions in generation space which are the physical
mass eigenstates we observe in experiment.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

We collect all of the terms for the fermions after SSB: the kinetic and
QCD terms in Eq. ( B ), the mass and Higgs coupling terms in Eq. ( B.59
) for the leptons and in Eq. ( B.64 ) for the quarks, and the weak CC,
weak NC and electromagnetic terms in Eq. ( B.55 ). We simplify the
notation for a fermion field @xmath as @xmath . The part of the SM
Lagrangian for fermions is given by

  -- -------- -- --------
     @xmath      (B.66)
  -- -------- -- --------

We denote the gauge eigenstate triplets in the generation space as

  -- -------- -- --------
     @xmath      
     @xmath      (B.67)
     @xmath      
  -- -------- -- --------

and denote the rotations from the gauge eigenstates to the mass
eigenstates as unitary matrices @xmath , @xmath , @xmath , @xmath ,
@xmath , and @xmath such that

  -- -- -- --------
           
           (B.68)
           
  -- -- -- --------

Because all of the neutrinos in the SM are massless, they are degenerate
in the mass eigenstates, namely we cannot tell the differences among the
mass eigenstates. We set the rotation for neutrinos as a unit matrix
denoted as @xmath .

First we check the QED part in Eq. ( B.66 ) to see if there is any
change under the rotations,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where we have let @xmath ( @xmath ) pass @xmath forward in Eq. ( B )
because the former rotates in the generation space and the latter is in
the spinor space. Since the unitary rotation matrices give @xmath and
@xmath , the electromagnetic interaction is diagonized in both the gauge
eigenstates and the mass eigenstates.

The same result holds for the Higgs, QCD, and weak NC parts in Eq. (
B.66 ) for the same reason. For the weak NC, this is called the GIM
mechanism [ 47 ] . The flavor changing neutral currents (FCNC), e.g.
@xmath decay “off-diagonal” in the generation space, are strongly
suppressed. On the other hand, the FCNC rare decays are very interesting
because they are possible probes for new interactions.

Now we check the weak CC in Eq. ( B.66 ). For leptons, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where we have let @xmath pass @xmath backward in ( B ). With @xmath
acting backward on the vector of the degenerated neutrino mass
eigenstates, we just go back to the original form, and the leptonic weak
CC interactions are diagonized in both kinds of the eigenstates.

So far, the distinction between the gauge eigenstates and the mass
eigenstates has been seen to have no apparent effect. However, mixing
between generations does manifest itself in the system of the weak CC
for quarks. By convention, the quark mixing is assigned to the down-type
quarks,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where

  -- -------- -- --------
     @xmath      (B.72)
  -- -------- -- --------

Thus the down-type quark gauge states participating in the transitions
of the weak CC are linear combinations of their mass eigenstates. For
three generations, it is called the CKM (Cabibbo-Kobayashi-Maskawa)
matrix [ 5 ] . The SM does not predict the content of @xmath . Rather
its matrix elements must be extracted from experiment.

  -- -------- -- --------
     @xmath      (B.73)
  -- -------- -- --------

Any @xmath complex matrix has 18 paramters. The quark mixing matrix
@xmath , being the product of two unitary matrices, is itself unitary,
@xmath , and this eliminates 9 paramters. The rest of 9 parameters can
be identified with 3 rotation angle, and 6 phase angles with 5 of them
eliminated by rephasing the relative quark phase angles in Eq. ( B.73 )
and leaving 1 global phase angle. So the actual total number of free
parameters is @xmath , which includes 3 rotation angle and 1 phase
angle.

The “standard” parametrization of the CKM matrix advocated in PDG [ 3 ]
is

  -- -------- -- --------
     @xmath      (B.74)
  -- -------- -- --------

In this equation, @xmath and @xmath , with @xmath and @xmath labeling
the generations. The interpretation is that if @xmath vanishes, so does
the mixing between those two generations. For example, in the limit
@xmath , the third generation decouples and it reduces to two
generations with @xmath identified as the Cabibbo angle.

The complex parameter in phase angle goes into the weak charged
interaction terms @xmath , and from quantum theory we know that the
Hamiltonian will not be invariant under time reversal, or equivalently,
CP. So this induces CP violation.

The magnitude of the complex matrix element in the CKM matrix presently
measured is

  -- -------- -- --------
     @xmath      (B.75)
  -- -------- -- --------

Here we discuss some of the immediate consequences. For top quark, with
@xmath , we have

  -- -------- -- --------
     @xmath      (B.76)
  -- -------- -- --------

For bottom quark, with @xmath ten times larger than @xmath , it mostly
decays by @xmath . Then @xmath can decay to @xmath , @xmath , @xmath ,
@xmath , and @xmath with a color factor 3 for each quark decaying mode.
The width of @xmath decays is @xmath . This gives

  -- -------- -- --------
     @xmath      (B.77)
  -- -------- -- --------

So the life time of @xmath is about two and half times longer than the
life time of @xmath because its decay can only happen by the rotation
from the mass eigenstates to the weak eigenstates and the magnitudes of
the matrix elements for this rotation are small.

Couplings to Fermions

For convenience, we repeat Eq. ( B.66 ) here.

  -- -------- -- --------
     @xmath      (B.78)
  -- -------- -- --------

We can read out the couplings to the fermions in the SM as follows:

-   The Higgs coupling for @xmath is @xmath .

-   The QCD coupling for @xmath is @xmath . (For the electroweak
    interactions of the quarks @xmath , the effect of the color charge
    is that the probabilities, i.e., the decay widths are multiplied by
    a constant color factor @xmath , rather than that the couplings
    appearing in the amplitudes are multiplied by the color generator
    @xmath . This is because that @xmath are colorless and the number of
    color combinations of @xmath is fixed to be three.)

-   The electromagnetic coupling for @xmath is @xmath .

-   The neutral weak coupling for @xmath is @xmath for left-handed
    fermions and @xmath for right-handed fermions.

-   The charged weak coupling is @xmath , and this only applies to
    left-handed fermions. We notice that the coupling for @xmath is
    @xmath , while the coupling for @xmath should be multiplied by a
    quark mixing element in the CKM matrix and it becomes @xmath .

These results are summarized in Table 2.4 in Section 2.1 .

## Appendix C How to Calculate Cross Section

We are concerned about the resonance production of tau pairs in the SM
i.e. @xmath . This is a good example to see how event generator [ 9 ] [
53 ] works by using Monte Carlo simulation.

At @xmath collider, the production of any process starts from parton
interaction. A proton is made of quarks and gluons and can be written as

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

The probability density for a given parton @xmath in a proton carrying
momentum fraction @xmath and being “seen” in an interaction by an
intermediate boson with energy scale @xmath is characterized by a
function @xmath , called the Parton Density Function (PDF) [ 22 ] . The
momentum density of a parton is its PDF multiplied by its momentum
fraction and is expressed as @xmath . An example of parametrization is
shown in Fig. C.1 .

The differential cross section for @xmath can be written as

  -- -------- -- -------
     @xmath      (C.2)
  -- -------- -- -------

where @xmath is the parton center-of-mass energy squared, @xmath (
@xmath ) is the momentum (energy) of the @xmath th particle, @xmath are
the fractions of the momenta of the incoming beam particles carried by
the incoming partons, @xmath are the PDF’s with an implicit dependence
on the energy scale of the interaction, and @xmath is the matrix element
squared for the process averaged over the spins and colors of the
incoming particles and summed over the spins and colors of the outgoing
particles.

First we consider the phase space. We perform the integral over the
three-momentum of @xmath , and reexpress the integral over the momentum
of @xmath in terms of the magnitude of the three-momentum @xmath in the
parton center-of-mass frame and the angle with respect to the beam
@xmath and the azimuthal angle @xmath . Then we make a transformation
using @xmath with @xmath the @xmath center-of-mass energy squared and we
get @xmath . After some algebra, the differential cross section becomes

  -- -------- -- -------
     @xmath      (C.3)
  -- -------- -- -------

The angular part can be uniformly generated with @xmath and @xmath . The
momentum fraction @xmath part can be transformed to @xmath and then
uniformly generated. For the distribution over @xmath , we impose a
minimum value of @xmath . There are two types of distributions to be
smoothed in order to converge faster for the Monte Carlo simulation. One
type is a power law distribution @xmath with @xmath which is the rise in
the cross section due to the photon exchange at small center-of-mass
energies. The other type is the Breit-Wigner resonance due to the @xmath
boson exchange with a mass @xmath and a width @xmath ,

  -- -------- -- -------
     @xmath      (C.4)
  -- -------- -- -------

Second we consider the matrix element which is the interesting part.
With a non-constant matrix element, the distribution is expected to
deviate from the pure phase space distribution. Further, compared with
the distributions described by the SM, there are probably deviations in
the distributions in real data due to some unknown matrix elements of
new physics. The effects shown in cross section could be an enhancement
or a suppression, a new resonance, changes in the angular distributions,
a divergence or a cancellation by interference, etc. A good deal of
particle physics consists of the measurements and the interpretations of
such effects in cross section. For the SM process @xmath , we have

  -- -------- -- -------
     @xmath      (C.5)
  -- -------- -- -------

where @xmath , @xmath , @xmath are the masses of the outgoing tau
particles. In the center-of-mass frame using @xmath , the value of
@xmath can be expressed as @xmath , and the value of @xmath can be
expressed as @xmath . The couplings are defined to be

  -- -------- -- -------
     @xmath      (C.6)
  -- -------- -- -------

where the sum runs over @xmath the intermediate gauge bosons with mass
@xmath and width @xmath , and @xmath is the coupling of the gauge boson
to the incoming partons and @xmath is the coupling of the gauge boson to
the outgoing tau particles. The couplings to the fermions in the SM are
listed in Table 2.4 .

To summarize, the major parts for generating an event include: (a)
generating randomly the incoming partons and incorporating the PDF’s,
(b) generating randomly the kinematic variables which describe the event
in the phase space of the final particles, and (c) calculating the
matrix element. Now we can put the parts together and get the weight for
an event by multiplying all of the factors. The weight is in GeV @xmath
and we need to convert to picobarn with a conversion constant @xmath GeV
@xmath pb.

After generating a large sample of events, we can fill the weights of
the events into a histogram, for example, a one-dimensional histogram of
@xmath which is the invariant mass of the tau pairs. The differential
cross section versus the invariant mass of the tau pairs can be obtained
by dividing the histogram by the number of events generated and the size
of the bins. The result is shown in Fig. 2.4 in Section 2.3 .

## Appendix D Separation Angle under Boost

The calculable case is to boost the simplest phase space, i.e. a
two-body decay, from the rest frame to the lab frame, as shown in Fig.
D.1 . The two final particles are back-to-back in the rest frame. The
separation angle @xmath of the two final particles in the lab frame can
be parametrized as a function of @xmath the polar angle in the rest
frame, which has an equal probability to be any value between @xmath and
@xmath , and the boost @xmath .

Let us consider two massless final particles, e.g. two photons from a
@xmath decay with a mass @xmath , an energy @xmath , and a boost @xmath
. We boost the four-momentum of @xmath from the rest frame to the lab
frame,

  -- -------- -- -------
     @xmath      (D.1)
  -- -------- -- -------

We denote the angle between @xmath in the lab frame and the direction of
the boost as @xmath . We have

  -- -------- -- -------
     @xmath      (D.2)
  -- -------- -- -------

We denote the angle between @xmath in the lab frame and the direction of
the boost as @xmath . By substituting @xmath with @xmath , we have

  -- -------- -- -------
     @xmath      (D.3)
  -- -------- -- -------

Now we can calculate the separation angle @xmath ,

  -- -------- -- -------
     @xmath      (D.4)
  -- -------- -- -------

For @xmath not too small and @xmath , we get an approximation for small
@xmath ,

  -- -------- -- -------
     @xmath      (D.5)
  -- -------- -- -------

For fixed @xmath (not too small) values, the functions are shown in Fig.
D.3 . For large boosts, the smearing by @xmath is small, thus the
correlation between the separation angle and the boost (energy) is very
strong.

Since @xmath has an equal probability to be any value between @xmath and
@xmath , the probability that the separation angle stays between the
curve for @xmath and the curve for @xmath is three times larger than the
probability that the separation angle stays between the curve for @xmath
and the curve for @xmath . The effect is very obvious. We use Monte
Carlo simulation to check the same plot, as shown in Fig. D.3 . It
confirms that the simplest case of two-body decay is indeed calculable
and the correlation between the separation angle and the boost (energy)
is very strong.

For the more complicated phase spaces such as those of tau’s hadronic
decays, the calculation is very hard. But Eq. ( D.5 ) is still a good
hint. We need to use Monte Carlo simulation to get the distribution,
which is shown in Fig. 5.4 in Section 5.2.2 .