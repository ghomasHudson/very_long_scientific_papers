# Acknowledgements

I am deeply indebted to my parents, for their unconditional support
throughout every challenge that I have faced in life, and also to
Professor Xavier Gómez-Mont, that rare yet crucial mentor who will go
all the way for a student he believes in.

I am very grateful to my adviser, Professor Andrei Okounkov, for his
generosity at accepting me as his student, for his valuable guidance,
and for sharing his good wisdom with me.

I am grateful to Professor Grigori Olshanski for several enlightening
conversations on the topic of my thesis and for reading this work, and
to Professor John N. Mather for numerous enlightening conversations on
other topics.

I am also grateful to Professor Joseph Kohn, who was my first-year
adviser and gave me an important push toward confidence.

I cannot cease to thank Jill LeClair for significantly lightening my
life and the life of all the graduate students in the department.

The completion of this project would have been impossible without the
continued support of my brothers Diego and Luis, and of many friends,
among whom I want to name especially René Flores, Anand Murugan, Jesús
Puente, Jorge Saavedra, and Péter Varjú. Of great importance too were
the people who prepared me for this endeavor, among whom I want to name
especially my teachers Professor Gonzalo Contreras and Professor Renato
Iturriaga, and my friends Andrés Martínez Arizpe and José Luis Martínez
Meyer.

I also want to acknowledge the generous support of a conacyt -Mexico
fellowship, a scholarship from the Mexican Secretariat of Public
Education ( sep ), and a fellowship from Princeton University.

r.a.r.z.r.z.

Princeton, n.j. , May, 2012

###### Contents

-    Abstract
-    Acknowledgements
-    1 Introduction
    -    1.1 Overview of results
    -    1.2 Plan of the thesis
    -    1.3 Motivation
        -    1.3.1 Quadratic differentials
        -    1.3.2 Examples of quadratic differentials in nature
        -    1.3.3 Moduli spaces
        -    1.3.4 Counting quadratic differentials
        -    1.3.5 The pillowcase orbifold
        -    1.3.6 A special family of covers of the pillowcase
        -    1.3.7 Counting ramified covers of the sphere
        -    1.3.8 Asymptotics of the generating function
-    2 A formula for near-involutions
    -    2.1 2-quotients
    -    2.2 Domino tableaux
        -    2.2.1 The classical case
        -    2.2.2 The case of skew tableaux
    -    2.3 Formula for the dimension of skew diagrams
    -    2.4 Formula for characters of near-involutions
    -    2.5 Quasimodularity of the expectations
-    3 Analysis of the pillowcase distribution
    -    3.1 The limit shape
    -    3.2 Alternative formula of the weights in terms of hooks
    -    3.3 A variational argument
    -    3.4 An application of the Theorem of Meinardus
    -    3.5 Vanishing of the first approximation of the volumes
    -    3.6 Next term
-    A Prerequisites
    -    A.1 Representations of the symmetric group
    -    A.2 Symmetric and shifted-symmetric functions
    -    A.3 The hook formula
    -    A.4 The Murnaghan-Nakayama rule
    -    A.5 The Littlewood-Richardson rule
    -    A.6 The limit shape in the uniform distribution
    -    A.7 The branching rule and Frobenius reciprocity
    -    A.8 The half-infinite wedge Fermionic Fock space
    -    A.9 The Jacobi theta function
    -    A.10 Quasimodular forms
    -    A.11 Ramified covers of a surface

## Chapter 1 Introduction

This is a reformatted version of the author’s dissertation, advised by
Professor Andrei Okounkov, submitted to the Faculty of Princeton
University in candidacy for the degree of Doctor of Philosophy and
defended on August 29, 2012. The results will be published in a
forthcoming paper.

### 1.1 Overview of results

This thesis presents progress in the computation of the volumes of the
moduli spaces of quadratic differentials on Riemann surfaces. As it will
be explained in Section 1.3.2 , quadratic differentials arise in the
study of several dynamical systems, like billiards and interval-exchange
transformations. The problem of finding the volumes of the different
strata of their moduli spaces was solved by A. Eskin and A. Okounkov [ 5
] . This thesis is motivated by the pursuit of a closed formula for
these volumes. Such a formula is not directly available from the methods
described in [ 5 ] .

Our work builds on the program proposed by A. Eskin and A. Okounkov [ 5
] , which we explain in Section 1.3 . We proceed now to give a quick
overview of our results. Most of the objects defined here are motivated
by [ 5 ] . The reader is referred to Appendix A as a reference for the
less standard background material we will use.

A partition of a positive integer @xmath is a decomposition of @xmath as
a sum of positive integers. To each partition @xmath corresponds an
irreducible linear representation of the symmetric group @xmath , with
character @xmath and dimension @xmath .

Denote by @xmath the expression

  -- -------- --
     @xmath
  -- -------- --

where @xmath denotes the conjugacy class of the elements of @xmath with
cycle type @xmath . (The function @xmath arises naturally in the way
explained in Section 1.3.7 .)

The pillowcase weights @xmath were first defined by A. Eskin and A.
Okounkov [ 5 ] , as follows:

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

Here, @xmath denotes the sum of the parts @xmath of the partition @xmath
. For a parameter @xmath , @xmath , the weights @xmath determine a
probability distribution, the pillowcase distribution , on the space of
all partitions @xmath of all the positive integers, after dividing by
the normalization constant

  -- -------- --
     @xmath
  -- -------- --

which they also computed (see Section 2.5 or [ 5 , Section 3.2.4] ). The
volumes of the strata of the moduli space of (disconnected) quadratic
differentials turn out to be given by the dominant term in the @xmath
asymptotics of the expectations @xmath of the functions

  -- -------- --
     @xmath
  -- -------- --

with respect to this distribution (see Section 1.3.4 for details). Here,
the partition @xmath encodes the multiplicities of zeros and poles of
the quadratic differentials in the corresponding stratum.

This thesis investigates the numbers @xmath . Our first contribution is
a fairly explicit formula for @xmath , which we present in Section 2.4 .

We also prove that the expectations of the shifted Schur functions
involved in that formula are quasimodular forms. This is important since
it implies that the precise computation of these expectations is within
our reach. This is done in Section 2.5 .

We then focus in the analysis of the pillowcase distribution. We are
able to prove that it induces a limit shape, which coincides with the
one for the uniform distribution; we explain this in Section 3.1 . Thus
the expectation is multiplicative in its highest degree. However, we
give examples that provide a negative answer to the question of
existence of a full Central Limit Theorem; see Remark 3.6 .

A partition @xmath is said to be balanced if its Young diagram can be
constructed by concatenating two-cell dominoes @xmath . Balanced
partitions are in one-to-one correspondence with pairs of partitions
@xmath with @xmath through the construction of the so-called 2-quotients
(see Section 2.1 ).

The weights @xmath vanish on partitions that are not balanced. In
Section 3.2 , we prove the following appealing formula for the
pillowcase weights on balanced partitions @xmath :

  -- -------- --
     @xmath
  -- -------- --

(for the definition of the hooks lengths , please see Section A.3 ). We
use this formula in Section 3.3 to show that the probability is
concentrated on the set of balanced partitions with 2-quotients composed
of very similar partitions @xmath . This has the consequence, explained
in Section 3.4 , that the first term of the asymptotics of expectations
of the form

  -- -------- --
     @xmath
  -- -------- --

coincide with the first term of the asymptotics of

  -- -------- --
     @xmath
  -- -------- --

From degree considerations (see Remark 3.19 ), it is expected that the
first term in the asymptotics of our formula for @xmath will vanish. In
fact, we are able to show this directly in Section 3.5 using the result
of Section 3.4 . We end with a brief discussion of what the next term
looks like in Section 3.6 .

### 1.2 Plan of the thesis

The rest of this chapter is devoted to explaining the motivations for
this thesis.

Chapter 2 is devoted to the study of the functions @xmath , and Chapter
3 is mainly about the weights @xmath and the distribution they induce on
the space of Young diagrams.

Appendix A describes some mathematical prerequisites.

### 1.3 Motivation

In their paper [ 5 ] , A. Eskin and A. Okounkov propose a method to
compute the volume of the moduli space of quadratic differentials. This
has been the main motivation for our work, so we review their approach
here.

While Sections 1.3.1 and 1.3.3 mainly collect definitions and facts, the
method is explained in Section 1.3.4 , and additional results that make
it work are collected in Sections 1.3.5 through 1.3.7 . Section 1.3.2
gives a couple of examples that aim to frame our study in a broader
context.

#### 1.3.1 Quadratic differentials

##### Abelian differentials.

Let @xmath be a compact Riemann surface with the topology locally
inherited from @xmath . Let @xmath denote the pre-sheaf of holomorphic
1-form germs, which to each open set @xmath assigns the complex vector
space @xmath of one-forms @xmath holomorphic on @xmath . Sections of the
corresponding sheaf @xmath are known as Abelian differentials .

##### Quadratic differentials.

Define a new pre-sheaf @xmath on @xmath by letting @xmath be the complex
vector space of squares @xmath of 1-form germs @xmath . Let @xmath
denote the corresponding sheaf. A quadratic differential on @xmath is a
meromorphic section of @xmath with poles of degree at most one. In other
words, on an atlas @xmath of open sets @xmath covering @xmath with local
coordinates @xmath , a quadratic differential consists of expressions
@xmath on each open set @xmath , where the functions @xmath and @xmath
are connected on @xmath by

  -- -------- --
     @xmath
  -- -------- --

The ordinary product @xmath should not be confused with the
antisymmetric wedge product @xmath .

##### Zeroes and poles.

Together, the zeroes and poles of a quadratic differential are known as
its singular or conic points . Unless it vanishes identically, a
quadratic differential has only finitely many singular points.

From the definition above, it follows that the quotient of two quadratic
differentials is a meromorphic function on @xmath with as many zeroes as
poles (taking their multiplicity into account). It follows that all
quadratic differentials on @xmath have the same number of zeroes and
poles. This should be twice the number of zeroes and poles on a
holomorphic Abelian differential, because a quadratic differential is
locally the square of an Abelian differential. By Riemann-Roch, we know
that an Abelian differential has @xmath zeroes on @xmath , so the
quadratic differentials must have a total of

  -- -------- --
     @xmath
  -- -------- --

counted with multiplicity.

##### Local square roots.

If @xmath does not have a zero or a pole at @xmath then, on a
small-enough neighborhood @xmath of @xmath , @xmath has a square root.
It suffices to take @xmath to be a small open ball where @xmath does not
vanish and remains holomorphic. Let @xmath be a coordinate on @xmath ,
and @xmath be such that @xmath . Then the square root of @xmath on
@xmath looks like

  -- -------- --
     @xmath
  -- -------- --

One has a choice of two different complex square roots of @xmath . This
choice can be done consistently throughout a small-enough neighborhood
of @xmath . Call the resulting form @xmath . Define @xmath to be

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where the integral is taken over any path joining @xmath and @xmath ,
and contained in @xmath ; by Cauchy’s theorem, @xmath is independent of
the chosen path. Since @xmath does not vanish on @xmath , @xmath is
locally injective. Using @xmath as a new coordinate (possibly within a
smaller open set @xmath that still contains @xmath ), we see that @xmath
, so that @xmath .

##### Flat structure and global square root.

The form @xmath induces the structure of a flat surface on @xmath . A
flat surface is a two-dimensional smooth manifold whose transition maps
are given by translations @xmath in @xmath . We can find such
coordinates @xmath and @xmath on @xmath by integrating the real and
imaginary parts of @xmath .

The flat structure cannot in general be extended throughout the set

  -- -------- --
     @xmath
  -- -------- --

it may be necessary to have not only translations, but also their
composition with reflections @xmath , among the transition maps. An
example of this is the pillowcase orbifold; see Section 1.3.5 . On the
other hand, @xmath always has a double cover @xmath where the definition
of @xmath can be extended globally, and filling in the holes in the
obvious way, @xmath can be completed into a ramified degree-two cover
@xmath of @xmath .

Let us show how to construct @xmath . Take an atlas @xmath on @xmath ,
such that each open set @xmath is simply connected, and @xmath is a
coordinate on it. We want to produce a new space gluing copies of the
sets @xmath . On @xmath , write @xmath , and let @xmath and @xmath be
two identical copies of @xmath corresponding to the two branches of the
square root @xmath . The choice of signs @xmath and @xmath on @xmath is
arbitrary, of course, but the resulting construction will not depend on
it. Now form the manifold corresponding to the full atlas @xmath , where
the sets @xmath , @xmath , are glued along the intersections @xmath if
the corresponding branches of the square root coincide on @xmath .
Finally, define @xmath locally on @xmath by letting @xmath or,
equivalently, by defining @xmath locally as in equation ( 1.2 ) and
taking its differential.

##### Flat Riemannian metric.

The form @xmath induces on each open simply-connected set @xmath , along
with the flat structure, a Riemannian metric, locally given by @xmath .
This metric has null curvature throughout @xmath . The same can be said
about its extension to all of @xmath . Moreover, since the metric is
invariant under reflections, it descends to @xmath . Intuitively
speaking, we have thus pushed all the curvature of @xmath to a few conic
points, where all the curvature is concentrated.

##### Horizontal and vertical foliations.

The forms @xmath and @xmath induce two foliations of @xmath . The leafs
are at each point @xmath tangent to the kernel of the respective forms
in the tangent space @xmath . These foliations are also invariant by
local reflections @xmath , so they descend to @xmath . They are known as
the vertical and horizontal foliations , respectively.

If @xmath is a point of @xmath , we can consider the leaves of the
horizontal and vertical foliations that have @xmath in their topological
closure. If the point @xmath is not a conic point, the picture is the
same as for the origin in @xmath : there is one horizontal leaf entering
@xmath from left and right, and there is a vertical leaf, coming from
above and below. As we go around @xmath , they alternate, and we cross
two vertical pieces, and two horizontal pieces.

On a conic point, the situation is slightly different. If we move around
@xmath on a non-self-intersecting closed loop, the leaves corresponding
to the horizontal and vertical foliations again alternate because they
are orthogonal to each other. What changes is the number of them that we
cross. We could cross @xmath pieces of each type, horizontal or
vertical, where @xmath can be any positive integer @xmath . In other
words, the angle around each conic point is no longer @xmath , but can
be @xmath , @xmath , @xmath , @xmath , @xmath ,…, or @xmath in general.

This is related to the degree of the zero or pole of @xmath at @xmath .
If again @xmath locally, and if @xmath can be expanded as a series

  -- -------- --
     @xmath
  -- -------- --

near @xmath , that is, @xmath has a zero of degree @xmath at @xmath ,
then the number @xmath of leaves of the horizontal and vertical
foliations with @xmath in their closure is @xmath . Heuristically, this
is because, @xmath (as above) is locally very much like @xmath , so
@xmath is @xmath (we take @xmath at @xmath ). Now, @xmath on its
‘intersections with the horizontal axis’, and @xmath on its
‘intersections with the vertical axis,’ and in this case the leaves of
the horizontal and vertical foliations play the role of these axes. The
two equations @xmath and @xmath have @xmath solutions each. The
solutions to the first equation correspond to the leaves of the
horizontal foliation emanating from @xmath ; the solutions to the second
one correspond to the vertical foliation.

In polar coordinates centered at the singular point, the metric will
look like

  -- -------- --
     @xmath
  -- -------- --

#### 1.3.2 Examples of quadratic differentials in nature

In this section we mention some research areas in which quadratic
differentials have found applications.

A good overview is given by A. Zorich in [ 39 ] . He includes
applications we will not mention here, like Novikov’s problem on the
dynamics of Fermi surfaces in the study of electronic configurations in
metals.

##### Billiards.

Let @xmath be a polygon in the plane @xmath . Inside it, we define the
billiard flow by having a point-like particle move in straight lines
until it reaches the boundary, at which point it bounces following the
usual rules of optical reflection. This dynamical system is known as a
polygonal billiard . A good introduction to these objects can be found
in [ 21 , 33 ] .

Let @xmath be the group generated by the reflections on the sides of
@xmath . If the size @xmath of this group is finite, @xmath is said to
be a rational billiard . This is equivalent to all the angles of the
polygon @xmath being rational multiples of the number @xmath .

To associate a surface and a quadratic differential with @xmath , we
take @xmath copies @xmath of @xmath , @xmath , and we think of each of
them as being the image of @xmath under the action of a different
element @xmath of @xmath . For each copy @xmath of @xmath and each
reflection @xmath , we glue each edge @xmath of @xmath to the edge
@xmath of @xmath . When @xmath is finite, the result is a compact
Riemann surface @xmath .

The quadratic differential @xmath in each copy @xmath induces a
quadratic differential @xmath on @xmath . It is easy to verify that the
singularities of @xmath are located at the vertices of the different
copies of @xmath . Thus, rational billiards can be seen as a (proper)
subfamily of the moduli space of quadratic differentials.

The application of these ideas is well illustrated by the work of S.
Kerckhoff, H. Masur, and J. Smillie [ 13 ] , in which they prove the
ergodicity of rational billiard flows through the examination of the
situation in the associated surface.

##### Interval exchange transformations.

Let @xmath be an interval in the real line, and decompose it as a
disjoint union of subintervals @xmath , where the indices indicate their
actual order within @xmath . Let @xmath be a permutation. The map @xmath
that scrambles the above decomposition according to @xmath , @xmath , is
an interval exchange transformation .

It turns out that all such objects in fact arise from picking a surface
@xmath , a quadratic differential @xmath on @xmath , a straight segment
@xmath inside @xmath that does not intersect the singularities of @xmath
, and studying the geodesic flow in the direction perpendicular to
@xmath ; the first-return map @xmath is an interval exchange
transformation. The extremes of the intervals in this case are
determined by the orbits that meet a singularity of @xmath and hence do
not return to @xmath .

This connection with the theory of quadratic differentials is fruitful.
A consequence of the work of S. Kerckhoff, H. Masur, and J. Smillie [ 13
] , is that the interval exchange transformations are ergodic [ 39 ] .

#### 1.3.3 Moduli spaces

In this section we define a space that parameterizes all quadratic
differentials on a surface, and we explain some of its properties.

##### Equivalence relation.

We say that two quadratic differentials @xmath and @xmath defined on
Riemann surfaces @xmath and @xmath , respectively, are equivalent if
there is a homomorphism @xmath sending the singular points of @xmath to
the singular points of @xmath of the same order, and having the same
transition functions in neighborhoods of all other points. That is, if
around the point @xmath we have a local coordinate @xmath and @xmath ,
and if around the point @xmath we have a local coordinate @xmath and
@xmath , then @xmath for every @xmath near the point @xmath . This
implies that @xmath is a diffeomorphism on the complement of the
singular points of @xmath , and also that @xmath and @xmath are surfaces
of the same genus.

##### Definition of the moduli space and its strata.

The moduli space of quadratic differentials @xmath is the set of all
equivalence classes of pairs @xmath consisting of a Riemann surface
@xmath of genus @xmath and a quadratic differential @xmath defined on
it.

The space @xmath is naturally stratified by the degree of the quadratic
differentials @xmath at their of singular points. Let @xmath be the
orders of the zeroes ( @xmath ) and poles ( @xmath ) of the quadratic
differential. We allow also @xmath , which stand for marked points. We
will denote by @xmath the stratum of @xmath corresponding to quadratic
differentials @xmath with (ordered) singular points @xmath of degrees
@xmath .

We say that a stratum is self-resolvent if for every @xmath in the
stratum the degree-two cover @xmath of @xmath constructed in Section
1.3.1 is simply a disjoint union of two copies of @xmath . Equivalently,
this means that the square-root of the quadratic differential is defined
globally on @xmath . If this happens for one pair @xmath , then it
happens for all points in the same stratum. For example, taking
square-roots, we see that there is a one-to-one correspondence between
the quadratic differentials represented in the strata @xmath , with
@xmath and @xmath for @xmath , and the Abelian differentials with
singularities of type @xmath , so this stratum is self-resolvent.

##### Dimension and local coordinates.

H. Masur [ 20 ] and W. A. Veech [ 34 ] established the fact that the
spaces @xmath are complex orbifolds of complex dimension @xmath if they
are self-resolvent, and @xmath otherwise.

Local coordinates on @xmath are given as follows [ 14 , 17 ] . Let
@xmath , and let @xmath be the degree-two covering that resolves the
square root of @xmath as explained in Section 1.3.1 . Denote by @xmath
the covering map @xmath and by @xmath the square root of the pullback
@xmath of the quadratic form @xmath . Let @xmath be the inverse image
under @xmath of the set of singular points of @xmath . There is an
involution @xmath that interchanges the fibers of @xmath . Then @xmath ,
and the fixed points of @xmath are a subset of @xmath . Since @xmath can
be written as a closed form @xmath on @xmath (see Section 1.3.1 ), it
defines an element of the relative cohomology group @xmath . The
involution @xmath induces an involution

  -- -------- --
     @xmath
  -- -------- --

which splits the vector space @xmath into a direct sum of two
eigenspaces:

  -- -------- --
     @xmath
  -- -------- --

The class @xmath of the form @xmath belongs to the space of
anti-invariant forms @xmath . A small neighborhood of @xmath inside
@xmath gives a local coordinate chart around @xmath .

Alternatively, one can define the period map @xmath that also gives a
local coordinate [ 22 ] . We will denote by @xmath the elements of the
singular set @xmath of @xmath . Let @xmath be a standard symplectic
basis of @xmath , and complete it to a basis of @xmath by adding paths
@xmath whose boundary is in @xmath and more specifically:

  -- -------- --
     @xmath
  -- -------- --

We record the full period map @xmath that will be used later, and is
defined by

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

The map @xmath is locally injective but is not a local surjection in
general; it maps to a space of very high dimension. To correct this, let
@xmath be the subspace of @xmath on which @xmath acts as multiplication
by @xmath . Choose cycles @xmath that form a basis of @xmath . Then we
let

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

This is the period map.

##### The area-2 slice.

By the Riemann bilinear relations, in the symplectic basis @xmath , …,
@xmath for the homology group @xmath , the area of @xmath induced by
@xmath , which is half the area of @xmath induced by @xmath , is given
by

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

Let @xmath be the slice of the stratum corresponding to pairs @xmath for
which the area induced on @xmath by @xmath equals 2. Note that the last
expression in equation ( 1.5 ) implies that in the coordinates given by
the period map, @xmath is a hyperboloid.

##### The measure.

We want to define a measure @xmath on @xmath . For a set @xmath , let

  -- -------- --
     @xmath
  -- -------- --

be the cone over @xmath . Let @xmath be a closed or open set entirely
contained in the domain of a coordinate chart @xmath . Define

  -- -------- --
     @xmath
  -- -------- --

This defines the measure @xmath . It was proven by H. Masur [ 20 ] and
W. Veech [ 35 ] that the resulting volume @xmath is finite.

##### Classification of the connected components.

The classification of the connected components of the strata @xmath was
given by E. Lanneau [ 16 ] , building on the classification of the
connected components of the strata of the moduli spaces of Abelian
differentials, given by Kontsevich and Zorich [ 15 ] . We summarize the
results. Let @xmath be the genus of the surfaces in the stratum @xmath
in question, and let @xmath be the list of integers @xmath that gives
their singularity data, satisfying @xmath . The hyperelliptic connected
components are the ones that correspond to an entire stratum (with
different singularity data @xmath ); we will list the correspondence
below. We have:

-   If the quadratic differentials in the stratum are self-resolvent [
    15 ] :

    -   If @xmath , there is only one connected component.

    -   If @xmath , the stratum has only one connected component, which
        is hyperelliptic.

    -   If @xmath :

        -   If @xmath or @xmath , the stratum has two connected
            components.

        -   All other strata are connected.

    -   If @xmath :

        -   If @xmath or @xmath for @xmath , the stratum has three
            connected components: a hyperelliptic one, and two others
            corresponding to odd and even spin structures.

        -   If @xmath for @xmath , the stratum has two connected
            components: a hyperelliptic one, and a non-hyperelliptic
            one.

        -   All other strata are connected.

-   If the stratum is not self-resolvent [ 16 ] , all strata that have
    two or more connected components have exactly one hyperelliptic
    component. The picture is the following:

    -   If @xmath , all strata are connected.

    -   If @xmath , all strata are connected, but the strata
        corresponding to @xmath and @xmath are empty.

    -   If @xmath , and if @xmath or @xmath , then the stratum has two
        connected components. All other strata with @xmath are
        connected.

    -   If @xmath , and if @xmath , @xmath , or @xmath , the stratum has
        two connected components. All other strata with @xmath are
        connected.

    -   If @xmath , and if @xmath , the stratum has exactly 2 connected
        components. All other strata with @xmath are connected.

    -   If @xmath :

        -   In the following cases there are exactly two connected
            components:

            -   @xmath , @xmath ,

            -   @xmath , @xmath , and

            -   @xmath , @xmath .

        -   All other strata are connected.

The hyperelliptic components are (by definition [ 17 ] ) precisely the
ones corresponding to the images of the following injective maps:

1.  @xmath , where @xmath , @xmath , @xmath ,

2.  @xmath , where @xmath , @xmath , @xmath ,

3.  @xmath , where @xmath , @xmath , and @xmath .

##### Action of @xmath.

As remarked by H. Masur [ 20 ] and W. A. Veech [ 34 ] , there is an
action of @xmath on any given quadratic differential @xmath on a surface
@xmath , given by

  -- -------- --
     @xmath
  -- -------- --

This preserves the singular points of @xmath and induces an action of
@xmath on the slice @xmath , given by

  -- -------- --
     @xmath
  -- -------- --

The action of the one-parameter subgroup of @xmath whose elements are of
the form

  -- -------- --
     @xmath
  -- -------- --

turns out to be ergodic in each connected component of @xmath . This
means that it preserves the measure defined above, and that invariant
sets that are Lebesgue measurable are of either null or full measure.

#### 1.3.4 Counting quadratic differentials

We now describe the approach of A. Eskin and A. Okounkov [ 5 ] to
finding the volume @xmath .

##### Description of the method.

In Section 1.3.6 , we will define a regular lattice @xmath inside @xmath
. Since the stratum is closed under multiplication by complex scalars,
the situation then becomes very similar to the following: Imagine having
an open cone @xmath . If we were able to count the number of points
@xmath for each @xmath , then the volume of @xmath would simply equal

  -- -------- --
     @xmath
  -- -------- --

The objects forming the lattice @xmath will turn out to be certain
ramified covers of the sphere @xmath . Let us the denote by @xmath the
covers of degree @xmath . By Lemma 1.2 , the area induced by the
quadratic form corresponding to each element of @xmath is equal to
@xmath . The area induced by the quadratic differential whose
coordinates are @xmath is @xmath times the area of @xmath . Thus, when
identified as a lattice inside @xmath , we have

  -- -------- --
     @xmath
  -- -------- --

where @xmath , @xmath . Their count, as we will see in Section 1.3.7 ,
is encoded in the following generating function:

  -- -------- -------- -- -------
     @xmath   @xmath
              @xmath      (1.6)
  -- -------- -------- -- -------

The sum is over all partitions @xmath . In Section 1.3.8 , we will
explain that this generating function is, in fact, a polynomial of
quasimodular forms. Whence the limit

  -- -- -- -------
           (1.7)
  -- -- -- -------

is amenable to computation. One does this by looking at the @xmath (from
below) asymptotics of the generating function ( 1.6 ); this amounts to
letting @xmath . In Section 1.3.8 , we will explain the approach
proposed in [ 5 ] for the understanding of these asymptotics.

##### Technical remarks.

Some additional comments are necessary in order to make the above
argument rigorous. First, the boundary of @xmath is rectifiable; this is
easy to show. Second, in order to prove equation ( 1.7 ), it is better
to work with the image of @xmath . One should observe that it follows
from the proof of the finiteness of the volume in [ 20 , 35 ] that for
every @xmath there is some compact subset @xmath such that @xmath . It
is for cones over these sets @xmath that the above should be done, if
one is to do it carefully, and this is not difficult. This concludes the
justification of the equality ( 1.7 ).

Finally, we remark that this method does not distinguish between the
different connected components of the strata, and applications in
dynamics do require this distinction. However, a quick examination of
the classification given in Section 1.3.3 reveals that it is enough to
know the volumes of the hyperelliptic components, except for finitely
many sporadic cases, whose volumes can be computed using, for example,
the method devised by M. Kontsevich and A. Zorich [ 15 ] , or the one
devised for the case of Abelian differentials by A. Eskin and A.
Okounkov [ 6 ] , which is analogous to what was described in this
section.

#### 1.3.5 The pillowcase orbifold

##### Definition and description.

Let @xmath be a lattice in the complex plane @xmath , @xmath , and let
@xmath be the associated complex torus. The pillowcase orbifold @xmath
is the space obtained by taking the quotient space of @xmath by the
action of the automorphism @xmath .

Although the underlying topological space does not depend on @xmath ,
the complex structure of the pillowcase orbifold does. For our purposes,
however, any lattice that induces area 2 on the orbifold will do. For
simplicity we will assume from here on that @xmath .

The intuitive picture is exactly the one that its name suggests: the
pillowcase orbifold can be obtained by superimposing two identical
squares of side 1 and gluing their sides. More precisely, one can take
the fundamental domain for the action of @xmath given by the rectangle
between the points @xmath , @xmath , @xmath , and @xmath . Here is a
picture.

[]

The action of @xmath will identify the boundary segments as follows:

  -- -------- --
     @xmath
  -- -------- --

In this notation, @xmath denotes the oriented line segment joining
@xmath with @xmath . This fundamental domain is formed by two squares of
side one, divided by the segment @xmath , which we can picture as the
locus where we should fold to obtain @xmath . There are four conic
points on the resulting orbifold, one corresponding to each corner
@xmath , @xmath , @xmath , and @xmath . The angle around each conic
point is @xmath .

##### Covers and global square-roots.

Now consider the covers @xmath of @xmath ramified only at the conic
points of @xmath . One can picture these covers as surfaces built by
gluing squares of side one.

The quadratic differential @xmath that the torus @xmath inherits from
@xmath descends to @xmath , except at the conic points. It can also be
pulled back to the cover @xmath by means of the cover map @xmath . On
@xmath , @xmath has four simple poles located at the conic points.

Locally on @xmath , @xmath has two square roots given by the Abelian
differentials @xmath and @xmath , the pullbacks of the locally-defined
square roots of @xmath on @xmath .

In @xmath it is impossible to find a global (i.e., defined at all points
except the conic ones) square root of @xmath . To see why, note that
taking the fundamental domain described above, it is clear that @xmath
is a well-defined square root of @xmath within the interior of the two
squares of side 1 that constitute the pillowcase. However, as soon as
one tries to go from the square @xmath to the square @xmath by crossing
the side segment @xmath , it becomes clear that the correct continuation
for @xmath would be @xmath on the second square. However, this
contradicts the fact that the right continuation for @xmath when
crossing the segment @xmath is @xmath itself. Using the procedure
described in Section 1.3.3 , we find again the degree-two cover @xmath
where @xmath is well-defined globally.

#### 1.3.6 A special family of covers of the pillowcase

The pillowcase orbifold @xmath , with resolvent cover @xmath , is
homeomorphic to the sphere @xmath . Viewed as such, the map @xmath has
ramification profile @xmath at each of the four conic points.
(Ramification profiles are explained in Section A.11 .)

In a similar vein, we will be interested in certain covers @xmath . We
fix a partition @xmath of an even number into odd parts, a partition
@xmath , and @xmath points @xmath in @xmath . We require the cover to
have profile @xmath over @xmath , and profile @xmath over the other
three conic points of @xmath . Additionally, we require each point
@xmath to have profile @xmath . Denote by @xmath the (discrete) family
of covers @xmath with these properties.

The quadratic differential @xmath on @xmath has zeros of order @xmath on
each one of the preimages of @xmath , and @xmath on one of the preimages
of each @xmath . As in the case of @xmath , a ramification profile of
@xmath over a conic point of @xmath produces no zeros on the quadratic
differential defined on the cover. In other words, @xmath with @xmath ,
so the choices of @xmath and @xmath are obvious, given @xmath : @xmath
corresponds to the odd entries of @xmath , while @xmath corresponds to
the even ones. Simple poles correspond to @xmath .

We remark that specializing the Riemann-Hurwitz formula ( A.10 ) to the
case of @xmath in @xmath , since @xmath , we get

  -- -------- --
     @xmath
  -- -------- --

Note that this does not depend on @xmath , and completely determines the
genus @xmath of @xmath through the relation @xmath .

As explained in Section 1.3.4 , the following lemma is crucial.

###### Lemma 1.1.

The family @xmath forms a regular lattice within the stratum @xmath
where @xmath .

To prove the lemma we will first need another lemma. Given a point
@xmath in the stratum @xmath , denote by @xmath the unique degree-two
cover @xmath of @xmath on which there is a form @xmath that is a
globally defined square root of the pullback of @xmath to @xmath (see
Section 1.3.1 ), and by @xmath the standard torus of area 4. Recall the
period map @xmath and the full period map @xmath were defined in
equations ( 1.4 ) and ( 1.3 ), respectively.

###### Lemma 1.2 (Analogous to [6, Lemma 3.1]).

Let @xmath be a surface of genus @xmath . The first @xmath coordinates
@xmath , @xmath , of the image of a point @xmath under the full period
map @xmath are in the lattice @xmath of complex points with even real
and imaginary parts if, and only if, the following holds:

1.   There exists a holomorphic map @xmath that makes @xmath into a
    ramified cover of @xmath .

2.  @xmath , for @xmath as above.

3.   The ramification points @xmath of @xmath are a subset of @xmath ,
    and they coincide with the set of zeros of @xmath .

4.   The ramification of @xmath around @xmath is locally of the form
    @xmath .

5.  @xmath .

6.   The degree of @xmath is equal to a quarter of the area of @xmath ,
    as defined by equation ( 1.5 ).

###### Proof of Lemma 1.2.

Sufficiency is clear; to prove necessity, define @xmath by

  -- -------- --
     @xmath
  -- -------- --

where @xmath is an arbitrary point. The integral is taken over any path
joining @xmath and @xmath . By Cauchy’s theorem, the result depends only
on the homotopy class of of the chosen path. But since @xmath , @xmath ,
the integral of @xmath along any closed path in @xmath results in a
complex number whose coordinates are even integers, so @xmath is
independent of the chosen path. ∎

###### Proof of Lemma 1.1.

We want to relate the images of @xmath and @xmath . Let @xmath be an
open set entirely contained in a chart of @xmath , that is, such that
@xmath is injective in @xmath , and assume @xmath is closed under the
action of @xmath . It is clear that @xmath is injective on @xmath as
well.

For each cover @xmath in @xmath , the double-covering @xmath satisfies
the hypotheses of Lemma 1.2 , so within @xmath , we have

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

Moreover, if we let @xmath be the projection of @xmath onto its first
@xmath coordinates, then from the definition of @xmath it is clear that

  -- -- --

  -- -- --

Also, the requirement that the ramifications be above the prescribed
points of @xmath ensures that @xmath is also structured as a lattice in
the remaining @xmath complex dimensions.

Going from the images @xmath to the corresponding points @xmath simply
entails finding a matrix @xmath with integral entries such that

  -- -------- --
     @xmath
  -- -------- --

where @xmath and @xmath are as in equations ( 1.4 ) and ( 1.3 ),
respectively. Such a matrix can be found in which the @xmath are
constant throughout @xmath (simply fix in the underlying topological
space of the surface @xmath which is the same throughout all points
@xmath , the generators of the homology groups involved in the
definition of @xmath and @xmath ). Hence there is a linear mapping
taking @xmath to @xmath bijectively. Of course, @xmath is just the image
of the lattice @xmath under the linear transformation @xmath . ∎

#### 1.3.7 Counting ramified covers of the sphere

Consider a cover of the sphere @xmath of degree @xmath , ramified at
points @xmath . For each @xmath , let @xmath be a small
non-self-intersecting loop encircling @xmath only, and intersecting no
other loop @xmath , @xmath . Let @xmath be the monodromy permutation
associated to the loop @xmath (see Section A.11 ). Since the sphere is
simply connected, the sum of the cycles @xmath is homologically
equivalent to the null cycle in @xmath . One deduces that the
composition of monodromy permutations @xmath is in fact equal to the
identity. This is why the following lemma is true.

###### Lemma 1.3.

The ramified covers of the sphere @xmath of degree @xmath are completely
determined, up to isomorphism, by the following data:

-    A finite set of points @xmath .

-    Permutations @xmath such that @xmath .

###### Remark 1.4.

The correspondence is not one-to-one. For instance, by conjugating the
permutations @xmath by an arbitrary permutation @xmath we get another
instance of data determining the same cover. If the cover does not have
nontrivial automorphisms, there are @xmath ways to alter the data
without changing the cover determined by it. On the other hand, if the
cover does have nontrivial automorphisms, there are only @xmath ways to
alter the data.

Let @xmath denote the number of degree @xmath covers @xmath of the
sphere, ramified at @xmath points @xmath , with monodromies @xmath of
cycle type @xmath , respectively, counted with weight @xmath . @xmath is
known as the Hurwitz number for covers of this type.

As @xmath goes to infinity, the number of covers with non-trivial
automorphisms grows much slower than the total number of covers, so the
weights @xmath end up being irrelevant; see [ 6 , Section 3.1] .

###### Proposition 1.5.

  -- -------- --
     @xmath
  -- -------- --

###### Remark 1.6.

Specializing this fomula to the case of @xmath with @xmath for all
@xmath , and assimilating the parts of @xmath into @xmath , we get
exactly formula ( 1.6 ): the ramification over 0 is of type @xmath , and
we have ramifications of type @xmath over the other three conic points
of the pillowcase orbifold @xmath .

###### Proof.

By Lemma 1.3 and Remark 1.4 , @xmath equals the cardinality @xmath of
the set

  -- -------- --
     @xmath
  -- -------- --

divided by @xmath .

Let @xmath be the group algebra of the symmetric group @xmath . Its
center @xmath is known as the class algebra and is generated by the
vectors

  -- -------- --
     @xmath
  -- -------- --

Here, @xmath denotes the conjugacy class of @xmath consisting of all
elements of cycle type @xmath . If we take the product @xmath , we get
precisely the sum of all the different products @xmath of permutations
@xmath with respective cycle types @xmath .

To determine the cardinality of @xmath , we want to count only the
summands that equal the identity. The key observation is that in the
adjoint representation @xmath , the matrices associated to the action of
all other summands have only zeros on the diagonal, since they are
permutation matrices. Hence, the number of summands that equal the
identity is the trace of the operator @xmath divided by the dimension
@xmath of the space @xmath . In other words,

  -- -------- --
     @xmath
  -- -------- --

Recall that @xmath reduces to a direct sum of all the irreducible
representations @xmath of @xmath indexed by partitions @xmath with
@xmath , where each of these representations appears with the same
multiplicity as its dimension (see Section A.1 ):

  -- -------- --
     @xmath
  -- -------- --

Since the operators @xmath commute with the whole algebra, by Schur’s
lemma (see Section A.1 ) we know that they act as scalars in each @xmath
. The actual scalar they represent is computed as follows: The trace of
a scalar matrix @xmath , @xmath , equals @xmath times the dimension of
the space, so we will take the trace and divide by the dimension @xmath
. Since @xmath is the sum of all the elements of the conjugacy class
@xmath , its trace equals the trace of each one of them —namely, the
character @xmath — multiplied by the size @xmath of the conjugacy class.
We conclude that @xmath acts as multiplication by

  -- -------- --
     @xmath
  -- -------- --

within @xmath .

Since the operators @xmath are scalars in @xmath , we can express the
trace as a product, as follows:

  -- -------- -------- --
     @xmath   @xmath
              @xmath
              @xmath
  -- -------- -------- --

Since, as explained above,

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

we are done. ∎

#### 1.3.8 Asymptotics of the generating function

In [ 5 ] , A. Eskin and A. Okounkov treat the generating function ( 1.6
) as the expectation of the function

  -- -- --

  -- -- --

with respect to the probability distribution on the space of young
diagrams @xmath induced by the pillowcase weights

  -- -------- --
     @xmath
  -- -------- --

multiplied by the additional (complex) parameter @xmath , @xmath . This
expectation is exactly the sum ( 1.6 ) divided by a normalization
constant

  -- -------- --
     @xmath
  -- -------- --

that makes the weights @xmath a probability distribution. The sum
defining @xmath is finite for @xmath because @xmath as was proven by S.
Fomin and N. Lulov [ 7 ] . In other words,

  -- -------- --
     @xmath
  -- -------- --

where @xmath denotes the expectation with respect to the distribution
described above.

They prove that the functions @xmath belong to the algebra @xmath
generated by the functions

  -- -------- --
     @xmath
  -- -------- --

and their @xmath -twisted analogs

  -- -------- --
     @xmath
  -- -------- --

where @xmath is defined by

  -- -------- --
     @xmath
  -- -------- --

Finally, they also prove that the expectation of any function in @xmath
with respect to the distribution induced by the weights @xmath is a
quasimodular form (see Section A.10 ).

To do this, they find that the exponential generating function

  -- -------- --
     @xmath
  -- -------- --

can be expressed explicitly in terms of Jacobi theta functions

  -- -------- --
     @xmath
  -- -------- --

(see also Section A.9 ), as follows. We let @xmath ,

  -- -------- --
     @xmath
  -- -------- --

Then @xmath equals

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

(For clarity, we have omitted @xmath in each occurrence of @xmath .) The
brackets indicate that we take the coefficient of @xmath of the
expansion of what is found to the right of them. The series expansion of
this generating function must be taken in the domain

  -- -------- --
     @xmath
  -- -------- --

The rest of their argument is very similar to what we do in Section 2.5
.

With expression ( 1.10 ) at hand, one can plausibly use the modular
transformation of @xmath and integrals on loops surrounding zero to
find, by stationary phase, the coefficients

  -- -------- --
     @xmath
  -- -------- --

from where the expectation @xmath can also be derived, since it is
simply a linear combination of these numbers.

We note that for the shifted power functions @xmath the first term of
the expectation is multiplicative (see Section 3.1 ):

  -- -------- --
     @xmath
  -- -------- --

(Of course, @xmath ; see [ 5 , Section 3.3.5] .) However, the
expectations of the functions @xmath turn out to be quite delicate. They
vanish to first order, the expectation of their products is not
multiplicative, and a simplification reminiscent of Wick’s theorem, that
is, an identity of the kind

  -- -------- --
     @xmath
  -- -------- --

(for functions @xmath , @xmath , @xmath , and @xmath of zero mean) does
not exist, as one learns as soon as one computes

  -- -------- --
     @xmath
  -- -------- --

Here, the symbol @xmath indicates the coefficient of the
fastest-increasing term of each of these as @xmath , and @xmath . (Of
course one does have that @xmath .) These numbers seem to be a
consequence of the lack of normal convergence to the limit shape for the
distribution of the pillowcase weights, which impedes the existence of a
Central Limit Theorem (see Remark 3.6 ). For these reasons, the
possibility of an analysis closely parallel to what was done for the
volumes of the moduli spaces of Abelian differentials by A. Eskin and A.
Okounkov [ 6 ] seems rather unlikely.

## Chapter 2 A formula for the characters of near-involutions

Recall from Section 1.3.4 that we are interested in the asymptotics of
the expectation of

  -- -------- --
     @xmath
  -- -------- --

with respect to the distribution induced by the pillowcase weights. In
this chapter, we intend to prove the following formula

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where the sum is taken over all balanced partitions @xmath of size
@xmath whose Young diagram is completely contained inside the Young
diagram of @xmath , @xmath and @xmath are the 2-quotients of @xmath and
@xmath (to be defined below), and @xmath equals @xmath to the power of
half the number of odd parts in @xmath .

This will follow immediately from formula ( 2.7 ), whose proof we
develop throughout the chapter, and the fact that

  -- -------- --
     @xmath
  -- -------- --

In the final section of the chapter, we prove that the expectations

  -- -------- --
     @xmath
  -- -------- --

are quasimodular forms, which greatly eases their practical computation.

### 2.1 2-quotients

We need to define the @xmath -quotients of a partition and some of their
properties. We mainly follow [ 31 , Excercise 7.59] , [ 19 , Example
I.1.8] .

##### Modified Frobenius coordinates and their geometric interpretation.

Let @xmath be a partition and let @xmath be its modified Frobenius
coordinates ¹ ¹ 1 This use of the term ‘modified Frobenius coordinates’
is non-standard. . If we take @xmath to equal 0 for all @xmath greater
than the number of non-zero parts of @xmath , we can visualize these
coordinates as follows. We rotate the picture of the Young diagram of
@xmath by @xmath counter-clockwise, and we rescale it by @xmath . We
then place black pebbles at each point @xmath on the reversed @xmath
-axis, and white ones in the remaining half-integers. For example, if
@xmath we start with the usual Young diagram,

  -- -------- --
     @xmath
  -- -------- --

and then we rotate to get the following diagram.

[]

In the diagram we have also drawn the rotated axes, which extend to
infinity. The contour @xmath of @xmath is the graph of the continuous
function that describes the piecewise-linear curve starting (in the
picture) with the diagonal axis on the left, running along the top
border (or rim) of the diagram of the partition and ending with the
diagonal axis on the right. It is clear that the contour of @xmath has
slope @xmath wherever there is a white pebble, and has slope @xmath in
the intervals where there is a black pebble. The association of
sequences of pebbles to a Young diagram is known as a Maya diagram .
Observe that in such a diagram there are always as many black pebbles to
the left of zero as there are white pebbles to the right of zero.

If we assign the number 0 to the white pebbles and the number 1 to the
black ones, we get a sequence @xmath , such that @xmath , @xmath for all
@xmath , and @xmath for all @xmath . In the case of the example above
the sequence equals:

  -- -------- --
     @xmath
  -- -------- --

The sequence completely determines the partition @xmath . It coincides
with the sequence one gets if one assigns the number 1 to each vertical
segment and the number 0 to each horizontal segment in the contour, as
follows:

[]

Note that two sequences @xmath and @xmath of zeros and ones with the
above properties determine the same partition if they are translates
@xmath of each other, for some @xmath . Both points of view —Maya
diagrams and binary sequences— are equivalent. In what follows, we will
prefer the language of pebbles placed under the rotated diagram.

##### Pebble operations and their relation to strips and hooks.

Consider how the sequence @xmath changes when one adds a strip of length
@xmath to the rim of the partition. (Strips are defined in Section A.4
.) Adding a strip is equivalent to moving a pebble to the left, and
interchanging it with a white pebble. Here is an example: we add a
7-strip to the Young diagram of the partition @xmath to obtain @xmath ;
compare with the diagram above.

[]

In the picture, the black pebble that was originally located at the site
@xmath has been moved to the site @xmath . The left-most cell of the
strip is always posed on a site that originally had a downward slope
(i.e., a white pebble) and it becomes an upward slope. The right-most
cell of the strip is always posed on a spot with upward slope, and it
turns it into a site with downward slope. All the sites in-between
preserve their original slopes.

It is also easy to identify, given the sequence of pebbles of a
partition, the sites from where it is possible to remove a @xmath
-strip: one only needs to look for a site with a black pebble such that
in the site @xmath units to the right there is a white pebble. In the
example above involving partition @xmath , since we have a black pebble
at the site @xmath , we can remove strips of sizes 2, 5, 6, 7, 8, and 9,
corresponding respectively to the white pebbles at the sites @xmath ,
@xmath , @xmath , @xmath , @xmath , and @xmath .

Note that there is an immediate correspondence between the strips we can
remove and the hooks of the partition. (The hooks and their lengths are
defined in Section A.4 .) Indeed, if instead of joining the left-most
and right-most cells of the strip along the rim, we look at the hook
whose two ends correspond to these two cells, it is easy to see that the
lengths of the hook and the strip are exactly the same. In the following
diagram, we see the same strip as before, and the corresponding hook
shaded in grey.

[]

Both the strip and the hook have length 7.

##### 2-quotients.

Given the sequence of black and white pebbles corresponding to any
partition @xmath , we can split it into two sequences by picking the
sites alternatingly. Namely, we assign to one of them all the pebbles on
the sites @xmath , @xmath , and to the other, the pebbles on the sites
@xmath , @xmath . The resulting sequences determine two partitions
@xmath and @xmath which are together known as the 2-quotient @xmath of
@xmath , and they carry information on how @xmath can be built by
adjoining 2-dominoes @xmath , @xmath and a 2-core, to be defined below.
For example, in the case of the partition @xmath , we split the pebbles
as follows:

[]

and we obtain the following two sequences of black and white pebbles:

[]

(Here, the position of zero has been recorded with a vertical line. It
is off-center in the sense that the number of black pebbles to the left
of it does not equal the number of white pebbles to the right of it. We
will discuss this below.) These in turn correspond to the following
partitions:

  -- -------- --
     @xmath
  -- -------- --

Every time we remove a 2-domino (which is the same as a strip of length
2) from @xmath , we are removing a cell from one of the components
@xmath and @xmath of the 2-quotient. This is because we are exchanging
two pebbles of opposite color which are exactly 2 units apart, and hence
belong in the same component of the 2-quotient.

##### 2-cores.

In the process of removing 2-dominoes, we may get stuck before removing
all the cells in the partition @xmath . The resulting partition is known
as the 2-core and it is always shaped as a staircase, that is, it is of
the form @xmath , @xmath . The following are the first few 2-cores:

  -- -------- --
     @xmath
  -- -------- --

It is easy to see, for example, that the 2-core of the partition @xmath
is @xmath . For instance, we may remove its 2-dominoes in the order
suggested by the following diagram:

  -- -- --

  -- -- --

These moves in turn correspond to the following removals in the
2-quotients:

  -- -------- --
     @xmath
  -- -------- --

In terms of pebble exchanges, the picture is as follows:

[]

As we noted before, the vertical bar denoting the original position of
zero with respect to the sequences of pebbles for @xmath and @xmath is
off-centered; this is just a consequence of the presence of the
non-trivial 2-core @xmath . A larger 2-core produces a larger
translation of the components of the 2-quotient.

##### Balanced partitions.

Recall that a partition is balanced when it can be completely
constructed by adjoining 2-dominoes. Equivalently, a partition is
balanced exactly when its 2-core is empty. This is also equivalent to
the components of the 2-quotient being centered (i.e., having the same
number of black pebbles to the left of zero as white pebbles to the
right of zero). Examples of balanced partitions are @xmath , @xmath ,
and @xmath . As we saw earlier, @xmath and @xmath are not balanced.

It follows from the Murnaghan-Nakayama rule (see Section A.4 ) that the
character @xmath vanishes automatically when @xmath is not balanced.

We record the following important facts about balanced partitions:

###### Lemma 2.1.

Let @xmath be a balanced partition and let @xmath and @xmath be the
components of its 2-quotient. Then

1.  @xmath

2.   The set @xmath equals the set @xmath .

3.   Exactly half of the hook lengths of @xmath are even.

4.   The two pebbles encoding a hook of even length (i.e., the pebbles
    laying at its extremes) are both in the same component @xmath of the
    2-quotient. In the case of a hook of odd length, they are in
    opposite components of the 2-quotient.

All of these points are clear from the description given above.

### 2.2 Domino tableaux

This section contains a few results about shapes made up of 2-dominoes
@xmath that we will need later on.

#### 2.2.1 The classical case

In this section, we prove a classical formula for the characters of
irreducible representations of the symmetric group evaluated at
involutions, that is, elements of cycle type @xmath . Our first
observation is that @xmath vanishes unless @xmath is balanced. This is
because the sum appearing in the Murnaghan-Nakayama rule (see Section
A.4 ) is empty if @xmath cannot be built by adjoining 2-dominoes.

Let @xmath be a balanced partition, @xmath be the number of odd parts of
@xmath , and @xmath . Note that @xmath must be even because @xmath is
balanced so item ( iii ) of Lemma 2.1 holds. Let @xmath be the
2-quotient of @xmath . Then we have

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

We now explain how this is an easy consequence of the Murnaghan-Nakayama
rule (see Section A.4 ). This rule says that

  -- -------- --
     @xmath
  -- -------- --

where the sum is over all ordered 2-domino tilings of @xmath starting at
the origin (i.e., @xmath -strip decompositions), and @xmath denotes the
height of @xmath , as defined in Section A.4 .

First note that all tilings @xmath of @xmath by 2-dominoes have the same
height modulo 2, and it is congruent with @xmath . To see this, observe
the following. The 2-dominoes placed horizontally have height 0, so they
are irrelevant. On the other hand, the length of each row of the Young
diagram of @xmath is congruent modulo 2 to the number of
vertically-placed dominoes it intersects. Since each of these vertical
dominoes spans two rows, we see that the number of vertical dominoes is
congruent to @xmath modulo 2, so the height is as well. This determines
the sign @xmath of the value of the character @xmath .

To count the tilings @xmath , observe that their construction is
equivalent to constructing the components @xmath and @xmath of the
2-quotient, one cell at a time. An obvious consequence of the
Murghan-Nakayama rule for @xmath is that there are @xmath ways to
construct @xmath one-cell at a time, and similarly there are @xmath ways
to construct @xmath . Among the total @xmath cells that should be added,
we have to decide in which order we will introduce the ones for @xmath
and the ones for @xmath . The count of their ‘internal ordering’ will be
taken care of by @xmath and @xmath , but we get a binomial factor
corresponding to the number of choices we have for assigning, among the
total @xmath turns, those that correspond to cells of @xmath (and the
rest will be for cells of @xmath ):

  -- -------- --
     @xmath
  -- -------- --

For the last equality, we have used item ( i ) of Lemma 2.1 . Thus the
total number of 2-dominio tilings of @xmath is

  -- -------- --
     @xmath
  -- -------- --

This finishes the proof of formula ( 2.2 ).

Note that, using the fact that @xmath and @xmath are given by the hook
formula ( A.3 ), together with item ( ii ) of Lemma 2.1 , we get

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

#### 2.2.2 The case of skew tableaux

We will need a slight generalization of formula ( 2.2 ). We let @xmath
and @xmath be two partitions, such that the Young diagram of @xmath is
contained inside the diagram of @xmath , and we denote by @xmath the
associated skew diagram; see Section A.4 for an example.

We define the character @xmath to be the obvious generalization of the
Murnaghan-Nakayama rule to this case. Namely, we define an @xmath -strip
decomposition of @xmath to be a sequence of partitions @xmath such that
@xmath is a strip of length @xmath , @xmath . The height of an @xmath
-decomposition of @xmath is the sum of the heights of the strips @xmath
, @xmath . Finally,

  -- -------- --
     @xmath
  -- -------- --

where the sum is taken over all @xmath -decompositions @xmath of @xmath
.

Let @xmath and @xmath be balanced and let @xmath and @xmath be their
2-quotients. We define the 2-quotient of @xmath to be the pair of skew
diagrams @xmath .

We can define the dimension @xmath to be the value of @xmath . Then
practically the same proof as for ( 2.2 ) shows that

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

This formula is still valid for non-balanced partitions @xmath and
@xmath , with the caveat that the character @xmath vanishes when the
2-core of @xmath is different from the 2-core of @xmath .

### 2.3 Formula for the dimension of skew diagrams

In this section we will state and prove a formula due to A. Okounkov and
G. Olshanski [ 26 ] for the dimension @xmath of a skew diagram. We
follow their exposition.

Let

  -- -------- --
     @xmath
  -- -------- --

We first define the shifted Schur polynomials in @xmath variables,
indexed by the partition @xmath , as the following ratio of two @xmath
determinants:

  -- -------- --
     @xmath
  -- -------- --

These polynomials satisfy [ 26 ] a stability condition

  -- -------- --
     @xmath
  -- -------- --

which allows us to take inverse limits, just as in the definition of
symmetric functions (see Section A.2 ). The resulting objects are known
as shifted Schur functions and we will denote them by @xmath . These are
also sometimes called Frobenius Schur functions (see for example [ 29 ]
). The algebra @xmath they generate coincides with the algebra generated
by the shifted-symmetric power functions @xmath .

We want to prove the following relation [ 26 ] :

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

We choose to reproduce the second proof of ( 2.5 ) given in [ 26 ]
because it is more self-contained and elementary than the two others.
Let @xmath and @xmath . We have, by the branching rule, orthonormality
of the characters, and Frobenius reciprocity (see Section A.7 ),

  -- -------- --
     @xmath
  -- -------- --

The characteristic map @xmath , defined in [ 19 , Section I.7] , assigns
to each character of the symmetric group (of any order) a symmetric
function. It is defined, for a character @xmath of @xmath , by

  -- -------- --
     @xmath
  -- -------- --

where @xmath is the symmetric power function, the product of several
instances of @xmath . In this correspondence, @xmath is the
(traditional) symmetric Schur function. On the other hand, the induction
of @xmath to @xmath equals the induction of @xmath (i.e., the character
of the product of the representation indexed by @xmath and the character
of the 1-dimensional identity representation) from @xmath to @xmath . It
is a property of @xmath that

  -- -------- --
     @xmath
  -- -------- --

After @xmath similar steps, we get

  -- -------- --
     @xmath
  -- -------- --

Taking the canonical inner product in the algebra of symmetric
functions, defined by

  -- -------- --
     @xmath
  -- -------- --

the map @xmath turns out to be an isometry, so that

  -- -------- --
     @xmath
  -- -------- --

If we restrict the symmetric functions to @xmath variables, we see by
looking at the definition of @xmath (see Section A.2 ) that we are
simply looking for the coefficient of

  -- -------- --
     @xmath
  -- -------- --

in the expansion of

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

By expanding ( 2.6 ), we can rewrite it as

  -- -------- --
     @xmath
  -- -------- --

The coefficient we need is then

  -- -------- -------- --
     @xmath   @xmath
              @xmath
              @xmath
              @xmath
              @xmath
              @xmath
  -- -------- -------- --

Here we used the definition of @xmath and formula ( A.4 ) for @xmath .
This completes the proof of formula ( 2.5 ).

### 2.4 Formula for characters of near-involutions

Let @xmath and @xmath be balanced partitions such that the Young diagram
of @xmath is completely contained inside @xmath . We want to prove the
following relation:

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

where the sum is taken over all balanced partitions @xmath of size
@xmath whose Young diagram is completely contained in the Young diagram
of @xmath , @xmath and @xmath are the 2-quotients of @xmath and @xmath ,
respectively, and @xmath is defined as in Section 2.2.1 .

To prove equation ( 2.7 ), we first observe that the Murnaghan-Nakayama
rule (see Section A.4 ) implies that

  -- -------- --
     @xmath
  -- -------- --

The sum is over all partitions @xmath of size @xmath whose diagram is
completely contained inside the diagram of @xmath . Clearly, @xmath
vanishes unless @xmath is balanced, so all sums from this point on will
be over balanced partitions @xmath of size @xmath . To this expression
we apply formula ( 2.4 ), and we apply formula ( 2.2 ) to the
denominator, to get

  -- -------- --
     @xmath
  -- -------- --

Here, @xmath and @xmath are the 2-quotients of @xmath and @xmath ,
respectively, and

  -- -------- --
     @xmath
  -- -------- --

Now we can apply formula ( 2.5 ) to each of the quotients of dimensions,
and we get exactly formula ( 2.7 ) because, by item ( i ) of Lemma 2.1 ,

  -- -------- --
     @xmath
  -- -------- --

### 2.5 Quasimodularity of the expectations of shifted symmetric
functions on the 2-quotients

In order for formula ( 2.1 ) to be useful, we must prove that there is a
reasonable way to compute the expectations of the terms involved. In
this section we prove, in close parallel to the work of A. Eskin and A.
Okounkov [ 5 ] , that the expectations

  -- -------- --
     @xmath
  -- -------- --

are quasimodular forms. Here, the expectation is defined by

  -- -------- --
     @xmath
  -- -------- --

where sum is taken over all balanced partitions, @xmath is the
2-quotient of @xmath , and

  -- -------- --
     @xmath
  -- -------- --

It was proven by A. Okounkov and G. Olshanski [ 26 ] that the algebra
generated by the shifted Schur functions @xmath coincides with the
algebra generated by the shifted power functions @xmath , whose
definition we recall: for a positive integer @xmath ,

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

where @xmath denotes the Riemann zeta function. For general partitions
@xmath , the definition of @xmath is

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

So it is enough to prove that the expectations of the form

  -- -------- --
     @xmath
  -- -------- --

are quasimodular forms.

To do this, we will first look at the exponential generating function of
these expectations, and then we will analyze this generating function.

We consider first the @xmath -point function,

  -- -------- --
     @xmath
  -- -------- --

where the last sum is taken over all balanced partitions @xmath with
2-quotient @xmath such that

  -- -------- --
     @xmath
  -- -------- --

and

  -- -------- --
     @xmath
  -- -------- --

Letting @xmath and @xmath be defined by @xmath and @xmath , it is easy
to verify that

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

This follows from the fact that the exponential generating function for
the shifted power functions @xmath is (cf. [ 3 , eq. (0.18)] , [ 6 , eq.
(2.8)] )

  -- -------- --
     @xmath
  -- -------- --

and we apply this identity separately for @xmath and for @xmath . This
identity is true for @xmath with positive real part; this must be taken
into account when computing series expansions.

We define the Jacobi theta function by

  -- -------- --
     @xmath
  -- -------- --

(See Section A.9 for a discussion.)

###### Lemma 2.2.

The @xmath -point function is given by

  -- -------- --
     @xmath
  -- -------- --

where the sum is taken over all functions

  -- -------- --
     @xmath
  -- -------- --

and

  -- -------- --
     @xmath
  -- -------- --

is the number of points at which these functions equal @xmath . The
expansion is valid in the domain

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

In the context of the Fock space representation @xmath (see Section A.8
for definitions and notations), we consider the vertex operator

  -- -------- --
     @xmath
  -- -------- --

In the paper [ 5 ] , @xmath is called the pillowcase operator because we
have

###### Theorem 2.3 ([5, Theorem 4]).

The diagonal matrix elements of @xmath are as follows:

  -- -------- --
     @xmath
  -- -------- --

We omit the proof of this theorem. The form of @xmath was probably
guessed using the tools developed by A. Okounkov and N. Reshetikhin [ 28
, Section 2.2.6] .

We define the operators

  -- -------- --
     @xmath
  -- -------- --

and

  -- -------- --
     @xmath
  -- -------- --

Note that, if @xmath is the 2-quotient of the partition @xmath ,

  -- -------- --
     @xmath
  -- -------- --

where @xmath stands for the operation of expanding the series with
respect to @xmath and @xmath and finding the coefficient of @xmath .
Similarly,

  -- -------- --
     @xmath
  -- -------- --

Define @xmath . Then @xmath can be expressed as the following trace in
@xmath :

  -- -------- --
     @xmath
  -- -------- --

In terms of the usual operators

  -- -------- --
     @xmath
  -- -------- --

we have

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

Thus @xmath is a sum of terms of the form

  -- -------- --
     @xmath
  -- -------- --

where

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

@xmath , and @xmath is the number of them that equals @xmath . From the
boson-fermion correspondence, we have the following formula [ 11 ,
Theorem 14.10] :

  -- -------- --
     @xmath
  -- -------- --

Note that the factor @xmath at the front can be checked comparing the
coefficients of the vacuum vector @xmath on both sides of the identity
when the operator is applied to @xmath . Adjusting the signs of @xmath
and @xmath , we have all products @xmath and @xmath covered with this
formula.

Now, these operators factor through the decomposition

  -- -------- --
     @xmath
  -- -------- --

and in each of these factors we have, for all @xmath ,

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

This identity can be easily checked directly by expanding both sides. In
our case,

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

We take the product of ( 2.11 ) for all @xmath , and expand the series
of the factor @xmath in the exponent of the right hand side of equation
( 2.11 ). Then we exchange the order of summation, and use the series

  -- -------- --
     @xmath
  -- -------- --

together with the definition of the theta function @xmath (see Section
A.9 ) and the formula [ 5 , Section 3.2.4]

  -- -------- --
     @xmath
  -- -------- --

to get the result of the statement of the lemma.

The domain of the expansion is justified in the same way as in [ 5 ,
Section 3.2.3] : we have the estimate

  -- -------- --
     @xmath
  -- -------- --

so the trace converges in the given domain. ∎

We proceed to complete the proof of the quasimodularity of the
coefficients of the generating function @xmath .

In order to obtain the coefficient of @xmath in the formula for @xmath
given in Lemma 2.2 , we want to take the integral

  -- -------- --
     @xmath
  -- -------- --

To do this we introduce variables @xmath and @xmath , which changes the
domain of integration to the interval @xmath on each of the variables.
Then we plug in the identities

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

where @xmath is the Dedekind eta function

  -- -------- --
     @xmath
  -- -------- --

and @xmath are the Eisentstein series

  -- -------- --
     @xmath
  -- -------- --

into the formula of Lemma 2.2 . These identities are easy to check
directly. Finally, we expand the series with respect to the variables
@xmath and we integrate term by term.

What we get in the end is a series in the variables @xmath and @xmath
whose coefficients are polynomials in the Eisenstein series @xmath .
This means that the coefficients are quasimodular forms (see Section
A.10 ). Since this series is precisely the generating function ( 2.10 ),
we are done.

## Chapter 3 Analysis of the pillowcase distribution

In this chapter, we first find the limit shape induced by the pillowcase
distribution and we analyze whether convergence is normal. This is the
content of Section 3.1 .

Then, we prove that the pillowcase distribution concentrates most of its
measure near the partitions that have very similar 2-quotients. This
requires us first to find an alternative formula for @xmath in terms of
hooks; we do this in Section 3.2 . Then we do a variational argument in
Section 3.3 to obtain asymptotics for @xmath . We show in Section 3.4
that the @xmath -probability of the set of partitions whose 2-quotients
significantly differ vanishes asymptotically.

Finally, as an application of these results, in Sections 3.5 and 3.6 we
analyze the first terms of the asymptotics of the expectation of @xmath
arising from formula ( 2.1 ).

### 3.1 The limit shape

In this section we argue that the limit shape induced by the pillowcase
weights coincides with the limit shape induced by the uniform
distribution (see Section A.6 ). We will also make some comments on the
multiplicativity of the mean, and on the possibility of a Central Limit
Theorem, at the end of this section.

##### Moments of the limit shape.

Let @xmath be a non-increasing continuous function such that

  -- -------- --
     @xmath
  -- -------- --

Let @xmath , @xmath , be a sequence of partitions such that @xmath as
@xmath . We say that @xmath converges to @xmath if

  -- -------- --
     @xmath
  -- -------- --

Let @xmath be the contour of @xmath ; this was defined in Section 2.1 .
Let @xmath be the function whose graph corresponds to the graph of
@xmath rotated @xmath in the counter-clockwise direction (or @xmath if
we think of @xmath drawn upside down, resembling a very large
partition). Then if @xmath converge to @xmath , we also have that @xmath
converge to @xmath in the topology of the supremum norm.

Recall that the shifted power functions @xmath were defined in equation
( 2.8 ). We want to give an interpretation of them as moments of the
contours. From the definition of @xmath it is clear that as @xmath ,

  -- -- --

  -- -- --

Now,

  -- -------- -------- --
     @xmath   @xmath
              @xmath
              @xmath
  -- -------- -------- --

where @xmath and @xmath . The change of variables is done as per the
following diagram, in which the curve @xmath depicts both the graph of
@xmath and the graph of @xmath , and the integration domain is shaded in
gray.

[]

In other words, if we consider @xmath as a density with moments @xmath ,
then

  -- -------- --
     @xmath
  -- -------- --

##### Candidate for the limit shape.

In order to determine what the candidate for the limit shape is, we will
show that, in the @xmath limit, the expectations of the shifted power
functions

  -- -------- --
     @xmath
  -- -------- --

coincide with those of the uniform distribution. The functions @xmath
play the role of the moments of the limit shape, and because these
moments @xmath do not grow very fast, they in fact determine it
uniquely. A sufficient condition for this to be the case (see for
example [ 2 , Chapter 30] ) is that

  -- -------- --
     @xmath
  -- -------- --

which is true in this case.

In the case of the uniform distribution, in which the weight of the
partition @xmath is @xmath , the rescaled limit of the exponential
generating function of the numbers @xmath is

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath , @xmath , and @xmath means “up to exponentially small
terms”; compare with formula ( 2.10 ). To prove that this is true, note
that (in the notations of Sections A.8 and 2.5 , and using similar
techniques)

  -- -------- --
     @xmath
  -- -------- --

Here, @xmath stands for the Jacobi theta function, whose defintion we
recall:

  -- -------- --
     @xmath
  -- -------- --

(see also Section A.9 ). Thus the approximation ( 3.1 ) follows from

###### Lemma 3.1 ([6, Proposition 4.1]).

We have

  -- -------- --
     @xmath
  -- -------- --

as @xmath uniformly in @xmath . This asymptotic relation can be
differentiated any number of times.

###### Proof.

We have

  -- -------- --
     @xmath
  -- -------- --

so, expanding the series of @xmath ,

  -- -------- --
     @xmath
  -- -------- --

From here it is clear that as @xmath the terms @xmath and @xmath
dominate all others. ∎

We will show that we have the same result ( 3.1 ) holds for the rescaled
limit of the exponential generating function of the numbers @xmath ,
that is, in the case of the pillowcase weights.

Recall the formula of A. Okounkov and A. Eskin [ 5 , Theorem 5] for the
1-point function,

  -- -------- --
     @xmath
  -- -------- --

Here @xmath means that we expand the series in the variable @xmath and
then we take the constant coefficient.

Since (in the conventional notations which are recalled in Section A.9
),

  -- -------- --
     @xmath
  -- -------- --

where @xmath , @xmath , and @xmath stands for the Dedekind eta function,
the following lemma about @xmath is relevant.

###### Lemma 3.2.

We have the following identities and approximations for @xmath at @xmath
and @xmath , respectively:

  -- -------- -------- --
     @xmath   @xmath
              @xmath
     @xmath   @xmath
              @xmath
  -- -------- -------- --

where @xmath stands for the integer closest to @xmath , @xmath , and
@xmath means “up to exponentially small terms.”

###### Proof.

This is a straightforward application of the modular transformation; see
Section A.9 . We also use the identity

  -- -------- --
     @xmath
  -- -------- --

In order to obtain the coefficient of @xmath , we take the integral

  -- -------- --
     @xmath
  -- -------- --

Letting @xmath , @xmath , and @xmath , and using the approximations in
Lemma 3.2 , this becomes

  -- -------- --
     @xmath
  -- -------- --

This integral can be performed by appropriately partitioning the domain
to reflect the discontinuities inherited from the functions @xmath and
@xmath . The result is

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

Since we are interested in the expansion with respect to @xmath of
@xmath , for @xmath and @xmath , the result of equation ( 3.2 ) becomes
@xmath as @xmath . Thus

  -- -------- --
     @xmath
  -- -------- --

Since this is precisely equivalent to ( 3.1 ), this establishes the
question of a candidate for the limit shape, which is settled to equal
the one corresponding to the uniform distribution. Also, from here we
know the top-degree terms of the expectations (up to a factor due to the
choice of scaling of the limit shape) are

  -- -------- --
     @xmath
  -- -------- --

##### Multiplicativity of the expectation.

To establish this property, we need a preliminary result. Recall the
definition of the @xmath -point function,

  -- -------- --
     @xmath
  -- -------- --

where @xmath denotes the set of partitions @xmath such that the numbers
@xmath are all contained in the set of modified Frobenius coordinates
@xmath of @xmath , and @xmath is the normalization constant. For the
same reasons as explained in Section 2.5 , the @xmath -point function
encodes the expectations of products of shifted symmetric power
functions. Whence our interest in its asymptotics:

###### Proposition 3.3.

The highest degree term of the exponential generating function @xmath of
the expectations @xmath of products of shifted-symmetric power functions
is

  -- -------- --
     @xmath
  -- -------- --

as @xmath .

###### Proof.

We consider A. Okounkov and A. Eskin’s formula for the @xmath -point
function,

  -- -------- --
     @xmath
  -- -------- --

We want to show that the factors of the form

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

are of order @xmath as @xmath . Then the same argument as we used before
for the 1-point function will complete the proof. We apply the
approximation of Lemma 3.1 to each factor of the crossterm ( 3.3 ).
Letting @xmath and @xmath , we get

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

We will show that the quotient of sines is approximately equal to 1 for
small, suitable @xmath .

We assume that @xmath is very close to the imaginary axis and is in the
first quadrant in @xmath (i.e., @xmath ), and that @xmath are such that
the determinants @xmath , @xmath , @xmath , @xmath are positive. Here,

  -- -------- --
     @xmath
  -- -------- --

As @xmath ,

  -- -------- --
     @xmath
  -- -------- --

so the quotient of sines behaves as

  -- -------- --
     @xmath
  -- -------- --

So only the exponential term in ( 3.4 ) counts. Since we really are
interested in the limiting behavior of @xmath , the correct form of the
term is

  -- -------- --
     @xmath
  -- -------- --

as @xmath , and we are done. ∎

It follows from the following proposition and from the estimate [ 5 ,
Section 3.3.5]

  -- -------- --
     @xmath
  -- -------- --

that

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

In other words, the top-degree term of these expectations is
multiplicative.

###### Remark 3.4.

This is only possible if the limiting measure is completely concentrated
at the limit shape candidate proposed above. Indeed, this means that for
any function @xmath in the algebra generated by the functions @xmath ,

  -- -------- --
     @xmath
  -- -------- --

(Here, @xmath refers to the grading that assigns @xmath .) The variance
vanishes, so the limiting measure must be a Dirac delta supported at the
limit shape.

###### Remark 3.5.

This is optimal: the multiplicativity does not go beyond the highest
degree term. Already in the case of products of @xmath we have ¹ ¹ 1
These numbers were obtained by finding the decomposition of the
corresponding series as a polynomial of Eisenstein series, through the
direct computation of the first few terms.

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

Here, “e.s.t.” stands for “exponentially small terms.”

###### Remark 3.6.

As another consequence of the asymptotic expansions above, we have no
hope of getting a full Central Limit Theorem for this regime, because
this would imply Wick’s theorem. Wick’s theorem characterizes Gaussian
probability distributions with mean zero; see for example [ 38 , Section
1.2] . In our case, it would contain the statement that

  -- -------- --
     @xmath
  -- -------- --

for all @xmath , @xmath , @xmath , and @xmath in the algebra generated
by the functions @xmath with vanishing @xmath -mean. In particular,
setting @xmath , this means that we would need to have

  -- -------- --
     @xmath
  -- -------- --

but instead we get

  -- -------- --
     @xmath
  -- -------- --

So there is no such theorem, and hence the convergence to the limit
shape is not normal.

Figuring out what the next terms are in the expansions of the
expectations of products of shifted power functions @xmath is left for
future work.

### 3.2 Alternative formula of the weights in terms of hooks

In this section, we will prove that

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

for @xmath balanced, and @xmath for all other @xmath .

Let @xmath be a balanced partition with 2-quotient @xmath . Recall that

  -- -------- -------- -- -------
     @xmath   @xmath
              @xmath      (3.7)
  -- -------- -------- -- -------

Now,

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

and, by formulas ( 2.2 ) and ( 2.3 ),

  -- -------- -------- --
     @xmath   @xmath
              @xmath
  -- -------- -------- --

By items ( i ) and ( iii ) of Lemma 2.1 , this equals

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

On the other hand, by the hook formula ( A.3 ), we have that

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

Since

  -- -------- --
     @xmath
  -- -------- --

plugging ( 3.8 ), ( 3.9 ), and ( 3.10 ) into ( 3.7 ), we get formula (
3.6 ).

On the other hand, as was remarked in Section 2.1 , if @xmath is not
balanced, it is impossible to decompose @xmath into a 2-domino tiling.
By the Murnaghan-Nakayama rule (see Section A.4 ) this implies that
@xmath vanishes when @xmath is not balanced, whence also @xmath in this
case.

### 3.3 A variational argument

In order to deduce the asymptotic behavior of the pillowcase weights
@xmath , we will use a variational argument resembling the idea that S.
Kerov and A. Vershik [ 37 ] and B. Logan and L. Shepp [ 18 ] used in the
analysis of the Plancherel distribution.

The idea is that we can approximate the logarithm of products of hooks
by an integral, whence we can exploit the form of formula ( 3.6 ).

For a non-increasing function @xmath , define

  -- -------- --
     @xmath
  -- -------- --

and

  -- -------- --
     @xmath
  -- -------- --

which gives an approximation of the hook length at @xmath . Let @xmath
be a balanced partition, and @xmath . We contract its diagram until it
has area 1, rescaling by @xmath , and we associate to it a function
@xmath that describes its rim,

  -- -------- --
     @xmath
  -- -------- --

In the following diagram, we have the example of @xmath .

[]

In the picture, we have inverted the orientation of the @xmath axis to
reflect the usual orientation of our Young diagrams, and we have drawn
the parts of the rim of @xmath that are described by @xmath with a solid
line, while the parts that correspond do @xmath are drawn with dashed
lines. The numbers on the axes reflect the rescaling by @xmath . We have
also highlighted the hook corresponding to the cell @xmath . We will
approximate the logarithm of its length by

  -- -------- --
     @xmath
  -- -------- --

where @xmath is the rectangle between the points @xmath and @xmath . To
motivate this approximation, we have drawn, at the center of the cell
@xmath , the point @xmath and an inverted L ending extending to the
rescaled rim of @xmath ; the length of this L is precisely @xmath : its
vertical part measures @xmath , while its horizontal part measures
@xmath . Then @xmath coincides with the length of the hook of cell
@xmath , and the integral above is very close to this number as well. In
general, we have

###### Lemma 3.7.

Let @xmath be a partition and let @xmath be a cell in its Young diagram,
and denote by @xmath the non-increasing function that describes the rim
of the Young diagram of @xmath , as defined above. Let @xmath be the
rectangular domain corresponding to @xmath . Let @xmath denote the hook
length of @xmath . Then

  -- -------- --
     @xmath
  -- -------- --

where

  -- -------- --
     @xmath
  -- -------- --

###### Remark 3.8.

The function @xmath is strictly decreasing in the interval @xmath . It
remains between @xmath and

  -- -------- --
     @xmath
  -- -------- --

This implies that the approximation of the logarithm of a product of any
@xmath hook lengths using the integral of @xmath will have an error of
order @xmath . This estimate can be improved in the large-scale case;
see Lemma 3.9 .

###### Proof.

Let @xmath be the point at the center of @xmath . Recall that the area
of @xmath is @xmath . Then

  -- -------- -------- --
     @xmath   @xmath
              @xmath
              @xmath
  -- -------- -------- --

where @xmath and @xmath . Now expand the Taylor series of the logarithm
and integrate term by term. ∎

###### Lemma 3.9.

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

We have

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Since @xmath is decreasing and @xmath very quickly as @xmath , the worst
case scenario is the case in which we maximize the number of small odd
hook lengths @xmath . This happens in the case of the staircase
partition @xmath . This partition is not balanced, but it is the worst
possible case. In the case of the staircase, it is obvious that the
right hand side of ( 3.11 ) is of order @xmath . ∎

Since we want to approximate the logarithm of the quotient ( 3.6 ), we
need to distinguish the domains @xmath and @xmath corresponding to the
cells whose hooks are of odd and even length, respectively. For example,
in the following diagram we have shaded in grey the domain @xmath in the
case of @xmath ; @xmath would be the remaining white area inside the
rescaled Young diagram.

[]

Then by formula ( 3.6 ) and Lemma 3.7 ,

  -- -------- --
     @xmath
  -- -------- --

By item ( iii ) of Lemma 2.1 , the area of @xmath is the same as the
area of @xmath , so the contributions of @xmath cancel out and we are
left with

  -- -------- --
     @xmath
  -- -------- --

The domains @xmath and @xmath can be very complicated, but in the case
of balanced partitions we can exploit item ( iv ) of Lemma 2.1 as
follows.

First, rotate the domain @xmath and let @xmath be the continuous
function that gives the rim of the rotated domain, as in the following
diagram:

[]

Note that @xmath where it is defined, and @xmath for @xmath large
enough. Denote by @xmath and @xmath the rotated versions of @xmath and
@xmath .

It is now convenient to change variables to @xmath and @xmath such that
@xmath and @xmath . To explain how this change of variables works we
have the following diagram.

[]

In the diagram, the point @xmath is at the center, and through it pass
two diagonals of lengths @xmath and @xmath intersecting the diagonal
axes at coordinates @xmath and @xmath , respectively. From their
intersections with the rim of the rotated Young diagram, we have
vertical segments of lengths @xmath and and @xmath . From the diagram it
is also clear that @xmath , and that our integration domains @xmath and
@xmath will be subsets of @xmath . The transform @xmath is not
bijective, but it is surjective, and it is injective in the region in
which its Jacobian is nonzero. The determinant of its Jacobian is

  -- -------- --
     @xmath
  -- -------- --

which is supported in a compact set because @xmath for large @xmath . If
we denote by @xmath and @xmath the images of @xmath and @xmath under
this change of variables, our integral becomes:

  -- -------- --
     @xmath
  -- -------- --

Let @xmath be the 2-quotient of @xmath , and let @xmath and @xmath be
the functions describing the rims of the Young diagrams of @xmath and
@xmath , rotated @xmath and rescaled by @xmath (so that together they
have area @xmath , by item ( i ) of Lemma 2.1 ). Recall from the
description given in Section 2.1 that the information of the derivative
@xmath is split into @xmath and @xmath . Indeed, the black and white
pebbles of the Maya diagram determine @xmath , and half of them
correspond to @xmath and determine @xmath , while the other half
correspond to @xmath and determine @xmath . In other words, we have

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

Item ( iv ) of Lemma 2.1 then implies that the integral over @xmath
essentially involves the interaction of each component of the 2-quotient
with itself, so it becomes

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

Similarly, the integral over @xmath involves the interactions of the
components of the 2-quotient with each other, and becomes

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

Note that there is an implicit change of coordinates here, that would
handle the translations by @xmath in formula ( 3.12 ) and the split of
the domains. Instead of translating and separating the parts of the
domain, we work directly with the components of the 2-quotient.

Adding ( 3.13 ) and ( 3.14 ), and simplifying, we obtain

  -- -------- --
     @xmath
  -- -------- --

where @xmath . We can also write this as

  -- -------- --
     @xmath
  -- -------- --

Integrating by parts twice, we can rewrite this as:

  -- -------- --
     @xmath
  -- -------- --

where the Sobolev norm @xmath is given by

  -- -------- --
     @xmath
  -- -------- --

In sum we have, as a consequence of Lemmas 3.7 and 3.9 ,

###### Proposition 3.10.

As @xmath ,

  -- -------- --
     @xmath
  -- -------- --

where @xmath is the difference of the functions describing the
(rescaled) rims of the Young diagrams of the components @xmath and
@xmath of the 2-quotient of @xmath .

###### Remark 3.11.

The partitions with identical components @xmath (and hence @xmath ) of
the 2-quotient @xmath are easily characterized: they are precisely the
ones that can be constructed concatenating @xmath blocks

  -- -------- --
     @xmath
  -- -------- --

and they are hence in one-to-one correspondence with the partitions of
size @xmath .

### 3.4 An application of the Theorem of Meinardus

###### Lemma 3.12.

As @xmath , we have the asymptotic behavior

  -- -------- --
     @xmath
  -- -------- --

where the sum is over all @xmath of size @xmath .

###### Proof.

It was shown by A. Eskin and A. Okounkov [ 5 , Section 3.2.4] that

  -- -------- --
     @xmath
  -- -------- --

We thus have the following parameters for the Theorem of G. Meinardus,
as presented by G. Andrews [ 1 , Chapter 6] : @xmath in the book is
@xmath here, @xmath , @xmath , @xmath , @xmath , @xmath , @xmath ,
@xmath . ∎

Denote by @xmath the number of partitions of @xmath . Recall that the
Theorem of G. Meinardus also implies the asymptotics

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

See [ 1 , Theorem 6.3] . We thus have

###### Proposition 3.13.

Let @xmath , and let @xmath be the set of balanced partitions @xmath of
@xmath whose 2-quotients @xmath satisfy @xmath (in the notations of
Section 3.3 ). Then the @xmath -probability of @xmath is asymptotically
of order @xmath as @xmath , for some @xmath that depends on @xmath .

###### Remark 3.14.

It is the case that @xmath as @xmath .

###### Proof.

Since we have a bound for the cardinality

  -- -------- --
     @xmath
  -- -------- --

and the @xmath -probability of each partition @xmath is given by

  -- -------- --
     @xmath
  -- -------- --

the result follows from Proposition 3.10 , Lemma 3.12 , and the
asymptotic relation ( 3.15 ). ∎

###### Corollary 3.15.

Let @xmath and @xmath be two functions with @xmath and @xmath increasing
at most polynomially as @xmath , with finite @xmath -expectations, and
continuous in the space of piecewise continuous functions with topology
of the supremum norm (i.e., we need @xmath and @xmath to be continuous
with respect to the functions describing the rim of the partitions).
Assume that @xmath grows at most polynomially:

  -- -------- --
     @xmath
  -- -------- --

for some @xmath . Then

  -- -------- --
     @xmath
  -- -------- --

where @xmath is the 2-quotient of the partition @xmath over which the
sum of the expectation is taken.

###### Proof.

Let @xmath . Let @xmath be such that if @xmath then @xmath . We want to
show that the following tends to 0:

  -- -------- --
     @xmath
  -- -------- --

Here, the summation can be split into two parts

  -- -------- --
     @xmath
  -- -------- --

The later can be bounded easily using Proposition 3.13 : we get

  -- -------- --
     @xmath
  -- -------- --

Since @xmath and @xmath grow polynomially, this tends to 0 as @xmath .
On the other hand, the first part in the summation above goes like

  -- -------- --
     @xmath
  -- -------- --

###### Remark 3.16.

The results in this section, together with those of Section 3.1 , imply
that the components @xmath and @xmath of the 2-quotient also approach
the limit shape corresponding to the uniform distribution, for large
partitions @xmath .

### 3.5 Vanishing of the first approximation of the volumes

We consider the distribution @xmath induced by the pillowcase weights on
the set of partitions of @xmath , for @xmath even. In this section we
discuss the term of highest degree in the @xmath -expectation of formula
( 2.1 ) for @xmath , which turns out to vanish.

We will prove that the term of top degree of the expectations

  -- -------- --
     @xmath
  -- -------- --

can be computed with the following formula:

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

where @xmath is the 2-quotient of @xmath , and the sum is over all
balanced partitions @xmath of size @xmath , and @xmath is a constant
that depends on the scaling. The approximation ( 3.16 ) vanishes: using
formula ( 2.2 ) and the orthogonality of the characters, we have

  -- -------- --
     @xmath
  -- -------- --

This is why we have to also analyze the terms in lower degree; this is
mostly future work, but we discuss it briefly in Section 3.6 .

Let us show why ( 3.16 ) is true. Taking another look at formula ( 2.1 )
for @xmath , we see that we really are interested in the asymptotics of

  -- -------- --
     @xmath
  -- -------- --

where @xmath stand for the 2-quotients of the partitions @xmath over
which summation occurs in the @xmath -expectation, and @xmath is as
above.

By Corollary 3.15 , we can substitute the expectation above by

  -- -------- --
     @xmath
  -- -------- --

The highest degree terms of @xmath are precisely the regular Schur
functions @xmath ; see [ 26 ] ² ² 2 The work of G. Olshanski, A. Regev
and A. Vershik [ 29 ] gives the full expansion of @xmath in terms of the
regular Schur functions @xmath . . Thus the relation that defines the
Littlewood-Richardson numbers (see Section A.5 ) should hold to the
highest degree at least, and we can write the above as

  -- -------- --
     @xmath
  -- -------- --

where @xmath denotes the usual Littlewood-Richardson numbers.

Moreover, A. Okounkov and G. Olshanski [ 26 ] proved that

  -- -------- --
     @xmath
  -- -------- --

where the sum is over all partitions @xmath of size @xmath , so we
really are interested in the asymptotics of

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

where the new sums are over all partitions @xmath of size @xmath and all
partitions @xmath of size @xmath .

A. Eskin and A. Okounkov [ 5 , Section 3.3.5] proved the following about
the asymptotics of the expectations of the power functions as the size
@xmath of the partitions considered grows:

  -- -------- --
     @xmath
  -- -------- --

In our case, a similar proof (using the generating function of Lemma 2.2
) shows that

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

This means that the terms that grow fastest in ( 3.17 ) are precisely
those that maximize the number @xmath . Since @xmath is fixed, only
@xmath varies. The maximum is thus achieved when @xmath equals the
partition @xmath of the corresponding length. The highest degree term of
( 3.17 ) is then

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

Since @xmath , and since by Proposition 3.10 @xmath with very high
probability ³ ³ 3 This also follows directly from the result in Section
2.5 : from the form of the @xmath -point function found in Proposition
2.2 , it is clear that the expected sizes of @xmath and @xmath (i.e.,
the expectations @xmath and @xmath ) are the same, and also that they
coincide, up to rescaling, with @xmath . , for all @xmath ,

  -- -------- --
     @xmath
  -- -------- --

Also @xmath and @xmath , so if we let

  -- -------- --
     @xmath
  -- -------- --

we obtain, from ( 3.19 ),

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

Formula ( 3.16 ) now follows from the following

###### Lemma 3.17.

For any two (possibly empty) partitions @xmath and @xmath ,

  -- -------- --
     @xmath
  -- -------- --

where the sum is taken over all partitions @xmath of size @xmath , and
@xmath denotes the Littlewood-Richardson coefficients (see Section A.5
).

###### Proof.

Compare the coefficients of the symmetric power function @xmath in the
expansions of both sides of

  -- -------- --
     @xmath
  -- -------- --

###### Remark 3.18.

In this proof, one can simply use the multiplicativity of the
expectation (proved in Section 3.1 ) instead of introducing the
Littlewood-Richardson numbers, but here we decided to give an proof that
would be independent of the other result.

### 3.6 Next term

We go back to expression ( 3.17 ), and according to the behavior given
by ( 3.18 ), we see that since the first term vanishes, the next one
will be the one corresponding to @xmath .

Appealing again to formula ( 2.5 ) and to the Murnaghan-Nakayama rule
(see Section A.4 ), we see that

  -- -------- -------- --
     @xmath   @xmath
              @xmath
  -- -------- -------- --

Also,

  -- -------- --
     @xmath
  -- -------- --

and

  -- -------- --
     @xmath
  -- -------- --

so the next term in the approximation is

  -- -------- --
     @xmath
  -- -------- --

The sum is over all balanced partitions @xmath of size @xmath and over
all partitions @xmath of size @xmath . We can simplify this further to

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

where

  -- -------- --
     @xmath
  -- -------- --

The proof is analogous to that of Lemma 3.17 , but this time looking at
the coefficients of @xmath . Alternatively, one can use the
multiplicativity of the expectation proved in Section 3.1 .

###### Remark 3.19.

We have by ( 3.18 ),

  -- -------- --
     @xmath
  -- -------- --

However, for @xmath , @xmath , since @xmath ,

  -- -------- --
     @xmath
  -- -------- --

if @xmath is not self-resolvent (see Section 1.3.3 ) and

  -- -------- --
     @xmath
  -- -------- --

if @xmath is self-resolvent. Hence we expect the term of highest degree
of first non-vanishing term to be of this degree. In particular, we
expect formula ( 3.21 ) to vanish in most cases.

## Appendix A Prerequisites

### a.1 Representations of the symmetric group

The symmetric group @xmath in @xmath elements is the set of bijections
of the set of @xmath elements @xmath . Its elements are known as
permutations . The group operation is the composition of permutations.

A representation @xmath of the symmetric group @xmath consists of a
vector space @xmath and a homomorphism @xmath of @xmath into the
multiplicative group @xmath of invertible linear transformations on
@xmath . A representation is reducible if there are subspaces @xmath
such that @xmath and @xmath factors through @xmath , that is, there
exist representations @xmath and @xmath such that @xmath and @xmath for
all @xmath . If two such subspaces fail to exist, we say that @xmath is
an irreducible representation of @xmath .

The dimension of the representation @xmath is simply the dimension of
the underlying vector space @xmath .

Two representations @xmath and @xmath are isomorphic if there exists a
linear bijection @xmath such that @xmath . The existence of an
isomorphism of representations implies that the underlying vector spaces
@xmath and @xmath are of the same dimension.

The character @xmath of a representation @xmath is the function @xmath .
The character is invariant under conjugation: for every @xmath ,

  -- -------- --
     @xmath
  -- -------- --

It is thus constant over conjugacy classes.

The classification of the finite-dimensional representations of the
symmetric group can be easily achieved using the standard theory of
group characters; for details we refer the reader to [ 10 , 30 ] , for
example. In order to explain this classification, we must introduce some
combinatorial objects. A partition of a positive integer @xmath is a way
to write @xmath as a sum @xmath of positive integers @xmath , and is
usually denoted @xmath . Conventionally, we order the parts so that
@xmath . For example, the partitions of the number 5 are @xmath , @xmath
, @xmath , @xmath , @xmath , @xmath , and @xmath . It is also standard
to abbreviate repetitions using exponents. For example, @xmath can be
written @xmath . We will use the notation @xmath , and @xmath will
denote the number of parts of @xmath .

The irreducible representations of the symmetric group @xmath can be
indexed by partitions of @xmath , that is, for each partition @xmath of
@xmath there exists an irreducible representation @xmath of @xmath . We
will denote by @xmath the character of the representation corresponding
to the partition @xmath .

In the case of the symmetric group @xmath , the conjugacy classes are
also indexed by partitions: the lengths of the cycles of an element of
@xmath are invariant under conjugation, they completely determine the
conjugacy class, and they correspond to a partition of @xmath . For
example, the permutation in @xmath that takes @xmath , @xmath , @xmath ,
@xmath , @xmath is denoted in cycle notation by @xmath ; it is composed
of two cycles, @xmath and @xmath , of lengths 3 and 2 respectively. Its
conjugacy type corresponds to the partition @xmath , and contains all
other permutations with one cycle of length 3 and one of length 2, such
as @xmath and @xmath . The partition @xmath that determines the
conjugacy class @xmath of a permutation is also known as its cycle type
. The number of elements @xmath in a conjugacy class is equal to @xmath
, where

  -- -------- --
     @xmath
  -- -------- --

is the size of the centralizer of @xmath , and @xmath is the number of
parts in @xmath that are equal to @xmath .

The only permutation of cycle type @xmath is the identity. A permutation
@xmath of cycle type @xmath is an involution, that is, @xmath is the
identity. A permutation of cycle type @xmath is an involution without
fixed points.

Since the characters are constant over conjugacy classes, we usually
denote the character of a permutation of cycle type @xmath in the
irreducible representation corresponding to the partition @xmath by
@xmath . In the following sections, we study some related objects that
provide ways to compute the values of these functions more or less
explicitly, and that relate them to other combinatorial constructions.

We recall two general facts about group representations. The first one
is the decomposition of the group algebra @xmath of any finite group
@xmath . It turns out to contain each of the irreducible representations
of @xmath exactly as many times as their dimensions, that is,

  -- -------- --
     @xmath
  -- -------- --

where the modules @xmath range over the different irreducible
representations of @xmath . See, for example, [ 30 , Section 1.10] .

The second one is Schur’s lemma : Let @xmath and @xmath be two
irreducible @xmath -modules. If @xmath is a @xmath -homomorphism (i.e.,
@xmath commutes with the action of @xmath ), then either @xmath is a
@xmath -isomorphism, or @xmath is the zero map. See, for example, [ 30 ,
Section 1.6] .

### a.2 Symmetric and shifted-symmetric functions

For variables @xmath , a symmetric polynomial is a polynomial @xmath
with coefficients in the rational numbers @xmath such that @xmath is
invariant by any reordering of the variables:

  -- -------- --
     @xmath
  -- -------- --

for all @xmath . Denote by @xmath the set of all symmetric polynomials
in @xmath variables.

Let @xmath be the specialization to @xmath variables, given by

  -- -------- --
     @xmath
  -- -------- --

Using the identification provided by @xmath , we can form the inverse
limit

  -- -------- --
     @xmath
  -- -------- --

whose elements are known as symmetric functions , and consist of formal
sums of monomials in countably many variables @xmath of the form

  -- -------- --
     @xmath
  -- -------- --

for @xmath , @xmath , where the @xmath ’s may be repeated. By
construction, symmetric functions are invariant by any finite
permutation. They form a ring, denoted @xmath , that is obviously also a
@xmath -module.

A basis of the symmetric functions @xmath is given by the symmetric
power functions @xmath . To define them, we let

  -- -------- --
     @xmath
  -- -------- --

and then extend this definition to partitions @xmath by letting

  -- -------- --
     @xmath
  -- -------- --

In other words, @xmath is algebraically generated by the functions
@xmath [ 19 ] .

While the symmetric power functions are by far the simplest linear basis
of the symmetric functions @xmath , there are a few other basis that are
of interest. Among these is the one composed of the so-called Schur
functions @xmath , which can be defined in many equivalent ways. One way
is as the sum [ 19 ]

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

where the sum is over all partitions @xmath , @xmath , @xmath is the
number of parts @xmath of @xmath that are equal to @xmath , and @xmath
stands for the character of the representation of the symmetric group
corresponding to the partition @xmath evaluated at an element of cycle
type @xmath .

A second way to define the Schur functions is by their characterization
as being the symmetric functions that specialize (by setting the
variables @xmath to zero) to the Schur polynomials , defined by
quotients of determinants:

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

This form of the definition, together with equation ( A.1 ) gives a way
to compute the characters @xmath . Other ways are described in the
following sections.

### a.3 The hook formula

The formula obtained in 1954 by J. Frame, G. Robinson, and R. Thrall [ 8
] to calculate the characters @xmath , has become known as the hook
formula due to the combinatorial objects it involves.

In order to introduce these concepts, we first remark that to a
partition @xmath , where @xmath , we can assign a Young diagram
consisting of rows of @xmath square boxes. For example, if our partition
is @xmath , the diagram looks like this:

  -- -------- --
     @xmath
  -- -------- --

In this diagram, each square is called a cell . To each cell, we can
assign several quantities. For our purposes, the most important one is
the hook length , which we now define. For a given cell, the hook
consists of the cell itself, together with all the cells to the right of
it and all the cells below it. So, for example, in this diagram we have
marked with bullets the hook of cell @xmath :

  -- -- --

  -- -- --

The hook length is the number of cells in the hook. In the example of
the last diagram, the hook length is 5. In the following diagram we have
filled in each cell with the corresponding hook length:

  -- -------- --
     @xmath
  -- -------- --

Now let @xmath be a partition of @xmath , and let @xmath be the product
of the hook lengths of @xmath . For the example above, @xmath , @xmath ,
and @xmath . Then the hook formula, discovered by Frame, Robinson, and
Thrall, says that

  -- -------- -- -------
     @xmath      (A.3)
  -- -------- -- -------

Here, @xmath stands for the partition with @xmath parts equal to 1.
There is an alternative way to express this as a function of the
coordinates of the partition @xmath :

  -- -------- -- -------
     @xmath      (A.4)
  -- -------- -- -------

In the example above, formula ( A.3 ) gives

  -- -------- --
     @xmath
  -- -------- --

A proof of the hook formula can be found in the original paper [ 8 ] ,
and also in [ 19 , Examples I.1.1 and I.7.6] , [ 30 , Section 3.10] ,
and [ 31 , Corollary 7.21.6] .

### a.4 The Murnaghan-Nakayama rule

The Murnaghan-Nakayama rule gives a combinatorial algorithm to compute
the value of the character @xmath of an irreducible representation of
the symmetric group @xmath corresponding to the partition @xmath and
evaluated at an element of cycle type @xmath .

In order to state the rule, we need to define some combinatorial
objects. Let @xmath and @xmath be two partitions, and assume that @xmath
, @xmath A skew Young diagram @xmath , consists of the cells of the
Young diagram of @xmath that would not belong to the Young diagram of
@xmath if we were to overlap them. For example, let @xmath and @xmath .
Then

  -- -- --

  -- -- --

A special kind of Young diagram that we will be interested in is the
strip , which consists of a connected skew Young diagram that does not
contain a @xmath block:

  -- -------- --
     @xmath
  -- -------- --

A skew Young diagram is connected if we can get from any cell to any
other cell jumping on adjacent cells. For example, the following are
strips:

  -- -- -- -------
           (A.5)
  -- -- -- -------

The following are not strips:

  -- -- --

  -- -- --

Here, the first example is disconnected (it is not enough to have a
common corner for cells to be adjacent), the second example cannot be
obtained as a difference of Young diagrams, and the third contains a
@xmath block.

Now suppose that the partitions @xmath and @xmath are both partitions of
the same number, that is, @xmath . A @xmath -strip decomposition of the
partition @xmath is a way to recover @xmath by successively adjoining
strips of size @xmath . More precisely, it is a sequence of partitions
@xmath , where @xmath is the number of parts in @xmath , such that
@xmath is a strip of size @xmath , @xmath is a strip of length @xmath ,
@xmath , and @xmath . For example, if @xmath and @xmath , a @xmath
-strip decomposition of @xmath can be represented as follows: we will
use number 1 to represent the strip of size 5, then number 2 to
represent the strip of size 3, and so on, always assigning the number
@xmath to the strip of length @xmath :

  -- -------- -- -------
     @xmath      (A.6)
  -- -------- -- -------

Note that the second and third examples are different only in the order
of the third and fourth strips.

The height of a strip @xmath is equal to the vertical distance between
the center of a cell in the lowest row of the strip to the center of a
cell in the highest row of the strip, assuming that each cell has side
length 1. For example, the strips in ( A.5 ) have heights 5, 3, and 4,
respectively. The height of a @xmath -strip decomposition equals the sum
of the height of the involved strips. For example, the height of the
first decompositions in ( A.6 ) is @xmath , and the height of the other
two is @xmath .

The Murnaghan Nakayama rule is the simple assertion that

  -- -------- -- -------
     @xmath      (A.7)
  -- -------- -- -------

where the sum is taken over all the @xmath -strip decompositions @xmath
of @xmath . For example, if @xmath and @xmath , then there are exactly
two @xmath -strip decompositions of @xmath , namely (in the same
notations as above),

  -- -------- --
     @xmath
  -- -------- --

The heights of these decompositions are @xmath and @xmath ,
respectively, so the Murnaghan-Nakayama rule implies that

  -- -------- --
     @xmath
  -- -------- --

Proofs of the Murnaghan-Nakayama rule can be found in [ 19 , Exercises
3.11 and 7.5] , [ 30 , Section 4.10] , or [ 31 , Theorem 7.17.3] .

### a.5 The Littlewood-Richardson rule

Recall that the Schur functions @xmath constitute a linear basis of the
space of symmetric functions. The Littlewood-Richardson numbers @xmath
give the linear decomposition of products of Schur functions in terms of
that basis:

  -- -------- --
     @xmath
  -- -------- --

The Littlewood-Richardson rule gives a way to compute these numbers in
terms of certain combinatorial objects.
