### Introduction \Fontlukas

« Having answered the Count’s salutation, I turned to the glass again to
see how I had been mistaken.

This time there could be no error, for the man was close to me, and I
could see him over my shoulder.

But there was no reflection of him in the mirror!»
From Jonathan Harker’s Diary,

Bram Stocker’s Dracula

\lettrine

If a neutrino, an exceptionally imaginative one, were able to write a
historically accurate novel about some macroscopic beings trying to
understand its characteristics and behaviour, how would it depict such a
history? Surely, it would remark about the singularity of the neutrino
hypothesis’ inception on the science of these non-quantum beings. Such
work would also emphasize the efforts of many brave scientists who
worked, and are still working, to give a complete insight about these
amazing particles. Let us put ourselves on the storyteller’s shoes, and
try to imagine how a novel about these classical beings attempting to
comprehend a neutrino would be. We will base this unpretentious gedanken
experiment on the book from C. Sutton [ 1 ] .

How would such a saga begin? Probably it would consider the origin of
the curiosity of the macroscopic creatures. Without going so far, it
could begin with the development of subatomic Physics. Particle physics
is one of the more recent fields of natural sciences. Its genesis
however goes to ancient Greek and Indian philosophers, who thought that
nature is composed by indivisible particles. Physics as we know it is an
experimental discipline; the atomic hypothesis could only be confirmed
by the end of the XIX century. The birth of Elementary Particle Physics
can be traced back to the works of Henri Becquerel [ 2 ] , who
discovered radioactivity in 1896, and J. J. Thomson [ 3 ] , who showed
that cathodic rays are composed by particles, i.e. electrons . The
greatest advances came after the advent of Relativity and Quantum
Mechanics. Moreover, the development of Quantum Mechanics is
intrinsically related to the evolution of Particle Physics.

One of the types of radioactivity discovered was named beta-rays , and
the works from Marie Skłodowska and Pierre Curie [ 4 , 5 ] and Walter
Kaufmann [ 6 ] showed that the particles in these rays are actually
electrons. Several studies were performed to understand the origin and
properties of those electrons. Specially, Lise Meitner and Otto Hahn [ 7
, 8 , 9 ] studied the energy spectrum of these beta-rays. It was
hypothesized that those electrons had a unique energy. As the initial
and final nucleus –nuclei were discovered previously by Ernest
Rutherford– have well known masses and energies, the outgoing electron
would have a definite energy. Nonetheless, experiments showed that
electrons were emitted with several energies, making the beta spectrum a
continuous one [ 10 ] . This created a crisis in the scientific
community since this continuous spectrum seemed to violate the
conservation of energy.

Niels Bohr went through an extreme path; he proposed that conservation
of energy would not be respected in the quantum realm. This however made
Wolfgang Pauli uncomfortable. He thought deeply about this “problem”,
making him to propose that in the beta process not only electrons were
produced, but also an additional neutral particle. Pauli would then be
named the discoverer of all neutrinos by the ingenious author. In his
letter to the “Radioactive Ladies and Gentlemen”, he speculates with
certain hesitation about ‘‘einen verzweifelten Ausweg’’ –a desperate
escape– [ 11 ]

  ‘‘... Nämlich die Möglichkeit, es könnten elektrisch neutrale
  Teilchen, die ich Neutronen nennen will, in der Kernen existieren,
  welche den Spin @xmath haben und das Ausschliessungsprinzip befolgen
  ...’’ ¹ ¹ 1 “… Namely, the possibility that in the nuclei there could
  exist electrically neutral particles, which I will call neutrons, that
  have spin 1/2 and obey the exclusion principle…”

In these few words the neutrino hypothesis was born. Pauli chose the
simplest name one could imagine, neutrons , as there were no other known
neutral particles. He further reflects about the properties of such
particles and the possibility of their detection [ 11 ] ,

  ‘‘... Die Masse der Neutronen müsste von derselben Grössenordnung wie
  die Elektronenmasse sein und jedenfalls nicht grösser als 0.01
  Protonenmasse ...’’ ² ² 2 “… The mass of the neutrons should be of the
  same order of magnitude as the electron mass and in any event not
  larger than @xmath proton mass…”

It is clear that Pauli did not only have doubts about the mass, but also
about the origin of the beta rays. He thinks that the neutrons
interacted through its small magnetic dipole, making its detection
difficult indeed. These and other reasons made him not to publish his
idea; however, the conception of a new neutral particle spread through
the community.

At this point, the neutrino chronicler would refer to the work of one of
the greatest physicists that ever lived, Enrico Fermi. In his work [ 12
] , he takes a step further on the Pauli’s hypothesis by proposing the
existence of a new interaction, called weak interaction. He supposes
that nucleus are composed by protons and recently discovered neutrons,
and the beta process consists in the emission of an electron together
with a neutrino . He is the one responsible for the name as neutrino
comes from Italian meaning the little neutral one . He also establishes
a method to determine the value of the neutrino mass: by studying in
detail the end point of the electron’s spectrum, it is possible to infer
the magnitude of such mass. Taking the experimental data from the time,
he found that neutrinos are particles with a mass much smaller than the
electron mass. In any case, the neutrino idea was now firmly
established.

Nevertheless, the magnitude of the neutrino mass is related with an
important property of neutrinos. H. Weyl [ 13 ] showed that if a fermion
is massless it can be described by a field with a definite chirality
(see appendix B ). Therefore, if the neutrino has a zero mass, parity
symmetry would be violated in decay processes. This was considered
completely unrealistic at the time as all the experiments with
electromagnetic and strong interactions were compatible with the
conservation of parity. Other great physicists in the neutrino saga,
T. D. Lee and C. N. Yang, emerged at this time. They actually presented
a modification of the Fermi theory, and showed that experiments were
needed to shed light on the conservation of parity for the specific case
of the weak interaction [ 14 ] . Experimentalist such as C. S. Wu
et. al. [ 15 ] and Goldhaber, Grodzins and Sunyar [ 16 ] performed
experiments showing that beta decays did not respected the parity
symmetry and that neutrinos were always left-helical. Everyone was as
astonished as Jonathan Harker when he did not see the reflection of
Count Dracula on the mirror. Anyhow, Landau [ 17 ] , Lee and Yang [ 14 ]
and Salam [ 18 ] did not get frightened by the violation of parity, and
they established the, now denominated, two-component theory of a
massless neutrino, in which a neutrino is described by a Weyl
left-handed fermion.

However, the creative neutrino writer would remark, neutrinos are way
more diverse than the macroscopic creatures initially thought. Studying
cosmic rays, S. Neddermeyer and C. Anderson, who also discovered the
positron [ 19 ] , found a particle closely related to the electron, the
muon ( @xmath ) [ 20 ] . Further analysis on the muon’s properties
showed that it decays weakly into an electron and some invisible
particle which was first thought to be the Pauli-Fermi neutrino.
Nevertheless, the absence of some kinematically allowed decays, such as

  -- -------- --
     @xmath   
  -- -------- --

led to the introduction of a conserved quantity which is different for
electrons and muons, the leptonic number. Then, in the muon decay, it is
necessary to have two distinct neutrinos which different leptonic
numbers

  -- -------- --
     @xmath   
  -- -------- --

Then, the Pauli-Fermi neutrino was actually an electron antineutrino (
@xmath ) and @xmath was a muon neutrino . Furthermore, after the
discovery of a third particle similar to the electron, the tau lepton (
@xmath ), it was necessary to introduce a third neutrino, the tau
neutrino ( @xmath ).

Using the Fermi theory, it was initially thought that neutrinos were
impossible to detect. This is because the probability of a single
neutrino interacting with a detector is tiny. However, technological
advances allowed us to detect electron antineutrinos by considering the
huge flux of those particles coming from a nuclear reactor. This was
achieved by Cowan and Reines in 1956 [ 21 ] , inaugurating the neutrino
experimental age. The @xmath was discovered in 1962 [ 22 ] , and finally
the @xmath was found in the year 2000 [ 23 ] . Thus, we finally settled
the current picture of three neutrinos, each belonging to a distinct
family; these types of neutrinos are called flavour eigenstates.

The ingenious neutrino would now mention that the curious macroscopic
beings also discovered how two apparently different interactions, the
electromagnetic one, which a neutrino does not experience, and the weak
are two facets of a unique interaction, the Electroweak interaction.
This led to the establishment of the Standard Model (SM) [ 24 , 25 , 26
] , model which describes the electromagnetic, weak and strong
interactions, based in two simple ideas: the gauge principle and the
Higgs mechanism [ 27 , 28 , 29 ] . The gauge principle explains how
interactions arise in a natural way after imposing that global
symmetries present in the model have to be local. The Higgs mechanism
describes how gauge bosons associated to weak interactions and fermions
acquire mass due to a spontaneous symmetry breaking. The SM is without
any doubt extremely successful. It has predicted neutral charged
currents; the existence of a neutral gauge boson @xmath ; and a neutral
scalar @xmath . All these have been found experimentally. The latest one
was the discovery of a particle that seems to be the Higgs boson in 2012
[ 30 , 31 ] . Nevertheless, the SM still has unsolved problems within
its construction. The Hierarchy Problem is one of the difficulties which
has been attacked for years without great success. This problem is
related to the large difference between the Planck and Weak scales,
which makes the Higgs mass unstable after radiative corrections. Other
difficulties are related to the explanation of the structure of the
model itself. For instance, why are there three families? Why the
fermion masses are so different? Unfortunately, the SM does not address
these problems. A crucial point here is that, by construction, neutrinos
are massless in this model; as the neutrino writer would notice, this
was indeed well accepted at the time.

Moreover, it is clear that our knowledge has improved significantly
after the neutrino and the weak interaction ideas came out. One of the
triumphs of the Fermi model is explaining why stars shine [ 32 , 33 ] .
With an explanation beyond the imagination of any ancient civilization,
we now understand the greatness of the Sun and its essential role in
allowing for life on the Earth. In the solar model, nuclear reactions
transform mainly hydrogen into helium and other elements, producing the
energy which feeds most of the life. This solar description, the
ingenious particle would certainly stress, was crucial for progress on
the neutrino understanding. The first experiment, the Homestake
experiment, was designed to detect solar neutrinos [ 34 ] . It consisted
of a large tank full of tetrachloroethylene in which a neutrino could
interact with a Chlorine nucleus, transforming it into Argon via
charged-current interactions. Thus, by counting the number of Argon
nuclei, it could be possible to measure the number of detected
neutrinos. Neutrinos had there another surprise for us; the number of
events was smaller than expected. Other experiments were performed to
confirm or refute this result. All of them found smaller numbers than
expected. Something was happening with solar neutrinos in their journey
to the Earth.

Gribov and Pontecorvo [ 35 ] suggested that if the neutrino masses were
different from zero, and, if their mass eigenstates were a combination
of the flavour eigenstates, neutrinos could undergo an oscillation
process. Thus, if a neutrino is created in some definite flavour, there
is a non zero probability for it to be detected in another flavour. This
could explain the solar neutrino deficit since part of the neutrinos
would not be detected by the experiment as they arrive in a distinct
flavour than expected. This was actually proven by the Sudbury Neutrino
Observatory (SNO) experiment [ 36 ] . This experiment first measured
neutrinos coming from the Sun using charged-current interactions,
finding the same deficit encountered by previous experiments; however,
it also was capable of measuring neutrinos through neutral-current
interactions and elastic scattering. They found that the neutrino events
were compatible with the number expected from neutrinos undergoing
adiabatic conversion in the Sun. Further evidences came from neutrinos
created in other independent sources, such as atmospheric neutrinos,
detected by the SuperKamiokande experiment [ 37 , 38 ] ; reactor
antineutrinos, detected for instance by the Kamioka Liquid scintillator
AntiNeutrino Detector (KAMLAND) [ 39 ] . All of them showed that
neutrinos do undergo oscillations. This was the final proof that
neutrinos are massive, and it confirmed experimentally the existence of
beyond SM physics. Still, the smallness of neutrino masses seems to be a
difficulty. Nonetheless, this is a problem of the SM itself, and perhaps
there is a unique solution for all fermions.

Thus, in principle, we could measure the values of the neutrino masses
and mixing angles, which describe the mixing among mass and flavour
eigenstates, and then we could obtain a final description of neutrinos.
Nonetheless, and fortunately, the clever particle would assert,
neutrinos are more complex than one may believe initially. Since such
fermions are neutral particles, their nature is ambiguous to us. Let us
remember that Dirac particles, evidently introduced by Dirac [ 40 ] ,
are fermions which are different from their antiparticles. Meanwhile,
E. Majorana [ 41 ] described how a massive fermion can be identical to
its antiparticle if it was neutral under any charge. As we see,
neutrinos are the only elementary particles which can be Majorana or
Dirac fermions. Unfortunately, there is no experimental evidence which
allow us to corroborate the neutrino’s true nature. Thus, we can
speculate if there is a connection between the smallness of the neutrino
mass and its nature. This will be one of the problems addressed in this
thesis.

The other two problems that we will consider here are related to the
confluence of Cosmology and Particle Physics, the Cosmic Neutrino
Background detection and the Dark Matter identity. Our scientific
cosmogony predicts the existence of a background composed by the archaic
neutrinos which remained after the Big Bang [ 42 ] . Such relic
neutrinos are completely different from the neutrinos we are used to
study since they are non-relativistic particles. Moreover, these
neutrinos are fundamental to asseverate our understanding of the origin
of the Universe. For the ingenious neutrino writer, such neutrinos would
be compared to elderly wise ones which were witnesses to the beginning
of the Universe. Nevertheless, they are enormously difficult to detect
given their minuscule energy. There have been proposed many methods to
observe these relic neutrinos, but most of them are beyond our current
technology. The most promising method, however, uses a capture by a
nucleus; a process closely related to beta decay. The main consequence
of neutrinos being non-relativistic on the capture rate is that, when
considering SM interactions, the rate for Dirac and Majorana neutrinos
are different [ 43 ] . Precisely, Majorana neutrinos expected rate is
double the value for Dirac neutrinos. This nevertheless is a strong
statement as one should take into account the possible existence of
beyond SM physics and modifications on the cosmological model. Thus, we
will analyse the consequences of both possibilities on the cosmic
neutrino background detection.

On the other hand, Dark Matter (DM) composes approximately @xmath of our
Universe, but we do not know its fundamental composition. We just know
that DM has gravitational interactions, and it does not couple with
photons [ 44 ] . It is supposed however that DM has other interactions
since it should have been created after the Big Bang. This is confirmed
by studying the oldest light in the Universe, the Cosmic Microwave
Background. The latest Planck results [ 45 ] confirm the existence of
the unknown DM component. Among the many candidates to be DM, the Weakly
Interacting Massive Particle (WIMP) emerges as one of the most studied
and discussed. The main reason is that it can give the correct measured
relic density and its characteristics seem to agree with the expected
for many beyond SM physics. Several experiments have been performed to
test the WIMP hypothesis, but they have not found anything.
Consequently, more precise and sensitive experiences are under planning,
but they will suffer a difficulty. A special chapter of the novel would
narrate how neutrinos became somewhat villains for the macroscopic
creatures in their quest for knowledge. This is because neutrinos became
an irreducible background in the WIMP detection experiments through a
process called Coherent Neutrino Scattering off Nuclei. Thus, we need to
analyse when neutrinos start to influence WIMP searches. Also, it seems
that we are at a point in time in which neutrinos may become merely
background to other breakthrough explorations. This couldn’t be less
true. If neutrinos are sensitive to some unknown physics which also
affects WIMPs, experimental searches could constraint such interactions.
This will be examined in detail here.

Regardless the specific topics we will discuss, neutrino physics is
beyond any doubt one of the more active and compelling areas in Particle
Physics. We certainly can imagine that the novel written by the clever
neutrino would have an end. But before getting there, it could have
chapters depicting the difficulties and wrong paths the inquisitive
creatures found, and it may tell how those beings finally understood the
neutrino. However, we, as main protagonists of such fictional history,
do not know what awaits for us in the future, and what other surprises
neutrinos have for us.

#### About this Thesis

This thesis intends to describe some phenomenological aspects of
neutrino physics given the current status of the field. The main
intention of the author is to give a friendly approach as complete as
possible to the distinct issues and topics that he has addressed during
his Doctoral studies in this fascinating and rich area. Keeping in mind
this purpose, the document has been divided in two main parts. The first
one contains the theoretical basis for a comprehension of the results
obtained, and the second part includes the novel contributions that have
resulted from the main research done in the past years.

The first part is composed by three chapters. The first chapter encloses
a brief description of the Standard Model; the details regarding the
neutrino sources that will be used in subsequent chapters; and the basis
of neutrino oscillations. Considering neutrinos as Majorana particles,
in the second chapter, we will give first a concise description of
Majorana fermions, making explicit their peculiar properties. After that
we will consider Majorana neutrinos in the SM framework from the point
of view of the see-saw mechanism and one of its main consequences,
leptogenesis. The other possibility for neutrinos, as being Dirac
particles, is analysed in the third chapter. We will first describe the
minimal SM extension, and, supposing that neutrino masses have a
different origin from the other fermions, we will analyse the
neutrinophilic two-Higgs-doublet models.

The second part contains the original results of this thesis, as already
mentioned. This part is also divided in three chapters. First, in
chapter four , we will consider the phenomenological and theoretical
limits on the neutrinophilic two-Higgs-doublet models coming from
Electroweak precision measurements and flavour physics. Then, we will
analyse the detection of the cosmic neutrino background in the fifth
chapter. Explicitly, we will describe the properties of such background
and the detection by capture in tritium. Then, we will analyse the
consequences of the possible existence of Non-Standard Interactions on
the capture rate. After that, we will depart slightly from the main
subject of the thesis in the sixth chapter. We will study there the
effect of the Coherent Neutrino Scattering off Nuclei on WIMP direct
detection experiments. We will introduce the definition of the WIMP
discovery limit considering only the SM interactions. Afterwards, we
will study the impact of beyond SM physics, coupling with neutrinos and
WIMP at the same experimental facilities. We will then give our
conclusions . We also include an appendix describing the fermion
representation of the Lorentz Group and the construction of Weyl,
Majorana and Dirac fields.

It is important to note that in each chapter of the second part we will
use a different method to introduce new physics, namely, Ultraviolet
complete models (neutrinophilic two-Higgs-doublet models); Effective
Field Theory approach in the relic neutrino detection chapter; and
simplified models, in the final chapter.

Throughout this Thesis, we will work with natural units in which the
reduced Planck, the light speed and the Boltzmann constants are equal to
the unity, @xmath . We also will make use of the Einstein notation, i.e.
repeated indices indicate sum unless explicitly stated in the text. We
will consider the Minkowski metric with trace @xmath and the Dirac
representation for the @xmath matrices when necessary. We will also
adopt the first letters of the Latin alphabet to indicate mass
eigenstates, and the first Greek alphabet letters for flavour
eigenstates. Greek letters starting from @xmath will indicate the
space-time indices. Further definitions of the conventions used will be
given in appendix A .

## Part I Theoretical Basis

### Chapter 1 Neutrinos in the Standard Model and Beyond \lettrine

The two greatest milestones of the modern physics developed in the first
decades of the XX century, the Quantum Mechanics and the Relativity,
have become the keystones for any advancement in High Energy physics. In
other words, any quantum theory that attempts to describe consistently
the physical phenomena at high energies must be in accordance with the
special relativity’s principles. The basic guidance to construct those
theories is the lagrangian formalism, borrowed from the classical
mechanics since it has the advantage of treating equally space and time.
In a relativistic compatible framework, the lagrangian, and therefore
the action, must be invariant under the Lorentz transformations. On the
other hand, it is firmly established that all matter fields, i.e. all
quarks and leptons, are particles with spin one-half, i.e. they are
fermions . Thus, it was necessary to build a invariant lagrangian for
those fields, achievement accomplished by Dirac [ 40 ] after the
non-relativistic approach of Pauli. The current understanding of these
fields, as belonging to a different representation of the Lorentz group
from those describing scalar and vector fields, allows us to distinguish
between two types of fermion representations, called, by historical
reasons, left - and right -handed fermions [ 46 ] . These two distinct
species of fermions emerge from the intrinsic properties of the Lorentz
group, see appendix B for further details. Let us denote the type of
representation as the chirality of the field. So, a fundamental question
appears at this point: Is it strictly necessary to have both chiralities
for a complete description of an interaction? To answer this we need to
notice that the parity operation converts one representation into the
another. For this reason, Dirac indirectly included both species, making
his theory parity-invariant. Nevertheless, as stated in the
Introduction, the beta decay does not conserve parity [ 15 ] , and,
consequently, we could have a unique fermion representation in a model
for the Weak interactions [ 14 ] .

Moreover, the smallness of the neutrino mass was established by direct
measurements in early studies of the weak interactions. Hence,
physicists actually believed that the violation of the parity was a
suggestion for a massless neutrino, represented by a left-handed chiral
fermion. The justification for the last statement is due to the work of
Weyl [ 13 ] where he proved that if a fermion was massless, one could
describe such a particle either by a left- or a right-handed chiral
field. This archetype of a left-handed and massless neutrino was
incorporated to the Standard Model (SM) in the 1960’s [ 24 , 25 , 26 ] .
In this chapter we will present the neutrino as described in the SM. For
that purpose, we will first consider briefly the Weyl description of
massless fermions and its most important properties. Then, we will
introduce the SM and its basic characteristics, and, then, we will
illustrate the relevant neutrino sources to be used in the development
of the thesis. Finally, based on experimental results, we will consider
the current status of neutrino oscillations phenomena.

#### 1.1 Weyl Fermions

Let us begin considering a massless left-handed two component spinor
field @xmath , i.e. a Weyl fermion field whose lagrangian is given by

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

where @xmath is a set of Pauli matrices ¹ ¹ 1 One should be careful with
the notation when stating that the set of matrices is a four-vector .
Evidently, these matrices do not transform as a four-vector; they are
independent of the inertial frame. Actually, as shown in the appendix B
, the current @xmath do transform as a four-vector, and so we can write
a invariant lagrangian as in 1.1 . , see appendix A . This lagrangian is
built considering the properties of spinors under Lorentz
transformations, see appendix B for more details. The Weyl equation of
motion,

  -- -------- --
     @xmath   
  -- -------- --

has solutions that also solve the Klein-Gordon equation,

  -- -------- --
     @xmath   
  -- -------- --

Therefore, constructing the solutions is straightforward. A solution is
given by,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a constant two component spinor, depending on the direction
of the propagation of the field.

The Weyl equation gives

  -- -------- -------- -- -------
     @xmath   @xmath      (1.2)
  -- -------- -------- -- -------

showing that the solution is an eigenstate of the operator @xmath . This
operator, called helicity , is interpreted as the projection of the spin
along the direction of motion. Let us note that this property is
intrinsic to the Weyl fermion since it cannot be altered by a Lorentz
transformation. In principle, if the particle was massive, one could
boost to another frame where the momentum is pointing in the opposite
direction, changing the value of the projection. But this cannot be done
for a massless particle. When the eigenvalue of the helicity is
negative, the particle is usually called left-handed. This is a source
of certain misunderstanding because it can be thought that helicity is
equivalent to the fermion representation within the Lorentz group. The
type of representation, i.e., the chirality, will only coincide with the
helicity in the case of a massless fermion. Obviously, for a massive
particle the helicity is frame-dependent while the chirality is not.
Furthermore, a massless fermion with a definite helicity violates the
parity symmetry, as the parity reverts the linear momentum, keeping at
the same time the angular momentum invariant. Thus, to avoid confusion
from now on, we will designate a particle with a negative (positive)
helicity as left-(right-)helical .

All fundamental fermions are now known to have mass, but, in the 1960’s,
there was no unquestionable evidences for that. The experiments showed
that the neutrino mass was quite small, but there was no proof for it
being different from zero. Invoking the Occam’s razor, the models were
built considering the neutrino as left-handed massless fermion [ 14 , 17
] , and the SM was assembled with this conjecture. Consequently, the SM
is as a chiral theory since the interactions affect differently the the
two fermion chiral types. Hereafter, we will introduce the SM
considering the basis for its construction, as the gauge principle and
the Higgs mechanism.

#### 1.2 The Standard Model in a nutshell

The modern theories are built considering the gauge principle ; this
principle expresses that a theory must be invariant under local (gauge)
phase transformations. Usually, when a free lagrangian possesses a
global symmetry, in such a way that there exists a conserved charge due
to the Noether’s theorem, it is imposed that such symmetry has to be a
local one. Under the new local symmetry the lagrangian is no longer
invariant. It is necessary to introduce new fields, with specific
transformation laws, that compensate for the extra terms. Afterwards, it
is noticed that the new fields, called gauge fields, mediate the
interactions among to particles present in the initial lagrangian. This
also can be viewed as the substitution of the partial derivatives for
covariant derivatives , derivatives which contain the gauge fields in a
specific manner. The best known example of a gauge theory is the Quantum
Electrodynamics (QED) [ 47 , 48 , 49 ] , the theory of the
electromagnetic interactions among electrons and positrons, which is
mediated by a gauge field, the photon. The QED is a prototype to
construct other gauge theories; the most important of all is the SM.

The SM is a theory for the strong, electromagnetic and weak fundamental
interactions [ 24 , 25 , 26 ] . One of its most important results is the
conspicuous unification between the electromagnetic and weak
interactions into the so-called Electroweak interaction. Given that our
purpose is to study the different properties of neutrinos, we will
concentrate ourselves on the electroweak part of the SM.

The accomplishments that the SM has presented since its formulation are
beyond any doubt. Distinct tests, in both theoretical and experimental
sides, have shown that this model gives an accurate description of
nature. Undoubtedly, the SM still has to resolve several issues
concerning, for instance, the set of parameters contained in the model.
The mathematical formulation of the SM has been the subject of
innumerable books, papers and thesis, many of which are far more
complete and detailed than the description below. The purpose of this
section will be to define the notation that will be used in this thesis
and the relevant components necessary for a complete subsequent
comprehension.

Technically speaking, the SM is a gauge theory whose symmetry group,
i.e. the group of the local transformations which leave the lagrangian
invariant, is SU @xmath U @xmath . The subscripts denote that the weak
interactions are left-handed ( @xmath ), and there exists an additional
abelian interaction, identified as hypercharge ( @xmath ). Regarding the
fields that compose the theory, we will classify them in three classes:
matter fields which are the fermion fields that constitute the matter of
the Universe; gauge fields, fields that carry the interactions, as
stated before; and the symmetry breaking fields, which are responsible
to give mass to the matter and gauge fields. In order to write a
consistent lagrangian, we need to define how our matter fields transform
under the symmetry group, and define the gauge fields by an appropriate
designation of the covariant derivatives.

The matter fields that compose the SM are divided in two categories,
depending on whether interact strongly or not: 6 quarks (up @xmath ,
down @xmath , charm @xmath , strange @xmath , top @xmath and bottom
@xmath ) and 6 leptons (electron @xmath , electron neutrino @xmath ,
muon @xmath , muon neutrino @xmath , tau @xmath , tau neutrino @xmath ).
They are grouped in three generations , each one composed by two quarks
and two leptons. These groups are not arbitrary, instead they are
arranged according to their increasing mass. From the point of view of
the gauge symmetry, each chiral component of the matter fermions
transforms in a different way. The left-handed matter fields will belong
to the fundamental representation of SU @xmath ² ² 2 For convenience, we
will consider the 4-component notation for the fermion fields. The
change among the notations is explicitly considered in the appendix B .
,

  -- -------- --
     @xmath   
  -- -------- --

being @xmath the generation (flavour) index, while the right-handed will
be singlets of SU @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Let us emphasize that the right-handed neutrinos are absent, in order to
keep the neutrino massless as a result of our previous discussions. For
the case of the hypercharge group, the charges of the matter fields are
given in table 1.1 . The lagrangian for the matter fields is given by,

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (1.3)
  -- -------- -------- -- -------

We introduced here the gauge fields, @xmath , @xmath , related to the SU
@xmath symmetry, and @xmath to the U @xmath one. These gauge fields are
spin-1 bosons, and we will denominate them simply by gauge bosons . The
parameters @xmath are the coupling constants of the interactions, and
@xmath are the generators of SU @xmath , @xmath . Let us note that there
exists a gauge boson for each generator of the SM group. The gauge
bosons also have a lagrangian that describes their kinetic terms,

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

where the field strength tensors @xmath and @xmath are

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (1.5a)
     @xmath   @xmath      (1.5b)
  -- -------- -------- -- --------

Let us mention here that the SU @xmath symmetry group in non-Abelian;
therefore, we expect to have self-interactions among the gauge bosons
related to this group. This is the reason why there is a term in ( 1.5a
) which is absent in ( 1.5b ).

The final interaction lagrangian will be simply the sum of the
lagrangians for the matter ( 1.2 ) and gauge ( 1.4 ) fields. All
possible electroweak interactions among the fermion fields is contained
there. This lagrangian is gauge invariant, by construction, and
renormalizable [ 50 , 51 ] . However, we encounter here three problems:
the charged fermions should have masses, which has been well established
by the experiments; second, it is not clear how the electromagnetic
interaction emerge in this model; and, third, the gauge bosons that
mediate the weak interaction should be also massive. Let us explore in
more detail the last difficulty. Experiments show that the range of the
weak interaction is finite. On the other hand, if one considers the
temporal component of a massive spin-1 boson, one finds that the
potential associated, denominated Yukawa potential , has a short range.
Thus, to explain the weak interactions, we need the gauge bosons to be
massive. The solution for this problem was found by Englert and Brout [
27 ] , Higgs [ 28 ] and Guralnik, Hagen and Kibble [ 29 ] .

##### 1.2.1 Mass Generation in the SM

The initial problem consisted in constructing a gauge invariant
lagrangian that possess mass terms for the gauge bosons and for the
fermions. An explicit mass term for those fields is not gauge invariant
since, for the case of the matter fields, the left- and right-handed
transform differently. The mechanism to give mass to the particles while
maintaining the gauge invariance is known as the Higgs mechanism . A
fundamental consequence of the application of this mechanism to the SM
is that a symmetry will remain unbroken, corresponding to the
electromagnetic interaction; or, in other words, the photon, will remain
massless. To implement the mechanism, we need to introduce a SU @xmath
doublet, composed of complex scalars,

  -- -------- --
     @xmath   
  -- -------- --

with a hypercharge given in table 1.1 . Then, we will need a lagrangian
to describe the scalar doublet,

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

the scalar potential @xmath is chosen to spontaneously break the gauge
symmetry. By this we mean that the potential has a minimum value, the
vacuum state, which is not invariant under the gauge symmetry. Thus, the
excited states over the vacuum will not manifest explicitly the
symmetry. Let us show this in some detail. The potential is given by

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

with @xmath and, also, @xmath . We see that this potential has a
minimum, @xmath , when @xmath . The crucial point here is that we can
choose the vacuum state without loss of generality ³ ³ 3 Initially, such
vacuum state can be taken in a general way, but after performing a gauge
transformation one can obtain the case we are considering. . We take

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , the vacuum expectation value (VEV) given by

  -- -------- --
     @xmath   
  -- -------- --

The choice of the vacuum is done to break the gauge symmetry. For
instance, applying the hypercharge operator @xmath , we have,

  -- -------- --
     @xmath   
  -- -------- --

which is non-zero. This implies that the vacuum has an hypercharge! Now,
let us compute the case of the third SU @xmath operator, @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

that is also non-zero. However, the combination @xmath gives us zero, so
that the vacuum is invariant under that combination,

  -- -------- --
     @xmath   
  -- -------- --

We can now define the electric charge operator, called
Gell-Mann–Nishijima operator, as

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

so, the electromagnetic interaction will remain unbroken. We can now
write explicitly the lagrangian in the broken phase. To do so, we write
the scalar doublet as

  -- -- -- -------
           (1.9)
  -- -- -- -------

being @xmath and @xmath scalar fields. The @xmath field are also known
as Goldstone bosons [ 52 ] , and they will be massless. Taking a gauge
transformation, these Goldstone fields can be hidden in the theory. In
fact, they are absorbed by the gauge bosons, becoming the longitudinal
polarization which a massive spin-1 particle has, but a massless one
does not. The kinetic part of the lagrangian ( 1.6 ) contains the
crucial terms,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (1.10)
  -- -------- -------- -- --------

so we can conclude here that, after the spontaneous symmetry breaking,
we obtain mass terms for the gauge bosons although there seems to appear
a mixing between @xmath and @xmath . This is solved when we define the
combinations,

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.11a)
     @xmath   @xmath      (1.11b)
     @xmath   @xmath      (1.11c)
  -- -------- -------- -- ---------

where the weak angle @xmath was introduced as

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

Substituting on the kinetic term, we have that

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (1.13)
  -- -------- -------- -- --------

so now is completely clear that three weak gauge bosons have mass,
@xmath , @xmath , @xmath ; while the fourth one, the photon @xmath , is
massless, as expected. Experimentally, all these particles have been
found which was one of the first triumphs of the SM. On the other hand,
we did not comment about the scalar field @xmath , the Higgs boson . As
we can see, this scalar have a mass @xmath which is not predicted by the
model. Nonetheless, a particle close to what is expected of the Higgs
boson behaviour was found in the LHC, with a mass of @xmath GeV [ 30 ,
31 ] . Studies still need to be done to affirm without doubt that this
particle is in fact the SM Higgs or other similar particle. The last
scenario seems more compelling, given that it opens a window to physics
beyond the SM.

Now, we need to write masses for the fermions. For that purpose, we need
to join the left- and right-handed chiral parts without explicitly
breaking the symmetry. A simple manner to do this is using the scalar
doublet @xmath , for instance, for the charged leptons

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

this term is gauge invariant. Note that this is a general term since the
Yukawa couplings matrix @xmath can be complex and non-diagonal. Thus, in
principle, it will be necessary to rotate to the physical states with a
defined mass. In the case of the charged leptons, we have after the
spontaneous symmetry breaking

  -- -------- --
     @xmath   
  -- -------- --

The rotation is achieved by defining the mass eigenstates @xmath as a
linear combination of the flavour eigenstates, @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

given that the matrices @xmath diagonalize the Yukawa matrix,

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we have that,

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (1.15)
  -- -------- -------- -- --------

so, we find that the charged leptons have masses @xmath , @xmath , and
couplings to the Higgs boson also proportional to their masses.
Obviously, the neutrinos are massless, as we wanted. But the SM do not
predict the values of the charged lepton masses, as the Yukawas are free
parameters. Here, a simple question may be asked: are there any
consequences of this mismatch between mass and flavour states? This
question may appear simple, but it is the basis for the confirmation of
the non-zero value of the neutrino masses. But before attacking the
neutrino sector, let us complete the fermion discussion with the quarks.
In this case, we have that in the Yukawa lagrangian we need to write two
types of terms,

  -- -------- -- --------
     @xmath      (1.16)
  -- -------- -- --------

This is because a term involving a quark doublet with the right-handed
up-like quarks @xmath cannot be written with the scalar doublet since it
would not be gauge invariant. Instead, it is necessary to consider the
conjugate doublet, @xmath , which also belongs to the fundamental
representation but has the opposite hypercharge (notice the similarity
with the two inequivalent representations of the Lorentz group, appendix
B ). On the other hand, the Yukawa matrices @xmath do not need to be
diagonal, as in the charged lepton case; it is required to diagonalize
those matrices by redefining the mass eigenstates, analogously to the
charged leptons,

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Again, we find that diagonalized lagrangian is

  -- -------- -- --------
     @xmath      (1.17)
  -- -------- -- --------

The quarks masses are not predicted by the SM, as in the case of the
leptons. However, there is a consequence of the discrepancy among
eigenstates. Let us define the charged current for quarks as,

  -- -------- -- --------
     @xmath      (1.18)
  -- -------- -- --------

After the diagonalization, we find that

  -- -------- -- --------
     @xmath      (1.19)
  -- -------- -- --------

where the Cabibbo-Kobayashi-Maskawa (CKM) matrix [ 53 , 54 ] , @xmath ,
was defined. This is a complex unitary matrix with 9 free parameters, in
principle. Nonetheless, it is possible to eliminate five phases by
re-shifting the quark fields, @xmath , remaining only four parameters.
This mixing matrix, understood as a rotation in the quark
"three-dimensional" space, is parametrized by three Euler angles @xmath
, and an additional phase, @xmath . This last parameter is related with
the CP violation that appears in the quark sector. Therefore, we see
manifestly the importance of the mixing for the High Energy Physics.
Experimentally, flavour-changing charged processes have been found,
proving of the non-diagonality of the CKM matrix. On the other hand,
Flavour-Changing Neutral Current (FNCN) processes in the SM are very
suppressed. Actually, they only occur at loop level, given that at tree
level the so-called Glashow-Iliopoulos-Maiani (GIM) mechanism forbids
these processes. In fact, there are experimental strong limits to these
FNCN, and these will constraint any new physics beyond the SM. Now, we
have completed our task. The fermions and the weak gauge bosons have
masses, while the photon is massless.

Finally, and for future convenience, let us introduce the ladder
operators,

  -- -------- --
     @xmath   
  -- -------- --

also, we define next the couplings of the left-handed ( @xmath ) and
right-handed ( @xmath @xmath ) matter fields with the @xmath boson:

-   leptons,

      -- -------- --
         @xmath   
      -- -------- --

-   quarks

      -- -------- --
         @xmath   
      -- -------- --

where the electromagnetic coupling, @xmath , appears explicitly. This is
the last piece of our construction of the SM. Let us write down in its
entire magnificence the SM lagrangian in the broken phase {mdframed}
[backgroundcolor=gray!20]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (1.20)
  -- -------- -------- -- --------

We see that electromagnetic and weak interactions are two facets of a
unique interaction, the electroweak interaction. The separation between
the two forces is a result of the spontaneous breaking due to the non
zero VEV of the scalar potential. Using our knowledge of Thermodynamics
and Cosmology, we can imagine that the universe should have been in an
unbroken phase where all the particles were massless and interacted with
a unique electroweak force. Then, due to the expansion of the universe,
a phase transition occurred, giving mass to the charged fermions and the
weak gauge bosons, while maintaining the electromagnetic symmetry intact
[ 42 ] . We can think if there is a fundamental reason for the
electromagnetic force be unaltered. However, any thoughts about this
will belong to the speculative realm. In any case, we can now focus our
study on the neutrino sector relevant for our purposes, considering
natural and artificial sources, and the experiments which have studied
these particles.

#### 1.3 Neutrino Sources

All possible neutrino interactions present in the SM lagrangian,
equation ( 1.2.1 ), allow us to understand several processes actually
happening in nature. Moreover, the different neutrino sources are
windows to comprehend the properties of the neutrino, and also analyse
if there are deviations from what is expected from the SM. There are
three basic types of neutrino sources: with an astrophysical origin,
such as the Solar, Supernova, galactic and cosmological neutrinos;
terrestrial, as the atmospheric and geoneutrinos; and artificial, like
the reactor and accelerator neutrinos. In the present thesis, we will
concentrate ourselves on the solar, atmospheric, reactor neutrinos,
together with the diffuse supernova and cosmic neutrino background. The
energy dependence of the flux of such neutrinos is in figure 1.1 . Let
us now study the four cases separately; the fifth case, the cosmic
neutrino background, will be considered in chapter 5 .

##### 1.3.1 Solar Neutrinos

Since the dawn of man, the Sun has been recognized by its immense
significance for Earth, inspiring several myths about its origin and
influence on the mankind. Nowadays, a complete picture about our star
has been established, as a plasma sphere which is maintained due to the
perfect balance between gravity and the radiation pressure, created by
the thermonuclear fusion of several elements. A crucial consequence is
that we now recognize the Sun as a huge source of neutrinos [ 55 ] .
Multiple experiments have detected neutrinos coming from our star,
allowing us to broaden our knowledge of these particles, and also about
the Sun itself, given that the neutrinos carry direct information
concerning the solar interior. The energy of the Sun is created by
thermonuclear processes, as concluded by Gamow and Bethe in the late
30’s [ 32 , 33 ] . There are two basic chains of these mechanisms in our
star: the pp-chain and CNO-cycle. In the pp-chain, two protons are
converted mainly in @xmath He through the fusion and/or decay of several
isotopes. In figure 1.2 , we present schematically this chain. Let us
explain this sequence in more detail.

Two hydrogen nuclei fuse together to form a deuterium nucleus in two
different manners: a direct @xmath fusion (99.6%) and in the presence of
an electron ( @xmath , 0.4%). In both cases a neutrino is produced,
which are denominated @xmath and @xmath neutrinos . The @xmath neutrinos
are mono-energetic since they are produced in a three body collision.
Next, the deuterium fuses with another proton to form helium-3. After
this, the helium-3 has three possibilities to interact. In the first
one, it fuses with another helium-3 to form 2 protons plus an @xmath He
nuclei; this occurs 85% of the times. The second possibility is to
interact with an helium-4, to produce beryllium-7, and the third one is
to fuse with a proton to create again an @xmath He isotope but with the
production of a neutrino, called @xmath neutrino . Later, the
beryllium-7 isotope also interacts in two different fashions: with an
electron, it produces lithium-7 with the emission of a neutrino,
labelled @xmath Be neutrino ; this lithium-7 fuses with a proton to form
2 helium-4 nuclei together with the emission of energy. Besides, if the
beryllium-7 interacts with a proton, this will create a boron-8 nuclei.
The boron-8 nuclei decays to an excited state of beryllium-8 with the
emission of a neutrino, the @xmath B neutrino . Finally, the excited
state decays into two helium-4 nuclei, completing the chain. In addition
to the pp-chain, the CNO cycle is also present in the Sun. This cycle,
outlined in figure 1.3 , is composed by two different branches in which
the @xmath C, @xmath N, @xmath O isotopes interact with hydrogen nuclei
to produce each other, and the @xmath N, @xmath O, @xmath F nuclei.
These last three isotopes decay producing neutrinos, which are labelled
according to the initial decaying isotope. It is important to note that
in the case of the Sun, the CNO cycle is only responsible for @xmath of
the energy it produces. However, for stars which higher temperatures,
this cycle becomes dominant [ 56 ] .

These chains have been extensively studied to estimate the flux and the
spectrum of the solar neutrinos. The denominated Standard Solar Model [
57 ] has been established from such studies. The neutrino fluxes and
spectra are computed considering the hydrodynamic evolution of our star
from some boundary conditions that reproduce the current values of the
solar characteristics. The complete solar neutrino flux is of the order
of @xmath cm @xmath s @xmath . For each type of the neutrino, the total
flux with its corresponding uncertainty is given in table 1.2 . In the
present Thesis, we are considering the Bahcall-Serenelli-Basu (BSB05)
Solar Standard Model [ 58 ] , with the input abundance of the heavy
elements in the Sun given by Grevesse-Sauval work (GS98) [ 59 ] .

The solar neutrino spectra obtained in the Solar Standard model can be
fitted by a polynomial of order nine [ 60 ] ,

  -- -------- -- --------
     @xmath      (1.21)
  -- -------- -- --------

with @xmath a normalization factor

  -- -------- -- --------
     @xmath      (1.22)
  -- -------- -- --------

@xmath the maximum neutrino energy for each component, see table 1.2 ,
and @xmath are the fitting parameters, given in table 1.3 . In figure
1.4 we show the dependence of the spectra on the energy. We see clearly
that for small neutrino energies, the flux is dominated by the @xmath
neutrinos, as expected, while for energies larger that @xmath MeV, the
solar neutrino flux is dominated by the @xmath B and @xmath neutrinos.
This energy dependence will be important in the next chapters.

Since the late 1960’s, several experiments have detected the solar
neutrino flux. The pioneering Homestake Chlorine experiment [ 34 ] was
capable of detecting specially the @xmath B neutrinos, given its
threshold energy of @xmath MeV [ 34 ] . However, the measured flux was
about one third of the expected one; this difference was denominated as
the solar neutrino problem . Some other experiments, such as the GALLium
Experiment (GALLEX) [ 61 ] , the Soviet-American Gallium Experiment
(SAGE) [ 62 ] , had similar results: the flux of the solar neutrinos was
lower than the models estimated.

Given that these three experiments were insensitive to the incoming
direction, other types of experiments were proposed to confirm the solar
origin of the detected neutrinos. These pioneering experiments used as
physical principle of the detection the Cherenkov process. The
Kamiokande [ 63 ] , and its successor, SuperKamiokande [ 64 ] , and the
Sudbury Neutrino Observatory (SNO) [ 36 ] experiments validated the
solar provenance of the neutrinos and also their diminished flux.
Nonetheless, the SNO experiment elucidated the situation given that they
were capable of identifying solar neutrinos in three manners: through
charged and neutral current interactions and electron scattering
processes. For the charged interactions, sensitive to the neutrino
flavour, they found that the flux was indeed smaller than predicted,
but, in the neutral current and scattering cases, they discovered that
the estimation from the Solar Standard Model was in agreement with their
results [ 36 ] . This showed that the "problem" was not related with the
Sun’s model, but with the neutrinos! In some way, the electron neutrinos
were metamorphosed to muon and tau neutrinos in its way to the Earth.
The complete explanation is that neutrinos suffer an adiabatic flavour
conversion inside the solar medium [ 65 ] . Yet, we will discuss this
process in the final section of these chapter; hereafter, we will
continue considering the neutrino sources.

##### 1.3.2 Atmospheric Neutrinos

The Earth is constantly under a shower of cosmic rays, composed
principally of protons. Their interactions with the atmosphere produce a
cascade of other particles, in special, pions and muons. The decay of
these particles creates an additional source of neutrinos, called for
clear reasons atmospheric neutrinos. For instance, the pions decay
primarily to muons which in turn decay to electrons and positrons, with
the emission of electron neutrinos and muon antineutrinos

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The energy range of these neutrinos is quite broad, from @xmath MeV to
@xmath TeV [ 55 ] . For low energies, @xmath GeV, which corresponds to
the case where almost all muons decay in the atmosphere, the previous
chain of decays shows that the following ratios between the fluxes
should be satisfied in an experiment if the neutrinos do not mutate into
other types,

  -- -------- -- --------
     @xmath      (1.23)
  -- -------- -- --------

Given that in a unique pion decay a muon neutrino-antineutrino pair is
produced, together with an electron neutrino or antineutrino (depending
on the charge of the initial pion), the ratio between the sum of the
muon neutrino and antineutrino flux should be twice the sum of the
electron neutrino and antineutrino flux. Let us note that if the
experiment is sensitive to the direction of the incoming (anti)neutrino,
we can even further determine the dependence of the fluxes with the
zenith angle of the experiment. These angle distributions showed that in
fact neutrinos suffer oscillations, a consequence of the existence of
masses and mixing. This was demonstrated by the SuperKamiokande [ 37 ,
38 ] , the MACRO [ 67 ] and the more recent IceCube Neutrino Observatory
[ 68 ] .

The complete computation of the atmospheric neutrino and antineutrino
flux needs to take into account the full cosmic rays spectrum and all
the possible interactions that can occur between the cosmic rays and the
atmosphere. Also, it is needed to know the model for the atmosphere. For
our future purposes, we will consider the results from the group of G.
Battistoni et. al. [ 66 ] . Let us keep in mind that these fluxes have
an uncertainty of @xmath . In figure 1.5 , we show the dependence of the
atmospheric neutrinos fluxes with the energy.

##### 1.3.3 Reactor Antineutrinos

The first technological achievement related to the discoveries and
theoretical advances in the Weak interaction physics was the creation of
a self-sustained nuclear chain reaction, and the subsequent elaboration
of a nuclear reactor. In these electricity generators, a set of isotopes
undergo fission due to the absorption of a neutron. The fission products
are usually unstable and rich in neutrons, generating approximately six
antineutrinos after decaying weakly. In average, @xmath are produced in
a 3 GW reactor [ 69 ] . Following closely [ 69 ] , we are going to
introduce the main pieces to determine the reactor antineutrino flux for
any place on the Earth. This will be used in the chapter 6 .

Let us note that the determination of the antineutrino spectra has two
separated contributions. The first one is related to the specific
properties of the reactor. A generic nuclear reactor is characterized by
its thermal power ( @xmath ) and the Load Factor ( @xmath ),
corresponding to the percentage of energy that a reactor has produced
over a time period compared to the energy it would have produced if it
were operating continuously at the reference power in the same period.
These two features are published each year by the International Atomic
Energy Agency (IAEA).

On the other hand, the antineutrino spectrum will depend on the details
of the beta decays of the fission products. In a typical reactor, there
are four isotopes, @xmath , @xmath , that undergo fission. For a given
reactor, the antineutrino spectrum is [ 69 ]

  -- -------- --
     @xmath   
  -- -------- --

where the sum is over the four isotopes, @xmath is the number of
fissions per second for each isotope; @xmath is the antineutrino
spectrum for one fission [ 69 , 70 ] . The thermal power produced by the
reactor is given by

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the energy released by each isotope. The values of the
@xmath for the isotopes under consideration can be found in table 1.4 .
Next, we introduce the power fraction @xmath , corresponding to the
fraction of the total thermal power created by the isotope @xmath [ 69 ,
70 ] , as

  -- -------- -- --------
     @xmath      (1.24)
  -- -------- -- --------

These power fractions depend on the type of reactor. We will consider
basically five types of reactors: Pressurized Water Reactors (PWR),
Boiling Water Reactors (BWR), Pressurized Heavy Water Reactors (PHWR),
Light Water Graphite Reactors (LWGR) and Gas Cooled Reactors (GCR) [ 69
, 72 ] . The power fractions for these reactors are in table 1.5 . Also,
if the reactor uses Mixed OXide fuel (MOX) as @xmath of the combustible,
the power fractions are slightly modified, see table 1.5 [ 69 , 72 ] .
So, we can write

  -- -------- --
     @xmath   
  -- -------- --

Now, to obtain the antineutrino spectrum per fission, @xmath , one has
to analyze the chain of decays originated form the fission. But given
that our purposes are not to study this computation, we give next the
result of Müller et. al. for the spectrum [ 74 ] . In such a work, after
the complete calculation, the spectrum is fitted for all those four
contributing isotopes in terms of the exponential of a order 5
polynomial,

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

note that this function has units of [energy] @xmath . The values of the
parameters @xmath are in table 1.6 . The flux of reactor antineutrinos
at any point on the Earth is then obtained supposing an isotropic
emission,

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

Here, the sum over @xmath is made over all reactors on the Earth, @xmath
is the average of the Load Factor over a given time and @xmath is the
distance between the reactor and the location on the Earth. In figure
1.6 , we considered the data corresponding to the year 2015, and the
distance to the laboratory is computed considering an spherical Earth ⁴
⁴ 4 The data to compute the flux has been taken from the source
maintained by the same authors of [ 69 ] . Their website is:
http://www.fe.infn.it/antineutrino/ . We determined the flux for five
laboratories:

-   Laboratoire Souterrain de Modane (LSM), France.

-   원자로 중성미자 진동 실험 (Reactor Experiment for Neutrino
    Oscillation – RENO), Korea.

-   Laboratori Nazionali del Gran Sasso (LNGS), Italy.

-   Sanford Underground Research Facility (SURF), USA.

-   中国锦屏地下实验室 – China Jinping Underground Laboratory (CJPL),
    China.

As expected, we see that in the places where there are several reactors
near by the flux expected there is high, as for the RENO and LSM cases.
For the LNGS, the flux is one order of magnitude less than in the LSM.
For SURF and CJPL, the flux is even smaller. Finally, for the remainder
of the work, we will consider a conservative @xmath uncertainty in the
neutrino fluxes [ 75 , 76 ] .

The first detection of an antineutrino was done by Cowan and Reines
using the reactor at the Savanna River Plant [ 21 ] . Ever since,
several experiments have been performed with the reactor antineutrinos.
The principle of detection is quite simple, using the inverse beta
decay, @xmath . The reactor experiments are divided according to the
distance from the core. The short-baseline experiments have a distance
of @xmath , while the long-baseline ones correspond to distances of
@xmath km. The third category is for the case of @xmath km,
corresponding to very-long-baseline experiments. Given the results from
solar neutrinos, the reactor experiments were searching the
disappearance of antineutrinos and its dependence with the distance. The
most recent experiments, the Daya-Bay Experiment [ 77 ] , RENO [ 78 ] ,
and KamLAND [ 39 ] h ave found results consistent with the disappearance
of the antineutrinos, confirming the non zero value of the neutrino mass
and the oscillation phenomena.

##### 1.3.4 Diffuse Supernova Neutrino Background

From the time of the birth of the first star, supernovae explosions have
been occurring in the Universe. These gigantic events have created a
flux of neutrinos and antineutrinos, denominated diffuse supernova
neutrino background (DSNB) [ 79 ] . Although this background has not
been observed yet, it is expected to be seen by future experiments [ 80
] . Let us note that this discovery would have a profound impact on our
knowledge not only about neutrinos but also regarding supernovae,
opening another window to understand our Universe. The DSNB depends on
the rate in which supernovae happen, and on how neutrinos have been
emitted in the explosion. As well stressed before, our purpose here will
not be to give the details of the complete computation of these factors,
but to make explicit the parameters and definitions we will use later in
the development of the thesis. We suggest the interested reader to see
the J. Beacom review [ 80 ] and some other papers [ 79 , 81 ] .

The first part, the rate in which supernovae occur in the Universe, can
be related to the cosmic star formation history, which is obtained by
direct measurements. We will adopt the continuous broken power law as a
function of the redshift [ 80 ] ,

  -- -- --
        
  -- -- --

where @xmath is a normalization constant, @xmath , @xmath , @xmath ,
@xmath are constants related to the redshift regimes [ 81 ] , and the
@xmath parameters are related to the redshift breaks, given by [ 81 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.27a)
     @xmath   @xmath      (1.27b)
  -- -------- -------- -- ---------

The values of the previous parameters are in table 1.7 . The rate of
neutrino emitting supernovae, in terms of the Solar mass @xmath , is
fitted to be [ 80 , 81 ]

  -- -------- --
     @xmath   
  -- -------- --

Now, the second component, the neutrino emission in the supernova, will
depend on the fraction of the total energy that has been taken by these
particles. Also, let us note that all three flavors of neutrinos and
antineutrinos are created, and each species takes an equal part.
Supernovae simulations have shown that the energy spectrum of the
neutrinos is well approximated by a Fermi-Dirac thermal distribution [
81 ]

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

where @xmath MeV is the total energy, @xmath is the effective
antineutrino temperature outside the protoneutron star. Having the two
main ingredients to construct the DSNB, we finally are able to compute
the flux [ 81 ] ,

  -- -------- -- --------
     @xmath      (1.29)
  -- -------- -- --------

where @xmath is the maximum redshift to compute the flux, @xmath ;
@xmath is the relation between the energy at the creation time and the
current energy, and

  -- -------- -- --------
     @xmath      (1.30)
  -- -------- -- --------

In the literature [ 81 , 80 ] , the DSNB is basically composed by the
electron antineutrino flux with temperatures of @xmath MeV. In figure
1.7 we show the spectrum of the DSNB for these three scenarios. Let us
stress that the systematic uncertainty of this flux is about @xmath .
Although the DSNB has not been found experimentally, there are good
prospects to find them in the Superkamiokande experiment [ 81 ] .
However, as we will see later, the existences of this cosmological flux
has an impact in some future experiments to be performed here on the
Earth.

Nonetheless, before getting to that point, we have now seen that
experiments from different sources has shown that neutrinos undergo
flavour oscillations in their travel between the source and the
detector. This is a fundamental proof that the neutrinos are indeed
massive particles. To understand in detail this, let us now introduce
the neutrino oscillations and its current status.

#### 1.4 Neutrino Oscillations

As we have seen in the previous section, experimental evidences show
that neutrinos metamorphose into another flavour in its journey between
a source and a detector. To describe in the standard manner this
process, let us start in an analogous way to what was done in the quark
sector. Supposing that the neutrinos are massive particles, having
masses equal to @xmath , and the flavour states that do not have
definite masses, we can write the flavour fields as a superposition of
the mass fields [ 82 , 83 ]

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

Then, the charged current for the leptons becomes,

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

with the definition of the Pontecorvo-Maki-Nakagawa-Sakata (PMNS) matrix
@xmath [ 82 , 83 ] , the analogous to the CKM matrix in the lepton
sector. Let us note that at this point we are not considering the origin
of the masses and the mixing of neutrinos; this will be our task in the
next chapters. Anyhow, if in a weak processes a neutrino is created by a
charged interaction, it will have a definite flavour, corresponding to
the flavour of the associated charged lepton created. Therefore, as we
have seen, the flavour eigenstate will be a superposition of the mass
eigenstate ⁵ ⁵ 5 For simplicity in the notation, from now on we will
remove the PMNS and CKM indexes; so, to avoid confusion, the PMNS matrix
will always have the symbol @xmath and the CKM matrix @xmath .

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

Let us stress that in the previous relation between flavour and mass
eigenstates appears the PMNS matrix. This is due to the fact that a
neutrino is created by a charged current process, which depends on such
a matrix, eq. 1.32 . If the neutrino is created in a neutral current
interaction, the neutrino will not have a definite flavour. However,
given that there are not flavour-changing neutral currents in the lepton
sector, a neutrino with a definite flavour will not undergo a flavour
change by neutral interactions, i.e. the mixing is not affected by
interactions with the Z boson.

If a neutrino is created in some point with a definite flavour at some
initial time @xmath , @xmath , we will be interested in determine the
probability of a detection of the neutrino with flavour @xmath in some
different point, given by [ 55 ]

  -- -------- -- --------
     @xmath      (1.34)
  -- -------- -- --------

with @xmath the evolution operator in space and time. Since the mass of
the neutrinos is usually smaller than the energy in which they are
produced, we can safely approximate that they travel at the light speed
@xmath , so the distance between the production and the detection is
equal to the time spent in the process, @xmath . Furthermore, if the
neutrino propagates in vacuum, we can take it as a free particle; the
evolution operator will be related to the free hamiltonian in a simple
manner,

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

The mass eigenstates are also energy eigenstates as the hamiltonian is a
free one. Therefore

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (1.36)
  -- -------- -------- -- --------

with the energy @xmath well aproximated to [ 55 ]

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Here we used that the momentum of the neutrino is approximately equal to
the neutrino energy @xmath , which is practically equal for all flavours
in this ultrarelativistic regime. Using these approximations, we have
that the probability @xmath is then

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

where @xmath , and @xmath . In 1.37 we wrote explicitly the sums over
@xmath to avoid confusion, given that there is no sum over @xmath and
@xmath .

Let us comment here that a neutrino oscillation experiment is only
sensitive to the squared mass difference, @xmath ; the real scale of the
neutrino masses needs to be studied by other phenomena. Experimentally,
there are two types of processes corresponding to the possible values of
@xmath . If @xmath , the experiment will be a disappearance one since
the experiment will seek a difference between the expected number of
neutrinos in the detector compared to the observed number. This is the
case of the solar and reactor experiments. While if the final flavour is
different from the initial one, @xmath , we will consider an appearance
experiment inasmuch as the detector will observe neutrinos in a flavour
that is not expected in the production process. The most known
appearance experiments are those that study neutrinos from accelerators
[ 55 ] . In this case, the flux of neutrinos is build to have some
specific flavour, and the detectors look for the other flavours.

Keeping in mind the analogy between the PMNS matrix with a rotation in
the flavour space as in the quark sector, it is costumary to write this
mixing matrix in terms of three angles @xmath and a CP-violating phase
@xmath as

  -- -------- -- --------
     @xmath      (1.38)
  -- -------- -- --------

where we used a simplified notation with @xmath and @xmath . In a given
experiment, the measurements will constrain both the mixing angle and
the squared mass difference of relevance for the channel in which the
searching of oscillations has been performed. A global fit for all the
neutrino oscillation experiments has been done by Esteban et. al. [ 84 ]
⁶ ⁶ 6 These authors maintain a website with the updated global fit for
the neutrino oscillations, http://www.nu-fit.org/ . . The last results
of the oscillation parameters global fit, from November - 2017, are
given in table 1.8 . From these results, it is clear that the
CP-violation phase is unknown. However, several experiments are being
proposed to measure this very important phase [ 85 , 86 ] . The
relevance of this phase will be clear in the next chapter.

On the other hand, since the real value of the neutrino masses are not
known, there are two possible structures for these masses that are in
agreement with the data. These arrangements, called Normal and Inverted
Orderings , are possible given that the lightest neutrino is unknown.
The lightest eigenstate can be the @xmath (normal ordering), which
corresponds to the neutrino mass eigenstate mostly composed by electron
flavour state, or the @xmath (inverted ordering) mass eigenstate, the
eigenstate which has the least electron flavour composition [ 55 ] . In
figure 1.8 we show schematically these possibilities.

In order to obtain the previous relations, we considered that the
neutrino was propagating in vacuum. However, there exist the possibility
of propagating in a dense medium such as the case of solar neutrinos. In
that case, it will be necessary to solve the complete Schödinger
equation in the presence of the medium,

  -- -------- -- --------
     @xmath      (1.39)
  -- -------- -- --------

where the hamiltonian will be

  -- -------- --
     @xmath   
  -- -------- --

being @xmath the free hamiltonian and @xmath the effective potential.
This potential can be obtained considering the interactions that a
neutrino will have in its journey in the medium. In the SM, both charged
and neutral current interactions can affect the neutrino, creating the
effective matter potential for a neutral homogeneous medium

  -- -------- -- --------
     @xmath      (1.40)
  -- -------- -- --------

where @xmath is the electron density and @xmath is the neutron one. It
is possible to show that the neutral current contribution will be
irrelevant for neutrino oscillations since it is common for the three
flavours. In practice, the matter potential can be interpreted as a
modification of the mixing angle and the squared mass difference. In a
medium, the neutrino has an effective mixing and mass difference
dependent on the effective potential [ 55 ] . This has an important
consequence [ 87 , 88 ] : it is possible to have a resonance of the
probability when the effective mixing angle is @xmath . This effect,
called the Mikheev-Smirnov-Wolfstein (MSW) effect, is the final
explanation of the solar neutrino problem [ 87 , 88 ] . It shows that
the deficit in the solar neutrino experiments is due to the adiabatic
flavour conversion in the solar medium [ 64 , 36 , 65 ] .

In summary, in the present chapter we have introduced the basis for the
development of this thesis. We have presented the basics of the SM,
giving emphasis to the mass generation in the model since the Higgs
sector is under experimental test in the LHC. We also introduced the
important definitions of mixing, showing that the SM does not predict
the precise values of the fermion masses, but it predicts the absence of
flavour-changing neutral current processes. The SM also predicts the
masses of the @xmath and @xmath bosons and the massless photon.
Nonetheless, the mass of the residual scalar, the Higgs boson, is not
predicted.

Afterwards, we focused on the relevant neutrino sources to be used in
the present manuscript, and showed the main components for studying
them. Solar, atmospheric neutrinos and reactor antineutrinos have been
observed experimentally while the diffuse supernova neutrino background
lacks a experimental proof. The experiments have shown that the
neutrinos metamorphose into each other after being created in a specific
processes. This conversion is a proof of the non zero value of the
neutrino masses, see the discussion from A. Smirnov [ 65 ] . The
neutrino oscillations phenomena gives a simple explanation: the flavour
states, created in charged current interactions, do not have a definite
mass which creates a non zero probability of detecting a different
flavour to the one created. Now we have at first glance a picture of
neutrino oscillations and the basic phenomena related to it. However, as
we mentioned before, the origin of the neutrino mass was not taken into
account. Furthermore, we can ask ourselves if there is a fundamental
reason for the PMNS matrix to have the form [ 84 ]

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

which is completely different from the CKM matrix, corresponding
approximately to an identity matrix. There are still some other open
questions about the neutrino masses regarding the ordering, which
eigenstates is the lightest neutrino, and also the value of the
CP-violation phase. Future experiments are being planned to shed some
light on these issues [ 85 , 86 ] . But, from the point of view of the
author, the basic question concerning the neutrinos is related to the
fundamental nature of these particles. As we have seen before, neutrinos
are the only fundamental fermions that can be Dirac or Majorana
particles. So, we can ask ourselves if there is a connexion between the
true nature of the neutrino and the smallness of their masses. Let us
note that there is no definitive answer to these questions. Several
models have been proposed to understand the true nature of the neutrino.
Such discussion will be the task for the next chapters. Concretely, we
will consider the neutrinos as Majorana fermions in the next chapter,
and see the different consequences of this case.

### Chapter 2 Majorana Neutrinos \lettrine

Neutrinos stand out undoubtedly from the other elementary particles due
to their peculiarities. Notably, the absence of electric charge make
their nature unclear; this is an additional problems which charged
leptons and quarks do not possess. Majorana particles appeared as a
solution to the negative energy problem, intrinsic to the Dirac
formalism, by introducing an improved quantization method [ 41 ] .
Majorana obtained that it is not necessary to presume the existence of
antiparticles when the particle is neutral. In other words, the Majorana
fermion is its own antiparticle, analogous to a real scalar field.
Evidently, we see that this is a quite simpler description for a neutral
fermion. Nonetheless, Physics is an experimental science, and
experiences will be the ultimate source of elucidation regarding the
true neutrino nature. On the other hand, the smallness of neutrino
masses constitutes an enigma to elementary particle physics. Certainly,
the origin of all fermion masses is by itself an unsolved problem since
the Yukawa couplings are not predicted by the SM as previously shown.
However, the large difference between neutrinos and charged leptons
masses may indicate a different origin for neutrino masses. The see-saw
mechanism gives an explanation to this difference; the left-handed
neutrinos masses are suppressed by the mass of heavy states. The main
inconvenient of this scenario is the lack of a direct proof of its
validity since the involved energy scales go beyond the current reaches.
Yet, Fukugita and Yanagida [ 89 ] found a connexion between the see-saw
mechanism and the absence of antimatter in our Universe through the
process named leptogenesis . In this chapter, we will consider the
essential properties of neutrinos supposing them as Majorana fermions.
For that purpose the fundamental properties of such fermions will be
analysed as basis to introduce the see-saw mechanism in its three forms.
Thenceforth, we will investigate the leptogenesis scenario in its
standard form, addressing its main characteristics.

#### 2.1 Majorana Fermions

The pioneering work of Majorana [ 41 ] proposed a symmetric theory of
the electron and the positron through a generalization of the
variational principle to Grassmann (anticommuting) variables. Majorana
asked what are the conditions for a massive fermion to be described by a
Weyl spinor; he found that the basic prerequisite is that the particle
has to be its own antiparticle. Evidently, this means that Majorana
fermions are completely neutral. Let us describe below the principal
characteristics of this class of fermions. In this section, we will
consider the notation of two-component fermions; after that, we will
return to the usual four-component notation. The lagrangian describing a
left-handed Majorana particle in this case will be ¹ ¹ 1 The details of
the derivation of this lagrangian are given in appendix B . [ 90 ]

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

This lagrangian is built considering the anticommuting character of
@xmath . If this condition were not true, the mass term would be
trivially zero (see appendix B ). We are also writing the terms with
dimension equal to four, without introducing new particles, i.e.,
supposing a free particle. The equation of motion for the particle,
which we will denote as Majorana equation, is given by

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

An important consequence appears at this point; the Majorana fermion
@xmath cannot be treated as a particle in the usual sense, but it needs
to be treated as a field from the beginning. In the rest frame of the
fermion, we have that there are two independent solutions [ 91 ]

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath Grassmann variables; it is evident that

  -- -------- --
     @xmath   
  -- -------- --

so the solutions are not eigenstates of the @xmath operator. In other
words, there are not travelling wave solutions that could be interpreted
as particles [ 91 ] . Therefore, we need to start by considering the
quantization of the Majorana field.

On the other hand, regarding the number of degrees of freedom, it is
possible to show that a Majorana fermion possesses half the degrees of
freedom of a Dirac one. This can be proved considering its properties
under the CPT operations and Lorentz transformations [ 55 ] . A Majorana
field will have two possible states for a given momentum

  -- -------- --
     @xmath   
  -- -------- --

where @xmath stands here for the helicity. Let us stress that the field
@xmath has a definite chirality, left-handed in the specific case we are
treating, but it also has the two distinct helicities, showing
definitely the unequivalence between chirality and helicity. In addition
to this, a crucial property of Majorana fermions is explicit in this
two-component notation. After quantizing the field in a canonical manner
by introducing appropriate anticommutators between the fields and their
canonical conjugate momenta, it is possible to determine the two-point
function associated to the Majorana fermion. Actually, there are two
possible manners to define the Feynman propagator in this case,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the time-ordering operator. This is a consequence of the
same field @xmath being able to create and annihilate the fermion.
Therefore, there are additional Wick contractions when compared to the
Dirac case [ 92 ] . Explicitly, we have that

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (2.3a)
     @xmath   @xmath      (2.3b)
  -- -------- -------- -- --------

with @xmath . To comprehend these two different propagators, let us make
the comparison with the Dirac case. There, the existence of two
different particles would make the second type of propagator vanishing;
this is due to the conservation of the charge that a Dirac fermion
carries, denominated fermion number. The Feynman propagators for Dirac
particles indicate this conservation graphically using an arrow.
However, for a Majorana fermion, there is no conservation of the fermion
number, which is described symbolically by a line with two arrows
pointing in opposite directions [ 92 ] . This is the information
contained in the second type of propagator. Let us stress that this
additional Feynman propagator is proportional to the mass of the field.
Thus, we expect that the processes where there is a violation of the
fermion number are proportional to the mass of the particle in the
propagator. This has an important consequence in the neutrinoless double
beta decay , decay which may occur if neutrinos are Majorana particles.
There are many works considering this neutrinoless decay; for the
interested reader we indicate the works from Schechter et. al. [ 93 ]
and Duerr et. al. [ 94 ] , which show what are the minimal requirements
for this decay to happen and for it to be a definite proof of the
Majorana nature of the neutrino.

#### 2.2 Weinberg Operator

The previous discussion was done for a generic Majorana fermion; let us
now consider the case we are interested on, the neutrino case. We now
return to the four-component notation by making the substitutions

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where @xmath is a four-component field and @xmath is the charge
conjugation matrix, see appendix A . The Majorana lagrangian is given by

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

with the usual definition of the charged conjugated field,

  -- -------- --
     @xmath   
  -- -------- --

Our task next will be to consider how to obtain a Majorana mass term, as
the one appearing in 2.5 , in terms of SU @xmath U @xmath invariant
operators. Let us note that the mass term is built with the left-handed
component of the neutrino. However, such term has an hypercharge of
@xmath ; we would need a triplet to construct a SU( @xmath ) @xmath
invariant term. Such triplet does not exists in the SM. Nonetheless, let
us remember that the SM is not considered a complete and final
description of the nature given that there are many aspects it cannot
explain in a satisfactory way. Thus, it is an essential work to consider
non-renormalizable terms. This is not new at all; the SM was built from
a non-renormalizable lagrangian, the Fermi description of the weak
interaction. Therefore, the SM is itself a great example of a theory
built as a Ultraviolet completion of an approximate model. Weinberg [ 95
] considered the lowest non-renormalizable terms built with the SM
matter fields which are gauge invariant. He wrote the following
dimension-5 operator

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

with @xmath some coupling constants and @xmath is a parameter with
dimension of mass. After the electroweak symmetry breaking, we get a
term

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

which corresponds to a Majorana mass term. We see that the lowest
non-renormalizable operator, which respects the SM gauge group, gives
mass to the neutrino. Another important point should be noted at this
point. Given that this term should be suppressed at electroweak scales,
the mass scale is larger than the VEV of the Higgs field, @xmath ,
making the neutrino mass also suppressed when compared to the rest of
the fermions. This is a significant result, we have proven that the
dimension-5 operator, which we will call as Weinberg operator [ 95 , 96
, 55 ] , explains the smallness of mass and the nature of the neutrino.

#### 2.3 See-saw Mechanism

It has been shown that the Weinberg operator can be obtained from a UV
theory in three different minimal manners [ 96 ] . These three cases are
denominated as See-saw mechanisms of type I, II and III. The reason for
such a name will be clear below. Evidently, there exists a large variety
of non-minimal models that can give rise to the dimension-five operator.
Nonetheless, we will consider here the basic three cases.

##### 2.3.1 Type I

In the simplest case we will introduce three right-handed singlet
neutrinos @xmath ( @xmath ) to the particle content of the SM [ 97 , 98
, 99 ] . These neutrinos can have a Majorana mass term given that they
have no SM charge

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

On the other hand, we can write also terms coupling left- and
right-handed neutrinos as the quarks’ case,

  -- -------- --
     @xmath   
  -- -------- --

notice the equivalence with the term for the up-type quarks. Therefore,
in general, we will have a mass term composed of these two terms,

  -- -------- -------- -- -------
     @xmath   @xmath      (2.8)
  -- -------- -------- -- -------

Such lagrangian is usually called Dirac-Majorana mass term. Let us
stress here that, differently from the other fermions, neutrinos are the
only SM matter fields which can have Majorana and Dirac terms
simultaneously. However, the true nature of neutrinos is hidden here. If
we rewrite the Dirac-Majorana mass term after the electroweak symmetry
breaking as

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

with

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

it is clear here that left- and right-handed neutrinos do not possess
definite mass due to the existence of the Dirac term. However, it is
possible to diagonalize the general term by considering a rotation in
the fields

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

Let us note that, differently from the charged fermions, the previous
diagonalization is achieved by an orthogonal transformation. This is
originated in the structure of the Majorana mass term since it can be
written as

  -- -------- --
     @xmath   
  -- -------- --

After the diagonalization, it is clear that the mass eigenstates are
Majorana fermions: their mass term is

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

which correspond to a Majorana mass term. The previous discussion was
general in the sense that we have not considered any explanation for the
smallness of neutrino masses. However, it is important to note that the
right-handed masses are not constrained by the electroweak scale; they
can be originated from new physics at higher scales. For instance, in
Grand Unified Theories (GUT), theories that consider the unification of
the Electroweak and Strong forces, it is usually needed to include
right-handed neutrinos, in such a way that their masses can be of the
order of the GUT symmetry breaking scale, approximately @xmath GeV.

In any case, we can suppose that the right-handed neutrinos masses are
larger compared to the electroweak scale. This allow us to diagonalize
the mass matrix explicitly in the case in which the eigenvalues of the
right-handed mass matrix are larger than those of the Dirac term, i.e

  -- -------- --
     @xmath   
  -- -------- --

Thus, it is possible to show that the active neutrino mass matrix is
then

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

therefore, we see that the mass of active neutrinos is proportional to
the inverse of the mass of the right-handed neutrinos. Furthermore,
considering that @xmath GeV, and choosing a yukawa of order one, we get
that active neutrino masses can be of order @xmath eV, which is of the
same order of the limit from PLANCK recent result on the sum of neutrino
masses [ 45 ] . This is the see-saw mechanism, given that increasing the
right-handed mass values, the active neutrino masses decreases. However,
a direct detection of a right-handed neutrino with a mass as large as
the one considered previously is beyond any future experiment. Thus,
there are several models in which the @xmath TeV, making it possible to
be searched at the LHC. Nonetheless, up to this moment the see-saw
mechanism has not yet been tested.

##### 2.3.2 Type II

The second possibility to obtain the Weinberg operator consists in
introducing a scalar triplet @xmath with an hypercharge @xmath [ 100 ] .
This triplet will transform in the adjoint representation of the SU
@xmath group. Our purpose here does not consist in studying in a great
detail this scenario, so we will briefly give the main results. In this
case, the lagrangian is given by

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

with the scalar potential @xmath being

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (2.16)
  -- -------- -------- -- --------

On the other hand, the Yukawa lagrangian, responsible to give mass to
neutrinos, is

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

in such a way that, when the neutral component of the triplet gets a
vev, the neutrino eigenstate @xmath gets a mass of

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

The relationship for the triplet vev @xmath was obtained considering the
properties of the scalar potential [ 101 ] . We can see that the @xmath
factor controls the smallness of neutrino masses, in a similar fashion
as in the type I case. In general, the @xmath parameter is of the same
order as the mass of the triplet @xmath , @xmath GeV. Contrary to the
previous see-saw scenario, the type II case is rich in phenomenology
since the scalar sector is constituted of seven bosons after the
symmetry breaking. However, this scenario suffers the same issue as the
type I see-saw , is nearly impossible to test it in its simpler form
with the current and proposed accelerators. There are forms to
circumnavigate this problem. In the Perez et. al.  work [ 101 ] , for
instance, it is considered a case in which the @xmath parameter is of
order TeV, making it reachable by the LHC.

##### 2.3.3 Type III

The last possibility to obtain a Majorana mass term at tree level
consist in introducing the a right-handed fermion triplet @xmath with
zero hypercharge. This scenario is known as type III see-saw [ 102 ] .
It is described by

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

where @xmath are the SU @xmath generators. After the electroweak
symmetry breaking, the sector responsible for the neutrino mass is

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (2.20)
  -- -------- -------- -- --------

with

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

Let us note here that the structure of the mass matrix is similar to the
type I scenario. Therefore, in the case which @xmath the active
neutrinos will have a small mass. An important difference between type I
and type III scenarios is the existence of the charged fermions @xmath
having gauge interactions, enriching the phenomenology of this case.

Finally, it is possible to show that in the three types of see-saw
mechanisms the Weinberg operator is obtained when integrating out the
heavy states [ 55 ] . It is also worth to mention here that a Majorana
mass term can be obtained by radiative corrections, such in GUT and
Supersymmetric (SUSY) models [ 103 ] .

#### 2.4 Leptogenesis

Among the possible consequences of neutrinos being Majorana particles is
the generation of lepton asymmetry in the early Universe. This process,
denominated Leptogenesis , has attracted a lot of attention given that
it connects two open problems in High Energy Physics, the smallness of
the neutrino masses and the matter-antimatter asymmetry. We will
concentrate ourselves in the remaining of this chapter on the discussion
of such process, considering as basis the type I see-saw mechanism.

##### 2.4.1 Evidences of a Baryonic Asymmetry

Nowadays, diverse evidences indicate that in our Universe exists a
baryonic asymmetry, i.e., the number density of antibaryons (antiprotons
and antineutrons) is smaller than the baryon density (protons and
neutrons) [ 42 ] . Such hypothesis was built from several astrophysical
measurements. In the first place, it is possible is assess that our
Solar System is made only from matter. For instance, it was observed
that cosmic rays are made of antiprotons in a quantity @xmath times
smaller than the number of protons. This number can be obtained
considering the quantity of antiprotons created in the atmosphere as
collision sub-products. Therefore, we see that the cosmic rays are a
good evidence that exists a difference between the baryon and antibaryon
numbers in our surroundings [ 42 ] .

On the other hand, in the scales of galaxy clusters, the asymmetry
evidence is weaker. For instance, if there were galaxies made completely
of antimatter in the same cluster, we would expect a large emission of
gamma rays due to the large quantities of matter and antimatter in an
annihilation process. However, the lack of those emissions shows that,
in general, the closest clusters are made entirely of baryons or
antibaryons [ 42 ] .

Now, to have large quantities of antimatter in a baryonically symmetric
Universe, it would be necessary that baryons and antibaryons were
separated in scales bigger than @xmath [ 42 ] . Nonetheless, the current
description of the evolution of our Universe given by the Standard
Cosmological Model ( @xmath CDM) shows that, in order to have a Universe
without baryonic asymmetry, some unknown process should have acted to
separate baryons and antibaryons. Otherwise, an “annihilation
catastrophe” would have occurred due to the absence of an asymmetry, and
the Universe would only be composed by radiation after the annihilation.

A simple question can be asked at this point; is it possible that the
asymmetry was an initial condition in the Universe? Such a solution has
an inconvenient. If the Inflation mechanism is actually correct, any
initial condition should have been erased by the accelerated expansion.
Therefore, we can imagine then that the Universe started in a symmetric
state and a dynamical mechanism acted to create the baryon asymmetry [
42 ] .

The baryon asymmetry is characterized by the ratio [ 104 ]

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

where @xmath in the baryon number density, @xmath in the antibaryon
number density, @xmath is the photon number density. The baryon
asymmetry @xmath has been obtained from the observations of the
Wilkinson Microwave Anisotropy Probe (WMAP) of the Cosmic Microwave
Background (CMB). This implies that for each @xmath antiquarks there
were @xmath quarks that created the structures we see.

Another evidence in favour of the asymmetry is obtained considering the
primordial abundance of the light elements D, @xmath He, @xmath He and
@xmath Li in the @xmath CDM and comparing with the observational data [
42 ] . These results also indicate the existence of a baryon asymmetry.
So, we can assert that the asymmetry hypothesis has strong experimental
bases. Therefore, from a theoretical point of view, the explanation of
this asymmetry is one of the principal open problems in elementary
particle physics and cosmology.

##### 2.4.2 Sakharov’s Conditions

Sakharov [ 105 ] established the three basic ingredients that a model
needs to contain to generate dynamically a baryonic asymmetry. Let us
revise them briefly:

  1. Baryonic Number Violation  

    It is necessary to have a source of baryon number violation to
    generate the asymmetry. This violation is present in several GUT
    models given that leptons and quarks usually belong to a irreducible
    representation of the gauge group in the model. However, in the SM
    it is possible to have a baryon number violation; processes known as
    instantons, created by non-perturbative phenomena, violate the total
    baryon number [ 104 ] .

  2. C and CP Violation  

    When a baryon number violation exists, it is also needed that the
    model contains some source of C and CP violation since the baryon
    number non-conserving processes create baryons and antibaryons in
    the same quantities.

  3. Out-of-equilibrium conditions  

    Since the mass of particles and antiparticles are equal in a CPT
    invariant model, which will respect also Lorentz invariance, the
    baryon and antibaryon numbers need to be the same in a equilibrium
    situation. Let us write the operator of a simultaneously charge
    conjugation, parity and temporal inversion operations as @xmath ,
    and @xmath a density matrix in a thermal equilibrium state, with
    @xmath the hamiltonian of the system. Then, the expectation value of
    the baryon number is @xmath

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    where we used that @xmath as, by definition, the antibaryon number
    is the opposite of the baryon number. So, we see that it is not
    possible to create a baryon asymmetry when a system is in thermal
    equilibrium.

Although all these ingredients are present in the SM, the CP violation
produced by the complex phase of the CKM matrix is not enough to create
an asymmetry of the order @xmath . Furthermore, the discovery of a
SM-like Higgs boson, mentioned in the previous chapter, implies that the
Electroweak phase transition, which would be the responsible for the
deviation from thermal equilibrium, is not of the first order [ 106 ,
107 , 108 ] . This proofs that baryogenesis needs beyond SM physics to
be understood.

There are many models which allow to generate dynamically a baryon
asymmetry. Usually, those models contain new sources of CP violation and
additional deviations from thermal equilibrium. Some of these mechanisms
are GUT baryogenesis, Affleck-Dine mechanism and leptogenesis [ 104 ] .
The last one, leptogenesis, or generation of lepton asymmetry is a
cosmological consequence of neutrinos being Majorana particles. We will
consider next this scenario.

##### 2.4.3 Standard Leptogenesis

The baryon asymmetry generation through a lepton asymmetry is a
scenario, which has attracted a lot of attention in the last years,
since it allows to connect two seemingly uncorrelated problems: the
smallness of neutrino masses and the baryogenesis. This is possible due
to the see-saw mechanism, as we will see. Let us note that lepton number
is not conserved by a Majorana mass term. This is due basically to the
fact that a Majorana fermion cannot have a conserved charge. Moreover,
new CP violation phases can exist both in active and sterile neutrino
sectors, in the mixing matrices @xmath . Let us notice that this matrix
has more CP violation phases than in the Dirac case as the Majorana mass
term in ( 2.5 ) is not invariant under phase transformations. In the
case of 3 right-handed heavy neutrinos, there are two additional phases
to the usual phase appearing in the Dirac case. These phases are known
as Majorana phases. One important consequence is that these phases do
not modify the neutrino oscillation probability, making the
differentiation between Majorana and Dirac natures impossible in an
oscillation experiment.

On the other hand, the deviation from thermal equilibrium can be present
in the decay of the heavy neutrinos. Thus, in principle, leptogenesis
obeys all Sakharov conditions. However, it is necessary to determine if
this scenario can give rise an asymmetry compatible with the observed
one. In the type II see-saw , described previously, is it possible to
generate the lepton asymmetry in different manners. The most well known,
and the one we will study here, is thermal leptogenesis. In that case,
the right-handed neutrinos are created by scatterings in the thermal
bath, and, after their decay, a lepton asymmetry is generated.

In the present section we will describe the standard formalism for
thermal leptogenesis. Let us recall the Majorana lagrangian ( 2.8 ) for
@xmath right-handed neutrinos as

  -- -------- -------- -- ---------
     @xmath   @xmath      ( 2.8 )
  -- -------- -------- -- ---------

where we will consider the basis in which the heavy right-handed
neutrinos mass matrix is diagonal @xmath . Lepton asymmetry is generated
in the following scheme. Scatterings in the thermal bath create an
important population of @xmath at temperatures of the same order of the
masses @xmath . Then, these neutrinos decay through the channels

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

If there is CP violation, asymmetries will be created in all channels;
meanwhile, if the interactions are out-of-equilibrium, those asymmetries
will remain. Finally, the processes which occur in the Electroweak
transition phase will transform part of the lepton asymmetry into a
baryonic one. An important fact that is noted in [ 104 ] is that the
creation and annihilation is controlled by the same set of coupling
constants, @xmath . Therefore, we should notice that the same CP
asymmetry is involved in the creation and the decays of the @xmath .
Thus, as a consequence of this, the total asymmetry can be zero since
the initial asymmetry is “washed out” by the decays, inverse decays and
scatterings [ 104 ] . Such washout will be critical for thermal
leptogenesis Furthermore, flavour effects will be very important, since
the washout depend on how the leptons are distinguished in the
processes. Anyhow, we will not address the washout here. Let us discuss
in more detail the Sakharov conditions in this scenario.

###### CP Violation

To consider the CP violation we need to keep in mind that there are two
different contributions: the asymmetry coming from the decays of the
right-handed neutrinos

  -- -------- --
     @xmath   
  -- -------- --

and the asymmetry from the scatterings

  -- -------- --
     @xmath   
  -- -------- --

Let us study the asymmetry from the decays as the scattering case is
analogous to the following discussion. The CP asymmetry is obtained
considering the quantum interference between the diagrams at tree level
with the 1-loop corrections; such asymmetry is zero when considering
only tree level processes. The self-energies and vertex contributions
are denominated as @xmath and @xmath respectively, see figure ( 2.1 ).
For the @xmath -loop contributions we will have the diagrams in figure (
2.2 ).

For the hierarchical case, in which one of the right-handed neutrino
masses is smaller that the other masses, @xmath , we have that the
contribution @xmath is not relevant since the transitions among
neutrinos is suppressed by the mass difference. On the other hand, the
@xmath contribution can be computed, and is given by [ 89 , 104 ]

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

where the Fukugita-Yanagida 1-loop function is [ 89 , 109 ]

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

Before considering the leptonic asymmetry, it is necessary to mention a
problem which appears in the computation of the CP violation. There
exists a double counting in the previous CP asymmetries. In the
scattering @xmath , we are considering processes where neutrinos are
created on-shell and then decaying @xmath . This process was already
included in the decay asymmetry.

Therefore, we need to subtract the “real intermediate state” by hand,

  -- -------- -------- -- --------
     @xmath   @xmath      (2.23)
     @xmath   @xmath      (2.24)
  -- -------- -------- -- --------

where @xmath corresponds to the matrix element in which the neutrino is
on-shell. We can then rewrite the previous term using the branching
ratio @xmath for @xmath ,

  -- -------- -------- -- --------
     @xmath   @xmath      (2.25)
  -- -------- -------- -- --------

When considering the Boltzmann equations, it will be necessary to take
into account this subtraction of the real intermediate states in order
to obtain the correct result.

###### Boltzmann Equations

The standard procedure to determine the generation and evolution of a
lepton asymmetry uses the Boltzmann equations as a fundamental equation
in the description of the right-handed neutrinos out-of-equilibrium. In
the case in which the Universe is described by the
Friedmann-Lemaître-Roberston-Walker (FLRW) metric, the equation for the
number density for the @xmath species, defined as

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the distribution function, @xmath the internal degrees of
freedom of the species, is given by ² ² 2 We are considering here the
notation @xmath

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

Here @xmath corresponds to the Hubble expansion parameter; @xmath are
the collision terms for decays and scatterings ( @xmath )

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (2.27a)
     @xmath   @xmath      (2.27b)
  -- -------- -------- -- ---------

being the signal @xmath an indicator of the fermionic or bosonic nature,
respectively, and we have defined the relativistic invariant probability
densities of interaction as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

@xmath are the averaged in the internal degrees of freedom probabilities
of occurring an interaction @xmath . The non-linear system of Boltzmann
equations for all the species present in the thermal bath is difficult
to solve since for each species there will be an equation which, in
general, will depend on the other species. Nonetheless, to solve such
system, we need to understand first how the out-of-equilibrium
conditions appear in the early Universe. The expansion of the Universe
will determine when a species is in equilibrium or not [ 42 ] . If the
interaction rate @xmath is of the same order or less than the Hubble
expansion @xmath

  -- -------- --
     @xmath   
  -- -------- --

the species will not be able to balance the reactions, and will be
out-of-equilibrium; meanwhile. if the interaction rates are larger than
@xmath , the species will be in thermal equilibrium with the primordial
plasma [ 42 ] . Such criterion regulates which species can be considered
in equilibrium, simplifying the whole system of Boltzmann equations.

For the initial conditions, we will assume that the Universe, composed
by SM particles interacting through gauge interactions, remains in
equilibrium. A thermal density of right-handed neutrinos can be produced
if the time scale of production @xmath , @xmath the decay width of the
right-handed neutrinos, is smaller than the age of the Universe in that
epoch @xmath where [ 42 ]

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the effective number of relativistic degrees of freedom of
the thermal bath and @xmath the Planck mass.

At this point we need to obtain the Boltzmann equations which govern the
generation and evolution of the asymmetry. However, since our purpose is
to give a general vision of the leptogenesis, we will give some results
taken from the literature. The procedure used consists in solving the
Boltzmann equation for the right-handed neutrino number density and then
solve the equation of motion for the lepton asymmetry. Such equations
are given by [ 42 , 110 , 111 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (2.28a)
     @xmath   @xmath      (2.28b)
  -- -------- -------- -- ---------

with @xmath , @xmath the number densities of the right-handed neutrinos
and the lepton asymmetry, respectively; @xmath are their values at
thermal equilibrium and @xmath are the reduced collision terms,

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (2.29a)
     @xmath   @xmath      (2.29b)
  -- -------- -------- -- ---------

being @xmath and @xmath the modified Bessel functions; @xmath , @xmath
are the expressions at zero temperature ( @xmath ) of the total decay
width and cross section of the scatterings @xmath , respectively. We
should notice here that the contributions of the real intermediate
states have been subtracted from the cross sections [ 111 ] . Some
suppositions have been made to obtain these equations [ 104 , 111 ] .
First, it was supposed that particles obey the Maxwell-Boltzmann
distribution functions, which is reasonable in the absence of effects
related to the statistics, such as Bose-Einstein condensates or
degeneracies due to fermionic degrees of freedom. Second, it was assumed
that the leptons and Higgs bosons are in thermal equilibrium. Third,
interactions which create a washout are weak, and we can neglect them in
the first discussion.

The figure 2.3 , taken from [ 112 ] , provides the results of the
numerical study of the Boltzmann equations for two different types of
initial conditions. Moreover, it presents the evolution of the abundance
of the right-handed neutrinos and the lepton asymmetry. For the case in
which the initial heavy neutrino abundance is zero (full blue line), we
see that such abundance grows until it exceeds the equilibrium abundance
(dotted blue line) creating an asymmetry at @xmath ; then, it decreases
and goes to the equilibrium value. For that case, an asymmetry appear
even before the neutrino density goes to its equilibrium value (full red
line) and, starting in @xmath the asymmetry becomes a constant due to
the freeze out process. Notice that in the point in which the neutrino
abundance gets to the thermal value, the lepton asymmetry goes to zero,
as expected. Now, for the second case, the initial abundance corresponds
to a thermal value (dashed blue line), choosing @xmath ³ ³ 3 This choice
is not arbitrary as it corresponds to the number of neutrinos per
comoving volume, which, in general, is equal to @xmath , @xmath being
the internal degrees of freedom of the field. For Majorana neutrinos we
have that @xmath . . The time evolution of the neutrino abundance is
such that it becomes out-of-equilibrium, and in that point a lepton
asymmetry is created (dashed red line). An important feature of this is
that in both cases the lepton asymmetry is of the same order.

In conclusion, in this chapter we have considered a general formalism
for the case in which neutrinos are Majorana particles. We have seen how
Majorana fermions have peculiar properties, such as having half of the
degrees of freedom of a Dirac particle; they are their own
antiparticles, making them completely neutral; and the quantization
procedure shows that there are two different types of Feynman
propagators. In the set of the known fundamental particles, the only
ones that can be Majorana are neutrinos. However, since a Majorana term
is forbidden by the SM symmetry group at tree level, we considered the
lowest non-renormalizable term which is invariant under the SU @xmath U
@xmath group. That term is a five dimensional operator, known as
Weinberg operator, and, after the electroweak symmetry breaking, it
gives mass to the neutrinos. Such term is suppressed by a energy scale
larger than the Electroweak scale, justifying the smallness of the
neutrino mass. We also considered the simplest Ultraviolet complete
theories which can give rise to the Weinberg operator when integrating
out the heavy states. These theories are known as the see-saw mechanisms
in its three different types.

The first type corresponds to the introduction of heavy right-handed
neutrinos while the second and third are for the cases in which a scalar
triplet or a fermion triplet is included to the SM set of fields,
respectively. Briefly, in this scenarios the mass of the active
(left-handed) neutrinos is inversely proportional to the new particles,
so, increasing the mass of the additional fields, the neutrino mass
becomes smaller; hence, the name of see-saw mechanism. A problem common
to the minimal three see-saw scenarios is that the new states are quite
heavy, making their production beyond the reach of current and future
experiments. Nonetheless, we showed a crucial consequence of the see-saw
mechanism, the explanation of the matter-antimatter asymmetry through
the denominated leptogenesis . In this case, the baryon asymmetry is
created by a lepton asymmetry which, in turn, is originated by the
out-of-equilibrium decay of the heavy states. We have seen in some
detail how the asymmetry is produced and maintained in the Universe
evolution. However, a definite proof of neutrinos being Majorana is
still to be found. The search of neutrinoless double beta decay is the
foremost candidate to establish the neutrino nature, although there are
some caveats in the interpretation of this decay. In the next chapter,
we will concentrate ourselves in the case of neutrinos being Dirac
fermions, focusing in two simple models for that case.

### Chapter 3 Dirac Neutrinos \lettrine

Planck scale is usually considered as a final frontier since it is
thought that all fundamental forces will have the same strength in that
scale. Furthermore, all the interactions could become one breaking the
laws of physics as we know them. Between the Planck and Electroweak
scales there is a large set of possible models that can exist, such as
GUT theories, SUSY, technicolor, extradimensions, etc, as solutions of
the hierarchy problem. It is also possible the existence of other
physics that are currently unknown. Experimentally, we have just started
to explore the TeV scale. Anyhow, neutrinos can be charged under new
interactions at higher energy scales, but the current sensitivity of our
experiments can not detect any evidences of it. Thus, in principle,
neutrinos can be Dirac particles in those possible scenarios since
Majorana terms would be forbidden. Nonetheless, how to explain the
smallness of Dirac neutrino masses with our current knowledge? We can
consider and constrain possible SM extensions that could give rise
neutrino masses; the simplest possibility is to extend minimally the SM
and give mass to neutrinos in a analogous manner to the other particles.
In that case, there is not an explanation of the smallness of neutrino
masses as there is not for the exact values of the other particles’
masses.

However, inspired by the see-saw mechanism, we can speculate that the
neutrino mass has a different origin from the charged fermions. We can
then ask ourselves what is the simplest scenario in which masses are
generated keeping @xmath couplings. As in the SM, we can suppose that
the mass has an origin in a spontaneous symmetry breaking created by a
new doublet whose VEV is of the same order of the neutrino masses. The
scenario in which we have a second doublet responsible for the neutrino
mass will be the object of our study in the present chapter. We will
consider first briefly the problems regarding the minimal SM extension;
after that, we will introduce the second Higgs doublet Model that will
be named neutrinophilic , as the second scalar doublet manly couples
with those fermions while the first doublet will couple basically with
charged fermions. We will analyse two different cases, related to the
symmetries imposed to the model.

#### 3.1 Minimal SM extension

The simplest extension that can be done in the SM to address neutrino
masses corresponds to introduce three right-handed neutrinos which will
be singlets of the SM gauge group

  -- -------- --
     @xmath   
  -- -------- --

in such a way that we will be able to write down Yukawa terms

  -- -------- --
     @xmath   
  -- -------- --

We need to prevent to have a Majorana mass term since such term will
imply that neutrinos are Majorana fermions as we saw before. This can be
done by keeping in mind that the total lepton number is conserved, so,
if neutrinos are charged with such number, Majorana terms are forbidden
¹ ¹ 1 It has been shown that global symmetries are violated by quantum
gravity effects [ 113 ] . This shows that symmetries as lepton number
conservation should be gauged at some point before the Planck scale,
avoiding this issue. This is also true for the symmetries that will be
considered in the next section. . Leptons will have then a Yukawa
lagrangian given by

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

then, after the Electroweak symmetry breaking, the charged leptons and
neutrinos will have definite masses after the diagonalization of the
mass terms. That diagonalization is performed similarly to the quarks,
by defining

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

to obtain the mass eigenstate lagrangian

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

The neutrino masses explicitly are given by

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

so, to have neutrino masses of order @xmath , we need that @xmath since
@xmath GeV. This is an extremely small number even if compared to the
electron Yukawa, which is of the order @xmath . However, as we have
seen, the SM does not address the origin of the Yukawa couplings.
Indeed, the neutrino Yukawa is small, but, analysing the difference
between the top quark ( @xmath ) and the electron Yukawa couplings, we
see that there is also a large hierarchy. Thus, what is different in the
neutrino case? We can consider the following argument. Since the doublet
components behave as one single field from the Electroweak interaction’s
point of view, we see that the difference among the masses of the
particles belonging to the same doublet is not so large in the quark
sector’s first and second families. Explicitly, the up and down quarks
have masses of @xmath MeV and @xmath MeV, respectively, while the
strange and charm quarks have masses of @xmath GeV and @xmath GeV.
Nonetheless, in the lepton sector, we see that the mass difference
between the doublet constituents is indeed large. This may suggest that
neutrino masses have a different origin and that is the reason of such
large hierarchy. Of course, in the third quark family there is an
important difference between the bottom ( @xmath GeV) and top ( @xmath
GeV) quark masses, yet such difference is not as large as in the lepton
case. Anyhow, we can simply suppose that the Yukawa neutrino has such
small value without trying to justify it, as done for the other
particles. Still, it is important to consider and constrain other
possible models for neutrino masses as we will analyse in the next
section.

#### 3.2 Neutrinophilic two-Higgs-doublets Models

Although there is not a fundamental reason for the neutrino masses in
the Dirac case to have a different origin from the rest of fermions, we
can study possible models that can give rise to small Dirac neutrino
masses. We can think about other possible extensions that can be done to
the SM. Our guide for such scrutiny is that we prefer neutrino masses
generated without any extremely small parameter, or, in other words, the
neutrino mass will be protected by some symmetry. Anyhow, to obtain
neutrino masses of order @xmath in a similar fashion to the other SM
particle, we would need a small VEV to evade small couplings. On the
other hand, the next to minimal extension to the SM would be to include
a second Higgs doublet, see [ 114 ] and references therein. Let us
stress that this two-Higgs-doublets models ( @xmath HDM) are interesting
by themselves since, for instance, supersymmetry requires the presence
of two scalar doublets.

For neutrino masses we can adapt @xmath HDM to induce small neutrino
masses. Thus, we will suppose that the two doublet neutral components of
the doublets get a VEV. The first doublet will be responsible to give
masses to the charged leptons while the second one will give mass to
neutrinos. We also require that the first doublet does not couple with
neutrinos; otherwise, the mass contribution from such doublet to the
neutrino will dominate. Consequently, it is necessary to introduce a new
symmetry in which right-handed neutrinos and the second doublet are
charged while the rest of particles are not. The two simplest cases
which have been considered are a @xmath symmetry, proposed by Gabriel
and Nandi [ 115 ] , and a U @xmath scenario in the Davidson Logan work [
116 ] . In general, the lagrangian associated to a @xmath HDM is given
by

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

with the scalar potential

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      
              @xmath      (3.5)
  -- -------- -------- -- -------

being @xmath two scalar doublets with hypercharge @xmath . The neutral
components of these doubles will have VEVs given by @xmath , @xmath .
Recalling our purposes, we will impose that the second doublet generates
neutrino masses, so @xmath eV. Besides, @xmath will break the
Electroweak symmetry, and we have that @xmath @xmath GeV. Clearly,
@xmath , with @xmath . Analysing the scalar potential, we have that the
@xmath parameters can be complex.

However, the new symmetry will forbid in general the terms proportional
to @xmath and @xmath while the @xmath and @xmath parameters may be
different from zero according to the symmetry. In the Gabriel-Nandi
scenario, we have that @xmath must be zero since the term proportional
to such coupling is not invariant under the symmetry. For the U @xmath
case both @xmath and @xmath need to be zero. Nonetheless, as we will see
shortly, to avoid a Nambu-Goldstone boson in the spectrum, @xmath cannot
be zero. We will consider in this section @xmath only to be as general
as possible.

The stationary conditions @xmath for our potential are

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (3.6a)
     @xmath   @xmath      (3.6b)
  -- -------- -------- -- --------

Thus, we have that the parameters @xmath can be written as functions of
the VEVs and the @xmath mass term. For the case in which such mass term
is zero, @xmath , we will have two stable solutions @xmath or @xmath ,
so one VEV will correspond to the SM one while the second one will be
inert. In general, for @xmath the equations ( 3.6 ) do not have
analytical solutions; nevertheless, supposing that @xmath we can obtain

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

and a symmetric solution interchanging the indices @xmath . Therefore,
we can conclude that a small VEV requires a correspondingly small @xmath
parameter. Finally, let us notice that there can be more than one
solutions to the stationary conditions ( 3.6 ), creating the possibility
of having simultaneously different minima @xmath and @xmath . However,
it can be checked analytically if the vacuum is a global one, see [ 117
, 118 ] . We have included such conditions to our analysis.

Given that there is a large hierarchy between the scales of the model,
we can wonder if the second VEV @xmath is stable under radiative
corrections. It has been shown that the radiative corrections for both
@xmath model [ 119 ] and the U( @xmath ) case [ 120 ] do not spoil the
smallness of the second VEV. In the case of the @xmath including a
non-zero value @xmath , it was shown that loop corrections induces the
terms which breaks the symmetry, similar to the terms proportional to
@xmath and @xmath [ 119 ] . Such additional contributions modify the
stability conditions ( 3.6 ), and it can be shown that the ratio between
the induced and the @xmath terms are given by [ 119 ]

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

Therefore, the order of @xmath will not be modified by radiative
corrections in this case. On the other hand, in the Davidson-Logan
model, it has been shown that the radiative corrections are also
proportional to the @xmath term, and they are dependent on the scalar
spectrum [ 120 ] . In the case in which the charged and pseudoscalar
scalars are mass degenerated, the corrections are small. As we will see
afterwards and in the next chapter, the theoretical and experimental
constraints actually imply that those particles need to be degenerated.

After the Electroweak symmetry breaking, we will parametrize the two
doublets as

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

The scalar spectrum is composed by four charged particles @xmath , two
CP-even neutral bosons @xmath e @xmath , and two CP-odd neutral scalars,
@xmath . However, due to the mixing terms, we have that these particles
do not possess definite masses. Introducing the rotations

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.11a)
     @xmath   @xmath      (3.11b)
     @xmath   @xmath      (3.11c)
  -- -------- -------- -- ---------

being @xmath and @xmath , we can diagonalize the mass terms of the
potential. The angles @xmath and @xmath must be

  -- -------- -------- -- --------
     @xmath   @xmath      (3.12)
     @xmath   @xmath      (3.13)
  -- -------- -------- -- --------

where @xmath . The physical states will be then a charged scalar @xmath
, two neutral scalars @xmath and @xmath , and a pseudoscalar @xmath

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.14a)
     @xmath   @xmath      (3.14b)
     @xmath   @xmath      (3.14c)
     @xmath   @xmath      (3.14d)
  -- -------- -------- -- ---------

whose masses are given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      
              @xmath      (3.15a)
     @xmath   @xmath      
              @xmath      (3.15b)
     @xmath   @xmath      (3.15c)
     @xmath   @xmath      (3.15d)
  -- -------- -------- -- ---------

being @xmath . The inverse relations are straightforwardly obtained [
121 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.16)
     @xmath   @xmath      (3.17)
     @xmath   @xmath      (3.18)
     @xmath   @xmath      (3.19)
     @xmath   @xmath      (3.20)
  -- -------- -------- -- --------

These relations will be useful for studying the physical parameter space
of the model. On the other hand, the @xmath and @xmath fields are
massless corresponding to the Nambu-Goldstone bosons appearing due to
the symmetry breaking. These bosons will be absorbed by the Gauge bosons
@xmath , @xmath . Let us see this in more detail. Rewriting the doublets
in terms of the physical states

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

we can show that it is equivalent to

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.21a)
     @xmath   @xmath      (3.21b)
  -- -------- -------- -- ---------

where the @xmath functions are related to the Nambu-Goldstone fields in
the following manner

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We can now do a gauge transformation to eliminate the non-physical
degrees of freedom, going to the so-called Unitary gauge

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath . After performing this gauge transformation, it is
necessary to study the gauge boson sector.; nonetheless, it will not be
affected by the new particles, remaining the same as studied previously
in the SM.

Now, we can turn our attention to the neutrino sector. In this case, the
Yukawa lagrangian is given by

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (3.22)
  -- -------- -------- -- --------

Let us stress that we have chosen a basis in which the charged leptons
and neutrinos mass matrices are diagonal, which implies that the
interaction term with the charged scalar is non-diagonal in the flavour
space. Moreover, as we will see later the angles @xmath and @xmath are
small due to the large hierarchy between the scales @xmath and @xmath .
Subsequently, the Yukawa lagrangian can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.23)
  -- -------- -------- -- --------

where we see that the charged lepton @xmath masses basically come from
the doublet @xmath , while the neutrino masses depend on the VEV of the
second doublet @xmath . Let us also note that in the previous lagrangian
appears explicitly the PMNS matrix. This can induce FNCN processes; such
processes will be considered in the following chapter. Now, let us
consider each scenario for the symmetry introduced to protect the
neutrino masses.

##### 3.2.1 @xmath Symmetry Model

For the Gabriel-Nandi scenario [ 115 ] a discrete @xmath symmetry is
introduced in such a way that only the second doublet @xmath and
right-handed neutrinos are odd under that symmetry while the SM
particles are even. Besides, lepton-number conservation is imposed to
make neutrinos Dirac particles. However, if such symmetry is not
imposed, neutrinos can have Majorana mass terms, given that the symmetry
is a discrete one, the Majorana condition for neutralness is still
satisfied. Anyhow, we will consider the conservation of lepton number,
maintaining the Dirac nature ² ² 2 In the work published by the author
with collaborators [ 118 ] , it was not considered the lepton number
conservation; thus, it was possible to write down Majorana mass terms.
However, we found that such mass term do not affect the results. . Also,
as previously mentioned, the @xmath parameter will be zero due to the
symmetry, therefore, when @xmath is imposed in the angles @xmath and
@xmath definitions, it is clear that they must be small. This implies
that the mixture between the doublets is also small. Phenomenologically
speaking, this has many consequences. The first one is that the @xmath
doublet behaves as the SM Higgs doublet so that the neutral scalar
@xmath can be identified as the @xmath GeV scalar boson found at the
LHC. The second consequence is that the neutrinophilic scalar @xmath has
a quite small mass, of order of the second doublet’s VEV, i.e. @xmath .
Besides, the masses of the charged scalar and the pseudoscalar will be
in the TeV scale, for values of the quartic couplings not very large.
Such a quite specific spectrum will have problems with the electroweak
precision measurements, as we will describe in detail in the next
chapter.

##### 3.2.2 @xmath Symmetry Model

In the case of the model with U @xmath symmetry, described in the work
of Davidson-Logan [ 116 ] , the spontaneous symmetry breaking of that
symmetry by the VEV @xmath induces the appearance of a Nambu-Goldstone
boson. This is quite problematic due to the many existing limits
regarding a massless scalar coming from electroweak precision test and
cosmology. This is the reason why it is necessary to have a term which
breaks explicitly the symmetry. Therefore, we will impose that @xmath is
zero, while @xmath is small. From equation ( 3.15d ) we can write

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

so that to have @xmath eV and a mass of the pseudoscalar of @xmath (
@xmath GeV) it is necessary that @xmath ( @xmath keV) @xmath . The
spectrum will be different from the @xmath model due to the small value
of @xmath . The main characteristic will be that the neutrinophilic
scalar @xmath mass depends on @xmath through the @xmath parameter, see (
3.15b ), which is not be necessary small. On the other hand, it is
possible to show that the quartic coupling @xmath , given by the
expression ( 3.17 ) in the case of @xmath , is

  -- -------- -------- -- --------
     @xmath   @xmath      (3.25)
  -- -------- -------- -- --------

This means that

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

Therefore, if we assume that @xmath , we see that the @xmath scalar and
the @xmath pseudoscalar are degenerated in mass, see equations ( 3.15b )
and ( 3.15d ). This is a consequence of the large hierarchy between the
VEV’s and the symmetry imposed to the potential. Therefore, we find that
the scalar spectra of the two models are quite different which will make
our theoretical and phenomenological limits also distinct. Regarding the
neutrino nature, let us note that the U @xmath symmetry is a continuous
one, preventing the development of a Majorana mass term, since the
right-handed neutrinos need to be charged under this symmetry. Neutrinos
will be Dirac particles.

We find then that it is possible to construct models for Dirac neutrinos
having naturally small masses although there is not a reason for
avoiding small Yukawas in the minimal SM extension. Accordingly, we have
introduced the neutrinophilic @xmath HDMs by introducing a second
doublet to the set of SM fields. Let us stress here that this @xmath HDM
scenario is different from those considered in the literature. Usually
it is considered that the second VEV is of the same order, larger than
the Electroweak one, or even sometimes is zero [ 114 ] . In the present
case, it is supposed by hypothesis that the VEV of the new doublet is of
the same order of the neutrino masses. Furthermore, a new symmetry is
needed in order to forbid the coupling of the first doublet, having a
VEV similar to the SM one, with the neutrino. There are two simple
cases, a @xmath and U @xmath scenarios. We have discused in detail the
properties of the scalar potential, stressing the differences in the two
models we are interested. Now, having established the models, we will
consider in the next chapter the theoretical and experimental
constraints of the neutrinophilic @xmath HDM; such constraints are
imposed from Electroweak precision measurements, @xmath and Higgs
decays, and flavour physics.

## Part II Phenomenology

### Chapter 4 Constraints on Neutrinophilic two-Higgs-doublets Models
\lettrine

Since the experimental discovery of a scalar boson compatible with the
SM Higgs by the ATLAS and CMS collaborations, many theories have been
under scrutiny given the updated information. The SM itself has been
analysed under the light of the new boson discovery. At first sight,
such discovery would not have a crucial impact on our purpose of
understanding neutrino’s nature and its relationship with neutrino
masses. However, as we have seen, in the Dirac scenario the structure of
the Higgs potential can teach us about the existence of further scalar
doublets. Other ways have been proposed some time ago to constrain the
existence of beyond SM physics through direct measurements or global
fits of the model. We can divide them in two basic categories,
theoretical and phenomenological bounds. Theoretical limits are related
to the properties that any model needs to fulfil to avoid contradictions
in some computations, while the phenomenological bounds come from
experimental data that the model has to agree with. We will consider in
this chapter the constraints on neutrinophilic @xmath HDM that are
imposed on two different sectors, the scalar potential and the flavour
leptonic sector; in the scalar sector theoretical bounds are related
with the properties of the potential while phenomenological limits are
related with unobserved decays and precision measurements in both scalar
and flavour sectors. The results presented in this chapter constitute an
original contribution, and have been published in [ 118 ] and [ 122 ] .

#### 4.1 Theoretical and Phenomenological Constraints on the Scalar
Potential

We will first consider theoretical and phenomenological constraints
imposed on the scalar sector of the models. Theoretical limits will
allow to reduced the models parameter space, in such a way that
phenomenological limits coming from LEP and LHC experiments will be only
applied to the theoretically allowed parameter space. We will present
first the limits in a general way applying them to our models of
interest in a further section.

##### 4.1.1 Theoretical Constraints

Our scalar potential needs to obey certain constrains, such as it should
be stable and unitarity should be respected. This will impose some
specific inequalities that should be respected by the @xmath couplings,
appearing in the potential. Let us examine these constraints. First, it
is necessary that the potential is stable at tree level, i.e. the scalar
potential can not take large negative values for large values of the
couplings. To do this, we must consider only the quartic terms in the
potential. Proceeding as in [ 123 ] and defining @xmath , @xmath ,
@xmath e @xmath , we have that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

To determine the conditions that the quartic couplings should obey, we
impose that there should not be directions in the parameter space in
which @xmath . For the direction in which @xmath , we obtain

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

while that considering the direction in which @xmath and @xmath and
putting @xmath , we obtain a quadratic inequality for the parameter
@xmath . This implies an inequality for the couplings, given by [ 123 ]

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

The conditions ( 4.1 ) and ( 4.2 ) are the constraints that we will
impose on the parameter space. On the other hand, perturbative unitarity
must be respected at tree level; in other words, at higher energies,
scalar-scalar scatterings should not violate unitarity [ 124 , 125 ] .
We will see how these constraints are obtained [ 125 ] . The total
cross-section for the process @xmath is given by [ 125 ]

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

where @xmath is the Mandelstam variables, @xmath is a partial @xmath
spin wave. Using the optical theorem, we obtain the condition for
unitarity

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

Graphically, the previous equation represents a circle in the plane
@xmath with radius @xmath and centred in @xmath . Therefore, it is
necessary that [ 125 ]

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

Inverting the partial wave @xmath in terms of the amplitude, and
considering only the @xmath wave for @xmath , one finds [ 125 ]

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

where @xmath is the four-point vertex and @xmath is the trilinear vertex
of the interaction @xmath , @xmath for processes with and without the
t-channel, respectively. As we see here, the first @xmath wave
contribution comes from the quartic coupling and the other contributions
come from diagrams in which there is an exchange of a third particle
@xmath in the @xmath channels (second and third terms) [ 125 ] . For
high energy collisions the dominant term is the quartic interaction term
since the other terms are suppressed by energy; thus, the unitarity
limit should be applied to such term. Specifically, if @xmath , the
quartic term should obey @xmath [ 125 ] .

To apply the previous results to a specific model, we should consider
all possible scalar-scalar, gauge boson-gauge boson, scalar-gauge boson
scattering process provided that they should satisfy @xmath in the high
energy limit. Nonetheless, in such limit, we can use the equivalence
theorem [ 126 ] . Such theorem establishes that a scattering amplitude
containing longitudinal gauge bosons is well approximated by the
amplitude obtained substituting the gauge bosons with their
corresponding Nambu-Goldstone bosons. Therefore, we have that the
unitarity limit is enforced studying only scalar scatterings [ 125 ] .
For the specific case of a @xmath HDM, and taking into account all
possible scattering processes, we have to deal with a @xmath amplitude
matrix composed by four sub-matrices @xmath , @xmath , @xmath and @xmath
, whose elements are the quartic couplings of the processes [ 125 ] .

Determining the eigenvalues of such matrix, one obtains the unitarity
constraints

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

where

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (4.8a)
     @xmath   @xmath      (4.8b)
     @xmath   @xmath      (4.8c)
     @xmath   @xmath      (4.8d)
     @xmath   @xmath      (4.8e)
     @xmath   @xmath      (4.8f)
     @xmath   @xmath      (4.8g)
     @xmath   @xmath      (4.8h)
     @xmath   @xmath      (4.8i)
  -- -------- -------- -- --------

Subsequently, the parameter space must obey the stability conditions,
equations ( 4.1 ) and ( 4.2 ) as well as the unitarity conditions,
equations ( 4.7 ). Therefore, as already mentioned, we will scan the
parameter space and select the points which obey these theoretical
conditions; then, we will apply the phenomenological constraints.

##### 4.1.2 Electroweak Oblique Parameters

The oblique parameters codify the impact of beyond SM physics in the
electroweak precision measurements realized by LEP I and II experiments.
These parameters were introduced by Peskin and Takeuchi [ 127 , 128 ] ,
and they are based in three suppositions related to the new physics: i)
the new physics does not change the gauge group SU @xmath U @xmath ;
therefore, there are no new gauge bosons beyond @xmath , @xmath and
@xmath ; ii) the couplings of the new physics with the lightest fermions
are suppressed compared to the gauge boson couplings; iii) the intrinsic
scale of the new interaction is larger than the Electroweak scale, i.e.,
compared to @xmath and @xmath . Thus, if the previous hypothesis are
obeyed, the impact of the new physics will appear through the
contributions to the gauge bosons self-energies.

  -- -------- --
     @xmath   
  -- -------- --

with @xmath . A new contribution is added to the SM term as

  -- -------- --
     @xmath   
  -- -------- --

Peskin and Takeuchi supposed that it is possible to do a Taylor
expansion in the new contributions when the new physics exists at a
higher energy scale

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

being @xmath the derivative with @xmath evaluated at @xmath . With this
assumption, the number of independent parameters is simple to obtain. In
principle, there are eight quantities which describe the new physics,
since @xmath . However, @xmath and @xmath are zero due to the gauge
invariance. On the other hand,three combinations of the six remaining
quantities can be eliminated when the parameters @xmath are
renormalized. Therefore, all the effect of the new physics are codified
in three combinations of @xmath ¹ ¹ 1 We should take into account that,
if the new physics scale assumptions is disregarded, there will be six
independent parameters, denominated @xmath . See, for instance, [ 129 ]
. These combinations are denominated @xmath parameters, given by [ 130 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (4.10a)
     @xmath   @xmath      (4.10b)
     @xmath   @xmath      (4.10c)
  -- -------- -------- -- ---------

where @xmath and @xmath . The physical interpretation of theses
parameters is given next. The @xmath parameter codifies the running of
the two-point functions of the neutral gauge bosons between zero
momentum and the @xmath pole. Therefore, this parameter will be very
sensitive to the presence of new physics in scales lower than the @xmath
mass. The @xmath parameter is sensitive to the custodial symmetry
breaking at zero momentum, i.e., to the difference between the two-
point functions of the @xmath and @xmath bosons; thus, this parameter
measures the isospin violation. The @xmath parameter, or the @xmath
combination, determines the presence of new light charged scalars in the
radiative corrections.

For the specific case of the neutrinophilic @xmath HDM, we will use the
expressions for a general @xmath HDM obtained in [ 130 ] . Let us stress
here that the assumption for the new physics scale is not valid for the
case that we are considering since the scale of the second VEV is
smaller than the electroweak one. Thus, we should use the full set
@xmath . Nevertheless, for simplicity, we will consider only the @xmath
parameters, which will give us strong limits in both models. We can
expect a general behaviour for these parameters. The @xmath parameter
will constrain strongly the models, due to the presence of the light
scalar in the case of the @xmath symmetry model. Meanwhile, the
difference between the masses of the charged scalar and the pseudoscalar
will be limited by the @xmath parameter given that those particles
belong to the same doublet; thus, any large mass difference will imply
an isospin breaking. The @xmath parameter will not be very important
since direct measurements put already a limit of @xmath GeV on the
charged scalars mass [ 131 ] . Therefore, the @xmath parameter will not
be affected.

Experimentally, the oblique parameters are obtained fitting the
electroweak precision measurements, specially the LEP data regarding
measurements at the @xmath pole and the Higgs mass, determined by the
LHC. Computing the relative values compared to the SM predictions, the
GFITTER group obtained the best fit results, uncertainties and the
covariance matrix given by [ 132 ]

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

Hence, to determine the impact of electroweak precision measurements in
the models, we construct the @xmath function

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

with @xmath and the covariance matrix @xmath where @xmath . We compute
then the goodness of the fit for each model codified through the allowed
regions at @xmath , @xmath e @xmath levels, which correspond to @xmath
for two degrees of freedom, respectively. Thus, concerning the oblique
parameters, we will study the behaviour of the parameter space’s regions
allowed theoretically, and we will establish the viability of each
models.

##### 4.1.3 Higgs Invisible Width

When we analise in detail the scalar potential after the mass matrices
diagonalization, it is clear that triple couplings among the scalars are
generated. Specifically, in the case in which the neutral scalar masses
are smaller than the mass of the scalar behaving as the SM Higgs, that
we will denominate hereafter simply as Higgs boson, @xmath , ( @xmath ),
we can have decays @xmath with @xmath decaying later as @xmath . Now,
keeping in mind that the Higgs couplings are practically unaltered by
the smallness of @xmath , the only important modification to the Higgs
branching ratios studied at the LHC will be the addition of an invisible
channel. The combination of ATLAS+CMS we considered gives BR @xmath at
@xmath CL of the invisible branching ratio [ 133 ] . The decay width in
our case is given by [ 134 ]

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

with couplings

  -- -------- -- --------
     @xmath      
     @xmath      (4.14)
     @xmath      (4.15)
  -- -------- -- --------

We should address here that these trilinear couplings can be large,
@xmath 60 GeV. Moreover, they can have a phenomenological important
impact since the SM total width is small, approximately @xmath MeV [ 135
] .

##### 4.1.4 @xmath Invisible Width

Other important contribution to the precision measurements in this model
is related to the @xmath boson properties, specially to the invisible
width. The neutrinophilic @xmath HDM contribute with such width through
the decays @xmath , @xmath . Let us notice that the two scenarios
contribute differently to the width given that in the U @xmath softy
broken symmetry both @xmath and @xmath can have masses smaller than the
@xmath mass. In that case, the width will be the superposition @xmath .
For the @xmath model, only @xmath will contribute to the decay.
Computing the width for a scalar @xmath with mass @xmath , we obtain

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.16)
  -- -------- -------- -- --------

where the total scalar decay width @xmath is simply – @xmath is the
neutrino mass squared sum –

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

In the width ( 4.1.4 ) it was defined the phase space function @xmath ,
and the functions @xmath , @xmath are

  -- -------- -------- -- --------
     @xmath   @xmath      (4.18)
     @xmath   @xmath      (4.19)
  -- -------- -------- -- --------

As experimental constraint we will use the LEP results, @xmath MeV [ 136
] , and the SM prediction @xmath MeV, [ 136 ] . Then, the limit in the
invisible width coming from new physics is @xmath MeV at @xmath level.
For the case of the @xmath model, the width expression contains an
infrared divergence, given that @xmath ; such divergence is cured by
considering the @xmath -loop contributions coming from the @xmath decay.

##### 4.1.5 Results

Using the theoretical and phenomenological constraints from last
section, we will study the parameter space of the @xmath e @xmath
models. Such parameter space is the physical parameter space, i.e the
parameter space of scalar masses and mixing angles. The quartic
couplings can be expressed in terms of these physical parameters,
equations ( 3.16 ) - ( 3.20 ). We performed an scan with approximately
@xmath points. For each point we applied the theoretical constraints
first to determine if such point is viable; then, if it is viable, we
considered the phenomenological limits. In the plots of this section we
will present the phenomenological constraints to the viable points in
different planes of the parameter space.

###### @xmath Symmetry Model

For the @xmath symmetry model we performed the scan over the parameter
space imposing the following relations,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where the value of the Higgs mass @xmath was taken from the combined
results of ATLAS+CMS experiments [ 137 ] and @xmath .

The scan results, presented in figure 4.1 , show the large tension that
this model possesses. In the same figure, we see the theoretically
allowed points in gray, in the @xmath plane, and the allowed regions at
1 @xmath (blue region), 2 @xmath (green region), 3 @xmath (red region)
levels. Basically, we find that Electroweak precision measurements
exclude this model since practically all gray points are out of the
experimentally allowed region. This is due to the presence of a quite
light scalar @xmath , @xmath , which contributes negatively to the
@xmath parameter. The @xmath parameter imposes certain degeneracy
between @xmath and @xmath , @xmath , as explained before. This fact
creates a displacement to negative values of @xmath . It was found an
allowed region at @xmath . However, when we consider a stronger
perturbativity limit of @xmath , this region disappears. On the other
hand, keeping in mind that these results were obtained considering the
spectrum at tree level, we can ask ourselves if loop effects can modify
significantly the mass of the scalar @xmath , in such a way that
constraints are avoided. In a general fashion, we have that the charged
scalar and pseudoscalar masses are not affected by loop corrections
while, for the CP even scalars, we have that the mass matrix can receive
corrections of the form [ 138 ] ,

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

The second term comes from the effective potential, being @xmath
functions on masses and quartic couplings. Therefore, we see that the
mass matrix structure is preserved by loop corrections; this implies
that if @xmath is small, @xmath will always be light. We checked
numerically this, finding that the parameter @xmath still presents
problem, despite the mass of the scalar @xmath being increased by a
factor of @xmath .

In figure 4.2 we present the allowed region by the Higgs invisible decay
(right panel) in the plane @xmath . Given that @xmath is, in general,
heavier than the Higgs, we have that only the @xmath decay will be
allowed. For @xmath and @xmath small, the @xmath coupling is
approximately

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

This shows that @xmath will have a value compatible with the
experimental limit when @xmath . This fact explains the region excluded
in figure 4.2 . Anyhow, as already mentioned, the electroweak precision
measurements exclude this model, and any other phenomenological bound
will be weaker is comparison. For this, we do not present the results
for the @xmath invisible decay width.

###### @xmath Symmetry Model

In the @xmath global symmetry scenario, the scan needs to take into
account that the @xmath parameter is non-zero. Thus, the mass of the
neutrinophilic scalar @xmath can have a larger value. Besides, as showed
in the previous chapter, the masses of the pseudoscalar @xmath and the
neutral scalar @xmath are degenerated at first order in @xmath ; this
was considered in the scan. We scanned over the region

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We present the results in figure 4.3 . We see here that, in the @xmath
plane, there is a region which passes the electroweak precision tests
and theoretical constraints simultaneously. An important characteristic
which appears in the analysis is that the difference between the
pseudoscalar @xmath mass and the charged scalar is approximately @xmath
@xmath GeV. Also, if the charged scalar has a mass of @xmath GeV, the
pseudoscalar and neutrinophilic scalar should be bigger than @xmath 150
GeV. Now, if the masses of the scalars are of @xmath , we find that the
precision measurements impose that the mass of the charged scalars is
also degenerated with the neutral scalars. For the @xmath and @xmath
angles, we find that @xmath and @xmath .

Furthermore, in the case in which the neutral scalars are light and
satisfy @xmath , @xmath , the bound from the Higgs invisible width
results similar to the @xmath scenario, and also do not imposes strong
limits. However, if the channel @xmath is kinematically allowed, the
@xmath invisible width imposes strong constraints to the parameter
space. We can see this in figure 4.3 , bottom. To obtain such result, we
also performed an scan on the oscillation parameters, given in table 1.8
. This is necessary since the width depends on the sum of the neutrino
masses, see equation ( 4.1.4 ). Imposing perturbativity in the scalar
@xmath decay, @xmath , we find that the region @xmath is completely
excluded due to the on-shell contribution of the scalar particles,
@xmath and @xmath . This increases the width by several orders of
magnitude.

Briefly, we see that in this case the Electroweak precision bounds
constrain this model in such a way that the spectrum gets very limited.
This results as the symmetry imposes that the neutral scalar masses to
be the same, and the @xmath parameter constraints the difference between
the pseudoscalar and charged scalar masses. Therefore, all particles end
up with very similar masses. Beyond this, the @xmath invisible width
excludes the region @xmath . Thus, the spectrum of this scenario becomes
a very specific one. This may create additional problems when the
oblique parameters be measured with a better precision.

#### 4.2 Flavour Constraints on Charged Scalar Sector

Other bounds which should be considered in neutrinophilic @xmath come
from flavour physics. Flavour bounds will only constrain the charged
scalar and leptons interactions since, as we have seen, couplings with
quarks are very suppressed; quarks will couple with the second doublet
proportionally to @xmath . Therefore, limits coming from hadron
observables as leptonic and semi-leptonic B meson decays, for instance,
will not be relevant for the model. Thus, we will concentrate ourselves
on leptonic observables. An important fact appears as consequence of the
specific form we are considering here: flavour limits will not depend on
the specific form of the symmetry imposed on the scalar potential.
Hence, the constraints we will obtain here will be applicable to both
@xmath and @xmath symmetry models. Let us write here the part of the
lagrangian which presents flavour changing interactions, in terms of
neutrino flavour eigenstates

  -- -------- -------- -- --------
     @xmath   @xmath      
                          (4.22)
  -- -------- -------- -- --------

We can integrate out the charged scalar since we know that its mass
needs to be larger than @xmath GeV. Consequently, for the energy scales
we will consider here ( @xmath MeV), we can work in an effective theory
framework. We find

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

where we defined

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

and we presented only the relevant interaction term for our purposes.
Let us notice that the previous effective lagrangian depends only in the
right-handed neutrino state; thus, this new interaction will not modify
the propagation of neutrinos created in nuclear processes since in such
processes neutrino are left-handed, as we have seen before. We will
divide our study in two categories: processes with or without flavour
conservation. Our results are summarized in 4.7 .

##### 4.2.1 Flavour-conserving Decays

For the case in which the interactions are flavour-conserving, we will
consider the tree level decays @xmath . The contribution of the scalar
can be codified through the flavour gauge couplings @xmath [ 139 ] . The
total width in the presence of a charged scalar is [ 116 , 103 ]

  -- -------- --
     @xmath   
  -- -------- --

which allows to obtain the relation for the flavour couplings as

  -- -------- -------- -- --------
     @xmath   @xmath      (4.25)
  -- -------- -------- -- --------

  -- -------- -------- -- --------
     @xmath   @xmath      (4.26)
  -- -------- -------- -- --------

where we defined @xmath and @xmath . Notice that the new physics is
codified through the @xmath parameter. From expressions ( 4.25 ), ( 4.26
), can be obtained bounds on the @xmath parameter from the @xmath and
@xmath leptons half-lives. However, experimentally we know that such
half-lives are compatible with the lepton universality at @xmath level.
A possible explanation for these results appears when we study the
dependence of @xmath with the mass of the lightest neutrino, @xmath ,
figure 4.4 . We see the specific values for @xmath and @xmath which can
be small for @xmath . Thus, the flavour couplings will be also small,
and we will not be able to extract information from these observables.

##### 4.2.2 Flavour-violating Processes

Next, we will analyse processes in which there is flavour violation.
These processes are, or will be, constrained by experimental data. For
the neutrinophilic case, such processes come from 1-loop corrections
mediated by the charged scalar, and they will constrain the model.

###### @xmath

The processes currently possessing the strongest experimental bounds is
@xmath . Considering in general the decay @xmath , it is possible to
find the branching ratio of this process as a function of the parameter
@xmath [ 103 ]

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

The strongest experimental bound comes form Mu to E Gamma-II (MEG-II)
experiment, @xmath [ 140 ] while, for the other channels, there are
weaker limits, @xmath and @xmath , obtained by the BaBar experiment [
141 ] . We can then set limits to our model as

  -- -------- --
     @xmath   
  -- -------- --

The bound @xmath is the best current limit obtained for the @xmath and
@xmath parameters since it implies that, supposing @xmath eV, the
charged scalar mass will be @xmath @xmath GeV. In the future, if the
predicted sensitivity of MEG will be achieved, @xmath [ 142 , 143 ] ,
the limit on the @xmath parameter can be improved by an order of
magnitude, @xmath . The current bound and future sensitivity are
presented in figure 4.7 , as the blue line. Furthermore, we should
emphasize that if the @xmath decay is observed by some experiment, the
neutrinophilic @xmath HDM will predict a specific relation between BR
@xmath and BR @xmath branching ratios, depending on the CP violation
phase @xmath in the leptonic sector. We present the ratio between these
branching ratios as a function of the CP phase in figure 4.5 . There we
can see that a limit on BR @xmath puts a stronger limit on BR @xmath ,
independently on the phase. If the CP phase is determined by oscillation
experiments, for instance, we will obtain a correlation among the
branching ratios.

###### @xmath

An analogous process that appears in these scenarios consists in the
decay into three charged leptons. Such process can be described by the
effective lagrangian

  -- -------- -- --------
     @xmath      (4.28)
  -- -------- -- --------

where @xmath and @xmath are the Wilson coefficients associated to the
penguin diagrams of the photon and the box diagrams of the Higgs,
respectively. Neglecting the neutrino masses and taking @xmath , we find

  -- -------- -------- -- --------
     @xmath   @xmath      (4.29)
     @xmath   @xmath      (4.30)
     @xmath   @xmath      (4.31)
  -- -------- -------- -- --------

where @xmath is the squared momentum of the photon. We should mention
here that we are not considering the penguin diagrams of the @xmath
boson since those diagrams are suppressed by the @xmath and @xmath
masses. Computing the branching ratio in terms of the previous
coefficients, we have

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.32)
  -- -------- -------- -- --------

Let us note that the Wilson coefficients associated to the box diagrams
have a different dependence on @xmath . This is the reason why we can
not write this ratio in terms of the parameter @xmath .

Taking into account the previous results, we see that the box diagrams
dominate when @xmath is small, while the penguin ones dominate for
larger values. Using the experimental bound @xmath [ 144 ] , and
supposing that @xmath is in the region where penguins dominate, we find
that @xmath eV @xmath . The result independent on the choice of @xmath
is in figure 4.7 , green dashed line. We should notice that the current
value for @xmath is stronger than the bound obtained in the previous
subsection when @xmath eV, region where box diagrams dominate.
Furthermore, using the sensitivity expected for the future experiment Mu
@xmath e, @xmath [ 145 ] , we find that @xmath future sensitivity is
bigger than @xmath , see figure 4.7 , right panel.

###### @xmath conversion in nuclei

The @xmath conversion is a process which may become an important bound
for different neutrino mass models. For the neutrinophilic @xmath HDM,
the dominant contributions come only from penguin photon diagrams given
that other diagrams are suppressed by the number of protons @xmath , the
electron mass or the tiny couplings between quarks and the
neutrinophilic charged scalar. The conversion rate in nuclei is given by
[ 146 , 147 , 148 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (4.33)
  -- -------- -------- -- --------

being @xmath the electron momentum and energy, and they are
approximately equal to the muon mass; @xmath are the proton and neutron
numbers of the nucleus, respectively; @xmath is the effective atomic
charge and @xmath is the nuclear matrix element given in table 4.1 for
the nuclei we will consider [ 147 ] . Let us note that the conversion
rate is normalized to the muon capture rate @xmath . The coefficients
@xmath are given by [ 146 , 147 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (4.34a)
     @xmath   @xmath      (4.34b)
  -- -------- -------- -- ---------

We have to emphasize here that only the vector couplings are relevant
given that only the photon penguins diagrams contribute. Therefore,
valence quarks ( @xmath ) will be relevant because see quarks, as the
strange quarks, interact effectively through the scalar part. The
couplings @xmath are

  -- -------- -------- -- --------
     @xmath   @xmath      (4.35)
  -- -------- -------- -- --------

For completeness, we quote the values of the coefficients @xmath [ 147 ]

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

From the current limits on @xmath conversion, given in table 4.2 and
taken from [ 153 ] , we obtain the following bounds

  -- -------- --
     @xmath   
  -- -------- --

while, using the future sensitivities proposed by future experiments, we
find the region which can be constrained in the neutrinophilic @xmath
HDM

  -- -------- --
     @xmath   
  -- -------- --

We see then that the @xmath conversion in nuclei will be the most
sensitive processes, if the collaborations achieve their proposed
sensitivities. In figure 4.7 , we see the current limits and future
sensitivities obtained from this process.

###### @xmath

Another process which can violate flavour due to the possible existence
of charged scalars is the @xmath boson decay, @xmath , @xmath . In the
models we are interested in, we have loop processes that generate this
decay, see figure 4.6 . The effective hamiltonian in this case is

  -- -------- -- --------
     @xmath      (4.37)
  -- -------- -- --------

where the Wilson coefficient @xmath is given by

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.38)
  -- -------- -------- -- --------

being @xmath . In the case in @xmath , the previous expression can be
approximated to

  -- -------- -- --------
     @xmath      (4.39)
  -- -------- -- --------

The @xmath boson decay width is

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

where we see that the Wilson coefficient appears explicitly in the
expression. Here @xmath .

The strongest experimental bound corresponds to the ATLAS superior
limit, @xmath [ 154 ] . The channels where there is a tau in the final
state were studied by LEP, and possess a weaker bound @xmath and @xmath
[ 155 ] . Thus, taking into account the previous results, we find that
@xmath eV @xmath , which is weaker than the results from previous
processes. Now, considering the future sensitivity of a
electron-positron collider, we have found that the bound will not be
improved significantly [ 122 ] .

###### @xmath

Finally, we will consider the flavour-violating Higgs decay. In an
analogous manner as previously done for the @xmath boson decay, we have
that the effective hamiltonian is given by

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

with the Wilson coefficient @xmath

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.42)
  -- -------- -------- -- --------

Here, we assumed that @xmath and defined @xmath . The coupling @xmath is
the trilinear coupling among @xmath , and will depend on the specific
case of the symmetry considered. The coefficient in the asymptotic limit
is given by

  -- -------- -- --------
     @xmath      (4.43)
  -- -------- -- --------

The decay width @xmath is

  -- -------- -- --------
     @xmath      (4.44)
  -- -------- -- --------

To obtain the bound from this case, we will consider only the @xmath
scenario since we have seen that the other model is strongly constrained
by Electroweak precision tests. Using the same scan performed in the
previous section, we obtained a value for the decay width @xmath ,
corresponding to the largest flavour violation, in terms of the
branching ratio @xmath , as shown in figure 4.8 . We see that @xmath can
not be larger than @xmath MeV, due to the strong limit on @xmath of
MEG-II. As consequence, we see that such small value of the branching
ratio is beyond the reach any future Higgs precision experiment.

We have seen in this chapter the limits coming from theoretical and
phenomenological characteristics that the neutrinophilic model must
fulfil. From the Electroweak precision tests, we see that the simplest
cases of the symmetries applied to the scalar potential have problems to
accommodate the data. In special, the @xmath symmetry model is
practically excluded after the Higgs discovery at the LHC. The second
model does not possess problems with the precision data, but it has a
very limited spectrum. It is possible that these problems can be solved
by choosing other symmetries, or modifying the value of the @xmath
parameters. Let us notice here that such parameter is the crucial one
for the phenomenology. On the other hand, we have seen how lower energy
bounds on flavour violating decays constrain the mass of the charged
scalar and the VEV of the second doublet. Basically, the @xmath decay
imposes that the mass of the charged scalar has to be bigger than @xmath
GeV when the VEV is smaller than @xmath eV. A crucial characteristic of
this limit is that it is independent on the additional symmetry chosen
for the model; thus, in principle, it can be applied to other possible
scenarios. In the next chapter we will consider a possible manner to
differentiate between Dirac and Majorana neutrinos by the detection of
the cosmic neutrino background.

### Chapter 5 Non-Standard Interactions and the Detection of the Cosmic
Neutrino Background \lettrine

Hubble’s discovery about the expansion of the Universe led to the
development of Cosmology. Works from several great physicists showed
that the Universe had a beginning, and its evolution can be tracked to
times larger than @xmath s. After the Big Bang, all known particles were
initially at thermal equilibrium provided by the interactions.
Nonetheless, the expansion of the Universe acted in such a way that some
particles decoupled from the rest of the particles as their interaction
rate became weaker than the expansion rate. More and more particles
decoupled from the bath until only neutrinos, electrons, positrons and
photons remained in thermal equilibrium at temperatures of @xmath MeV
@xmath . Then, neutrinos decoupled @xmath s after the Big Bang, creating
the cosmic neutrino background ( @xmath ). Afterwards, electrons and
positrons annihilated each other, creating the cosmic microwave
background (CMB); such radiation background, created @xmath years after
the Big Bang, have been already detected and is still being analysed [
45 ] . Even though the @xmath contains information on a very early epoch
of the Universe, it has not been observed yet; thus, the detection of
these relic neutrinos is fundamental. However, such discovery does not
seem to be an easy one. The main reason is the small interaction between
very low energy neutrinos and the rest of matter.

Distinct methods have been proposed, but many of them are beyond the
current technology. The most promising one consists in the capture of
the neutrinos belonging to the @xmath by a nucleus, creating an
electron. The energy of such electron will depend directly on the
neutrino mass. Supposing only SM interactions, previous works [ 43 ]
have shown that the capture rate is different according to the
neutrino’s nature (Dirac or Majorana). Then, one can ask what could be
the impact on the capture rate if there were Non-Standard Interactions
(NSI) couplings with neutrinos? We will present hereafter the
repercussion of those NSI on the @xmath capture rate. Accordingly, we
will first analyse the properties of the neutrino background and its
detection. Subsequently we will determine the consequence of the
possible existence of NSI. This chapter contains novel results which
have been published in [ 156 ] .

#### 5.1 Cosmic Neutrino Background

Let us start considering the generation of the @xmath . To do so, we
will analyse the primordial plasma at a temperature of @xmath MeV [ 157
] , in which left-handed neutrinos were in thermal equilibrium with
electrons, positrons and photons. All the other particles are supposed
to be already decoupled. Neutrinos were maintained in equilibrium due to
charged- and neutral-current interactions @xmath and @xmath . As noted
before, weak interactions are the responsible for the preservation of
the thermal equilibrium. In such equilibrium situation, we can compute
the number density of one neutrino species @xmath , having a mass @xmath
, at a temperature @xmath

  -- -------- -------- -- -------
     @xmath   @xmath      (5.1)
  -- -------- -------- -- -------

with @xmath , @xmath the number of internal degrees of freedom and
@xmath the chemical potential. Since we are considering neutrinos at
temperatures larger than the masses @xmath and we suppose that there is
a negligible lepton asymmetry @xmath , we can approximate the integrals
to obtain [ 42 ]

  -- -------- -------- -- -------
     @xmath   @xmath      (5.2)
  -- -------- -------- -- -------

However, at some point, the expansion rate of the Universe became
stronger than the weak interaction rate, and neutrinos froze out from
the primordial plasma. To determine the temperature @xmath in which the
freeze out happened, let us remember the criterion established in
chapter 2 . When the interaction rate is smaller than the Hubble
expansion rate, the species becomes out-of-equilibrium. For the weak
interaction we have [ 42 , 157 ]

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

so, near a temperature of @xmath MeV, neutrinos decouple from the
primordial plasma. After the neutrino decoupling, when the plasma
becomes colder than the electron mass, electrons start to annihilate
with positrons, increasing the photon temperature. Considering the
entropy conservation, one can show that the neutrino and photon
temperatures are related by [ 42 ]

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

thus, as the photon temperature measured at the present time is @xmath K
( @xmath meV), neutrinos should have a temperature of @xmath K ( @xmath
meV) today. To comprehend the properties of the @xmath , let us compute
the root mean square momentum per neutrino species at the present time

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

where the number density today per species is

  -- -------- -------- -- -------
     @xmath   @xmath      (5.6)
  -- -------- -------- -- -------

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Therefore,

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

We see that neutrinos have a very small momentum today, so the @xmath is
actually composed by non-relativistic particles unless one of them is
massless. This will have crucial consequences for the detection of these
particles. In the first place, neutrino flavour eigenstates have
suffered decoherence into their mass eigenstates due to the separation
of the mass eigenstates wave packets; the @xmath is then basically
composed by these independent mass eigenstates. Second, at the present
time, the neutrino background is composed not by chiral but by helicity
eigenstates. Let us analyse this in more detail.

When neutrinos decouple from the primordial plasma, they have momenta of
@xmath ; thus, they are ultrarelativistic particles. We can then
approximate helical and chiral states. Due to the expansion of the
Universe, neutrinos evolved into a non-relativistic state, and chirality
became different from helicity. At first sight, neutrinos are free
particles, but what are the states that are conserved in the evolution?
Let us remember that the free Dirac hamiltonian conserves helicity and
violates chirality due to the mass term. Therefore, neutrinos were
created with a definite chirality, but the free evolution conserved only
the helical states ¹ ¹ 1 If the neutrino underwent a clustering process,
we have that the helicity is not conserved either. However, the final
@xmath will be composed by equal abundances of the helicity states [ 43
] . Consequently, an essential differentiation between Majorana and
Dirac neutrinos arises in the @xmath . If neutrinos are Dirac fermions,
the left- and right-handed components @xmath behave differently under SM
gauge interactions. Only left-handed neutrinos are in thermal
equilibrium with the plasma as a right-handed neutrino cannot be in
equilibrium through Yukawa interactions only [ 158 , 159 ] . Thus,
neutrinos @xmath and antineutrinos @xmath ² ² 2 @xmath corresponds to
the charge conjugate of @xmath . before the freeze out have the
following abundances per species [ 160 , 43 ]

  -- -------- -------- -- --------
                          
     @xmath   @xmath      
     @xmath   @xmath      (5.8a)
  -- -------- -------- -- --------

being @xmath the temperature before the decoupling. Notice the absence
of the @xmath factor; this is due to the fact that we are explicitly
writing the densities for each internal degree of freedom. After
neutrinos froze out, the previous abundances become abundances of
helical states @xmath , with @xmath being the left-(right-) helicity at
the present time per species

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (5.9a)
     @xmath   @xmath      (5.9b)
  -- -------- -------- -- --------

with

  -- -------- --
     @xmath   
  -- -------- --

On the other hand, if neutrinos are Majorana fermions, we will need two
different particles per generation, a left-handed neutrino @xmath and a
right-handed neutrino @xmath . Only the left-handed neutrino interacts
weakly while, if we consider the seesaw scenario, the right-handed
neutrinos are heavy, making their abundances zero at the present time.
This due to the fact that they decayed into leptons and Higgs way before
the neutrino decoupling as we saw in chapter 2 when we considered
leptogenesis. Therefore, their abundances per species before the freeze
out are

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.10a)
     @xmath   @xmath      (5.10b)
  -- -------- -------- -- ---------

This means that today the abundances of the helicity states in the
Majorana case are

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.11a)
     @xmath   @xmath      (5.11b)
  -- -------- -------- -- ---------

as a left(right)-handed Majorana neutrino has two helical states @xmath
. We can see then that the abundances of left- and right-helical states
is different in Dirac and Majorana cases. This discrepancy is due to the
distinct behaviour of chiralities and helicities for Dirac and Majorana
neutrinos since only left-handed chiral states interact weakly. If
neutrinos are Dirac particles, just left-handed neutrinos and
right-handed antineutrinos are decoupled at @xmath MeV, and their free
streaming makes the left-handed chiral states to be actually
left-helical particle states, and right-handed chiral states become
right-helical antiparticle states. In the Majorana scenario, the
left-handed neutrino freezes out alone; nonetheless, it is composed by
the two helical states. Therefore, the Dirac @xmath is composed by
left-helical particles and right-helical antiparticles while, in the
Majorana case, it will be composed by left- and right-helical particle
states. This difference will be decisive when we consider the possible
detection of the @xmath .

#### 5.2 Detection of the @xmath

The detection of the @xmath in Particle Physics and Cosmology is
comparable to the quest of the Holy Grail. The @xmath can confirm
several properties predicted by the @xmath CDM cosmological model since
it contains information from an era before the CMB creation. Thus,
during the past decades, several methods have been proposed to detect
this background. We will present next briefly some of them. Let us
stress here that we will not consider the possible clustering of
neutrinos around massive objects, for simplicity. For more information,
see the work from A. Ringwald and Y. Y. Y. Wong [ 161 ] and the more
recent work from P. F. de Salas et. al. [ 162 ] .

Stodolsky Effect. This effect, proposed by Stodolsky [ 163 ] , considers
the generation of an energy difference between the two electron helicity
states in a ferromagnet due to the presence of the @xmath . Such energy
shift will depend on the neutrino asymmetry. It has been shown that it
is different for Dirac and Majorana neutrinos [ 160 ] . For the Dirac
case, the energy difference created per species is proportional to

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

where @xmath is the Earth velocity with respect to the neutrino
background, @xmath is the axial SM coupling, @xmath is the chemical
potential @xmath , and R(NR) are for relativistic (non-relativistic)
relic neutrinos. Therefore, any given neutrino can be relativistic or
not since we are considering any possible value for the masses. For
Majorana neutrinos [ 160 ] ,

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

Considering the energy difference previously shown, we can conceptualize
an experimental set up for the detection. Supposing that we have a
magnetized spherical material, a ferromagnet, we find that the @xmath
will create a torque on the sample, given by [ 160 , 164 , 165 ]

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the number of polarized electrons. Supposing Dirac and
relativistic neutrinos, the @xmath will produce an acceleration on the
material [ 160 , 165 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.14)
  -- -------- -------- -- --------

being @xmath a geometrical factor related to the detector’s moment of
inertia, @xmath the atomic number, @xmath the radius of the material,
and @xmath is the neutrino-antineutrino asymmetry number density. For
non-relativistic Dirac and Majorana neutrinos, the acceleration can be
one order of magnitude larger, at most [ 160 ] . Anyhow, this is an
extremely small acceleration, faraway from the current sensitivity.

CNSN and a Cavendish-like torsion balance. Relic neutrinos can be
scattered coherently by a nucleus. This specific interaction, the
Coherent Neutrino Scattering off Nuclei, will be studied deeply in the
chapter 6 . Integrating the differential cross section for such process
and considering small neutrino energies, one finds [ 160 , 164 , 165 ]

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

where the neutrino energy is

  -- -------- --
     @xmath   
  -- -------- --

with the factor @xmath coming from the thermal average over the
Fermi-Dirac distribution function. This is a quite small cross section;
however, relic neutrinos have macroscopic de Broglie wavelengths @xmath
. Therefore, the cross section is also enhanced by the scattering on
nuclei distributed in a volume with size @xmath . In an experiment like
a Cavendish torsion balance, we can detect the force exerted on a
pendulum by the cosmic neutrino background. This will result in a
acceleration [ 160 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (5.16)
  -- -------- -------- -- --------

where @xmath is the number of nuclei, @xmath is the mass density of the
target and @xmath is the Earth velocity in the CMB frame. For
non-relativistic neutrinos, we have [ 160 , 164 , 165 ]

  -- -- -- --------
           (5.17)
  -- -- -- --------

which is also a tiny acceleration. Let us also stress here that the
previous value corresponds to Dirac neutrinos; for the Majorana case, we
have an additional suppression since these particles only have axial
couplings.

Scattering from Ultra-high-energy Cosmic Rays. Another possibility to
detect the relic neutrino background is by its interaction with
Ultra-High-Energy (UHE) neutrinos, neutrinos with energy of @xmath GeV [
164 ] ,

  -- -------- --
     @xmath   
  -- -------- --

then, a detector could see either a @xmath burst, as an excess of cosmic
rays above the Greisen-Zatsepin-Kuzmin (GZK) cutoff, or a diminution of
the UHE cosmic neutrino flux as consequence of the interaction with the
@xmath . Nevertheless, the rates for both cases are small and beyond the
current tecnology [ 164 ] .

Neutrino Capture. A more promising manner to detect the @xmath is
through neutrino capture by a nuclei [ 166 ] . This capture will create
a peak in the value of the neutrino masses. We will concentrate
ourselves in the remaining of the chapter on this method, following the
description given by the Long et. al. work [ 43 ] . This approach is
based on the threshold-less interaction

  -- -------- --
     @xmath   
  -- -------- --

to capture a relic neutrino. We have chosen tritium as target material
since it will be used by the Princeton Tritium Observatory for Light,
Early-Universe, Massive-Neutrino Yield (PTOLEMY) experiment, which is
being developed [ 167 ] . The capture rate of the @xmath will be
computed in detail, given its peculiarities compared to rates and cross
sections computed with ultrarelativistic neutrinos. Let us first compute
the neutrino capture by a neutron,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the @xmath -th neutrino mass eigenstate field. The
effective lagrangian for this process will be the Fermi lagrangian,

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

Here we have @xmath and @xmath , the CKM and PMNS matrix elements
relevant for the process; @xmath are the nuclear form factors, related
to the vector and axial nucleon structures. Computing the amplitude
squared for this process and summing over the spin indexes, we can
obtain the total rate. However, we need to take into account that
neutrinos are prepared in an specific helicity state while the neutron,
proton and electron are not. Therefore, we will just sum over the
neutron, proton and electron spins. We use the usual completeness
relation for @xmath

  -- -------- --
     @xmath   
  -- -------- --

while for the relic neutrino we use the relation for a fixed helicity (
@xmath )

  -- -------- --
     @xmath   
  -- -------- --

being the spin four-vector @xmath given by

  -- -------- --
     @xmath   
  -- -------- --

Now, we can determine the differential cross section for the neutrino
capture in a standard way. We get in the rest frame of the neutron

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

where @xmath are the neutrino and electron velocities, respectively;
@xmath is the energy and momentum of the electron, @xmath the angle
between the electron and the neutrino. @xmath is the Fermi function
which takes into account the enhancement of the cross section due to the
electromagnetic attraction between the proton and electron,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , @xmath the fine structure constant. The functions @xmath
and @xmath appearing in 5.19 are given by

  -- -------- -------- -- --------
     @xmath   @xmath      (5.20)
  -- -------- -------- -- --------

We see here that if neutrinos are ultrarelativistic, @xmath , @xmath are
zero for right-helical neutrinos, making their capture impossible, while
for left-helical @xmath . This is actually an expected result; let us
remember that, in the massless limit, chirality and helicity coincide
and only left-chiral neutrinos interact weakly. On the other hand, if
neutrinos are non-relativistic we have that @xmath , showing the
possibility of detecting both kinds of helical states. The integration
in the angle is trivial, and we can obtain the capture cross section
multiplied by the neutrino velocity, which is the relevant quantity for
the @xmath capture rate,

  -- -- -- --------
           (5.21)
  -- -- -- --------

In the case of interest, the neutrino capture of a tritium nuclei, we
simply need to make the substitutions of @xmath and @xmath . Notice that
for simplicity we are not considering the modification of the nuclear
form factors, as done in [ 168 ] ³ ³ 3 We will not consider the vector
and axial form factor for tritium as we do not have defined values for
scalar and tensor ones. So, to avoid having two different sets of
parameters, we will use only neutron form factors, as done in [ 43 ] .
This will introduce a difference of @xmath with the values presented in
[ 168 ] . The total capture rate expected in a sample of tritium is the
sum over the cross section for each of the three mass eigenstates (
@xmath ) weighted by the appropriate flux

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

where @xmath is the number of nuclei present in the sample. In the case
of non-relativistic neutrinos, we get a simpler relation,

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

being

  -- -------- --
     @xmath   
  -- -------- --

Applying these results to the Dirac and Majorana cases we have that

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

for Dirac neutrinos, while

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

for the Majorana case. Evidently,

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

which shows that the capture rate of Majorana neutrinos is twice as the
Dirac case. This can be explained keeping in mind that the @xmath in the
Dirac case consists of left-helical neutrinos and right-helical
antineutrinos. However, the right-helical antiparticle states cannot be
captured because the process involving an antineutrino @xmath is
kinematically forbidden. Thus, Dirac neutrinos have only half of the
@xmath abundance available to be captured. In the Majorana case, we will
have left- and right-helical neutrinos, which can be captured. This is a
crucial result since, in principle, the neutrino capture experimental
technique not only can be used to detect the neutrino background, but
also to shed some light on the neutrino nature. Numerically, we have
that

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

which corresponds approximately to the values given in [ 43 ] when the
sample is composed by @xmath g of material, as in the case of PTOLEMY [
167 ] .

We should ask ourselves at this point how would be the signal in the
neutrino capture rate, and what are the main difficulties of this
method. PTOLEMY intends to detect relic neutrinos by the measurement of
the electron created in the process. Nonetheless, tritium atoms undergo
beta decay, in which the electrons emitted have a wide energy spectrum.
Thus, one should be able to discriminate electrons from neutrino capture
from the beta decay electrons. From a kinematic point of view, electrons
produced by relic neutrinos will have a definite energy [ 43 ]

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

where @xmath corresponds to the beta decay endpoint energy. This shows
that relic neutrinos can produce a peak in an energy bigger than the
beta endpoint one, making it possible to discriminate them.
Nevertheless, this is a questionable affirmation since it does not take
into account the finite resolution that a real detector has. In order to
do a more realistic study, we will convolute the @xmath capture rate
with a Gaussian resolution function [ 43 ]

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

Furthermore, we will need the beta decay rate for tritium. We will use
the more recent result from [ 168 ] ,

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

where the rate for one neutrino mass eigenstate is

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

with the definitions [ 168 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.32a)
     @xmath   @xmath      (5.32b)
     @xmath   @xmath      (5.32c)
     @xmath   @xmath      (5.32d)
     @xmath   @xmath      (5.32e)
     @xmath   @xmath      (5.32f)
     @xmath   @xmath      (5.32g)
  -- -------- -------- -- ---------

and

  -- -------- --
     @xmath   
  -- -------- --

The beta decay rate will be also convoluted with a Gaussian resolution
function,

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

To estimate the region that can be distinguished from the beta decay
background, we will compute the number of events around the energy
created by the relic neutrino capture as [ 43 ]

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.34a)
     @xmath   @xmath      (5.34b)
  -- -------- -------- -- ---------

where @xmath corresponds the full width at half maximum (FWHM) of the
Gaussian function, related to the standard deviation @xmath as

  -- -------- --
     @xmath   
  -- -------- --

Therefore, to distinguish the @xmath signal from the beta decay
background, we will consider the ratio,

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

in such a way that the signal can be discriminated when @xmath .
However, we are laying aside the fact that both signal and background
depend on the values of the neutrino masses. Thus, we should understand
the regions where the mass eigenstates are degenerated or not, and see
that if there is a possible differentiation among each contribution.
This can, in principle, be possible as each mass eigenstate is captured
independently from the others. Even though we computed the total
neutrino capture as the sum over the three mass eigenstates, we can
consider each contribution in ( 5.22 ) as

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

thus, we also can compute the number of events after convoluting with a
proper Gaussian

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

with @xmath the energy of the electrons produced by each mass
eigenstate. Then, we have two tasks, first see if it possible to
discriminate the @xmath signal over the background and, second,
comprehend if a mass eigenstate can be distinguished from the others.
The first discrimination can be achieved by considering the ratio @xmath
for each eigenstate; for the second one, we should ask ourselves how to
differentiate two Gaussians according to their mean values and standard
deviations. We will use the Bhattacharya distance between two Gaussians
[ 169 ] as a basic condition for discrimination, given by

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

with @xmath two different Gaussians. We will define a discrimination
function to determinate the separation of each neutrino capture rate
contribution

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

This function has been constructed to fulfil the following purpose. When
the mass eigenstates are degenerated, the function will give the value
of the total neutrino capture. This is clear as the Bhattacharya
distance in such case goes to zero, making the Heaviside theta to be
null. Then, if the third mass eigenstate ⁴ ⁴ 4 The third neutrino can be
separated first from the other two as the quadratic mass difference
@xmath ( @xmath ) is larger than @xmath . has a mass different enough to
be distinguished from the other two masses, the @xmath will correspond
to the value of neutrino capture for @xmath , while @xmath and @xmath
will be equal to the sum of the rates of @xmath and @xmath . The last
possibility consists in the separation of the three eigenstates; thus,
for each case, @xmath will give the value of the individual neutrino
capture rate. In the definition of @xmath , equation ( 5.38 ), we chose
a value of @xmath as a parameter to distinguish the two Gaussians. This
number has been adopted noting that the Bhattacharya distance for two
functions with equal standard deviation is

  -- -------- --
     @xmath   
  -- -------- --

so, to completely separate two Gaussians, we require that the difference
of their mean values to be at least equal to @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Therefore,

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

Let us note that this definition does not take into account the cases in
which the Gaussians are superimposed but distinguishable since it
depends on the number of events and the analysis performed on the data.
Therefore, we will consider only when the Gaussian functions are
completely separated. To understand the behaviour the @xmath function,
we performed a scan over the neutrino oscillations parameters at @xmath
level. In figure 5.1 , we show the discrimination function dependence on
the lightest neutrino mass @xmath , for the mass eigenstates @xmath
(green), @xmath (red), @xmath (blue), for both types of mass orderings
and two values of @xmath . The gray points can not be distinguished from
the beta decay background.

We see that for both orderings and @xmath eV and for @xmath eV that the
relic neutrinos will appear as a single peak while for @xmath eV it
could be possible to differentiate two peaks. For a Normal Ordering and
the smaller example of @xmath eV there are two possibilities: for @xmath
eV, it would be possible to distinguish two peaks whilst, for @xmath eV
the three peaks could be discriminated. For the Inverted Ordering case,
there will be still two peaks. This is related to the mass difference in
this ordering, as the neutrinos @xmath and @xmath become almost
degenerated when @xmath .

To illustrate how could be the spectra observed by PTOLEMY, we show two
examples in figures 5.2 and 5.2 for the values of @xmath considered. In
figure 5.2 we show simulated spectra for two values of masses @xmath eV
and the beta decay spectrum (gray). In the first case, figure (a)a , we
see that in both orderings the spectra for each mass eigenstate can not
be distinguished as they are superimposed. Thus, in this case we expect
a unique peak for the electrons produced by the @xmath . For the
lightest neutrino mass of @xmath eV, figure (b)b , the peak related with
the @xmath eigenstate can be in principle differentiated from the other
two neutrinos. Nevertheless, such peak is tiny compared to the other
two. This is due to the dependence of the neutrino capture with the PMNS
matrix. Explicitly, we have

  -- -------- --
     @xmath   
  -- -------- --

where [ 84 ]

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

This shows that the neutrino capture rate for the third mass eigenstate
is very small, and it can be lost in other background that could appear
in PTOLEMY. This is further visualized in figure 5.3 for the extreme
resolution @xmath eV. For the mass of @xmath eV, figure (a)a , it is
clear that @xmath neutrinos can be distinguished, but the size of the
peak is extremely small. On the other hand, in the case @xmath eV,
figure (b)b , we see that the three peaks can be separated in the Normal
Ordering, but such separation is not possible in the Inverted Ordering.
This is related to the degeneracy that appears in such ordering, as
already pointed out.

Furthermore, as explained in [ 43 ] , the detection in the Normal
Ordering is harder than in the Inverted case, since in the Inverted case
@xmath and @xmath have the largest rate and they are more separated from
the beta decay background. While in the Normal Ordering case occurs the
opposite, the @xmath and @xmath are always closer to the beta decay
background. This also can be seen in figure 5.1 since the region hidden
in the background is different for each ordering; then, in the Inverted
case, the gray points are only in the @xmath value of the discrimination
function, while in the Normal one, they are in the largest contribution.

The expected resolution of PTOLEMY is @xmath eV [ 167 ] ; thus, it will
explore the initial part of the mass spectrum. In that case, the
neutrinos are degenerated, and the experience will search a single peak.
Accordingly, we will consider from now on the degenerated mass spectrum.
Also, this implies that neutrinos should be non-relativistic in the
@xmath . Next, we will consider the consequences of this fact in the
presence of beyond SM physics.

#### 5.3 Parametrization of the Beyond SM Physics

To obtain the previous relic capture rate we considered only the Fermi
lagrangian, i.e. we considered only SM interactions. Nevertheless, it is
possible that NSI play a role in neutrino capture since the @xmath is
composed by non-relativistic particles. Thus, we can expect
contributions that are usually negligible for an ultrarelativistic
neutrino to be sizable here. In order to maintain the discussion as
general as possible, we will consider the Effective Field Theory
approach. The first operator we could think about, the dimension-five
Weinberg operator, will give only mass to neutrinos, as we have seen in
chapter 2 . So, we will start considering dimension-six operators which
are invariant under the SM gauge group, SU( @xmath ) @xmath U( @xmath )
@xmath , but also including right-handed neutrinos [ 170 ] .

The general lagrangian we will consider is given by

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

where @xmath is an energy scale, @xmath are the dimensionless Wilson
coefficients, @xmath is the neutrino mass lagrangian. The set of
operators with left- and right-handed neutrinos @xmath is given in table
5.1 . The relevant terms for the determination of the relic neutrino
capture can be obtained from the complete lagrangian 5.40 ,

  -- -------- -- --------
     @xmath      (5.41)
  -- -------- -- --------

where @xmath , related to the dimensionless couplings @xmath ,
parametrize the NSI; @xmath corresponds to the coupling in the lepton
sector while @xmath to the quark one, @xmath and @xmath are the Lorentz
structures for each case. The couplings and structures are given in
table 5.2 [ 171 , 172 , 168 ] .

We need to translate these interactions to the hadron level by
considering [ 168 ]

  -- -------- -- --------
     @xmath      (5.42)
  -- -------- -- --------

where @xmath and @xmath are the hadronic initial and final states. These
matrix elements are calculated by matching the low-energy QCD effective
theory to the quark-level lagrangian. For our case, we have that for
protons and neutrons ⁵ ⁵ 5 We are not including the contribution of a
weak-magnetic term as

@xmath

since we found that it does not contribute to the @xmath capture rate.

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.43a)
     @xmath   @xmath      (5.43b)
     @xmath   @xmath      (5.43c)
     @xmath   @xmath      (5.43d)
  -- -------- -------- -- ---------

We introduced the different hadronic form factors @xmath , @xmath
corresponding to the different vector, axial, scalar, pseudoscalar and
tensor Lorentz structures, respectively. These couplings depend on the
momentum transfer @xmath ; nonetheless, given the small momentum
transfer for the capture rate, we can neglect safely this dependence.
The values of the couplings we are considering are in table 5.3 . For
the specific case of tritium and helium-3, we will suppose that the
hadronic states are obtained by ( 5.43 ) with the substitutions @xmath
and @xmath [ 168 ] .

##### 5.3.1 Specific cases to be considered

The previous NSI lagrangian would not only affect the relic neutrino
capture, but also other low energy processes, such as the beta decay [
178 ] , Cabbibo Universality [ 179 ] , radiative pion decay [ 180 ] and
neutron decays [ 181 ] . A complete compendium of the limits regarding
all low energy decays is given in refs. [ 171 , 172 ] . Thus, before
considering the modification to the capture rate, we should analyse the
limits on the @xmath coefficients from experimental data. We will apply
here the limits from the @xmath -decay of several nuclei [ 178 ] ,
obtaining the allowed parameter space for six specific @xmath
combinations. The bounds on those combinations come from a large set of
experimental data on nuclear beta decay, considering pure Fermi and pure
Gamow-Teller transitions plus data from neutron decay. In such work, the
limits are imposed on the couplings among leptonic and hadronic
currents, @xmath , with @xmath . The prime indicates when the coupling
is related to a Lorentz structure containing the @xmath matrix. This set
of cases is relevant for our case since they include couplings with
right-handed neutrinos. We first need to make a translation between the
@xmath and the @xmath coefficients. One finds that [ 171 ]

  -- -------- -- --------
     @xmath      (5.44)
  -- -------- -- --------

Furthermore, the authors in [ 178 ] constraint specific ratios of the
@xmath parameters

  -- -------- --
     @xmath   
  -- -------- --

In each scenario, distinct combinations of these ratios are bounded. We
performed a scan over the non zero @xmath parameter, to find the allowed
values of @xmath at @xmath C.L. from the global fit for the beta decay
data, in the ranges

  -- -------- -- --------
     @xmath      (5.45)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

We have also scanned over the @xmath value given in table 5.3 since such
parameter is affected by the presence of BSM [ 182 ] . The previous
ranges in which the scan is performed have been chosen to include the
constraints of refs. [ 179 , 180 , 181 ] in the left-chiral coefficients
at the @xmath level. Although stronger limits can be imposed on
right-handed couplings using pion decay [ 183 ] , we will not include
them as they are strongly dependent on the flavour structure of the
model [ 171 , 172 ] . Other constraints, such as LHC bounds coming from
@xmath have been considered in [ 181 , 171 ] . However, in such analysis
is supposed that the interactions of eq. ( 5.41 ) remain point-like up
to the LHC energies, i.e. up to a few TeV. We will allow for the
possibility of having physics BSM at the electroweak scale; thus, we
will use only low-energy constraints. In all scenarios we found that the
parameters @xmath and @xmath are unconstrained by the experimental data,
as it has been previously noted in ref. [ 182 ] .

Left-handed three parameter case. The first case consists in considering
only left-handed couplings in the effective lagrangian by imposing

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

i.e., @xmath , with @xmath . The fit gives the following allowed ranges
for the free parameters [ 178 ]

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

Vector axial-vector three-parameter case. In this case, scalar and
tensor couplings are set to zero. This is achieved by imposing @xmath
and @xmath . The free parameters, in terms of the @xmath parameters, are

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.48a)
     @xmath   @xmath      (5.48b)
  -- -------- -------- -- ---------

The fit obtained for the ratio @xmath is [ 178 ]

  -- -------- --
     @xmath   
  -- -------- --

while for the other two free parameters the @xmath limits have a strong
correlation [ 178 ] .

Right-handed scalar and tensor three-parameter case. We can impose the
constraints

  -- -------- -- --------
     @xmath      (5.49)
  -- -------- -- --------

so, we are considering that the right-chiral scalar and tensor couplings
@xmath are different from zero.

Five parameter case. In this scenario, we will only impose that

  -- -------- -- --------
     @xmath      (5.50)
  -- -------- -- --------

making a total of five free parameters. However, as noticed in the
review [ 178 ] , it is interesting to consider the limits of the
difference and the sum of the scalar and tensor parameters

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.51a)
     @xmath   @xmath      (5.51b)
     @xmath   @xmath      (5.51c)
  -- -------- -------- -- ---------

The limits we will impose are

  -- -------- --
     @xmath   
  -- -------- --

while, for the other parameters, we will consider the correlation bound
at @xmath C. L. [ 178 ] .

#### 5.4 Capture rate of the @xmath considering Beyond SM physics

Having established the scenarios, we can compute the new contributions
to the @xmath capture rate at PTOLEMY. It is important to note here that
Ludl and Rodejohann [ 168 ] have shown that the endpoint of the beta
decay is not modified significantly by the existence of NSI.
Nonetheless, the spectrum has sizeable distortions which can improve the
limits presented before. Thus, it could be possible to differentiate the
@xmath capture rate from the beta decay background even in the presence
of NSI. We will consider neutrinos as Dirac particles since our purpose
is to analyse the possible increase of the capture rate in such case. On
the other hand, we will suppose here that the relic neutrino number
density is not modified significantly by the NSI. We will consider the
implications of modification in the Cosmology in the next section. Let
us remember here that, in order to obtain the capture rate

  -- -------- -- ----------
     @xmath      ( 5.22 )
  -- -------- -- ----------

we need to compute the cross section times the neutrino velocity. The
procedure to obtain this quantity will be identical to the one showed in
previous sections. Considering the complete effective lagrangian, the
capture cross section for a neutrino mass eigenstate @xmath , with
helicity @xmath and velocity @xmath including BSM effects is given by

  -- -------- -- --------
     @xmath      (5.52)
  -- -------- -- --------

where @xmath and @xmath are the helium and tritium masses, and @xmath ,
@xmath , @xmath are the electron energy, mass and momentum,
respectively. The @xmath function contains the dependence on the
neutrino helicity and on the @xmath parameters,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (5.53)
  -- -------- -------- -- --------

with @xmath the mass and energy of the @xmath -th neutrino mass. Let us
study next each case independently.

Left-chiral three parameter case. For the scenario in which only there
are left-chiral couplings, we have

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (5.54)
  -- -------- -------- -- --------

Evidently, when we take all the non-standard couplings to zero, we
obtain the SM result. Let us also note that scalar and tensor parameters
have distinct dependence on the electron energy and mass, because of the
different Lorenz structure. Now, computing the total capture rate for
relic neutrinos using the allowed points obtained in the scan previously
performed, we found that the modification in this case is in the region
@xmath at @xmath level. Here, a minus percentage indicates a diminution
of the rate compared to the SM value. Therefore, we find that the change
is not very significant in this case. This is actually expected as we
saw that the allowed values of the effective couplings are not large,
especially, the values of the scalar and tensor parameters.

Vector axial-vector three-parameter case. In this scenario, we have,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.55)
  -- -------- -------- -- --------

Let us note that the term linear in the right-handed coupling is
proportional to @xmath ; such term would be negligible in the case of a
ultrarelativistic neutrino. Also, we can see that this term comes from
the interference of the standard model with the right-handed neutrino
current. The term proportional to @xmath comes from the square of the
right-handed currents, and it is proportional to the @xmath . Using the
allowed values at @xmath for the @xmath obtained from the beta decay
data, we found that the modification on the @xmath capture rate is in
the range @xmath ; such modification could be significant for a large
enough set of data.

Right-handed scalar and tensor three-parameter case. We have in this
case

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (5.56)
  -- -------- -------- -- --------

again the term proportional to the neutrino mass comes from the
interference between SM and right-handed currents. Furthermore, we
observe that this interference term is not dependent of the neutrino
helicity, i.e. it does not depend on @xmath . This is due to the
different Lorentz structures that appear in the BSM physics.

Considering the allowed parameter space, we obtained the possible
modifications to the relic neutrino capture in this case. We found that
the variation of the rate is in the range @xmath compared to the SM
Dirac case. It is important to note here that the parameter space is
highly correlated since the beta decay bounds impose such correlation.
In figure 5.4 we present the correlation between the parameters @xmath
and @xmath in this scenario. The color code indicates the ratio between
the modified capture rate, denominated as @xmath (RST from Right-handed
Scalar Tensor), and the Dirac SM rate. We see that, for positive values
of the couplings, the modified rate is lower than the SM one while for
negative values the behaviour is the opposite. Therefore, the relic
neutrino capture is sensitive to the sign of the couplings.

Five parameter case. In the fourth scenario, corresponding to the case
in which we have five parameters, we find that the cross section times
the velocity is basically the superposition of the left- and
right-handed leptonic currents coupled with scalar and tensor quarks
currents plus interference terms

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
                          
              @xmath      
              @xmath      (5.57)
  -- -------- -------- -- --------

where now the interference term proportional to the neutrino mass has
mixing terms between @xmath with @xmath . In figure 5.5 , we show the
ratio between the beyond SM capture rate with the SM Dirac rate for this
scenario in the planes which present correlation among the couplings.
Again, the color code indicates the value of the ratio of the modified
capture rate with respect to the SM one. In this case, we find that the
ratio can get the maximum value of @xmath , which is very significant
since it shows that NSI can alter the Dirac relic capture rate to a
value close the Majorana one. Nevertheless, as observed in each plane,
we see that the capture rate can also be diminished by the NSI.
Therefore, if PTOLEMY finds data compatible with the @xmath given the
position of the peak, but the number of events are smaller than the
predicted by the SM, this could suggest the contribution of NSI.
Nevertheless, we should consider the impact of a modification in the
relic neutrino density, and see if one can differentiate such modified
cosmology from NSI.

#### 5.5 Relic Right-Handed Neutrinos

Since we are assuming that NSI are present, we can imagine that in the
Early Universe those interactions may have been important in such a way
that they modified the relic neutrino abundance. Thus, in the first
place, we should consider the modifications in the left-handed Dirac
neutrino abundance. Given that we have seen that these NSI can be at
most @xmath orders of magnitude smaller than the weak interaction, as
the @xmath parameters are of such order, we see that active
(left-handed) neutrinos were mainly maintained in equilibrium by the SM
interactions. Therefore, we do not expect a significant change in the
active neutrino abundance. On the other hand, an important right-handed
Dirac neutrino abundance could have been created. The initial
right-handed abundance can have a thermal or a non-thermal origin. Thus,
in order to estimate such abundance, we will consider the cosmological
constraints on right-handed neutrinos as previously presented in [ 184 ,
185 , 186 , 159 ] for these two different origins.

Let us begin with an initial thermal right-handed neutrino abundance
present in the Universe and maintained in equilibrium by the NSI
themselves or other interactions. As usual, when the expansion rate of
the Universe becomes stronger than the interactions rate, the
right-handed abundance will become decoupled from the plasma. At that
point, the abundance of both left- and right-handed neutrinos per
species are equal since they are maintained in equilibrium

  -- -------- -- --------
     @xmath      (5.58)
  -- -------- -- --------

being @xmath the right-handed neutrino freeze out temperature. The
relationship between the temperature @xmath of a massless ⁶ ⁶ 6 Since
neutrinos are Dirac by hypothesis, the right-handed component has the
same mass as the active one; thus, as @xmath , the right-handed freeze
out temperature should be larger than the left-handed one. Neutrinos can
be considered massless at those temperatures. species after the
decoupling and @xmath is [ 42 ]

  -- -------- -- --------
     @xmath      (5.59)
  -- -------- -- --------

with @xmath the scale factor at the epoch in which occurs the
decoupling. Thus, recalling the relation between number density and
temperature, equation ( 5.2 ), we have [ 186 ]

  -- -------- -- --------
     @xmath      (5.60)
  -- -------- -- --------

To relate the right-handed neutrino abundance with the left-handed one,
we should take into account the conservation of the entropy @xmath [ 42
] , with the effective relativistic degrees of freedom for entropy
@xmath given by

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

Using this conservation, we can get the relation

  -- -------- -- --------
     @xmath      (5.61)
  -- -------- -- --------

where we chose the final temperature as the left-handed neutrino
decoupling temperature @xmath . Furthermore, taking into account that
left-handed neutrinos were in equilibrium in this period @xmath and the
equality at @xmath , equation ( 5.58 ), one can relate the abundances as
[ 186 ] ,

  -- -------- -- --------
     @xmath      (5.62)
  -- -------- -- --------

We need then to obtain the relation of the effective relativistic
degrees of freedom for entropy at both temperatures. This can be done
taking into account that the right-handed neutrino can modify the Big
Bang Nucleosynthesis (BBN), i.e., the creation of light elements at the
Early Universe. Therefore, we define the effective number of thermal
neutrino species @xmath from the total energy density as [ 42 , 186 ]

  -- -------- -- --------
     @xmath      (5.63)
  -- -------- -- --------

with @xmath the total radiation energy density. In the standard @xmath
CDM cosmological model, @xmath . Actually, analysing the CMB spectrum it
is possible to constrain this effective number. It has been shown that
the deviation from the standard value @xmath is related to the ratio of
the effective degrees of freedom as [ 184 , 185 , 186 ]

  -- -------- -- --------
     @xmath      (5.64)
  -- -------- -- --------

so we have

  -- -------- -- --------
     @xmath      (5.65)
  -- -------- -- --------

From the Planck data, we will use the measured effective number of
neutrino species as [ 45 ]

  -- -------- --
     @xmath   
  -- -------- --

thus we have that this value can give us a limit on the right-handed
neutrino density. Considering the upper bound, one gets the largest
possible value of the right-helical neutrino and left-helical
antineutrino number density per species at the present time [ 186 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (5.66)
  -- -------- -------- -- --------

As consequence, the relic neutrino capture needs to be modified to
include the non zero right-handed abundance. In the pure SM case, we
have that the capture rate is proportional to @xmath which for both
left- and right-helical states is approximately @xmath in the case of
non-relativistic neutrinos. Thus, the increase in the capture rate for
Dirac neutrinos can be of @xmath [ 186 ] . Furthermore, for all the
cases in the presence of NSI we have considered, the modification to the
@xmath capture rate due to the additional right-handed abundance
consists on increasing the rate. This is of course expected since we are
including new neutrinos that can be captured. Nevertheless, the
enlargement of the rate is dependent on the case considered. This can be
seen from the definition on the capture rate, equation ( 5.22 ), and the
value of the cross section times velocity in each scenario. We have
checked that the presence of further neutrinos enlarges the capture rate
on @xmath in the vector axial-vector case to a value of @xmath in the
five parameter case. In this last scenario, the @xmath rate can be as
large as @xmath , reinforcing our results on the possibility of having
Dirac neutrinos with a relic capture rate numerically similar to the
Majorana one.

The second possibility consists in having an initial non-thermal right
handed neutrino abundance. We will follow the description given in [ 159
] ; we will suppose that right-handed Dirac neutrinos are initially a
degenerated Fermi gas, decoupled from the thermal bath, with number and
energy densities per species given by [ 159 ]

  -- -------- -- --------
     @xmath      (5.67)
  -- -------- -- --------

being @xmath the Fermi energy. Since the entropy conservation is not
spoiled by the presence of these right-handed neutrinos, the number
density for any given temperature is

  -- -------- -- --------
     @xmath      (5.68)
  -- -------- -- --------

with @xmath . Thus, the relic right-handed neutrino density can be
related to the photon number density as [ 159 ]

  -- -------- -- --------
     @xmath      (5.69)
  -- -------- -- --------

It is necessary to determine the bound from observations on the value of
@xmath . Noticing that these additional degrees of freedom could also
modify the BBN, we can get a value for @xmath using the energy density
at a given temperature [ 159 ] . Adding over the three species, one has

  -- -- -- --------
           (5.70)
  -- -- -- --------

thus, from the Planck value, we have the limit,

  -- -------- -- --------
     @xmath      (5.71)
  -- -------- -- --------

This constraint implies that a right-helical neutrino and the
left-helical antineutrino number density per species today is given by [
159 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (5.72)
  -- -------- -------- -- --------

Including these additional neutrinos, we find that the capture rates
increase even more compared to the thermal right-handed neutrino
abundance, which is completely expected. Furthermore, for the left
chiral and vector axial-vector cases we found that the modification on
the rate can be in the interval @xmath , getting closer to the expected
value for SM Majorana neutrinos. For the other three scenarios we found
larger modifications. In the right-handed scalar-tensor case, the NSI
capture rate has a maximum value of @xmath , while in the five-parameter
case we obtained @xmath . This confirms that it is possible to have a
capture rate for Dirac neutrinos identical to the Majorana case.

Nevertheless, we should notice an important fact. As previously
stressed, the additional relic right-handed neutrinos can only increase
the relic capture rate; thus, if PTOLEMY detects a decrease in the total
capture rate, this may indicate the possible existence of NSI. On the
other hand, let us suppose that PTOLEMY shows results compatible with an
enhanced Dirac relic capture rate, yet lower than the Majorana value.
Such result could be interpreted as a modification in the number of the
relic neutrinos predicted by the Standard Cosmology, but it also can be
described by the existence of NSI. This degeneracy can not be solved by
PTOLEMY-like experiments only as they just measure the number of events
compatible to a peak expected from relic neutrino capture. Thus, other
studies need to be performed.

In this chapter we have considered the impact of NSI in the detection of
the cosmic neutrino background. We have discussed briefly the origin of
such background and its properties, such as number density, pressure,
and the root mean square momentum. These characteristics indicate that
relic neutrinos can be non-relativistic particles if their masses are of
@xmath eV or bigger. This has many important consequences; the most
crucial one dwells with the differentiation between Dirac and Majorana
natures. This can be explained taking into account the difference
between chirality and helicity for non-relativistic neutrinos. When the
neutrino decouples from the thermal primordial bath, it is basically a
left-handed particle. The free streaming after the freeze out imposes
that helicity, not chirality, is conserved as neutrinos are massive.

Since Majorana and Dirac particles have different chiral and helical
components, the final abundances for the helical states are different in
both cases. Dirac particles and antiparticles are distinct, and each
chiral state can have two possible helicity projections. Keeping in mind
that left-handed neutrinos interact weakly and a left-handed neutrino
becomes a left-helical state, we can see that only the abundances for
left-helical particle and right-helical antiparticle states are
different from zero. In the other cases, we expect their abundances to
be negligible. On the other hand, if neutrinos are left-handed Majorana
fermions, which have the two helical states, we see that both helical
neutrino states will have a non zero abundance after the decoupling. The
right-handed heavy neutrino will be decoupled way before the left-handed
one, making its abundance zero at the present.

The detection of the cosmic neutrino background is of main interest for
both Particle Physics and Cosmology as these neutrinos contain
information from a time of about @xmath second after the Big Bang.
Nonetheless, given its tiny energy, their detection is quite
complicated. Several methods have been proposed, as the Stodolky effect,
a Cavendish-like torsion balance and scattering with UHE cosmic rays.
All these methods have extremely small rates, far away from the current
sensitivity. The most promising candidate for the @xmath detection is
the capture by tritium. The PTOLEMY experiment has been designed as a
first attempt for such detection. As result of the possible
non-relativistic nature of relic neutrinos, we have seen that the
capture rate for the Majorana case is twice the value for Dirac
fermions. However, this is a result obtained considering only SM weak
interactions. Therefore, we asked ourselves about the implications of
having NSI for the specific supposition of neutrinos being Dirac
particles. Considering an Effective Field Theory approach and using the
limits from data on beta decays, we found that it is possible to
increase the Dirac relic capture rate to values numerically identical to
the Majorana rate.

This is a substantial result since it shows that a detection compatible
with the Majorana capture rate does not exclude the Dirac nature.
Nevertheless, if the NSI bounds are improved this result can change. We
also found that NSI can decrease the value of the capture rate. A
possible discovery of relic neutrinos with a smaller rate may suggest
the existence of beyond SM physics. To confirm this affirmation, we
included the largest possible relic right-handed neutrino abundance
allowed by the Planck data. Evidently, such additional neutrinos can
only increase the relic neutrino capture. Notwithstanding, if the
neutrino abundance is diminished by some unknown process, the relic
capture can also be reduced, but, a NSI interpretation is also possible
in such case. This degeneracy may be solved by a significant improvement
on the measurements on the leptonic-hadronic couplings. Let us also
stress here that we have not considered other possible beyond SM
physics, such as neutrino decay, sterile neutrinos, or clustering
processes. Nevertheless, the extension for those cases should be
straightforward. In the final chapter, we will deviate from the main
study of the thesis, i.e, the analysis of the consequences of the
neutrino nature. We will consider the implications of neutrinos in
experiments trying to detect the Weakly Interacting Massive Particle,
candidate for Dark Matter.

### Chapter 6 Neutrino background in Dark Matter direct detection
experiments \lettrine

Many experimental evidences have shown that there exists in the Universe
matter which can not be directly detected by the usual telescopes. Such
matter, denominated Dark Matter (DM) as it does not couple with photons,
composes approximately @xmath of the Universe. It is then a crucial task
to unveil its nature and its relationship with the known particles.
Several candidates exist to form the Dark Matter; among them, we have
the Weakly Interacting Massive Particle (WIMP) [ 44 ] . This candidate
has called a lot of attention since it gives the correct cosmological
abundances via thermal production with cross sections in the range
expected by weak interactions and masses in the @xmath GeV scale; thus,
coinciding with the expected region for beyond SM physics. Therefore, if
a WIMP exists and if it was created in the Early Universe, it should
couple with SM particles, making its detection possible. Hence,
experiments have been searching these particles by the interaction with
nucleus, which creates a detectable recoil. Nevertheless, confirmed
evidences have not been found yet, so, new experiments have been
planned.

Recently [ 187 , 188 , 189 , 190 ] , it has been shown that neutrinos
will turn into an irreducible background in those searches. This is due
to the coherent scattering between a neutrino and a nucleus, predicted
by the SM. We will concentrate ourselves in this chapter in the study of
the impact of neutrinos in direct detection searches, considering the
presence of NSI. We will consider first the characteristics of direct
detection experiments and the parametrization of the neutrino background
through the discovery limit. We will introduce the NSI in the form of
simplified models, and then we will analyse the limits and consequences
of their possible existence. This chapter contains original research
mainly published in [ 191 ] , and other new results, regarding the
inclusion of the reactor antineutrino flux contribution to the discovery
limit considering the total number of reactors on the Earth.

#### 6.1 Dark Matter Problem and Weakly Interacting Massive Particle

##### 6.1.1 Dark Matter Evidences and The WIMP Miracle

The DM problem is one of the oldest open problems in Particle Physics.
The first evidences originated from the work of Fritz Zwicky, who
studied the Coma Cluster. He showed that the cluster can not be bound by
the gravitational attraction of the matter observed. Therefore, one
needs the existence of some invisible matter to explain it [ 192 ] .
Later, in the 1970’s Vera Rubin and others concluded that the rotation
curves of disk galaxies indicate that the mass of the galaxy is bigger
than what is actually observed [ 193 ] . Other evidences from
gravitational lensing [ 194 , 195 ] show that the mass in a galaxy is
about 4 times greater than observed through light. In larger scales,
there are additional evidences. At cluster level, the Bullet Cluster [
196 ] is considered a definitive proof of the existence of DM. In that
system, in which two clusters are colliding, visible matter and DM
behave different from each other. Visible matter suffers a modification
in its trajectory while gas in the two clusters is emitting x-rays. But,
more important, observations from gravitational lensing show that most
of the matter is not in the places in which visible matter is. This is
an indication of the existence of an invisible collisionless matter,
i.e. DM. Finally, at cosmological scales, the observations indicate that
visible matter is 5% of the Universe content while an unknown invisible
component is about @xmath [ 45 ] .

What do we know about DM? There are some basic properties we know about
this invisible component [ 44 ] :

1.   DM is stable or with a lifetime bigger than the age of the
    Universe. Evidently, we see DM nowadays in several scales, and we
    know that it has existed since the Big-Bang.

2.   DM interacts gravitationally and it does not interact with photons.
    The current evidences of the existence of DM come from gravitational
    observations only. We also know that DM does not couple with light
    in any observable way. DM can interact through other interactions,
    but there are still no evidences of it.

3.   The mass of DM has only been constrained in @xmath 80 orders of
    magnitude. An upper bound of the DM mass of @xmath GeV comes from
    the study of the gravitational microlensing by the Kepler satellite
    [ 197 ] . There is no lower experimental limit on the DM mass. For
    instance, it has been proposed the so-called Fuzzy DM, which DM is a
    boson with a de Broglie wavelength of 1 kpc [ 198 ] .

4.   DM requires physics beyond the SM. In the early studies of DM, it
    was supposed the neutrino could actually be perfect DM candidate.
    However, as we have seen, neutrino masses are of @xmath and they
    constitute a hot component in the Universe. This basically means
    that neutrinos decoupled from the primordial thermal bath at
    temperatures @xmath as we previously showed. For DM we need for it
    to be warm or cold in order to explain the structures that we see in
    the Universe [ 42 ] . Thus, there is no viable candidate of DM in
    the SM set of particles; new particles are required.

There are several possible DM candidates [ 44 ] . We will concentrate
ourselves in the denominated WIMP candidate. These particles are
supposed to be produced in the early Universe by interactions present in
the primordial bath. Then, due to the expansion of the Universe, the
abundance of such particles freezes out in the same manner we studied in
chapter 2 when we considered Leptogenesis. Thus, if we consider a Dirac
stable particles @xmath with mass @xmath , @xmath the freeze-out
temperature, it can been shown that the relic density of those particles
is given by [ 44 ]

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

where @xmath , @xmath are the relativistic degrees of freedom at
freeze-out and @xmath is the annihilation cross section, with @xmath and
@xmath the s-wave and p-wave contributions. In the case of WIMP masses
in the GeV range, and imposing a correct DM relic density, one obtains
that the cross sections should be of order @xmath cm @xmath , which is
of the same order of the weak interactions. This is the denominated WIMP
miracle ; the WIMP candidate suggests the existence of new physics above
the @xmath GeV scale as indicated by other independent arguments such as
the hierarchy problem. This is the main reason why WIMPs have attracted
the attention in the last years. Usually, beyond SM physics has a stable
neutral state which can have a mass of order @xmath GeV, making it a
perfect DM candidate. Anyhow, we should keep in mind some assumptions
that are made to obtain the previous relic density [ 44 ] . 1) The DM
decouples when the Universe is in its radiation-dominated epoch. 2) The
WIMP is stable. 3) There is no asymmetry if the WIMP has an
antiparticle. Any modification in these assumptions can modify the final
result of the relic abundance. We will consider in the rest of the
chapter the simplest possibility.

Therefore, it is of main interest the detection of WIMPs. There are
three basic modes to detect them supposing the existence of an
interaction with SM particles; such interaction can be originated by
some beyond SM physics. The three basic modes are the direct , indirect
and collider searches. The direct detection looks for elastic
scatterings between a WIMP and some particle, in such a way that it
creates some energy that can be detected. The indirect search probe the
particles resulting from annihilations of WIMP in form of photons,
neutrinos, or other particles. In the case of photons, it is supposed
that interactions are originated from higher order levels, suppressing
the magnitude of those interactions. Finally, in colliders, the
existence of processes in which there is transverse missing energy are
considered as evidence of an long lived particle, a WIMP. We will study
the direct detection in the next section.

##### 6.1.2 Direct Detection Principle

Since the Earth is moving around the Sun, and we suppose that DM is
distributed in the Milky Way galaxy, we expect that the Earth is under a
shower of WIMPs. Furthermore, the flux of these particles is expected to
be large, @xmath (GeV/m)/cm @xmath s [ 44 ] . Therefore, if DM particles
interact with nuclei, for instance, we can expect elastic scatterings
among them. Nonetheless, the energies and rates of such processes are
expected to be small, given the order of magnitude of cross sections
involved. This is the reason why experiments are performed underground
to avoid large backgrounds as cosmic rays. Depending on the nature of
the DM-SM interactions and the target material of the detector, two
distinct kind of events can be probed: spin-independent and
spin-dependent scatterings. The limits in the first case are stronger
than in the second one, but future experiments will prove both
scenarios. Nevertheless, let us focus on the spin-independent case. The
differential recoil rate for the scattering between a WIMP and a nucleus
is given by [ 44 ]

  -- -------- -------- -- -------
     @xmath   @xmath      (6.2)
  -- -------- -------- -- -------

where @xmath GeV/ @xmath /cm @xmath is the local DM density [ 199 , 200
] ; @xmath is the total number of nuclei in the detector; @xmath is the
mass of the nucleus; @xmath and @xmath are the DM velocity and mass,
respectively; @xmath is the minimum WIMP speed required to cause a
nuclear recoil with energy @xmath for an elastic collision; and @xmath
the WIMP velocity distribution in the Earth’s frame of reference.
Usually, the differential cross section is parametrized in terms of the
total nucleon -WIMP cross-section at zero momentum transfer @xmath ,
defined by [ 199 , 44 ]

  -- -------- -------- -- -------
     @xmath   @xmath      (6.3)
  -- -------- -------- -- -------

being @xmath the number of protons and neutrons in the nucleus and
@xmath the reduced mass of the WIMP-nucleon(nucleus) system. We write

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

where we introduced the nuclear form factor [ 200 ]

  -- -------- -------- -- -------
     @xmath   @xmath      (6.5)
  -- -------- -------- -- -------

with @xmath is a spherical Bessel function, @xmath the momentum
exchanged during the scattering, @xmath MeV the nucleon mass, @xmath the
nuclear skin thickness and @xmath the effective nuclear radius.

Thus, the WIMP recoil rate is given by

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (6.6)
  -- -------- -------- -- -------

The factor @xmath is the integral

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

We will assume a Maxwell-Boltzmann distribution

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

where @xmath km s @xmath , @xmath km s @xmath and @xmath is a
normalization factor taken from [ 199 ] . Then, @xmath is given by

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (6.9)
  -- -------- -------- -- -------

being @xmath km s @xmath is the WIMP velocity and @xmath is the WIMP
kinetic energy, @xmath . The numerical factors @xmath are obtaining by
fitting the last expression, and are given by @xmath [ 200 ] . The
number of DM events per ton-year can be obtained integrating the recoil
rate in the energy recoil,

  -- -------- -------- -- --------
     @xmath   @xmath      (6.10)
  -- -------- -------- -- --------

where @xmath is the energy threshold and @xmath efficiency of the
experiment.

Several experiments have been performed in the last decade looking for
evidences of WIMPs through direct detection. The detectors are built
with different materials, in order to take advantage of their
properties. A first class consists of liquid noble gas detectors, using
Argon or Xenon, which look for nuclear and electron recoils in form of
photons and electrons in photomultipliers. In this case, we have the
experiments DarkSide [ 201 ] , Particle and Astrophysical Xenon Detector
(PandaX) [ 202 ] , the Large Underground Xenon (LUX) [ 203 ] , Xenon10 [
204 ] , Xenon100 [ 205 ] , Xenon @xmath T [ 206 ] , and the future
LUX-ZonEd Proportional scintillation in LIquid Noble gases (LUX-ZEPLIN)
[ 207 ] , DARk matter WImp search with liquid xenoN (DARWIN) [ 208 ] .
Other experiments, such as Cryogenic Dark Matter Search (CDMS) [ 209 ] ,
Cryogenic Rare Event Search with Superconducting Thermometers (CRESST) [
210 ] , CoGeNT Dark Matter Experiment [ 211 ] , Expérience pour DEtecter
Les WIMPs En Site Souterrain (EDELWEISS) [ 212 ] are cryogenic detectors
in which a nuclear recoil is detected by ionization and phonons created
in crystals. A third type of detector is a bubble chamber, such as PICO,
union of the Project In Canada to Search for Supersymmetric Objects
(PICASSO) and Chicagoland Observatory for Underground Particle Physics
(COUP) collaborations [ 213 ] and Superheated Instrument for Massive
ParticLe Experiments (SIMPLE) [ 214 ] . So far, no strong evidence of
WIMPs has been found. There are claims of WIMP detection in experiments
such as DAMA/LIBRA [ 215 ] , but these are in contradiction with other
experiments’ results. In figure 6.1 , we show the current limits and
future sensitivities of WIMP searches through direct detection in the
plane @xmath . The regions above the curves are excluded at @xmath %
C.L. As we can see, large part of the parameter space has been excluded
by experiments putting an stringent limit. Thus, new experiments have
been proposed with large sensitivities and exposures. However, these
future experiments will have an inconvenient. Neutrinos will become a
source of irreducible background due to the existence of the Coherent
Neutrino Scattering off Nuclei, which we will consider next.

#### 6.2 Coherent Neutrino Scattering off Nuclei

A similar event to the one we expect from a WIMP scattering can be
produced by neutrinos in the phenomenon called Coherent Neutrino
Scattering off Nuclei (CNSN) [ 216 , 217 , 218 ] , constituting a
background for those searches. Differently from other known backgrounds,
such low energy electron recoils, neutron scatterings or cosmic rays,
the CNSN background is irreducible [ 188 , 187 ] . An important fact
related to this process is that it has not been observed so far, due to
the small cross section; several experiments are nevertheless trying to
directly observe the CNSN [ 219 , 220 ] in the very near future. Let us
study in detail this process, and show the problems that it brings to DM
direct detection experiments.

##### 6.2.1 A brief on Quantum Mechanical Coherence

Let us start with a general and brief discussion about coherence in
scattering theory. A cross section can be obtained from the transition
amplitude @xmath as

  -- -- --
        
  -- -- --

such amplitude contains the information about the interaction between
the incident particle and the target. In the case in which the target is
a composed system, the amplitude is the sum over each element, @xmath
being the total number of constituents

  -- -------- --
     @xmath   
  -- -------- --

where we introduced a phase factor related to the relative phase of the
wave scatterings at @xmath [ 221 ] . Defining the momentum transfer as

  -- -------- --
     @xmath   
  -- -------- --

and the relative size of the target

  -- -------- --
     @xmath   
  -- -------- --

we have that the scattering cross section will depend on the value of
@xmath , with @xmath . If @xmath , the phase factors can create
cancellations among the different contributions, making the scattering
small, but it can give information about the spacial structure of the
target system [ 221 ] . On the other hand, when @xmath , the relative
phases are negligible and we can compute the cross section as [ 221 ]

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

therefore we see that each contribution adds up coherently . The
incident particle sees the target as a whole, and each constituent
particle contributes to the cross section in the same form. Now, if the
constituents have a spacial density distribution @xmath , the amplitude
is modified to [ 221 ]

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where we defined the form factor @xmath as the Fourier transform of the
spatial density distribution,

  -- -------- --
     @xmath   
  -- -------- --

Let us note that we supposed that each constituent has the same
amplitude @xmath . This is true for the nucleus from the point of view
of the neutrino; the difference among proton and neutron is basically a
coefficient as we will see in the next section. Again, in the case in
which the energies are small, i.e. @xmath , the process is coherent, and
the cross section will be proportional to the square of the number of
constituents.

##### 6.2.2 SM Cross section

Now, we can determine the cross section for the CNSN. This is a process
in which a neutrino scatters elastically from a nucleus @xmath ,
creating a recoil

  -- -------- --
     @xmath   
  -- -------- --

Such process is mediated by neutral currents in the SM, so we can start
with the effective lagrangian

  -- -------- --
     @xmath   
  -- -------- --

where the current is given by

  -- -------- --
     @xmath   
  -- -------- --

Here, the sum is made over all the relevant fermions in the process,
@xmath . We explicitly have that the relevant lagrangian for the CNSN is
given by

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

To compute the CNSN cross section, we need to go from quarks to hadrons.
Accordingly, we consider the hadronic matrix elements of quark currents
as in WIMP computations [ 199 ] . The amplitude for the CNSN in terms of
initial and final nuclear states @xmath , respectively, is given by

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

We use the matrix element [ 199 ]

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

where @xmath is the number of quarks @xmath inside the nucleus @xmath ,
and @xmath is the quark coupling with the Z boson. Then, to obtain the
cross section, we just need to keep in mind that the spin average is
only done over nucleus states since the neutrino is automatically
left-handed in the sources we are considering. Finally, the differential
cross section in terms of the nuclear recoil energy @xmath is [ 188 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (6.15)
  -- -------- -------- -- --------

with the SM coupling factor

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

Here, @xmath and @xmath are the number of neutrons and protons in the
target nucleus, respectively, @xmath the incident neutrino energy and
@xmath the nucleus mass. Let us stress that this cross section is
proportional to the square of the number of constituents, such as
expected in a coherent scattering. The only difference is the @xmath
factor, which comes from the different effective weak coupling of
protons and neutrons. Also, notice the introduction of the nuclear form
factor @xmath , defined in an analogous manner as in equation ( 6.5 ).

##### 6.2.3 CNSN in Direct Detection Experiments

After obtaining the differential cross section for the CNSN, we can
determine the recoil event rates in terms of the detector properties,
such as exposure, efficiency and target material. The differential
recoil rate will be the integration over the neutrino energy of the
multiplication of the cross section and the incoming flux of neutrinos

  -- -------- -------- -- --------
     @xmath   @xmath      (6.17)
  -- -------- -------- -- --------

where @xmath is the number of target nuclei per unit mass, @xmath the
incident neutrino flux and

  -- -------- --
     @xmath   
  -- -------- --

is the minimum neutrino energy.

The fluxes we will consider in this chapter are those described in the
chapter 1 , i.e., neutrinos coming from solar, atmospheric, DSNB and
reactor sources. In figure 6.2 we present the recoil rates in terms of
the nuclear recoil energy for each source and Xe and Ar targets at the
four different locations on Earth, the positions of the LNGS, SURF, CJPL
and LSM laboratories. We can see that the recoil rates are large for
small recoil energy, given the large low energy solar neutrino flux;
however, such small recoil energies are extremely difficult to measure.
On the other hand, @xmath B and @xmath solar and atmospheric neutrinos
have a smaller rate, but larger recoil energies, which in principle
could be detected. The reactor antineutrino flux has been computed
considering the 2015 data for all the reactors on the Earth, see
subsection 1.3.3 . We also should notice that the contribution of the
reactor antineutrinos to the total rate is indeed small for the
laboratories we have chosen, even in the case in which the flux was
large, as for the LSM case. Nonetheless, we will study the impact of the
reactor antineutrinos flux in the discovery potential of WIMPs for
detectors located in those laboratories ¹ ¹ 1 We should mention here the
reason of choosing these laboratories. LNGS hosts the Xenon1T, DAMA,
CRESST and future DARWIN experiments, SURF is the location of LUX and
future LZ experiments, EDELWEISS and future EURECA will be placed in the
LSM site and CJPL is currently operating the PandaX experiment. . Also,
we should note the difference between the recoil rates for Xe and Ar
targets. It mainly comes from the fact that Xe has more nucleons than
Ar, and the cross section is proportional to the number of components
squared. Now, integrating the recoil rate from the experimental
threshold @xmath up to @xmath keV [ 188 ] , one obtains the number of
neutrino events

  -- -------- -------- -- --------
     @xmath   @xmath      (6.18)
  -- -------- -------- -- --------

@xmath is again the detector threshold energy and @xmath is the detector
efficiency function. In figure 6.3 we present the number of events in
terms of the energy threshold for each source considered, and in the
same locations for a @xmath efficiency. As expected by the previous
results, we see that the number of events is larger for a smaller
threshold, due to the increasing contribution of the solar neutrinos.
Yet, from an experimental point of view, such tiny threshold are quite
difficult to achieve. For instance, the LUX experiment have a threshold
of 1.1 keV [ 203 ] , while CRESST has one of @xmath eV [ 210 ] . Anyhow,
we see that for those realistic thresholds, the number of events are of
order @xmath per ton-year. Let us stress that the dominant contributions
in that realistic case are the @xmath B and @xmath solar neutrinos.
Besides this, we see again that the contribution of reactor
antineutrinos is smaller when compared with the solar neutrinos
contribution, but they should not be neglected for thresholds smaller
than 1 keV.

To demonstrate the implications of the CNSN phenomenon in direct
detection searches, we compare the recoil rate for two specific cases
with the CNSN recoil rate in figure 6.4 for Xe and Ar detectors. We see
that in the Xe case the recoil rate for a WIMP with a mass of @xmath GeV
and cross section of @xmath cm @xmath (red line, right panel) is
completely mimicked by the CNSN rate (blue line), specifically by the
contribution of the @xmath B neutrinos [ 188 ] . For a WIMP with @xmath
GeV and @xmath cm @xmath (green line, right panel), the atmospheric
contribution to the CNSN rate resembles the WIMP event rate. In the case
of the Ar, we show the case of a WIMP with @xmath GeV and @xmath cm
@xmath (red line, left panel). This shows that neutrinos are an
irreducible background for WIMP direct detection experiments, and such
background is dependent of the specific target of the experiment.
Therefore, it is important to perform a detailed analysis to understand
in which point such background becomes significant. This has been done
by the introduction of the denominated neutrino floor , which is
basically a discovery limit for direct detection searches. Let us notice
that recently there have been several attempts to distinguish between
WIMP and neutrino events in direct detection experiments [ 222 , 223 ,
224 , 225 , 226 ] . Nonetheless, we will consider only the basic direct
detection experiments.

#### 6.3 Discovery Limit in Direct Detection Experiments

To establish a minimal DM - nucleon cross section from which the
neutrino background due to the CNSN can not be avoided, we will consider
first a background free approach by the introduction of the One-neutrino
event contour line . Nevertheless, it is important to perform a complete
statistical analysis to understand deeply the influence of the neutrino
coherent scattering in direct detection experiments. This will be the
task of a subsequent subsection.

##### 6.3.1 One-neutrino Event Contour line

We can start by considering a background free approach in the sense that
we want to represent the CNSN in the plane @xmath . This is done by
introducing the one-neutrino event contour line , line which defines the
best background-free WIMP cross section that can be constrained
supposing the background to be composed by one neutrino event. This
contour line depends on the experiment performed, i.e. it relies upon
its characteristics, such as exposure, threshold energy and target
material. To determine the one-neutrino event contour line, we will
adopt the procedure established in [ 188 ] . Let us consider a generic
experiment. The exposure needed to detect a single neutrino event as a
function of the energy threshold is given by

  -- -------- -------- -- --------
     @xmath   @xmath      (6.19)
  -- -------- -------- -- --------

Then, for each threshold, we compute the background-free exclusion limit
at @xmath C.L.; that is, the curve in which we obtain @xmath WIMP events
employing the previous exposure function

  -- -------- -------- -- --------
     @xmath   @xmath      (6.20)
  -- -------- -------- -- --------

Finally, we take the lowest excluded cross section for each WIMP mass.
Such cross section as function of the mass will be the one-neutrino
event contour line. In other words, the one-neutrino event contour line
describes the best background free sensitivity achievable for each WIMP
mass with one-neutrino event. In figure 6.5 we present the one-neutrino
event contour line (black line) for Ar (left panel) and Xe (right panel)
targets computed with solar, atmospheric and DSNB neutrinos and reactor
antineutrinos at LNGS; we also see that background-free exclusion limits
computed considering the exposure needed to have a neutrino event for
several thresholds.

We observe that the line corresponding to Xe is higher that the one for
Ar. This is due basically to the dependence of the recoil rate with the
number of nucleons in the WIMP case as well as for neutrinos. Thus, we
expect the CNSN to be important first for Xe experiments. Furthermore,
we see that there is a kink near to a WIMP mass of @xmath GeV; such
change is due to the presence of the @xmath B neutrinos, and, as we will
see later, the discovery limit is worsened for that specific mass. Let
us notice that these lines have been computed considering a @xmath
efficiency in the detector, which is a crude approximation since each
experiment has a definite efficiency. Anyhow, the one-neutrino contour
event line is not a definitive limit for WIMP searches, but a
preliminary estimate of the region in which CNSN effect becomes
relevant. Thus, it is necessary to perform a complete statistical
analysis which includes background fluctuations related to the
uncertainty on the neutrino fluxes.

##### 6.3.2 Discovery Limit

Experiments constructed for a specific pursuit, such as direct detection
experiments, perform detailed statistical analysis to identify signal
events over known backgrounds. Such statistical analysis are undertaken
by considering the spectra of the possible signal compared to the
background one; then, the statistical significance can be evaluated
using some test. The significance is a endorsement of the model
predictions by the data obtained experimentally. In other words, it
indicates if the model represents accurately the data. However, in
general, there exists some parameters which are not known a priori when
an experiment is carried out; instead, they are obtained by some other
data set. Those parameters are known as nuisance parameters . Therefore,
a procedure to determine the statistical significance needs to take into
account those parameters in a fully determined way. A common frequentist
approach uses a likelihood ratio as test statistics. It will be the
basis to estimate the discovery limit in a direct detection experiment.
We will follow the approach conceived from the general treatment by
Cowan et. al. [ 21 ] by Billard and collaborators [ 227 ] . It was later
applied to the CNSN background in the references [ 189 , 190 ] . Let us
discuss the method to obtain the discovery limit with some detail. We
start by defining a binned likelihood function as

  -- -------- -------- -- --------
     @xmath   @xmath      (6.21)
  -- -------- -------- -- --------

This likelihood is built as the product of Poisson probability
distribution functions @xmath for each recoil energy bin @xmath . We
will consider @xmath as the total number of bins. The likelihood
functions @xmath correspond to Gaussian functions parametrizing the
uncertainties on each neutrino flux parameter; thus, neutrino fluxes
will be here the nuisance parameters. We will consider the fluxes and
their uncertainties presented in the chapter 1 , section 1.3 . Besides,
@xmath correspond to each neutrino component so far considered in this
thesis. The neutrino ( @xmath ) and WIMP ( @xmath ) number of events are
computed as in equations ( 6.18 ) and ( 6.10 ), but integrated in the
intervals of the energy bin @xmath . Finally, @xmath will include the
information on extra parameters that could be present in either
neutrinos or WIMPs number of events. The test between the neutrino-only
hypothesis @xmath and the neutrino+WIMP hypothesis @xmath consists in
defining the ratio –for a fixed WIMP mass–

  -- -------- -- --------
     @xmath      (6.22)
  -- -------- -- --------

where @xmath and @xmath are the fluxes and WIMP-nucleon cross section
values which maximize the likelihood @xmath ; meanwhile, @xmath is
obtained by maximizing the likelihood function in the case of the null
hypothesis, @xmath .

Then, to assess the positive signal we compute the test statistics [ 21
, 227 ]

  -- -------- --
     @xmath   
  -- -------- --

we have that @xmath measures the discrepancy between the null and the
alternative (positive) hypothesis. This test is specially outlined to
determine the rejection of the background-only hypothesis to appraise a
discovery. Hence, we need to compute the p -value @xmath from the
probability density function of @xmath under the background-only
hypothesis @xmath , @xmath , as

  -- -------- --
     @xmath   
  -- -------- --

being @xmath the observed value of @xmath from the data. In other words,
@xmath is the probability of a disagreement between @xmath and @xmath to
be equal or larger than the value @xmath . Thus, it is necessary to know
the probability density function (p.d.f.) @xmath . Considering Wilk’s
theorem, it can be shown that such p.d.f. follows a half chi-square
distribution for one degree of freedom, @xmath [ 21 ] . Therefore, the
significance @xmath will be simply

  -- -------- --
     @xmath   
  -- -------- --

in units of @xmath .

Evidently, the previous procedure is done when a real experiment has
data to be analysed. Nevertheless, we can perform a simulation in order
to estimate the discovery limit in direct detection searches. We will
create simulated spectra for both WIMP and neutrinos, and then we will
compute the significance through the procedure previously presented.
Clearly, such significance will not have a definite meaning since it
will dependent on the details of the simulated spectrum. Thus, we will
construct an ensemble of @xmath simulated experiments to obtain a
statistical set of significances from which we can extract relevant
information. Let us define @xmath as the significance that can be
obtained @xmath of the times in the statistical ensemble by computing
the quantile function of @xmath as [ 227 , 189 , 190 ] .

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

or, equivalently,

  -- -------- -------- -- --------
     @xmath   @xmath      (6.23)
  -- -------- -------- -- --------

where @xmath is the p.d.f. of the significances obtained from the
simulated experiments ensemble. Hence, for each WIMP mass and cross
section, we will have a value of @xmath .

We will define the discovery limit as the minimum value of the
cross-section in which an experiments has a @xmath probability of making
a 3 @xmath discovery for each WIMP mass [ 227 , 189 , 190 ] . In other
words, the neutrino floor will correspond to the value of @xmath having
@xmath .

In figure 6.6 and 6.7 , we present the results of the WIMP discovery
limit in the plane @xmath for the same laboratories considered
previously, using Xe and Ar as targets, and an artificial threshold of
@xmath eV. Specifically, in figure 6.6 , we show the dependence of the
discovery limit on the exposure of a simulated experiment at LNGS. Each
peak appearing in the discovery limit corresponds to the region in which
the WIMP spectrum is highly mimicked by some neutrino component.
Explicitly, the peaks correspond to the @xmath , @xmath , @xmath ,
reactor, @xmath , @xmath , and atmospheric neutrinos, respectively [ 189
, 190 ] . We indicate the masses more affected by these neutrinos using
gray dashed lines. We also see that when increasing the exposure,
different peaks start to appear.

Different from what has been considered in literature, we considered the
contribution due to reactor antineutrinos to the discovery limit. Such
reactor contribution at LNGS appears at large exposures ( @xmath
ton-year). Furthermore, we determined the discovery limit for different
laboratories to understand the dependence on the location. Figure 6.6
shows the discovery limit for the four laboratories we have considered
so far. As expected, the discovery limit only differs on the reactor
associated peak, near to a WIMP mass of @xmath GeV. For the LSM, the
contribution is the largest as such laboratory is relatively close to
the reactors in France. Meanwhile, for the LNGS, CJPL and SURF, we see
that the reactor contribution is small for this exposure.

Finally, we see in both figures the difference between the discovery
limits for distinct target materials. The positions of the peaks are not
modified significantly, since both WIMP and neutrino spectra are
multiplied by the number of the constituents. Nonetheless, for a
experiment whose target is composed by different atoms, the discovery
limit should be different. Also, for different exposures, the lowest
cross section that can be studied by the experiment is different for
each target.

#### 6.4 Non-Standard Interactions and the Discovery Limit

We have considered so far the existence of a WIMP @xmath which couples
to the SM particles. Such interaction is only parametrized by the
WIMP-nucleon cross section, since further details about the couplings
are actually unnecessary. On the other hand, we can speculate about the
existence of NSI coupling with neutrinos in such a way that they modify
the results obtained previously. Earlier works have shown that NSI
affecting neutrino-nucleus scattering will change the CNSN at direct
detection experiments [ 228 , 229 , 223 , 226 ] . Notwithstanding, these
works suppose that the beyond SM physics is present in either the WIMP
sector or the neutrino scattering. It is reasonable that NSI converse
with both neutrino and WIMP sectors; furthermore, it is possible that
the new physics is responsible of the smallness of neutrino masses [ 230
] . We can then analyse the effects of an NSI coupling with both
neutrinos and WIMPs on the discovery limit at future experiments.
Accordingly, we will work within the framework of simplified models [
231 , 232 ] , models which consist in the addition of a WIMP and a
mediator to the SM. In such frameworks, it is also supposed that the
WIMP is odd under an additional @xmath symmetry, forbidding its decay on
SM particles, but allowing scattering processes. We will concentrate
ourselves on two cases for the mediator, a scalar and a vector boson [
191 ] . Let us start with the vector scenario.

##### 6.4.1 Vector Mediator

In this case, our mediator will be a real boson @xmath , with a mass
@xmath , described by the following lagrangian

  -- -------- -------- -- --------
     @xmath   @xmath      (6.24)
  -- -------- -------- -- --------

coupling with the fermions @xmath as

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

where we have introduced the vector @xmath and axial-vector @xmath
couplings. Let us also notice that we have written down left- and
right-handed currents, supposing the existence of right-handed
neutrinos; thus, neutrinos can be Dirac or Majorana here, but this will
be irrelevant for the purposes of the present chapter as the CNSN is
independent of the neutrino nature. It is important to note that
constraints coming from other experiments should be applied to these
simplified models to obtain a consistent Ultraviolet completion. For
instance, a @xmath gauge scenario, studied in [ 233 ] , has large
regions of the parameter space that may be excluded depending on the
nature of the couplings @xmath .

Other constraints may be applied if there is isospin breaking or if the
new physics affects the electroweak precision measurements. However,
such analysis is model dependent, and we will just consider here limits
in the invisible sector of neutrinos and WIMPS coming from direct
detection experiments. Clearly, experimental limits constraint the
neutral vector boson mass depending on the couplings with electrons and
muons [ 234 , 136 , 235 , 236 , 237 , 238 ] ; nevertheless, these limits
can be avoided for specific fermion charges.

The differential cross section for the CNSN is indeed modified by the
additional vector boson; we get

  -- -------- -------- -- --------
     @xmath   @xmath      (6.26)
  -- -------- -------- -- --------

where @xmath is the square of the momentum transferred in the scattering
process, and the coupling @xmath is obtained using the same matrix
element as in the SM, but keeping in mind that couplings with quarks are
now arbitrary [ 199 ]

  -- -------- -- --------
     @xmath      (6.27)
  -- -------- -- --------

Let us stress here that we have assumed that neutrino production in the
Sun is basically unaltered by the vector boson as only left-handed
neutrinos interact with the target nuclei. Furthermore, if the new
interaction couples only with right-handed neutrinos, there will not be
any modification to the CNSN, so we see that the interference term,
proportional to @xmath , can increase or decrease the number of events
expected in a detector. Therefore, @xmath can be smaller (larger) than
@xmath if @xmath ( @xmath ) since @xmath is negative. Notice that we
recover the SM result when @xmath , for zero or completely right-handed
interactions. In the WIMP sector, we will keep considering only
spin-independent interactions by setting @xmath . It is possible then to
obtain the explicit dependence on the couplings of the differential
cross section as

  -- -------- -------- -- --------
     @xmath   @xmath      (6.28)
  -- -------- -------- -- --------

with @xmath the incident WIMP energy.

##### 6.4.2 Scalar Mediator

The second scenario we will consider here consists in the introduction
of a real scalar boson, @xmath , with mass @xmath , whose lagrangian is

  -- -------- -------- -- --------
     @xmath   @xmath      (6.29)
  -- -------- -------- -- --------

where @xmath are the couplings between the scalar and the fermions.
Notice that we are considering a CP even real scalar to forbid spin
dependent interactions at direct detection experiments. Besides, a
right-handed neutrino is also assumed to be present in the particles
set. Analogous to the vector case, one can wonder about a UV-completion
of this simplified model. Nonetheless, such discussion is not crucial
for the results we will obtain later; hence, we will not enter in
details about it here. See, for instance [ 191 ] . The differential
cross section for the CNSN is once more modified by the new physics, as
expected. The modification is however different to the previous case as
the Dirac structure is different. Therefore, the hadron matrix element
needs to take into account that a scalar is coupling to the quarks. In
such case, the matrix element is given by [ 199 ]

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

where @xmath are the effective couplings with protons and neutrons,
which are given by

  -- -------- -------- -- --------
     @xmath   @xmath      (6.31)
  -- -------- -------- -- --------

being @xmath is the average nucleon mass and @xmath correspond to the
effective low energy coupling between a scalar mediator and a quark
inside a proton or neutron, respectively. These form factors can be
obtained using chiral perturbation theory. We will use the values from
the micrOMEGAs package [ 239 ] , given by @xmath , @xmath , @xmath ,
@xmath and @xmath . Let us stress that a more recent determination has
been done in [ 240 , 241 ] ; we have concluded that such new
determination will affect our results by @xmath . The differential cross
section is then found to be

  -- -------- -------- -- --------
     @xmath   @xmath      (6.32)
  -- -------- -------- -- --------

We see here that the modified differential cross section has an
additional term coming from the different Dirac structure present in the
lagrangian. Therefore, we expect that the differential recoil rate and
the number of events to be modified in shape.

On the other hand, the values of @xmath are quite large since it is a
target dependent quantity. For instance, in a Xe experiment we have that
@xmath , considering universal quark-scalar couplings. Hence, for @xmath
, @xmath , @xmath GeV, values of @xmath are @xmath . Finally, we can
compute the differential cross section for WIMP scatterings at direct
detection experiments

  -- -------- -------- -- --------
     @xmath   @xmath      (6.33)
  -- -------- -------- -- --------

Now, having established the models which will be our framework, we can
analyse their impact in direct detection experiments.

##### 6.4.3 Current Limits and Future Sensitivity

As a first step we should consider the limits that current and future
experiments can impose on the simplified models. Direct detection
experiments actually do not discriminate among neutrinos and WIMPs as
they just compute the number of nuclear recoil events seen in the
detector. Therefore, the constraints will be in the sum of scattering
events from the two kinds of particles. For the present analysis we will
adopt the 2016 results for the LUX experiment [ 203 ] , although Xenon
@xmath T results [ 206 ] are more recent and stronger. The main reason
is that Xenon @xmath T has a larger threshold than LUX, and the
efficiency is smaller for lower recoil energies. Hence, we have checked
that the limits in the neutrino sector are weaker than those from LUX,
while in the WIMP sector bounds have not improved considerably. On the
other hand, we will analyse the reach of two future proposed Xe
experiments, LUX-ZEPLIN [ 207 ] and DARWIN [ 208 ] .

Current bounds . For the current limits we consider the LUX results
obtained after a @xmath kg-days run presented in 2016 [ 203 ] , with an
energy threshold of @xmath keV. The energy efficiency @xmath is also
acquired from the same published result. We compute the likelihood
function built as a Poisson p.d.f.

  -- -------- -- --------
     @xmath      (6.34)
  -- -------- -- --------

where @xmath correspond to the total number of nuclear recoil events as

  -- -------- -------- -- --------
     @xmath   @xmath      (6.35)
  -- -------- -------- -- --------

being @xmath the set of parameters of each model. In the likelihood
function, we also have the observed number of events @xmath and the
expected background @xmath . We employ @xmath for the number of observed
events and @xmath for the estimated background. Thus, to obtain limits
in the different planes of the parameter space, we will maximize the
likelihood function ( 6.34 ).

Regarding the vector scenario, we scanned the parameter space in the
ranges

  -- -------- -- --------
     @xmath      (6.36)
  -- -------- -- --------

Our results are shown in figure 6.8 for the plane @xmath and the
parameter @xmath GeV @xmath on the left (right) panel. The @xmath choice
was done considering the couplings at the perturbativity limit, i.e.
@xmath and a mass of the mediator of @xmath GeV. For clarity, we present
the limit for three different WIMP masses, @xmath GeV (violet), @xmath
GeV (red) and @xmath GeV (green). The bounds present two distinct
regions; for @xmath GeV @xmath , when @xmath , the WIMP contribution is
dominant over the neutrino one, implying that @xmath ( @xmath ) for
@xmath GeV. When the neutrino couplings @xmath become large enough, the
neutrino events increases and dominates the bounds. Let us also point
out the asymmetry in the bounds of the neutrino couplings. Such
asymmetry is related to the interference in the CNSN since, when @xmath
, the interference is positive making the number of events larger.
Furthermore, the constraints on the neutrino couplings are independent
of the WIMP mass because the mass becomes irrelevant when @xmath . For
the second case @xmath GeV @xmath , we can constrain the regions @xmath
( @xmath ) for @xmath GeV and @xmath few @xmath .

For the case of the scalar mediator, we analysed the constraints from
LUX results, varying the ranges

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

In figure 6.9 we display the results concerning the scalar scenario for
similar cases as in the vector case. We can constraint the region @xmath
( @xmath ) for @xmath GeV if @xmath , when @xmath GeV @xmath . For the
extreme case of @xmath GeV @xmath , we get a bound of @xmath ( @xmath )
for @xmath GeV if @xmath . When the neutrino couplings are strong enough
to dominate the number of events, we can set a limit of @xmath ( @xmath
few @xmath ) for @xmath ( @xmath ) GeV @xmath . As in the previous case,
such limit is independent of the WIMP mass.

Future sensitivity. Given the future experiments being planned to
discover, or constraint even more, the WIMP model, we can predict the
future bounds on the simplified models we have studied so far. We will
estimate the sensitivity of the future Xe based experiments LUX-ZEPLIN
and DARWIN. In the design studies of those experiments, the
collaborations present the initial parameters in which they will start
operating. LUX-ZEPLIN collaboration assumes an energy threshold of
@xmath keV, a maximum nuclear recoil energy of @xmath keV and a future
exposure of @xmath ton-years [ 207 ] . Moreover, they suppose an energy-
independent efficiency of @xmath . In the DARWIN case, it is designed
for an aggressive exposure of @xmath ton-years, with a @xmath acceptance
of recoils in the energy range of @xmath keV [ 208 ] .

The future bounds for both models are shown on the bottom panels of
figures 6.8 and 6.9 for LUX-ZEPLIN (dashed lines) and DARWIN (dotted
lines). Certainly, to obtain those possible constraints we are supposing
that these experiments do not find any evidence of WIMPs. Again, there
are two distinct regions in the figures. First, in the region in which
the WIMPs dominate, LUX-ZEPLIN will be able to improve the bounds on
@xmath and @xmath by a factor of @xmath . In the neutrino dominating
region, we see nevertheless that the constraints are weaker than the
current bounds obtained by LUX. This is an effect directly related to
the energy threshold of the experiments. The higher LUX-ZEPLIN energy
threshold diminishes the number of neutrino events since it does not
allow for detection of solar ( @xmath B) neutrinos. Actually, this also
occurs for DARWIN, but, given the strong exposure, the effect is
balanced.

##### 6.4.4 Discovery Limit including Non-Standard Interactions

A more crucial consequence of the possible existence of NSI is related
to the discovery limit of direct detection experiments. Let us start
considering the modifications on the one-neutrino event contour line. In
figure 6.10 . we present some examples of modified one-neutrino event
contour lines, by fixing the values of the parameters @xmath and @xmath
so that they are still allowed by the experimental constraints obtained
in the previous section. The left (right) panel corresponds to the
vector (scalar) scenarios. In the vector case, we see that the
one-neutrino contour line is essentially a rescaling of the SM case, as
expected from the modification of the cross section; the scalar scenario
shows a deviation from the SM since the cross section in that case is
altered by an additional factor, see equation ( 6.32 ).

As depicted in figure 6.10 , it is possible to lower the one-neutrino
contour line in the vector case, for the value of @xmath . Therefore, in
principle, the CNSN contribution can be cancelled for a massive mediator
case ( @xmath GeV) when

  -- -------- -------- -- --------
     @xmath   @xmath      (6.38)
  -- -------- -------- -- --------

with the assumption of @xmath , and @xmath is a target-related numerical
value. We show in table 6.1 the values of @xmath for some nuclei. On the
other hand, in the scalar scenario, the cancelling of the one-neutrino
event contour line is only partial. Examining the equations ( 6.15 ) and
( 6.32 ) we observe that the positive scalar contribution can cancel
merely the term proportional to @xmath . This is achieved when

  -- -------- -------- -- --------
     @xmath   @xmath      (6.39)
  -- -------- -------- -- --------

being @xmath a numerical value depending on the target, see table 6.1 .
In the right panel, orange line of figure 6.10 we present the case of a
Xe experiment for @xmath and @xmath GeV, which corresponds to @xmath .

Having determined the one-neutrino event contour line, we can proceed to
compute the real discovery limit including NSI. We will compute first
the discovery limit for a more realistic case, the LUX-ZEPLIN experiment
with two different energy thresholds. We show our results in figures
6.11 and 6.12 . In figure 6.11 , we have the neutrino floor considering
the vector mediator scenario. We have there the SM contribution (dark
blue) and the case @xmath (light blue), which can be considered an
extreme case since it corresponds to the current limit on @xmath (
@xmath ) for @xmath GeV @xmath . We also show the cases @xmath (orange,
red). In the last case, the SM contribution is partially canceled by the
vector contribution. Thus, the neutrino floor is below the SM one. For
the specific case of @xmath keV, we see the peak corresponding to the
@xmath B neutrinos. Let us stress that these and the other peaks are
originated by the similarity of the WIMP spectra with the neutrino one,
worsening the discovery limit. Furthermore, in the specific case of the
vector mediator, we have that the modification on the neutrino floor
only affects the value of the cross section in which the peaks appear,
but not the WIMP mass correspondent to each peak. This is expected as
the CNSN cross section is modified in a similar fashion.

On the other hand, in the scalar case, figure 6.12 we considered the
extreme value of @xmath (red) corresponding to the current limit on
@xmath ( @xmath ) for @xmath GeV @xmath . We also present the case of
@xmath (orange). For the case of the smaller threshold, we have that the
discovery limit is displaced to a mass of @xmath GeV. This shift is
originated by the modification of the CNSN cross section as we have seen
previously. In the case of the larger threshold, the scalar mediator
does not affect the discovery limit significantly.

Taking into account that the scalar and vector limits are obtained from
the LUX bound on the number of events, we can ask ourselves the reason
of the difference among the discovery limits in each scenario. We
determined the number of CNSN events as a function of the energy
threshold, see figure 6.13 for the two extreme cases of @xmath and
@xmath . We can see there that for @xmath keV the contributions of both
models are the same, as expected from the LUX limit. Nevertheless, due
to the different behaviour of the rates in both scenarios, we see that
the values of the number of events in the scalar scenario is smaller
than in the vector one, approximately @xmath times different. This is
explained by noting that the scalar scenario has the additional term
@xmath (see equation ( 6.32 )) making the dependence on the threshold
energy non-trivial. For a higher threshold, when only atmospheric
neutrinos contribute, both SM and scalar contributions are of the same
order. The thickness of the curves represent a variation on the
efficiency of @xmath . This variation on the detector efficiency does
not modify significantly our results. In summary, for the LUX-ZEPLIN
experiment the vector model only will affect the experimental
sensitivity for @xmath few @xmath cm @xmath , while the scalar one does
not.

In order to confirm our results for both scenarios, we determined the
discovery limit for a unrealistic Xe experiment located at LNGS, with a
extreme threshold of @xmath eV, exposure of @xmath ton-years and @xmath
efficiency. In figure ( 6.14 ) we have the modification of the discovery
limit for both vector (left) and scalar (right) scenarios. In the vector
scenario, the modification is manifested in a similar way to increasing
the experimental exposure. Thus, for the extreme case of @xmath , the
peaks corresponding to reactor antineutrinos, @xmath and atmospheric
neutrinos are now evident while in the SM case they are absent. This
also happens for the value of @xmath , in which @xmath and atmospheric
neutrinos are noticeable, but reactor antineutrinos are not. In the case
of @xmath , only the peaks of the largest neutrino contribution are
present, due to the decrease of the number of events. In the scalar
scenario, the behaviour is more involved as we have already stressed.
For lower masses @xmath GeV, the discovery limit coincides with the SM
one since the scalar contribution is actually small. This may seem
strange, as the @xmath neutrinos are the least energetic neutrinos;
however, let us remember that the recoil energy is in such case tiny.
For the higher masses, the scalar contribution is important, even
changing the structure of the discovery limit. Again, this is related to
the additional contribution in this scenario.

Finally, to show explicitly how NSI modify the detection of WIMPs at
direct detection experiments, we present an example of two simulated
energy spectra for the points in figure 6.11 (vector) and figure 6.12
(scalar) in figure 6.15 . In such figure we present all possible
contributions produced by WIMPs only (green), the SM CNSN (black) and
the NSI CNSN (blue) for the vector (left) and scalar (right) scenarios.
We present also in red the combined spectrum. For the cases we are
considering, it would be possible to discriminate between WIMP and the
SM neutrino background, using the test previously discussed.
Nevertheless, the existence of NSI, which increases the neutrino
background, does not allow to discriminate the WIMP in these cases.

In this chapter we have considered the influence of the neutrino
background in the WIMP direct detection experiments. We presented
briefly the properties of a WIMP as candidate to be the DM present in
the Universe. Thus, in order to detect such particle, or particles,
several experiments searching for nuclear recoil events that a WIMP can
create have been performed. Although there have been some claims
regarding a detection of a WIMP, more recent experiments have excluded a
large part of the parameter space. Thus, more sensitive experiments have
been proposed increasing the exposure and decreasing the energy
threshold. Unfortunately, this creates an additional problem, neutrinos
become an irreducible background for these searches. Such background is
originated by the coherent neutrino scattering, process which is
predicted by the SM. Since the neutrino energy is small enough to
consider the nucleus components in a coherent way, the CNSN will depend
on the square of the number of constituents.

We also introduced a simplified way to estimate when neutrinos become
important through the definition of the one-neutrino event contour line,
line corresponding to the lowest WIMP cross section which can be studied
with a neutrino background of one event. Nevertheless, it is crucial to
perform a complete statistical analysis to have certainty about the
region affected by the neutrino background. This is done by introducing
a discovery limit, corresponding to a curve from which a WIMP discovery
can be achieved by an experiment with a significance of @xmath or
higher.

We determined the discovery limit, or neutrino floor as it is also
known, for a simulated Xe and Ar detectors with a minuscule energy
threshold of @xmath eV to completely scan the limit. We obtained similar
results of the position of the neutrino peaks appearing in the discovery
limit as in other previous studies. However, we included the reactor
antineutrinos to analyse their impact on the neutrino floor. Let us
stress that this had not been done previously in the literature. We
found that reactor antineutrinos will be important when experiments
achieve exposures of order @xmath ton-year and thresholds which allow to
study WIMP masses of order @xmath GeV, depending on the location.

In the final sections we devoted our study to understand the impact of
NSI in direct detection experiments. Accordingly, we introduced two
simplified models with a scalar and a vector mediator. First we analysed
the limits on these scenarios coming from the latest LUX results. The
more recent Xenon1T results give a worst limit since this experiment has
a larger threshold. After we determined the current limits and future
sensitivity which can be achieved by LUX-ZEPLIN and DARWIN experiments,
we determined the modification of the discovery limit by the simplified
models. We concluded that the vector mediator modifies significantly the
neutrino floor, specially in the region @xmath GeV or @xmath cm @xmath .
The scalar scenario does not modify in a significant way the discovery
limit. We confirmed these results by scanning the whole mass range
affected by the CNSN, including the new mediators. Therefore, we see
that future WIMP searches with direct detection experiments will have to
deal with the neutrinos in a very careful way, principally when
considering small thresholds and large exposures.

### Conclusions \lettrine

A complete depiction of neutrino properties is still to be constructed.
Experimental proposals pretend to unravel certain specific neutrino
characteristics, such as mass ordering, value of the CP violation phase,
real scale of neutrino masses and, hopefully, the neutrino nature (Dirac
or Majorana). The future of neutrino physics is indeed promissory of
great days to come. In this thesis we have considered some phenomena
which can be observed in the near future. We also have explored other
more exotic processes that involve the possible existence of Beyond SM
physics. The introduction of NSI is in fact justifiable as we know that
the SM is not the final theory, if such theory even exists. There are
unsolved problems related to the SM which could have an impact on our
knowledge of neutrinos. For instance, it could be possible to discover a
flavour theory that explains the families and the masses of all
fermions. This, of course, is just speculation from the author. Physics
evolves by an intricate combination of experimental observations and
theoretical advances, and the theories which future physicists could
create can be completely distinct from the ones we know. Anyhow, we must
work within the framework we have in order to propel the scientific
knowledge.

The present thesis was divided in two main parts. The first one intended
to establish the basis for a subsequent understanding of the novel
results obtained. In the first chapter we described briefly the
characteristics of the SM and the neutrino sources we used throughout
the thesis. Specifically, we started by describing the basic properties
of a Weyl fermion, and we showed that in this case chirality , i.e the
type of fermion representation of the Lorentz group, coincides with
helicity , which is the projection of the spin in the momentum
direction. As we stressed all over the document, chirality and helicity
only are identical for a massless fermion. After that, we described as
succinct as possible the SM. It is not worth describing it further here
as it has been outlined extensively in the literature. However, let us
emphasize that neutrinos in the SM are massless particles by
construction.

We considered next the neutrino sources relevant for our purposes:
solar, atmospheric neutrinos and DSNB together with reactor
antineutrinos. For each case we analysed their origin, spectra and the
experiments which have detected or intend to detect them. One common
result present in the neutrinos already detected was the divergence
between the expected and measured number of events. Such discrepancy is
explained by the existence of the neutrino oscillation phenomena, which
occurs if neutrino are indeed massive and present mixing between mass
and flavour eigenstates. Thus, in the final part of the chapter, we
described oscillations, without explicitly considering the origin of the
masses. We analysed briefly the neutrino propagation in vacuum and
matter, and we quoted the current values of the quadratic mass
differences and mixing angles. We also presented the parameters which
are still unknown, as the CP phase and the mass ordering. In any case,
oscillation experiments show that neutrinos are massive, but they do not
clarify their Dirac or Majorana nature.

The second chapter was constructed under the supposition that neutrinos
are Majorana particles. Thus, we first described the properties of a
Majorana fermion, showing two main differences. First, we saw that such
fermions must be treated as quantum fields from the beginning since
there are no travelling wave solutions. We also found that there are two
distinct manners to define the Feynman propagator as the fermion number
is not conserved by a Majorana field. The additional propagator,
proportional to the fermion’s mass, is the main ingredient for the
neutrinoless double beta decay process, decay which could proof the
Majorana nature of neutrinos. Afterwards, we considered the requirements
for a neutrino to be Majorana within the SM framework. We saw that in
the basic SM Majorana neutrinos are not possible as there is no SU
@xmath triplet with hypercharge two.

Nevertheless, when one considers the dimension-five operator invariant
under the SU @xmath U @xmath SM gauge group, the Weinberg operator, one
finds that such term generates a Majorana mass term.Therefore, it can
explain the smallness of neutrino masses as the non-renormalizable
operator is suppressed by a scale larger than the electroweak one. Thus,
one can analyse the possible extensions of the SM that can generate the
Weinberg operator from tree-level interactions. We saw that there are
three possibilities, including a set of right-handed singlets (type I),
a scalar triplet (type II) or a fermion triplet (type III) to the SM. In
all cases, we found that left-handed neutrino masses are suppressed by
the large masses of the additional fields; a see-saw mechanism explains
the smallness of neutrino masses. The main problem these models suffers
is that finding the new states, in general, requires energies beyond the
current technology. Finally, we outlined one of the most important
consequences of the see-saw models, the explanation of the
matter-antimatter asymmetry in the Universe by leptogenesis.

It is also possible to have models for Dirac neutrinos. Under this
supposition, in the third chapter we analysed the two simplest SM
extensions, the minimal introduction of right-handed neutrino singlets
to the SM particle content and the neutrinophilic @xmath . In the first
case, we saw how neutrinos can get masses from the electroweak symmetry
breaking as the other SM particles. In such minimal scenario, the
smallness of neutrinos is not explained at all; all fermion masses are
not predicted by the SM. Nonetheless, inspired in the see-saw mechanism,
we can suppose that neutrino masses are generated by a different
physics. Thus, we considered the neutrinophilic 2HDM, in which a second
scalar doublet is included to the set of SM particles. That second
doublet is supposed to give mass to neutrinos by a spontaneous symmetry
breaking. To avoid couplings between the new doublet and the charged
fermions, we also need to add a new symmetry. The two minimal scenarios
that have been considered in the literature correspond to a discrete
@xmath or a continuous U @xmath symmetry. We presented the main features
for both cases in the final sections of the chapter.

The second part of the thesis was focused on the novel results we
achieved during the Doctorate. We divided them into three chapter, each
one related to a different topic. The fourth chapter contains the
results related to the phenomenological constraints on the
neutrinophilic @xmath . These constraints are divided in two classes,
bounds on the scalar potential and flavour limits on the charged scalar
sector. The constraints on the scalar potential are theoretical and
phenomenological since such potential needs to fulfil certain
properties, as stability, perturbative unitarity. The phenomenological
limits correspond to bounds from the oblique parameters and Higgs,
@xmath decay widths. Applying these constraints we found that the @xmath
symmetry model is basically excluded by precision measurements.
Meanwhile, the U @xmath scenario is still allowed, but its spectrum
needs to be highly degenerated. On the other hand, limits coming from
flavour physics constrain the parameter space spanned by the VEV of the
second doublet and the charged scalar mass. We found that bounds from
@xmath are the strongest ones in most of the region, but, for small VEV
and large charged scalar mass, the constraint from @xmath is more
important. In the future, and if the proposed experimental sensitivities
are achieved, the @xmath conversion in nuclei could exclude a larger
region on the parameter space. Hence, we have explored the possibility
of having Dirac neutrinos with small masses and we analysed the general
bound on those models.

The fifth chapter considered the possible consequences of having NSI on
the detection of the cosmic neutrino background. We presented first the
properties of the relic neutrinos, showing that those neutrinos can be
non-relativistic, given the small momentum they have at the present
time. This is crucial for the purpose of differentiating between
neutrino natures. The reason is that the neutrinos belonging to the
@xmath are helicity eigenstates since the free hamiltonian does not
conserve chirality. Thus, studying in detail the abundances for the
helical states in the Dirac and Majorana cases, it was found that they
are different. Moreover, we found that the Dirac @xmath is composed by
left-helical particle states and right-helical antiparticle states while
it is composed by left- and right-helical particle states if neutrinos
are Majorana. So, if we could detect the relic neutrinos it would be
possible to shed some light on the real neutrino nature.

Nevertheless, such detection seems to be extremely difficult. There are
several proposed methods to detect the @xmath . Among them, the most
promising is the neutrino capture by tritium; such reaction creates a
detectable electron. Previous works have computed the capture rate,
showing that the expected value for Majorana neutrinos is twice the
Dirac case result. This is basically related to the different helical
composition of the @xmath once the tritium can only capture particles
but not antiparticles. Nonetheless, one should analyse the details of
the detection processes. In fact, the @xmath signal could be hidden by
the background of the tritium beta decay. Also, it is important to see
if any experiment can differentiate the mass eigenstates. We introduced
a novel discrimination function to understand the requirements to
distinguish the peaks related to the eigenstates. However, we found that
it is necessary to have a extreme resolution for identifying at least
two peaks, the one of the third mass eigenstate, and the other for the
combination of @xmath and @xmath states. Furthermore, the capture rate
is proportional to the PNMS mixing matrix element @xmath , @xmath , so
the rate for @xmath is quite small, worsening the possibility of
detection. The PTOLEMY proposal has a resolution which will not be able
to differentiate the peaks, and only will be sensitive for masses @xmath
eV. Thus, a detection could only discriminate the neutrino nature.

However, such statement should be considered carefully. Supposing that
neutrinos are Dirac fermions, we considered the implications of having
contribution of NSI in the @xmath capture rate, which has not been
considered previously. To do so, we wrote the NSI using the Effective
Theory approach, by considering the SU @xmath U @xmath SM gauge
invariant dimension-six operators relevant for the capture process. We
computed the new contributions to the capture rate for four combinations
of these operators. Such combinations were chosen from a work studying
the bounds on NSI from nuclear beta decay of a set of isotopes and the
neutron decay. An important result we obtained is that the rate has
terms proportional to the ratio @xmath , being @xmath the neutrino
energy, coming from the interference between the SM and the NSI.
Usually, such terms would be negligible as neutrinos are
ultrarelativisitic. But this is not the case for the @xmath ;
furthermore, these contributions are as important as the others.
Applying the existing limits, we found that it is possible to increase
the Dirac capture rate to values close to the one expected for Majorana
neutrinos. Therefore, a detection of the relic neutrinos compatible with
the Majorana value is not a definite proof that neutrinos are their own
antiparticles.

On the other hand, we found that the capture rate for Dirac neutrinos
can be decreased. If a @xmath detection occurs with a smaller value than
expected, it may indicate the existence of NSI. We also included the
possibility of having relic right-handed neutrino with both thermal and
non-thermal origins. We found that the capture rate is always increased
since there are more relic neutrinos that could be captured.

Departing somewhat from the main subject of thesis, we considered in the
final chapter the impact on DM direct detections searches due to the
neutrino background. For that purpose, we first gave the general
properties of DM, and we described the direct detection principle of the
WIMP candidate. In direct detection searches, it is supposed that WIMPs
interact with nuclei in such a way that they create an experimentally
detectable recoil. Unfortunately, the searches performed until now have
presented negative results. Thus, more sensitive new experiments are
being planned for execution in the near future. This however introduces
an additional problem provided that neutrinos will become an irreducible
background. To understand the origin of such background, we introduced
the coherent neutrino scattering off nuclei, which is a process
predicted by the SM. Such process is called coherent due to the small
energies involved, making the incoming neutrino not be able to
differentiate the nuclear components. Then, a neutrino would “see” a
nucleus as a whole, and the cross-section will be proportional to the
number of constituents squared.

Taking into account the CNSN, we computed the recoil rate of neutrinos
at direct detection experiments, and we found that it can mimic very
well a recoil produced by a WIMP. Then, it is a central task to
determine at which point neutrinos become unavoidable. A preliminary
approach is done by introducing the one-neutrino event contour line ,
which is a contour line in the @xmath vs @xmath plane, @xmath the WIMP
@xmath -nucleon cross section and @xmath the WIMP mass, and it describes
the best background-free @xmath that can be constrained considering one
neutrino event background. We determined such contour line for two
target materials, Xenon and Argon, and we found that the line for Xe is
higher in @xmath than the one for Ar. This is simply explained recalling
that Xe has more nucleons than Ar; therefore, the CNSN is larger for
Xenon.

Nevertheless, a complete statistical computation is necessary to be
performed to give a real estimative about the neutrino background. This
is achieved by the introduction of the discovery limit of direct
detection searches, or, as is also known in the literature, the neutrino
floor . It is defined as the minimun value of the WIMP-nucleon cross
section in which an experiment has a @xmath of probability of making a
WIMP discovery with a significance of @xmath . We also confirmed
previous results in the literature regarding the peaks appearing in the
discovery limit. Such peaks are related to the values of WIMP masses and
cross sections whose spectrum is very similar to the spectrum of a
neutrino. To compute the neutrino floor, we included the reactor
antineutrino flux which has not been done previously. The reactor
antineutrino flux is computed by considering all reactors on the Earth
and the data available about their properties. We found that reactor
antineutrinos contributions is highly dependent on the location of the
experiment, which is completely expected. This was checked by computing
the discovery limit for four different laboratories. We also obtained
that the reactor fluxes will become important for experimental exposures
of @xmath ton-years and thresholds small enough to detect WIMPs with
masses of @xmath GeV.

All previous results were obtained by considering only the SM coherent
neutrino scattering. We then asked ourselves what would be the impact of
the existence of NSI coupling with both neutrinos and WIMPs at direct
detection experiments. By considering the simplified model framework, we
considered two scenarios regarding a vector and a scalar mediator. For
these two cases, we computed the additional contributions to the CNSN
cross sections. We found that, in the vector scenario, the modification
comes in a form of a rescaling of the cross section while, in the scalar
case, an additional term appears. Thus, to determine the influence of
these simplified models, we first studied the constraints coming from
the results of the LUX experiment. The limits show three different
regions. One, where the WIMP contribution dominates, other, where
neutrino contribution is the most important, and, finally an
intermediate region. We also considered the future sensitivity of DARWIN
and LUX-ZEPLIN experiments on the models; in this case, the future
sensitivity seems weaker than the current limits. This is explained by
noticing the larger energy threshold of the proposed experimental
facilities.

Afterwards, we estimated the influence of the NSI in the WIMP searches.
We first introduced the modifications on the one-neutrino event contour
line, finding that it is possible to cancel the neutrino background in
the vector scenario for some specific values of the couplings. For the
scalar case, it is only possible to partially cancel the cross section.
Another feature we found is that the contour line is only modified by an
overall rescaling in the vector case while there is a shift in the
position in the scalar scenario. Furthermore, we calculated the
discovery limit in the presence of NSI. We found that the neutrino floor
modification in the vector scenario behaves as a rescaling that would be
produced by a increase or decrease of the experimental exposure. In the
scalar scenario, we found that the alteration is dependent on the WIMP
mass since the cross section has a different dependence on the recoil
energy compared to the SM case. However, the modification is not as
significant as in the vector case. For completeness, we showed simulated
spectra for a Xe target, and we showed explicitly the difficulties that
could appear if one considers NSI. So, direct detection searches need to
be very careful to include the neutrino background in a proper manner.

In this thesis we have investigated several aspects of neutrino physics,
from mass models to non-standard neutrino interactions, and their
implications in breakthrough experiments. As already mentioned, future
experiments will hopefully unravel the missing neutrino properties
expanding our knowledge of the extraordinary particles. Such properties
can shed some light in other open problems in Particle Physics, and
enlarge our comprehension of the Universe. From the point of view of the
author, neutrinos have always boosted the advances of Particle Physics,
and surely this will be similar in the future. We certainly live in
exciting times in neutrino physics.

### Appendix A Conventions

We present the conventions used in the development of the present
thesis.

-   We use natural units in which reduced Planck, light speed and
    Boltzmann constants are equal to the unity. @xmath . This implies
    the conversion factors [ 136 ]

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

-   We use the metric tensor with trace @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

-   Spacetime coordinates and momenta are contravariant four-vectors
    while derivatives are covariant four-vectors.

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

-   The Dirac gamma matrices obey the algebra

      -- -------- --
         @xmath   
      -- -------- --

    and the properties

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

-   When needed, we will use the Dirac representation of the gamma
    matrices, given by

      -- -------- --
         @xmath   
      -- -------- --

    with @xmath and @xmath . Here, we have the @xmath identity matrix
    @xmath and the Pauli matrices @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

-   The chirality @xmath matrix is defined as

      -- -------- --
         @xmath   
      -- -------- --

    and it obeys the following properties

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

-   Chirality projectors are defined as

      -- -------- --
         @xmath   
      -- -------- --

    with

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

-   The charge conjugation matrix @xmath fulfils the properties

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    obeying the following relations with the chiral projector, @xmath
    @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

### Appendix B The Lorentz Group and Fermion Representations \lettrine

The two postulates in which the Special Relativity is based are
satisfied by imposing that the interval between two events in the
space-time does not depend on the observer. Namely, two inertial
observers moving relatively one to each other will measure the same
infinitesimal interval

  -- -------- --
     @xmath   
  -- -------- --

Therefore, the transformations that keep this interval invariant will be
the basis for constructing a relativistically consistent quantum theory
of fermions. In general, a transformation can be understood through two
alternative interpretations. The passive interpretation, when the
transformation is performed upon the coordinate system, and the active
one, where the transformation acts on the physical state. Usually, the
special relativity is studied in a passive way, analysing the
transformations between two inertial observers. However, we can also
consider an active approach. In this case, the change among inertial
frames is accomplished by changing one coordinate in the space-time into
another,

  -- -------- --
     @xmath   
  -- -------- --

keeping the norm of the quadrivector constant, i.e. @xmath , with @xmath
. This kind of transformations will be denominated as Lorentz
transformations . The invariance of the interval imposes a constraint in
the transformation matrix @xmath ( @xmath the metric tensor)

  -- -------- -- -------
     @xmath      (B.1)
  -- -------- -- -------

Let us note that these transformations include all possible rotations
and boosts. Several comments can be made about these transformations.
The most important one for our purposes is that the Lorentz
Transformations form a group, and all the fields will have unambiguous
properties upon the action of these transformations. Since our intention
is to study massless and massive fermions, let us examine in detail the
spinorial representations of the Lorentz group. We will restrict
ourselves to the proper and orthochronous Lorentz group, given that the
parity and time reversal cases are usually treated separately. A generic
quantum field @xmath , with @xmath a finite number of indexes,
transforms under a Lorentz transformation, represented as a unitary
operator @xmath , as [ 46 ]

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are matrices that obey all the properties of the Lorentz
group, i.e. they belong to a representation of the group. In the case of
an infinitesimal Lorentz transformation,

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

the unitary operator @xmath is given by [ 46 ]

  -- -------- -- -------
     @xmath      (B.2)
  -- -------- -- -------

being @xmath a set of operators obeying the following commutation
relations

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

This operators are known as the generators of the Lorentz group and the
relations ( B.3 ) are the Lie algebra of the group. Whereas the
generators @xmath are antisymmetric, we will have only 6 independent
operators. Those operators will correspond to the components of the
angular momentum @xmath and the components of the boosts @xmath ,
defined as [ 46 ]

  -- -------- --
     @xmath   
  -- -------- --

An important consequence of these definitions is that the commutation
relations for @xmath will be

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (B.4a)
              @xmath      (B.4b)
              @xmath      (B.4c)
  -- -------- -------- -- --------

with @xmath the Levi-Civita symbol in three dimensions. The
interpretation of these relations is straightforward. The first and the
second ones are the standard relations among the components of the
angular momentum and the commutator between the angular momentum and any
vector, respectively. The third one shows that a set of boosts can be
equivalent to a rotation, as in the case of the Thomas precession [ 243
] . Although the operators @xmath have a definite interpretation, let us
introduce the operators @xmath [ 46 ]

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The commutation relations ( B.4 ) take a simpler form,

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (B.5a)
              @xmath      (B.5b)
              @xmath      (B.5c)
  -- -------- -------- -- --------

This shows that the @xmath form two independent commuting SU @xmath
algebras ¹ ¹ 1 Technically speaking, the complex linear combinations of
the Lorentz algebra are isomorphic to the complex linear combinations of
the Lie algebra of SU @xmath SU @xmath . related by hermitian
conjugation. This simplifies the construction of the representations
since the properties of SU @xmath are well known. Hence, a
representation of the Lorentz group will be characterized by two angular
momenta @xmath , corresponding to @xmath respectively, with @xmath Each
representation will have @xmath components. Explicitly, we will
designate the first four cases as [ 46 ]

    [align=right,labelwidth=6.5cm]

 @xmath 

    scalar or singlet,

 @xmath 

    left-handed spinor,

 @xmath 

    right-handed spinor,

 @xmath 

    vector.

Therefore, we see here that there are two different representations
containing the one-half angular momentum. Besides, those inequivalent
representations are related by hermitian conjugation. The first thing we
could ask here is if we can have a fermion field that transforms only in
one of those representations. To answer this, let us examine the
properties of the left-handed and right-handed representations. Given
our knowledge of the SU @xmath , we know that in both cases the
fundamental representation will have two components.

Left-handed representation. Let us call the fundamental representation
for the left-handed spinor as @xmath , @xmath taking two values. We can
choose the angular momentum and boosts operators as [ 46 ]

  -- -------- -- -------
     @xmath      (B.6)
  -- -------- -- -------

being @xmath the Pauli matrices, see appendix A . As consequence of this
choosing, we have that @xmath and @xmath , as expected. The matrix
@xmath can be obtained considering the transformation of the left-handed
spinor,

  -- -------- -- -------
     @xmath      (B.7)
  -- -------- -- -------

Explicitly, one can find that

  -- -------- --
     @xmath   
  -- -------- --

being @xmath the generators of this representation, i.e. the @xmath
operators for the @xmath representation,

  -- -------- --
     @xmath   
  -- -------- --

or, considering the “four-vectors” @xmath and @xmath defined in the
appendix A , [ 46 ]

  -- -------- -- -------
     @xmath      (B.8)
  -- -------- -- -------

Right-handed representation. As stated before, when we take the
hermitian conjugate of a left-handed field, we will obtain a field
transforming under the @xmath or right-handed representation. It is
customary to put a dot on the indexes of the right-handed field in order
to distinguish them from a left-handed field, [ 46 ]

  -- -------- -- -------
     @xmath      (B.9)
  -- -------- -- -------

In this case, the angular momentum and boost operators are given by,

  -- -------- -- --------
     @xmath      (B.10)
  -- -------- -- --------

and the Lorentz transformation of a right-handed field is [ 46 ]

  -- -------- -- --------
     @xmath      (B.11)
  -- -------- -- --------

The transformation matrix is given by

  -- -------- --
     @xmath   
  -- -------- --

#### b.1 Weyl Algebra

To write terms which will be invariant under Lorentz transformations, we
will introduce some definitions next. Let us first define the
antisymmetric @xmath symbol [ 46 ]

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The @xmath symbol will be useful to raise and lower spinorial indices,

  -- -------- -------- -- --------
     @xmath   @xmath      (B.12)
  -- -------- -------- -- --------

Thus, it will be possible to contract spinorial indices as is done with
spacetime ones. However, it is important to note that the ordering in
which the indices are contracted is crucial. For instance, using the
antisymmetric property of @xmath

  -- -------- --
     @xmath   
  -- -------- --

It is necessary to establish a convention about the contracted indices.
Following Srednicki [ 46 ] , we will identify a pair of undotted
contracted indices always as @xmath and for dotted indices we will have
the opposite @xmath . Therefore, if we attempted to write invariant term
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

it should be identical to zero. Nevertheless, it is clear that the
representations we are considering correspond to fermion
representations. Then, we expect that such fields do anticommute . Thus,
the term will be

  -- -------- --
     @xmath   
  -- -------- --

For a general combination,

  -- -------- --
     @xmath   
  -- -------- --

and we safely can ignore the spinorial indices keeping in mind the
convention on the ordering

  -- -------- --
     @xmath   
  -- -------- --

For right-handed fields, we will have @xmath [ 46 ] . We will define the
indices of the @xmath and @xmath as

  -- -------- -- --------
     @xmath      (B.13)
  -- -------- -- --------

notice the position and order of the indices. Such strange definitions
are clarified by noting that [ 46 ]

  -- -------- -- --------
     @xmath      (B.14)
  -- -------- -- --------

Other properties that @xmath and @xmath obey are,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Now, armed with these definitions, we can write invariant terms under
Lorentz transformations. Evidently, we already have invariant @xmath
terms, but let us consider [ 46 ]

  -- -------- -- --------
     @xmath      (B.15)
  -- -------- -- --------

Applying the transformation properties of left- and right-handed fields,
we have that the previous term transforms as a vector field,

  -- -------- -- --------
     @xmath      (B.16)
  -- -------- -- --------

Thus, a term like

  -- -------- -- --------
     @xmath      (B.17)
  -- -------- -- --------

is Lorentz invariant. Having the two main types of terms with and
without derivatives, we can write invariant lagrangians.

#### b.2 Weyl Fermions

Let us start considering a fermion field @xmath in such a way that it
has a conserved charged, that is, its lagrangian has to be invariant
under transformations [ 244 ]

  -- -------- -- --------
     @xmath      (B.18)
  -- -------- -- --------

this avoids terms as @xmath or @xmath . Therefore, the lagrangian for
such fields, which we will name as Weyl fermions, is

  -- -------- -- --------
     @xmath      (B.19)
  -- -------- -- --------

As we can see here, this lagrangian is built from one type of field.
Thus, a Weyl fermion does have a definite chirality. It is also possible
to show that it has a definite helicity, as proven in the chapter 1 .

#### b.3 Majorana Fermions

Now, let us suppose that there is no conserved charge; we can then
include bilinear terms in the fields [ 46 ]

  -- -------- -- --------
     @xmath      (B.20)
  -- -------- -- --------

We have included both terms with the field in order to maintain our
lagrangian hermitian. We can obtain the equations of motion for the
@xmath field. The Euler-Lagrange equation for @xmath is

  -- -------- -- --------
     @xmath      (B.21)
  -- -------- -- --------

which coincides with the equation ( 2.2 ) appearing in chapter 2 by
writing explicitly the @xmath matrix to lower the spinorial index of
@xmath . This fermion will have a definite chirality, as it is built
from a unique Weyl field; but, it actually has two helicities, as
presented in the chapter 2 . This kind of fermion representation is
named after Ettore Majorana, i.e. this is a Majorana fermion.

#### b.4 Dirac Fermions

Now, let us consider a theory with two left-handed fermions, @xmath with
@xmath , having the same mass @xmath [ 46 ]

  -- -------- -- --------
     @xmath      (B.22)
  -- -------- -- --------

Note that this lagrangian is invariant under the SO( @xmath )
transformation, [ 46 ]

  -- -------- -- --------
     @xmath      (B.23)
  -- -------- -- --------

so, we can define the following two combinations

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (B.24a)
     @xmath   @xmath      (B.24b)
  -- -------- -------- -- ---------

in such a way that our lagrangian becomes

  -- -------- -- --------
     @xmath      (B.25)
  -- -------- -- --------

We can now derive the equations of motion for the fields,

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (B.26a)
     @xmath   @xmath      (B.26b)
  -- -------- -------- -- ---------

these equations are evidently coupled. We can write them in a better way
using matrix properties,

  -- -------- -- --------
     @xmath      (B.27)
  -- -------- -- --------

where we have taken the hermitian conjugate of the second equation and
we used the properties of the @xmath matrices, equation ( B.14 ). Thus,
we can define a four-component field,

  -- -------- -- --------
     @xmath      (B.28)
  -- -------- -- --------

and define new gamma matrices as

  -- -------- -- --------
     @xmath      (B.29)
  -- -------- -- --------

We obtain the acclaimed Dirac equation,

  -- -------- -- --------
     @xmath      (B.30)
  -- -------- -- --------

Therefore, we can conclude that a Dirac fermion is composed by two
chiral fields @xmath , having opposite chiralities. Hence, a Dirac field
will not have a definite chirality.

It is possible to get back to the Weyl two-component notation. Let us
define the chirality matrix as

  -- -------- -- --------
     @xmath      (B.31)
  -- -------- -- --------

and the left and right projectors @xmath

  -- -------- -- --------
     @xmath      (B.32)
  -- -------- -- --------

Projecting the Dirac field @xmath , we find

  -- -------- -- --------
     @xmath      (B.33)
  -- -------- -- --------

Therefore, we see that we can pass from one notation to the other by
using the projector operators. We also can conclude that a Dirac fermion
is composed by two Majorana fermions. Let us also stress that the Dirac
fermion @xmath is invariant under the trasnformation,

  -- -------- --
     @xmath   
  -- -------- --

which comes from the SO( @xmath ) original invariance.

In this appendix we have shown how the distinct types of fermions are
generated in a systematic manner by considering the properties of the
Lorentz trasformations and the Lorentz group. Considering that the Lie
algebra of the Lorentz group can be written in the form of two
independent SU( @xmath ) algebras, we found that the representations
have two different numbers, that is, two different values of the angular
momenta. For the case of interest, fermion representations, there are
two possible representations, called left- and right-handed
representations. The type of representation of a fermion is usually
called chirality . We explicitly considered each representation. After
developing the notation usually applied to fermions, we wrote explicitly
the lagrangians for Weyl, Majorana and Dirac fermions. We saw that a
Weyl fermion corresponds to a field, with a well defined chirality,
invariant under phase transformations. If one eliminates the restriccion
of the invariance, it is possible to include mass terms for the fermion,
and we obtain a Majorana field. Finally, if we write a lagrangian for
two left-handed Majorana fermions invariant under a SO( @xmath )
symmetry, it is possible to derive the Dirac equations in
four-components; then, we can conclude that a Dirac fermion is composed
by two Majorana fields.
