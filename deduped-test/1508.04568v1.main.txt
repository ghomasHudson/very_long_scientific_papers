##### Contents

-    1 Introduction
    -    1.1 Summary and Context
    -    1.2 Conventions and Notation
    -    1.3 Acknowledgments
-    2 Symplectic Linear Algebra
    -    2.1 Basic notions
    -    2.2 Lagrangian splittings
    -    2.3 Reduction, Witt-Artin decomposition
-    3 Linear Relations
    -    3.1 Definitions, Properties
    -    3.2 Classification
-    4 Linear Canonical Relations
    -    4.1 Definitions, Properties
    -    4.2 Factorization
-    5 Coisotropic Pairs
    -    5.1 General classification of coisotropic pairs
    -    5.2 Elementary types and normal forms
-    6 Classification of Linear Canonical Relations
    -    6.1 Reduced classification problem
    -    6.2 Normal forms

## 1 Introduction

### 1.1 Summary and Context

The subject of the present work is the problem of classifying, up to
linear symplectomorphism, linear canonical relations from a symplectic
vector space @xmath to itself. We begin with a precise formulation of
this classification problem and a short overview of this work’s
contents, which comprise partial results toward the solution of this
classification problem, as well as an exposition of the tools and
results used toward this aim.

The basic setting involves a finite-dimensional real vector space @xmath
, equipped with a symplectic form @xmath , i.e. a non-degenerate
antisymmetric bilinear form @xmath . If one multiplies @xmath by @xmath
this also gives a symplectic form; we use the notation @xmath to
indicate when @xmath is endowed with this symplectic structure. On the
space @xmath we have a naturally defined symplectic form which is the
direct sum of the symplectic forms on @xmath and @xmath

  -- -------- --
     @xmath   
  -- -------- --

A linear subspace @xmath is a linear canonical relation if it is a
lagrangian subspace, i.e. such that the symplectic form on @xmath is
identically zero when restricted to @xmath and such that @xmath has the
maximum possible dimension for such a subspace, that is @xmath . If
@xmath and @xmath are symplectic vector spaces and @xmath and @xmath
linear canonical relations in @xmath and @xmath respectively, we say
they are equivalent if there exists a linear symplectomorphism @xmath (a
linear isomorphism satisfying @xmath ) such that

  -- -------- --
     @xmath   
  -- -------- --

The classification problem at hand is to determine invariants which
uniquely determine the equivalence classes of this equivalence relation
and to give normal forms for these, i.e. unique representatives of each
equivalence class.

The graph of any linear symplectomorphism from @xmath to itself is a
special case of a linear canonical relation. If we consider only such
linear canonical relations, the above classification problem amounts to
the problem of giving normal forms for the conjugacy classes of the
group of linear symplectomorphisms on @xmath . This problem has various
solutions and a long history, which extends from Williamson [ 17 ] to,
most recently, Gutt [ 7 ] . The paper of Laub and Meyer [ 8 ] contains a
helpful albeit somewhat dated survey of this history. In [ 12 ] Towber
carries out the classification of linear relations up to linear
isomorphism, i.e. the more general version of our present classification
problem which does not include any symplectic structure. We will discuss
some basic properties of linear relations and Towber’s results in
Section 3 . In Section 4 we describe basic properties of linear
canonical relations, the most important being the result of Benenti and
Tulczyjew stating that a linear canonical relation is described by two
coisotropic subspaces and an induced linear symplectomorphism between
their reduced spaces. In particular, as a first step in our
classification problem it is necessary to classify pairs of coisotropic
subspaces up to linear symplectomorphism. This is done in Section 5 .
Finally in Section 6 we present partial results towards a full solution
of the classification problem.

Linear canonical relations are the linear counterparts of canonical
relations (also known as lagrangian correspondences), which are
lagrangian submanifolds of the product of two symplectic manifolds. One
motivation for the study of such objects arises in the context of
quantization, where one is interested in making rigorous the
correspondences between mathematics associated to classical mechanics on
the one hand, and to quantum mechanics on the other. On the classical
side a symplectic manifold, symplectomorphisms of and functions on this
manifold are used to describe the possible states, the symmetries, time
evolution, and the observables of a physical system. The corresponding
objects on the quantum side are usually given by a Hilbert space
together with an algebra of operators on this space and probability
measures constructed from such operators. One approach to the
quantization problem is to try to find appropriate descriptions on both
the classical and quantum sides which exhibit the structure of a
category, and for which the passage from classical to quantum is
functorial.

In this context, canonical relations are a way to generalize the idea of
a symplectomorphism with the goal of obtaining a category in which they
are the morphisms. In the linear case, the linear canonical relations do
in fact define the morphisms of a category of which the objects are
symplectic vector spaces. In the non-linear case, where the objects are
symplectic manifolds, this is not so. Both the linear and the non-linear
cases exhibit delicacies when one attempts to compose canonical
relations which do not satisfy a certain transversality condition. In
the linear situation this manifests itself in that the composition
operation becomes non-continuous in terms of the usual topology on the
space of all lagrangian subspaces. A solution to this problem is
presented by Li-Bland and Weinstein in [ 9 ] . In the non-linear case,
further difficulties arise. Although these issues are beyond the scope
of the present exposition, they form part of a greater context in which
it is embedded. For more on the these general topics, we refer the
interested reader to [ 2 ] and [ 15 ] , and the many references therein.

### 1.2 Conventions and Notation

Throughout the text, notation is usually standard or is introduced as
needed. We note here though that everything takes place in finite
dimensions and that everything is linear. Many times the adjective
“linear” will thus be omitted (and tacitly implied). In this vein, the
terms “linear symplectomorphism”, “symplectomorphism” and “symplectic
map” will be used as synonyms.

### 1.3 Acknowledgments

I wish to thank first and foremost Alan Weinstein, for his generous
kindness, humor, patience and guidance throughout my stay at UC
Berkeley, of which this thesis is but one product. My gratitude also
goes to Giovanni Felder, for his encouragement, mentorship and the
reading course last fall, which led to where I am now. Lastly, I express
my appreciation toward the Anna and Hans Kägi Foundation, the ETH Zurch,
and the City of Zurich for their financial sponsorship, and to my family
and friends for their support.

## 2 Symplectic Linear Algebra

### 2.1 Basic notions

We recount here some linear algebraic definitions and constructions in
the setting of a symplectic vector space @xmath . If @xmath are
subspaces, we say they are @xmath - orthogonal if @xmath for all @xmath
. For any subspace @xmath , its @xmath -orthogonal subspace is

  -- -------- --
     @xmath   
  -- -------- --

This space is not in general a complement of @xmath in @xmath , but its
dimension is complementary

  -- -------- --
     @xmath   
  -- -------- --

One way to see this is via the mapping

  -- -------- --
     @xmath   
  -- -------- --

The non-degeneracy of @xmath means that @xmath is an isomorphism. By
post-composing this map with the restriction @xmath one obtains an
epimorphism @xmath with kernel @xmath , and consequently an isomorphism
@xmath .

As an operation on subspaces, taking the @xmath -orthogonal is
involutive and exchanges sums and intersections

  -- -------- --
     @xmath   
  -- -------- --

If we restrict @xmath to @xmath , its kernel is @xmath . One defines

  -- -------- --
     @xmath   
  -- -------- --

A subspace @xmath is called symplectic if the restriction @xmath of
@xmath to @xmath defines a symplectic form, making @xmath a symplectic
space in its own right. That @xmath be non-degenerate means @xmath and
@xmath is symplectic if and only if @xmath . In particular, if @xmath is
symplectic then @xmath is too, and one has an @xmath -orthogonal
decomposition @xmath . Further fundamental types of subspaces can also
be defined via the relation of a space with its orthogonal: @xmath is

  -- -- -------- --
        @xmath   
        @xmath   
        @xmath   
  -- -- -------- --

In particular, @xmath is lagrangian if and only if it is isotropic (or
coisitropic) and @xmath .

A linear symplectomorphism or symplectic map from one symplectic space
@xmath to another @xmath is a linear isomorphism @xmath such that @xmath
. For such a map one has

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

hence in particular @xmath is symplectic/(co)isotropic/lagrangian when
@xmath is, and any @xmath -orthogonal decomposition @xmath is mapped to
an @xmath -orthogonal decomposition @xmath . In general, if @xmath and
@xmath are any given decompositions (possibly not @xmath -orthogonal),
we say a map @xmath satisfying @xmath and @xmath respects the
decompositions in @xmath and @xmath . If @xmath , @xmath , @xmath and
@xmath are symplectic subspaces and @xmath is a symplectic map which
respects the decompositions, then @xmath and @xmath are again symplectic
maps. The following gives a kind of converse to this fact.

###### Lemma 1

Let @xmath and @xmath be two @xmath -orthogonal direct sum
decompositions with symplectic subspaces. Let @xmath and @xmath , and
set @xmath . Then @xmath is symplectic iff @xmath and @xmath are
symplectic.

Proof. Assume @xmath and @xmath are symplectic, and let @xmath denote
the decomposition of any @xmath with respect to the splitting @xmath .
For @xmath one has

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the second and fourth equalities hold due to the orthogonality of
@xmath and @xmath , and @xmath and @xmath , respectively. This shows
that @xmath is symplectic. The converse statement, when @xmath is
assumed symplectic, is clear since then @xmath and @xmath .

@xmath

In the above, the orthogonality condition on @xmath and @xmath (and
@xmath and @xmath ) amounts to @xmath being naturally symplectomorphic
to the external direct sum of two separate symplectic spaces @xmath and
@xmath , endowed with the direct sum symplectic form @xmath defined by
@xmath .

The 2-dimensional symplectic spaces are the basic building blocks of
symplectic vector spaces in the sense that any such may be decomposed as

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath is a 2-dimensional symplectic subspace and @xmath . In
particular @xmath is even. We will henceforth always use @xmath to
denote half the dimension of @xmath . To prove the above, one can use an
iterative Gram-Schmidt-type process to construct a basis @xmath of
@xmath such that

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

Any ordered basis satisfying this property is a symplectic basis . For
such a basis, the 2-dimensional subspaces @xmath are @xmath -orthogonal
when @xmath , and the matrix associated to each @xmath

  -- -------- --
     @xmath   
  -- -------- --

is non-singular, so each @xmath is a symplectic subspace. To construct a
symplectic basis, begin with any vector @xmath . Since @xmath is
non-degenerate there exists a vector @xmath such that @xmath , and this
vector may be normalized if need be so that @xmath . Note that @xmath
implies that @xmath and @xmath are linearly independent since by
antisymmetry @xmath for any @xmath . The subspace @xmath is a symplectic
subspace, and its @xmath -orthogonal complement is such that @xmath . If
this complement is zero we are done, otherwise we can choose any vector
@xmath and, because @xmath is non-degenerate, we can also find @xmath
such that @xmath . In particular the dimension of @xmath , if non-zero,
must be at least two. One sets @xmath and continues this process in the
@xmath -orthogonal complement of the symplectic space @xmath .
Proceeding iteratively one must reach a point after a finite number
@xmath iterations where the @xmath -orthogonal complement of @xmath is
zero, since the dimension of such complements decreases by 2 with each
step, and each complement has dimension either greater than 1 or equal
to 0. Hence the @xmath and @xmath span @xmath , and they are linearly
independent and satisfy ( 1 ) by construction. The fact that every
symplectic vector space admits a symplectic basis is the linear version
of Darboux’s theorem.

### 2.2 Lagrangian splittings

In addition to direct sum decompositions into symplectic subspaces, one
may also consider decompositions of the form @xmath , where @xmath and
@xmath are lagrangian subspaces. In such a case we call @xmath a
lagrangian splitting of @xmath or a transverse lagrangian pair . Because
a symplectic basis always exists, so also do lagrangians and lagrangian
splittings. If @xmath is a symplectic basis, @xmath and @xmath are
lagrangian subspaces forming a lagrangian splitting.

###### Proposition 2.1

Let @xmath be lagrangian. Then there exists a lagrangian subspace @xmath
such that @xmath is a lagrangian splitting of @xmath .

Proof. Let @xmath and let @xmath be a basis of @xmath . We proceed in a
similar manner as in the iterative construction of a symplectic basis,
though now the @xmath must be in the prescribed subspace @xmath . To
@xmath we can find @xmath such that @xmath by choosing @xmath in @xmath
and scaling if necessary. This is possible because @xmath is @xmath
-dimensional, and @xmath is @xmath -dimensional; @xmath is clear because
@xmath . Set @xmath . Because @xmath , we have @xmath , and this is an
equality for dimension reasons, since @xmath . So @xmath is a
Langrangian subspace of the symplectic space @xmath and one can iterate
the procedure by choosing @xmath and normalizing such that @xmath .
After a finite number of steps one will have constructed a symplectic
basis @xmath , which means that @xmath is a langrangian complement of
@xmath .

@xmath

In the proof above, we constructed a symplectic basis which extends a
given basis of @xmath . One can in prescribe a lagrangian @xmath , a
basis of @xmath , as well as a lagrangian complement @xmath .

###### Proposition 2.2

Let @xmath be a lagrangian splitting of V, and let @xmath be a basis of
@xmath . Then there exists exactly one basis @xmath of @xmath such that
@xmath is a symplectic basis of @xmath .

Proof. One way to show this is to note that the isomorphism @xmath
induces an isomorphism @xmath , and the images of the @xmath basis
vectors in @xmath give the dual basis of the desired basis @xmath of
@xmath . Indeed, by precomposing @xmath with the inclusion map @xmath
and post-composing with the restriction @xmath , one obtains a linear
mapping @xmath . We check that it is an isomorphism.

For surjectivity, consider any @xmath . We can extend @xmath to a linear
map @xmath by setting @xmath , where @xmath is the projection onto the
second lagrangian subspace with respect to the splitting @xmath . Then
@xmath has a unique pre-image @xmath such that @xmath . But @xmath is in
fact in @xmath : If @xmath is the decomposition of an arbitrary @xmath
into its @xmath and @xmath components (and @xmath the @xmath component
of @xmath ), then we find @xmath (the first term is @xmath and the
second term vanishes because @xmath is lagrangian). Hence @xmath , i.e.
@xmath , and @xmath maps @xmath to @xmath .

For injectivity, consider @xmath in the kernel of @xmath . Then for
arbitrary @xmath , @xmath : the first term vanishes by the lagrangian
property and the second term because @xmath by the assumption @xmath .
Since @xmath was arbitrary, @xmath .

So @xmath maps the basis @xmath to a basis of @xmath . Let @xmath be the
dual basis in @xmath of this basis, i.e. such that

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath , this condition - together with the fact that the @xmath
and @xmath each span a lagrangian subspace - means precisely that @xmath
is a symplectic basis of @xmath . It is clear that the subbasis @xmath
is unique given @xmath and @xmath , since any such has to fulfill @xmath
, which has a unique solution.

@xmath

###### Proposition 2.3

Let @xmath be a lagrangian splitting of @xmath . Set @xmath and equip
@xmath with the symplectic form @xmath . Then there exists a
symplectomorphism @xmath such that @xmath and @xmath .

Proof. A canonical symplectic basis for @xmath is given by the standard
basis on @xmath , together with its dual basis. By Proposition 2.2 , we
can find a symplectic basis @xmath in @xmath such that @xmath and @xmath
. Then the mapping defined by @xmath and @xmath gives a
symplectomorphism @xmath as desired.

@xmath

###### Corollary 2.4

Let @xmath and @xmath be two symplectic vector spaces of the same
dimension, and @xmath and @xmath decompositions into complementary
lagrangian pairs. Then there exists a symplectomorphism @xmath such that
@xmath and @xmath .

### 2.3 Reduction, Witt-Artin decomposition

The quotient construction known as symplectic reduction produces a
symplectic space from any subspace @xmath .

###### Lemma 2

Let @xmath be any subspace. Then @xmath carries a natural induced
symplectic structure @xmath , given by @xmath for all @xmath .

Proof. To check that the form @xmath is well-defined, let @xmath be such
that @xmath and @xmath . Then @xmath and @xmath for some @xmath and

  -- -------- --
     @xmath   
  -- -------- --

is equal to @xmath because the three right-hand terms above vanish since
@xmath and @xmath are @xmath -orthogonal to all of @xmath . To see that
@xmath is non-degenerate, assume @xmath is such that @xmath for all
@xmath . This implies @xmath for all @xmath , so @xmath and hence @xmath
.

@xmath

The reduced space @xmath will sometimes be denoted @xmath and @xmath is
the reduction map associated to the reduction of @xmath by @xmath . In
the special case when @xmath is a coisotropic subspace, this map has the
following useful property.

###### Lemma 3

Let @xmath be a coisotropic subspace. If @xmath is an isotropic
(coisotropic) subspace, then the image of @xmath under @xmath is an
isotropic (coisotropic) subspace of @xmath . In particular, when @xmath
is lagrangian, then so is @xmath .

Proof. Let @xmath denote the image under @xmath of any subspace @xmath .
One has

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the last equality holds because @xmath . Since the partial
ordering of inclusion is preserved under the map @xmath (signified by
brackets), we see that @xmath if @xmath is isotropic, and @xmath is
@xmath is coisotropic.

@xmath

For any subspace @xmath , the subspace @xmath is the kernel of @xmath as
well as @xmath , hence one can in a sense simultaneously perform a
reduction with respect to both @xmath and @xmath . Lifting back to
@xmath , this induces a decomposition of @xmath as an @xmath -orthogonal
direct sum of symplectic subspaces.

###### Proposition 2.5 (Witt-Artin decomposition)

Let @xmath be any subspace, and @xmath and @xmath complements of @xmath
in @xmath and @xmath respectively. Then @xmath and @xmath are symplectic
subspaces and @xmath -orthogonal, and @xmath decomposes as the @xmath
-orthogonal direct sum

  -- -------- --
     @xmath   
  -- -------- --

Moreover, @xmath is a lagrangian subspace of @xmath .

Proof. Let @xmath be the projection map associated to the decomposition
@xmath . This induces an isomorphism @xmath such that @xmath for all
@xmath . Under this map, the symplectic form @xmath on the reduced space
@xmath is pushed forward to a symplectic form on @xmath , and @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Thus @xmath is symplectic, and by analogous arguments @xmath is
symplectic as well. @xmath and @xmath are @xmath -orthogonal because
@xmath and @xmath . As a consequence, @xmath and @xmath is symplectic
also. From this it follows that @xmath .

Finally, @xmath is in @xmath since it is in @xmath and @xmath each, and
@xmath . Clearly @xmath is isotropic. To see that it is lagrangian in
@xmath , note that @xmath and recall the general fact that if @xmath are
subspaces such that @xmath and @xmath , it holds that @xmath . We now
calculate

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the last inequality uses the fact that @xmath and the second to
last uses the general fact about subspace above, with @xmath in the role
of @xmath .

@xmath

[]

Figure 1

Figure 1 gives a representation of the Witt-Artin decomposition of
@xmath with respect to @xmath , each of the four slices denoting a
direct summand. The circle is all of @xmath red is used for the subspace
@xmath and blue for @xmath giving a violet hue where they intersect. The
yellow subspace @xmath represents a choice of a lagrangian complement of
@xmath in @xmath .

## 3 Linear Relations

In this section, @xmath and @xmath all denote finite dimensional vector
spaces over @xmath .

### 3.1 Definitions, Properties

A linear relation from @xmath to @xmath is a linear subspace of the
direct sum @xmath . In particular, a linear relation is a relation in
the set-theoretic sense. If @xmath is a linear relation, the notation
@xmath will be used to say that @xmath .

We think of linear relations as generalizations of linear maps in the
sense that the graph @xmath of a linear map @xmath

  -- -------- --
     @xmath   
  -- -------- --

is always a linear relation and contains all the information of @xmath .
If @xmath is another linear map, the graph of the composition @xmath is

  -- -------- --
     @xmath   
  -- -------- --

The composition rule for linear relations should be a generalization of
this usual composition rule for maps. Given linear relations @xmath and
@xmath their composition or product is defined as

  -- -------- --
     @xmath   
  -- -------- --

For a linear relation @xmath we call @xmath its source , @xmath its
target , and we define its domain , range , kernel and halo respectively
as

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

A linear relation @xmath is the graph of a linear map if and only if its
domain is the entire source space and if it is single valued as a
mapping. This is expressed in the conditions

1.  @xmath such that @xmath

2.  @xmath

where, by linearity, the second condition is equivalent to saying that
if @xmath and @xmath , then @xmath . A linear relation is called
cosurjective when i) is satisfied, and called coinjective if ii) is
satisfied.

The familiar notions of direct sums and the adjoint of a map can be
extended to linear relations. If @xmath and @xmath are linear relations,
their (external) direct sum is the linear relation in @xmath given by
the subspace @xmath . The adjoint of a linear map @xmath is defined such
that for the natural pairing of any vector space @xmath with its dual
@xmath

  -- -------- --
     @xmath   
  -- -------- --

holds @xmath for all @xmath , which, because this pairing is
non-degenerate, is equivalent to saying that for any @xmath

  -- -------- --
     @xmath   
  -- -------- --

One generalizes this to define the adjoint @xmath of a linear relation
@xmath via the condition

  -- -------- --
     @xmath   
  -- -------- --

If non-degenerate bilinear maps @xmath and @xmath are given, then

  -- -------- --
     @xmath   
  -- -------- --

define natural isomorphisms, which one may use to define the transpose
relation @xmath such that the diagram

  -- -------- --
     @xmath   
  -- -------- --

commutes, i.e.

  -- -------- --
     @xmath   
  -- -------- --

When @xmath is a linear map, this is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

i.e. the definition coincides with the usual notion of the transpose of
a map.

One notion which is quite natural in the context of relations is the
reverse or converse @xmath of a linear relation @xmath , which is
defined

  -- -------- --
     @xmath   
  -- -------- --

The operation of taking the converse reverses the roles of source and
target; one has

  -- -------- --
     @xmath   
  -- -------- --

and @xmath is cosurjective (coinjective) if @xmath is surjective
(injective). In the special case when @xmath is a linear isomorphism,
@xmath corresponds to the inverse map @xmath The converse of a relation
is not in general an inverse though, as illustrated by the simple
example when @xmath . The composition @xmath is equal to all of @xmath ,
whereas @xmath is equal to @xmath . The linear relation corresponding to
the identity map @xmath will be denoted

  -- -------- --
     @xmath   
  -- -------- --

and this acts as a unit when precomposed with linear relations from
@xmath to @xmath or composed with linear relations from @xmath to @xmath
. It may be readily verified that linear relations form the morphisms of
a category LRel whose objects are finite dimensional vector spaces, and
where for each object @xmath , the diagonal @xmath is the identity
morphism.

In the following section we will restrict ourselves to considering only
linear relations where the source and target space coincide. In this
context, we think of the linear relations as the objects, and define a
morphism from a linear relation @xmath and a linear relation @xmath as a
linear map @xmath such that

  -- -------- -- -----
     @xmath      (2)
  -- -------- -- -----

In this way one again obtains the structure of a category, which we call
EndLRel . A morphism @xmath in EndLRel is an isomorphism when it is
invertible, and in the special case when @xmath and @xmath are linear
maps, the condition ( 2 ) is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

i.e. endomorphisms which are isomorphic in EndLRel are precisely those
which are conjugate.

### 3.2 Classification

We present here the result due to Towber [ 12 ] stating that any linear
relation in EndLRel is isomorphic to the direct sum of objects in
EndLRel which are of only four basic types. Up to the order of summands
this decomposition is unique; it gives a full classification of the
isomorphism classes of EndLRel .

We describe first the four basic types, using for each dimension @xmath
the model space @xmath . The linear endomorphisms of a vector space form
a special subset of EndLRel (in fact a subcategory), and by the
generalized Jordan normal form any such map is isomorphic to the direct
sum of endomorphisms which are indecomposable, i.e. they are not
isomorphic to the direct sum of endormorphisms on spaces of smaller
dimension. In coordinates, this corresponds to a block matrix form. The
decomposition is unique up to order and can be split into two parts,
comprising a non-singular and a singular endomorphism respectively. The
non-singular part is characterized by the number and size of the blocks,
as well as the eigenvalues they correspond to. The singular part can be
represented by a sum of Jordan blocks of the form

  -- -------- --
     @xmath   
  -- -------- --

In @xmath , for appropriate dimension @xmath , such blocks correspond to
the linear relation generated over @xmath by the basis

  -- -------- --
     @xmath   
  -- -------- --

Following Towber, we use @xmath to denote this linear relation.

The other indecomposable basic types identified by Towber have a similar
form, but do not correspond to linear endomorphisms (i.e. they fail
either to be single-valued or everywhere-defined). For each dimension
@xmath they are denoted @xmath , @xmath and @xmath , and given in @xmath
by the span of

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

respectively. For completeness we restate ¹ ¹ 1 see [ 12 ] , p.6 here

###### Theorem 3.1

Every finite-dimensional linear relation is isomorphic to a direct sum
of a non-singular linear map and a finite number of linear relations of
the types @xmath , @xmath , @xmath , and @xmath (for various values of
@xmath and possibly with finite multiplicities). Furthermore the number
of summands of each type and each given dimension is unique, i.e. these
numbers give a complete set of invariants which classify linear
relations up to isomorphism.

## 4 Linear Canonical Relations

### 4.1 Definitions, Properties

We now come to our main objects of study, in which the structures of
linear relations and symplectic linear algebra interact. Let @xmath and
@xmath be symplectic vector spaces, and again denote by @xmath the
symplectic vector space @xmath . A linear canonical relation from @xmath
to @xmath is a linear relation @xmath which is a lagrangian subspace
with respect to the direct sum symplectic form on @xmath , i.e. a
subspace of dimension @xmath which is isotropic

  -- -------- --
     @xmath   
  -- -------- --

We think of linear canonical relations as a generalization of linear
symplectomorphisms (also known as linear canonical transformations).
Indeed, if @xmath is a symplectic map, then @xmath because @xmath is
bijective, and by definition

  -- -------- --
     @xmath   
  -- -------- --

so its graph @xmath is an isotropic subspace of @xmath . Since @xmath
(this holds for any linear map), @xmath is lagrangian.

In fact, symplectic maps correspond to the only cases when a linear
canonical relation is the graph of a linear map. To see this suppose
@xmath for a linear map @xmath from @xmath to @xmath . Being a graph,
@xmath must have dimension equal to @xmath , and hence @xmath since
@xmath . So, @xmath is bijective if it is injective. If @xmath is an
element of the kernel of @xmath , the condition that @xmath by isotropic
gives

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath , so @xmath and @xmath is injective. The
condition that @xmath be isotropic in @xmath means that @xmath is
symplectic.

Another important special type of linear canonical relation consists of
those which are in some sense the farthest away from being
symplectomorphisms. These are linear canonical relations which are
entirely either a kernel or a halo, of the form

  -- -------- --
     @xmath   
  -- -------- --

or the converse of a relation of this form. It is easily verified that
for such a linear canonical relation one must have @xmath and @xmath
must be a lagrangian subspace. Thus canonical relations of this form are
in one to one correspondence with lagrangian subspaces of @xmath (or
subspaces of @xmath in the case of the converse).

Similar to linear relations, linear canonical relations are the
morphisms of a category, which we call and where the objects are
finite-dimensional symplectic vector spaces. Composition is the same as
in , and for each symplectic vector space @xmath , the identity morphism
@xmath is again the diagonal @xmath (which, as the graph of the
identity, is indeed a linear canonical relation). To show that the
composition

  -- -------- --
     @xmath   
  -- -------- --

of linear canonical relations @xmath , @xmath is again a linear
canonical relation, we describe the subspace @xmath as the image of a
lagrangian under a reduction map. To see this, we note first that the
set @xmath is the result of the following steps:

1.  intersect @xmath with @xmath

2.  project @xmath onto @xmath

It is easily checked that @xmath is a coisotropic subspace of @xmath
(its orthogonal space is @xmath ) and that @xmath is a lagrangian
subspace in @xmath . Hence, by Lemma 3 the reduction map @xmath maps
@xmath to a lagrangian subspace. But @xmath , which one identifies with
@xmath , and the image of @xmath under the reduction and after this
identification is precisely the image of the projection in step ii)
above, i.e. @xmath .

In general, the reduction of a symplectic space @xmath by a coisotropic
subspace @xmath , given by the reduction map @xmath , can be recast in
the present context as a linear relation @xmath which is surjective,
single-valued (coinjective), but whose domain is @xmath , i.e. it is not
defined everywhere. The fact that @xmath means precisely that @xmath in
this case is an isotropic subspace of @xmath and

  -- -------- --
     @xmath   
  -- -------- --

shows that @xmath is lagrangian. It turns out that any linear canonical
relation which is surjective and coinjective is induced in the above way
by a reduction map on some coisotropic subspace. For this reason one
calls a surjective, coinjective canonical relation a reduction and
accordingly a cosurjective, injective canonical relation a coreduction .
Equivalently, a coreduction is simply the converse of a reduction.

It is worth noting that in the literature one usually refers here to the
transpose instead of the converse. Either wording is appropriate since
for linear canonical relations these two concepts coincide with respect
to @xmath on each symplectic vector space @xmath . Indeed, if @xmath is
a canonical relation and @xmath , then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

### 4.2 Factorization

In this section we show how every linear canonical relation may be
factored as the composition of a reduction, a symplectic map and a
coreduction. This has in particular important consequences for our
classification problem. We once again restrict ourselves to the special
context of linear canonical relations whose source and target coincide,
fixing our notation such that @xmath always denotes a linear canonical
relation, @xmath denotes its domain, @xmath its image, and @xmath the
symplectic form on @xmath .

If @xmath is another canonical relation and @xmath an equivalence
between the two, i.e. a symplectic map such that

  -- -------- --
     @xmath   
  -- -------- --

then it is clear that @xmath maps @xmath and @xmath respectively to the
domain and range of @xmath ,

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

Another simple but important observation is that the orthogonal of
@xmath in @xmath is the kernel of @xmath . An analogous statement holds
for @xmath and the halo of @xmath .

###### Lemma 4

For the domain @xmath of @xmath holds: @xmath is in @xmath iff @xmath .

Proof. Assume first that @xmath . For every @xmath one has @xmath , and
hence @xmath , and @xmath because @xmath is lagrangian. Assume on the
other hand that @xmath . Then @xmath for every @xmath , and hence @xmath
for every @xmath , i.e. @xmath .

@xmath

This in turn leads to the following factorization result ² ² 2 see [ 3 ]
, Proposizioni 4.4 & 4.5 .

###### Proposition 4.1 (Benenti-Tulczyjew)

For any @xmath , the domain @xmath and range @xmath are coisotropic
subspaces of @xmath and the quotient relation @xmath induced by @xmath
defines a symplectomorphism between the reduced spaces @xmath and @xmath
. In other words @xmath factors as @xmath , where @xmath is the
canonical relation of the reduction of @xmath by @xmath , and @xmath the
transpose of the reduction of @xmath by @xmath .

Proof. @xmath (and @xmath ) must be coisotropic, i.e. @xmath , since by
the previous proposition one has @xmath for any @xmath , and hence also
@xmath . We recall that the induced quotient relation @xmath is
(well)defined by @xmath iff @xmath . Observe that for every @xmath there
exists @xmath such that @xmath , simply by virtue of the fact that
@xmath implies that @xmath for some @xmath . Thus @xmath is the graph of
a linear map @xmath . Via the same argument, but with the roles of
@xmath and @xmath reversed, one sees that this linear map must also be
surjective. For injectivity, assume that @xmath and @xmath are both in
@xmath . By linearity, @xmath is also in @xmath , and hence @xmath ,
which by proposition 4 is equivalent to @xmath . It follows that @xmath
, i.e. @xmath . So, the linear mapping corresponding to @xmath is
nonsingular. To check that it is a symplectomorphism, let @xmath and
@xmath be two elements of @xmath . If @xmath and @xmath denote the
induced symplectic forms on @xmath and @xmath respectively, one has
@xmath , which is zero as desired because @xmath and @xmath are in
@xmath .

@xmath

###### Corollary 4.2

Let @xmath and @xmath be such that @xmath and @xmath . Denote by @xmath
the corresponding decomposition of a vector @xmath in @xmath or @xmath .
Then @xmath .

Proof. One has @xmath , or equivalently @xmath . The terms @xmath and
@xmath are in @xmath by Proposition 4 , hence if @xmath is in @xmath ,
then so is @xmath .

@xmath

###### Corollary 4.3

One has @xmath , and hence also @xmath .

Proof. Let @xmath be a subspace of @xmath such that @xmath , and define
a @xmath analogously. Because @xmath and @xmath , by Proposition 4.1 it
follows that @xmath . Also, we know that @xmath , and similarly so for
@xmath . Combining these facts gives the result.

@xmath

###### Corollary 4.4

Given @xmath with domain @xmath and range @xmath , let @xmath and @xmath
be any choice of subspaces such that @xmath , @xmath . Then @xmath
induces a symplectic map @xmath such that @xmath .

###### Remark 1

The notation @xmath does not reflect the fact that this map depends on
the choice of @xmath and @xmath .

###### Proposition 4.5

Let @xmath and @xmath be two canonical relations, @xmath and @xmath
their respective domains and ranges, and @xmath and @xmath any subspaces
such that @xmath , @xmath . Let @xmath be the symplectic map induced by
@xmath and these decompositions. A symplectic map @xmath is an
equivalence between @xmath and @xmath if and only if

1.  @xmath and @xmath

2.  @xmath

whereby @xmath is the symplectic map induced by @xmath and the
decompositions @xmath and @xmath .

Proof. Assume i) and ii) hold. We show first @xmath . Let @xmath . We
have @xmath , where @xmath , @xmath and @xmath . Since @xmath , we have
@xmath , analogously @xmath , and @xmath follows from assumption ii):
@xmath , and indeed @xmath follows from @xmath (cf. Corollary 4.2 ). So
all three summands are in @xmath , and hence so is their sum @xmath .
Because @xmath is invertible and symplectic, the converse implication
follows by arguing symmetrically in the opposite direction.

Now assume @xmath is an equivalence between @xmath and @xmath . The
property i) follows via Proposition 4 , and implies that @xmath iff
@xmath and @xmath iff @xmath , and hence we have @xmath iff @xmath .
Property (2) then follows from the set of equivalences @xmath , which
hold for all @xmath .

@xmath

This last proposition breaks our classification problem into two parts.
The property i) above is equivalent to ( 3 ), i.e. the condition

  -- -------- --
     @xmath   
  -- -------- --

and constitutes a necessary step in the classification of linear
canonical relations. For this reason we now investigate the question of
when such a symplectic map @xmath exists between any two given pairs
@xmath and @xmath of coisotropic subspaces.

## 5 Coisotropic Pairs

The results in this section constitute joint work together with Alan
Weinstein which have, in the meantime, been extended to the settings of
presymplectic and Poisson vector spaces (see [ 10 ] ).

We call an ordered pair @xmath of coisotropic subspaces @xmath a
coisotropic pair and say that coisotropic pairs @xmath and @xmath given
in @xmath and @xmath respectively are equivalent if there exists a
linear symplectomorphism @xmath such that @xmath and @xmath . For a
coisotropic pair @xmath in @xmath we allow the general situation where
@xmath and @xmath are not necessarily equal; we will see that @xmath is
fully characterized up to equivalence by the following five numbers

  -- -------- --
     @xmath   
  -- -------- --

which will be called the canonical invariants of @xmath and labeled
@xmath through @xmath in the above order. They are largely independent,
subject only to certain inequalities (see Corollary 5.8 ).

The first four invariants @xmath characterize the subspaces @xmath and
@xmath up to the above equivalence if one drops the condition that
@xmath be symplectic and that @xmath and @xmath be coisotropic, i.e.
these four invariants contain the purely linear algebraic information.
Indeed, using the identities @xmath and @xmath , which hold for any
subspaces @xmath , @xmath , @xmath in @xmath , one can obtain the the
linear algebraic data

  -- -------- -- -----
     @xmath      (4)
  -- -------- -- -----

from these four invariants: @xmath , @xmath , @xmath , and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

It is straightforward to check that his relationship is invertible; one
could thus equivalently use the numbers ( 4 ) as the first four
invariants.

The fifth invariant @xmath is what fixes the symplectic information. One
could equivalently choose @xmath as the fifth invariant, since

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

When @xmath it follows that @xmath , and a total of four invariants
suffice to characterize the coisotropics @xmath and @xmath . They can be
given in a symmetric way as

  -- -------- --
     @xmath   
  -- -------- --

where for any subspace @xmath , rank @xmath . The symmetry of these
invariants implies that @xmath and @xmath are equivalent as coisotropic
pairs in this special case.

Note that because a coisotropic subspace @xmath is uniquely determined
by the isotropic subspace @xmath , and @xmath for any linear
symplectomorphism @xmath , one could equivalently consider isotropic
pairs instead of coisotropic ones. This indeed simplifies some
calculations and proofs; for the present though we treat things from the
coisotropic standpoint.

### 5.1 General classification of coisotropic pairs

Given a coisotropic pair @xmath , we fix the notation @xmath and @xmath
. As announced, the numbers @xmath , @xmath , @xmath , @xmath and @xmath
, which we call the canonical invariants associated to @xmath ,
completely characterize a coisotropic pair up to equivalence.

###### Proposition 5.1

Let @xmath and @xmath be pairs of coisotropic subspaces in @xmath and
@xmath respectively. Then @xmath and @xmath are equivalent if and only
if their associated canonical invariants are equal.

Proof. If @xmath and @xmath are equivalent via some symplectic map
@xmath , it is clear that all the canonical invariants of @xmath and
@xmath coincide.

For the converse, we will show that @xmath can be written as an @xmath
-orthogonal direct sum of five symplectic subspaces

  -- -------- --
     @xmath   
  -- -------- --

where each symplectic piece, except for @xmath , is further decomposed
as a lagrangian pair

  -- -------- --
     @xmath   
  -- -------- --

so that we obtain a decomposition of @xmath into a total of nine
subspaces

  -- -------- -- -----
     @xmath      (5)
  -- -------- -- -----

Moreover, this decomposition will have the following properties:

1.  the dimension of each summand is uniquely determined by the
    canonical invariants of @xmath

2.  @xmath and @xmath are decomposable as

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

One can decompose @xmath in an analogous manner, and hence when @xmath
and @xmath have the same invariants, by property i) the dimensions of
corresponding symplectic pieces in the decompositions of @xmath and
@xmath will match. In this case, for dimension reasons alone there exist
five symplectic maps, one each between corresponding symplectic pieces,
i.e. one from @xmath to @xmath , one from @xmath to @xmath , and so on.
These maps can further be be chosen to respect the respective
decompositions into lagrangian pairs.

Because the five-part decompositions of @xmath and @xmath are
symplectic-orthogonal, the direct sum of these five symplectic maps
defines a symplectic map @xmath which respects all nine summands of the
decompositions of @xmath and @xmath . In particular, by property ii),
@xmath will then also satisfy @xmath and @xmath .

To achieve the decomposition ( 5 ) we will construct a certain
Witt-Artin decomposition of @xmath with respect to @xmath , refined and
adapted to the coisotropic subspaces @xmath and @xmath .

Recall that @xmath and @xmath , and note that

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

We begin by decomposing @xmath into three parts by choosing a subspace
@xmath such that @xmath and a subspace @xmath such that @xmath , giving
a decomposition

  -- -------- --
     @xmath   
  -- -------- --

Analogously we obtain a decomposition

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is such that @xmath , and @xmath such that @xmath . Note
that @xmath and @xmath have zero intersection, since @xmath and @xmath
and @xmath . Similarly, @xmath . In particular we have

  -- -------- --
     @xmath   
  -- -------- --

We now set @xmath . This defines a subspace such that @xmath . Indeed,

  -- -------- --
     @xmath   
  -- -------- --

and @xmath since

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Because @xmath is a complement of @xmath in @xmath , @xmath is
symplectic by Lemma 2.5 , and since @xmath and @xmath are both
isotropic, we conclude that they form a transversal lagrangian pair in
@xmath .

To obtain a Witt-Artin decomposition with respect to @xmath , we choose
a complement @xmath of @xmath in @xmath , i.e. so that

  -- -------- --
     @xmath   
  -- -------- --

Applying Lemma 2.5 again we know that @xmath is symplectic, as is @xmath
, and @xmath decomposes into the @xmath -orthogonal direct sum

  -- -------- --
     @xmath   
  -- -------- --

with @xmath as a lagrangian subspace of the symplectic subspace @xmath .

We refine this decomposition by choosing a lagrangian complement @xmath
of @xmath in @xmath and by defining a decomposition in @xmath using the
decomposition @xmath as follows. Any basis of @xmath is mapped under
@xmath to a basis of @xmath , whose dual basis in @xmath is conjugate to
, i.e. together and form a symplectic basis of @xmath . If we consider a
basis which is adapted to the decomposition in @xmath , then this
partitioning induces a partitioning of which defines subspaces @xmath ,
@xmath and @xmath in @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and @xmath , @xmath and @xmath are @xmath -orthogonal symplectic
subspaces, comprised each of a lagrangian pair, giving

  -- -------- --
     @xmath   
  -- -------- --

In total we thus obtain a decomposition

  -- -------- --
     @xmath   
  -- -------- --

where parentheses enclose transversal lagrangian pairs in a symplectic
subspace. This decomposition is visualized in Figure 2 - the full circle
represents @xmath , each piece is a direct summand, and lagrangian pairs
are aligned symmetrically with respect to the horizontal axis and shaded
with colors of a similar hue.

[]

Figure 2

The coisotropics @xmath and @xmath are related to the decomposition in
@xmath in that @xmath and @xmath . To see this it suffices to show that
their @xmath -orthogonal complements are equal. For the case of @xmath
(the case for @xmath is analogous) one has

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where we use in the last step that @xmath is @xmath -orthogonal to
@xmath , @xmath , @xmath and @xmath and that the dimensions match.

It can now be quickly checked that our decomposition of @xmath satisfies
property ii), i.e. that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

We show this for @xmath , the decomposition of @xmath follows in the
same way. The inclusion “ @xmath ” is obvious since all the spaces on
the right-hand side are subsets of @xmath . The opposite inclusion “
@xmath ” can be argued using dimensions:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the last equality follows from the fact that

  -- -------- --
     @xmath   
  -- -------- --

since @xmath , @xmath , and @xmath (each pair of subspaces is a
lagrangian pair in @xmath , @xmath and @xmath respectively).

The decompositions of @xmath and @xmath are visualized below.

[]
Figure 3 []
Figure 4

Figure 3 is a recoloring of Figure 2, and Figure 4 gives an intuitive
representation of @xmath and @xmath intersecting, where @xmath is given
by the entire rectangle. This is not a proper Venn diagram in the
set-theoretic sense, though certain intersections are represented
properly, namely @xmath , @xmath and @xmath .

It remains now only to check that the property i) is fulfilled, i.e.
that the dimensions of the nine summands in our decomposition are
uniquely determined by the canonical invariants associated to the pair
@xmath . Since any lagrangian subspace of a symplectic subspace has half
the dimension of the space within which it is lagrangian, it suffices to
show for example that the dimensions of the subspaces @xmath , @xmath ,
@xmath , @xmath and @xmath are uniquely determined.

First,

  -- -------- --
     @xmath   
  -- -------- --

and the relationships

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

show that @xmath and @xmath are determined.

Because @xmath and @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Lastly, @xmath and @xmath , so

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

which proves the property i) and concludes the proof.

@xmath

### 5.2 Elementary types and normal forms

The key to Proposition 5.1 was the decomposition ( 5 ), satisfying the
properties i) and ii). One may rephrase the construction as follows. We
found an @xmath -orthogonal decomposition

  -- -------- --
     @xmath   
  -- -------- --

into five symplectic subspaces, such that

a) the dimensions of these subspaces are uniquely determined by the
canonical invariants associated to the coisotropic pair @xmath , and

b) @xmath and @xmath decompose into direct sums

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath and @xmath for @xmath .

In other words, we can set @xmath , @xmath , @xmath , etc., and relabel
the decompositions

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

by setting as @xmath as the sum of those summands which lie in @xmath ,
i.e. @xmath , @xmath , @xmath , @xmath , @xmath , and analogously so for
@xmath .

Note that for each @xmath the subspaces @xmath and @xmath form a
coisotropic pair in @xmath of a particularly simple form, each member of
the pair being either the entire subspace @xmath or a lagrangian
subspace therein. Indeed, @xmath are the same lagrangian subspace of
@xmath , @xmath and @xmath form a lagrangian pair in @xmath , @xmath ,
@xmath is a lagrangian subspace of @xmath , and finally @xmath and
@xmath is lagrangian in this space. We introduce notation for these
particularly simple cases of coisotropic pairs.

###### Definition 5.2

A coisotropic pair @xmath in a symplectic space @xmath is of elementary
type if it is one of the following types:

 @xmath  :  

    @xmath and @xmath are lagrangian subspaces, and @xmath

 @xmath  :  

    @xmath and @xmath are lagrangian subspaces, and @xmath

 @xmath  :  

    @xmath , i.e. @xmath and @xmath are symplectic

 @xmath  :  

    @xmath and @xmath is a lagrangian subspace

 @xmath  :  

    @xmath and @xmath is a lagrangian subspace

We will consider these types ordered as listed and also call them @xmath
through @xmath .

The cases when a coisotropic subspace @xmath is the entire space or is
lagrangian are the two extreme cases of a coisotropic subspace in the
sense that they correspond respectively to when @xmath or when @xmath is
as large as possible, i.e. @xmath . The basic types listed above cover
all the scenarios when two coisotropics @xmath and @xmath are given by
either of these two extremes, except for the possible scenario when
@xmath and @xmath are two non-identical lagrangians with non-zero
intersection. This case, though, can be split into a “direct sum” of the
cases @xmath and @xmath , i.e. it is not “elementary” as a type of
coisotropic pair. To see this, assume that @xmath and @xmath are such,
and let @xmath and @xmath be complements of @xmath in @xmath and @xmath
respectively (in particular @xmath ). Set @xmath and note that @xmath
because @xmath and @xmath are lagrangian. The subspace @xmath is such
that @xmath , hence by Lemma 2.5 it is symplectic and

  -- -------- --
     @xmath   
  -- -------- --

with @xmath as a lagrangian subspace of @xmath . With respect to this
decomposition of @xmath , the coisotropics @xmath and @xmath decompose
as @xmath and @xmath , where @xmath and @xmath are a lagrangian pair in
@xmath , i.e. a coisotropic pair of type @xmath , whereas @xmath , seen
as the component of both @xmath and @xmath in @xmath , represents a
coisotropic pair in @xmath of the type @xmath .

In the following we make more precise the sense in which a coisotropic
pair is the direct sum of smaller coisotropic pairs and in which way the
elementary types defined above are indeed elementary.

###### Definition 5.3

Given an @xmath -orthogonal decomposition of @xmath into a finite number
@xmath of symplectic subspaces

  -- -------- --
     @xmath   
  -- -------- --

and given subspaces @xmath , @xmath forming a coiostropic pair in @xmath
for each @xmath , we say that @xmath is the direct sum of the
coisotropic pairs @xmath if

  -- -------- --
     @xmath   
  -- -------- --

Such a direct sum decomposition will be denoted

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 5.4

A coisotropic pair @xmath in @xmath is called elementary if there exists
no such direct sum decomposition of @xmath except as a direct sum of
coisotropic pairs of only one of the elementary types @xmath , @xmath ,
@xmath , @xmath or @xmath .

###### Proposition 5.5

The elementary types @xmath , @xmath , @xmath , @xmath and @xmath are
elementary according to the above definition.

Proof. Assume that @xmath is a coisotropic pair of some elementary type

  -- -------- --
     @xmath   
  -- -------- --

and that

  -- -------- --
     @xmath   
  -- -------- --

is a direct sum decomposition into coisotropics, subordinate to an
@xmath -orthogonal decomposition @xmath into symplectic subspaces, i.e.
such that @xmath and @xmath for each @xmath . We need to show that each
coistropic pair @xmath in @xmath is of type @xmath . Because @xmath is
an elementary type, @xmath is either equal to @xmath or is lagrangian in
@xmath . If @xmath , then @xmath for dimension reasons. If @xmath is
lagrangian, it is in particular isotropic, and hence each @xmath is
isotropic in @xmath because @xmath . Because @xmath , we have @xmath on
@xmath , so @xmath is also isotropic in @xmath . Since @xmath is assumed
coisotropic in @xmath , it follows that @xmath is lagrangian in @xmath .
By the same arguments, if @xmath then @xmath , or if @xmath is
lagrangian in @xmath then @xmath is lagrangian in @xmath . It is now
clear that if @xmath , then @xmath for all @xmath , so the summand pairs
@xmath are all also of type @xmath . If @xmath , then all the @xmath and
@xmath are lagrangian subspaces in their respective @xmath , and @xmath
implies that @xmath for all @xmath , so each pair @xmath is also of type
@xmath . If @xmath , then similarly the @xmath and @xmath are lagrangian
in @xmath . To see that here @xmath , consider @xmath , which has a
unique decomposition @xmath with @xmath for each @xmath . Because @xmath
and @xmath , @xmath also has such unique decompositions with respect to
@xmath and @xmath , but because @xmath for each @xmath , these
decompositions must coincide with the above decomposition. Hence @xmath
for each @xmath . In particular @xmath , which, for dimension reasons,
implies @xmath for all @xmath . So each pair @xmath is indeed of type
@xmath when @xmath is. Now assume @xmath . For each @xmath , @xmath is
lagrangian in @xmath and @xmath , so @xmath is also of type @xmath . The
case for @xmath is the same, but with the roles of @xmath and @xmath
reversed.

@xmath

###### Corollary 5.6

If a coisotropic pair @xmath has a direct sum decomposition

  -- -------- --
     @xmath   
  -- -------- --

where every coisotropic pair @xmath is of the same elementary type, then
@xmath is elementary and of that type.

Proof. It suffices to show that @xmath is of the same type as its
summands, since by Proposition 5.5 it is then elementary. If the
elementary type of the summands is such that the @xmath are all
lagrangian subspaces of the @xmath , then the @xmath are isotropic
subspaces of @xmath and hence their @xmath -orthogonal sum @xmath will
also be isotropic. Since each @xmath has half the dimension of @xmath ,
@xmath will have half the dimension of @xmath , i.e. it is lagrangian.
If on the other hand the elementary type in question is such that @xmath
for each @xmath , then clearly @xmath . The same arguments apply to
@xmath . Thus the coisotropic pair @xmath is such that @xmath and @xmath
are each either lagrangian or all of @xmath in the same way that their
summands @xmath and @xmath are. It remains only to be sure that when
@xmath and @xmath are both lagrangian, they are either identical or such
that @xmath , according to whether @xmath or @xmath . If @xmath then
clearly @xmath . Assume @xmath and let @xmath . We have a unique
decomposition @xmath with @xmath for all @xmath , and because @xmath and
@xmath are direct sum decompositions subordinate to @xmath , each @xmath
lies in @xmath . Hence @xmath , and we conclude that @xmath when @xmath
.

@xmath

Proposition 5.5 guarantees that the five elementary types of coisotropic
pairs are independent of one another in the sense that one cannot
express any one of them as a sum of the others. The proof of Proposition
5.1 showed that these basic types are also “generating” in the sense
that any coisotropic pair decomposes into a direct sum of such
elementary types. The corollary implies that one can simplify any direct
sum decomposition of a coisotropic pair so that it has only five
summands, these summands being of one each of the elementary types. We
will call any such five part decomposition an elementary decomposition .
The following shows that elementary decompositions give a set of
invariants for a coisotropic pair @xmath which are equivalent to the
original invariants we associated to such a pair.

###### Proposition 5.7

Let @xmath be a coisotropic pair in @xmath and let

  -- -------- --
     @xmath   
  -- -------- --

be an elementary decomposition subordinate to an @xmath -orthogonal
decomposition

  -- -------- --
     @xmath   
  -- -------- --

ordered such that @xmath is of type @xmath . Set @xmath . Then the
5-tuple

  -- -------- --
     @xmath   
  -- -------- --

gives a set of invariants (call them elementary invariants ) which are
equivalent to the canonical invariants

  -- -------- --
     @xmath   
  -- -------- --

Proof. Consider @xmath as a coordinate in the space @xmath of all
possible 5-tuples of elementary invariants (each @xmath is symplectic,
hence of even dimension), and let @xmath denote the space of all
possible sets of canonical invariants @xmath .

Fix a coisotropic pair @xmath and fix also an elementary decomposition
of this pair, with @xmath and @xmath . This gives a 5-tuple . From this
we can obtain the canonical invariants associated to @xmath as follows.

Clearly one has

  -- -------- --
     @xmath   
  -- -------- --

For the remaining invariants, we claim that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

To see this, we show

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

which gives the above formulae for @xmath and @xmath directly.

For any @xmath we have the decomposition @xmath with @xmath , and for
@xmath also in @xmath

  -- -------- -- -----
     @xmath      (6)
  -- -------- -- -----

because @xmath and @xmath are lagrangian in their respective @xmath . If
@xmath is in @xmath , then choosing @xmath as any element in @xmath we
find @xmath and hence @xmath , since @xmath is symplectic in @xmath .
Similarly one finds @xmath , so @xmath , which shows @xmath . The
opposite inclusion @xmath follows from ( 6 ) as well, since for @xmath
and any @xmath we find @xmath . Arguing analogously one also shows
@xmath .

For the equalities @xmath and @xmath we use the fact that if @xmath is
in @xmath or @xmath , then in particular @xmath is in @xmath and hence
has a unique decomposition @xmath with @xmath .

If @xmath , then @xmath implies @xmath . Also, @xmath . Thus @xmath and
@xmath holds. On the other hand, because @xmath and @xmath , we have
@xmath .

If @xmath , then not only are @xmath and @xmath zero because @xmath ,
but also @xmath , because @xmath does not contain non-zero summands in
@xmath . Thus @xmath . The opposite in inclusion holds since @xmath is a
summand in the decompositions of both @xmath and @xmath .

The equations above describing the @xmath in terms of the @xmath define
a linear map @xmath , representable by matrix multiplication with the
matrix

  -- -------- --
     @xmath   
  -- -------- --

which is non-singular ( @xmath ). Hence @xmath defines an injective map,
which means in particular that the numbers @xmath which we associate to
an elementary decomposition of a coisotropic pair @xmath do not depend
on the particular elementary decomposition but only depend on the pair
@xmath . In other words, does in fact define a set of invariants for
@xmath . The map @xmath is also surjective. Any @xmath is, by
definition, realizable by some coiostropic pair @xmath and by the proof
of Propostion 5.1 this pair has an elementary decomposition; by the
above, the invariants associated to this decomposition are mapped under
@xmath to .

@xmath

To compute the elementary invariants from the canonical invariants one
can simply use the inverse of the mapping @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which gives the linear equations for the @xmath in terms of the @xmath :

  -- -------- -------- -- ------
     @xmath   @xmath      (7)
     @xmath   @xmath      (8)
     @xmath   @xmath      (9)
     @xmath   @xmath      (10)
     @xmath   @xmath      (11)
  -- -------- -------- -- ------

Note that we already nearly explicitly computed these equations in the
proof of Proposition 5.1 .

###### Corollary 5.8

The canonical invariants @xmath are subject only to the five
inequalities

  -- -------- --
     @xmath   
  -- -------- --

Proof. That the @xmath must satisfy these inequalities follows from the
linear equations ( 7 ) though ( 11 ) for the @xmath in terms of the
@xmath and the fact that @xmath . The equation for @xmath implies @xmath
, the equation for @xmath gives @xmath , the one for @xmath gives @xmath
, and the inequalities @xmath and @xmath follow from the equations for
@xmath and @xmath .

To see that these inequalities are the only constraints on the @xmath ,
let @xmath be an arbitrary 5-tuple of integers subject only to the above
inequalities. We need to show that is in @xmath , the set of canonical
invariants realizable by a coisotropic pair, which is the image of
@xmath . In other words we must find a 5-tuple of non-negative integers
@xmath such that @xmath , i.e. which solve the linear equations

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

For @xmath we choose @xmath and for @xmath we can always choose @xmath
such that @xmath . Next, because @xmath , we can choose @xmath such that
@xmath . Thus far @xmath and @xmath are fixed and the equations for
@xmath and @xmath solved. For @xmath we have @xmath , so @xmath can be
chosen such that @xmath . Finally, for @xmath , an integer @xmath is
still free to be chosen such that @xmath as desired.

@xmath

Using the elementary invariants one can easily construct a normal form
@xmath for a coisotropic pair @xmath , a standardized representative of
the equivalence class of @xmath . Let @xmath be the elementary
invariants of @xmath . We choose @xmath as our model space, equip each
summand with the standard symplectic form @xmath represented by the
@xmath matrix

  -- -------- --
     @xmath   
  -- -------- --

and give the whole space the direct sum symplectic form @xmath . Let

  -- -------- --
     @xmath   
  -- -------- --

denote the standard coordinates on @xmath and denote

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

defines a normal form for @xmath . By construction @xmath is a
coisotropic pair such that the elementary invariants of @xmath and
@xmath match. Indeed the very definition of @xmath gives an elementary
decomposition with appropriate dimensions: @xmath is a coisotropic pair
of elementary type @xmath in @xmath , @xmath a pair of type @xmath in
@xmath , and so on. From Proposition 5.7 we know that the canonical
invariants of @xmath and @xmath match because their elementary
invariants do, and by Proposition 5.1 this means that @xmath .

## 6 Classification of Linear Canonical Relations

### 6.1 Reduced classification problem

Let @xmath and @xmath denote once again canonical relations, and @xmath
and @xmath the coisotropic pairs giving their respective ranges and
domains. We have seen that for @xmath and @xmath to be equivalent it is
necessary that @xmath and @xmath be equivalent as coisostropic pairs.
Assume now that this is the case, and let @xmath be a symplectic map
such that @xmath and @xmath . Furthermore let

  -- -------- --
     @xmath   
  -- -------- --

be elementary decompositions such that @xmath and @xmath for each @xmath
. This situation can be assumed without loss of generality, since the
image under @xmath of the decomposition of @xmath defines an elementary
decomposition of @xmath , and this decomposition can in turn can be
mapped into any other elementary decomposition of @xmath by a symplectic
map which respects the decompositions.

The elementary decomposition of @xmath (and similarly so for @xmath ) is
subordinate to a decomposition of @xmath of the form

  -- -------- --
     @xmath   
  -- -------- --

i.e. @xmath and @xmath decompose as

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and we will use the lettered names and indexed names of subspaces
interchangeably. Set @xmath and @xmath , i.e. @xmath and @xmath are
symplectic subspaces such that @xmath and @xmath . Recall that @xmath
and @xmath . From Proposition 4.1 we know that @xmath and @xmath induce
symplectic maps @xmath and @xmath , and that by Proposition 4.5 , @xmath
if and only if

  -- -------- -- ------
     @xmath      (12)
  -- -------- -- ------

This is equivalent to asking that the diagram

  -- -------- --
     @xmath   
  -- -------- --

commute. Thus when @xmath and @xmath have matching coisotropic pair
invariants, the classification problem reduces to the question of when a
map @xmath satisfying this condition exists.

We consider first two special cases. If @xmath , then ( 12 ) is
equivalent to commutativity of the simpler diagram

  -- -------- --
     @xmath   
  -- -------- --

Because the invariants of @xmath and @xmath match, we can construct an
equivalence @xmath (in the sense of coisotropic pairs) by freely
choosing symplectic maps @xmath through @xmath between the symplectic
pieces of the decomposition

  -- -------- --
     @xmath   
  -- -------- --

and their corresponding counterparts in the decomposition of @xmath ,
and then taking @xmath as the direct sum of these maps. In particular,
in the present case @xmath and for any choice of symplectic map @xmath
one may choose @xmath as the symplectic map

  -- -------- --
     @xmath   
  -- -------- --

resulting in a map @xmath which both respects the decompositions in
@xmath and @xmath and satisfies the condition ( 12 ).

The second special case is when @xmath . Here the condition ( 12 )
amounts to the condition that @xmath and @xmath are conjugate via a
symplectic map, i.e. there exists a symplectic map @xmath such that the
diagram

  -- -------- --
     @xmath   
  -- -------- --

commutes. In other words, @xmath and @xmath are equivalent here when
@xmath and @xmath , seen as canonical relations in @xmath and @xmath
respectively, are equivalent. Thus the classification here is reduced to
the symplectic map case.

For the remainder of this section we now consider the remaining case,
i.e. we assume that @xmath , @xmath (and @xmath ) are all non-zero. This
case is at the present moment yet unresolved. We reformulate the problem
in coordinates to show what the problem looks like in terms of matrices.
Let @xmath denote the dimension of @xmath and @xmath the dimension of
@xmath and @xmath . Let @xmath be a basis of @xmath and @xmath be the
corresponding coordinate chart which maps the @xmath -th canonical basis
vector to @xmath . Similarly let @xmath and @xmath denote bases of
@xmath and @xmath , with corresponding charts @xmath and @xmath . The
condition ( 12 ) is equivalent to asking that the diagram

  -- -- --
        
  -- -- --

commute (the brackets surrounding the maps on the outer rectangle are
used to denote the coordinate matrices with respect to the given bases).
In other words, finding the maps @xmath , @xmath and @xmath as required
by ( 12 ) is equivalent to finding bases @xmath , @xmath and @xmath and
block diagonal matrices @xmath and @xmath such that @xmath , @xmath ,
and @xmath are symplectic and

  -- -------- -- ------
     @xmath      (13)
  -- -------- -- ------

If one writes @xmath and @xmath as a block matrices

  -- -------- --
     @xmath   
  -- -------- --

then the commutation condition ( 13 ) reads as

  -- -------- -- ------
     @xmath      (14)
  -- -------- -- ------

which gives four matrix equations. A complication here is the fact that,
although @xmath represents a symplectic map, the blocks @xmath
themselves do not (and similarly for @xmath ). For the problem of
finding the equivalence classes of matrices up to the relation ( 14 ),
the following are possible strategies:

1.  put @xmath first into a normal form for symplectic matrices, and
    then apply the condition ( 14 )

2.  find a normal form for the condition ( 14 ) without any symplectic
    assumptions, and then apply symplectic constraints as a second step

In the case of either i) or ii), an apparent issue is the following. The
normal form given by Gutt [ 7 ] , for example, arises from a
decomposition of a symplectic map into a direct sum of symplectic maps
on generalized eigenspaces. This decomposition need not “respect” the
splitting @xmath , and thus one is faced again with the problem of how
one of the normal form blocks “intertwines” the spaces @xmath , @xmath
and @xmath . Furthermore it is a priori unclear which of the normal form
blocks leave @xmath invariant and map @xmath to @xmath (and hence are
unaffected by the condition ( 14 )) and which do not. Because the
literature on normal forms for symplectic matrices is diverse, it is
possible that a different normal form than the one given by Gutt in [ 7
] would be more amenable to the condition ( 14 ). The study of other
normal form structures would thus be one natural step in the further
study of this problem.

Besides the approach of considering the problem in coordinate matrices,
one might obtain a simplification of the of the classification
associated to ( 12 ) by first considering invariants of this subproblem
which are built from the dimensions and ranks of the subspaces given by
the intersections of @xmath and @xmath with @xmath and @xmath .
Additionally, a computation of the decomposition of @xmath as a direct
sum of Towber’s basic types of linear relations might give insight into
the structure of the induced relation @xmath . These steps, yet
incomplete, are at present omitted from this exposition.

### 6.2 Normal forms

We present one possible way of representing a linear canonical relation
which reflects its decomposition into linear canonical relations of
simpler types, and is also amenable to the yet to be completed full
classification. As a subspace in @xmath , any linear canonical relation
@xmath is specified by a basis for this subspace, which in split
coordinates can be written as

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath for each @xmath . These pairs can be arranged
vertically as the columns of a matrix having @xmath rows and @xmath
columns, ordered to reflect the decompositions of the coisotropic
subspaces which are the domain and range of @xmath . Clearly, for any
element of @xmath one has @xmath , and for @xmath holds @xmath . Because
@xmath and @xmath decompose as

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

we can represent @xmath in matrix form as

  -- -------- --
     @xmath   
  -- -------- --

where each letter stands in for a basis of the subspace it denotes.
Recall that in the decomposition

  -- -------- --
     @xmath   
  -- -------- --

@xmath is lagrangian subspace, and @xmath form a transverse lagrangian
pair in @xmath . One sees that the block columns corresponding to @xmath
in the representation of @xmath above represent a linear canonical
relation @xmath in @xmath given by the block matrix

  -- -------- --
     @xmath   
  -- -------- --

and similarly the columns corresponding to @xmath and @xmath represent a
linear canonical relation @xmath

  -- -------- --
     @xmath   
  -- -------- --

in @xmath . Setting @xmath we thus have a decomposition

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the linear canonical relation with ker @xmath , hal
@xmath and with induced symplectic map @xmath which coincides with
@xmath . In terms of the matrix representation of @xmath we write

  -- -------- --
     @xmath   
  -- -------- --

Finally, using the notation from the classification and normal forms for
coisotropic pairs one can choose as a canonical normal form the “block
matrix” given by

  -- -------- --
     @xmath   
  -- -------- --

where one is implicitly assuming the use of the canonical bases in the
spaces @xmath , @xmath , etc., and @xmath denotes here a yet to be
determined general normal form for @xmath .