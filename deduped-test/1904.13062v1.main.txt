##### Contents

-    Abstract
-    1 Introduction
    -    1.1 Main results
        -    1.1.1 Measure estimate I
        -    1.1.2 Measure estimate II
        -    1.1.3 Measure estimate III
    -    1.2 Notations and set up
    -    1.3 General remarks
-    I Classical KAM Theorems and Quantitative normal forms
    -    2 Quantitative KAM normal forms
        -    2.1 Statement of the explicit KAM normal forms theorems
            -    2.1.1 Kolmogorov’s normal form
            -    2.1.2 KAM Theorem après Arnold
            -    2.1.3 KAM Theorem après J. Moser (following J. Pöschel)
            -    2.1.4 KAM Theorem après Salamon–Zehnder
        -    2.2 Some preliminary facts
        -    2.3 Proofs
            -    2.3.1 Proof of Theorem 2.1.1
            -    2.3.2 Proof of Theorem 2.1.2
            -    2.3.3 Proof of Theorem 2.1.4
    -    3 Comparison of the KAM theorems on a mechanical Hamiltonian
        -    3.1 Application of Theorem 2.1.1
        -    3.2 Application of Theorem 2.1.2
        -    3.3 Application of Theorem 2.1.4
        -    3.4 Application of Theorem 2.1.6
    -    4 Global symplectic extension of Arnold’s theorem
        -    4.1 Assumptions
        -    4.2 Statement of the extension Theorem
        -    4.3 Proof of Theorem 4.2.1
    -    5 A “sharp” version of Arnold’s theorem
        -    5.1 Assumptions
        -    5.2 Statement of the KAM Theorem
        -    5.3 Proof of Theorem 5.2.1
-    II “Sharp” measure estimates of Kolmogorov’s sets
    -    6 “Explicit” integrability on a Cantor–like set and a “sharp”
        measure estimate
        -    6.1 Assumptions
        -    6.2 Statement of the extension Theorem
        -    6.3 Proof of Theorem 6.2.1
        -    6.4 Sharp measure estimate of the complement of @xmath in
            an arbitrary set
            -    6.4.1 Local analysis: the case where @xmath is a cube
            -    6.4.2 Global analysis
    -    Appendices
        -    A On the initial order of truncation @xmath of the Fourier
            series in Theorem 2.1.4
        -    B Smooth contraction mapping Lemma
        -    C Extension of Lipschitz–Hölder continuous functions with
            control on the sup–norm
        -    D Lebesgue measure and Lipschitz continuous map
        -    E Whitney’s smoothness
        -    F Generalized Steiner’s formula
        -    G Some others facts on Lipschitz continuous functions

### Acknowledgements

I would like to express my deep gratitude to Prof. Luigi Chierchia for
introducing to the absolutely fascinating field of KAM theory , for his
guidance, availability, patience, support which goes much much beyond
mathematics and this thesis, and his precious help all along the trip
leading to the accomplishment of this thesis.

I would like aslo to express my sincere gratitude to Prof. Francesco
Pappalardi for his inestimable support. I am in Roma thanks to him
mainly and without him I would not have the chance to meet Prof. Luigi
and this thesis would not be possible simply.

I am very grateful to Prof. Luca Biasco and Prof. Michela Procesi for
their availability, kindness, the very helpful discussions i had with
them.

I am also deeply grateful to Prof. Antonio Siconolfi, with whom I spent
almost the half of the three years of my PhD, for his help, generosity,
patience and precious advises. I could have completed my PhD with him,
but at some some point, due to time constrained, I had to choose and
focus on a single subject.

I would like to address a special thanks to Prof. Wilfrid Gangbo whose
impact on my career is considerable and this, since 2015 that I met him.
It was through him I met Prof. Siconolfi.

I would like to address my sincere gratitude to Prof. Théophile Olory
for his precious advises and assistance.

I am very grateful to Prof. Bernadin Kpamingan for his help all those
years along.

I would like to express my gratitude to Prof. Rafael De La Llave for his
interest in my work, for offering the opportunity to attend a workshop
and for drawing my attention on some related papers in the literature.

I would like to express my gratitude to Prof. Jean–Pierre Marco and
Prof. Tere M–Seara for their interest in my thesis and their
availability to help.

I am also very grateful to Prof. Stefano Luzzatto and Prof. Carlangelo
Liverani for their support and precious time.

A big big thanks to my mom, my sisters and brothers, especially Zizi,
Igor, Marcelin, Adèle, Jeannette, Justine, Eulalie, …, for their
permanent support.

Finally, I want to thank my queen Cica and my princess Merquela, for
their patience and constant encouragement, I am infinitely grateful to
you.

This list is of course far from being exhaustive and detailed; I tried
to be as short as possible. Otherwise, I would somehow fall into writing
my biography and here is certainly not the place for!!!!

To the memory of my father

#### Notational conventions

-   @xmath denotes the Neper’s number i.e. @xmath

-   @xmath and @xmath

-   @xmath and @xmath are respectively the set of real and complex
    numbers

-   @xmath and @xmath , for any @xmath

-   @xmath for any @xmath

-   @xmath and @xmath

-   @xmath

-   @xmath denotes the distance function

-   @xmath denotes the closure of @xmath

-   @xmath denotes the “boundary” of @xmath

-   @xmath denotes the convex–hall of @xmath

-   @xmath ( resp. @xmath ) denote respectively the set of functions of
    class @xmath ( resp. @xmath with compact supports) from @xmath into
    @xmath

-   @xmath denotes the @xmath –dimensional Lebesgue–measure

-   @xmath denotes the domain of @xmath

-   @xmath denotes the support of @xmath

-   @xmath ( resp. @xmath ) denotes the ball centered at p with radius
    @xmath in @xmath ( resp. in @xmath )

-   @xmath ( resp. @xmath ) denotes the r–neighborhood of @xmath in
    @xmath ( resp. in @xmath )

-   @xmath denotes the set of @xmath –Diophantine vectors

-   @xmath denotes the strip of width @xmath around @xmath in @xmath

-   @xmath denotes the average of @xmath on @xmath

-   @xmath denotes derivative of order @xmath of @xmath

-   @xmath denotes the set of isomorphisms from @xmath onto itself

-   @xmath the set of @xmath –by– @xmath matrices with entries in @xmath
    and @xmath the set of symmetric square matrices of order @xmath

-   @xmath denotes the adjoint of @xmath

-   @xmath denotes the determinant of @xmath

-   @xmath denotes the transposed of @xmath

-   @xmath and @xmath are respectively the normal and tangent bundle of
    the manifold @xmath

-   @xmath denotes the space of smooth vector field on @xmath

-   @xmath denotes the space of smooth functions on @xmath

-   @xmath denotes the minimal focal distance of the manifold @xmath

### Chapter 1 Introduction

In the solar system framework, Celestical Mechanics, a branch of
astronomy, consists ultimately in the study of the @xmath –body problem.
The @xmath –body problem is the dynamical system that governs the motion
of @xmath planets interacting according to Newton’s gravitation law. A
holy–grail question in Celestical Mechanics was and remains the
stability of the solar system, i.e. whether the current configuration of
the planets will stay unchanged forever under their interaction, or
whether some planets will be kicked out of the system or have their
trajectories be drastically affected to eventually collapse and give
rise to unpredictable behaviors. Across the history of Mathematics, most
of the great figures devoted some part of their works to this question.
Laplace (1773), Lagrange (1776), Poisson (1809), and Dirichlet (1858)
used series expansion techniques to study the question of stability of
the solar system and claimed all to have proved it. Then Bruns (1887)
proved that, from quantitative point of view, the only method which
could solve the @xmath –body problem is the series expansions. But, the
works of Haretu (1878) and Poincaré (1892) (see [ Poi99 ] ) show that
all those series expansion techniques fail as the series expansions they
use diverge (see [ Dug57 , Mou02 , Mos73 , Dum14 , AMM78 ] for more
historical details).
A new viewpoint is thus undeniably needed to overcome this embarrassing
fact. The change of paradigm was made by Poincaré. Indeed, Poincaré
introduced a completely revolutionary qualitative approach to Mechanics
(see [ Poi90 , Poi99 ] ). The point is that, for question such as
stability, one needs to study the entire phase portrait, and in
particular the asymptotic time behavior of the solutions.
The phase portrait is the family of solutions curves, which fill up the
entire phase space. The phase space is a symplectic manifold (a
differentiable manifold together with a symplectic structure). Dynamical
system is then just given by a Hamiltonian vector field; this is the
Mathematical model for the global study in Mechanics that Poincaré gave
in his qualitative theory. With his new geometrical methods, Poincaré
discovered the non-integrability of the three body problem. In fact, the
small divisor problem was well–known to Poincaré, who was aware that,
because of this problem, nearly–integrable Hamiltonian systems are, in
general, not integrable (analytically). Poincaré and his successors then
speculate that most of the classical systems were chaotic, and ergodic.
There were even a gaped proof of the ergocity of a generic Hamiltonian
system by E. Fermi in the 1920’ (see [ Fer23a , Fer23b , Fer23c , Fer24
] ). This ergodic hypothesis was accepted by many, including some of the
brightest mind of those times, till the discoveries by Kolmogorov and
his followers.
At the 1954 International Congress of Mathematician in Amsterdam,
against any expectation, Kolmogorov (see [ Kol54a , Kol54b ] ) presented
a four–pages note where he sketched the proof of the persistence of the
majority of tori for a nearly–integrable Hamiltonian system. Then, his
former student Arnol’d (see [ Arn63a , Arn63c ] ) completed the proof in
the analytic category, and Moser (see [ Mos62 , Mos66b , Mos66a ] ) in
the smooth category, whence the acronym KAM Theory.
The object of KAM Theory is the construction of quasiperiodic
trajectories, which are sets of perpetual stability, in Hamiltonian
dynamics. A KAM scheme is essentially based on the Newcomb idea of
successive constructions of change of variable through a Newton–like
method. Those successive changes of variables are carried out to
eliminate, in a super–exponentianlly increasing manner, the fast phase
variables. A KAM scheme of course encounters the small divisor problem
that Poincaré faced. Netherless, the super–exponentianlly decay make the
whole scheme converge.
Formally, one is given a symplectic manifold @xmath , a (smooth)
Hamiltonian @xmath . To the Hamiltonian @xmath , is associated a
(unique!) smooth vector field, the Hamiltonian vector field, say @xmath
, given by the equation

  -- -------- --
     @xmath   
  -- -------- --

The smooth vector field @xmath then generates a flow, say @xmath , by
the relation

  -- -------- -- ---------
     @xmath      (1.0.1)
  -- -------- -- ---------

In particular, if @xmath and @xmath , then @xmath and, therefore, the
equation ( 1.0.1 ) reads

  -- -------- -- ---------
     @xmath      (1.0.2)
  -- -------- -- ---------

Then, to construct quasi–periodic trajectories for the Hamiltonian
system ( 1.0.1 ), one looks for a change of variable @xmath , with the
following properties

-   @xmath preserves the Hamiltonian structure of ( 1.0.1 ). More
    precisely, @xmath preserves the symplectic form i.e. @xmath ;

-   @xmath conjugates @xmath to a linear flow:

      -- -------- -- ---------
         @xmath      (1.0.3)
      -- -------- -- ---------

However, one does not solve directly ( 1.0.3 ). Instead, one conjugates
the Hamiltonian itself i.e. construct @xmath in such away that

  -- -------- -- ---------
     @xmath      (1.0.4)
  -- -------- -- ---------

as the latter is much easier to carry out than the former. Once ( 1.0.4
) holds, by the property @xmath , ( 1.0.3 ) follows (see for instance [
MZ05 ] for details).
The numerical property of the frequency or winding number @xmath plays a
crucial role in the construction of the invariant tori. The most common
assumption is the Diophantine property. A vector @xmath is said @xmath
–Diophantine if

  -- -------- -- ---------
     @xmath      (1.0.5)
  -- -------- -- ---------

where @xmath .
Facts Let

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

be the set of all @xmath –Diophantine vectors. Thus

-   If @xmath , then @xmath (see [ Cas57 ] );

-   If @xmath , then the set @xmath has zero Lebesgue–measure, but is of
    Hausdorff dimension @xmath . In particular, the intersection of
    @xmath with any open set has the cardinality of @xmath (see [ Sch66
    , Sch69 ] );

-   If @xmath , then the Lebesgue–measure of @xmath is zero. In fact,

      -- -------- -- ---------
         @xmath      (1.0.6)
      -- -------- -- ---------

As soon as the existence of invariant tori is established, one can speak
of Kolmogorov sets, which turn out to be very big. A Kolmogorov set
associated to a Hamiltonian @xmath is an union of its invariant maximal
KAM tori. A maximal KAM torus for @xmath is an embedded, Lagrangian,
Kronecker torus with Diophantine frequency @xmath . A Kronecker torus
with frequency @xmath is an embedded torus on which the @xmath –flow is
conjugated to the linear flow

  -- -------- --
     @xmath   
  -- -------- --

In this thesis, we are mainly concerned with “sharp” measure estimates
of Kolmogorov sets, with emphasize on the dependence of those measure
estimates upon the geometry of the domain .

Moser introduced in [ Mos67 ] the original idea of parametrizing a
non–degenerate quasi–integrable Hamiltonian by the frequency vectors and
then apply the KAM technics (see also [ Pös01 , Pös82 ] ). In [ Pös01 ]
, the author made a short discussion of the measure of the complement of
Kolmogorov set. Then, very recently, Biasco and Chierchia [ BC18 ] ,
give a detailed proof of the measure estimate result in [ Pös01 ] and
show how this measure estimate depends upon the domain. We revisit the
paper [ Pös01 ] in this thesis and our computation in particular fixes a
small gap in the statement of [ Pös01 ] (see @xmath of Remark 2.1.5
below).

Arnold’s scheme [ Arn63a , Arn63b ] can be summarized as follows. Let
@xmath and @xmath be real–analytic in @xmath , with @xmath integrable
and such that

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath . Thus, the torus @xmath is a KAM torus for
@xmath on which its flow @xmath is linear:

  -- -------- --
     @xmath   
  -- -------- --

Then, the idea of Arnold is to construct a near–to–identity symplectic
change of variables

  -- -------- --
     @xmath   
  -- -------- --

with @xmath such that

  -- -------- -- ---------
     @xmath      (1.0.7)
  -- -------- -- ---------

And for @xmath small enough, one can iterate the process and build a
sequence of symplectic transformations ( @xmath )

  -- -------- --
     @xmath   
  -- -------- --

and satisfying

  -- -------- -- ---------
     @xmath      (1.0.8)
  -- -------- -- ---------

In performing this construction, one is first attempt to solve the
linear PDE

  -- -------- -- ---------
     @xmath      (1.0.9)
  -- -------- -- ---------

where @xmath is a generating function for @xmath . But ( 1.0.9 ) does
not admit solution, because of small divisor problem (see [ Chi12 ] for
more discussion). The key idea of Arnold is then to solve only a
truncated version of ( 1.0.9 ), with the order of truncation large
enough so that the error one commits by solving approximately ( 1.0.9 )
is of order the square of the size of the perturbation. The truncation
is the origin of the logarithmic correction in the smallness condition
required in order to iterate infinitely many times the Arnold process.
In particular, the Lebesgue–measure estimate of the complementary of the
Kolmogorov set one gets from Arnold’s scheme is @xmath . This estimate
is not the optimal one, which is @xmath (see for instance [ BC18 ] ,
where the constant in front of @xmath in the optimal measure estimate is
computed explicitly and the proof uses the KAM Theorem à la Moser). The
task of getting rid of the logarithmic correction in the Arnold’s scheme
is not obvious. The first paper in this direction is the sketchy 7–pages
paper [ Nei81 ] , where Neishtadt outlines how to overcome the
logarithmic correction. The approach we adopt here is essentially
equivalent to the one in [ Nei81 ] though conceptually different.
Indeed, in our scheme we fix the frequencies of the tori we build up
from the beginning once for all. Instead, in [ Nei81 ] as well as in the
original paper by Arnold [ Arn63b ] , the tori as well as their
respective frequencies are constructed iteratively.

Moreover, in our approach, we focus on the smallest possible @xmath
i.e.  the situations where the square–root of the sizes of the
perturbations are proportional to the Diophantine constant @xmath of the
frequency of the tori. We then discuss the measure estimate of the
Kolmogorov set we build up . The sharpness of the measure of the
Kolmogorov set is in fact intimately related to the power of the
Diophantine constant @xmath in the smallness condition under which one
performs the KAM scheme. Recently, Villanueva [ Vil08 ] revisited the
classical Kolmogorov scheme and succeed to cut down the power of @xmath
in the smallness condition, from @xmath to the optimal which is @xmath ;
but with no measure estimate of Kolmogorov set discussion. See also [
Vil18 ] where he got the exponent @xmath for @xmath in the smallness
condition, in the framework of exact symplectic maps in Euclidean spaces
of even dimensions.

#### 1.1 Main results

As a basic rule in this thesis, we compute explicitly all the KAM
constants. Investigating the explicit dependence of the “KAM constants”
upon the parameters in a quasi–integrable Hamiltonian system is of great
interest, not only in view of its applications (for instance to the
@xmath –body problem [ CC06 ] , to geodesic flows on surfaces, etc ) but
also for the discussion of explicit measure estimates of Kolmogorov
sets. The content of this thesis can be described very roughly as
follows:

-   We prove three quantitative KAM normal forms following closely the
    original ideas of the pioneers Kolmogorov, Arnold and Moser. We
    compute in particular explicitly all the KAM constants in them and
    fix physical dimension issues by rescaling conveniently various
    quantities. Then, we compare those three quantitative KAM normal
    forms on a simple mechanical system.

-   We give detailed proof of how to get rid of the logarithmic
    correction in the Arnold’s scheme and then use it to prove an
    explicit and “sharp” Theorem of integrability on Cantor–type set.

-    We prove three types of sharp measure estimate of Kolmogorov sets.
    In the first one, we adopt the global approach which consists in
    constructing the Kolmogorov set in a given bounded domain and then
    estimate its measure. In the two others, we slice the domain into
    relatively small cubes with equilength sides. In each of those
    cubes, we construct a Kolmogorov set associated to the restriction
    of the Hamiltonian to such a cube and estimate its measure. Then, we
    sum up the local Kolmogorov sets constructed.
    One of the local approaches follows the idea in [ BC18 ] and recover
    its result.
    In the second local approach, we introduce a geometric integer
    constant of a set which is the minimal number of cubes one needs to
    cover the set by cubes with the same side–length, centered on the
    set and with total “volume” not exceeding some fixed amount. This
    third approach is somehow more intrinsic.

@xmath More precisely, we prove in Theorem 2.1.1 (following Kolmogorov’s
proof in [ Kol54a ] , scheme to which a complete proof was given in [
Chi08 , Chi12 ] ) that for any small enough perturbation of a
non–degenerate Kolmogorov normal form, there exists a symplectic change
of variables such that in the new variables, the Hamiltonian reduced to
a Kolmogorov normal form.

We prove in Theorem 2.1.2 (following Arnold [ Arn63a ] and basing on [
Chi08 , Chi12 ] ) that, under a sufficiently small perturbation, with
size say @xmath , of a non–degenerate integrable Hamiltonian system, the
majority ( @xmath of the total Lebesgue–measure) of the invariant,
Lagrangian, Kronecker tori with Diophantine frequencies of the
integrable system persist, being only slightly deformed.

In Theorem 2.1.4 , we prove (following Moser [ Mos67 ] and basing on [
Pös01 ] ) that on a bounded domain, the totality of the invariant
maximal KAM tori of the linear normal form, whose frequencies are far
enough from the boudary persist under any small enough perturbation.
These tori are just a little bit deformed and persist as invariant
maximal KAM tori, not of the perturbed Hamiltonian itself, but of the
perturbed Hamiltonian plus a small shift of the frequency.

In Chapter 3 , we compare the explicit KAM mormal forms on a simple
mechanical Hamiltonian and compute the numerical values of the
thresholds within these Theorems in a concrete case.

In Theorem 4.2.1 , we prove an explicit Theorem of integrability on a
Cantor–like set. Namely, for any given sufficiently small perturbation
of a non–degenerate integrable Hamiltonian on a bounded domain, we
construct a @xmath –symplectomorphism which conjugates the perturbed
Hamiltonian to an integrable Hamiltonian on a Cantor–like set. The
Cantor–like set is equipotent to the set of phase points which are at
some minimal distance from the boundary and such that their image by the
Jacobian of the unperturbed part are Diophantine vectors, with fixed
Diophantine parameters. Moreover, the ratio of their respective
Lebesgue–measures minus 1 is small with the size of the perturbation.

@xmath In Theorem 5.2.1 , we prove a refinement of the Arnold’s Theorem
by overcoming the logarithmic correction looming from the original
scheme. Indeed, we prove that, for any small enough perturbation of a
non–degenerate integrable Hamiltonian system, most of ( @xmath of the
total Lebesgue–measure, where @xmath is the size of the perturbation) of
the invariant maximal KAM tori of the integrable system persist, up to a
small deformation. To do so, we isolate the smallness parameter @xmath
from the super–exponential parameter so that, and this is the whole
point, as soon as @xmath is chosen conveniently to perform the scheme
one time, one can iterate infinitely many times without any other
requirement and, in particular, @xmath “disappears” once for all from
the second step on.

In Theorem 6.2.1 , we prove an explicit, intrinsic and sharp
integrability Theorem on a Cantor–like set . Namely, given any small
enough, real–analytic perturbation of a non–degenerate integrable
Hamiltonian on a bounded domain, we build-up a transformation, @xmath in
the Whitney sense and symplectic. Actually, the two Cantor--like sets
are lipeomorphic ¹ ¹ 1 i.e. there exists a bijective Lipschitz
continuous function from one onto the other. . In those new variables,
the nearly–integrable Hamiltonian becomes integrable on a Cantor–like
set. The Cantor-like set is equipotent to the set of phase points which
are far enough from the boundary and which images through the Jacobian
of the unperturbed part are @xmath –Diophantine, for some @xmath and
@xmath a number larger than the half–dimension minus one. In particular,
we get a family of invariant maximal KAM torus which complement has a
Lebesgue–measure bounded from above by a constant proportional to @xmath
.

@xmath The novel part of the present thesis consists mainly in Part II
and, in particular and more interestingly, the various “sharp” and
geometric measure estimates of the unstable sets within a Hamiltonian
system we provide .

##### 1.1.1 Measure estimate I

Then, we derive in Theorem 6.2.2 the following. Let @xmath be a
non–empty bounded domain with smooth boundary @xmath and a small enough
@xmath , depending on the geometry of the hypersurface @xmath . Let
@xmath be a sufficiently small perturbation, of order @xmath , of a
non–degenerate integrable Hamiltonian @xmath . Then, the set @xmath left
out of the @xmath – invariant maximal KAM tori is bounded in measure by

  -- -------- -------- -- ---------
     @xmath               (1.1.1)
              @xmath      (1.1.2)
  -- -------- -------- -- ---------

where ² ² 2 See Appendix F for the definitions. @xmath denotes the
@xmath –dimensional Hausdorff measure (or equivalently, the @xmath
–surface area), @xmath denotes the curvature tensor of @xmath , @xmath
is the loss of analyticity, @xmath is the norm of the inverse of the
Hessian @xmath of the unperturbed part,

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

with @xmath , the @xmath –th integrated mean curvature of @xmath in
@xmath .

###### Remark 1.1.1

(i) The first two terms of the r.h.s. of ( 1.1.1 ) arise from the
estimation of the @xmath –strip around @xmath , @xmath , out of which we
construct the family of invariant KAM tori. Notice that the last term
@xmath is of order @xmath by ( 1.0.6 ), whence ( 1.1.2 ) holds.
(ii) The estimate ( 1.1.1 ) might be seen as a “sharp” version of the
measure estimate of the invariant set in the Two–scale KAM Theorem of [
CP10 ] .

The following is proven in Theorem 6.4.2 . Let @xmath be a perturbation
of a non–degenerate integrable Hamiltonian @xmath , where @xmath a
non–empty, bounded subset of @xmath and @xmath two real analytic
function on @xmath with bounded extension to @xmath , for some @xmath
and @xmath . We prove that, for a sufficiently small @xmath (with
explicit upper–bound), one can construct by “localization” argument a
family of @xmath –invariant maximal KAM torus, say @xmath , which
complement has a Lebesgue–measure of order @xmath and estimated in two
ways as follows.

##### 1.1.2 Measure estimate II

More specifically, we show one hand that the Kolmogorov set @xmath is
bounded in measure from above (in the spirit of [ BC18 ] ) by

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a positive universal constant depending only upon the
dimension @xmath and @xmath ,

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

This provides an alternative proof to the result in [ BC18 ]
(alternative in the sense that the proof in [ BC18 ] is based upon
Moser’s idea while here, we use Arnold’s scheme) and our proof is
somehow more complete as we compute explicitly all the constants while [
BC18 ] refers to [ Pös01 ] , where the constants are left implicit.

##### 1.1.3 Measure estimate III

On the other hand, in a more intrinsic way, we build up (under the same
basic assumptions as above) a family @xmath of @xmath – invariant
maximal KAM torus such that

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , @xmath , @xmath as in @xmath , @xmath a positive universal
constant depending only upon the dimension @xmath and @xmath , and
@xmath a “covering number” of @xmath defined morally as follows.
Given @xmath , define the set @xmath of coverings of @xmath by cubes as
follows: @xmath if and only if there exists @xmath and @xmath cubes, say
@xmath @xmath , of equal side–length @xmath , centered at a point @xmath
and such that

  -- -------- --
     @xmath   
  -- -------- --

Then define

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 1.1.2

In the above definition of “covering number”, one could replace the
coefficient @xmath in front of @xmath in the definition of @xmath by
@xmath , leading to

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -- --
        
  -- -- --

#### 1.2 Notations and set up

Fix ³ ³ 3 For us, @xmath . @xmath . Let @xmath be non-empty and bounded
domain with piecewise smooth boundary and @xmath , the @xmath
–dimensional torus.
Given @xmath and a non-empty @xmath , @xmath , we define the following.
Let ⁴ ⁴ 4 As usual @xmath .

  -- -------- -- ---------
     @xmath      (1.2.1)
  -- -------- -- ---------

be the set of @xmath –Diophantine numbers, where @xmath is the @xmath
--norm on ⁵ ⁵ 5 And in general on @xmath as well as on all its subsets (
@xmath etc). @xmath and

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is some norm on @xmath ; everywhere in this thesis, we
shall use

  -- -------- --
     @xmath   
  -- -------- --

the sup–norm on @xmath , except in @xmath where we shall use @xmath .
Let ⁶ ⁶ 6 We shall nevertheless drop the dimension @xmath as it is fixed
once for all, and write @xmath instead of @xmath , etc .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath is the unit matrice of order @xmath .
@xmath will be equipped with the canonical symplectic form @xmath .
Given a linear operator @xmath , its “operator–norm” is given by

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath (resp. @xmath ) be the set of real–analytic functions @xmath
on @xmath (resp. @xmath ) with finite norm @xmath (resp. @xmath ),
defined below. Let

  -- -------- --
     @xmath   
  -- -------- --

@xmath and @xmath are defined analogously. Given @xmath and @xmath , we
define

  -- -------- --
     @xmath   
  -- -------- --

write ⁷ ⁷ 7 As usual, @xmath . Here, and henceforth, @xmath denotes the
Neper number and @xmath a complex–square–root of @xmath : @xmath .

  -- -------- --
     @xmath   
  -- -------- --

where @xmath define

  -- -------- --
     @xmath   
  -- -------- --

and define on @xmath (resp. @xmath ), the norms ⁸ ⁸ 8 Notice that the
above definitions apply also to vector–valued real analytic functions
i.e. @xmath with @xmath etc.

  -- -- -------- --
        @xmath   
        @xmath   
  -- -- -------- --

Moreover, for a matrix–valued periodic functions @xmath , we define ⁹ ⁹
9 With an analogous definitions with the other norms. For instance,
@xmath

  -- -- --
        
  -- -- --

and for a given @xmath , the Fourier’s norm of the @xmath –tensor @xmath
is given by

  -- -- --
        
  -- -- --

Given a map @xmath , its Lipschitz constant is defined by

  -- -------- --
     @xmath   
  -- -------- --

#### 1.3 General remarks

-   We have chosen the norms for simplicity but any others ¹⁰ ¹⁰ 10 An
    algebra norm is a norm satisfying @xmath , for any @xmath and @xmath
    . “algebra norms” maybe be used.

-   As we are going to compare the four theorems on a concrete
    Hamiltonian and since we use two different norms, we need a kind of
    equivalence between them. Indeed, we have, for any @xmath

      -- -- -------- --
            @xmath   
            @xmath   
            @xmath   
            @xmath   
            @xmath   
            @xmath   
      -- -- -------- --

-   Through the present thesis, we shall denote by @xmath (resp. @xmath
    ), at any place (with index or not), a constant depending
    (eventually) only on @xmath and @xmath (see below) and greater
    (resp. less) or equal than @xmath i.e. @xmath (resp. @xmath ).

## Part I Classical KAM Theorems and Quantitative normal forms

### Chapter 2 Quantitative KAM normal forms

#### 2.1 Statement of the explicit KAM normal forms theorems

##### 2.1.1 Kolmogorov’s normal form

###### 2.1.1.1 Assumptions

Let @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Let’s consider a hamiltonian @xmath such that @xmath has the form ¹¹ ¹¹
11 As usual, @xmath ; @xmath means that @xmath for all @xmath with
@xmath , where @xmath and @xmath .

  -- -------- -- ---------
     @xmath      (2.1.1)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (2.1.2)
  -- -------- -- ---------

Furthermore, assume that @xmath in ( 2.1.1 ) is non--degenerate in the
sense that ¹² ¹² 12 @xmath being the average over @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Write

  -- -------- --
     @xmath   
  -- -------- --

and set

  -- -------- --
     @xmath   
  -- -------- --

Finally define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### 2.1.1.2 Statement of the KAM Theorem

###### Theorem 2.1.1 (Komogorov [Kol54a], pg. 52)

Under the assumptions in @xmath , the following hold. There exists a
real–analytic symplectomorphism @xmath , depending analytically also on
@xmath , with

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath is the identity map and, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ---------
     @xmath      (2.1.3)
  -- -------- -- ---------

##### 2.1.2 KAM Theorem après Arnold

###### 2.1.2.1 Assumptions

Let @xmath and consider the Hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -------- -- ---------
     @xmath      (2.1.4)
  -- -------- -- ---------

Set

  -- -------- --
     @xmath   
  -- -------- --

Finally, for a given @xmath , define ¹³ ¹³ 13 Notice that @xmath
@xmath because @xmath . Thus, @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### 2.1.2.2 Statement of the KAM Theorem

###### Theorem 2.1.2 (Arnold [Arn63a])

Under the assumptions in @xmath , the following hold. For any given
@xmath satisfying

  -- -------- -- ---------
     @xmath      (2.1.5)
  -- -------- -- ---------

there exist @xmath and an embedding @xmath real–analytic on @xmath and
close to the trivial embedding

  -- -------- --
     @xmath   
  -- -------- --

such that the @xmath –torus

  -- -------- -- ---------
     @xmath      (2.1.6)
  -- -------- -- ---------

is a non-degenrate invariant Kronecker torus for @xmath i.e.

  -- -------- -- ---------
     @xmath      (2.1.7)
  -- -------- -- ---------

Moreover,

  -- -------- -- ---------
     @xmath      (2.1.8)
  -- -------- -- ---------

uniformly on @xmath

###### Remark 2.1.3

It is not difficult to see that Theorem 2.1.2 is stronger than Theorem
2.1.1 . Indeed, let the assumptions in § 2.1.1.1 hold. Then, Taylor’s
expansion yields @xmath , where

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Thus,

  -- -------- --
     @xmath   
  -- -------- --

Consequently, by choosing @xmath proportional to @xmath , one can apply
Theorem 2.1.2 and recover Theorem 2.1.1 .

##### 2.1.3 KAM Theorem après J. Moser (following J. Pöschel)

###### 2.1.3.1 Assumptions

Let @xmath and consider the hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

and @xmath and @xmath the hamiltonian vector fields associate to @xmath
and @xmath respectively with respect to the canonical symplectic form
@xmath . Let @xmath and @xmath be the hamiltonian flow associate to
@xmath and @xmath respectively. We have then, @xmath . Let ¹⁴ ¹⁴ 14
Notice that one could use any @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and define ¹⁵ ¹⁵ 15 @xmath is the Euler’s gamma function. Notice that if
@xmath then @xmath , where @xmath denotes the integer part of @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath            
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

and ¹⁶ ¹⁶ 16 Notice that @xmath . Moreover, if @xmath then @xmath and
therefore @xmath ; compare Appendix A , with @xmath and @xmath replaced
by @xmath .

  -- -------- -------- -------- ---------
     @xmath   @xmath            (2.1.9)
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- ---------

Finally, let

  -- -------- --
     @xmath   
  -- -------- --

be the trivial embedding.

###### 2.1.3.2 Statement of the KAM Theorem

###### Theorem 2.1.4 (Pöschel [Pös01])

Let @xmath and @xmath as in @xmath and assume that

  -- -------- -- ----------
     @xmath      (2.1.10)
  -- -------- -- ----------

where

  -- -------- --
     @xmath   
  -- -------- --

Then, there exist a Lipeomorphism @xmath close to the identity and a
Lipschitz continuous family of real analytic Lagrangian torus embeddings
@xmath closed to the trivial embedding @xmath such that the following
hold. For any @xmath , @xmath is a Lagrangian submanifold and an
invariant Kronecker torus for @xmath with @xmath , @xmath

  -- -------- -- ----------
     @xmath      (2.1.11)
  -- -------- -- ----------

Moreover, @xmath is a Lagrangian submanifold and the maps @xmath is real
analytic on @xmath for each given @xmath and one has uniformly on @xmath
and @xmath respectively, the following estimates ¹⁷ ¹⁷ 17 Here and in
@xmath as well, we shall denote by @xmath , the uniform Lipschitz’
semi-norm of the function @xmath w.r.t the @xmath –argument (parameter)
varying in the set @xmath .

  -- -------- -- ----------
     @xmath      (2.1.12)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.1.13)
  -- -------- -- ----------

###### Remark 2.1.5

-    If one chooses @xmath , then the assumption ( 2.1.10 ) in Theorem
    2.1.4 reduced to

      -- -------- --
         @xmath   
      -- -------- --

-    Notice that we have some freedom in the choice of @xmath . Indeed,
    one just needs to chose

      -- -------- -- ----------
         @xmath      (2.1.14)
      -- -------- -- ----------

-    To be precise, in Theorem 2.1.4 ,

      -- -------- --
         @xmath   
      -- -------- --

-    Notice that the @xmath in Theorem 2.1.4 is larger than the @xmath
    Pöschel uses in Theorem @xmath and @xmath in [ Pös01 ] . In fact the
    Theorem @xmath and @xmath are not valid for @xmath . Indeed ¹⁸ ¹⁸ 18
    We are using here the same notations as in [ Pös01 ] . , assuming
    the contrary, then for any @xmath , there would exists @xmath such
    that

      -- -------- -- ----------
         @xmath      (2.1.15)
      -- -------- -- ----------

    But then ¹⁹ ¹⁹ 19 Because @xmath . , @xmath i.e. @xmath . Hence, we
    would have, if we take @xmath in particular, for any @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

    i.e.

      -- -------- --
         @xmath   
      -- -------- --

##### 2.1.4 KAM Theorem après Salamon–Zehnder

###### 2.1.4.1 Assumptions

Let

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Let’s consider a hamiltonian @xmath , for some @xmath and
a pair of real–analytic functions @xmath on @xmath such that

  -- -- --
        
  -- -- --

for any @xmath and

  -- -- --
        
  -- -- --

for some

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

are invertible for each given @xmath and, defining ²⁰ ²⁰ 20 @xmath
stands for the transpose of the inverse of @xmath : @xmath . ,

  -- -------- --
     @xmath   
  -- -------- --

@xmath is invertible. Let @xmath and define @xmath and @xmath by

  -- -------- -- ----------
     @xmath      (2.1.16)
  -- -------- -- ----------

Futhermore, assume that

  -- -- --
        
  -- -- --

for some @xmath and @xmath . Finally, define

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

###### 2.1.4.2 Statement of the KAM Theorem

###### Theorem 2.1.6 (Celletti–Chierchia [Cc97])

Under the assumptions in @xmath , the following holds. There exists a
polynomial @xmath in @xmath satisfying

  -- -------- -- ----------
     @xmath      (2.1.17)
  -- -------- -- ----------

such that, if

  -- -------- -- ----------
     @xmath      (2.1.18)
  -- -------- -- ----------

then there exists @xmath , real–analytic on @xmath , @xmath –close to
@xmath and solving

  -- -------- -- ----------
     @xmath      (2.1.19)
  -- -------- -- ----------

Futhermore, @xmath and the solution @xmath is uniquely determined in the
@xmath –neighborhood of @xmath by the condition @xmath .

For a proof, see [ CC97 ] .

###### Remark 2.1.7

Notice that instead of the bound @xmath on @xmath used in [ CC97 ] to
define the parameters, here we use @xmath . The point is that, with this
change, one is then allowed to chose @xmath when @xmath is constant.

#### 2.2 Some preliminary facts

As we are going to use the same idea as in [ Chi90 ] to extend maps
obtained through the KAM step in the proof of Theorem 2.1.4 , we will
need a cut–off function.

###### Lemma 2.2.1 (Cut–Off)

Then, for any @xmath , there exists a constant @xmath such that for any
given @xmath and a non–empty @xmath , there exists @xmath with @xmath on
@xmath and for any @xmath with @xmath ,

  -- -------- -- ---------
     @xmath      (2.2.1)
  -- -------- -- ---------

Proof Let @xmath such that @xmath and @xmath . Consider

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Define ²¹ ²¹ 21 @xmath denotes the characteristic function of the set
@xmath , i.e. @xmath on @xmath and @xmath on @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Thus, @xmath and

-   @xmath . Indeed, for any @xmath , @xmath implies that @xmath and
    @xmath for a.e. @xmath (with respect to the Lebesgue measure on
    @xmath ); which implies in particular that there exist @xmath and
    @xmath such that @xmath and @xmath , so that @xmath i.e. @xmath .

-   @xmath on @xmath . Indeed, let @xmath i.e. @xmath , for some @xmath
    . Then, for any @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

    Hence,

      -- -------- --
         @xmath   
      -- -------- --

Moreover, for any @xmath and for any @xmath , we have ²² ²² 22 In fact,
one checks easily that for any @xmath , @xmath .

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

One checks easily that for any @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and for any @xmath

  -- -------- --
     @xmath   
  -- -------- --

and one has, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The existence of the sequence @xmath then follows easily and in
particular, by choosing @xmath and, then, @xmath , we can take ²³ ²³ 23
We have @xmath .

  -- -------- -- ---------
     @xmath      (2.2.2)
  -- -------- -- ---------

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The following lemma establishes a bound on the Lipschitz constant of a
map obtained as the composition of infinetly many Lipschitz maps and
will be used to prove the Lipschitz continuity of the map in Theorem
2.1.4 , obtained through the infinite iterative KAM scheme.

###### Lemma 2.2.2

Let @xmath be a real or complex normed vector space, @xmath be a
sequence of invertible linear operators and @xmath be a sequence of
Lipschitz continuous maps from @xmath to itself. Define

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -- ---------
     @xmath      (2.2.3)
  -- -------- -- ---------

Then @xmath is a sequence of Lipschitz continuous maps and for any
@xmath ,

  -- -------- -- ---------
     @xmath      (2.2.4)
  -- -------- -- ---------

Proof For any @xmath , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Hence, we get, inductively, that for any @xmath , @xmath .

We recall the very famous Cauchy estimate used to control the
derivatives of an analytic function.

###### Lemma 2.2.3 (Cauchy’s estimate)

Let @xmath . Then, for any multi–index @xmath with @xmath and for any
@xmath , ²⁴ ²⁴ 24 As usual, @xmath .

  -- -------- --
     @xmath   
  -- -------- --

In the next lemma, we recall some properties of the Fourier’s
coefficients of an analytic function.

###### Lemma 2.2.4

Let @xmath with @xmath . Then

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Proof

-   Let @xmath . Then

      -- -------- --
         @xmath   
      -- -------- --

    But, for any given @xmath , by periodicity of @xmath in each
    argument and Cauchy’s theorem, we get

      -- -------- --
         @xmath   
      -- -------- --

    Now, we choose @xmath with @xmath . Thus, we get

      -- -------- --
         @xmath   
      -- -------- --

    and letting @xmath , we get the desired inequality.

-   We have

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

In the following lemma, we recall some facts about the homological
equation.

###### Lemma 2.2.5 ([Cc95])

Let @xmath and @xmath . Then, for any @xmath , the equation

  -- -------- --
     @xmath   
  -- -------- --

has a unique solution in @xmath and there exist constants @xmath and
@xmath such that for any multi–index @xmath with @xmath

  -- -------- --
     @xmath   
  -- -------- --

In particular, one can take @xmath (see [ Rüs75 , CC95 ] ).

Now, we recall the classical implicit function theorem, in a
quantitative framework.

###### Lemma 2.2.6 (Implicit Function Theorem I[Chi12])

Let @xmath and ²⁵ ²⁵ 25 Let us point out that any other norm
(different!) may be used on @xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

be continuous with continuous Jacobian matrix @xmath . Assume that
@xmath is invertible with inverse @xmath such that

  -- -------- -- ---------
     @xmath      (2.2.5)
  -- -------- -- ---------

Then, there exists a unique continuous function @xmath such that the
following are equivalent

-   @xmath and @xmath ;

-   @xmath and @xmath .

Moreover, @xmath satisfies

  -- -------- -- ---------
     @xmath      (2.2.6)
  -- -------- -- ---------

Finally, we recall some inversion function theorems.
Taking @xmath and @xmath in Lemma 2.2.6 , for a given @xmath , then the
following holds.

###### Lemma 2.2.7 (Inversion Function Theorem I)

Let @xmath be a @xmath function with invertible Jacobian @xmath and
assume that

  -- -------- --
     @xmath   
  -- -------- --

Then, there exists a unique @xmath function

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -------- --
     @xmath   
  -- -------- --

Moreover,

  -- -------- -- ---------
     @xmath      (2.2.7)
  -- -------- -- ---------

###### Remark 2.2.8

-    Notice that in Lemmata 2.2.6 and 2.2.7 if, in addition, @xmath is
    periodic in @xmath (resp. analytic, real on reals) then so is @xmath
    .

-    Notice that Lemmata 2.2.6 and 2.2.7 still hold if, everywhere
    therein, open balls are replaced by closed balls or complex–balls by
    real–balls.

Another consequence of the Implicit Function Theorem is the following
version of Inversion Function Theorem.

###### Lemma 2.2.9 (Inversion Function Theorem II [Pös01])

Assume that @xmath is a real analytic function from @xmath into @xmath
such that

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath has a real analytic inverse @xmath defined on @xmath and on
which it satisfies

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 2.2.10

Notice that, all the Lemmata above are valid if one replace @xmath by
@xmath or @xmath .

#### 2.3 Proofs

##### 2.3.1 Proof of Theorem 2.1.1

The proof is essentially the one in [ Chi08 ] though one needs to
re–scale various quantities; therefore we shall skip some details. First
of all, notice that @xmath . For simplicity, sometimes, the explicit
dependence on @xmath or @xmath will not be denoted in the norm @xmath or
in the @xmath –spaces, etc, as @xmath and @xmath will not be changed
during the iteration. We begin by describing completely one step of the
scheme, namely the KAM step, which will be then iterated infinitely many
time to compute the symplectic change of variable.

KAM step Kolmogorov’s idea is to construct a near–to–the–identity
symplectic transformation @xmath , such that

  -- -------- -- ---------
     @xmath      (2.3.1)
  -- -------- -- ---------

if this is achieved, the Hamiltonian @xmath has the same basic
properties of @xmath (the linear part in @xmath is the same and, being
@xmath close to the identity, @xmath is non–degenerate) and the
procedure can be iterated.

For, Kolmogorov considers the generating function of @xmath of the form
²⁶ ²⁶ 26 Compare [ DS01 , AKN06 ] for generalities on symplectic
transformations and their generating functions. For simplicity, we do
not report in the notation the dependence of various functions on @xmath
, but, in fact, @xmath , @xmath , @xmath , etc.

  -- -------- -- ---------
     @xmath      (2.3.2)
  -- -------- -- ---------

where, @xmath and @xmath are (respectively, scalar and vector–valued,
@xmath –dependent) real–analytic functions on @xmath with zero average
and @xmath . Define ²⁷ ²⁷ 27 As usual, we denote @xmath and @xmath
denotes the matrix @xmath ; as above, we often do not report in the
notation the dependence upon @xmath (but @xmath , @xmath and @xmath do
depend also on @xmath ).

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath is implicitely defined by

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for @xmath small, @xmath defines a diffeomorphism of @xmath
with inverse

  -- -------- --
     @xmath   
  -- -------- --

for a suitable real–analytic function @xmath . Thus @xmath is explicitly
given by

  -- -------- -- ---------
     @xmath      (2.3.3)
  -- -------- -- ---------

To determine @xmath , @xmath and @xmath , observe that by Taylor’s
formula

  -- -------- -- ---------
     @xmath      (2.3.4)
  -- -------- -- ---------

where @xmath with

  -- -------- -- ---------
     @xmath      (2.3.5)
  -- -------- -- ---------

Note that

  -- -------- -- ---------
     @xmath      (2.3.6)
  -- -------- -- ---------

and that (again by Taylor’s formula)

  -- -------- -- ---------
     @xmath      (2.3.7)
  -- -------- -- ---------

Thus, since ²⁸ ²⁸ 28 Recall that @xmath and @xmath . @xmath , we find

  -- -------- -- ---------
     @xmath      (2.3.8)
  -- -------- -- ---------

with @xmath as in ( 2.3.4 )–( 2.3.5 ) and

  -- -------- -- ---------
     @xmath      (2.3.9)
  -- -------- -- ---------

By Lemma 2.2.5 , there exist a unique constant @xmath and unique
functions @xmath and @xmath (with zero average) such that @xmath is
constant . In fact, if

  -- -- --
        
  -- -- --

then @xmath . Thus, with this determination of @xmath in ( 2.3.2 ),
recalling ( 2.3.3 ), we find that ( 2.3.1 ) holds with

  -- -------- --
     @xmath   
  -- -------- --

Clearly, for @xmath small enough @xmath is invertible and, if @xmath ,
we may write

  -- -------- -- ----------
     @xmath      (2.3.10)
  -- -------- -- ----------

Next, we provide the KAM step with carefull estimates. Actually, we
shall do the estimates in term of a lower bound of @xmath instead of
@xmath , so that, by taking this lower bound equal to @xmath , we shall
get the estimates in Theorem 2.1.1 ²⁹ ²⁹ 29 The point is that, if we
replace @xmath by @xmath everywhere in § 2.1.1 , except in the
expressions of @xmath and @xmath , then, Theorem 2.1.1 holds for any
@xmath such that @xmath . . Thus, we fix, for the remainder of the
proof,

  -- -------- -- ----------
     @xmath      (2.3.11)
  -- -------- -- ----------

Recall the definition in @xmath ; in particular ³⁰ ³⁰ 30 The notation in
Eq. ( 2.3.12 ) means that each term on the l.h.s. is bounded by the
r.h.s.

  -- -------- -- ----------
     @xmath      (2.3.12)
  -- -------- -- ----------

Finally, fix ³¹ ³¹ 31 The parameter @xmath will be the size of the
domain of analyticity of the new symplectic variables @xmath , domain on
which we shall bound the Hamiltonian @xmath , while @xmath is an
intermediate domain where we shall bound various functions of @xmath and
@xmath . Note that @xmath .

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 2.3.1

Then ³² ³² 32 Here @xmath .

  -- -------- -- ----------
     @xmath      (2.3.13)
  -- -------- -- ----------

Furthermore, if @xmath satisfies

  -- -------- -- ----------
     @xmath      (2.3.14)
  -- -------- -- ----------

then

  -- -------- -- ----------
     @xmath      (2.3.15)
  -- -------- -- ----------

and the following hold. For @xmath , the map @xmath has an analytic
inverse @xmath such that, for all @xmath ,

  -- -------- -- ----------
     @xmath      (2.3.16)
  -- -------- -- ----------

for any @xmath , @xmath ; the map @xmath is a symplectic diffeomorphism
and

  -- -------- -- ----------
     @xmath      (2.3.17)
  -- -------- -- ----------

where @xmath is defined by the relation @xmath .

Finally, if ³³ ³³ 33 Notice that @xmath since @xmath , so that ( 2.3.18
) implies ( 2.3.14 ).

  -- -------- -- ----------
     @xmath      (2.3.18)
  -- -------- -- ----------

then

  -- -- -- ----------
           (2.3.19)
  -- -- -- ----------

Proof We begin by estimating @xmath . Actually these estimate will be
given on a larger intermediate domain, namely, @xmath , allowing to give
the remaining bounds on the smaller domain @xmath . Let @xmath . By
definition of @xmath and @xmath , it follows that @xmath . By Lemma
2.2.5 with @xmath and @xmath , one gets

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Next, we estimate @xmath . By definitions and Lemma 2.2.3 , we have ³⁴
³⁴ 34 Remember that @xmath and @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Next, we estimate @xmath . We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Next, we estimate @xmath . We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Next, we estimate @xmath and @xmath . Let @xmath . Then, by Lemma 2.2.3
2.2.5 , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, by Lemma 2.2.5 , we obtain ³⁵ ³⁵ 35 The factor @xmath comes from
the fact @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Next, we estimate @xmath . We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Next, we estimate @xmath . To do this, we need to estimate @xmath and
@xmath . By definitions and Lemma 2.2.3 , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Finally, we estimate @xmath . We have, once again by Lemma 2.2.3 ,

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

Now, under the assumption ( 2.3.14 ), we prove ( 2.3.15 ). For @xmath
and @xmath , by ( 2.3.13 ) one has

  -- -------- -- ----------
     @xmath      (2.3.20)
  -- -------- -- ----------

so that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus

  -- -------- --
     @xmath   
  -- -------- --

Next, we show how ( 2.3.14 ) implies the existence of the inverse of
@xmath satisfying ( 2.3.16 ). The defining relation @xmath implies that
@xmath , where @xmath is short for @xmath and such relation is a fixed
point equation for the non–linear operator @xmath . To find a fixed
point for this equation one can use a standard contraction Lemma (see [
KF99 ] ). Let @xmath denote the closed ball (with respect to the
sup–norm) of continuos functions @xmath such that @xmath . By ( 2.3.14
), @xmath , for any @xmath , and any @xmath ; thus, @xmath by ( 2.3.13
), so that @xmath ; notice that, in particular, this means that @xmath
sends @xmath –periodic functions into @xmath –periodic functions.
Moreover, ( 2.3.14 ) implies also that @xmath is a contraction: if
@xmath , then, by the mean value theorem and ( 2.3.13 ), @xmath @xmath
@xmath , so that, by taking the sup–norm, one has @xmath showing that
@xmath is a contraction. Thus, there exists a unique @xmath such that
@xmath . Furthermore, recalling that the fixed point is achieved as the
uniform limit @xmath ( @xmath ) and since @xmath is analytic, so is
@xmath for any @xmath and, hence, by Weierstrass Theorem on the uniform
limit of analytic function, the limit @xmath itself is analytic. In
conclusion, @xmath and ( 2.3.16 ) holds. Next, ( 2.3.16 ) and ( 2.3.20 )
imply ( 2.3.17 ) and therefore, @xmath defines a symplectic
diffeomorphism ³⁶ ³⁶ 36 Notice, in particular that the matrix @xmath is,
for any @xmath , invertible with inverse @xmath ; in fact, since @xmath
the matrix @xmath is invertible with inverse given by the “Neumann
series” @xmath , so that @xmath . satisfying ( 2.3.17 ) and the fourth
inequality in the first line of ( 2.3.19 ). It remains to show the other
estimates in ( 2.3.19 ). Since @xmath , the bound on @xmath follows (
2.3.13 ). By ( 2.3.15 ), ( 2.3.17 ) and ( 2.3.20 ), one has @xmath .
Now, by Cauchy estimates, ( 2.3.13 ), ( 2.3.14 ) and ( 2.3.17 ), it
follows that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and ³⁷ ³⁷ 37 Recall that @xmath so that @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that ³⁸ ³⁸ 38 It is only here that a constant @xmath is needed; the
(irrelevant) factor @xmath has been introduced for later convenience.

  -- -------- -- ----------
     @xmath      (2.3.21)
  -- -------- -- ----------

Thus,

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (2.3.22)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ----------

and, in view of ( 2.3.12 ) and ( 2.3.21 ), we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, by ( 2.3.18 ), @xmath , implying that @xmath is invertible
and

  -- -------- --
     @xmath   
  -- -------- --

with @xmath . In conclusion, by ( 2.3.22 ), and the estimate on @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

proving last estimate in ( 2.3.19 ) and, hence, Lemma 2.3.1 .

Next Lemma shows that, for @xmath small enough, Kolmogorov’s
construction can be iterated and convergence proved.

###### Lemma 2.3.2

Fix @xmath and, for @xmath , let ³⁹ ³⁹ 39 Notice that @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Let also @xmath , @xmath , @xmath , @xmath , @xmath , with @xmath ,
@xmath , @xmath , @xmath , @xmath and @xmath as in @xmath and assume
that @xmath satisfies

  -- -------- -- ----------
     @xmath      (2.3.23)
  -- -------- -- ----------

Then, one can construct a sequence of symplectic transformations

  -- -------- -- ----------
     @xmath      (2.3.24)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (2.3.25)
  -- -------- -- ----------

converges uniformly to a Kolmogorov’s normal form. More precisely,
@xmath , @xmath , @xmath , @xmath , @xmath converge uniformly on @xmath
to, respectively, @xmath , @xmath , @xmath , @xmath , @xmath , which are
real–analytic on @xmath and @xmath with @xmath . Finally, the following
estimates hold for any @xmath and for any @xmath :

  -- -------- -- ----------
     @xmath      (2.3.26)
     @xmath      (2.3.27)
  -- -------- -- ----------

where @xmath .

Proof Notice that ( 2.3.23 ) implies ( 2.3.18 ) (and, hence, ( 2.3.14
)). For @xmath , define

  -- -------- --
     @xmath   
  -- -------- --

Let us assume ( inductive hypothesis ) that we can iterate @xmath times
Kolmogorov transformation obtaining @xmath symplectic transformations
@xmath , for @xmath , and @xmath Hamiltonians @xmath real–analytic on
@xmath such that, for any @xmath ,

  -- -------- -- ----------
     @xmath      (2.3.28)
  -- -------- -- ----------

Observe that for @xmath , it is @xmath and ( 2.3.28 ) is implied by the
definition of @xmath and by condition ( 2.3.23 ).

Because of ( 2.3.28 ), ( 2.3.18 ) holds for @xmath and Lemma 2.3.1 can
be applied to @xmath and one has, for @xmath and for any @xmath (compare
( 2.3.19 )):

  -- -------- -- ----------
     @xmath      
     @xmath      (2.3.29)
  -- -------- -- ----------

Observe that, by definition of @xmath , @xmath in ( 2.3.23 ) and of
@xmath in ( 2.3.28 ), one has @xmath , so that @xmath , thus by last
relation in ( 2.3.1 ), for any @xmath , @xmath @xmath @xmath , which
iterated, yields ( 2.3.26 ) @xmath @xmath for @xmath .

Next, we show that, thanks to ( 2.3.23 ), ( 2.3.28 ) holds also for
@xmath . In fact, by ( 2.3.28 ) and the definition of @xmath in @xmath ,
we have

  -- -------- --
     @xmath   
  -- -------- --

The bound for @xmath is proven in an identical manner. Now, by @xmath
and ( 2.3.23 ),

  -- -------- --
     @xmath   
  -- -------- --

which implies the second inequality in ( 2.3.28 ) with @xmath ; the
proof of the induction is finished and one can construct an infinite
sequence of Kolmogorov transformations satisfying ( 2.3.28 ), ( 2.3.1 )
and ( 2.3.26 ) for all @xmath .

To check ( 2.3.27 ), we observe that

  -- -- --
        
  -- -- --

and therefore

  -- -------- --
     @xmath   
  -- -------- --

Thus,

  -- -------- --
     @xmath   
  -- -------- --

and analogously for @xmath and @xmath .

Next, we prove that @xmath is convergent by proving that it is Cauchy.
For any @xmath , we have ⁴⁰ ⁴⁰ 40 Notice that @xmath , for any @xmath
and, by ( 2.3.13 ), ( 2.3.14 ), ( 2.3.16 ) and ( 2.3.23 ), we have,

@xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence @xmath converges uniformly on @xmath to some @xmath , which is
then real–analytic function on @xmath .

To estimate @xmath , observe that

  -- -------- --
     @xmath   
  -- -------- --

which iterated yields

  -- -------- -------- --
     @xmath            
              @xmath   
  -- -------- -------- --

Therefore, taking the limit over @xmath completes the proof of ( 2.3.27
), Lemma 2.3.2 and, whence, of Kolmogorov’s Theorem.

##### 2.3.2 Proof of Theorem 2.1.2

###### Lemma 2.3.3 (KAM step)

Let @xmath and consider the hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

Assume that ⁴¹ ⁴¹ 41 In the sequel, @xmath and @xmath stand for generic
real analytic hamiltonians which, later on, will respectively play the
roles of @xmath and @xmath , and @xmath , the roles of @xmath in the
iterative step. ^(,) ⁴² ⁴² 42 Notice that @xmath .

  -- -- -------- -------- ----------
        @xmath            (2.3.30)
                 @xmath   
                 @xmath   
  -- -- -------- -------- ----------

Fix @xmath and let

  -- -- -------- -------- ----------
        @xmath            (2.3.31)
                 @xmath   
  -- -- -------- -------- ----------

Finally, define ⁴³ ⁴³ 43 Notice that @xmath since @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Then, there exists a generating function @xmath with the following
properties:

  -- -------- -- ----------
     @xmath      (2.3.32)
  -- -------- -- ----------

where

  -- -- --
        
  -- -- --

If, in addition,

  -- -------- -- ----------
     @xmath      (2.3.33)
  -- -------- -- ----------

then, there exists @xmath such that

  -- -- -- ----------
           (2.3.34)
  -- -- -- ----------

where

  -- -------- --
     @xmath   
  -- -------- --

and the following hold. For @xmath , the map @xmath has an analytic
inverse @xmath such that

  -- -- -- ----------
           (2.3.35)
  -- -- -- ----------

for any @xmath , @xmath ; the map @xmath is a symplectic diffeomorphism
and

  -- -------- -- ----------
     @xmath      (2.3.36)
  -- -------- -- ----------

with

  -- -------- -- ----------
     @xmath      (2.3.37)
  -- -------- -- ----------

where @xmath is defined by the relation @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ----------
     @xmath      (2.3.38)
  -- -------- -- ----------

with

  -- -------- --
     @xmath   
  -- -------- --

Proof

Step 1: Construction of the Arnold’s transformation We seek for a
near–to–the–identity symplectic transformation

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , generated by a function of the form @xmath , so that

  -- -------- -- ----------
     @xmath      (2.3.39)
  -- -------- -- ----------

such that

  -- -------- -- ----------
     @xmath      (2.3.40)
  -- -------- -- ----------

By Taylor’s formula, we get ⁴⁴ ⁴⁴ 44 Recall that @xmath stands for the
average over @xmath .

  -- -------- -------- -------- ----------
     @xmath   @xmath            (2.3.41)
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- ----------

with @xmath , which will be chosen large enough so that @xmath and

  -- -- -- ----------
           (2.3.42)
  -- -- -- ----------

By the non–degeneracy condition in ( 2.3.30 ), for @xmath small enough
(to be made precised below), @xmath and, therefore, by Lemma 2.2.6 ,
there exists a unique @xmath such that the second part of ( 2.3.40 )
holds. In view of ( 2.3.41 ), in order to get the first part of ( 2.3.40
), we need to find @xmath such that @xmath vanishes; such a @xmath is
indeed given by

  -- -------- -- ----------
     @xmath      (2.3.43)
  -- -------- -- ----------

provided that

  -- -------- -- ----------
     @xmath      (2.3.44)
  -- -------- -- ----------

But, in fact, since @xmath is rationally independent, then, given any
@xmath , there exists @xmath such that

  -- -------- -- ----------
     @xmath      (2.3.45)
  -- -------- -- ----------

The last step is to invert the function @xmath in order to define @xmath
. But, by Lemma 2.2.6 , for @xmath small enough, the map @xmath admits
an real–analytic inverse of the form

  -- -------- -- ----------
     @xmath      (2.3.46)
  -- -------- -- ----------

so that the Arnod’s symplectic transformation is given by

  -- -------- -- ----------
     @xmath      (2.3.47)
  -- -------- -- ----------

Hence, ( 2.3.40 ) holds with

  -- -------- -- ----------
     @xmath      (2.3.48)
  -- -------- -- ----------

Step 2: Quantitative estimates
First of all, notice that ⁴⁵ ⁴⁵ 45 Recall footnote ⁴² .

  -- -------- -- ----------
     @xmath      (2.3.49)
  -- -------- -- ----------

We begin by extending the “diophantine condition w.r.t. @xmath ”
uniformly to @xmath up to the order @xmath . Indeed, by the Mean Value
Inequality and @xmath , we get, for any @xmath and any @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      (2.3.50)
  -- -------- -------- -- ----------

so that, by Lemma 2.2.4 – @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, analogously,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Next, we prove the existence and uniqueness of @xmath in ( 2.3.40 ).
Consider then

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then

-   @xmath ;

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   Recalling @xmath , we have

      -- -------- -------- -- ----------
         @xmath   @xmath      
                  @xmath      
                  @xmath      (2.3.51)
                  @xmath      
                  @xmath      
      -- -------- -------- -- ----------

Therefore, Lemma 2.2.6 applies. Hence, there exists a function @xmath
such that its graph coincides with @xmath . In particular, @xmath is the
unique @xmath satisfying @xmath i.e. the second part of ( 2.3.40 ).
Moreover,

  -- -------- -- ----------
     @xmath      (2.3.52)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (2.3.53)
  -- -------- -- ----------

Next, we prove that @xmath is invertible. Indeed, by Taylor’ formula, we
have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, by Cauchy’s estimate,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence @xmath is invertible with

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Next, we prove estimate on @xmath . We have,

  -- -------- --
     @xmath   
  -- -------- --

so that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and by Lemma 2.2.4 – @xmath , we have,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence ⁴⁶ ⁴⁶ 46 Recall that @xmath . ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The proof of the claims on @xmath and @xmath are proven in a similar way
as in Lemma 2.3.1 .

Finally, we prove the convergence of the scheme by mimicking Lemma 2.3.2
.

###### Lemma 2.3.4

Let @xmath , @xmath , @xmath , @xmath , and @xmath , @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath , @xmath , @xmath and @xmath be as in
@xmath . For a given @xmath , define ⁴⁷ ⁴⁷ 47 Notice that @xmath and
@xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Assume that @xmath is such that

  -- -------- -- ----------
     @xmath      (2.3.54)
  -- -------- -- ----------

Then, one can construct a sequence of symplectic transformations

  -- -------- -- ----------
     @xmath      (2.3.55)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (2.3.56)
  -- -------- -- ----------

converges uniformly. More precisely, @xmath , @xmath , @xmath , @xmath
converge uniformly on @xmath to, respectively, @xmath , @xmath , @xmath
, @xmath which are real–analytic on @xmath and @xmath with @xmath .
Finally, the following estimates hold for any @xmath :

  -- -------- -- ----------
     @xmath      (2.3.57)
     @xmath      (2.3.58)
  -- -------- -- ----------

Proof For @xmath , define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Let us assume ( inductive hypothesis ) that we can iterate @xmath times
the KAM step obtaining @xmath symplectic transformations ⁴⁸ ⁴⁸ 48
Compare ( 2.3.36 ).

  -- -------- -- ----------
     @xmath      (2.3.59)
  -- -------- -- ----------

and @xmath Hamiltonians @xmath real–analytic on @xmath such that, for
any @xmath ,

  -- -------- -- ----------
     @xmath      (2.3.60)
  -- -------- -- ----------

Observe that for @xmath , it is @xmath and ( 2.3.60 ) is implied by the
definitions of @xmath and by condition ( 2.3.54 ).

Because of ( 2.3.54 ) and ( 2.3.60 ), ( 2.3.33 ) holds for @xmath and
Lemma can be applied to @xmath and one has, for @xmath (see ( 2.3.32 ),
( 2.3.34 ), ( 2.3.37 ) and ( 2.3.38 )):

  -- -------- -- ----------
     @xmath      (2.3.61)
  -- -------- -- ----------

Let @xmath . Since

  -- -------- --
     @xmath   
  -- -------- --

then

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, since

  -- -------- -- ----------
     @xmath      (2.3.62)
  -- -------- -- ----------

we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, fix @xmath . We have

  -- -------- -- ----------
     @xmath      (2.3.63)
  -- -------- -- ----------

so that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

thus by last relation in ( 2.3.61 ), for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e. @xmath , which iterated, yields @xmath for @xmath . Next, we show
that, thanks to ( 2.3.54 ), ( 2.3.60 ) holds also for @xmath . In fact,
by ( 2.3.60 ) and ( 2.3.61 ), we have

  -- -------- --
     @xmath   
  -- -------- --

and similarly for @xmath . Now, by @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which implies the last inequality in ( 2.3.60 ) with @xmath .
Next, we check the fourth inequality in ( 2.3.60 ) for @xmath . We have
⁴⁹ ⁴⁹ 49 Notice that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The proof of the induction is then finished and one can construct an
infinite sequence of Arnold’s transformations satisfying ( 2.3.60 ), (
2.3.61 ) and ( 2.3.57 ) for all @xmath .
Next, we prove that @xmath is convergent by proving that it is Cauchy.
For any @xmath , we have, using again Cauchy’s estimate, ⁵⁰ ⁵⁰ 50 Notice
that @xmath and recall that @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath converges uniformly on @xmath to some @xmath , which is
then real–analytic map in @xmath .

To estimate @xmath on @xmath , observe that , for @xmath , ⁵¹ ⁵¹ 51
Recall that @xmath .

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which iterated yields

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, taking the limit over @xmath completes yields, uniformly on
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Now, to complete the proof of the Lemma and, consequently, of the
Theorem, just set @xmath and observe that, uniformly on @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

##### 2.3.3 Proof of Theorem 2.1.4

As usual, the proof is inductive: at each step @xmath , a small
perturbation of some normal form @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

is considered. Then, a coordinates and parameter transformation @xmath
is constructed so that

  -- -------- --
     @xmath   
  -- -------- --

with another normal form @xmath , some much smaller error term @xmath
satisfying

  -- -------- --
     @xmath   
  -- -------- --

for some constant @xmath and the sequence @xmath converges to an
embedding of an invariant Kronecker torus.
The first step, called KAM step , will be then to describe one cycle of
this iterative scheme in which, for readability, we drop the subscribe
@xmath and consider a generic hamiltonian @xmath . First of all, instead
of @xmath , we consider the hamiltonian @xmath obtained from @xmath by
first linearizing the perturbation @xmath in @xmath and then truncating
its Fourier series in @xmath at some suitable high order @xmath .
The transformation @xmath is of the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is obtained as the time–1–map of the flow @xmath of some
hamiltonian @xmath and

  -- -------- -- ----------
     @xmath      (2.3.64)
  -- -------- -- ----------

In particular, @xmath is then symplectic for @xmath fixed ⁵² ⁵² 52
Indeed, denoting the Lie derivative by @xmath and the contraction
operator by @xmath , we have

@xmath

. Then, we iterate this cycle and prove the convergences.

In all this section, the sup–norm on @xmath will be denoted by @xmath ,
while on @xmath (resp. @xmath ), it will be denoted by @xmath (resp.
@xmath ).

###### 2.3.3.1 KAM step

###### Lemma 2.3.5 (KAM step)

Assume that @xmath with

-   @xmath ,

-   @xmath ,

-   @xmath ,

for some @xmath and sufficiently large @xmath . Then there exist @xmath
a @xmath –diffeomorphism with @xmath and @xmath on @xmath , @xmath a (
@xmath –) family of symplectic transformations parametrized over @xmath
, each being real–analytic with holomorphic extention to @xmath and
@xmath in @xmath on @xmath and such that, if @xmath , the following
hold: its restriction map

  -- -------- --
     @xmath   
  -- -------- --

is well–defined, real–analytic (in all arguments), @xmath with another
normal form @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Moreover ⁵³ ⁵³ 53 We denote by @xmath and @xmath , respectively, the
jacobian of @xmath with respect to @xmath and of @xmath with respect to
@xmath . ,

  -- -------- -- ----------
     @xmath      (2.3.65)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.3.66)
  -- -------- -- ----------

  -- -- -- ----------
           (2.3.67)
  -- -- -- ----------

for a given @xmath , with

  -- -------- --
     @xmath   
  -- -------- --

Proof For convenience, we will follow the scheme of the proof in [ Pös01
] and add two more steps allowing us, later, as we said, to estimate the
Lipschitz’ semi–norm of the symplectic transformation we are going to
build–up without invoking the Whitney’s extension theorem.
1. Truncation. Let @xmath , the linerization of @xmath and @xmath . Then
by Cauchy’s estimate we get

  -- -------- --
     @xmath   
  -- -------- --

And

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

By Lemma 2.2.4 , we have

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

because @xmath and, later, @xmath will be chosen so that @xmath .
2. Extending the Diophantine condition. The Diophantine condition
(compare ( 1.2.1 )) is assumed to hold only on @xmath . Nevertheless,
given @xmath , there exits @xmath such that @xmath , so that, for any
@xmath

  -- -------- --
     @xmath   
  -- -------- --

and thanks to ( 1.2.1 ), we get, for any @xmath

  -- -------- -- ----------
     @xmath      (2.3.68)
  -- -------- -- ----------

3. Finding the hamiltonian F by solving a homological equation. We have

  -- -------- --
     @xmath   
  -- -------- --

Let’s remind that we are looking at for a hamiltonian @xmath such that
its flow @xmath satisfies ⁵⁴ ⁵⁴ 54 In fact, rigorously, one should write
@xmath and so on.

  -- -------- --
     @xmath   
  -- -------- --

for some hamiltonian @xmath closed to a normal form and much smaller
error term @xmath . We have

  -- -------- --
     @xmath   
  -- -------- --

Next we expend @xmath around @xmath to get ⁵⁵ ⁵⁵ 55 Given a function K
and denoting the Poisson bracket by @xmath , we have

@xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Since @xmath is affine in the variable @xmath , then so is @xmath and a
fortiori @xmath ; moreover @xmath does not depend on @xmath . Therefore,
there exist analytic functions @xmath and @xmath such that @xmath (in
fact @xmath ) so that

  -- -------- -- ----------
     @xmath      (2.3.69)
  -- -------- -- ----------

Let

  -- -------- -- ----------
     @xmath      (2.3.70)
  -- -------- -- ----------

The main point is then to determine @xmath by solving the homological
equation

  -- -------- --
     @xmath   
  -- -------- --

@xmath (recall that @xmath )

  -- -------- -- ----------
     @xmath      (2.3.71)
  -- -------- -- ----------

so that we have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -- ----------
     @xmath      (2.3.72)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (2.3.73)
  -- -------- -- ----------

Since @xmath and @xmath , Lemma 2.2.5 applies to ( 2.3.71 ) and we find
@xmath with

  -- -------- -- ----------
     @xmath      (2.3.74)
  -- -------- -- ----------

Then by Cauchy’s estimate we get

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ----------
     @xmath      (2.3.75)
  -- -------- -- ----------

so that

  -- -------- --
     @xmath   
  -- -------- --

and by using assumption @xmath , we get

  -- -------- -- ----------
     @xmath      (2.3.76)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.3.77)
  -- -------- -- ----------

4. Extending the hamiltonian @xmath . Thanks to Lemma 2.2.1 , there
exists a cut–off @xmath with @xmath and @xmath on @xmath . Now we extend
@xmath , witch we call @xmath , as follows: @xmath on @xmath and @xmath
on @xmath . Thus

-   @xmath concide with @xmath on @xmath , is continuous on @xmath ,
    @xmath on @xmath and for any @xmath given, the map @xmath is
    real–analytic with holomorphic extention to @xmath .

-   -- -------- -------- -- ----------
         @xmath   @xmath      (2.3.78)
         @xmath   @xmath      (2.3.79)
         @xmath   @xmath      (2.3.80)
      -- -------- -------- -- ----------

    and by using ( 2.2.1 ), ( 2.3.74 ) and ( 2.3.75 ), we get

      -- -------- -------- -------- -- ----------
         @xmath   @xmath   @xmath      (2.3.81)
                  @xmath   @xmath      (2.3.82)
      -- -------- -------- -------- -- ----------

5. Transforming coordinates. As we said, the coordinates transformation
@xmath is obtained as the time–1–map of the flow @xmath of the
hamiltonian @xmath with equations of motion

  -- -------- --
     @xmath   
  -- -------- --

By using ( 2.3.79 ) and ( 2.3.80 ), we deduce that, given @xmath , the
flow @xmath is well–defined, real–analytic with holomorphic extention to
@xmath and @xmath in @xmath on @xmath for any @xmath , with

  -- -------- -- ----------
     @xmath      (2.3.83)
  -- -------- -- ----------

and, setting @xmath , we have

  -- -------- -- ----------
     @xmath      (2.3.84)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.3.85)
  -- -------- -- ----------

Moreover, since @xmath is affine in the variable @xmath , then so is
@xmath and then @xmath so that @xmath and @xmath do not depend on @xmath
, therefore the jacobian of @xmath is of the form

  -- -------- -- ----------
     @xmath      (2.3.86)
  -- -------- -- ----------

with, by using Cauchy’s estimate, the following bounds

  -- -------- -------- -- ----------
     @xmath   @xmath      (2.3.87)
     @xmath   @xmath      (2.3.88)
     @xmath   @xmath      (2.3.89)
     @xmath   @xmath      (2.3.90)
     @xmath   @xmath      (2.3.91)
  -- -------- -------- -- ----------

6. New error term estimate. To estimate @xmath (compare ( 2.3.70 )), we
need to estimate @xmath . By Cauchy’s estimate, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and therefore

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Hence

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (2.3.92)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ----------

7. Transforming frequencies. In view of ( 2.3.69 ), we need to invert
the map

  -- -------- --
     @xmath   
  -- -------- --

But we have

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we apply Lemma 2.2.9 and get a real analytic map @xmath ,
inverse of @xmath and satisfies

  -- -------- --
     @xmath   
  -- -------- --

Now we extend @xmath : by Lemma 2.2.1 , there exists a cut–off @xmath
with @xmath on @xmath . Then let @xmath on @xmath and @xmath on @xmath .
Thus, setting

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

we have @xmath on @xmath , with all the required properties. Moreover,

  -- -------- -- ----------
     @xmath      (2.3.93)
  -- -------- -- ----------

and

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      (2.3.94)
  -- -------- -------- -- ----------

So, in particular, @xmath is @xmath –diffeomorphism from @xmath onto
itself and since ⁵⁶ ⁵⁶ 56 because @xmath and @xmath will be chosen (just
below) in such away that @xmath so that @xmath . @xmath outside of
@xmath then @xmath is @xmath –diffeomorphism from @xmath onto itself.
8. Estimating @xmath . By ( 2.3.84 ), ( 2.3.85 ) and ( 2.3.93 ), we have
⁵⁷ ⁵⁷ 57 Recall that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Now ⁵⁸ ⁵⁸ 58 Recall that @xmath denotes the Jacobian of @xmath w.r.t
@xmath , @xmath the Jacobian of @xmath w.r.t @xmath and @xmath means
@xmath . , since

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , then by ( 2.3.87 )–( 2.3.91 ) and ( 2.3.94 ), we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Since @xmath , then the estimates on @xmath are proven.

###### 2.3.3.2 Iteration of the KAM step

Since we are going to iterate the KAM step infinitely many times, we
need to choose the sequences @xmath conveniently so that at each step,
all the assumptions in the KAM step hold. See [ Pös01 ] , for details on
how those sequences are choosen. First, we set up the sequences, then we
prove that at each step they meet all the assumptions in KAM step and
then we prove the iterative lemma.
Let then @xmath and (recall ¹⁶ )
@xmath @xmath @xmath @xmath @xmath
@xmath Thus the following hold

###### Lemma 2.3.6

For any @xmath ,
@xmath

Proof @xmath As @xmath is decreasing (super–exponentially) and @xmath
then it is enough to check it for @xmath . But by definitions, we have

  -- -------- --
     @xmath   
  -- -------- --

@xmath By definitions, it follows ⁵⁹ ⁵⁹ 59 See Appendix A .

  -- -------- --
     @xmath   
  -- -------- --

Now let @xmath and assume

  -- -------- --
     @xmath   
  -- -------- --

Then, by using the above definitions we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which ends the proof of @xmath and @xmath .
@xmath We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

@xmath We have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Now we arrive to the iterative lemma. Given @xmath , let ⁶⁰ ⁶⁰ 60 Notice
that @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Then, by the definitions, we have @xmath and @xmath . Thus,

  -- -------- --
     @xmath   
  -- -------- --

In particular for any @xmath ,

  -- -------- -- ----------
     @xmath      (2.3.95)
  -- -------- -- ----------

###### Lemma 2.3.7

Suppose @xmath is real analytic on @xmath with

  -- -------- --
     @xmath   
  -- -------- --

Then for each @xmath , there exist a normal form @xmath and a
transformation
@xmath such that

-   @xmath is a @xmath –diffeomorphism with @xmath on @xmath and @xmath
    is a ( @xmath –) family of real–anatylitic, symplectic
    transformations parametrized over @xmath and @xmath in @xmath ;

-   @xmath is Lipschitz–continuous in @xmath with

      -- -------- -- ----------
         @xmath      (2.3.96)
      -- -------- -- ----------

    uniformly on @xmath .

-    The restriction @xmath is real–analytic with holomorphic extension
    to @xmath for each given @xmath and satisfies @xmath , @xmath with

      -- -------- --
         @xmath   
      -- -------- --

Furthermore

  -- -------- -- ----------
     @xmath      (2.3.97)
  -- -------- -- ----------

Proof For @xmath we take @xmath and we are done.
Next we pick @xmath and we assume that it holds at the step @xmath .
Then we have to check it for the step @xmath . But, thanks to lemma
2.3.6 , we can apply the KAM step to @xmath to get a transformation
@xmath for which every properties in KAM step hold. So, its restriction

  -- -------- --
     @xmath   
  -- -------- --

and there exists a normal form @xmath such that @xmath with

  -- -------- --
     @xmath   
  -- -------- --

Then we apply @xmath of lemma 2.3.6 to obtain

  -- -------- --
     @xmath   
  -- -------- --

Therefore

  -- -------- --
     @xmath   
  -- -------- --

is a transformation such that @xmath with all the required properties in
@xmath and @xmath .
It remains the estimates on @xmath . By ( 2.3.65 ) and ( 2.3.66 ) we
have ⁶¹ ⁶¹ 61 Notice that @xmath .

  -- -- -------- -------- -------- ----------
                 @xmath            (2.3.98)
                 @xmath   @xmath   
                 @xmath   @xmath   
        @xmath   @xmath            (2.3.99)
  -- -- -------- -------- -------- ----------

Thus

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Next, we need to bound @xmath uniformly on @xmath . But for any @xmath ,
we have ⁶² ⁶² 62 Recall that any @xmath , @xmath .

  -- -------- -------- -- -----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (2.3.100)
  -- -------- -------- -- -----------

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so that,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Therefore,

  -- -------- --
     @xmath   
  -- -------- --

Finally, using again ( 2.3.98 ) and ( 2.3.100 ), we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, letting

  -- -------- --
     @xmath   
  -- -------- --

we get, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

so that, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

In particular, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

i.e. ⁶³ ⁶³ 63 Recall that @xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

###### 2.3.3.3 Deduction of Theorem 2.1.4

We set @xmath ; thus Lemma 2.3.7 applies. Hence, by ( 2.3.97 ), @xmath
is a Cauchy sequence and therefore converges uniformly to some @xmath on

  -- -------- --
     @xmath   
  -- -------- --

with the map @xmath real analytic on @xmath for each given @xmath (by
Weierstrass’s theorem) and for any @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and letting @xmath , we get, uniformly on @xmath ,

  -- -------- -- -----------
     @xmath      (2.3.101)
  -- -------- -- -----------

Moreover, by letting @xmath in ( 2.3.96 ), we get, uniformly on @xmath ,

  -- -------- -- -----------
     @xmath      (2.3.102)
  -- -------- -- -----------

Let’s prove that @xmath is a lipeomorphism from @xmath onto itself.
Indeed, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

so that ⁶⁴ ⁶⁴ 64 Recall that @xmath , so that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, @xmath is a lipeomorphism (Lipschitz continuous bijection with
inverse Lipschitz continuous as well) from @xmath onto itself closed to
the identity. Furthermore, @xmath outside of @xmath since each @xmath is
so, so that @xmath restricted to @xmath is a lipeomorphism from @xmath
onto itself.
Next, we prove that for each @xmath , @xmath is an invariant Kronecker
torus for @xmath . Indeed, by letting @xmath in Iterative Lemma , @xmath
, we obtain

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Thus,

  -- -------- --
     @xmath   
  -- -------- --

on @xmath .
It remains just to prove that the tori are Lagragian. Indeed, since
@xmath for any @xmath , each @xmath is symplectic and @xmath is smooth,
then we have, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 2.3.8

Notice that one could apply Lemma 2.2.2 as well to prove that @xmath is
a lipeomorphism, provided that @xmath is chosen a little bigger. In
fact, by ( 2.3.67 ), we have ⁶⁵ ⁶⁵ 65 Recall the notations in the proof
of Iterative Lemma.

  -- -------- --
     @xmath   
  -- -------- --

Thus, for

  -- -------- --
     @xmath   
  -- -------- --

by taking With @xmath , since @xmath , for any @xmath so that we apply
again Lemma 2.2.2 to get

  -- -------- --
     @xmath   
  -- -------- --

Therefore

  -- -------- --
     @xmath   
  -- -------- --

### Chapter 3 Comparison of the KAM theorems on a mechanical Hamiltonian

We consider the simple mechanical Hamiltonian ⁶⁶ ⁶⁶ 66 As usual, @xmath
.

  -- -------- --
     @xmath   
  -- -------- --

and we choose

  -- -------- --
     @xmath   
  -- -------- --

Moreover, we have

  -- -------- -- ---------
     @xmath      (3.0.1)
  -- -------- -- ---------

#### 3.1 Application of Theorem 2.1.1

By ( 3.0.1 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Hence ⁶⁷ ⁶⁷ 67 See @xmath for an idea to compute @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Therefore, Theorem 2.1.1 holds for

  -- -------- -- ---------
     @xmath      (3.1.1)
  -- -------- -- ---------

#### 3.2 Application of Theorem 2.1.2

By the very definition of @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

so that ⁶⁸ ⁶⁸ 68 See @xmath for an idea to compute @xmath and @xmath ;
for the later, writing @xmath , one can just choose the family @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Therefore, Theorem 2.1.2 holds for

  -- -------- -- ---------
     @xmath      (3.2.1)
  -- -------- -- ---------

where

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

#### 3.3 Application of Theorem 2.1.4

By ( 3.0.1 ), we have

  -- -------- --
     @xmath   
  -- -------- --

We choose

  -- -------- --
     @xmath   
  -- -------- --

with @xmath as in ( 2.1.9 ) and @xmath . Next, we compute @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Now, choosing

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Therefore,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Consequently, if

  -- -------- -- ---------
     @xmath      (3.3.1)
  -- -------- -- ---------

then Theorem 2.1.4 holds.

#### 3.4 Application of Theorem 2.1.6

We choose

  -- -------- --
     @xmath   
  -- -------- --

Thus,

  -- -- --
        
  -- -- --

Therefore, we can take

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Next, we compute @xmath . We have,

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

But then, taking @xmath if @xmath and

  -- -------- --
     @xmath   
  -- -------- --

we obtain

  -- -- --
        
  -- -- --

Hence

  -- -------- --
     @xmath   
  -- -------- --

It remains the choice of @xmath . Writting

  -- -------- -- ---------
     @xmath      (3.4.1)
  -- -------- -- ---------

we have, for any @xmath ,

  -- -------- -- ---------
     @xmath      (3.4.2)
  -- -------- -- ---------

so that

  -- -- -------- --
                 
                 
                 
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
  -- -- -------- --

Therefore

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
  -- -------- -------- --

Therefore, Theorem 2.1.6 holds for

  -- -------- -- ---------
     @xmath      (3.4.3)
  -- -------- -- ---------

In particular, for @xmath , we have the following.

###### Corollary 3.4.1

Consider the hamiltonian @xmath and @xmath . Then, for any @xmath ,
there exists a Kronecker’s invariant torus @xmath for @xmath i.e.

  -- -- --
        
  -- -- --

### Chapter 4 Global symplectic extension of Arnold’s theorem

#### 4.1 Assumptions

Let @xmath be a non--empty, bounded domain ⁶⁹ ⁶⁹ 69 i.e. open and
connected. and consider the Hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are real--analytic functions with bounded holomorphic
extensions to ⁷⁰ ⁷⁰ 70 Recall the notations in @xmath

  -- -------- --
     @xmath   
  -- -------- --

the norm being

  -- -------- --
     @xmath   
  -- -------- --

Assume that

  -- -------- -- ---------
     @xmath      (4.1.1)
  -- -------- -- ---------

Define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Finally, for @xmath given, let ⁷¹ ⁷¹ 71 Recall from footnote ¹³ that
@xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

#### 4.2 Statement of the extension Theorem

###### Theorem 4.2.1

Under the assumptions in @xmath , we have the following. For any given
@xmath such that ⁷² ⁷² 72 Notice that @xmath equivals to: @xmath .

  -- -------- -- ---------
     @xmath      (4.2.1)
  -- -------- -- ---------

there exist @xmath having the same cardinality as @xmath , a
lipeomorphism @xmath , a @xmath map @xmath and a @xmath
–symplectomorphism @xmath real–analytic in @xmath and such that the
following hold.

  -- -------- -------- -- ---------
     @xmath   @xmath      (4.2.2)
     @xmath   @xmath      (4.2.3)
  -- -------- -------- -- ---------

and

  -- -------- -------- -- ---------
     @xmath   @xmath      (4.2.4)
     @xmath   @xmath      (4.2.5)
  -- -------- -------- -- ---------

where

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 4.2.2

From ( 4.2.3 ), on deduces that the @xmath –tori

  -- -- -- ---------
           (4.2.6)
  -- -- -- ---------

are non-degenrate invariant Kronecker tori for @xmath i.e.

  -- -------- -- ---------
     @xmath      (4.2.7)
  -- -------- -- ---------

#### 4.3 Proof of Theorem 4.2.1

KAM step Given @xmath satisfying the assumptions , we seek for @xmath ,
a set @xmath having the same cardinality as @xmath and a
near–to–the–identity real–analytic symplectic transformation @xmath
satisfying

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath generated by an extension @xmath of a function of
the form @xmath i.e.

  -- -------- -- ---------
     @xmath      (4.3.1)
  -- -------- -- ---------

such that

  -- -------- -- ---------
     @xmath      (4.3.2)
  -- -------- -- ---------

By Taylor’s formula, we get ⁷³ ⁷³ 73 Recall that @xmath stands for the
average over @xmath .

  -- -------- -------- -------- ---------
     @xmath   @xmath            (4.3.3)
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- ---------

with @xmath , which will be chosen large enough so that @xmath , @xmath
and

  -- -- -- ---------
           (4.3.4)
  -- -- -- ---------

By the non–degeneracy condition in ( 4.1.1 ) and Lemma 2.2.7 , for
@xmath small enough (to be made precised below), there exists @xmath
such that for each @xmath , there exists a unique @xmath satisfying
@xmath and @xmath ; @xmath is precisely the set of those @xmath when
@xmath runs in @xmath . More precisely, @xmath and @xmath are
‘‘diffeomorphic’’ ⁷⁴ ⁷⁴ 74 i.e. there a exits a bijection from @xmath
onto @xmath which extends to a diffeomorphism on some neighborhood of
@xmath . , say via @xmath , and, for each @xmath , the matrix @xmath is
invertible with inverse of the form

  -- -------- --
     @xmath   
  -- -------- --

Write

  -- -------- -- ---------
     @xmath      (4.3.5)
  -- -------- -- ---------

In view of ( 4.3.3 ), in order to get the first part of ( 4.3.2 ), we
need to find @xmath such that @xmath vanishes; such a @xmath is indeed
given by

  -- -------- -- ---------
     @xmath      (4.3.6)
  -- -------- -- ---------

provided that

  -- -------- -- ---------
     @xmath      (4.3.7)
  -- -------- -- ---------

But, in fact, since @xmath is rationally independent, for each @xmath ,
then, given any @xmath , there exists @xmath such that

  -- -------- -- ---------
     @xmath      (4.3.8)
  -- -------- -- ---------

Then we invert the function @xmath in order to define @xmath . But, by
Lemma 2.2.6 , for @xmath small enough, the map @xmath admits an
real–analytic inverse of the form

  -- -------- -- ---------
     @xmath      (4.3.9)
  -- -------- -- ---------

so that the Arnod’s symplectic transformation is given by

  -- -------- -- ----------
     @xmath      (4.3.10)
  -- -------- -- ----------

Hence, ( 4.3.2 ) holds with

  -- -------- -- ----------
     @xmath      (4.3.11)
  -- -------- -- ----------

Finally, we extend @xmath .

Next, we make a quantitative evaluation of the above construction.
Assume that ⁷⁵ ⁷⁵ 75 In the sequel, @xmath and @xmath stand for generic
real analytic Hamiltonians which, later on, will respectively play the
roles of @xmath and @xmath , and @xmath , the roles of @xmath in the
iterative step. @xmath , where @xmath are real–analytic functions with
bounded holomorphic extensions to @xmath and

  -- -- -------- -------- ----------
        @xmath            (4.3.12)
                 @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- ----------

Fix @xmath and fix @xmath in such away that,

  -- -- -------- -------- ----------
        @xmath            (4.3.13)
                 @xmath   
  -- -- -------- -------- ----------

so that ⁷⁶ ⁷⁶ 76 Recall footnote ⁴² .

  -- -------- -- ----------
     @xmath      (4.3.14)
  -- -------- -- ----------

###### Lemma 4.3.1

Let ⁷⁷ ⁷⁷ 77 Notice that @xmath since @xmath . Notice also that @xmath ,
so that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Then

  -- -------- -- ----------
     @xmath      (4.3.15)
  -- -------- -- ----------

If @xmath satisfies

  -- -------- -- ----------
     @xmath      (4.3.16)
  -- -------- -- ----------

then, for any @xmath , there exists a diffeomorphism @xmath , @xmath and
such that @xmath ,

  -- -- -- ----------
           (4.3.17)
  -- -- -- ----------

and the following hold. @xmath has and extension @xmath and, for any
@xmath and @xmath , the map @xmath has an analytic inverse @xmath such
that, for all @xmath ,

  -- -------- -- ----------
     @xmath      (4.3.18)
  -- -------- -- ----------

for any @xmath and @xmath , @xmath ; the map @xmath is a symplectic
diffeomorphism and

  -- -------- -- ----------
     @xmath      (4.3.19)
  -- -------- -- ----------

with

  -- -------- -- ----------
     @xmath      (4.3.20)
  -- -------- -- ----------

where @xmath is defined by the relation @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -- -------- -- ----------
        @xmath      (4.3.21)
  -- -- -------- -- ----------

Moreover, @xmath possesses a @xmath –extensions @xmath such that for any
@xmath , there exists @xmath and for any @xmath with @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      (4.3.22)
     @xmath   @xmath      (4.3.23)
  -- -------- -------- -- ----------

Proof We begin by extending the “diophantine condition w.r.t. @xmath ”
uniformly to @xmath up to the order @xmath . Indeed, for any @xmath ,
@xmath and @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      (4.3.24)
  -- -------- -------- -- ----------

so that, by Lemma 2.2.4 – @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and analogously,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

and, for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Now, we extend the generating function and @xmath to @xmath and @xmath
respectively, by making use of a cut–off function. Let then @xmath ,
with @xmath on @xmath and satisfying ( 2.2.1 ). Thus, given @xmath , set
@xmath if @xmath , @xmath if @xmath and @xmath on @xmath .

  -- -------- -------- -- ----------
     @xmath   @xmath      (4.3.25)
     @xmath   @xmath      (4.3.26)
     @xmath   @xmath      (4.3.27)
     @xmath   @xmath      (4.3.28)
  -- -------- -------- -- ----------

And generally, for any @xmath , there exists @xmath and for any @xmath
with @xmath ,

  -- -------- -- ----------
     @xmath      (4.3.29)
  -- -------- -- ----------

( 4.3.23 ) is a straightforward consequence of Leibniz’s rule.
Next, we construct @xmath in ( 4.3.2 ) for @xmath . For, fix @xmath ,
@xmath and consider

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then

-   @xmath and

      -- -------- -------- --
         @xmath   @xmath   
      -- -------- -------- --

    Hence, @xmath is invertible, with inverse

      -- -------- --
         @xmath   
      -- -------- --

    satisfying

      -- -------- -- ----------
         @xmath      (4.3.30)
      -- -------- -- ----------

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

    i.e.

      -- -------- --
         @xmath   
      -- -------- --

Therefore, Lemma 2.2.6 applies. Hence, there exists a real–analytic map
@xmath such that its graph coincides with @xmath i.e. @xmath is the
unique @xmath satisfying @xmath , for any @xmath . Moreover, @xmath ,

  -- -------- -- ----------
     @xmath      (4.3.31)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (4.3.32)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (4.3.33)
  -- -------- -- ----------

Next, we prove that @xmath is invertible, where @xmath for some given
@xmath . Indeed, by Taylor’s formula, we have,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, by Cauchy’s estimate, for any ⁷⁸ ⁷⁸ 78 Recall footnote ⁴² . @xmath
,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence @xmath is invertible with

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Similarly, from

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

one has that, for any @xmath ,

  -- -------- -- ----------
     @xmath      (4.3.34)
  -- -------- -- ----------

Now, differentiating @xmath , we get, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Therefore @xmath is a local diffeomorphism, with

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- -- ----------
     @xmath      (4.3.35)
  -- -------- -- ----------

Now, we show that the family @xmath is compatible so that, together,
they define a global map on @xmath , say @xmath and that, in fact,
@xmath is a real–analytic diffeomorphism. For, assume that @xmath , for
some @xmath . Then, we need to show that @xmath . But, we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath and, by definitions, @xmath . Then, by unicity, we get
@xmath . Thus, the map

  -- -------- --
     @xmath   
  -- -------- --

is well–defined and, therefore, is a real–analytic local diffeomorphism.
It remains only to check that @xmath is injective to conclude that it is
a global diffeomorphism. Let then @xmath such that @xmath , for some
@xmath . Then, we have

  -- -------- --
     @xmath   
  -- -------- --

Indeed, if not then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

contradiction. Therefore,

  -- -------- -- ----------
     @xmath      (4.3.36)
  -- -------- -- ----------

Thus,

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath . But @xmath is equivalent to @xmath and then,

  -- -------- --
     @xmath   
  -- -------- --

Thus, it is enough to show that @xmath is invertible. But

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, @xmath is invertible and then we get @xmath i.e. @xmath is
injective.
Next, we estimate @xmath . We have, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

so that, for any @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and, by Lemma – @xmath , we have

  -- -- -------- --
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
  -- -- -------- --

Hence, ⁷⁹ ⁷⁹ 79 Recall that @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, we need to invert @xmath . But, thanks to ( 4.3.27 ), ( 4.3.28 ), (
4.3.29 ) and ( 4.3.16 ), we can apply Lemma B.1 (see Appendix B ), to
conclude that for any given @xmath , the map @xmath has an inverse
@xmath , @xmath on @xmath and real analytic on @xmath such that ( 4.3.18
) holds and ( 4.3.22 ) as well, using the multivariate Fàa Di Bruno
formula (see [ CS96 ] , Theorem @xmath ) and the real–analyticity of
@xmath .

Finally, we prove the convergence of the scheme by mimicking Lemma 2.3.2
.

###### Lemma 4.3.2

Let @xmath , @xmath , @xmath , @xmath , and @xmath , @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath , @xmath , @xmath , @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath , @xmath and @xmath be as in @xmath
and for a given @xmath , sequence of non–negative numbers @xmath and
@xmath , define ⁸⁰ ⁸⁰ 80 Notice that @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Assume that @xmath satisfies

  -- -------- -- ----------
     @xmath      (4.3.37)
  -- -------- -- ----------

where

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then, for any @xmath , one can construct a sequence of diffeomorphisms

  -- -------- --
     @xmath   
  -- -------- --

and of @xmath –symplectomorphisms

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -------- -- ----------
     @xmath      (4.3.38)
     @xmath      (4.3.39)
     @xmath      (4.3.40)
  -- -------- -- ----------

and converge uniformly. More precisely, given any @xmath , we have the
following:

-    the sequence @xmath converges uniformely on @xmath to a
    lipeomorphism @xmath ;

-   @xmath converges uniformly on @xmath to @xmath , for any @xmath ;

-   @xmath converges uniformly on @xmath to a @xmath –symplectomorphism
    @xmath , with @xmath holomorphic, for any @xmath ;

-   @xmath converges uniformly on @xmath to a @xmath –map @xmath , with

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

Finally, the following estimates hold for any @xmath and for any @xmath
:

  -- -------- -------- -- ----------
     @xmath   @xmath      (4.3.41)
     @xmath   @xmath      (4.3.42)
     @xmath   @xmath      (4.3.43)
  -- -------- -------- -- ----------

Proof For @xmath , define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Let us assume ( inductive hypothesis ) that we can iterate @xmath times
the KAM step, obtaining @xmath diffeomorphisms

  -- -------- --
     @xmath   
  -- -------- --

and @xmath @xmath –symplectomorphisms

  -- -------- -- ----------
     @xmath      (4.3.44)
  -- -------- -- ----------

satisfying @xmath , for @xmath , with

  -- -------- -- ----------
     @xmath      (4.3.45)
  -- -------- -- ----------

Observe that for @xmath , it is @xmath and ( 4.3.45 ) is implied by the
definitions of @xmath and by condition ( 4.3.37 ).

Because of ( 4.3.37 ) and ( 4.3.45 ), ( 4.3.16 ) holds for @xmath and
Lemma 4.3.1 can be applied to @xmath and one has, for @xmath and for any
@xmath (see ( 4.3.15 ), ( 4.3.17 ) and ( 4.3.21 )):

  -- -------- -------- -- ----------
     @xmath   @xmath      (4.3.46)
     @xmath   @xmath      (4.3.47)
     @xmath   @xmath      (4.3.48)
     @xmath   @xmath      (4.3.49)
     @xmath   @xmath      (4.3.50)
              @xmath      (4.3.51)
     @xmath   @xmath      (4.3.52)
  -- -------- -------- -- ----------

Let @xmath . Then, by definition,

  -- -------- -- ----------
     @xmath      (4.3.53)
  -- -------- -- ----------

and, since @xmath i.e.

  -- -------- -- ----------
     @xmath      (4.3.54)
  -- -------- -- ----------

we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and for @xmath ⁸¹ ⁸¹ 81 Notice that @xmath . ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

thus by ( 4.3.52 ), for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e. @xmath , which iterated, yields @xmath for @xmath . Next, we show
that, thanks to ( 4.3.37 ), ( 4.3.45 ) holds also for @xmath . In fact,
by ( 4.3.45 ) and ( 4.3.50 ), we have

  -- -------- --
     @xmath   
  -- -------- --

and similarly for @xmath . Now, we check the last relation in ( 4.3.45 )
for @xmath . But, by definitions, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

which iterated yields, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

Now, by @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which implies the fourth inequality in ( 4.3.45 ) with @xmath ; the
proof of the induction is finished and one can construct an infinite
sequence of diffeomorphisms @xmath and symplectomorphisms @xmath
satisfying ( 4.3.45 ), @xmath , ( 4.3.41 ) and @xmath for all @xmath .
Next, we show that @xmath converges. For any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Thus, @xmath is Cauchy and therefore converges uniformly on @xmath to a
map @xmath .

Next, we prove that @xmath is convergent by showing that it is Cauchy as
well. For any @xmath , we have, using again Cauchy’s estimate,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, for any @xmath ,

  -- -- -------- --
        @xmath   
        @xmath   
        @xmath   
        @xmath   
                 
                 
                 
        @xmath   
  -- -- -------- --

Hence @xmath converges uniformly on @xmath to some @xmath , which is
then real–analytic function on @xmath .

To estimate @xmath , observe that , for @xmath , ⁸² ⁸² 82 Notce that
@xmath .

  -- -- --
        
  -- -- --

and therefore

  -- -------- --
     @xmath   
  -- -------- --

Moreover,

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which iterated yields

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, taking the limit over @xmath completes the proof of ( 4.3.43
).

Next, we show that @xmath , which will imply that ⁸³ ⁸³ 83 See
Proposition II.2. in [ Zeh10 ] . @xmath is a lipeomorphism. Indeed, for
any @xmath , there exists @xmath such that the restricted maps @xmath ,
@xmath with @xmath , are well--defined ⁸⁴ ⁸⁴ 84 i.e. @xmath , @xmath .
and, therefore,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which iterated leads to ⁸⁵ ⁸⁵ 85 Recall that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, @xmath is Lipschitz continuous, with

  -- -------- --
     @xmath   
  -- -------- --

so that, by ⁸⁶ ⁸⁶ 86 With @xmath . Lemma D.1 (see Appendix D ), we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

which proves ( 4.3.42 ), Lemma 4.3.2 and, whence, the extension Theorem.

### Chapter 5 A “sharp” version of Arnold’s theorem

#### 5.1 Assumptions

Let @xmath and consider the hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -------- -- ---------
     @xmath      (5.1.1)
  -- -------- -- ---------

Set

  -- -------- --
     @xmath   
  -- -------- --

Finally, define ⁸⁷ ⁸⁷ 87 Recall from footnote ¹³ that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

#### 5.2 Statement of the KAM Theorem

###### Theorem 5.2.1

Under the assumptions in @xmath , the following holds. Let

  -- -------- -- ---------
     @xmath      (5.2.1)
  -- -------- -- ---------

and assume that

  -- -------- -- ---------
     @xmath      (5.2.2)
  -- -------- -- ---------

Assume

  -- -------- -- ---------
     @xmath      (5.2.3)
  -- -------- -- ---------

Then, there exist @xmath and an embedding @xmath real–analytic on @xmath
and close to the trivial embedding

  -- -------- --
     @xmath   
  -- -------- --

and such that the @xmath –torus

  -- -------- -- ---------
     @xmath      (5.2.4)
  -- -------- -- ---------

is a non-degenerate invariant Kronecker torus for @xmath i.e.

  -- -------- -- ---------
     @xmath      (5.2.5)
  -- -------- -- ---------

Moreover,

  -- -------- -------- -- ---------
     @xmath   @xmath      (5.2.6)
     @xmath   @xmath      (5.2.7)
  -- -------- -------- -- ---------

uniformly on @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

#### 5.3 Proof of Theorem 5.2.1

###### Lemma 5.3.1 (KAM step)

Let @xmath and consider the hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

Assume that ⁸⁸ ⁸⁸ 88 In the sequel, @xmath and @xmath stand for generic
real analytic hamiltonians which, later on, will respectively play the
roles of @xmath and @xmath , and @xmath , the roles of @xmath in the
iterative step. ^(,) ⁸⁹ ⁸⁹ 89 Notice that @xmath .

  -- -- -------- -------- ---------
        @xmath            (5.3.1)
                 @xmath   
                 @xmath   
  -- -- -------- -------- ---------

Fix @xmath and assume that

  -- -------- -- ---------
     @xmath      (5.3.2)
  -- -------- -- ---------

Let

  -- -- -------- -------- ---------
        @xmath            (5.3.3)
                 @xmath   
  -- -- -------- -------- ---------

and ⁹⁰ ⁹⁰ 90 Notice that @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath            
              @xmath   
  -- -------- -------- --

Then, there exists a generating function @xmath with the following
properties:

  -- -------- -- ---------
     @xmath      (5.3.4)
  -- -------- -- ---------

where

  -- -- --
        
  -- -- --

If, in addition,

  -- -------- -- ---------
     @xmath      (5.3.5)
  -- -------- -- ---------

then, there exists @xmath such that

  -- -- -- ---------
           (5.3.6)
  -- -- -- ---------

where

  -- -------- --
     @xmath   
  -- -------- --

and the following hold. For @xmath , the map @xmath has an analytic
inverse @xmath such that

  -- -- -- ---------
           (5.3.7)
  -- -- -- ---------

for any @xmath , @xmath ; the map @xmath is a symplectic diffeomorphism
and

  -- -------- -- ---------
     @xmath      (5.3.8)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (5.3.9)
  -- -------- -- ---------

where @xmath is defined by the relation @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ----------
     @xmath      (5.3.10)
  -- -------- -- ----------

with

  -- -------- --
     @xmath   
  -- -------- --

Proof

Step 1: Construction of the Arnold’s transformation We seek for a
near–to–the–identity symplectic transformation

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , generated by a function of the form @xmath , so that

  -- -------- -- ----------
     @xmath      (5.3.11)
  -- -------- -- ----------

such that

  -- -------- -- ----------
     @xmath      (5.3.12)
  -- -------- -- ----------

By Taylor’s formula, we get ⁹¹ ⁹¹ 91 Recall that @xmath stands for the
average over @xmath .

  -- -------- -------- -------- ----------
     @xmath   @xmath            (5.3.13)
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- ----------

with @xmath , which will be chosen large enough so that @xmath and

  -- -- -- ----------
           (5.3.14)
  -- -- -- ----------

By the non–degeneracy condition in ( 5.3.1 ), for @xmath small enough
(to be made precised below), @xmath and, therefore, by Lemma 2.2.6 ,
there exists a unique @xmath such that the second part of ( 5.3.12 )
holds. In view of ( 5.3.13 ), in order to get the first part of ( 5.3.12
), we need to find @xmath such that @xmath vanishes; such a @xmath is
indeed given by

  -- -------- -- ----------
     @xmath      (5.3.15)
  -- -------- -- ----------

provided that

  -- -------- -- ----------
     @xmath      (5.3.16)
  -- -------- -- ----------

But, in fact, since @xmath is rationally independent, then, given any
@xmath , there exists @xmath such that

  -- -------- -- ----------
     @xmath      (5.3.17)
  -- -------- -- ----------

The last step is to invert the function @xmath in order to define @xmath
. But, by Lemma 2.2.6 , for @xmath small enough, the map @xmath admits
an real–analytic inverse of the form

  -- -------- -- ----------
     @xmath      (5.3.18)
  -- -------- -- ----------

so that the Arnod’s symplectic transformation is given by

  -- -------- -- ----------
     @xmath      (5.3.19)
  -- -------- -- ----------

Hence, ( 5.3.12 ) holds with

  -- -------- -- ----------
     @xmath      (5.3.20)
  -- -------- -- ----------

Step 2: Quantitative estimates
First of all, notice that ⁹² ⁹² 92 Recall footnote ⁴² .

  -- -------- -- ----------
     @xmath      (5.3.21)
  -- -------- -- ----------

We begin by extending the “diophantine condition w.r.t. @xmath ”
uniformly to @xmath up to the order @xmath . Indeed, by the Mean Value
Inequality and @xmath , we get, for any @xmath and any @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      (5.3.22)
  -- -------- -------- -- ----------

so that, by Lemma 2.2.4 – @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, analogously,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Next, we prove the existence and uniqueness of @xmath in ( 5.3.12 ).
Consider then

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then

-   @xmath ;

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   Recalling @xmath , we have

      -- -------- -------- -- ----------
         @xmath   @xmath      
                  @xmath      
                  @xmath      
                  @xmath      
                  @xmath      (5.3.23)
                  @xmath      
                  @xmath      
      -- -------- -------- -- ----------

Therefore, Lemma 2.2.6 applies. Hence, there exists a function @xmath
such that its graph coincides with @xmath . In particular, @xmath is the
unique @xmath satisfying @xmath i.e. the second part of ( 5.3.12 ).
Moreover,

  -- -------- -- ----------
     @xmath      (5.3.24)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (5.3.25)
  -- -------- -- ----------

Next, we prove that @xmath is invertible. Indeed, by Taylor’ formula, we
have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, by Cauchy’s estimate,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence @xmath is invertible with

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Next, we prove estimate on @xmath . We have,

  -- -------- --
     @xmath   
  -- -------- --

so that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and by Lemma 2.2.4 – @xmath , we have,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence ⁹³ ⁹³ 93 Recall that @xmath . ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The proof of the claims on @xmath and @xmath are proven in a similar way
as in Lemma 2.3.1 .

Finally, we prove the convergence of the scheme by mimicking Lemma 2.3.2
.
Let @xmath , @xmath , @xmath and @xmath , @xmath , @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath , @xmath be as in @xmath and for a
given @xmath and @xmath , define ⁹⁴ ⁹⁴ 94 Notice that @xmath and @xmath
.

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
     @xmath            
              @xmath   
  -- -------- -------- --

Thus, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

The very first step being quite different from all the others, it has to
be done separately. Hence,

###### Lemma 5.3.2

Under the above assumptions and notations, if

  -- -------- -- ----------
     @xmath      (5.3.26)
  -- -------- -- ----------

then, there exist @xmath and a real–analytic symplectomorphism

  -- -------- -- ----------
     @xmath      (5.3.27)
  -- -------- -- ----------

such that, for @xmath , we have

  -- -------- -- ----------
     @xmath      (5.3.28)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (5.3.29)
     @xmath      (5.3.30)
     @xmath      (5.3.31)
     @xmath      (5.3.32)
  -- -------- -- ----------

Proof By

  -- -------- -- ----------
     @xmath      (5.3.33)
  -- -------- -- ----------

and

  -- -------- --
     @xmath   
  -- -------- --

we get

  -- -------- -- ----------
     @xmath      (5.3.34)
  -- -------- -- ----------

and, thus

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (5.3.35)
  -- -------- -------- -- ----------

Therefore, Lemma 5.3.2 is a straightforward consequence of Lemma 5.3.1 .

Once the first step is completed, all the following steps do not need
any other condition. Actually, they are “completely” independent upon
@xmath , and, therefore, the first condition in ( 5.3.26 ) is useless.
To be precise, the following holds.

###### Lemma 5.3.3

Assume @xmath with some @xmath and

  -- -------- -- ----------
     @xmath      (5.3.36)
  -- -------- -- ----------

Then, one can construct a sequence of symplectic transformations

  -- -------- -- ----------
     @xmath      (5.3.37)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (5.3.38)
  -- -------- -- ----------

converges uniformly. More precisely, @xmath , @xmath , @xmath , @xmath
converge uniformly on @xmath to, respectively, @xmath , @xmath , @xmath
, @xmath which are real–analytic on @xmath and @xmath with @xmath .
Finally, the following estimates hold for any @xmath :

  -- -------- -- ----------
     @xmath      (5.3.39)
     @xmath      (5.3.40)
     @xmath      (5.3.41)
  -- -------- -- ----------

Proof First of all, notice that, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where

  -- -------- -- ----------
     @xmath      (5.3.42)
  -- -------- -- ----------

For a given @xmath , let @xmath be the following assertion: there exist
@xmath symplectic transformations ⁹⁵ ⁹⁵ 95 Compare ( 5.3.8 ).

  -- -------- -- ----------
     @xmath      (5.3.43)
  -- -------- -- ----------

and @xmath Hamiltonians @xmath real–analytic on @xmath such that, for
any @xmath ,

  -- -------- -- ----------
     @xmath      (5.3.44)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (5.3.45)
  -- -------- -- ----------

Assume @xmath , for some @xmath and let’s check @xmath . Fix then @xmath
. Thus

  -- -------- --
     @xmath   
  -- -------- --

and, similarly,

  -- -------- --
     @xmath   
  -- -------- --

which prove the two first relations in ( 5.3.44 ) for @xmath . Also

  -- -------- -- ----------
     @xmath      (5.3.46)
  -- -------- -- ----------

so that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

thus by last relation in ( 5.3.45 ), for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which proves the fourth relation in ( 5.3.44 ) for @xmath . Hence, by
exactly the same computation as above, one gets

  -- -------- --
     @xmath   
  -- -------- --

which proves the last relation in ( 5.3.44 ) for @xmath . It remains
only to check that the fifth relation in ( 5.3.44 ) holds as well for
@xmath in order to apply Lemma 5.3.1 to @xmath , @xmath and get ( 5.3.45
) and, consequently, @xmath . But in fact, we have ⁹⁶ ⁹⁶ 96 Notice that,
since @xmath then @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

To finish the proof of the induction i.e. one can construct an infinite
sequence of Arnold’s transformations satisfying ( 5.3.44 ) and ( 5.3.45
) for all @xmath , one needs only to check @xmath . Thanks to ⁹⁷ ⁹⁷ 97
Observe that for @xmath , @xmath . @xmath , we just need to check the
two last inequalities in @xmath . But, in fact, one proves those two
relations by exactly the same computation as above. Then, we apply Lemma
5.3.1 to @xmath to get @xmath and @xmath , which achieves the proof of
@xmath .
Next, we prove that @xmath is convergent by proving that it is Cauchy.
For any @xmath , we have, using again Cauchy’s estimate, ⁹⁸ ⁹⁸ 98 Recall
that @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, by ( 5.3.36 ), @xmath converges uniformly on @xmath to some
@xmath , which is then real–analytic map in @xmath .

To estimate @xmath on @xmath , observe that , for @xmath , ⁹⁹ ⁹⁹ 99
Recall that @xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which iterated yields

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, taking the limit over @xmath completes the proof of ( 5.3.41
), Lemma 5.3.3 .
Now, to complete the proof of the Theorem, just set @xmath and observe
that, uniformely on @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Moreover, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and then passing to the limit, we get

  -- -------- --
     @xmath   
  -- -------- --

## Part II “Sharp” measure estimates of Kolmogorov’s sets

### Chapter 6 “Explicit” integrability on a Cantor–like set and a
“sharp” measure estimate

#### 6.1 Assumptions

Let @xmath and set ¹⁰⁰ ¹⁰⁰ 100 Notice that each @xmath is greater than
@xmath and depends only upon @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

#### 6.2 Statement of the extension Theorem

###### Theorem 6.2.1

Under the assumptions and notations in @xmath , we have the following.
Let @xmath be a non--empty, bounded domain. ¹⁰¹ ¹⁰¹ 101 i.e. open and
connected. Consider the Hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are real–analytic functions defined on @xmath with bounded
holomorphic extensions to ¹⁰² ¹⁰² 102 Recall the notations in @xmath

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath , the norm being

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath , @xmath and ¹⁰³ ¹⁰³ 103 Notice that @xmath is closed,
connected, with non–empty interior of @xmath provided that @xmath is
small enough.

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Assume that

  -- -------- -- ---------
     @xmath      (6.2.1)
  -- -------- -- ---------

Fix

  -- -------- --
     @xmath   
  -- -------- --

and define ¹⁰⁴ ¹⁰⁴ 104 Notice that @xmath .

  -- -------- --
              
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

where @xmath . Finally, assume

  -- -------- -- ---------
     @xmath      (6.2.2)
  -- -------- -- ---------

Then, there exist @xmath having the same cardinality as @xmath , a
lipeomorphism @xmath , a function @xmath and a @xmath --symplectic
transformation ¹⁰⁵ ¹⁰⁵ 105 Which means that the Whitney–gradient @xmath
satisfies @xmath uniformly on @xmath , where @xmath . @xmath and
real–analytic in @xmath , such that ¹⁰⁶ ¹⁰⁶ 106 Notice that the
derivatives are taken in the sense of Whitney.

  -- -------- -------- -- ---------
     @xmath   @xmath      (6.2.3)
     @xmath   @xmath      (6.2.4)
  -- -------- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.2.5)
     @xmath      (6.2.6)
     @xmath      
     @xmath      (6.2.7)
  -- -------- -- ---------

Now, by applying Theorem F.1 (see Appendix F ) to ( 6.2.7 ), we get the
following measure estimate of the unstable set @xmath .

###### Theorem 6.2.2

Let the notations and assumptions in Theorem 6.2.1 hold, with

  -- -------- -- ---------
     @xmath      (6.2.8)
  -- -------- -- ---------

in place of ( 6.2.2 ) and

  -- -------- --
     @xmath   
  -- -------- --

where ¹⁰⁷ ¹⁰⁷ 107 Notice that the first condition in ( 6.2.8 ) then
reads @xmath . The condition @xmath ensures that the interior of @xmath
is non–empty.

  -- -------- --
     @xmath   
  -- -------- --

Futhermore, assume that the boundary @xmath of @xmath is a smooth
hypersurface of @xmath . Then, the conclusions in Theorem 6.2.1 still
hold. Moreover,

  -- -------- -- ---------
     @xmath      (6.2.9)
  -- -------- -- ---------

where ¹⁰⁸ ¹⁰⁸ 108 See Appendix F for the definitions. @xmath denotes the
curvature tensor of @xmath , @xmath , the @xmath –th integrated mean
curvature of @xmath in @xmath and

  -- -- --
        
  -- -- --

###### Remark 6.2.3

(i) Notice that ( 6.2.7 ) is mainly a consequence of ( 6.2.5 ); the
crucial part of the proof is that one can actually extend a Lipschitz
continuous function to a global Lipschitz continuous function without
increasing neither the Lipschitz constant nor the sup–norm (see Theorem
C.1 in Appendix C ).
(ii) The following estimates hold as well:

  -- -------- -- ----------
     @xmath      (6.2.10)
     @xmath      (6.2.11)
  -- -------- -- ----------

where

  -- -------- --
     @xmath   
  -- -------- --

Notice that the constant in ( 6.2.10 ) is of order 1 and not @xmath ;
that is why we need Minty’s Theorem (see (i) above).
(iii) Notice that the Theorem is consistent for @xmath . In fact, in
that case

  -- -------- --
     @xmath   
  -- -------- --

Hence, the Hamiltonian @xmath is integrable. Moreover,

  -- -------- --
     @xmath   
  -- -------- --

Thus,

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we get @xmath , for any @xmath , as expected.

#### 6.3 Proof of Theorem 6.2.1

###### Lemma 6.3.1 (KAM step)

Let @xmath and consider the Hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are real–analytic functions with bounded holomorphic
extensions to @xmath .
Assume that ¹⁰⁹ ¹⁰⁹ 109 In the sequel, @xmath and @xmath stand for
generic real analytic Hamiltonians which, later on, will respectively
play the roles of @xmath and @xmath , and @xmath , the roles of @xmath
in the iterative step.

  -- -- -------- -------- ---------
        @xmath            (6.3.1)
                 @xmath   
                 @xmath   
  -- -- -------- -------- ---------

Fix @xmath and assume that

  -- -------- -- ---------
     @xmath      (6.3.2)
  -- -------- -- ---------

Let

  -- -- -------- -------- ---------
        @xmath            (6.3.3)
                 @xmath   
  -- -- -------- -------- ---------

and ¹¹⁰ ¹¹⁰ 110 Notice that @xmath since @xmath . Notice also that
@xmath , so that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Then, there exists a generating function @xmath , with @xmath and
satisfying the following inequalities:

  -- -------- -- ---------
     @xmath      (6.3.4)
  -- -------- -- ---------

where

  -- -- --
        
  -- -- --

If, in addition,

  -- -------- -- ---------
     @xmath      (6.3.5)
  -- -------- -- ---------

then, there exists a diffeomorphism @xmath , such that ,

  -- -- -- ---------
           (6.3.6)
  -- -- -- ---------

where

  -- -------- --
     @xmath   
  -- -------- --

and the following hold. For any @xmath , the map @xmath has an analytic
inverse @xmath such that

  -- -------- -- ---------
     @xmath      (6.3.7)
  -- -------- -- ---------

for any @xmath and @xmath , @xmath ; the map @xmath is a symplectic
diffeomorphism and

  -- -------- -- ---------
     @xmath      (6.3.8)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (6.3.9)
  -- -------- -- ---------

where @xmath is defined by the relation @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -- -------- -- ----------
        @xmath      (6.3.10)
  -- -- -------- -- ----------

with

  -- -------- --
     @xmath   
  -- -------- --

Proof

Step 1: Construction of the Arnold’s transformation We seek for @xmath ,
a set @xmath having the same cardinality as @xmath and a
near–to–the–identity real–analytic symplectic transformation @xmath
satisfying

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath generated by @xmath i.e.

  -- -------- -- ----------
     @xmath      (6.3.11)
  -- -------- -- ----------

such that

  -- -------- -- ----------
     @xmath      (6.3.12)
  -- -------- -- ----------

By Taylor’s formula, we get ¹¹¹ ¹¹¹ 111 Recall that @xmath stands for
the average over @xmath .

  -- -------- -------- -------- ----------
     @xmath   @xmath            (6.3.13)
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- ----------

with @xmath , which will be chosen large enough so that @xmath and

  -- -- -- ----------
           (6.3.14)
  -- -- -- ----------

By the non–degeneracy condition in ( 4.1.1 ) and Lemma 2.2.7 , for
@xmath small enough (to be made precised below), there exists @xmath
such that for each @xmath , there exists a unique @xmath satisfying
@xmath and @xmath ; @xmath is precisely the set of these @xmath when
@xmath runs in @xmath . More precisely, @xmath and @xmath are
‘‘diffeomorphic’’ ¹¹² ¹¹² 112 i.e. there a exits a bijection from @xmath
onto @xmath which extends to a diffeomorphism on some neighborhood of
@xmath . , say via @xmath , and, for each @xmath , the matrix @xmath is
invertible with inverse of the form

  -- -- --
        
  -- -- --

In view of ( 6.3.13 ), in order to get the first part of ( 6.3.12 ), we
need to find @xmath such that @xmath vanishes; such a @xmath is indeed
given by

  -- -------- -- ----------
     @xmath      (6.3.15)
  -- -------- -- ----------

provided that

  -- -------- -- ----------
     @xmath      (6.3.16)
  -- -------- -- ----------

But, in fact, since @xmath is rationally independent, for each @xmath ,
then, given any @xmath , there exists @xmath such that

  -- -------- -- ----------
     @xmath      (6.3.17)
  -- -------- -- ----------

Then we invert the function @xmath in order to define @xmath . But, by
Lemma 2.2.6 , for @xmath small enough, the map @xmath admits an
real–analytic inverse of the form

  -- -------- -- ----------
     @xmath      (6.3.18)
  -- -------- -- ----------

so that the Arnod’s symplectic transformation is given by

  -- -------- -- ----------
     @xmath      (6.3.19)
  -- -------- -- ----------

Hence, ( 6.3.12 ) holds with

  -- -------- -- ----------
     @xmath      (6.3.20)
  -- -------- -- ----------

Step 2 Above all, notice that ¹¹³ ¹¹³ 113 Recall footnote ⁴² .

  -- -------- -- ----------
     @xmath      (6.3.21)
  -- -------- -- ----------

We begin by extending the “diophantine condition w.r.t. @xmath ”
uniformly to @xmath up to the order @xmath . Indeed, for any @xmath ,
@xmath and @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      (6.3.22)
  -- -------- -------- -- ----------

so that, by Lemma 2.2.4 – @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and analogously,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Next, we construct @xmath in ( 6.3.12 ). For, fix @xmath and consider

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then

-   @xmath and

      -- -------- -------- --
         @xmath   @xmath   
      -- -------- -------- --

    Hence, @xmath is invertible, with inverse

      -- -------- --
         @xmath   
      -- -------- --

    satisfying

      -- -------- -- ----------
         @xmath      (6.3.23)
      -- -------- -- ----------

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

-   For any @xmath ,

      -- -------- -------- --
         @xmath   @xmath   
                  @xmath   
                           
                  @xmath   
                  @xmath   
                  @xmath   
      -- -------- -------- --

    i.e.

      -- -------- --
         @xmath   
      -- -------- --

Therefore, Lemma 2.2.6 applies. Hence, there exists a real–analytic map
@xmath such that its graph coincides with @xmath i.e. @xmath is the
unique @xmath satisfying @xmath , for any @xmath . Moreover, @xmath ,

  -- -------- -- ----------
     @xmath      (6.3.24)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (6.3.25)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (6.3.26)
  -- -------- -- ----------

Next, we prove that @xmath is invertible, where @xmath for some given
@xmath . Indeed, by Taylor’s formula, we have,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and, by Cauchy’s estimate, ¹¹⁴ ¹¹⁴ 114 Recall footnote ⁴² .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
                       
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence @xmath is invertible with

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Similarly, from

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- --
     @xmath      
  -- -------- -- --

one has that, for any @xmath ,

  -- -------- -- ----------
     @xmath      (6.3.27)
  -- -------- -- ----------

Now, differentiating @xmath , we get, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Therefore @xmath is a local diffeomorphism, with

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- -- ----------
     @xmath      (6.3.28)
  -- -------- -- ----------

Now, we show that the family @xmath is compatible so that, together,
they define a global map on @xmath , say @xmath and that, in fact,
@xmath is a real–analytic diffeomorphism. For, assume that @xmath , for
some @xmath . Then, we need to show that @xmath . But, we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath and, by definitions, @xmath . Then, by unicity, we get
@xmath . Thus, the map

  -- -------- --
     @xmath   
  -- -------- --

is well–defined and, therefore, is a real–analytic local diffeomorphism.
It remains only to check that @xmath is injective to conclude that it is
a global diffeomorphism. Let then @xmath such that @xmath , for some
@xmath . Then, we have

  -- -------- --
     @xmath   
  -- -------- --

Indeed, if not then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

contradiction. Therefore,

  -- -------- -- ----------
     @xmath      (6.3.29)
  -- -------- -- ----------

Thus,

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath . But @xmath is equivalent to @xmath and then,

  -- -------- --
     @xmath   
  -- -------- --

Thus, it is enough to show that @xmath is invertible. But

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, @xmath is invertible and then we get @xmath i.e. @xmath is
injective.
Next, we estimate @xmath . The strategy is to show that the expression
@xmath defines a map on @xmath by means of the Inversion Function Lemma
2.2.7 ; hence, we will get an explicit formula for @xmath :

  -- -------- -- ----------
     @xmath      (6.3.30)
  -- -------- -- ----------

But, the proof is part of the above computation: for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

implies, using Lemma 2.2.7 , that @xmath admits an inverse defined on
@xmath , where

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and thus, ( 6.3.30 ) is proven. Hence, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, we estimate @xmath . We have,

  -- -------- --
     @xmath   
  -- -------- --

so that, for any @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and, by Lemma – @xmath , we have

  -- -- -------- --
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
        @xmath   
  -- -- -------- --

Hence, ¹¹⁵ ¹¹⁵ 115 Recall that @xmath and @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The proof of the claims on @xmath and @xmath are proven in a similar way
as in Lemma 2.3.1 .

Let @xmath , @xmath , @xmath , @xmath and @xmath , @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath and @xmath be as in @xmath . For a
given @xmath and @xmath , define ¹¹⁶ ¹¹⁶ 116 Notice that @xmath and
@xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Thus,

  -- -------- --
     @xmath   
  -- -------- --

and, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
                       
  -- -------- -------- --

i.e.

  -- -------- --
     @xmath   
  -- -------- --

The very first step being quite different from all the others, it has to
be done separately. Hence,

###### Lemma 6.3.2

Under the above assumptions and notations, if

  -- -------- -- ----------
     @xmath      (6.3.31)
  -- -------- -- ----------

then, there exist @xmath , a real–analytic diffeomorphism

  -- -------- --
     @xmath   
  -- -------- --

and a real–analytic symplectomorphism

  -- -------- -- ----------
     @xmath      (6.3.32)
  -- -------- -- ----------

such that

  -- -------- -- ----------
     @xmath      (6.3.33)
     @xmath      (6.3.34)
     @xmath      (6.3.35)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.3.36)
     @xmath      (6.3.37)
     @xmath      (6.3.38)
     @xmath      (6.3.39)
                 (6.3.40)
     @xmath      (6.3.41)
  -- -------- -- ----------

Proof By

  -- -------- -- ----------
     @xmath      (6.3.42)
  -- -------- -- ----------

and

  -- -------- --
     @xmath   
  -- -------- --

we get

  -- -------- -- ----------
     @xmath      (6.3.43)
  -- -------- -- ----------

and, thus

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.44)
  -- -------- -------- -- ----------

Therefore, Lemma 6.3.2 is a straightforward consequence of Lemma 6.3.1 .

###### Lemma 6.3.3

Assume @xmath with some @xmath and

  -- -------- -- ----------
     @xmath      (6.3.45)
  -- -------- -- ----------

Then, one can construct a sequence of real–analytic diffeomorphisms

  -- -------- --
     @xmath   
  -- -------- --

and of real–analytic symplectic transformations

  -- -------- -- ----------
     @xmath      (6.3.46)
  -- -------- -- ----------

such that

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

converge uniformly. More precisely, we have the following:

-    the sequence @xmath converges uniformly on @xmath to a
    lipeomorphism @xmath and @xmath .

-   @xmath converges uniformly on @xmath to @xmath , for any @xmath ;

-   @xmath converges uniformly on @xmath to a symplectic transformation

      -- -------- --
         @xmath   
      -- -------- --

    with @xmath and @xmath holomorphic, for any @xmath ;

-   @xmath converges uniformly on @xmath to a function @xmath , with

      -- -------- --
         @xmath   
         @xmath   
      -- -------- --

Finally, the following estimates hold for any @xmath :

  -- -------- -- ----------
     @xmath      (6.3.47)
                 (6.3.48)
     @xmath      (6.3.49)
     @xmath      (6.3.50)
     @xmath      (6.3.51)
  -- -------- -- ----------

Proof First of all, notice that

  -- -- -- ----------
           (6.3.52)
  -- -- -- ----------

Indeed, for any @xmath , we have

  -- -------- -- ----------
     @xmath      (6.3.53)
  -- -------- -- ----------

so that

  -- -------- --
     @xmath   
  -- -------- --

and if

  -- -------- --
     @xmath   
  -- -------- --

then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and ( 6.3.52 ) is proven.

For a given @xmath , let @xmath be the following assertion: there exist
@xmath real–analytic diffeomorphisms

  -- -------- --
     @xmath   
  -- -------- --

@xmath real–analytic symplectic transformations

  -- -------- -- ----------
     @xmath      (6.3.54)
  -- -------- -- ----------

and @xmath Hamiltonians @xmath real–analytic on @xmath such that, for
any @xmath ,

  -- -------- -- ----------
     @xmath      (6.3.55)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.3.56)
  -- -------- -- ----------

Assume @xmath , for some @xmath and let us check @xmath . Fix then
@xmath . Thus

  -- -- --
        
  -- -- --

and, similarly,

  -- -------- --
     @xmath   
  -- -------- --

which prove the second and third relations in ( 6.3.55 ) for @xmath .
Therefore

  -- -------- -- ----------
     @xmath      (6.3.57)
  -- -------- -- ----------

so that

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.58)
  -- -------- -------- -- ----------

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

thus by last relation in ( 6.3.56 ), for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which proves the fourth relation in ( 6.3.55 ) for @xmath . Hence, by
exactly the same computation as above, one gets

  -- -------- --
     @xmath   
  -- -------- --

which proves the last relation in ( 6.3.55 ) for @xmath . It remains
only to check that the fifth relation in ( 6.3.55 ) holds as well for
@xmath in order to apply Lemma 6.3.1 to @xmath , @xmath and get ( 6.3.56
) and, consequently, @xmath . But in fact, we have, for any @xmath ,
@xmath ,
so that

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.59)
  -- -------- -------- -- ----------

To finish the proof of the induction i.e. one can construct an infinite
sequence of Arnold’s transformations satisfying ( 6.3.55 ) and ( 6.3.56
) for all @xmath , one needs only to check @xmath . But, ¹¹⁷ ¹¹⁷ 117
Observe that for @xmath , @xmath . @xmath and @xmath imply @xmath .
Thus, we apply Lemma 6.3.1 to @xmath to achieve the proof of @xmath .
Next, we show that @xmath converges. For any @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.60)
  -- -------- -------- -- ----------

Thus, @xmath is Cauchy and therefore converges uniformly on @xmath to a
map @xmath .

Next, we prove that @xmath is convergent by showing that it is Cauchy as
well. For any @xmath , we have, using again Cauchy’s estimate,

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
                 @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

Therefore, for any @xmath ,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.61)
  -- -------- -------- -- ----------

Hence @xmath converges uniformly on @xmath to some @xmath , which is
then real–analytic function in @xmath .

To estimate @xmath on @xmath , observe that , for @xmath , ¹¹⁸ ¹¹⁸ 118
Recall that @xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
                       
                       
                       
              @xmath   
  -- -------- -------- --

which iterated yields

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Therefore, taking the limit over @xmath completes the proof of ( 6.3.51
).

Next, we show that @xmath , which will imply that ¹¹⁹ ¹¹⁹ 119 See
Proposition II.2. in [ Zeh10 ] . @xmath is a lipeomorphism. Indeed, for
any @xmath , we have

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which iterated leads to ¹²⁰ ¹²⁰ 120 Recall that @xmath .

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.62)
  -- -------- -------- -- ----------

Thus, letting @xmath , we get that @xmath is Lipschitz continuous, with

  -- -- --
        
  -- -- --

so that, by ¹²¹ ¹²¹ 121 With @xmath . Lemma D.1 (see Appendix D ), we
get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which proves ( 6.3.50 ).
Next, we show that @xmath . For any @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, letting @xmath , we get

  -- -------- -- ----------
     @xmath      (6.3.63)
  -- -------- -- ----------

Hence, ¹²² ¹²² 122 Recall that, by definition, @xmath and @xmath . for
any @xmath ,

  -- -- -- ----------
           (6.3.64)
  -- -- -- ----------

Therefore, for any @xmath , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

since, for @xmath sufficiently large,

  -- -------- --
     @xmath   
  -- -------- --

Thus, writing

  -- -------- --
     @xmath   
  -- -------- --

and invoking Lemma E.2 (see Appendix E ), we conclude that @xmath .

Finally, we prove @xmath analogously. For any @xmath and @xmath , we
have

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which proves that @xmath .

Now, to complete the proof of Theorem 6.2.1 , observe that, uniformly on
@xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Moreover, setting @xmath , we have for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and then passing to the limit, we get

  -- -------- --
     @xmath   
  -- -------- --

Finally, we prove ( 6.2.7 ). By Theorem C.1 , @xmath can be extended to
a global Lipschitz continuous function @xmath , with ¹²³ ¹²³ 123 Where
@xmath and recall that @xmath , for any @xmath .

  -- -------- -------- -- ----------
     @xmath   @xmath      (6.3.65)
     @xmath   @xmath      (6.3.66)
  -- -------- -------- -- ----------

Hence,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.67)
  -- -------- -------- -- ----------

and

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.3.68)
  -- -------- -------- -- ----------

Set @xmath . Then, by Lemma G.1 ,

  -- -------- -- ----------
     @xmath      (6.3.69)
  -- -------- -- ----------

Notice also that, by ( 6.3.68 ), ¹²⁴ ¹²⁴ 124 See [ Zeh10 ,
Proposition II.2.] . @xmath is a homeomorphism of @xmath . Consequently,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

#### 6.4 Sharp measure estimate of the complement of @xmath in an
arbitrary set

The strategy here is to localize the Kolmogorov set and then sum them
up. Thus, we start by examining the cube case.

##### 6.4.1 Local analysis: the case where @xmath is a cube

###### Theorem 6.4.1

Let

  -- -------- --
     @xmath   
  -- -------- --

and let the assumptions in Theorem 6.2.1 hold, with

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Furthermore, assume that

  -- -------- --
     @xmath   
  -- -------- --

is a diffeomorphism. Then,

  -- -------- --
     @xmath   
  -- -------- --

with ¹²⁵ ¹²⁵ 125 Indeed, pick any matrix @xmath . Then @xmath and @xmath
, where @xmath is the set of permutations of @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Proof We shall denote the Euclidean norm by ¹²⁶ ¹²⁶ 126 Recall that
@xmath , for any @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Recall that

  -- -------- --
     @xmath   
  -- -------- --

and @xmath . Therefore,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

It remains to estimate @xmath . Firstly, thanks to Theorem C.1 (see
Appendix C ), @xmath can be extended to a global Lipschitz continuous
function @xmath , with

  -- -------- -------- -- ---------
     @xmath   @xmath      (6.4.1)
     @xmath   @xmath      (6.4.2)
  -- -------- -------- -- ---------

Hence,

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.4.3)
  -- -------- -------- -- ---------

and

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.4.4)
  -- -------- -------- -- ---------

Set @xmath . Then, by Lemma G.1 ,

  -- -------- -- ---------
     @xmath      (6.4.5)
  -- -------- -- ---------

Notice also that, by ( 6.4.4 ), ¹²⁷ ¹²⁷ 127 See [ Zeh10 ,
Proposition II.2.] . @xmath is a homeomorphism of @xmath . Consequently,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Finally,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
                       
              @xmath   
  -- -------- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Putting all together, we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

##### 6.4.2 Global analysis

Let @xmath be any non–empty, bounded subset of @xmath . Consider the
Hamiltonian parametrized by @xmath

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are real–analytic functions defined on @xmath with bounded
holomorphic extensions to ¹²⁸ ¹²⁸ 128 Recall the notations in @xmath

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath , the norm being

  -- -------- --
     @xmath   
  -- -------- --

Assume that

  -- -------- -- ---------
     @xmath      (6.4.6)
  -- -------- -- ---------

Fix @xmath and define ¹²⁹ ¹²⁹ 129 Recall footnote ¹²⁵ .

  -- -------- -------- --
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath . Let

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Given @xmath , define the set @xmath of coverings of @xmath by cubes as
follows: @xmath iff there exists @xmath and @xmath cubes, say @xmath
@xmath , of equal side–length @xmath , centered at a point @xmath and
such that

  -- -------- -- ---------
     @xmath      (6.4.7)
  -- -------- -- ---------

Then define

  -- -------- -- ---------
     @xmath      (6.4.8)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.4.9)
  -- -------- -- ---------

Pick any @xmath and @xmath such that @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

Thus, the following holds.

###### Theorem 6.4.2

Let the above assumptions and notations hold. Assume

  -- -------- -- ----------
     @xmath      (6.4.10)
  -- -------- -- ----------

where @xmath .
Part I: Description of the local Kolmogorov’s sets @xmath
There exists @xmath and and @xmath , @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

and the following holds. Pick any @xmath . Define

  -- -------- -------- --
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then, there exist @xmath having the same cardinality as @xmath , a
lipeomorphism @xmath , with @xmath , a function @xmath and a @xmath
--symplectic transformation ¹³⁰ ¹³⁰ 130 Which means that the
Whitney–gradient @xmath satisfies @xmath uniformly on @xmath , where
@xmath . @xmath and real–analytic in @xmath , such that ¹³¹ ¹³¹ 131
Notice that the derivatives are taken in the sense of Whitney.

  -- -------- -------- -- ----------
     @xmath   @xmath      (6.4.11)
     @xmath   @xmath      (6.4.12)
  -- -------- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.4.13)
     @xmath      (6.4.14)
  -- -------- -- ----------

Part II: Sharp measure estimate of the complement of @xmath
Set

  -- -------- --
     @xmath   
  -- -------- --

Case 1: @xmath .
In that case, ¹³² ¹³² 132 @xmath and @xmath , where @xmath and @xmath
are the ones appearing in Lemma 6.4.3 , with @xmath .

  -- -------- -- ----------
     @xmath      (6.4.15)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.4.16)
  -- -------- -- ----------

Case 2: @xmath .
In that case, @xmath , @xmath and

  -- -------- -- ----------
     @xmath      (6.4.17)
  -- -------- -- ----------

We shall need the following elementary Lemmas in the proof.

###### Lemma 6.4.3 (Covering Lemma)

For any @xmath , there exist ¹³³ ¹³³ 133 @xmath denotes the integer part
function @xmath , while @xmath denotes the ”ceiling function” @xmath .

  -- -------- --
     @xmath   
  -- -------- --

and @xmath , @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Proof Let @xmath and @xmath . Then @xmath . Now, let @xmath close enough
to @xmath so that

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath can be covered by @xmath closed, contiguous cubes @xmath ,
@xmath , of equal side–length @xmath . Let @xmath those indices such
that @xmath and pick @xmath ; let @xmath be the number of such cubes.
But then, one has @xmath , for each @xmath . The Lemma is therefore
proved.

###### Lemma 6.4.4

Let ¹³⁴ ¹³⁴ 134 @xmath denotes the symmetric matrices of order @xmath ,
with entries in @xmath . @xmath be a matrix–valued function. Assume that

  -- -------- --
     @xmath   
  -- -------- --

Then, for any @xmath , the eigenvalues @xmath are bounded in modulus
from below by @xmath . hence, in particular,

  -- -------- -- ----------
     @xmath      (6.4.18)
  -- -------- -- ----------

Proof Let @xmath and @xmath an eigenvector of @xmath with associated
eigenvalue @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, the Lemma is proven since the determinant is equal to the product
of the eigenvalues, counted with multiplicities.

Proof of Theorem 6.4.2 Set

  -- -------- --
     @xmath   
  -- -------- --

Then,

  -- -------- --
     @xmath   
  -- -------- --

Hence,

  -- -------- -------- -- ----------
     @xmath   @xmath      (6.4.19)
     @xmath   @xmath      
  -- -------- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (6.4.20)
  -- -------- -- ----------

Thus, thanks to ( 6.4.19 ) and ( 6.4.20 ), we need only to check that
@xmath is injective on @xmath in order to apply Theorem 6.4.1 to @xmath
. But, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, by Lemma 2.2.7 , @xmath is a real analytic diffeomorphism on
@xmath , where

  -- -------- --
     @xmath   
  -- -------- --

Furthermore,

  -- -------- -- ----------
     @xmath      (6.4.21)
  -- -------- -- ----------

Set @xmath . Then, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, again by Lemma 2.2.7 , the inverse of @xmath , i.e. @xmath , is a
real analytic diffeomorphism on @xmath (since @xmath ), where

  -- -------- --
     @xmath   
  -- -------- --

Moreover, in exactly the same way as above, one gets

  -- -------- -- ----------
     @xmath      (6.4.22)
  -- -------- -- ----------

Hence,

  -- -------- -------- -- ----------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (6.4.23)
  -- -------- -------- -- ----------

The estimates ( 6.4.17 ) and ( 6.4.16 ) then follow easily. For
instance, let us treat the second case i.e. @xmath . The case @xmath is
proved in a similar way by firstly using Lemma 6.4.3 , with @xmath ;
then setting @xmath , @xmath and thus applying Theorem 6.4.1 to each
@xmath .
Let then @xmath . Thus, we can apply Theorem 6.4.1 to @xmath . Hence,
there exists a Kolmogorov set

  -- -------- -- ----------
     @xmath      (6.4.24)
  -- -------- -- ----------

associated to @xmath , with all the desired properties and satisfying
¹³⁵ ¹³⁵ 135 Where, @xmath is replaced by @xmath , thanks to ( 6.4.23 );
@xmath and @xmath by @xmath and @xmath respectively.

  -- -------- -- ----------
     @xmath      (6.4.25)
  -- -------- -- ----------

Therefore

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

### Appendices

##### A On the initial order of truncation @xmath of the Fourier series
in Theorem 2.1.4

Let

  -- -------- --
     @xmath   
  -- -------- --

with ¹³⁶ ¹³⁶ 136 Notice that

@xmath

so that one can choose @xmath and in that case, if one chooses in
addition @xmath , then @xmath and @xmath , with @xmath and @xmath as in
@xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Then

###### Lemma A.1

-    If @xmath then

      -- -------- -- -------
         @xmath      (A.1)
      -- -------- -- -------

-    If @xmath and @xmath then

      -- -------- -- -------
         @xmath      (A.2)
      -- -------- -- -------

Proof Above all, notice that (for any @xmath )

  -- -------- -- -------
     @xmath      (A.3)
  -- -------- -- -------

Let @xmath .
Let’s prove @xmath . Assume that @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Therefore @xmath and @xmath , so that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

On the other hand, since @xmath then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Finally we prove @xmath . If @xmath and @xmath then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

##### B Smooth contraction mapping Lemma

Let @xmath . Let @xmath , with @xmath holomorphic on @xmath for any
given @xmath . Assume,

  -- -- -- -------
           (B.1)
  -- -- -- -------

where

  -- -------- --
     @xmath   
  -- -------- --

Assume also that for any @xmath there exists a constant @xmath with the
following property: for any @xmath with @xmath ,

  -- -------- -- -------
     @xmath      (B.2)
  -- -------- -- -------

###### Lemma B.1

Under the above assumptions, there exists a unique map @xmath , with
@xmath holomorphic on @xmath such that for any given @xmath , the map
@xmath is the inverse of @xmath . Moreover, for any @xmath there a
constant @xmath such that for any @xmath with @xmath ,

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (B.4)
  -- -------- -- -------

Furthermore, @xmath can be expressed in term of @xmath , for any @xmath
.

Proof Let @xmath be the set of @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath is a Banach space and for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence the map

  -- -------- --
     @xmath   
  -- -------- --

is well–defined. Notice that

  -- -------- --
     @xmath   
  -- -------- --

Hence, we have to show that @xmath admits a unique fixed point. But

  -- -------- --
     @xmath   
  -- -------- --

i.e. , @xmath is a contraction. Therefore, by the Banach’s Fixed Point
(or contraction mapping) Theorem, @xmath admits a unique fixed point,
say @xmath , and @xmath is obtained as the uniform limit of the sequence
@xmath . Thus, by Weierstrass’s Theorem, @xmath is holomorphic on @xmath
, for each @xmath . Moreover

  -- -------- --
     @xmath   
  -- -------- --

and, by differentiating @xmath w.r.t @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

which conclude the proof of ( B.4 ). Next, we shall proceed inductively
for the remainder of the proof. We have

  -- -------- --
     @xmath   
  -- -------- --

which proofs @xmath . Set @xmath i.e. @xmath . Now, fix @xmath and
assume that @xmath and @xmath holds, for any @xmath . Then, using the
multivariate Fàa Di Bruno’s formula (see [ CS96 ] , Theorem @xmath ) to
differentiate @xmath , for any @xmath , with @xmath , we have ¹³⁷ ¹³⁷
137 With the convention @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

i.e. ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where

  -- -------- --
     @xmath   
              
     @xmath   
     @xmath   
  -- -------- --

and, for all @xmath if and only if one of the following holds

-   @xmath or

-   @xmath and there exists @xmath such that @xmath for all @xmath and
    @xmath .

Therefore, @xmath . Moreover, since @xmath , by the inductive
hypothesis, ( B.1 ) and ( B.2 ), we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath is an universal constant, independent upon @xmath .
Finally, notice that @xmath can be expressed in term of @xmath if @xmath
can be expressed in term of @xmath . These concludes the proof of the
Lemma.

##### C Extension of Lipschitz–Hölder continuous functions with control
on the sup–norm

We aim to recall here a very deep Extension Theorem for Lipschitz–Hölder
continuous function, following closely [ Min70 ] . ¹³⁸ ¹³⁸ 138 Recall
that, Kirszbraun’s Theorem (see [ Fed ] , @xmath ) asserts only that one
can extend a Lipschitz continuous function without increasing the
Lipschitz constant.

###### Theorem C.1 (G. J. Minty[Min70])

Let @xmath be a separable inner product space, @xmath , @xmath and
@xmath a @xmath –Lipschitz–Hölder continuous function on @xmath i.e. ¹³⁹
¹³⁹ 139 Recall that @xmath denotes the Euclidean norm on @xmath .

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

Then, there exists a global @xmath --Lipschitz--Hölder continuous
function ¹⁴⁰ ¹⁴⁰ 140 i.e. satisfying ( C.1 ) on @xmath . @xmath such
that @xmath . Futhermore, @xmath can be chosen in such away that @xmath
is contained in the closed convex hull of @xmath . Hence, in particular,

  -- -------- -- -------
     @xmath      (C.2)
  -- -------- -- -------

We need some preliminaries to prove the Theorem. Given @xmath , we shall
denote

  -- -------- --
     @xmath   
  -- -------- --

###### Definition C.2 (Kirszbraun function)

Let @xmath be a @xmath –vector space and @xmath a non–empty set. A
function @xmath is called Kirszbraun function (K–function) if:

-   @xmath is convex and for any @xmath and for any finite–dimensional
    subspace @xmath of @xmath , the function @xmath is Lower
    semicontinuous ¹⁴¹ ¹⁴¹ 141 i.e. for any @xmath , the sublevel set
    @xmath is closed in @xmath endowed with the canonical topology. ;

-    for any @xmath , for any @xmath , for any @xmath and for any @xmath
    , the inequality

      -- -------- -- -------
         @xmath      (C.3)
      -- -------- -- -------

    holds.

Then, the following holds.

###### Theorem C.3 (G. J. Minty[Min70])

Let @xmath be a K–function, @xmath , @xmath . Assume that @xmath is
continuous and for any @xmath ,

  -- -------- -- -------
     @xmath      (C.4)
  -- -------- -- -------

Then, given any @xmath , there exists @xmath in the convex hull of
@xmath such that @xmath , for any @xmath .

Proof Consider the function

  -- -------- --
     @xmath   
  -- -------- --

Then, it is clear that @xmath is convex and lower semicontinuous in
@xmath , concave and upper semicontinuous in @xmath . Thus, since @xmath
is compact and thanks to the von Neumann’s Minimax Theorem, there exists
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Hence,

  -- -------- -- -------
     @xmath      (C.5)
  -- -------- -- -------

But,

  -- -------- --
     @xmath   
  -- -------- --

Set

  -- -------- --
     @xmath   
  -- -------- --

Therefore, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the Kronecker delta: @xmath if @xmath and @xmath
otherwise.

We shall need also the following.

###### Lemma C.4

Let @xmath . Then,

-    given any @xmath , we have ¹⁴² ¹⁴² 142 @xmath being the Euler’s
    Gamma function.

      -- -- -- -------
               (C.6)
      -- -- -- -------

-    given any @xmath and any @xmath ,

      -- -------- -- -------
         @xmath      (C.7)
      -- -------- -- -------

Proof @xmath is trivial. Let us prove @xmath . Above all, we recall the
Bernoulli inequality:

  -- -------- -- -------
     @xmath      (C.8)
  -- -------- -- -------

The case @xmath is obvious. Let then @xmath . By the continuity of the
norm, up to approximating the zero vector by a sequence of non–zero
vectors, we can assume that each @xmath , @xmath . Thus, we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, we are in position to prove Theorem C.1 .

Proof of Theorem C.1 The proof is divided into three steps.
Step 1 We show that

  -- -------- --
     @xmath   
  -- -------- --

is a K–function. @xmath is obviously continuous (actually, @xmath ) and
convex in @xmath . Now, let @xmath , @xmath , @xmath and @xmath , and
set @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Step 2 We want to show that we can extend @xmath to @xmath in such away
that the image of @xmath by the extension lies in closed convex hull
@xmath of @xmath , for any @xmath . If @xmath , there is nothing to do.
Let then @xmath . Set ¹⁴³ ¹⁴³ 143 Notice that, for any @xmath , @xmath
and @xmath is the closed ball (with respect to the Euclidean norm)
centered at @xmath with radius @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Then, for any @xmath , @xmath is a compact convex subset of @xmath . Now
pick any @xmath and set @xmath . Thus, ( C.1 ) implies

  -- -------- --
     @xmath   
  -- -------- --

Thanks to Step 1 , we can apply Theorem C.3 . Therefore, there exists
@xmath in the convex hull of @xmath such that @xmath , for any @xmath .
Hence,

  -- -------- --
     @xmath   
  -- -------- --

Thus, by Helly’s Theorem ¹⁴⁴ ¹⁴⁴ 144 See [ DGK21 ] , there exists

  -- -------- --
     @xmath   
  -- -------- --

Consequently, the extension @xmath of @xmath to @xmath is obtained by
setting @xmath .
Step 3 Pick any countable dense subset @xmath of @xmath . Then, by Step
2 , we can extend @xmath inductively to @xmath . Denote by @xmath such
an extension and notice that @xmath and satisfies ( C.1 ) on @xmath , by
construction. Now, pick any @xmath and sequences @xmath converging to
@xmath , @xmath . Fix @xmath . Then, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence, the sequence @xmath is Cauchy and, therefore, converges to a
@xmath and @xmath does not depend upon the sequence chosen but only upon
@xmath . Now, by

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , we get, by passing to the limit,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Then, a desired extension is obtained by just setting

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and @xmath any sequence converging to @xmath .

##### D Lebesgue measure and Lipschitz continuous map

###### Lemma D.1

Let @xmath be a Lebesgue–measurable set and @xmath be Lipschitz
continuous with

  -- -------- -- -------
     @xmath      (D.1)
  -- -------- -- -------

Then

  -- -------- -- -------
     @xmath      (D.2)
  -- -------- -- -------

###### Remark D.2

Notice that the inequality ( D.2 ) is sharp as shown by the example
@xmath .

Proof By Theorem C.1 (see Appendix C ), @xmath can be extended to a
Lipschitz continuous @xmath with

  -- -------- --
     @xmath   
  -- -------- --

Now, by Rademacher’s Theorem, there exists a set @xmath with @xmath and
such that @xmath is differentiable on @xmath . Then ¹⁴⁵ ¹⁴⁵ 145 Let’s
point out that @xmath is non–convex if @xmath is non–empty. Netherless,
one can just approximate a segment by curves contained in @xmath and
with length arbitrarily close to the length of the segment.

  -- -------- --
     @xmath   
  -- -------- --

Now pick @xmath . Then,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Thus, by the change of variable (or area or coarea) formula ¹⁴⁶ ¹⁴⁶ 146
See [ EG15 ] , @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

##### E Whitney’s smoothness

###### Definition E.1

Let @xmath be non–empty and @xmath , @xmath . A function @xmath is said
@xmath on @xmath in the Whitney sense, with Whitney derivatives @xmath ,
@xmath , and we write @xmath , if for any @xmath and @xmath , there
exists @xmath such that, for any @xmath and @xmath , with @xmath ,

  -- -------- -- -------
     @xmath      (E.1)
  -- -------- -- -------

The following is proven in [ Chi86 , @xmath , pg. 58] for @xmath .

###### Lemma E.2

Let @xmath be non–empty and @xmath . For @xmath , let @xmath be a
real–analytic function with holomorphic extension to @xmath , with
@xmath as @xmath . Assume that

  -- -------- -- -------
     @xmath      (E.2)
  -- -------- -- -------

Then @xmath with Whitney’s derivatives @xmath .

Proof Let @xmath , with @xmath . We start showing that

  -- -------- --
     @xmath   
  -- -------- --

is well–defined on @xmath . Indeed, for any @xmath , @xmath and, by
Cauchy’s estimate,

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Finally, we show that @xmath are the Whitney’s derivatives of @xmath .
Fix then @xmath , @xmath and @xmath , with @xmath . Set

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath such that ¹⁴⁷ ¹⁴⁷ 147 Such a @xmath exists by ( E.2 ).

  -- -------- -- -------
     @xmath      (E.3)
  -- -------- -- -------

Let ¹⁴⁸ ¹⁴⁸ 148 Let us point out that @xmath does not depend upon @xmath
. These is crucial! Actually, @xmath does not even depend upon @xmath .

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Now, pick @xmath , with @xmath . Let then ¹⁴⁹ ¹⁴⁹ 149 Notice that such a
@xmath exists since @xmath and the sequence @xmath is strictly
decreasing. @xmath such that

  -- -------- -- -------
     @xmath      (E.4)
  -- -------- -- -------

Notice that @xmath is holomorphic on @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for any @xmath ,

  -- -- -- -------
           (E.5)
  -- -- -- -------

Therefore, by Taylor–Lagrange’s formula and Cauchy’s estimates, we have
(for some @xmath )

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (E.6)
  -- -------- -------- -- -------

Furthermore, for any @xmath , with @xmath ,

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (E.7)
  -- -------- -------- -- -------

Thus,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which concludes the proof, by the arbitrariness of @xmath .

###### Remark E.3

1.   Actually, we proved something stronger. Namely, for any @xmath ,
    there exists @xmath such that, for any @xmath and @xmath , with
    @xmath and @xmath ,

      -- -------- -- -------
         @xmath      (E.8)
      -- -------- -- -------

2.   In fact, @xmath satisfies the following “uniform” Whitney’s
    condition, provided @xmath : for any @xmath and @xmath , with @xmath
    and @xmath ,

      -- -------- -- -------
         @xmath      (E.9)
      -- -------- -- -------

    Indeed, for such given @xmath , let @xmath such that @xmath Then, by
    similar computations as above, we have

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

Finally, we recall the very deep Whitney’s extension theorem.

###### Theorem E.4 (Whitney [Whi34])

Let @xmath and @xmath , @xmath . If @xmath is closed, then there exists
@xmath , real–analytic on @xmath and such that @xmath on @xmath , for
any @xmath , with @xmath .

##### F Generalized Steiner’s formula

We aim here to recall the generalized Steiner’s formula to compute the
volume of the two halves tubes that composes a (uniform) tubular
neighborhood of an embedded hypersurface without boundary of @xmath .
¹⁵⁰ ¹⁵⁰ 150 For a genralization to a non–uniform tubular neighborhood,
see [ Roc13 ] .
Let @xmath be a smooth, bounded, orientable hypersurface without
boundary of @xmath (equipped with the Euclidean metric). Fix the
orientation given by a smooth unit normal vector field of @xmath

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be the volume form on @xmath (which induces the
Lebesgue–measure @xmath on @xmath ) and @xmath be the Levi–Civita
connection on @xmath . Then, let @xmath be the induced area–form on
@xmath , defined by

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath , where @xmath denotes the Lie algebra of smooth vector
fields on @xmath . Define the shape operator @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Define the map @xmath by ¹⁵¹ ¹⁵¹ 151 @xmath is the distance from @xmath
to its cut-focal point in the direction @xmath if such a cut–focal point
exists; otherwise @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Then, define the minimal focal distance

  -- -------- --
     @xmath   
  -- -------- --

Given @xmath , define the two half–tubes about @xmath

  -- -------- --
     @xmath   
  -- -------- --

and the @xmath –tubular neighborhood of @xmath

  -- -------- --
     @xmath   
  -- -------- --

The contraction operators @xmath on the space of double forms of type
¹⁵² ¹⁵² 152 A double form of type @xmath is a @xmath –linear map @xmath
, which is antisymmetric in the first @xmath variables and in the last
@xmath as well, where @xmath denotes the space of smooth functions on
@xmath . @xmath are defined inductively as follows: @xmath and, for
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is any orthonormal frame field of @xmath . Let @xmath be
the curvature tensor of @xmath . @xmath being a double form of type
@xmath , one can then take the wedge product of @xmath with itself
@xmath times to get the double form @xmath of type @xmath . Set @xmath
and define the @xmath –th and @xmath –th integrated mean curvatures of
@xmath in @xmath as follows ( @xmath ):

  -- -------- -------- --
     @xmath            
     @xmath   @xmath   
  -- -------- -------- --

Thus, the foolowing holds.

###### Theorem F.1 ([Gra12], pg. 224)

  -- -------- -- -------
     @xmath      (F.1)
  -- -------- -- -------

for any @xmath .

##### G Some others facts on Lipschitz continuous functions

In the following, we prove that any set is contained in some enlargement
of itself through any contracting mapping which is bounded on the former
set.

###### Lemma G.1

Let @xmath be Lipschitz continuous function. Assume that

  -- -------- -- -------
     @xmath      (G.1)
     @xmath      (G.2)
  -- -------- -- -------

Then, for any @xmath , ¹⁵³ ¹⁵³ 153 Where @xmath denotes the closed
@xmath –neighborhood of @xmath in @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Proof Set @xmath and let @xmath . It is enough to show that there exists
@xmath such that @xmath i.e. @xmath i.e. @xmath is a fixed point of the
map

  -- -------- --
     @xmath   
  -- -------- --

But, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

i.e. @xmath . Moreover, @xmath is a contraction since @xmath . Thus, we
can apply the Banach’s fixed point Theorem to complete the proof.