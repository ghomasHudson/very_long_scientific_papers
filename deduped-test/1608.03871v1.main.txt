###### Contents

-    1 Background and motivations
    -    1.1 Optimal power flow problem
    -    1.2 Optimality conditions in optimization
    -    1.3 Convex relaxation of the optimal power flow problem
    -    1.4 Definitions of complex numbers
-    2 Lasserre hierarchy for small-scale networks
    -    2.1 Introduction
    -    2.2 Polynomial optimization formulation
    -    2.3 Moment-sos approach
    -    2.4 Numerical results
    -    2.5 Conclusion
-    3 Zero duality gap in the Lasserre hierarchy
    -    3.1 Introduction
    -    3.2 Proof
    -    3.3 Conclusion
-    4 Data of European transmission network
    -    4.1 case89pegase
    -    4.2 case1354pegase
    -    4.3 case2869pegase
    -    4.4 case9241pegase
-    5 Penalized Lasserre hierarchy
    -    5.1 Introduction
    -    5.2 Preprocessing low-impedance lines
    -    5.3 Moment relaxations and penalization
    -    5.4 Penalization of reactive power generation
    -    5.5 Moment+penalization approach
    -    5.6 Numerical results
    -    5.7 Conclusion
-    6 Laplacian matrix approach
    -    6.1 Introduction
    -    6.2 Laplacian objective function
    -    6.3 Determining Laplacian weights
    -    6.4 Numerical results
    -    6.5 Conclusion
-    7 Complex hierarchy for enhanced tractability
    -    7.1 Introduction
    -    7.2 Motivation
    -    7.3 Complex moment/sum-of-squares hierarchy
    -    7.4 Numerical results
    -    7.5 Conclusion
-    8 Conclusion and perspectives
-    A Ring Homomorphism
-    B Rank-2 Condition
-    C Invariance of Shor Relaxation Bound
-    D Invariance of SDP- @xmath Relaxation Bound
-    E Discrepancy Between Second-Order Conic Relaxation Bounds
-    F Five-Bus Illustrative Example for Exploiting Sparsity
-    G Complex Hierarchy Applied to Optimal Power Flow

## Chapter 1 Background and motivations

The industrial problem which motivates this work can be viewed as an
optimization problem. In this chapter, the equations that define this
problem are presented and their relevance in practice is discussed.
Next, optimality conditions are presented for general optimization
problems. These are crucial to current methods used by industry, and
remain important for the approach investigated in this thesis. This
approach consists in solving convex relaxations of the original
nonconvex problem. The original problem is written using complex numbers
and this thesis advocates the use of convex relaxations in complex
numbers. To that end, several definitions of complex numbers are
provided.

### 1.1 Optimal power flow problem

The optimal power flow is a central problem in electric power systems
introduced half a century ago by Carpentier [ 25 ] . It seeks to find a
steady state operation point of an alternating current transmission
network that respects Kirchoff’s laws, Ohm’s law, and power balance
equations. In addition, the point has to be optimal under a criteria
such as generation costs. It must also satisfy operational constraints
which include narrow voltage ranges around nominal values and line
ratings to keep Joule heating to acceptable levels.

While many nonlinear methods [ 50 , 88 , 132 , 27 ] have been developed
to solve this notoriously difficult problem, there is a strong
motivation for producing more robust and reliable tools. Firstly,
electric power systems are growing in complexity due to the increase in
the share of renewables, the increase in the peak load, and the expected
wider use of demand response and storage. This could hamper power
systems reliability if decision-making tools do not evolve. Costly power
interruptions could occur more often. Secondly, new tools are needed to
profit from high-performance computing and advances in
telecommunications such as phasor measurement units and dynamic line
ratings. This will reduce operation costs and help keep power supply
affordable at a time when expensive investments are being made for
renewables. Lastly, system operators face large-scale optimization
problems with combinatorial complexity due to phase-shifting
transformers, high-voltage direct current transmission lines, and
special protection schemes. Solving the continuous case to global
optimality would be of great benefit for a more automated decision
process.

Electricity transmission networks are meshed networks in which buses not
only inject or retrieve power from the network, but also serve as a
relay for other buses. Topologically, there exists cycles in the
network. This is not the case for distribution networks where the
topology of the network is a tree ¹ ¹ 1 Optimization over distribution
networks may involve graphs that are not trees however. This is due to
different possible configurations of the connections between buses in
the network. . A simple model of high-voltage power lines in
transmission networks uses a resitance @xmath , an inductance @xmath ,
and a capacitance @xmath (cf. figure 1.1 ).

Continental Europe uses alternating current (AC) at a frequency of
@xmath Hz @xmath @xmath Hz, which makes for an angular speed of @xmath .
The total impedence of a resistance @xmath and an inductance @xmath in
series is @xmath . @xmath is a typical value for inductance in a 100 km
long line operating at 400 kV line, so reactance @xmath is roughly equal
to @xmath . Divided by a hundred, the value lies in the range given in
table .

In order to switch from one of the voltage levels shown in table to
another, electricity transmission networks are equipped with an
electrical device called transformer . In this work, it is assumed that
power entering a transformer is equal to power exiting it. Such a
transformer is said to be an ideal transformer . It is modeled by a
complex number called ratio . The output voltage is equal to the input
voltage divided by the ratio while the output current is equal to the
input current multiplied by the conjugate of the ratio. This is visible
in figure 1.2 (where @xmath denotes the conjugate transpose). Regular
transformers have a real ratio and some special transformers called
phase-shifting transformers have a complex ratio.

Consider a non-zero integer @xmath . We model an electricity
transmission network by a set of buses @xmath of which a subset @xmath
is connected to generators. Let @xmath denote generated power at bus
@xmath . All buses are connected to a load (i.e. power demand). Let
@xmath denote power demand at bus @xmath . Let @xmath denote voltage at
bus @xmath and @xmath denote current injected into the network at bus
@xmath . The convention used for current means that @xmath is the power
injected into the network at bus @xmath . This means that @xmath at bus
@xmath and @xmath at bus @xmath .

The network links buses to one another through a set of lines @xmath . A
link between two buses is described in figure . In this figure, @xmath
denotes the mutual admittance between buses @xmath ( @xmath for all
@xmath ); @xmath denotes the admittance-to-ground at end @xmath of line
@xmath ; @xmath denotes the ratio of the phase-shifting transformer at
end @xmath of line @xmath ( @xmath if there is no transformer); and
@xmath denotes current injected in line @xmath at bus @xmath .

A formulation of the optimal power flow problem is given in tables
(where @xmath ) and .

According to the second constraint in table , for all @xmath :

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

Together with the first constraint in table , relationship ( ) yields
that for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

Define the admittance matrix @xmath as the complex matrix of size @xmath
by:

  -- -------- --
     @xmath
  -- -------- --

Also, define @xmath and @xmath . It follows that :

  -- -------- --
     @xmath
  -- -------- --

### 1.2 Optimality conditions in optimization

As mentionned in Section 1.1 , current methods for solving the optimal
power flow problem use nonlinear optimization techniques. These aim to
find at least a solution to the optimality conditions, which we present
in this section. Satisfaction of the optimality conditions does not
guarantee global optimality for nonconvex problems, but they do for
convex problems. The proposed approach in this dissertation uses the
optimality conditions to solve convex relaxations of the optimal power
flow problem, a concept presented in the next section.

To discuss optimality conditions, we consider a general framework that
encompasses both the nonconvex and convex cases. Consider a finite
dimensional normed vector space @xmath over @xmath or @xmath and an
objective function @xmath . Also, consider a feasible set @xmath
described by a single function @xmath where @xmath is a Hilbert space
over @xmath or @xmath . The feasible set is also defined by a nonempty
closed convex cone @xmath . Using these notations, the problem to be
solved can be written:

  -- -------- --
     @xmath
  -- -------- --

Objective function @xmath and constraint function @xmath will be
considered twice differentiable. This is valid for the optimal power
flow problem and its convex relaxations.
Relationship between local optimality and derivatives
Let’s illustrate the relationship between local optimality and
derivatives with a simple example. Consider a function @xmath with a
local minimum in 0 equal to 0. The first order Taylor series reads:

  -- -------- --
     @xmath
  -- -------- --

Thus @xmath . The second order Taylor series reads:

  -- -------- --
     @xmath
  -- -------- --

Thus @xmath . If @xmath then the above line of equations tells us that
@xmath is a strict local minimum. Else if @xmath , the third order
Taylor series reads:

  -- -------- --
     @xmath
  -- -------- --

Thus @xmath . The fourth order Taylor series will then imply that @xmath
. We can again distinguish between stricly inequality and equality, and
so on @xmath
In practice, only first order and second order conditions are considered
because higher order derivatives are expensive to compute. Moreover,
higher order derivatives are unrelated to local optimality unless all
lower order derivatives zero out in one point. An example is @xmath
where @xmath and @xmath . The fourth order strict inequality indicates
that 0 is a strict local minimum. On the other hand, if one considers
@xmath and @xmath , this yields @xmath , @xmath , and @xmath so that 0
is a strict local minimum regardless of the value of the third order
derivative.
First and second order necessary optimality conditions
Let’s go back to the general case where @xmath . When there are no
constraints, a locally optimal point must be stationnary, that is to say
that first order derivatives must zero out in that point. Indeed,
consider an optimal point @xmath and write the first order Taylor series
for @xmath close to but different from zero:

  -- -------- --
     @xmath
  -- -------- --

Hence for all @xmath , one has @xmath . Taking @xmath leads to @xmath .
Consider the second order Taylor series for @xmath close to but
different from zero:

  -- -------- --
     @xmath
  -- -------- --

Hence for all @xmath , one has @xmath .
When there are constraints, establishing necessary optimality conditions
requires the concept of duality in some way or another. Let’s establish
these conditions using the notion of saddle point in min-max duality.
This implies an assumption of global rather than local optimality.
Min-max duality consists of writing the objective function as the
supremum of a coupling function, that is to say : @xmath . The
optimization problem can thus be written, for some @xmath and some
@xmath :

  -- -------- --
     @xmath
  -- -------- --

If it is legitimate to swap inf and sup, i.e. @xmath (called no duality
gap ), and there exists a solution to the right-hand problem, then
solving the original problem is equivalent to finding a saddle point of
the coupling function. Indeed, @xmath is saddle point of @xmath if and
only if there is no duality gap and @xmath solves @xmath and @xmath
solves @xmath .
The Lagrange function @xmath where @xmath and @xmath is an example of a
coupling function with the enviable property that @xmath is an affine
function. Let’s consider a saddle point @xmath of the Lagrange function.
By definition :

  -- -------- --
     @xmath
  -- -------- --

The right-hand side inequality means that @xmath is an optimal solution
of the unconstrained problem @xmath . Thus @xmath . Proceeding in the
same fashion with the left-hand side inequality leads to a constrained
optimization problem, so we will proceed differently. The left-hand side
inequality implies:

  -- -------- --
     @xmath
  -- -------- --

Plugging in for @xmath and @xmath yields @xmath , known as complementary
slackness .
To sum up, if @xmath is primal optimal and @xmath is dual optimal and
there is no duality gap, then:

  -- -------- --
     @xmath
  -- -------- --

Note that min-max duality originates from the minimax theorem proven by
Von Neumann in his 1928 paper Zur Theorie der Gesellschaftsspeile . A
generalization of the minimax theorem states that if @xmath and @xmath
are nonempty convex sets, @xmath is compact, and @xmath is continuous
and convex-concave, then:

  -- -------- --
     @xmath
  -- -------- --

In general, the KKT conditions do not guarantee global optimality, nor
even local optimality in fact. If the objective and constraint functions
@xmath and @xmath are convex, then they guarantee global optimality. In
the next section, nonconvexities are removed from the optimal power flow
problem, yielding a relaxed convex problem. This convex problem is
solved using interior-point methods which involve solving for KKT
conditions.

### 1.3 Convex relaxation of the optimal power flow problem

Lavaei and Low [ 66 ] proposed a formulation of the optimal power flow
problem where the variables are the real and imaginary parts of voltages
at each bus. To do so, they defined a real vector @xmath where @xmath
are the complex voltages. Next they proposed a convex relaxation of the
optimal power flow problem. We illustrate their work by considering an
example of power loss minimization.

The system of Figure 1.3 links a generator to a load via a line of
admittance @xmath while respecting upper voltage constraints. Minimizing
power loss reads

  -- -------- -- -------
     @xmath      (1.2)

     @xmath      (1.3)
     @xmath      (1.4)
     @xmath      (1.5)
     @xmath      (1.6)
  -- -------- -- -------

where denotes the imaginary number. Identifying real and imaginary parts
of the variables @xmath and @xmath leads to

  -- -------- -- --------
     @xmath      (1.7)

     @xmath      (1.8)
     @xmath      (1.9)
     @xmath      (1.10)
     @xmath      (1.11)
  -- -------- -- --------

This problem can be rewritten as

  -- -------- -- --------
     @xmath      (1.13)

     @xmath      (1.14)
     @xmath      (1.15)
     @xmath      (1.16)
     @xmath      (1.17)
     @xmath      (1.18)
     @xmath      (1.19)
  -- -------- -- --------

Removing the rank constraint leads to a convex relaxation of the optimal
power flow problem.

As an extension of Lavaei and Low’s work, Sojoudi and Lavaei [ 110 ]
studied the theory behind optimization over graphs. To help with future
work, we provide fully detailed proofs of results found in [ 110 ] . The
reader may skip these by moving to Section 1.4 and still understand the
rest of the dissertation.
Consider

  -- -------- --
     @xmath
  -- -------- --

Let denote the imaginary number. The notation of set @xmath stems from
the following proposition:

###### Proposition 1.1.

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

( @xmath ) Consider a matrix @xmath , that is, there exists @xmath such
that @xmath . Firstly, observe that @xmath . Secondly, for all @xmath ,
@xmath . Lastly, each column of @xmath is a linear combination of , so
that the rank of @xmath is at most 1.
( @xmath ) Matrix @xmath is of rank at most 1 so there exists two
vectors @xmath such that @xmath . Define @xmath such that for all @xmath
:

  -- -------- --
     @xmath
  -- -------- --

Thus :

  -- -------- --
     @xmath
  -- -------- --

Vector @xmath thereby satisfies @xmath . ∎

Given a set of edges @xmath , define the following @xmath -linear
operator :

  -- -------- --
     @xmath
  -- -------- --

Given a graph @xmath , graph theory can be used to decompose the
constraint @xmath into several smaller constraints. (The graph @xmath
typically corresponds to the sparsity pattern. In a such sparse
optimization problem, the constraint @xmath may be replaced by @xmath .)
First, two lemmas are presented.

###### Lemma 1.2.

Any undirected connected graph has a spanning tree.

###### Proof.

Let @xmath be the set of edges of an undirected connected graph. Define
the following set :

  -- -------- --
     @xmath
  -- -------- --

@xmath is a partially ordered set since @xmath is a partially ordered
set and @xmath . Consider a totally ordered subset of @xmath and name it
@xmath . @xmath is a bound of @xmath in @xmath . Zorn’s lemma implies
that @xmath contains a maximal element. If the maximal element is not a
spanning tree, there exists a vertex not contained in it. Since the
graph is connected, there exists a path in @xmath linking this vertex to
a vertex in the maximum tree. The union of the maximum tree and that
path forms a tree of @xmath that contradicts the maximality of the
maximum tree. Thus the maximum tree is a spanning tree of @xmath . ∎

###### Lemma 1.3.

Let @xmath denote a spanning tree of a finite, undirected, and connected
graph @xmath and let @xmath denote some real numbers. Assume that @xmath
for all @xmath . Then there exists some real numbers @xmath such that:

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

Simply define @xmath by choosing a random real number @xmath for some
@xmath and for all @xmath , choose @xmath where the sum is taken over
the path in @xmath linking @xmath to @xmath . This is possible because
@xmath is a finite graph. Thus defined, the real numbers @xmath satisfy
for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

because all terms in the sums associated respectively to @xmath and
@xmath cancel each other out except for @xmath . Indeed, @xmath so the
paths starting at @xmath and @xmath and both ending at @xmath are the
same expect that one contains @xmath or @xmath and the other doesn’t. If
the former contains @xmath , the only term that does not cancel out is
@xmath . If the latter contains @xmath , the only term that does not
cancel out is @xmath . ∎

Let @xmath denote a cycle basis of @xmath and let @xmath denote the set
of bridge edges of @xmath . Define the following set :

  -- -------- --
     @xmath
  -- -------- --

###### Proposition 1.4.

The following statement holds:

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

( @xmath ) It suffices to see that @xmath for all @xmath . Indeed,
@xmath implies that @xmath .
( @xmath ) Consider @xmath . For all @xmath , there exists @xmath and
@xmath such that :

  -- -------- --
     @xmath
  -- -------- --

Thus, for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

Moreover, @xmath so @xmath if @xmath or @xmath . It follows that for all
@xmath :

  -- -- -------- -- -- ---------
        @xmath         (1.20a)
        @xmath         (1.20b)
  -- -- -------- -- -- ---------

@xmath is an undirected connected graph so there exists a spanning tree
@xmath of @xmath according to lemma . The real numbers @xmath satisfy
@xmath due to @xmath . Indeed, given @xmath , there exists some @xmath
such that @xmath and @xmath so that @xmath and @xmath . Moreover, the
set of vertices @xmath is finite. Lemma can thereby by applied to prove
that there exists a vector @xmath such that :

  -- -- -------- -- -- ---------
        @xmath         (1.21a)
        @xmath         (1.21b)
  -- -- -------- -- -- ---------

Notice that for all @xmath ,

  -- -------- --
     @xmath
  -- -------- --

Moreover, for all @xmath ,

  -- -------- --
     @xmath
  -- -------- --

To sum up :

  -- -------- --
     @xmath
  -- -------- --

Therefore there exists @xmath such that :

  -- -------- --
     @xmath
  -- -------- --

∎

###### Lemma 1.5.

Let @xmath denote a cycle of a finite and undirected graph @xmath and
let @xmath denote some real numbers. Assume that @xmath for all @xmath
and that @xmath . Then for each vertex @xmath of @xmath , there exists a
real number @xmath such that:

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

Simply define the set of all @xmath ’s for each vertex @xmath of @xmath
by choosing a random real number @xmath for some vertex @xmath of @xmath
and for all other vertices @xmath , choose @xmath where the sum is taken
over the path in @xmath linking @xmath to @xmath for some orientation of
@xmath . This is possible because @xmath is a finite graph. Thus
defined, the real numbers @xmath satisfy for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

Indeed, for all @xmath but the edge ending in @xmath , all terms in the
sums associated respectively to @xmath and @xmath cancel each other out
except for @xmath . As for the edge @xmath ending in @xmath , notice
that @xmath where the sum is taken over the path in @xmath linking
@xmath to @xmath so that @xmath . It is assumed that @xmath thus @xmath
. It follows that @xmath , ie @xmath . ∎

###### Proposition 1.6.

The following statement holds:

  -- -------- --
     @xmath
  -- -------- --

###### Proof.

( @xmath ) Consider @xmath . For all @xmath , @xmath thus @xmath .
Consider a cycle @xmath . There exists @xmath such that for all @xmath ,
@xmath . Therefore:

  -- -------- --
     @xmath
  -- -------- --

( @xmath ) Consider @xmath such that @xmath . The following is true for
all @xmath :

  -- -- -------- -- -- ---------
        @xmath         (1.22a)
        @xmath         (1.22b)
  -- -- -------- -- -- ---------

Consider a cycle @xmath . The real numbers @xmath satisfy @xmath due to
@xmath . Moreover, it is assumed that @xmath . Lemma can therefore be
used to show that there exists @xmath such that:

  -- -- -------- -- -- ---------
        @xmath         (1.23a)
        @xmath         (1.23b)
  -- -- -------- -- -- ---------

Notice that for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

Thus for all @xmath :

  -- -------- --
     @xmath
  -- -------- --

Moreover, it is assumed that :

  -- -------- --
     @xmath
  -- -------- --

Therefore :

  -- -------- --
     @xmath
  -- -------- --

where the equality follows from proposition . ∎

### 1.4 Definitions of complex numbers

Complex numbers are a central aspect of the thesis. They are used to
model an oscillatory phenomenon, namely alternating current. We now
consider several definitions of complex numbers.

A complex number @xmath can be thought of as the matrix:

  -- -------- --
     @xmath
  -- -------- --

The additions and multiplications of complex numbers translate into
additions and multiplications of real matrices. Concerning addition, we
have

  -- -------- --
     @xmath
  -- -------- --

Concerning multiplication, we have:

  -- -------- --
     @xmath
  -- -------- --

In particular, we have

  -- -------- --
     @xmath
  -- -------- --

As stated above, a complex number can be viewed as a real matrix of size
@xmath . More generally, a complex square matrix can be viewed as a real
matrix of double its size. This will become very helpful when we
consider optimization over complex matrix variables in Chapter 7 .

We note that complex numbers can also be defined using the Euclidian
division of polynomials. The idea is to build a solution to the equation
@xmath though it has no real solution. To do so, consider the ring of
polynomials @xmath with one real indeterminate @xmath . The remainder of
@xmath when divided by @xmath is equal to @xmath , which is written
@xmath . More generally, given a polynomial @xmath , its division by
@xmath has a remainder of the form @xmath where @xmath and @xmath are
some real numbers. Indeed, the degree of the remainder must be strictly
less than the degree of @xmath . Let @xmath denote the equivalence class
modulo @xmath represented by @xmath . The set of equivalence classes is
thus equal to @xmath . This set may be identified with the set of
complex numbers because it is isomorphic to it. Indeed, consider two
classes @xmath and @xmath with @xmath . Concerning addition, we have

  -- -------- --
     @xmath
  -- -------- --

since

  -- -------- --
     @xmath
  -- -------- --

Concerning multiplication, we have

  -- -------- --
     @xmath
  -- -------- --

since

  -- -------- --
     @xmath
  -- -------- --

## Chapter 2 Lasserre hierarchy for small-scale networks

Finding a global solution to the optimal power flow (OPF) problem is
difficult due to its nonconvexity. A convex relaxation in the form of
semidefinite optimization (SDP) had attracted much attention when I
started my Ph.D. Indeed, it yielded a global solution in several
practical cases. However, it did not in all cases, and such cases had
been documented in several publications. Here we present another SDP
method known as the moment-sos (sum of squares) approach, which
generates a sequence that converges towards a global solution to the OPF
problem at the cost of higher runtime. Our finding is that in the small
examples where the previously studied SDP method fails, this approach
finds the global solution. The higher cost in runtime is due to an
increase in the matrix size of the SDP problem, which can vary from one
instance to another. Numerical experiment shows that the size is very
often a quadratic function of the number of buses in the network,
whereas it is a linear function of the number of buses in the case of
the previously studied SDP method. The material in this chapter is based
on the publication:
C. Josz, J. Maeght, P. Panciatici, and J.C. Gilbert , Application of the
Moment-SOS Approach to Global Optimization of the OPF Problem ,
Institute of Electrical and Electronics Engineers, Transactions on Power
Systems, 30, pp. 463–470, May 2014. [doi] [preprint]

### 2.1 Introduction

The optimal power flow can be cast as a nonlinear optimization problem
which is NP-hard, as was shown in [ 66 ] . So far, the various methods [
50 , 88 ] that have been investigated to solve the OPF can only
guarantee local optimality, due to the nonconvexity of the problem.
Recent progress suggests that it may be possible to design a method,
based on semidefinite optimization (SDP), that yields global optimality
rapidly.

The first attempt to use SDP to solve the OPF problem was made by Bai et
al. [ 13 ] in 2008. In [ 66 ] , Lavaei and Low show that the OPF can be
written as an SDP problem, with an additional constraint imposing that
the rank of the matrix variable must not exceed 1. They discard the rank
constraint, as it is done in Shor’s relaxation [ 106 ] , a procedure
which applies to quadratically constrained quadratic problems (see [ 116
, 71 ] and the references therein). They also accept quartic terms that
appear in some formulations of the OPF, transforming them by Schur’s
complement. Their finding is that for all IEEE benchmark networks,
namely the 9, 14, 30, 57, 118, and 300-bus systems, the rank constraint
is satisfied if a small resistance is added in the lines of the network
that have zero resistance. Such a modification to the network is
acceptable because in reality, resistance is never equal to zero.

There are cases when the rank constraint is not satisfied and a global
solution can thus not be found. Lesieutre et al. [ 67 ] illustrate this
with a practical 3-bus cyclic network. Gopalakrishnan et al. [ 45 ] find
yet more examples by modifying the IEEE benchmark networks. Bukhsh et
al. [ 22 ] provide a 2-bus and a 5-bus example. In addition, they
document the local solutions to the OPF in many of the above-mentioned
examples where the rank constraint is not satisfied [ 23 ] .

Several papers propose ways of handling cases when the rank constraint
is not satisfied. Gopalakrishnan et al. [ 45 ] propose a branch and
reduce algorithm. It is based on the fact that the rank relaxation gives
a lower bound of the optimal value of the OPF. But according to the
authors, using the classical Lagrangian dual to evaluate a lower bound
is about as efficient. Sojoudi and Lavaei [ 110 ] prove that if one
could add controllable phase-shifting transformers to every loop in the
network and if the objective is an increasing function of generated
active power, then the rank constraint is satisfied. Though numerical
experiments confirm this [ 41 ] , such a modification to the network is
not realistic, as opposed to the one mentioned earlier.

Cases where the rank constraint holds have been identified. Authors of [
19 , 130 , 111 ] prove that the rank constraint is satisfied if the
graph of the network is acyclic and if load over-satisfaction is
allowed. This is typical of distribution networks but it is not true of
transmission networks.

This paper examines the applicability of the moment-sos (sum of squares)
approach to the OPF. This approach [ 61 , 89 , 62 ] aims at finding
global solutions to polynomial optimization problems, of which the OPF
is a particular instance. The approach can be viewed as an extension of
the SDP method of [ 66 ] . Indeed, it proposes a sequence of SDP
relaxations whose first element is the rank relaxation in many cases.
The subsequent relaxations of the sequence become more and more
accurate. When the rank relaxation fails, it is therefore natural to see
whether the second order relaxation provides the global minimum, then
the third, and so on.

The limit to this approach is that the complexity of the relaxations
rapidly increases. The matrix size of the SDP relaxation of order @xmath
is roughly equal to the number of buses in the network to the power
@xmath . Surprisingly, in the 2, 3, and 5-bus systems found in [ 67 , 22
] where the rank relaxation fails, the second order relaxation nearly
always finds the global solution.

Below, section 2.2 shows that the OPF can be viewed as a polynomial
optimization problem. The moment-sos approach which aims at solving such
problems is described in section 2.3 . In section 2.4 , numerical
results show that this approach successfully finds the global solution
to the 2, 3, and 5-bus systems mentioned earlier. Conclusions are given
in section 2.5 .

### 2.2 Polynomial optimization formulation

In order to obtain a polynomial formulation of the OPF, we proceed in 3
steps. First, we write a formulation in complex numbers. Second, we use
it to write a formulation in real numbers. Third, we use the real
formulation to write a polynomial formulation.

Let @xmath and @xmath denote the conjugate transpose of a complex vector
and of a complex matrix @xmath respectively. It can be deduced from [
110 ] that there exist finite sets @xmath and @xmath , Hermitian
matrices @xmath of size @xmath , complex matrices @xmath and @xmath of
size @xmath , and complex numbers @xmath and @xmath such that the OPF
can be written as

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

subject to

  -- -------- -- -------
     @xmath      (2.2)
     @xmath      (2.3)
  -- -------- -- -------

Constraints ( 2.3 ) correspond to bounds on apparent power flow.
Constraints ( 2.2 ) correspond to all other constraints.

Let @xmath denote @xmath as is done in [ 66 ] . In order to transform
the complex formulation of the OPF ( 2.1 )-( 2.3 ) into a real number
formulation, observe that @xmath , where the superscript @xmath denotes
transposition,

  -- -------- -------- --
     @xmath   @xmath
     @xmath   @xmath
  -- -------- -------- --

Then ( 2.1 )-( 2.3 ) becomes

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

subject to

  -- -------- -- -------
     @xmath      (2.5)
     @xmath      (2.6)
     @xmath      (2.7)
  -- -------- -- -------

We recall that a polynomial is a function @xmath , where @xmath is a
finite set of integer multi-indices, the coefficients @xmath are real
numbers, and @xmath is the monomial @xmath . Its degree, denoted @xmath
, is the largest @xmath associated with a nonzero @xmath .

The formulation of the OPF in real numbers ( 2.4 )-( 2.7 ) is said to be
a polynomial optimization problem since the functions that define it are
polynomials. Indeed, the objective ( 2.4 ) is a polynomial of @xmath of
degree 4, the constraints ( 2.5 )-( 2.6 ) are polynomials of of
degree 2, and the constraints ( 2.7 ) are polynomials of of degree 4.

Formulation ( 2.4 )-( 2.7 ) will however not be used below because it
has infinitely many global solutions. Indeed, formulation ( 2.1 )-( 2.3
) from which it derives is invariant under the change of variables
@xmath where @xmath . This invariance property transfers to ( 2.4 )-(
2.7 ). An optimization problem with non isolated solutions is generally
more difficult to solve than one with a unique solution [ 17 ] . This
feature manifests itself in some properties of the moment-sos approach
described in section 2.3 . For this reason, we choose to arbitrarily set
the voltage phase at bus @xmath to zero. Bearing in mind that @xmath ,
this can be done by replacing voltage constraint ( 2.8 ) at bus @xmath
by ( 2.9 ):

  -- -------- -- -------
     @xmath      (2.8)
     @xmath      (2.9)
  -- -------- -- -------

In light of ( 2.9 ), a polynomial optimization problem where there are
@xmath variables instead of @xmath variables can be formulated. More
precisely, the OPF can be cast as the following polynomial optimization
problem

PolyOPF:

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

subject to

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

where @xmath is an integer, @xmath denotes the real coefficients of the
polynomial functions @xmath , and summations take place over @xmath .
The summations are nevertheless finite because only a finite number of
coefficients are nonzero.

### 2.3 Moment-sos approach

We first review some theoretical aspects of the moment-sos approach (a
nice short account can be found in [ 9 ] , and more in [ 64 , 16 ] ).
Next, we present a set of relaxations of PolyOPF obtained by this method
and illustrate it on a simple example. Finally, we emphasize the
relationship between the moment-sos approach and the rank relaxation of
[ 66 ] .

The moment-sos approach has been designed to find global solutions to
polynomial optimization problems. It is grounded on deep results from
real algebraic geometry. The term moment-sos derives from the fact that
the approach has two dual aspects: the moment and the sum of squares
approaches. Both approaches are dual of one another in the sense of
Lagrangian duality [ 99 ] . Below, we focus on the moment approach
because it leads to SDP problems that have a close link with the
previously studied SDP method in [ 66 ] .

Let be a subset of @xmath . The moment approach rests on the surprising
(though easy to prove) fact that the problem @xmath : @xmath is
equivalent to the convex optimization problem in @xmath :

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

Although the latter problem has a simple structure, it cannot be solved
directly, since its unknown @xmath is an infinite dimensional object.
Nevertheless, the realized transformation suggests that the initial
difficult global optimization problem can be structurally simplified by
judiciously expressing it on a space of larger dimension. The moment-sos
approach goes along this way by introducing a hierarchy of more and more
accurate approximations of problem ( 2.12 ), hence ( 2.10 )-( 2.11 ),
defined on spaces of larger and larger dimension.

When @xmath is a polynomial and @xmath : @xmath , for @xmath is defined
by polynomials @xmath like in PolyOPF, it becomes natural to approximate
the measure @xmath by a finite number of its moments. The moment of
@xmath , associated with @xmath , is the real number @xmath . Then, when
@xmath is the polynomial in ( 2.10 ), the objective of ( 2.12 ) becomes
@xmath , whose linearity in the new unknown @xmath is transparent. The
constraint @xmath is also readily transformed into @xmath . In contrast,
expressing which are the vectors @xmath that are moments of a positive
measure @xmath on (the other constraint in ( 2.12 )) is a much more
difficult task known as the moment problem , which has been studied for
over a century [ 97 ] . It is that constraint that is approximated in
the moment-sos approach, with more and more accuracy in spaces of higher
and higher dimension.

The sum of squares approach is dual to the moment approach in the sense
of Lagrangian duality [ 99 ] . It relies on the fact that minimizing a
function @xmath over a set is equivalent to maximizing a real number
@xmath under the constraints @xmath for all @xmath . These trivial
linear constraints are intractable because there is an infinite number
of them. In the case of polynomial optimization, one recovers the
problem of finding certificates ensuring the positivity of the
polynomial @xmath on the semi-algebraic set , which involves sums of
squares of polynomials [ 76 ] . Relaxations consist in imposing degree
bounds on these sos polynomials.

Lasserre [ 62 ] proposes a sequence of relaxations for any polynomial
optimization problem like PolyOPF that grow better in accuracy and
bigger in size when the order @xmath of the relaxation increases. Here
and below, @xmath is an integer larger than or equal to each @xmath for
all @xmath (we have denote by @xmath the ceiling operator).

Let @xmath denote that @xmath is a symmetric positive semidefinite
matrix. Define @xmath , whose cardinality is @xmath , and denote by
@xmath a matrix indexed by the elements of @xmath .

Relaxation of order d:

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

subject to

  -- -------- -- --------
     @xmath      (2.14)
     @xmath      (2.15)
     @xmath      (2.16)
  -- -------- -- --------

We have already discussed the origin of ( 2.13 )-( 2.14 ) in the above
SDP problem, while ( 2.15 )-( 2.16 ) are necessary conditions to ensure
that @xmath is formed of moments of some positive measure on . When
@xmath increases, these problems form a hierarchy of semidefinite
relaxations , called that way because the objective ( 2.13 ) is not
affected and the feasible set is reduced as the size of the matrices in
( 2.15 )-( 2.16 ) increases. These properties show that the optimal
value of problem ( 2.13 )-( 2.16 ) increases with @xmath and remains
bounded by the optimal value of ( 2.10 )-( 2.11 ).

For the method to give better results, a ball constraint @xmath must be
added according to the technical assumption 1.1 in [ 9 ] . For the OPF
problem, this can be done easily by setting @xmath to @xmath without
modifying the problem. The following two properties hold in this case [
9 , theorem 1.12] :

1.  the optimal values of the hierarchy of semidefinite relaxations
    increasingly converge toward the optimal value of PolyOPF,

2.  let @xmath denote a global solution to the relaxation of order
    @xmath and @xmath denotes the canonical basis of @xmath ; if PolyOPF
    has a unique global solution, then @xmath converges towards the
    global solution to PolyOPF as @xmath tends to @xmath .

The largest matrix size of the moment relaxation appears in ( 2.14 ) and
has the value @xmath , where @xmath is the number of buses. For a fixed
@xmath , matrix size is therefore equal to @xmath . This makes high
order relaxations too large to compute with currently available SDP
software packages. Consequently, the success of the moment-sos approach
relies wholly upon its ability to find a global solution with a low
order relaxation, for which there is no guarantee. Note that the global
solution is found by a finite order relaxation under conditions that
include the convexity of the problem [ 63 ] (not the case of PolyOPF
though) or the positive definiteness of the Hessian of the Lagrangian at
the saddle points of the Lagrangian [ 39 ] (open question in the case of
PolyOPF).

#### Moment-sos relaxations and rank relaxation

When the polynomials @xmath defining PolyOPF are quadratic, the first
order ( @xmath ) relaxation ( 2.13 )-( 2.16 ) is equivalent to Shor’s
relaxation [ 60 ] . To make the link with the rank relaxation of [ 66 ]
, consider now the case when the varying part of the @xmath ’s are
quadratic and homogeneous like in [ 66 ] , that is @xmath for all @xmath
, with symmetric matrices @xmath and scalars @xmath . Then introducing
the vector and the matrix @xmath defined by @xmath and @xmath , reads

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

subject to

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

Using Schur’s complement, the positive semidefiniteness condition in (
2.18 ) is equivalent to @xmath . Since does not intervene elsewhere in (
2.17 )-( 2.18 ), it can be eliminated and the constraints of the problem
can be replaced by

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

The pair made of ( 2.17 ) and ( 2.19 ) is the rank relaxation of [ 66 ]
. We have just shown that the equivalence between that the SDP
relaxation of [ 66 ] and to the first-order moment relaxation holds when
the varying part of the @xmath ’s are quadratic and homogeneous. For the
OPF problem, this certainly occurs when

1.  the objective of the OPF is an affine function of active power,

2.  there are no constraints on apparent power flow,

3.  ( 2.8 ) is not replaced by ( 2.9 ).

Point 1 ensures that the objective is quadratic and has a homogeneous
varying part. Points 2 and 3 guarantee the same property for the
constraint functions.

### 2.4 Numerical results

We present numerical results for the moment-sos approach applied to
instances of the OPF for which the rank relaxation method of [ 66 ]
fails to find the global solution. We focus on the WB2 2-bus system,
LMBM3 3-bus system, and the WB5 5-bus system that are described in [ 22
] . Note that LMBM3 is also found in [ 67 ] . For each of the three
systems, the authors of [ 22 ] modify a bound in the data and specify a
range for which the rank relaxation fails. We consider 10 values
uniformly distributed in the range in order to verify that the rank
relaxation fails and to assess the moment-sos approach. We proceed in
accordance with the discussion of section 2.3 by adding the redundant
ball constraint. Surprisingly, the second order relaxation whose
greatest matrix size is equal to @xmath nearly always finds the global
solution.

The materials used are:

-   Data of WB2, LMBM3, WB5 systems available online [ 23 ] ,

-   Intel® Xeon™ MP CPU 2.70 GHz 7.00 Go RAM,

-   MATLAB version 7.7 2008b,

-   MATLAB-package MATPOWER version 3.2 [ 132 ] ,

-   SeDuMi 1.02 [ 115 ] with tolerance parameter pars.eps set to @xmath
    for all computations,

-   MATLAB-based toolbox YALMIP [ 69 ] to compute Optimization 4 (Dual
    OPF) in [ 66 ] that yields the solution to the rank relaxation,

-   MATLAB-package GloptiPoly version 3.6.1 [ 48 ] to compute solutions
    to a hierarchy of SDP relaxations ( 2.13 )-( 2.16 ).

The same precision is used as in the solutions of the test archives [ 23
] . In other words, results are precise up to @xmath p.u. for voltage
phase, @xmath degree for angles, @xmath MW for active power, @xmath MVA
for reactive power, and cent per hour for costs. Computation time is
several seconds.

GloptiPoly can guarantee that it has found a global solution to a
polynomial optimization problem, up to a given precision. This is
certainly the case when it finds a feasible point giving to the
objective a value sufficiently close to the optimal value of the
relaxation.

#### 2-bus network: WB2

Authors of [ 22 ] observe that in the WB2 2-bus system of figure 2.1 ,
the rank constraint is not satisfied in the rank relaxation method of [
66 ] when @xmath In table 2.1 , the first column is made up of 10 points
in that range that are uniformly distributed. The second column contains
the lowest order of the relaxations that yield a global solution. The
optimal value of the relaxation of that order is written in the third
column. The fourth column contains the optimal value of the rank
relaxation (it is put between parentheses when the relaxation is
inexact).

The hierarchy of SDP relaxations is defined for @xmath because the
objective is an affine function and there are no apparent flow
constraints. Let’s explain how it works in the case where @xmath p.u.
The optimal value of the first order relaxation is 861.51 $/h, that of
the second order relaxation is 901.38 $/h, and that of the third is
905.73 $/h. This is coherent with point 1 of the discussion of section
2.3 that claims that the optimal values increase with @xmath . Computing
higher orders is not necessary because GloptiPoly numerically proves
global optimality for the third order.

Notice that for @xmath p.u. the value of the rank relaxation found in
table 2.1 (888.08 $/h) is different from the value of the first order
relaxation (861.51 $/h). If we run GloptiPoly with ( 2.8 ) instead of (
2.9 ), the optimal value of the first order relaxation is equal
888.08 $/h as expected according to section 2.3 .

For @xmath and @xmath (see the first and last rows of table 2.1 ), the
rank constraint is satisfied in the rank relaxation method so its
optimal value is equal to the one of the successful moment-sos method.
In between those values, the rank constraint is not satisfied since the
optimal value is less than the optimal value of the OPF. Notice the
correlation between the results of table 2.1 and the upper half of
figure 8 in [ 22 ] . Indeed, the figure shows the optimal value of the
OPF is constant whereas the optimal value of the rank relaxation
decreases in a linear fashion when @xmath

Surprisingly and encouragingly, according to the second column of table
2.1 , the second order moment-sos relaxation finds the global solution
in 8 out of 10 times, and the third order relaxation always find the
global solution.

Remark: The fact that the rank constraint is not satisfied for the WB2
2-bus system of [ 22 ] seems in contradiction with the results of papers
[ 19 , 130 , 111 ] . Indeed, the authors of the papers state that the
rank is less than or equal to 1 if the graph of the network is acyclic
and if load over-satisfaction is allowed. However, load
over-satisfaction is not allowed in this network. For example, for
@xmath p.u., adding 1 MW of load induces the optimal value to go down
from 905.73 $/h to 890.19 $/h. One of the sufficient conditions in [ 18
] for the rank is less than or equal to 1 relies on the existence of a
strictly feasible point. It is not the case here because equality
constraints must be enforced in the power balance equation.

#### 3-bus network: LMBM3

We observe that in the LMBM3 3-bus system of figure 2.2 , the rank
constraint is not satisfied in the rank relaxation method of [ 66 ] when
@xmath . Below @xmath , no solutions can be found by the OPF solver
runopf in MATPOWER nor by the hierarchy of SDP relaxations. At @xmath ,
the rank constraint is satisfied in the rank relaxation method so its
optimal value is equal to the optimal value of the OPF found by the
second order relaxation; see to the last row of table 2.2 .

The objective of the OPF is a quadratic function of active power so the
hierarchy of SDP relaxations is defined for @xmath . Again, it is
surprising that the second order moment-sos relaxation always finds the
global solution to the LMBM3 system, as can be seen in the second column
of table 2.2 .

Authors of [ 66 ] make the assumption that the objective of the OPF is
an increasing function of generated active power. The moment-sos
approach does not require such an assumption. For example, when @xmath ,
active generation at bus 1 is equal to 148.07 MW and active generation
at bus 2 is equal to 170.01 MW using the increasing cost function of [
67 , 23 ] . Suppose we choose a different objective which aims at
reducing deviation from a given active generation plan at each
generator. Say that this plan is @xmath at bus 1 and @xmath at bus 2.
The objective function is equal to @xmath . It is not an increasing
function of @xmath and @xmath . The second order relaxation yields a
global solution in which active generation at bus 1 is equal to
169.21 MW and active generation at bus 2 is equal to 149.19 MW.

#### 5-bus network: WB5

Authors of [ 22 ] observe that in the WB5 5-bus system of figure 2.3 ,
the rank constraint is not satisfied in the rank relaxation method of [
66 ] when @xmath . Above @xmath , no solutions can be found by the OPF
solver runopf in MATPOWER. At @xmath , the rank constraint is satisfied
in the rank relaxation method so its optimal value is equal to the
optimal value of the OPF found by the second order moment-sos
relaxation; see the first row of table 2.3 . As for the 9 values
considered greater than @xmath , the rank constraint is not satisfied
since the optimal value is not equal to the optimal value of the OPF.
Notice that the objective of the OPF is a linear function of active
power and there are bounds on apparent flow so the hierarchy of SDP
relaxations is defined for @xmath .

When @xmath , the hierarchy of SDP relaxations is unable to find a
feasible point, hence the empty slots in the last row of table 2.3 .
Apart from that value, the second order moment-sos relaxation again
always finds the global solution according to the second column of table
2.3 .

Waki et al. [ 125 ] have produced a piece of software called SparsePOP [
127 ] similar to GloptiPoly only that it seeks to reduce problem size in
Lasserre’s relaxations using matrix completion theory in semidefinite
programming. SparsePOP successfully solves the systems studied in this
paper to global optimality but fails to reduce the size of the
moment-sos relaxations and to solve problems with a larger number of
buses.

### 2.5 Conclusion

This chapter examined the application of the moment-sos (sum of squares)
approach to the global optimization of the optimal power flow (OPF)
problem. The result is that the OPF can be successfully convexified in
the case of several small networks where a previously known SDP method
fails. The SDP problems considered in this paper can be viewed as
extensions of the previously used rank relaxation. It is guaranteed to
be more accurate than the previous one but requires more runtime.

Interestingly, Daniel K. Molzahn and Ian A. Hiskens independently made
very similar findings [ 79 ] as presented in this chapter. They
successfully solved networks with up to 10 buses. A group at IBM
research Ireland was also working on the same ideas [ 44 ] . They
managed to solve networks with up to 40 buses. To do so, they formulated
the OPF problem as a quadratically-constrained quadratic problem and
used SparsePOP. This works better than what we had tried, namely using
SparsePOP with an OPF formulation with monomials of order 4.

We next focus on a property of the moment-sos approach to further prove
its applicability in practice. In the small examples considered in this
chapter, there is no duality gap at each order of the moment-sos
hierarchy according to numerical results. This property is necessary for
efficient solvers to work such as interior-point solvers. However, in
the existing literature, there were no results guaranteeing this
property. In the next chapter, we prove there is no duality gap in the
moment-sos hierarchy in the presence of a ball constraint. We also
explain why there is no duality gap when applying the moment-sos
hierarchy to the OPF without a ball constraint.

## Chapter 3 Zero duality gap in the Lasserre hierarchy

A polynomial optimization problem (POP) consists of minimizing a
multivariate real polynomial on a semi-algebraic set @xmath described by
polynomial inequalities and equations. In its full generality it is a
nonconvex, multi-extremal, difficult global optimization problem. More
than an decade ago, J. B. Lasserre proposed to solve POPs by a hierarchy
of convex semidefinite optimization (SDP) relaxations of increasing
size. Each problem in the hierarchy has a primal SDP formulation (a
relaxation of a moment problem) and a dual SDP formulation (a
sum-of-squares representation of a polynomial Lagrangian of the POP). In
this chapter, we show that there is no duality gap between each primal
and dual SDP problem in Lasserre’s hierarchy, provided one of the
constraints in the description of set @xmath is a ball constraint. Our
proof uses elementary results on SDP duality, and it does not assume
that @xmath has a strictly feasible point. The material in this chapter
is based on the publication:
C. Josz and D. Henrion , Strong Duality in Lasserre’s Hierarchy for
Polynomial Optimization , Optimization Letters, February 2015. [doi]
[preprint]

### 3.1 Introduction

Consider the following polynomial optimization problem (POP)

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where we use the multi-index notation @xmath for @xmath , @xmath and
where the data are polynomials @xmath so that in the above sums only a
finite number of coefficients @xmath and @xmath are nonzero. Let @xmath
denote its feasible set:

  -- -------- --
     @xmath
  -- -------- --

To solve POP ( 3.1 ), Lasserre [ 61 , 62 ] proposed a semidefinite
optimization (SDP) relaxation hierarchy with guaranteed asymptotic
global convergence provided an algebraic assumption holds:

###### Assumption 3.1.

There exists a polynomial @xmath such that @xmath is bounded and @xmath
where polynomials @xmath , @xmath are sums of squares (SOS) of other
polynomials.

Nie et al. [ 87 ] have proven that Assumption 3.1 also implies
generically finite convergence, that is to say that for almost every
instance of POP, there exists a finite-dimensional SDP relaxation in the
hierarchy whose optimal value is equal to the optimal value of the POP.
Assumption 3.1 can be difficult to check computationally (as the degrees
of the SOS multipliers can be arbitrarily large), and it is often
replaced by the following slightly stronger assumption:

###### Assumption 3.2.

The description of @xmath contains a ball constraint, say @xmath for
some real number @xmath .

Indeed, under Assumption 3.2 , simply choose @xmath , @xmath , and
@xmath to conclude that Assumption 3.1 holds as well. In practice, it is
often easy to see to it that Assumption 3.2 holds. In the case of a POP
with a bounded feasible set, a redundant ball constraint can be added.

More generally, if the intersection of the sublevel set @xmath with the
feasible set of the POP is bounded for some feasible point @xmath , then
a redundant ball constraint can also be added. As an illustration, a
reviewer suggested the example of the minimization of @xmath on the
unbounded set defined on @xmath by the constraint @xmath . The
intersection of the feasible set with the set defined by the constraint
@xmath is included in the ball defined by @xmath so that the POP can be
equivalently defined on the bounded set @xmath .

Each problem in Lasserre’s hierarchy consists of a primal-dual SDP pair,
called SDP relaxation, where the primal corresponds to a convex moment
relaxation of the original (typically nonconvex) POP, and the dual
corresponds to a SOS representation of a polynomial Lagrangian of the
POP. The question arises of whether the duality gap vanishes in each SDP
relaxation. This is of practical importance because numerical algorithms
to solve SDP problems are guaranteed to converge only where there is a
zero duality gap, and sometimes under the stronger assumption that there
is a primal or/and dual SDP interior point.

In [ 104 , Example 4.9] , Schweighofer provides a two-dimensional POP
with no interior point for which Assumption 3.1 holds, yet a duality gap
exists at the first SDP relaxation: @xmath , with primal SDP value equal
to zero and dual SDP value equal to minus infinity. This shows that a
stronger assumption is required to ensure a zero SDP duality gap. A
sufficient condition for strong duality has been given in [ 62 ] : set
@xmath should contain an interior point. However, this may be too
restrictive: in the proof of Lemma 1 in [ 47 ] the authors use
notationally awkward arguments involving truncated moment matrices to
prove the absence of SDP duality gap for a certain set @xmath that
contains no interior point. This shows that the existence of an interior
point is not necessary for a zero SDP duality gap. More generally, it is
not possible to assume the existence of an interior point for POPs with
explicit equality constraints, and a weaker assumption for zero SDP
duality gap is welcome.

Motivated by these observations, in this note we prove that under the
basic Assumption 3.2 on the description of set @xmath , there is no
duality gap in the SDP hierarchy. Our interpretation of this result, and
the main message of this contribution, is that in the context of
Lasserre’s hierarchy for POP, a practically relevant description of a
bounded semialgebraic feasibility set must include a redundant ball
constraint.

### 3.2 Proof

For notational convenience, let @xmath denote the unit polynomial.
Define the localizing matrix

  -- -------- --
     @xmath
  -- -------- --

where @xmath is the smallest integer greater than or equal to half the
degree of @xmath , for @xmath , and @xmath . The Lasserre hierarchy for
POP ( 3.1 ) consists of a primal moment SDP problem

  -- -------- --
     @xmath
  -- -------- --

and a dual SOS SDP problem

  -- -------- --
     @xmath
  -- -------- --

where @xmath stands for matrix @xmath positive semidefinite, @xmath is
the inner product between two matrices. The Lasserre hierarchy is
indexed by an integer @xmath . The primal-dual pair @xmath is called the
SDP relaxation of order @xmath for POP ( 3.1 ). The size of the primal
variable @xmath is @xmath and the size of the dual variable @xmath is
@xmath

Let us define the following sets:

-   @xmath : feasible points for @xmath ;

-   @xmath : feasible points for @xmath ;

-   @xmath : strictly feasible points for @xmath ;

-   @xmath : strictly feasible points for @xmath ;

-   @xmath : optimal solutions for @xmath ;

-   @xmath : optimal solutions for @xmath .

Finally, let us denote by @xmath the infimum in problem @xmath and by
@xmath the supremum in problem @xmath .

###### Lemma 3.3.

@xmath nonempty or @xmath nonempty implies @xmath .

Lemma 3.3 is classical in convex optimization, and it is generally
called Slater’s condition, see e.g. [ 105 , Theorem 4.1.3] .

###### Lemma 3.4.

The two following statements are equivalent :

1.  @xmath is nonempty and @xmath is nonempty;

2.  @xmath is nonempty and bounded.

A proof of Lemma 3.4 can be found in [ 122 ] . According to Lemmas 3.3
and 3.4 , @xmath nonempty and bounded implies strong duality. This
result is also mentioned without proof at the end of [ 105 , Section
4.1.2] .

###### Lemma 3.5.

Under Assumption 3.2 , set @xmath is included in the Euclidean ball of
radius
@xmath centered at the origin.

###### Proof.

If @xmath , the result is obvious. If not, consider a feasible point
@xmath . Let @xmath . In the SDP problem @xmath , the localizing matrix
associated to the ball constraint @xmath reads

  -- -------- --
     @xmath
  -- -------- --

with trace equal to

  -- -------- --
     @xmath
  -- -------- --

From the structure of the localizing matrix, it holds @xmath hence
@xmath and

  -- -------- --
     @xmath
  -- -------- --

from which we derive

  -- -------- --
     @xmath
  -- -------- --

since @xmath . The operator norm @xmath , equal to the maximum
eigenvalue of @xmath , is upper bounded by @xmath , the sum of the
eigenvalues of @xmath , which are all nonnegative. Moreover the
Frobenius norm satisfies

  -- -------- --
     @xmath
  -- -------- --

where matrices @xmath can be written using column vectors @xmath ,
containing only zeros apart from the value 1 at index @xmath , via the
explicit formula

  -- -------- --
     @xmath
  -- -------- --

The proof follows then from

  -- -- --

  -- -- --

∎

###### Theorem 3.6.

Assumption 3.2 implies that @xmath for all @xmath .

###### Proof.

Let @xmath . Firstly, let us consider the case when @xmath is nonempty.
According to Lemma 3.5 , @xmath is bounded and closed, and the objective
function in @xmath is linear, so we conclude that @xmath is nonempty and
bounded. According to Lemma 3.4 , @xmath is nonempty, and from Lemma 3.3
, @xmath .
Secondly, let us consider the case when @xmath is empty. An infeasible
SDP problem can be either weakly infeasible or strongly infeasible, see
[ 40 , Section 5.2] for definitions. Let us prove by contradiction that
@xmath cannot be weakly infeasible. If @xmath is weakly infeasible,
there must exist a sequence @xmath such that

  -- -- --

  -- -- --

where @xmath denotes the minimum eigenvalue of a symmetric matrix.
According to the proof of Lemma 3.5 , for all @xmath and all real
numbers @xmath , one has

  -- -------- --
     @xmath
  -- -------- --

Clearly, @xmath where @xmath denotes the size of the moment matrix
@xmath . The following holds

  -- -------- --
     @xmath
  -- -------- --

from which we derive

  -- -------- --
     @xmath
  -- -------- --

Together with @xmath , this yields

  -- -------- --
     @xmath
  -- -------- --

where @xmath denotes the minimum eigenvalue of a symmetric matrix. Hence
for all @xmath , the spectrum of the moment matrix @xmath is lower
bounded by @xmath and upper bounded by @xmath . Therefore:

  -- -------- --
     @xmath
  -- -------- --

The sequence @xmath is hence included in a compact set. Thus there
exists a subsequence which converges towards @xmath such that @xmath and
@xmath , @xmath . The limit @xmath is thus included is @xmath , which is
a contradiction.
SDP problem @xmath is strongly infeasible which means that its dual
problem @xmath has an improving ray [ 40 , Definition 5.2.2] . To
conclude that @xmath , all that is left to prove is that @xmath .
Consider the primal problem @xmath discarding all constraints but @xmath
, @xmath , and @xmath . It is a feasible and bounded SDP problem owing
to Lemma 3.5 . According to Lemma 3.4 , its dual problem must contain a
feasible point @xmath and hence @xmath .

∎

### 3.3 Conclusion

We prove that there is no duality gap in Lasserre’s SDP hierarchy for
POPs whose description of the feasible set contains a ball constraint.
Prior results ensuring zero duality gap required the existence of a
strictly feasible point, which excludes POPs with equality constraints.
A zero duality gap is an important property for interior-point solvers
to successfully find solutions. A slight adaption of the proof we
propose shows that in the case of the optimal power flow problem, upper
bounds on voltage imply that there is no duality gap at each order of
the Lasserre hierarchy. The adaption consists of summing the traces of
each localizing matrix associated to an upper voltage constraint. The
sum is equal to the trace of the localizing matrix of a sphere
constraint that would be obtained by adding all upper voltage
constraints. This means that the computation in Lemma 3.5 is still valid
and that the overall proof still holds.

In Chapter 2 , we’ve proven the applicability of Lasserre’s hierarchy
from numerical perspective. In this chapter, its applicability was
enforced from a theoretical perspective. To prove its applicability to
large-scale networks, new test cases needed to be made publicly
available. Indeed, the only large-scale networks available so far were
Polish networks, each corresponding to a different period in the year,
and the Great Britain network. These networks contain roughly two to
three thousand buses each. In the next chapter, we present new data of
European networks from various countries and with up to nine thousand
buses. Figure 3.1 gives a brief history of the computations prior to the
introduction of these networks. Only computations leading to physically
meaningful results are presented, in other words those that lead to
feasible solutions. These are either global solutions or nearly global
solutions (in the case of penalization). Working in collaboration with
Daniel K. Molzahn and Ian Hiskens, we were to find global solutions in
the case of active power minimization for well-conditioned networks with
up to two thousand variables (Chapters 5 and 7 ).

## Chapter 4 Data of European transmission network

We contributed four new test cases [ 55 ] to M atpower [ 132 ] , a
package of MATLAB. They represent parts and all of the European high
voltage AC transmission network. The data stems from the Pan European
Grid Advanced Simulation and State Estimation (PEGASE) project, part of
the 7 ^(th) Framework Program of the European Union (
http://www.fp7-pegase.com/ ). Its goal was to develop new tools for the
real-time control and operational planning of the pan-Euporean
transmission network. Specifically, new approaches were implemented for
state estimation, dynamic security analysis, steady state optimization.
A dispatcher training simulator was also created. The associated public
data we provided is:
C. Josz, S. Fliscounakis, J. Maeght, and P. Panciatici, Power Flow Data
for European High-Voltage Transmission Network: 89, 1354, 2869, and
9241-bus PEGASE Systems , M atpower 5.1, March 2015. [link]
PEGASE data contains asymmetric shunt conductance and susceptance in the
PI transmission line model of branches. However, M atpower format do not
allow for asymmetry. As a result, we set the total line charging
susceptance of branches to 0 per unit in the M atpower files. We used
the nodal representation of shunt conductance and susceptance. This
procedure leaves the power flow equations unchanged compared with the
original PEGASE data. However, line flow constraints in the optimal
power flow problem are modified.
The data includes negative resistances and negative lower bounds on
active power generation. This is due to sections of the network that are
not represented. These sections may include generators, which accounts
for the negative resistances. Imports and exports with these sections
account for negative bounds on generation. These sections may be a
country connected to the European network that is represented by the
data. It may also be a section within a country for which data was not
provided. A big challenge when making realistic test cases is to account
for missing data in a sensible manner. See [ 86 , 6 ] for work on the
subject. Note that the non-represented sections also account for buses
where voltage magnitudes have very large lower and upper bounds. All
others buses have tight constraints, plus or minus @xmath of the nominal
value. This is visible is figure 4.2 . It represents the voltages at
each bus along with the lower and upper constraints resulting in an
annulus.

### 4.1 case89pegase

This case accurately represents the size and complexity of a small part
of the European high voltage transmission network. The network contains
89 buses, 12 generators, and 210 branches. It operates at 380, 220, and
150 kV.

### 4.2 case1354pegase

This case accurately represents the size and complexity of a medium part
of the European high voltage transmission network. The network contains
1,354 buses, 260 generators, and 1,991 branches. It operates at 380, and
220 kV.

### 4.3 case2869pegase

This case accurately represents the size and complexity of a large part
of the European high voltage transmission network. The network contains
2,869 buses, 510 generators, and 4,582 branches. It operates at 380,
220, 150, and 110 kV.

### 4.4 case9241pegase

This case accurately represents the size and complexity of the European
high voltage transmission network. The network contains 9,241 buses,
1,445 generators, and 16,049 branches. It operates at 750, 400, 380,
330, 220, 154, 150, 120 and 110 kV. It represents 23 countries as can be
seen in figure 4.1 . The numbers between the countries correspond the
sum of the active power flows traded at the interconnections for the
voltage profile of figure 4.2 . This voltage profile was found with the
nonlinear solver KNITRO. It is contained in the case9241 M atpower file.

The PEGASE data provides large-scale test cases on which to test new
methods and tools. After having shown the applicability of
moment/sum-of-squares approach to small-scale systems, the main
challenge was to make the approach tractable for large-scale systems. A
significant turn took place when Daniel K. Molzahn and Ian A. Hiskens
proposed a novel way to exploit sparsity when applying the moment-sos
hierarchy to the OPF problem [ 81 ] . The main idea is that a global
solution can be obtained by only applying high-order moments to some
constraints. These constraints are deduced by looking at the moment
matrix when the relaxation fails. The authors of [ 81 ] were thus able
to solve networks to global optimality with up to three hundred buses.
In the next chapter, their method is combined with a penalization
approach due to Madani et al [ 72 ] . Tests are made with the PEGASE
data in the next three chapters.

## Chapter 5 Penalized Lasserre hierarchy

Applications of convex relaxation techniques to the nonconvex OPF
problem have been of recent interest, including work using the Lasserre
hierarchy of “moment” relaxations to globally solve many OPF problems.
By preprocessing the network model to eliminate low-impedance lines,
this chapter demonstrates the capability of the moment relaxations to
globally solve large OPF problems that minimize active power losses for
portions of several European power systems. Large problems with more
general objective functions have thus far been computationally
intractable for current formulations of the moment relaxations. To
overcome this limitation, this chapter proposes the combination of an
objective function penalization with the moment relaxations. This
combination yields feasible points with objective function values that
are close to the global optimum of several large OPF problems. Compared
to an existing penalization method, the combination of penalization and
the moment relaxations eliminates the need to specify one of the penalty
parameters and solves a broader class of problems. The material
presented in this chapter is based on the publication:
D.K. Molzahn, C. Josz, I.A. Hiskens, and P. Panciatici , Solution of
Optimal Power Flow Problems using Moment Relaxations Augmented with
Objective Function Penalization , 54th Annual Conference on Decision and
Control, Osaka, December 2015. [preprint]

### 5.1 Introduction

The SDP relaxation of [ 66 ] has been generalized to a family of “moment
relaxations” using the Lasserre hierarchy [ 64 ] for polynomial
optimization [ 79 , 57 , 44 ] . The moment relaxations take the form of
SDPs, and the first-order relaxation in this hierarchy is equivalent to
the SDP relaxation of [ 66 ] . Increasing the relaxation order in this
hierarchy enables global solution of a broader class of OPF problems.

The ability to globally solve a broader class of OPF problems has a
computational cost; the moment relaxations quickly become intractable
with increasing order. Fortunately, second- and third-order moment
relaxations globally solve many small problems for which the first-order
relaxation fails to yield the globally optimal decision variables.

However, increasing system size results in computational challenges even
for low-order moment relaxations. The second-order relaxation is
computationally intractable for OPF problems with more than ten buses.
Exploiting network sparsity enables solution of the first-order
relaxation for systems with thousands of buses [ 52 , 82 ] and the
second-order relaxation for systems with about forty buses [ 81 , 44 ] .
Recent work [ 81 ] solves larger problems (up to 300 buses) by both
exploiting sparsity and only applying the computationally intensive
higher-order moment relaxations to specific buses in the network. Other
recent work improves tractability using a second-order cone programming
(SOCP) relaxation of the higher-order moment constraints [ 80 ] .

Solving larger problems using moment relaxations is often limited by
numerical convergence issues rather than computational performance. We
present a preprocessing method that improves numerical convergence by
removing low-impedance lines from the network model. Similar methods are
commonly employed (e.g., PSS/E [ 107 ] ), but more extensive
modifications are needed for adequate convergence due to the limited
numerical capabilities of current SDP solvers.

After this preprocessing, the moment relaxations globally solve several
large OPF problems which minimize active power losses for European power
systems. Directly using the moment relaxations to globally solve more
general large OPF problems with objective functions that minimize
generation cost has been computationally intractable thus far.

To solve these OPF problems, we form moment relaxations using a
penalized objective function. Previous literature [ 74 , 72 ] augments
the SDP relaxation [ 66 ] with penalization terms for the total reactive
power generation and the apparent power loss of certain lines. For many
problems, this penalization finds feasible points with objective
function values that are very close to the lower bounds obtained from
the SDP relaxation. Related work [ 83 ] uses a Laplacian-based objective
function with a constraint on generation cost to find feasible points
are very near the global optima. This section analyzes the physical and
convexity properties of the reactive power penalization.

There are several disadvantages of the penalization method of [ 72 ] .
This penalization often requires choosing multiple parameters. (See [ 83
] for a related approach that does not require choosing penalty
parameters.) Also, there are OPF problems that are globally solved by
the moment relaxations, but no known penalty parameters yield a feasible
solution.

We propose a “moment+penalization” approach that augments the moment
relaxations with a reactive power penalty. Typical penalized OPF
problems only require higher-order moment constraints at a few buses.
Thus, for a variety of large test cases, augmenting the moment
relaxation with the proposed single-parameter penalization achieves
feasible solutions that are at least very near the global optima (within
at least 1% for a variety of example problems). The moment+penalization
approach enables solution of a broader class of problems than either
method individually.

Below, Section 5.2 describes the low-impedance line preprocessing.
Section 5.3 discusses the existing penalization and the proposed
moment+penalization approaches. Section 5.6 demonstrates the
moment+penalization approach using several large test cases, and Section
5.7 concludes.

### 5.2 Preprocessing low-impedance lines

By exploiting sparsity and selectively applying the higher-order
constraints, the moment relaxations globally solve many OPF problems
with up to 300 buses. Solution of larger problems with higher-order
relaxations is typically limited by numerical convergence issues rather
than computational concerns. This section describes a preprocessing
method for improving numerical properties of the moment relaxations.

Low-impedance lines, which often represent “jumpers” between buses in
the same physical location, cause numerical problems for many
algorithms. Low line impedances result in a large range of values in the
bus admittance matrix @xmath , which causes numerical problems in the
constraint equations.

To address these numerical problems, many software packages remove lines
with impedances below a threshold. For instance, lines with impedance
below a parameter thrshz are removed prior to applying other algorithms
in PSS/E [ 107 ] .

We use a slightly modified version of the low-impedance line removal
procedure in PSS/E [ 107 ] . ¹ ¹ 1 Lines with non-zero resistances are
not considered to be “low impedance” by PSS/E. We consider both the
resistance and the reactance. Low-impedance lines are eliminated by
grouping buses that are connected by lines with impedances below a
specified threshold thrshz . Each group of buses is replaced by one bus
that is connected to all lines terminating outside the group.
Generators, loads, and shunts (including the shunt susceptanes of lines
connecting buses within a group) are aggregated. The series parameters
of lines connecting buses within a group are eliminated.

Removing low-impedance lines typically has a small impact on the
solution. To recover an approximate solution to the original power
system model, assign identical voltage phasors to all buses in each
group and distribute flows on lines connecting buses within a group
under the approximation that all power flows through the low-impedance
lines.

A typical low-impedance line threshold thrshz is @xmath per unit.
However, the numerical capabilities of SDP solvers are not as mature as
other optimization tools. Therefore, we require a larger @xmath per unit
to obtain adequate convergence of the moment relaxations. This larger
threshold typically introduces only small errors in the results,
although non-negligible errors are possible.

Matpower solutions obtained for the Polish [ 132 ] and most PEGASE
systems [ 42 , 55 ] were the the same before and after low-impedance
line preprocessing to within 0.0095 per unit voltage magnitude and
@xmath voltage angle difference across each line. Operating costs for
all test problems were the same to within 0.04%. The 2869-bus PEGASE
system had larger differences: 0.0287 per unit voltage magnitude and
@xmath angle difference. A power flow solution for the full network
using the solution to the OPF problem after low-impedance line
preprocessing yields smaller differences: 0.0059 per unit voltage
magnitude and @xmath angle difference. Thus, the differences from the
preprocessing for the 2869-bus PEGASE system can be largely attributed
to the sensitivity of the OPF problem itself to small changes in the
low-impedance line parameters. Preprocessing reduced the number of buses
by between 21% and 27% for the PEGASE and between 9% and 26% for the
Polish systems.

These results show the need for further study of the sensitivity of OPF
problems to low-impedance line parameters as well as additional
numerical improvements of the moment relaxations and SDP solvers to
reduce thrshz .

### 5.3 Moment relaxations and penalization

As will be shown in Section 6.4 , the moment relaxations globally solve
many large OPF problems with active power loss minimization objectives
after removing low-impedance lines as described in Section 5.2 .
Directly applying the moment relaxations to many large OPF problems with
more general cost functions has so far been computationally intractable.
This section describes the nonconvexity associated with more general
cost functions and proposes a method to obtain feasible solutions that
are at least near the global optimum, if not, in fact, globally optimal
for many problems.

Specifically, we propose augmenting the moment relaxations with a
penalization in the objective function. Previous literature [ 74 , 72 ]
adds terms to the first-order moment relaxation that penalize the total
reactive power injection and the apparent power line loss (i.e., @xmath
) for “problematic” lines identified by a heuristic. This penalization
often finds feasible points that are at least nearly globally optimal.

However, the penalization in [ 72 ] requires choosing two penalty
parameters and fails to yield a feasible solution to some problems. This
section describes progress in addressing these limitations by augmenting
the moment relaxations with a reactive power penalization. The proposed
“moment+penalization” approach only requires a single penalty parameter
and finds feasible points that are at least nearly globally optimal for
a broader class of OPF problems. This section also analyzes the
convexity properties and provides a physical intuition for reactive
power penalization.

### 5.4 Penalization of reactive power generation

The penalization method proposed in [ 72 ] perturbs the objective
function to include terms that minimize the total reactive power loss
and the apparent power loss on specific lines determined by a heuristic
method. These terms enter the objective function with two scalar
parameter coefficients. Obtaining a feasible point near the global
solution requires appropriate choice of these parameters.

For typical operating conditions, reactive power is strongly associated
with voltage magnitude. Penalizing reactive power injections tends to
reduce voltage magnitudes, which also tends to increase active power
losses since a larger current flow, with higher associated loss, is
required to deliver a given quantity of power at a lower voltage
magnitude.

For many problems for which the first-order moment relaxation fails to
yield the global optimum, the relaxation “artificially” increases the
voltage magnitudes to reduce active power losses. This results in
voltage magnitudes and power injections that are feasible for the SDP
relaxation but infeasible for the OPF problem.

By choosing a reactive power penalty parameter that balances these
competing tendencies (increasing voltage magnitudes to reduce active
power losses vs. decreasing voltage magnitudes to reduce the penalty),
the penalized relaxation finds a feasible solution to many OPF problems.
Since losses typically account for a small percentage of active power
generation and active and reactive power are typically loosely coupled,
the reactive power penalization often results in a feasible point that
is near the global optimum.

We next study the convexity properties of the cost function and the
reactive power penalization. The cost function is convex in terms of
active power generation but not necessarily in terms of the real and
imaginary voltage components. ² ² 2 The cost function of the moment
relaxation is always convex. This section studies the convexity of the
penalized objective function for the original nonconvex OPF problem.
Thus, the objective function is a potential source of nonconvexity which
may result in the relaxation’s failure to globally solve the OPF
problem.

Consider the eigenvalues of the symmetric matrices @xmath and @xmath ,
where, for the vector @xmath containing the voltage components, @xmath
is a linear cost of active power generation and @xmath calculates the
reactive power losses. For the 2383-bus Polish system [ 132 ] , which
has linear generation costs, the most negative eigenvalue of @xmath is
@xmath . Thus, the objective function of the original OPF problem is
nonconvex in terms of the voltage components, which can cause the SDP
relaxation to fail to yield the global optimum. Conversely, active power
loss minimization is convex in terms of the voltage components due to
the absence of negative resistances.

As indicated by the potential for negative eigenvalues of @xmath (e.g.,
the matrix @xmath for the 2383-bus Polish system has a pair of negative
eigenvalues at @xmath ), penalizing reactive power losses is generally
nonconvex due to capacitive network elements (i.e., increasing voltage
magnitudes may decrease the reactive power loss). See [ 83 ] for related
work that uses a convex objective based on a Laplacian matrix.

Further work is needed to investigate the effects of reactive power
penalization on OPF problems with more realistic generator models that
explicitly consider the trade-off between active and reactive power
outputs (i.e., generator “D-curves”). A tighter coupling between active
and reactive power generation may cause the reactive power penalization
to yield solutions that are far from the global optimum.

The apparent power line loss penalty’s effects are not as easy to
interpret as the reactive power penalty. Ongoing work includes
understanding the effects of the line loss penalty.

### 5.5 Moment+penalization approach

Although the reactive power penalization often yields a near rank-one
solution, this penalization alone is not sufficient to obtain a feasible
point for many problems. Reference [ 72 ] penalizes the apparent power
line loss associated with certain lines to address the few remaining
non-rank-one “problematic” submatrices. However, this approach has
several disadvantages.

First, penalizing apparent power line losses introduces another
parameter. ³ ³ 3 Reference [ 72 ] uses the same penalization parameter
for each “problematic” line. Generally, each line could have a different
penalty parameter. Introducing parameters is problematic, especially
when lacking an intuition for appropriate values.

Second, the combination of reactive power and line loss penalization may
not yield a feasible solution to some problems. For instance, the OPF
problems case9mod and case39mod1 from [ 22 ] are globally solved with
low-order moment relaxations, but there is no known penalization of
reactive power and/or apparent power line loss that yields a feasible
solution for these problems. Also, the penalization approach is not
guaranteed to yield a feasible solution that is close to the global
optimum.

Unlike the penalization approach, the moment relaxation approach does
not require the choice of penalty parameters, globally solves a broader
class of OPF problems, and is guaranteed to yield the global optimum
when the rank-one condition is satisfied. However, direct application of
the moment relaxations to large problems has so far been limited to
active power loss minimization objective functions. We conjecture that
the nonconvexity associated with more general cost functions requires
higher-order moment constraints at too many buses for computational
tractability.

To apply the moment relaxations to large OPF problems with active power
generation cost objective functions, we augment the moment relaxations
with a reactive power penalty. Specifically, we add to the objective the
total reactive power produced by all generators multiplied by a
penalization parameter @xmath (which is a positive scalar). That is,
rather than apply an apparent power loss penalization to the objective
function, we apply higher-order moment constraints to specific buses [
81 ] . As will be demonstrated in Section 6.4 , higher-order moment
constraints are only needed at a few buses in typical OPF problems after
augmenting the objective function with a reactive power penalization
term.

Similar to the existing penalization, when the rank condition is
satisfied, the proposed “moment+penalization” approach yields the global
solution to the modified OPF problem, but not necessarily to the
original OPF problem. However, since the penalization does not change
the constraint equations, the solution to the moment+penalization
approach is feasible for the original OPF problem. The first-order
moment relaxation without penalization (i.e., @xmath ) gives a lower
bound on the globally optimal objective value for the original OPF
problem. This lower bound provides an optimality metric for the feasible
solution obtained from the moment+penalization approach. As will be
shown in Section 6.4 , the feasible solutions for a variety of problems
are within at least 1% of the global optimum.

The moment+penalization approach inherits a mix of the advantages and
disadvantages of the moment relaxation and penalization methods. First,
the moment+penalization approach requires selection of a single scalar
parameter (one more than needed for the moment relaxations, but one less
than generally needed for the penalization in [ 72 ] ). This parameter
must be large enough to result in a near rank-one solution, but small
enough to avoid large changes to the OPF problem.

Second, the penalization eliminates the moment relaxations’ guarantees:
the
moment+penalization approach may yield a feasible solution that is far
from the global optimum or not give any solution. However, the
moment+penalization approach finds global or near-global solutions to a
broader class of small OPF problems than penalization approach of [ 72 ]
(e.g., case9mod and case39mod1 with @xmath , and case39mod3 with @xmath
[ 22 ] ). This suggests that the moment+penalization approach inherits
the ability of the moment relaxations to solve a broad class of OPF
problems.

Finally, the penalization in the moment+penalization approach enables
calculation of feasible solutions that are at least nearly globally
optimal for a variety of large OPF problems with objective functions
that minimize active power generation cost rather than just active power
losses.

Note that it is not straightforward to compare the computational costs
of the
moment+penalization approach and the penalization approach in [ 72 ] . A
single solution of a penalized first-order moment relaxation, as in [ 72
] , is faster than a relaxation with higher-order moment constraints.
Thus, if one knows appropriate penalty parameters, the method in [ 72 ]
is faster. Although a relatively wide range of penalty parameters tends
to work well for typical OPF problems, there are problems for which no
known penalty parameters yield feasible solutions. For these problems,
the moment+penalization approach has a clear advantage.

The moment+penalization approach has the advantage of systematically
tightening the relaxation rather than requiring the choice of penalty
parameters. However, the higher-order constraints can significantly
increase solver times. Thus, there is a potential trade-off between
finding appropriate penalization parameters for the approach in [ 72 ]
and increased solver time from the moment+penalization approach. The
speed of the moment+penalization approach may be improved using the
mixed SDP/SOCP relaxation from [ 80 ] .

### 5.6 Numerical results

This section first globally solves several large, active-power-loss
minimizing OPF problems using moment relaxations without penalization (
@xmath ). Next, this section applies the moment+penalization approach to
find feasible points that are at least nearly globally optimal for
several test cases which minimize active power generation cost. Unless
otherwise stated, the preprocessing method from Section 5.2 with thrshz
set to @xmath per unit is applied to all examples. No example enforces a
minimum line resistance.

The results are generated using the iterative algorithm from [ 81 ]
which selectively applies the higher-order moment relaxation
constraints. The algorithm terminates when all power injection
mismatches are less than 1 MVA.

The implementation uses MATLAB 2013a, YALMIP 2015.06.26 [ 69 ] , and
Mosek 7.1.0.28, and was solved using a computer with a quad-core
2.70 GHz processor and 16 GB of RAM. The test cases are the Polish
system models in Matpower [ 132 ] and several PEGASE systems [ 42 , 55 ]
representing portions of the European power system.

##### Active Power Loss Minimization Results

Table 5.1 shows the results of applying the moment relaxations to
several large OPF problems that minimize active power losses. The
solutions to the preprocessed problems are guaranteed to be globally
optimal since there is no penalization. The columns in Table 5.1 list
the case name, the number of iterations of the algorithm from [ 81 ] ,
the maximum power injection mismatch, the globally optimal objective
value, and the solver time summed over all iterations. The abbreviation
“PL” stands for “Poland”. Table 5.1 excludes several cases (the 89-bus
PEGASE system and the Polish 2736sp, 2737sop, and 2746wp systems) which
only require the first-order relaxation and thus do not illustrate the
capabilities of the higher-order relaxations. PEGASE-1354 and
PEGASE-2869 use a thrshz of @xmath per unit. All other systems use
@xmath per unit.

Each iteration of the algorithm in [ 81 ] after the first adds
second-order constraints at two buses. Thus, a small number of
second-order buses (between 0.1% and 0.7% of the number of buses in the
systems in Table 5.1 after the low-impedance line preprocessing) are
applied to all examples in Table 5.1 . This results in computational
tractability for the moment relaxations.

Note that PL-2746wop has a much greater solver time than the other
systems even though it only has second-order constraints at two buses.
This slow solution time is due to the fact that the two second-order
buses are contained in submatrices corresponding to cliques with 10 and
11 buses. The second-order constraints for these large submatrices
dominate the solver time. The mixed SDP/SOCP relaxation in [ 80 ] may be
particularly useful beneficial for such cases.

Since the low-impedance line preprocessing has been applied to these
systems, the solutions do not exactly match the original OPF problems.
Matpower [ 132 ] solutions of the original problems have objective
values that are slightly larger than the values in Table 5.1 due to
losses associated with the line resistances removed by the
preprocessing.

After the low-impedance line preprocessing, local solutions from
Matpower match the solutions from the moment relaxations and are
therefore, in fact, globally optimal. This is not the case for all OPF
problems [ 22 , 81 ] .

##### Moment+Penalization for More General Cost Functions

As discussed in Section 5.4 , minimization of active power generation
cost often yields a nonconvex objective function in terms of the voltage
components. Despite this nonconvexity, low-order moment relaxations
typically yield global solutions to small problems, including problems
without known penalty parameters for obtaining a feasible points (e.g.,
case9mod and case39mod1 from [ 22 ] ).

However, the moment relaxations are thus far intractable for some large
OPF problems with nonconvex objective functions. A reactive power
penalty often results in the first-order moment relaxation yielding a
solution that is nearly globally optimal (i.e., most of the submatrices
in the clique decomposition satisfy the rank-one condition). Enforcing
higher-order constraints at buses in the remaining submatrices yields a
feasible solution to the OPF problem. This is illustrated in Fig. 5.1 ,
which shows the ratio between the largest and second-largest eigenvalues
of the submatrices of the moment matrix, arranged in increasing order,
for the 2383-bus Polish system. If the submatrices were all rank one,
then this eigenvalue ratio would be infinite. Thus, large numeric values
(i.e., greater than @xmath ) indicate satisfaction of the rank condition
within numerical precision. Without the reactive power penalty, the rank
condition is not satisfied for most submatrices. With the reactive power
penalty, the rank condition is satisfied for many but not all
submatrices. Enforcing higher-order moment constraints at two buses
which are in the high-rank submatrices results in a feasible (rank-one)
operating point for the OPF problem which is within at least 0.74% of
the global optimum.

To further illustrate the effectiveness of the moment+penalization
approach, Table 5.2 shows the results of applying the
moment+penalization approach to several large OPF problems with active
power generation cost functions. The optimality gap column gives the
percent difference between a lower bound on the optimal objective value
from the first-order moment relaxation and the feasible solution
obtained from the moment+penalization approach for the system after
low-impedance line preprocessing.

The penalized first-order relaxation requires 74.6, 88.9, and 97.0
seconds for PL-2383wp, PL-3012wp, and PL-3120sp, respectively.
Attributing the rest of the solver time to the higher-order constraints
implies that these constraints accounted for 3.1, 433.7, and 582.4
seconds beyond the time required to repeatedly solve the first-order
relaxations.

The moment+penalization approach can yield feasible points that are at
least nearly globally optimal for cases where both the penalization
method of [ 72 ] and low-order moment relaxations fail individually. For
instance, the moment+penalization approach with a reactive power penalty
of @xmath gives a feasible point within 0.28% of the global optimum for
case39mod3 from [ 22 ] , but both second- and third-order moment
relaxations and the penalization method in [ 72 ] fail to yield global
solutions.

### 5.7 Conclusion

“Moment” relaxations from the Lasserre hierarchy for polynomial
optimization globally solve a broad class of OPF problems. By exploiting
sparsity and selectively applying the computationally intensive
higher-order moment relaxations, previous literature demonstrated the
moment relaxations’ capability to globally solve moderate-size OPF
problems. This chapter presented a preprocessing method that removes
low-impedance lines to improve the numerical conditioning of the moment
relaxations. After applying the preprocessing method, the moment
relaxations globally solve a variety of OPF problems that minimize
active power losses for systems with thousands of buses. A proposed
“moment+penalization” method is capable of finding feasible points that
are at least nearly globally optimal for large OPF problems with more
general cost functions. This method has several advantages over previous
penalization approaches, including requiring fewer parameter choices and
solving a broader class of OPF problems. In the next chapter, we devise
a method that provides nearly global solutions to large-scale OPF
problems without the need to specify any parameter.

## Chapter 6 Laplacian matrix approach

A semidefinite optimization (SDP) relaxation globally solves many
optimal power flow (OPF) problems. For other OPF problems where the SDP
relaxation only provides a lower bound on the objective value rather
than the globally optimal decision variables, recent literature has
proposed a penalization approach to find feasible points that are often
nearly globally optimal. A disadvantage of this penalization approach is
the need to specify penalty parameters. This paper presents an
alternative approach that algorithmically determines a penalization
appropriate for many OPF problems. The proposed approach constrains the
generation cost to be close to the lower bound from the SDP relaxation.
The objective function is specified using iteratively determined weights
for a Laplacian matrix. This approach yields feasible points to the OPF
problem that are guaranteed to be near the global optimum due to the
constraint on generation cost. The proposed approach is demonstrated on
both small OPF problems and a variety of large test cases representing
portions of European power systems. The material presented in this
chapter is based on the submitted manuscript:
D.K. Molzahn, C. Josz, I.A. Hiskens, and P. Panciatici , A
Laplacian-Based Approach for Finding Near Globally Optimal Solutions to
OPF Problems , submitted to Institute of Electrical and Electronics
Engineers, Transactions on Power Systems. [preprint]

### 6.1 Introduction

Literature has proposed an objective function penalization approach for
finding feasible points that are near the global optimum for the OPF
problem [ 74 , 72 ] . The penalization approach has the advantage of not
using potentially computationally expensive higher-order moment
constraints, but has the disadvantage of requiring the choice of
appropriate penalization parameters. This choice involves a compromise,
as the parameters must induce a feasible solution to the original
problem while avoiding large modifications to the problem that would
cause unacceptable deviation from the global optimum.

The penalization formulation in the existing literature [ 72 ] generally
requires specifying penalty parameters for both the total reactive power
injection and apparent power flows on certain lines. Penalty parameters
in the literature range over several orders of magnitude for various
test cases, and existing literature largely lacks systematic algorithms
for determining appropriate parameter values. Recent work [ 84 ]
proposes a “moment+penalization” approach that eliminates the need to
choose apparent power flow penalization parameters, but still requires
selection of a penalty parameter associated with the total reactive
power injection.

This chapter presents an iterative algorithm that builds an objective
function intended to yield near-globally-optimal solutions to OPF
problems for which the SDP relaxation is not exact. The proposed
algorithm first solves the SDP relaxation to obtain a lower bound on the
optimal objective value. This lower bound is often very close to the
global optimum of many practical OPF problems. The proposed approach
modifies the SDP relaxation by adding a constraint that the generation
cost must be within a small percentage (e.g., 0.5%) of this lower bound.
This percentage is the single externally specified parameter in the
proposed approach.

This constraint on the generation cost provides freedom to specify an
objective function that aims to obtain a feasible rather than
minimum-cost solution for the OPF problem. In other words, we desire an
objective function such that the SDP relaxation yields a feasible
solution to the original nonconvex OPF problem, with near-global
optimality ensured by the constraint on generation cost.

This chapter proposes an algorithm for calculating an appropriate
objective function defined using a weighted Laplacian matrix. The
weights are determined iteratively based on the mismatch between the
solution to the relaxation and the power flows resulting from a related
set of voltages. The paper will formalize these concepts and demonstrate
that this approach results in near global solutions to many OPF
problems, including large test cases. Like many
penalization/regularization techniques, the proposed approach is not
guaranteed to yield a feasible solution. As supported by the results for
several large-scale, realistic test cases, the proposed algorithm
broadens the applicability of the SDP relaxation to achieve operating
points for many OPF problems that are within specified tolerances for
both constraint feasibility and global optimality.

There is related work that chooses the objective function of a
relaxation for the purpose of obtaining a feasible solution for the
original nonconvex problem. For instance, [ 67 ] specifies objective
functions that are linear combinations of squared voltage magnitudes in
order to find multiple solutions to the power flow equations.
Additionally, [ 73 ] proposes a method for determining an objective
function that yields solutions to the power flow equations for a variety
of parameter choices. The objective function in [ 73 ] is defined by a
matrix with three properties: positive semidefiniteness, a simple
eigenvalue of 0, and null space containing the all-ones vector. We note
that the weighted Laplacian objective function developed in this paper
is a special case of an objective function that also has these three
properties.

This chapter is organized as follows. Section 6.2 describes the
Laplacian objective function approach that is the main contribution of
this chapter. Section 6.3 describes an algorithm for determining the
Laplacian weights. Section 6.4 demonstrates the effectiveness of the
proposed approach through application to a variety of small OPF problems
as well as several large test cases representing portions of European
power systems. Section 6.5 concludes the chapter.

### 6.2 Laplacian objective function

The proposed approach exploits the empirical observation that the SDP
relaxation provides a very close lower bound on the optimal objective
value of many typical OPF problems (i.e., there is a very small
relaxation gap ). For instance, the SDP relaxation gaps for the
large-scale Polish [ 132 ] and PEGASE [ 42 , 55 ] systems, which
represent portions of European power systems, are all less than 0.3%. ¹
¹ 1 To obtain satisfactory convergence of the SDP solver, these systems
are pre-processed to remove low-impedance lines (i.e., lines whose
impedance values have magnitudes less than @xmath per unit) as in [ 84 ]
. ² ² 2 These relaxation gaps are calculated using the objective values
from the Shor SDP relaxation and solutions obtained either from the
second-order moment relaxation [ 81 ] (where possible) or from M atpower
[ 132 ] . Further, the SDP relaxation is exact (i.e., zero relaxation
gap) for the IEEE 14-, 30-, 39-, 57-bus systems, the 118-bus system
modified to enforce a small minimum line resistance, and several of the
large-scale Polish test cases.

We assume that the lower bound @xmath provided by the SDP relaxation is
within a given percentage @xmath of the global optimum to the OPF
problem. (Most of the examples in Section 6.4 specify @xmath .) We
constrain the generation cost using this assumption by requiring it to
be less than or equal to @xmath . Note that the feasible set thus
defined is non-empty (i.e., the corresponding SDP problem is feasible)
for any choice of @xmath . However, if @xmath is too small, there may
not exist a rank-one matrix @xmath (i.e., a feasible point for the
original OPF problem) in the feasible space.

The lack of a priori guarantees on the size of the relaxation gap is a
challenge that the proposed approach shares with many related approaches
for convex relaxations of the optimal power flow problem. Existing
sufficient conditions that guarantee zero relaxation gap generally
require satisfaction of non-trivial technical conditions and a limited
set of network topologies [ 70 , 74 ] . The SDP relaxation is exact for
a significantly broader class of OPF problems than those that have a
priori exactness guarantees, and has a small relaxation gap for an even
broader class of OPF problems.

There are test cases that are specifically constructed to exhibit
somewhat anomalous behavior in order to test the limits of the convex
relaxations. The SDP relaxation gap is not small for some of these test
cases. For instance, the 3-bus system in [ 78 ] , the 5-bus system in [
85 ] , and the 9-bus system in [ 22 ] have relaxation gaps of 20.6%,
8.9%, and 10.8%, respectively, and the test cases in [ 58 ] have
relaxation gaps as large as 52.7%. The approach proposed in this paper
is not appropriate for such problems. Future progress in convex
relaxation theory is required to develop broader conditions that provide
a priori certification that the SDP relaxation is exact or has a small
relaxation gap. We also await the development of more extensive sets of
OPF test cases to further explore the observation that many typical
existing practical test cases have small SDP relaxation gaps.

By inserting the original cost function as a constraint, this
effectively frees the choice of the objection function (which we will
denote @xmath ) to obtain a feasible rather than minimum-cost solution
to the OPF. Here, @xmath denotes the real SDP matrix variable of @xmath
where @xmath is the number of buses. Any solution with @xmath yields a
feasible solution to the OPF problem within @xmath of the globally
optimal objective value. We therefore seek an objective function @xmath
which maximizes the likelihood of obtaining @xmath . This section
describes a Laplacian form for the function @xmath . Specifically, we
consider a @xmath diagonal matrix @xmath containing weights for the
network Laplacian matrix @xmath , where @xmath is the @xmath incidence
matrix for the network. The off-diagonal term @xmath is equal to the
negative of the sum of the weights for the lines connecting buses @xmath
and @xmath , and the diagonal term @xmath is equal to the sum of the
weights of the lines connected to bus @xmath . The objective function is

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

The choice of an objective function based on a Laplacian matrix is
motivated by previous literature. An existing penalization approach [ 74
] augments the objective function by adding a term that minimizes the
total reactive power injection. This reactive power penalty can be
implemented by adding the term

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

to the objective function of the Shor relaxation of the OPF, where
@xmath is a specified penalty parameter, @xmath indicates conjugate
transpose, and @xmath is the admittance matrix. In the absence of
phase-shifting transformers (i.e., @xmath ), the matrix @xmath is
equivalent to @xmath , which is a weighted Laplacian matrix (with
weights determined by the branch susceptance parameters @xmath ) plus a
diagonal matrix composed of shunt susceptances.

Early work on SDP relaxations of OPF problems [ 66 ] advocates enforcing
a minimum resistance of @xmath for all lines in the network. For
instance, the SDP relaxation fails to be exact for the IEEE 118-bus
system [ 1 ] , but the relaxation is exact after enforcing a minimum
line resistance of @xmath per unit. After enforcing a minimum line
resistance, the active power losses are given by

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

where @xmath is the network admittance matrix after enforcing a minimum
branch resistance of @xmath . In the absence of phase-shifting
transformers, @xmath is equivalent to @xmath , which is a weighted
Laplacian matrix (with weights determined by the branch conductance
parameters @xmath ) plus a diagonal matrix composed of shunt
conductances. Since typical OPF problems have objective functions that
increase with active power losses, enforcing minimum line resistances is
similar to a weighted Laplacian penalization. ³ ³ 3 Note that since
enforcing minimum line resistances also affects the power injections and
the line flows, the minimum line resistance cannot be solely represented
as a Laplacian penalization of the objective function.

The proposed objective function ( 6.1 ) is equivalent to a linear
combination of certain components of @xmath :

  -- -------- -------- -- -------
     @xmath   @xmath
              @xmath      (6.4)
  -- -------- -------- -- -------

where @xmath is the diagonal element of @xmath corresponding to the line
from bus @xmath to bus @xmath .

From a physical perspective, the Laplacian objective’s tendency to
reduce voltage differences is similar to both the reactive power
penalization proposed in [ 74 ] and the minimum branch resistance
advocated in [ 66 ] . For typical operating conditions, reactive power
injections are closely related to voltage magnitude differences, so
penalizing reactive power injections tends to result in solutions with
similar voltages. Likewise, the active power losses associated with line
resistances increase with the square of the current flow through the
line, which is determined by the voltage difference across the line.
Thus, enforcing a minimum line resistance tends to result in solutions
with smaller voltage differences in order to reduce losses.

In addition, a Laplacian regularizing term has been used to obtain
desirable solution characteristics for a variety of other optimization
problems (e.g., machine learning problems [ 109 , 77 ] , sensor network
localization problems [ 128 ] , and analysis of flow networks [ 120 ] ).
The Laplacian matrix is also used for image reconstruction problems [ 31
] .

### 6.3 Determining Laplacian weights

Having established a weighted Laplacian form for the objective function,
we introduce an iterative algorithm for determining appropriate weights
@xmath for obtaining a solution with @xmath . We note that the proposed
algorithm is similar in spirit to the method in [ 24 , Section 2.4] ,
which iteratively updates weighting parameters to promote low-rank
solutions of SDPs related to image reconstruction problems.

The proposed algorithm is inspired by the apparent power line flow
penalty used in [ 72 ] and the iterative approach to determining
appropriate buses for enforcing higher-order moment constraints in [ 81
] . The approach in [ 72 ] penalizes the apparent power flows on lines
associated with certain submatrices of @xmath that are not rank one. ⁴ ⁴
4 The submatrices are determined by the maximal cliques of a chordal
supergraph of the network; see [ 52 , 82 , 72 ] for further details.
Similar to the approach in [ 72 ] , the proposed algorithm adds terms to
the objective function that are associated with certain “problematic
lines.”

The heuristic for identifying problematic lines is inspired by the
approach used in [ 81 ] to detect “problematic buses” for application of
higher-order moment constraints. Denote the SDP solution as @xmath and
the closest rank-one matrix to @xmath as @xmath . Previous work [ 81 ]
compares the power injections associated with @xmath and @xmath to
calculate power injection mismatches @xmath for each bus @xmath :

  -- -- -------- -- -------
        @xmath
                    (6.5)
  -- -- -------- -- -------

where @xmath denotes the magnitude of the complex argument. In the
parlance of [ 81 ] , problematic buses are those with large power
injection mismatches @xmath .

To identify problematic lines rather than buses, we modify ( 6.5 ) to
calculate apparent power flow mismatches @xmath for each line @xmath :

  -- -- -------- -- -------
        @xmath
        @xmath
        @xmath      (6.6)
  -- -- -------- -- -------

Observe that @xmath sums the magnitude of the apparent power flow
mismatches at both ends of each line.

The condition @xmath (i.e., “feasibility” in this context) is considered
satisfied for practical purposes using the criterion that the maximum
line flow and power injection mismatches (i.e., @xmath and @xmath ) are
less than specified tolerances @xmath and @xmath , respectively, and the
voltage magnitude limits are satisfied to within a specified tolerance
@xmath . ⁵ ⁵ 5 For all test cases, the voltage magnitude limits were
satisfied whenever the power injection and line flow mismatch tolerances
were achieved.

1: Input : tolerances @xmath and @xmath , max relaxation gap @xmath

2: Set @xmath

3: Solve the Shor SDP relaxation to obtain @xmath

4: Calculate @xmath and @xmath using ( 6.6 ) and ( 6.5 )

5: while termination criteria not satisfied

6: Update weights: @xmath

7: Solve the generation-cost-constrained relaxation

8: Calculate @xmath and @xmath using ( 6.6 ) and ( 6.5 )

9: Calculate the voltage phasors and terminate

Algorithm 1 Iterative Algorithm for Determining Weights

As described in Algorithm 1 , the weights on the diagonal of @xmath are
determined from the line flow mismatches @xmath . Specifically, the
proposed algorithm first solves the Shor relaxation to obtain both the
lower bound @xmath on the optimal objective value and the initial line
flow and power injection mismatches @xmath and @xmath .

While the termination criteria ( @xmath , @xmath , and no voltage limits
violated by more than @xmath ) are not satisfied, the algorithm solves
the SDP relaxation with the constraint ensuring that the generation cost
is within @xmath of the lower bound. The objective function is defined
using the weighting matrix @xmath , where @xmath denotes the matrix with
the vector argument on the diagonal and other entries equal to zero.
Each iteration adds the line flow mismatch vector @xmath to the previous
weights (i.e., @xmath ).

Note that Algorithm 1 is not guaranteed to converge. Non-convergence may
be due to the value of @xmath being too small (i.e., there does not
exist a rank-one solution) or failure to find a rank-one solution that
does exist. To address the former case, Algorithm 1 could be modified to
include an “outer loop” that increments @xmath by a specified amount
(e.g., @xmath %) if convergence is not achieved in a certain number of
iterations. We note that, like other convex relaxation methods, the
proposed approach would benefit from further theoretical work regarding
the development of a priori guarantees on the size of the relaxation gap
for various classes of OPF problems.

For some problems with large relaxation gaps (e.g., the 3-bus system in
[ 78 ] , the 5-bus system in [ 85 ] , and the 9-bus system in [ 22 ] ),
no purely penalization-based methods have so far successfully addressed
the latter case where the proposed algorithm fails to find a rank-one
solution that satisfies the generation cost constraint with sufficiently
large @xmath (i.e., no known penalty parameters yield feasible solutions
using the methods in [ 74 , 72 ] for these test cases). One possible
approach for addressing this latter case is the combination of
penalization techniques with Lasserre’s moment relaxation hierarchy [ 79
, 57 , 44 , 81 ] . The combination of the moment relaxations with the
penalization methods enables the computation of near-globally-optimal
solutions for a broader class of OPF problems than either method
achieves individually. See [ 84 ] for further details on this approach.

We note that despite the lack of a convergence guarantee, the examples
in Section 6.4 demonstrate that Algorithm 1 is capable of finding
feasible points that are near the global optimum for many OPF problems,
including large test cases.

### 6.4 Numerical results

This section demonstrates the effectiveness of the proposed approach
using several small example problems as well as large test cases
representing portions of European power systems. The SDP relaxation
yields a small but non-zero relaxation gap for the test cases selected
in this section, and Algorithm 1 yields points that are feasible for the
OPF (to within the specified termination criteria) and that are near the
global optimum for these test cases. For other test cases with a large
SDP relaxation gap, such as those mentioned earlier in [ 22 , 85 , 78 ,
58 ] , the proposed algorithm does not converge when tested with a
variety of values for @xmath .

The results in this section use line flow and power injection mismatch
tolerances @xmath and @xmath that are both equal to @xmath MVA and
@xmath per unit. The implementation of Algorithm 1 uses MATLAB 2013a,
YALMIP 2015.02.04 [ 69 ] , and Mosek 7.1.0.28 [ 2 ] , and was solved
using a computer with a quad-core 2.70 GHz processor and 16 GB of RAM.

Applying Algorithm 1 to several small- to medium-size test cases from [
67 , 85 , 81 , 1 , 58 ] yields the results shown in Table 6.1 . Tables
6.2 and 6.3 show the results from applying Algorithm 1 to large test
cases which minimize generation cost and active power losses,
respectively. These test cases, which are from [ 132 ] and [ 42 , 55 ] ,
represent portions of European power systems. The Shor relaxation has a
small but non-zero relaxation gap for all test cases considered in this
section. The columns of Tables 6.1 – 6.3 show the case name and
reference, the number of iterations of Algorithm 1 , the final maximum
apparent power flow mismatch @xmath in MVA, the final maximum power
injection mismatch @xmath in MVA, the specified value of @xmath , an
upper bound on the relaxation gap from the solution to the Shor
relaxation, and the total solver time in seconds.

Note that the large test cases in Tables 6.2 and 6.3 were preprocessed
to remove low-impedance lines as described in [ 84 ] in order to improve
the numerical convergence of the SDP relaxation. Lines which have
impedance magnitudes less than a threshold ( thrshz in [ 84 ] ) of
@xmath per unit are eliminated by merging the terminal buses. Table 6.4
describes the number of buses and lines before and after this
preprocessing. Low-impedance line preprocessing was not needed for the
test cases in Table 6.1 . After preprocessing, MOSEK’s SDP solver
converged with sufficient accuracy to yield solutions that satisfied the
voltage magnitude limits to within @xmath per unit and the power
injection and line flow constraints to within the corresponding
mismatches shown in Tables 6.1 – 6.3 .

These results show that Algorithm 1 finds feasible points (within the
specified tolerances) that have objective values near the global optimum
for a variety of test cases. Further, Algorithm 1 globally solves all
OPF problems for which the Shor relaxation is exact (e.g., many of the
IEEE test cases [ 66 ] , several of the Polish test systems [ 82 ] , and
the 89-bus PEGASE system [ 42 , 55 ] ). Thus, the algorithm is a
practical approach for addressing a broad class of OPF problems.

We note, however, that Algorithm 1 does not yield a feasible point for
all OPF problems. For instance, the test case WB39mod from [ 22 ] has
line flow and power injection mismatches of 18.22 MVA and 12.99 MVA,
respectively, after 1000 iterations of Algorithm 1 . The challenge
associated with this case seems to result from light loading with
limited ability to absorb a surplus of reactive power injections,
yielding at least two local solutions. In addition to challenging the
method proposed in this paper, no known penalty parameters yield
feasible solutions to this problem. Generalizations of the SDP
relaxation using the Lasserre hierarchy have successfully calculated the
global solution to this case [ 81 , 84 ] . Further, while Algorithm 1
converges for five of the seven test cases in [ 58 ] which have small
relaxation gaps (less than 2.5%), the algorithm fails for two other such
test cases as well as several other test cases in [ 58 ] which have
large relaxation gaps. We note that the tree topologies used in the test
cases in [ 58 ] are a significant departure from the mesh networks used
in the standard test cases from which they were derived; the proposed
algorithm succeeds for several test cases that share the original
network topologies.

We note that the interior point solver in M atpower obtained superior
relaxation gaps for the test cases considered in this paper. Within
approximately five seconds for the large test cases in Tables 6.2 and
6.3 , M atpower obtained relaxation gaps that ranged from @xmath to
@xmath smaller than those obtained with Algorithm 1 . ⁶ ⁶ 6 Of course, M
atpower cannot provide any measure of the quality of its solution in
terms of a lower bound on the globally optimal objective value whereas
Algorithm 1 provides such guarantees. This suggests that smaller values
of @xmath could be used in Algorithm 1 . Indeed, additional numerical
experiments demonstrated that Algorithm 1 converged with @xmath (half
the value used in previous numerical experiments) for all test cases for
which the M atpower solution indicated that a value of @xmath was
achievable.

We select termination parameter values of @xmath and @xmath of 1 MVA.
This tolerance is typically numerically achievable with MOSEK’s SDP
solver, which experience suggests is often a limiting factor to
obtaining smaller mismatches.

Note that the maximum mismatches do not necessarily decrease
monotonically with each iteration of Algorithm 1 . Figs. 6.1 and 6.2
show the maximum flow mismatches (on a logarithmic scale) for the test
cases that minimize active power losses (cf. Table 6.3 ). Likewise,
Figs. 6.3 and 6.4 show the maximum power injection mismatches for the
same test cases. Although the mismatches do not always decrease
monotonically, there is a generally decreasing trend which results in
satisfaction of the termination criteria for each test case. At each
iteration, Algorithm 1 yields larger reactive power mismatches than
active power mismatches for these test cases.

Note that it is not straightforward to compare the computational costs
of the Laplacian objective approach and other penalization approaches in
the literature [ 74 , 72 ] . A single solution of the penalized SDP
relaxations in [ 72 ] requires approximately the same computational
effort as one iteration of Algorithm 1 . Thus, if one knows appropriate
penalty parameters, the method in [ 72 ] is faster for problems where
the SDP relaxation is not exact. However, the key advantage of the
proposed approach is that there is no need to specify any parameters
other than the value of @xmath used in the generation cost constraint.
In contrast, the literature largely lacks systematic approaches for
identifying appropriate parameter values for the penalization methods in
[ 74 , 72 ] .

### 6.5 Conclusion

The SDP relaxation of [ 66 ] is capable of globally solving a variety of
OPF problems. To address a broader class of OPF problems, this paper has
described an approach that finds feasible points with objective values
that are within a specified percentage of the global optimum.
Specifically, the approach in this paper adds a constraint to ensure
that the generation cost is within a small specified percentage of the
lower bound obtained from the SDP relaxation. This constraint frees the
objective function to be chosen to yield a feasible (i.e., rank-one)
solution rather than a minimum-cost solution. Inspired by previous
penalization approaches and results in the optimization literature, an
objective function based on a weighted Laplacian matrix is selected. The
weights for this matrix are iteratively determined using “line flow
mismatches.” The proposed approach is validated through successful
application to a variety of both small and large test cases, including
several OPF problems representing large portions of European power
systems. There are, however, test cases for which the approach takes
many iterations to converge or does not converge at all.

Future work includes modifying the algorithm for choosing the weights in
order to more consistently require fewer iterations. Also, future work
includes testing alternative SDP solution approaches with “hot start”
capabilities to improve computational efficiency by leveraging knowledge
of the solution to a “nearby” problem from the previous iteration of the
algorithm. Future work also includes extension of the algorithm to a
broader class of OPF problems, such as the test case WB39mod from [ 22 ]
and several examples in [ 58 ] .

In this chapter and the one before that, two methods were proposed to
find nearly global solutions to large-scale OPF problems with generation
cost minimization. In the case of active power loss minimization,
Lasserre’s hierarchy finds the global solution to large-scale problems,
provided the data is preprocessed to avoid bad conditioning. The
difference between the two cases is that active power loss is a convex
function of voltages, whereas generation cost is not. In the next
chapter, Lasserre’s hierarchy is transposed to complex numbers in order
to reduce its computional cost for OPF problems. Moreover, the sparsity
exploiting algorithm from [ 81 ] designed for OPF problems is formalized
for general polynomial optimization problems with either real or complex
variables.

## Chapter 7 Complex hierarchy for enhanced tractability

We consider the problem of finding the global optimum of a real-valued
complex polynomial @xmath ( @xmath ) on a compact set defined by
real-valued complex polynomial inequalities. It reduces to solving a
sequence of complex semidefinite optimization relaxations that grow
tighter and tighter thanks to D’Angelo’s and Putinar’s
Positivstellenstatz discovered in 2008. In other words, the Lasserre
hierarchy may be transposed to complex numbers. We propose a method for
exploiting sparsity and apply the complex hierarchy to problems with
several thousand complex variables. These problems consist of computing
optimal power flows in the European high-voltage transmission network.
The material presented in this chapter is based on the submitted
manuscript:
C. Josz, D. K. Molzahn , Moment/Sum-of-Squares Hierarchy for Complex
Polynomial Optimization , submitted to Society for Industrial and
Applied Mathematics, Journal on Optimization. [preprint]

### 7.1 Introduction

Multivariate polynomial optimization where variables and data are
complex numbers is a non-deterministic polynomial-time hard problem that
arises in various applications such as electric power systems (Section
7.4 ), imaging science [ 108 , 24 , 14 , 43 ] , signal processing [ 75 ,
3 , 29 , 71 , 68 , 12 ] , automatic control [ 121 ] , and quantum
mechanics [ 49 ] . Complex numbers are typically used to model
oscillatory phenomena which are omnipresent in physical systems.
Although complex polynomial optimization problems can readily be
converted into real polynomial optimization problems where variables and
data are real numbers, efforts have been made to find ad hoc solutions
to complex problems [ 112 , 53 , 54 ] . The observation that relaxing
nonconvex constraints and converting from complex to real numbers are
two non-commutative operations motivates our work. This leads us to
transpose to complex numbers Lasserre’s moment/sum-of-squares hierarchy
[ 62 ] for real polynomial optimization.

The moment/sum-of-squares hierarchy succeeds to the vast development of
real algebraic geometry during the twentieth century [ 91 ] . In 1900,
Hilbert’s seventeenth problem [ 103 ] raised the question of whether a
non-negative polynomial in multiple real variables can be decomposed as
a sum of squares of fractions of polynomials, to which Artin [ 10 ]
answered in the affirmative in 1927. Later, positive polynomials on sets
defined by a finite number of polynomial inequality constraints were
investigated by Krivine [ 59 ] , Stengle [ 113 ] , Schmüdgen [ 102 ] ,
and Putinar [ 92 ] . A theorem concerning such polynomials is referred
to as Positivstellensatz [ 101 ] . For instance, Putinar proved under an
assumption slightly stronger than compactness that they can be
decomposed as a weighted sum of the constraints where the weights are
sums of squares of polynomials. Lasserre [ 61 , 62 , 64 ] used this
result in 2001 to develop a hierarchy of semidefinite programs to solve
real polynomial optimization problems with compact feasible sets, with
Parrilo [ 89 , 90 ] making a similar contribution independently. In
order to satisfy the assumption made by Putinar, Lasserre proposed to
add a redundant ball constraint @xmath to the description of the
feasible set when it is included in a ball of radius @xmath . Subsequent
work on the hierarchy includes its comparison with lift-and-project
methods [ 65 ] , a new proof of Putinar’s Positivstellensatz via a 1928
theorem of Pólya [ 104 ] , and a proof of generically finite convergence
[ 87 ] .

In 1968, Quillen [ 98 ] showed that a real-valued bihomogenous complex
polynomial that is positive away from the origin can be decomposed as a
sum of squared moduli of holomorphic polynomials when it is multiplied
by @xmath for some @xmath . The result was rediscovered years later by
Catlin and D’Angelo [ 28 ] and ignited a search for complex analogues of
Hilbert’s seventeenth problem [ 35 , 36 ] and the ensuing
Positivstellensätze [ 94 , 38 , 96 , 95 ] . Notably, D’Angelo and
Putinar [ 37 ] proved in 2008 that a positive complex polynomial on a
sphere intersected by a finite number of polynomial inequality
constraints can be decomposed as a weighted sum of the constraints where
the weights are sums of squared moduli of holomorphic polynomials.
Similar to Lasserre, we use D’Angelo’s and Putinar’s Positivstellensatz
to construct a complex moment/sum-of-squares hierarchy of semidefinite
programs to solve complex polynomial optimization problems with compact
feasible sets. To satisfy the assumption in the Positivstellensatz, we
propose to add a slack variable @xmath and a redundant constraint @xmath
to the description of the feasible set when it is in a ball of radius
@xmath . The complex hierarchy is more tractable than the real hierarchy
yet produces potentially weaker bounds. Computational advantages are
shown using the optimal power flow problem in electrical engineering.

Below, Section 7.2 uses Shor and second-order conic relaxations to
motivate the construction of a complex moment/sum-of-squares hierarchy
in Section 7.3 . Using a sparsity-exploiting method, numerical
experiments on the optimal power flow problem are presented in Section
7.4 . Section 7.5 concludes our work.

### 7.2 Motivation

Let @xmath , @xmath , @xmath , @xmath and @xmath denote the set of
natural, positive natural, real, non-negative real, and complex numbers
respectively. Also, let “ ” denote the imaginary unit and @xmath denote
the set of Hermitian matrices of order @xmath . Let’s begin with the
subclass of complex polynomial optimization composed of
quadratically-constrained quadratic programs

  -- -------- -- --------

     @xmath      (7.1a)
     @xmath      (7.1b)
  -- -------- -- --------

where @xmath , @xmath , @xmath , and @xmath denotes the conjugate
transpose. The feasible set is not assumed to contain a point (i.e. it
may be empty). The Shor [ 106 ] and second-order conic relaxations of
QCQP- @xmath share the following property: it is better to relax
nonconvex constraints before converting from complex to real numbers
rather than to do the two operations in the opposite order.

#### Shor relaxation

For @xmath and @xmath , the relationship @xmath holds where @xmath
denotes the trace ¹ ¹ 1 For all matrices @xmath , @xmath . of a complex
square matrix. Relaxing the rank of @xmath in @xmath yields

  -- -------- -- --------

     @xmath      (7.2a)
     @xmath      (7.2b)
     @xmath      (7.2c)
  -- -------- -- --------

where @xmath indicates positive semidefiniteness.

Let @xmath and @xmath denote the real and imaginary parts of the matrix
@xmath respectively. Consider the ring homomorphism @xmath defined by

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

whose relevant properties are proven in Appendix A . To convert SDP-
@xmath into real numbers, real and imaginary parts of the complex matrix
variable are identified using two properties: (1) a complex matrix
@xmath is positive semidefinite if and only if the real matrix @xmath is
positive semidefinite, and (2) if @xmath , then @xmath . This yields the
converted problem

  -- -------- -- --------

     @xmath      (7.4a)
     @xmath      (7.4b)
     @xmath      (7.4c)
     @xmath      (7.4d)
  -- -------- -- --------

where @xmath denotes the set of real symmetric matrices of order @xmath
and @xmath indicates the transpose. Note that the set of matrices
satisfying ( 7.4d ) is isomorphic to @xmath . A global solution to QCQP-
@xmath can be retrieved from CSDP- @xmath if and only if @xmath at
optimality (proof in Appendix B ).

In order to convert QCQP- @xmath into real numbers, real and imaginary
parts of the complex vector variable are identified. This is done by
considering a new variable @xmath and observing that if @xmath , then
@xmath . This gives rise to a problem which we will call QCQP- @xmath .
Relaxing the rank of @xmath yields

  -- -------- -- --------

     @xmath      (7.5a)
     @xmath      (7.5b)
     @xmath      (7.5c)
  -- -------- -- --------

A global solution to QCQP- @xmath can be retrieved from SDP- @xmath if
and only if @xmath or @xmath and ( 7.4d ) holds at optimality.

We have @xmath where “val” is the optimal value of a problem (proof in
Appendix C ). The number of scalar variables of CSDP- @xmath is half
that of SDP- @xmath due to constraint ( 7.4d ). This constraint also
halves the possible ranks of the matrix variable, which must be an even
integer in CSDP- @xmath whereas it can be any integer between 0 and
@xmath in SDP- @xmath . The number of variables in SDP- @xmath can be
reduced by a small fraction ( @xmath to be exact) by setting a diagonal
element of @xmath to 0. This does not affect the optimal value (proof in
Appendix D ). Figure 7.1 summarizes this section.

#### Second-order conic relaxation

In SDP- @xmath , assume that the semidefinite constraint ( 7.2c ) is
relaxed to the second-order cones

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

Equation ( 7.6 ) is equivalent to constraining the determinant @xmath
and diagonal elements @xmath to be non-negative. This yields

  -- -------- -- --------

     @xmath      (7.7a)
     @xmath      (7.7b)
     @xmath      (7.7c)
     @xmath      (7.7d)
  -- -------- -- --------

where @xmath denotes the complex modulus. Identifying real and imaginary
parts of the matrix variable @xmath leads to

  -- -------- -- --------

     @xmath      (7.8a)
     @xmath      (7.8b)
     @xmath      (7.8c)
     @xmath      (7.8d)
     @xmath      (7.8e)
  -- -------- -- --------

In SDP- @xmath of Section, assume that the semidefinite constraint (
7.5c ) is relaxed to the second-order cones

  -- -------- -- -------
     @xmath      (7.9)
  -- -------- -- -------

This leads to

  -- -------- -- ---------

     @xmath      (7.10a)
     @xmath      (7.10b)
     @xmath      (7.10c)
     @xmath      (7.10d)
  -- -------- -- ---------

Unlike in the Shor relaxation, we have @xmath (proof in Appendix E ).
The number of scalar variables of CSOCP- @xmath is half that of SOCP-
@xmath due to constraint ( 7.8e ). The number of second-order conic
constraints in CSOCP- @xmath , equal to @xmath , is roughly a fourth of
that in SOCP- @xmath , equal to @xmath .

#### Exploiting sparsity

Given an undirected graph @xmath where @xmath and @xmath , define for
all @xmath

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

We associate an undirected graph @xmath to QCQP- @xmath whose nodes are
@xmath and that satisfies @xmath for @xmath . Let @xmath denote the set
of positive semidefinite Hermitian matrices of size @xmath and let “Ker”
denote the kernel of a linear application. Given the definition of
@xmath , constraint ( 7.2c ) of SDP- @xmath can be relaxed to @xmath
without changing its optimal value for any graph @xmath whose nodes are
@xmath and where @xmath . Consider a chordal extension @xmath , that is
to say that all cycles of length four or more have a chord (edge between
two non-consecutive nodes of the cycle). Let @xmath denote the maximal
cliques of @xmath . (A clique is a subgraph where all nodes are linked
to one another. The set of maximally sized cliques of a given graph can
be computed in linear time [ 117 ] ). A chordal extension has a useful
property for exploiting sparsity [ 46 ] : for all @xmath , we have that
@xmath if and only if @xmath for @xmath . Note that @xmath if and only
if @xmath , where “ @xmath ” is the composition of functions. Given a
graph @xmath , define for @xmath

  -- -- -- --------
           (7.12)
  -- -- -- --------

using the block decomposition in the left hand part of ( 7.4d ). Notice
that @xmath . As a result, ( 7.4c ) can be replaced by @xmath for @xmath
without changing the optimal value of CSDP- @xmath , with an analogous
replacement for constraint ( 7.5c ) in SDP- @xmath . If in SDP- @xmath
we exploit the sparsity of matrices @xmath instead of that of @xmath ,
the resulting graph has twice as many nodes. Computing a chordal
extension and maximal cliques is hence more costly.

Sparsity in the second-order conic relaxations is exploited using the
fact that applying ( 7.8c ) and ( 7.10c ) only for @xmath that are edges
of @xmath does not change the optimal values of CSOCP- @xmath and SOCP-
@xmath .

### 7.3 Complex moment/sum-of-squares hierarchy

We now transpose the work of Lasserre [ 62 ] from real to complex
numbers. Let @xmath denote the monomial @xmath where @xmath and @xmath
for some integer @xmath . Define @xmath and @xmath as the conjugate of
@xmath . Define @xmath where @xmath . Consider the sets

  -- -------- -- --------
     @xmath      (7.13)
  -- -------- -- --------

and for all @xmath

  -- -- -- --------
           (7.14)
  -- -- -- --------

Note that the coefficients of a function @xmath satisfy @xmath for all
@xmath for some @xmath . The set of complex polynomials @xmath is a
@xmath -algebra (i.e. commutative ring and vector space over @xmath )
and the set of holomorphic polynomials @xmath is a subalgebra of it
(i.e. subspace closed under sum and product). The set of real-valued
complex polynomials @xmath is an @xmath -algebra. The set of sums of
squared moduli of holomorphic polynomials @xmath and the set @xmath are
pointed cones (i.e. closed under multiplication by elements of @xmath )
that are convex (i.e. @xmath with @xmath belongs to them if @xmath and
@xmath do). Let @xmath denote the Banach (i.e. complete) @xmath -algebra
of continuous functions from a compact set @xmath to @xmath equipped
with the norm @xmath . Consider @xmath defined by @xmath where @xmath
denotes the restriction of @xmath to @xmath . @xmath is a unital
subalgebra of @xmath (i.e. contains multiplicative unit) that separates
points of @xmath (i.e. @xmath ) and that is closed under complex
conjugation. It is hence a dense subalgebra due to the Complex
Stone-Weiestrass Theorem. Likewise, @xmath is a Banach @xmath -algebra
of which @xmath is a dense subalgebra. In other words, a continuous
real-valued function of multiple complex variables can be approximated
as close as desired by real-valued complex polynomials when restricted
to a compact set. They are hence a powerful modeling tool in
optimization. Speaking of which, let @xmath and @xmath . Consider @xmath
where there exists @xmath and @xmath such that @xmath . In addition, for
@xmath , there exists @xmath and @xmath such that @xmath . Consider the
complex multivariate polynomial optimization problem

  -- -------- -- --------
     @xmath      (7.15)
  -- -------- -- --------

where by convention @xmath if the feasible set is empty. The feasible
set is a closed semi-algebraic set on which we make the following
assumption from now on:

  -- -------- -- --------
     @xmath      (7.16)
  -- -------- -- --------

Let @xmath denote the set of optimal solutions to ( 7.15 ). It may be
empty because we do not assume @xmath to be non-empty. (Note that in
practice, it is often hard to know whether there exists a feasible
solution, as for the application of Section 7.4 .)

Let @xmath denote the Banach space over @xmath of Radon measures on
@xmath . Bear in mind that since @xmath is compact, @xmath may be
identified with the topological dual of @xmath i.e. the Banach space
over @xmath of linear continuous applications from @xmath to @xmath
equipped with the operator norm. (This is due to the
Riesz-Markov-Kakutani Representation Theorem.) For @xmath , define
@xmath [ 100 , 1.31 Definition] ² ² 2 We wish to thank Bruno Nazaret for
bringing this reference to our attention. . Next, consider the convex
pointed cone @xmath . A Radon measure @xmath is positive (denoted @xmath
) if @xmath implies that @xmath . Let @xmath denote the set of positive
Radon measures. With these definitions, we have

  -- -------- -- --------
     @xmath      (7.17)
  -- -------- -- --------

Indeed, if @xmath , then the Dirac ³ ³ 3 The Dirac measure @xmath with
@xmath may be identified with the continuous linear application from
@xmath to @xmath defined by @xmath . This is one way to interpret the
fact that @xmath . measure @xmath is a feasible point of ( 7.17 ) for
which the objective value is equal to @xmath . Hence the optimal value
of ( 7.17 ) is less than or equal to @xmath . Conversly, if @xmath is a
feasible point of ( 7.17 ), then @xmath and hence @xmath .

###### Proposition 7.1.

The set of optimal solutions to ( 7.17 ) is

  -- -------- -- --------
     @xmath      (7.18)
  -- -------- -- --------

As a consequence, if @xmath is a finite set of @xmath points @xmath ,
then the set optimal solutions to ( 7.17 ) is @xmath .

###### Proof.

Consider @xmath an optimal solution to ( 7.17 ). It must be that @xmath
. Thus @xmath and @xmath . Therefore @xmath . Conversly, if @xmath
belongs to the set in ( 7.18 ), then it is feasible for ( 7.17 ) and
@xmath . Hence @xmath . ∎

In order to dualize the equality constraint in ( 7.17 ), consider the
Lagrange function @xmath defined by @xmath . We have @xmath and

  -- -------- -- --------
     @xmath      (7.19)
  -- -------- -- --------

since, in the second case, we may consider @xmath for a @xmath such that
@xmath and @xmath . This leads to the dual problem

  -- -------- -- --------
     @xmath      (7.20)
  -- -------- -- --------

Primal problem ( 7.17 ) gives rise to the complex moment hierarchy
below. Dual problem ( 7.20 ) gives rise to the complex sum-of-squares
hierarchy below.

#### Complex moment hierarchy

Let @xmath (respectively @xmath ) denote the set of sequences of complex
numbers @xmath (respectively @xmath ) such that @xmath for all @xmath
(respectively @xmath ).

###### Definition 7.2.

An element @xmath is said to have a representing measure @xmath on
@xmath if @xmath and @xmath for all @xmath . In that case, @xmath is
called the @xmath -moment of @xmath .

When @xmath has a representing measure on @xmath , the measure is unique
because @xmath is dense in @xmath . The complex moment problem consists
in characterizing the sequences that are representable by a measure on
@xmath and is connected to other branches of mathematics such as
functional analysis and spectral theory of operators [ 4 ] . It has been
studied by Atzmon [ 11 ] , Schmüdgen [ 102 ] , Putinar [ 93 ] , Curto
and Fialkow [ 32 , 34 , 33 ] , Stochel [ 114 ] , and Vasilescu [ 124 ] .
For example, Atzmon [ 11 , Theorem 2.1] proved that the solutions to the
complex moment problem where @xmath are the sequences @xmath such that
@xmath and @xmath for all complex numbers @xmath and @xmath with only
finitely many non-zero terms. A generalization to the multidimensional
case is considered in Section 7.3 . We conclude our presentation of the
complex moment problem by noting that the case where @xmath is not
compact is an open problem.

Consider a feasible point @xmath of ( 7.17 ) and the sequence @xmath
that has representation measure @xmath on @xmath . Notice that @xmath
and @xmath . For all @xmath , we have @xmath on @xmath . Since @xmath ,
this implies that @xmath . Naturally, we also have @xmath if we define
@xmath . Define @xmath and @xmath . Consider @xmath , @xmath , and
@xmath . We have @xmath

  -- -------- -- --------
     @xmath      (7.21)
  -- -------- -- --------

where @xmath and @xmath is a Hermitian matrix indexed by @xmath . As a
result

  -- -------- -- --------
     @xmath      (7.22)
  -- -------- -- --------

To sum up, @xmath is a feasible point of

  -- -------- -- --------
     @xmath      (7.23)
  -- -------- -- --------

with same objective value as @xmath in ( 7.17 ). Automatically, @xmath .
Consider the relaxation of ( 7.23 ) defined by

  -- -------- -- --------
     @xmath      (7.24)
  -- -------- -- --------

which we name the complex moment relaxation of order @xmath for reasons
that will become clear with Theorem 7.11 . In Section 7.3 , we will
introduce its dual counterpart.

###### Remark 7.3.

Given @xmath , the function @xmath in this section can be formally be
defined by the @xmath -linear operator @xmath such that @xmath for all
@xmath . If @xmath and @xmath , then @xmath . Given @xmath and @xmath ,
the matrix @xmath in ( 7.21 ) can be formally be defined as the
Hermitian matrix indexed by @xmath such that @xmath . Notice that @xmath
. Lastly, define @xmath which we refer to as complex moment matrix of
order @xmath .

#### Complex sum-of-squares hierarchy

We introduced notation @xmath for @xmath where @xmath and will now
extend it to @xmath . For such an element, there exists @xmath and
@xmath such that @xmath . Let @xmath . Also, define @xmath where @xmath
. Given @xmath , consider the Lagrange function @xmath defined by @xmath
. Compute @xmath . Observe that

  -- -------- -- --------
     @xmath      (7.25)
  -- -------- -- --------

Indeed, in the second case, there exists @xmath such that @xmath . With
@xmath , @xmath for either @xmath or @xmath . The associated dual
problem of ( 7.24 ) is thus

  -- -------- -- --------
     @xmath      (7.26)
  -- -------- -- --------

which we name the complex sum-of-squares relaxation of order @xmath .
Consider

  -- -------- -- --------
     @xmath      (7.27)
  -- -------- -- --------

whose relationship with ( 7.23 ) is touched upon in Proposition 7.4
below.

###### Proposition 7.4.

We have @xmath for all @xmath and @xmath .

###### Proof.

The sequence @xmath is non-decreasing and upper bounded by @xmath . Thus
it converges towards some limit @xmath such that @xmath . If @xmath ,
then @xmath for all @xmath and @xmath . If not, by definiton of the
optimum @xmath , there exists a sequence @xmath of feasible points such
that @xmath and @xmath . To each @xmath , we may associate an integer
@xmath such that @xmath is a feasible point of the complex
sum-of-squares relaxation of order @xmath . Thus @xmath . As a result,
@xmath . Moreover, @xmath is non-decreasing and upper bounded by @xmath
. Thus it converges towards some limit @xmath such that @xmath .
Moreover, weak duality implies that @xmath . Thus @xmath . It was
already shown that @xmath . ∎

###### Remark 7.5.

Problems ( 7.27 ) and ( 7.23 ) may be interpreted as a pair of
primal-dual linear programs in infinite-dimensional spaces [ 8 ] .
Indeed, consider the duality bracket @xmath defined from @xmath to
@xmath by @xmath . A sequence @xmath in @xmath is said to converge
weakly towards @xmath if for all @xmath , we have @xmath . Consider the
weakly continuous @xmath -linear operator @xmath defined by @xmath . Its
dual @xmath is defined by @xmath where @xmath and @xmath if @xmath .
Indeed, @xmath for all @xmath . Consider the convex pointed cone defined
by @xmath and its dual cone @xmath . With @xmath , notice that

  -- -------- -- --------
     @xmath      (7.28)
  -- -------- -- --------

Let @xmath denote the weak closure of @xmath in @xmath . According to [
5 , 5.91 Bipolar Theorem] ⁴ ⁴ 4 We wish to thank Jean-Bernard Baillon
for bringing this reference to our attention. , we have @xmath . In the
next section, Theorem 7.6 and Theorem 7.11 provide a sufficient
condition ensuring no duality gap in ( 7.28 ) and @xmath respectively.

#### Convergence of the complex hierarchy

We now turn our attention to a result from algebraic geometry discovered
in 2008.

###### Theorem 7.6 (D’Angelo’s and Putinar’s Positivstellenstatz [37]).

If one of the constraints that define @xmath in ( 7.16 ) is a sphere
constraint @xmath , then

  -- -------- -- --------
     @xmath      (7.29)
  -- -------- -- --------

###### Proof.

D’Angelo and Putinar wrote the theorem slightly differently so we
provide an explanation. Say that constraints @xmath and @xmath are such
that @xmath and @xmath where @xmath . With the assumptions of Theorem
7.6 , the authors of [ 37 , Theorem 3.1] show that there exists @xmath
and @xmath such that @xmath for all @xmath . Thanks to [ 36 ,
Proposition 1.2] , there exists @xmath such that @xmath hence the
desired result. ∎

Theorem 7.6 can easily be generalized to any sphere @xmath of radius
@xmath . With scaled variable @xmath , the sphere constraint has radius
1 and a monomial of ( 7.15 ) with coefficient @xmath reads @xmath . With
the scaled coefficients @xmath , Theorem 7.6 can then be applied.
Reverting back to the old scale @xmath in ( 7.29 ) leads to the desired
result. Accordingly, we define the following statement which we will
consider true only when explicitly stated:

  -- -------- -- --------
     @xmath      (7.30)
  -- -------- -- --------

Under the sphere assumption, @xmath is compact so assumption ( 7.16 )
holds.

###### Corollary 7.7.

Under the sphere assumption ( 7.30 ), @xmath and @xmath .

###### Proof.

Theorem 7.6 implies that @xmath because for all @xmath , function @xmath
is positive on @xmath . The sequences @xmath and @xmath converge towards
@xmath due to Proposition 7.4 . ∎

To require a sphere constraint in a complex polynomial optimization
problem seems very restrictive and irrelevant for many problems. But in
fact, a sphere constraint can be applied to any complex polynomial
optimization problem ( 7.15 ) with a feasible set contained in a ball
@xmath of known radius @xmath . Indeed, simply add a slack variable
@xmath and the constraint

  -- -------- -- --------
     @xmath      (7.31)
  -- -------- -- --------

Let @xmath denote the feasible set of the problem in @xmath variables.
If @xmath , then @xmath and has the same objective value. Conversly, if
@xmath , then @xmath for all @xmath such that @xmath . Again, the
objective value is unchanged. To ensure a bijection between @xmath and
@xmath , add yet two more constraints @xmath and @xmath , thereby
preserving the number of global solutions. In that case, the application
from @xmath to @xmath defined by @xmath is a bijection. Adding the two
extra constraints is optional and not required for convergence of
optimal values.

As seen in Theorem 7.6 , an equality constraint may be enforced via two
opposite inequality constraints. Let @xmath denote @xmath equality
constraints in polynomial optimization problem ( 7.15 ). Putinar and
Scheiderer [ 95 , Propositions 6.6 and 3.2 (iii)] show that the sphere
assumption in D’Angelo’s and Putinar’s Positivstellensatz may be
weakened to the existence of @xmath , @xmath , and @xmath such that

  -- -------- -- --------
     @xmath      (7.32)
  -- -------- -- --------

If a problem contains the constraints @xmath , then the assumption is
satisfied by @xmath , @xmath and @xmath . In particular, there is no
need to add a slack variable in the non-bipartite Grothendieck problem
over the complex numbers [ 14 ] .

###### Example 7.8.

D’Angelo and Putinar [ 37 ] consider @xmath and problem

  -- -------- -- --------
     @xmath      (7.33)
  -- -------- -- --------

whose set of global solutions is @xmath and @xmath . They prove that the
decomposition @xmath of Theorem 7.6 does not hold. As a result, the
optimal values of the complex sum-of-squares relaxations cannot exceed 0
even though @xmath . Indeed, if @xmath for some order @xmath , then
there exists @xmath and @xmath such that @xmath . Thus @xmath where
@xmath , which is a contradiction. We suggest solving

  -- -------- -- --------
     @xmath      (7.34)
  -- -------- -- --------

for which the decomposition of Theorem 7.6 holds thereby ensuring
convergence of the complex moment/sum-of-squares hierarchy (Corollary
7.7 ). In other words, for all @xmath there exists @xmath and @xmath
such that

  -- -------- -- --------
     @xmath      (7.35)
  -- -------- -- --------

Plug in @xmath and @xmath and obtain @xmath for all @xmath . While
function @xmath belongs to @xmath , function @xmath does not! Hence we
do not contradict the fact that @xmath is impossible. Consider @xmath so
that @xmath . Notice that @xmath for ( 7.33 ) and ( 7.34 ). The complex
relaxations of orders @xmath of ( 7.33 ) both yield ⁵ ⁵ 5 MATLAB 2013a,
YALMIP 2015.06.26 [ 69 ] , and MOSEK are used for the numerical
experiments. the value @xmath . The complex relaxation of order 2 of (
7.34 ) yields the value @xmath and optimal polynomials @xmath and @xmath
, all of which satisfy ( 7.35 ).

###### Example 7.9.

Putinar and Scheiderer [ 96 ] consider parameters @xmath and @xmath ,
and problem

  -- -------- -- --------
     @xmath      (7.36)
  -- -------- -- --------

whose set of global solutions is @xmath and @xmath . They prove that the
decomposition of Theorem 7.6 does not hold. Since the feasible set is
included in the Euclidean ball of radius @xmath , we suggest solving

  -- -------- -- --------
     @xmath      (7.37)
  -- -------- -- --------

Consider @xmath and @xmath so that @xmath . Notice that @xmath for (
7.36 ) and ( 7.37 ). The complex relaxations of orders @xmath of ( 7.36
) are unbounded. The complex relaxation of order 2 of ( 7.37 ) yields
the value 0.6813. That of order 3 yields the value 1.0000 and the
complex moment matrix ⁶ ⁶ 6 It so happens that the Hermitian matrix
@xmath , indexed by @xmath with @xmath , is real-valued in this example.
with @xmath precision

  -- -- -- --------
           (7.38)
  -- -- -- --------

which satisfies @xmath .

Examples 7.8 and 7.9 show the importance of the modeling of the feasible
set of the optimization problem. Depending on what equations are used to
define the feasible set, the complex moment/sum-of-squares hierarchy may
or may not converge towards the globally optimal value. If one of the
constraints is a sphere, convergence is guaranteed. The real
moment/sum-of-squares hierarchy also depends on how the feasible set is
modeled. In that case, convergence is guaranteed if one of the
constraints is a ball.

As a by-product of Corollary 7.7 , we propose a solution to the complex
moment problem in Theorem 7.11 below. To that end, consider Lemma 7.10
below where we transpose [ 56 , Lemma 3] from real to complex numbers.

###### Lemma 7.10.

Let @xmath be defined by @xmath . Given @xmath and @xmath , we have

  -- -------- -- --------
     @xmath      (7.39)
  -- -------- -- --------

###### Proof.

Given @xmath , we have @xmath

  -- -------- -- --------
     @xmath      (7.40)
  -- -------- -- --------

@xmath implies that @xmath for all @xmath and hence @xmath . In
addition, @xmath . Thus

  -- -------- -- --------
     @xmath      (7.41)
  -- -------- -- --------

which proves the lemma. ∎

The next theorem can be deduced from [ 95 ] but we provide a different
proof.

###### Theorem 7.11.

Under the sphere assumption ( 7.30 ), a sequence @xmath has a
representing measure on @xmath if and only if

  -- -------- -- --------
     @xmath      (7.42)
  -- -------- -- --------

###### Proof.

It was already shown that if @xmath has a representing measure on @xmath
, then ( 7.22 ) holds. Notice that ( 7.22 ) and ( 7.42 ) are equivalent,
hence the “only if” part. Concerning the “if” part, assume that @xmath
satisfies ( 7.42 ). If @xmath , then Lemma 7.10 implies that @xmath
which can be represented by @xmath on @xmath . Otherwise @xmath and
@xmath is a feasible point of problem ( 7.23 ) whose optimal value is
@xmath for all @xmath according to Corollary 7.7 . If moreover @xmath ,
then @xmath . In particular, if @xmath , then @xmath . We may therefore
define @xmath such that @xmath (similarily to Schweighofer [ 104 , Proof
of Theorem 2] ). If @xmath , then @xmath and @xmath . Linearity implies
that @xmath . As a result, for all @xmath , we have @xmath . Moreover,
@xmath is dense in @xmath . Therefore @xmath may be extended to a
continous linear functional on @xmath (we preserve the same name for the
extension). @xmath is compact thus the Riesz-Markov-Kakutani
Representation Theorem implies that there exists a unique Radon measure
@xmath such that @xmath for all @xmath . It is positive because @xmath
implies that @xmath (density argument). Finally, if @xmath , @xmath
(c.f. Remark 7.3 ) hence @xmath has representing measure @xmath on
@xmath . ∎

Vasilescu [ 124 , Theorem I.2.17] has already proposed a different
solution to the complex moment problem on @xmath . We now transpose the
proof of [ 56 , Theorem 1] from real to complex numbers.

###### Proposition 7.12.

Under the sphere assumption ( 7.30 ), @xmath for all @xmath .

###### Proof.

Given @xmath , consider the operator norm @xmath , the greatest
eigenvalue of @xmath in absolute value, and the Frobenius norm @xmath .
Consider @xmath . Two cases can occur. The first is that the feasible
set of the complex moment relaxation of order @xmath is non-empty, in
which case we consider a feasible point @xmath . All norms are
equivalent in finite dimension so there exists a constant @xmath such
that @xmath , according to Lemma 7.10 . As a result, the feasible set of
the complex moment relaxation of order @xmath is a non-empty compact set
and so is its image by @xmath (defined in ( 7.3 )). We can thus apply
Trnovská’s result [ 122 ] which states that in a semidefinite program in
real numbers, if the primal feasible set is non-empty and compact, then
there exists a dual interior point and there is no duality gap.

The second case is that the feasible set of the complex moment
relaxation of order @xmath is empty, i.e. @xmath . It must be strongly
infeasible because it cannot be weakly infeasible (see [ 40 , Section
5.2] for definitions). Indeed, if it is weakly infeasible, then there
exists a sequence @xmath of elements of @xmath such that for all @xmath
, we have @xmath and @xmath where @xmath . Define @xmath . We now mimick
the computations in Lemma 7.10 using @xmath and @xmath if @xmath .
Consider @xmath such that for all @xmath and @xmath , we have @xmath .
Equation ( 7.41 ) then becomes @xmath . As a result, @xmath , which,
together with @xmath , yields @xmath . Hence for all @xmath , the
spectrum of @xmath is lower bounded by @xmath and upper bounded by
@xmath . We therefore have @xmath . The sequence @xmath is thus included
in a compact set. Hence there exists a subsequence that converges
towards a limit @xmath which satisfies @xmath and the constraints @xmath
. Therefore @xmath is a feasible point of the complex moment relaxation
of order @xmath , which is a contradiction. Strong infeasibility means
that the dual feasible set contains an improving ray [ 40 , Definition
5.2.2] . Moreover, @xmath subject to @xmath is a semidefinite program
with a non-empty compact feasible set hence the dual feasible set
contains a point @xmath . As result @xmath is a feasible point of the
complex sum-of-squares relaxation of order @xmath . Together with the
improving ray, this means that @xmath . To conclude, @xmath in both
cases. ∎

###### Proposition 7.13.

Assume that complex polynomial optimization problem ( 7.15 ) satisfies (
7.32 ) and has a global solution @xmath . In addition, assume that
@xmath is an optimal solution to the sum-of-squares problem ( 7.27 ).
Then @xmath is a saddle point of @xmath defined by @xmath .

###### Proof.

The optimality of @xmath means that @xmath . With @xmath , @xmath , and
@xmath , we have @xmath for @xmath . It follows that @xmath for all
@xmath . For all @xmath , @xmath because @xmath . ∎

Given an application @xmath , define @xmath by @xmath . If @xmath is
@xmath -differentiable at point @xmath , consider the Wirtinger
derivative [ 129 ] defined by @xmath .

###### Corollary 7.14.

With the same assumptions as in Proposition 7.13 , we have

  -- -------- -- --------
     @xmath      (7.43)
  -- -------- -- --------

###### Proof.

@xmath is a minimizer of @xmath thus @xmath . Consider @xmath . Since
@xmath and @xmath , it must be that @xmath divides @xmath . With @xmath
, the real number @xmath is a root of multiplicity 2 of @xmath , with an
analogous remark for @xmath . Thus @xmath which leads to the desired
result. ∎

#### Comparison of real and complex hierarchies

Similar to Shor relaxation and the second-order conic relaxation, the
following notations will be used: POP- @xmath denotes the complex
polynomial optimization problem ( 7.15 ); POP- @xmath denotes the real
polynomial optimization problem after conversion of POP- @xmath into
real numbers; @xmath - @xmath denotes the complex moment/sum-of-squares
relaxation of order @xmath applied to POP- @xmath ; @xmath - @xmath
denotes the conversion of @xmath - @xmath into real numbers; and @xmath
- @xmath denotes the real moment/sum-of-squares relaxation of order
@xmath applied to POP- @xmath . Let @xmath - @xmath and @xmath - @xmath
respectively denote the minimum orders of the real and complex
hierarchies. Consider the sets

  -- -- -- --------
           (7.44)
  -- -- -- --------

where @xmath and @xmath .

###### Proposition 7.15.

Under the sphere assumption ( 7.30 ), for all integer @xmath greater
than or equal to @xmath , we have

  -- -------- -- --------
     @xmath      (7.45)
  -- -------- -- --------

###### Proof.

It suffices to compare the optimal values of the real and complex
sum-of-squares relaxations. This is due to Proposition 7.12 and [ 56 ]
where the ball constraint can be replaced by the sphere constraint to
ensure no duality gap. We have

  -- -------- -- --------
     @xmath      (7.46)
  -- -------- -- --------

We now conclude because for all @xmath , @xmath . Indeed, if @xmath with
@xmath and @xmath , then @xmath . ∎

We may suspect the inequality in ( 7.45 ) to be strict in some cases
because @xmath is a strict subset of @xmath for all @xmath . Indeed, for
@xmath , we have @xmath . According to numerical experiments ⁷ ⁷ 7 We
attempted a formal proof but it is difficult even on such a small
example. , the inequality is strict for ( 7.37 ) in Example 7.9 ( @xmath
and @xmath ).

Proposition 7.45 seems to imply that the real moment/sum-of-squares
hierarchy is better than the complex one. However, the size of the
largest semidefinite constraint of @xmath - @xmath , equal to @xmath ,
is far inferior to that of @xmath - @xmath , equal to @xmath . For
instance, if @xmath and @xmath , the former is 572 and the latter is
1,771.

###### Proposition 7.16.

Given @xmath and @xmath , we have

  -- -------- -- --------
     @xmath      (7.47)
  -- -------- -- --------

###### Proof.

( @xmath ) Notice that @xmath
@xmath . Polarization implies that for all @xmath , we have
@xmath and hence for all @xmath , @xmath . If @xmath , then for all
@xmath , @xmath and thus @xmath . ( @xmath ) Simply compute @xmath . ∎

###### Definition 7.17.

Complex polynomial optimization problem ( 7.15 ) is said to be
oscillatory if @xmath , and @xmath satisfy either of the two equivalent
properties in ( 7.47 ).

###### Proposition 7.18.

If complex polynomial optimization problem ( 7.15 ) is oscillatory, then
@xmath .

###### Proof.

Observe that @xmath - @xmath and @xmath where @xmath denotes the ceiling
of a real number. Both are equal if the problem is oscillatory. ∎

###### Conjecture 7.19.

Under the sphere assumption ( 7.30 ), if complex polynomial optimization
problem ( 7.15 ) is oscillatory, then for all @xmath , we have

  -- -------- -- --------
     @xmath      (7.48)
  -- -------- -- --------

In Section 7.4 , we consider problems for which Conjecture 7.19 seems to
hold numerically. This suggests that for oscillatory problems, the
complex hierarchy is more tractable than the real hierarchy at no loss
of bound quality.

#### Exploiting sparsity in real and complex hierarchies

The chordal sparsity technique described in Section 7.2 has been
extended to the real hierarchy by Waki [ 126 ] and may readily be
transposed to the complex hierarchy. Each positive semidefinite
constraint in ( 7.24 ) is replaced by a set of positive semidefinite
constraints on certain submatrices of @xmath . These submatrices are
defined by the maximal cliques of a chordal extension of the graph
associated with the objective and constraint equations. Equivalently,
the sum-of-squares variables @xmath in the dual formulation ( 7.26 ) are
restricted to be functions of a subset (defined by the same maximal
cliques) of the decision variables @xmath . These sparse relaxation
hierarchies provide potentially lower bounds than their dense
counterparts yet retain convergence guarantees [ 64 ] . However, further
size reduction is often necessary. We propose to selectively apply
computationally intensive higher-order constraints in the sparse
relaxations. In other words, rather than a single relaxation order
applied to all constraints, each constraint has an associated relaxation
order. This allows for solving many large-scale problems.

We now formalize our approach applied to the complex hierarchy. ⁸ ⁸ 8
See [ 81 ] for the details of this approach as applied to @xmath -
@xmath in the context of the optimal power flow problem. Objective
function @xmath and constraints @xmath in ( 7.15 ) have an associated
undirected sparsity graph @xmath with nodes @xmath corresponding to each
variable and edges @xmath for each pair of variables that appear
together in any monomial that has a non-zero coefficient in the
objective function or constraints.

Each constraint function @xmath has an associated relaxation order
@xmath so that @xmath . When @xmath , there must exist at least one
clique of a chordal extension of @xmath that contains all variables with
non-zero coefficients in @xmath . To ensure this, define a supergraph
@xmath where @xmath is composed of @xmath augmented with edges
connecting all variables with non-zero coefficients in @xmath , not
necessarily in the same monomial. For example, @xmath with @xmath
implies @xmath and @xmath .

To exploit sparsity, construct a chordal extension @xmath of @xmath . ⁹
⁹ 9 One approach to creating a chordal extension is to use the sparsity
pattern of a Cholesky factorization (employing a minimum degree ordering
to maintain sparsity) of the Laplacian matrix associated with @xmath
plus an identity matrix. Denote the set of maximally sized cliques of
the chordal extension by @xmath . By construction of @xmath , each
constraint function @xmath for which @xmath has all associated variables
contained in at least one clique. For each @xmath for which @xmath ,
denote as @xmath the minimal covering clique (i.e., the smallest clique
in @xmath that contains all variables in @xmath ). (If not unique, a
single clique @xmath is chosen arbitrarily among the smallest cliques.)
Associate an order @xmath with each clique @xmath defined such that
@xmath is the maximum relaxation order @xmath among all constraints for
which the clique @xmath is the minimal covering clique. If a clique
@xmath is not a minimal covering clique for any constraints, then @xmath
. See Appendix F for a small illustrative example.

For all @xmath such that @xmath , the positive semidefinite constraints
@xmath in the moment hierarchy ( 7.24 ) are replaced by @xmath , where
@xmath such that all non-zero entries of @xmath and @xmath correspond to
variables in @xmath . For @xmath , the positive semidefinite constraint
@xmath (recall that @xmath and @xmath ) is replaced by constraints
defined by each maximal clique: @xmath , where @xmath such that all
non-zero entries of @xmath and @xmath correspond to variables in @xmath
.

For the sum-of-squares representation of the hierarchy, the polynomials
@xmath in ( 7.26 ) are replaced by sums-of-squares polynomials @xmath ,
where @xmath denotes the subset of variables @xmath that are in the
clique @xmath . The polynomial @xmath is replaced by the polynomial
@xmath where @xmath .

The sparse version of the real hierarchy @xmath - @xmath converges to
the global optimum of a polynomial optimization problem when the
constraints include ball constraints on all decision variables @xmath
included in each clique: @xmath , where @xmath is the radius of a ball
enclosing all decision variables in clique @xmath [ 64 ] . A similar
result holds for the complex hierarchy @xmath - @xmath with sphere
constraints enforced for the variables included in each clique. Due to (
7.32 ), the sparse version of the complex hierarchy is guaranteed to
converge to the global optimum of ( 7.15 ) with increasing relaxation
order when the constraints include @xmath , where @xmath is a slack
variable associated with clique @xmath .

Selectively applying the higher-order constraints requires a method for
determining the relaxation order @xmath for each constraint. We use a
heuristic based on “mismatches” to the closest rank-one matrix [ 81 ] .
The idea is to extract the largest eigenvalue @xmath and its associated
unit-length eigenvector @xmath from @xmath , hence defining an
“approximate” solution @xmath to the polynomial optimization problem.
Define “mismatches” @xmath and @xmath between the solution @xmath to the
relaxation and @xmath :

  -- -------- -------- -- ---------

     @xmath   @xmath      (7.49a)
     @xmath   @xmath      (7.49b)
  -- -------- -------- -- ---------

We use the iteration in Algorithm 2 to determine relaxation orders
@xmath . Each iteration solves the moment/sum-of-squares relaxation
after increasing the relaxation orders @xmath in a manner that is
dependent on the largest associated @xmath values. Denote @xmath . ¹⁰ ¹⁰
10 Note that @xmath is not a specified maximum relaxation order but can
change at each iteration. At each iteration of the algorithm, increment
@xmath at up to @xmath constraints, where @xmath is a specified
parameter, that have the largest mismatches @xmath among constraints
satisfying two conditions: (1) @xmath and (2) @xmath , where @xmath is a
specified mismatch tolerance. If no constraints satisfy both of these
conditions, increment @xmath at up to @xmath constraints with the
largest @xmath greater than the specified tolerance and increment @xmath
. That is, in order to prevent unnecessarily increasing the size of the
matrices, the heuristic avoids incrementing the maximum relaxation order
@xmath until @xmath at all constraints @xmath with mismatch @xmath .

There is a computational trade-off in choosing the value of @xmath .
Larger values of @xmath likely result in fewer iterations of the
algorithm but each iteration is slower if more buses than necessary have
high-order relaxations. Smaller values of @xmath result in faster
solution at each iteration, but may require more iterations.

The algorithm terminates upon satisfaction of two conditions: First,
@xmath , where @xmath denotes the infinity norm (maximum absolute
value), which indicates that the iterate is a numerically feasible point
of polynomial optimization problem ( 7.15 ). Second, @xmath , which
indicates global optimality to within a relative tolerance @xmath . If
the relaxation satisfies the former but not the latter termination
condition (which was never observed in practice for the problem in
Section 7.4 ), the algorithm increases @xmath at the @xmath constraints
with largest mismatch @xmath and continues iterating.

The moment/sum-of-squares hierarchy is successively tightened in a
manner that preserves computational tractability. For sufficiently small
tolerances @xmath and @xmath , Algorithm 2 eventually proceeds to build
the complete moment/sum-of-squares hierarchies. Thus, Algorithm 2
inherits the theoretical convergence guarantees of @xmath - @xmath . The
same can be said of the real version of Algorithm 2 applied to @xmath -
@xmath .

1: Set @xmath .

2: repeat

3: Solve relaxation with order @xmath for constraints @xmath .

4: Calculate mismatches @xmath using ( 7.49b ).

5: Increase entries of @xmath according to the mismatch heuristic.

6: until @xmath and @xmath

7: Extract solution @xmath .

Algorithm 2 Iterative Solution for Sparse Moment/Sum-of-Squares
Relaxations

### 7.4 Numerical results

The optimal power flow problem is an instance of complex polynomial
optimization. Since 2006, the power systems literature has been studying
the ability of the Shor and second-order conic relaxations to find
global solutions [ 51 , 13 , 66 , 82 , 131 , 119 , 22 , 85 , 20 , 70 ,
72 , 7 , 30 , 18 , 118 , 80 , 84 , 83 ] . Some relaxations are presented
in real numbers [ 66 , 82 ] and some in complex numbers [ 131 , 20 , 18
] . Nevertheless, in all numerical applications, standard solvers such
as SeDuMi, SDPT3, and MOSEK are used which currently handle only real
numbers. Modeling languages such as YALMIP and CVX do handle inputs in
complex numbers, but the data is transformed into real numbers before
calling the solver [ 21 , Example 4.42] . We use the European network to
illustrate the fact that it is beneficial to relax nonconvex constraints
before converting from complex to real numbers. The Shor relaxation, the
second-order conic relaxation, and the moment/sum-of-squares hierarchy
are considered.

We consider large test cases representing portions of European electric
power systems. They represent Great Britain (GB) [ 123 ] and Poland (PL)
[ 132 ] power systems as well as other European systems from the PEGASE
project [ 42 , 55 ] . The test cases were preprocessed to remove
low-impedance lines as described in [ 84 ] in order to improve the
solver’s numerical convergence, which is a typical procedure in power
system analyses. ¹¹ ¹¹ 11 Low-impedance lines often model connections
between buses in the same physical location. A @xmath per unit
low-impedance line threshold was used for all test cases except for
PEGASE-1354 and PEGASE-2869 which use a @xmath per unit threshold. The
processed data is described in Table 7.1 . This table also includes the
at-least-locally-optimal objective values obtained from the interior
point solver in M atpower [ 132 ] for the problems after preprocessing.
Note that the PEGASE systems specify generation costs that minimize
active power losses, so the objective values in both columns are the
same.

Implementations use YALMIP 2015.06.26 [ 69 ] , Mosek 7.1.0.28, and
MATLAB 2013a on a computer with a quad-core 2.70 GHz processor and 16 GB
of RAM. The results do not include the typically small formulation
times.

#### Shor relaxation

Table 7.2 shows the results of applying SDP- @xmath and SDP- @xmath to
the test cases. For some problems, the Shor relaxation is exact and
yields the globally optimal decision variables and objective values. To
practically identify such problems, solutions for which all power
injection mismatches @xmath (see Section 7.4 ) are less than a tolerance
of 1 MVA are considered exact. These problems are identified with an
asterisk (*) in Table 7.2 .

The lower bounds in Table 7.2 suggest that the corresponding M atpower
solutions in Table 7.1 are at least very close to being globally
optimal. The gap between the M atpower solutions and the lower bounds
from SDP- @xmath for the generation cost minimizing problems are less
than 0.72% for GB-2224, 0.29% for the Polish systems, and 0.02% for the
PEGASE systems with the exception of PEGASE-9241. The non-physical
negative resistances in PEGASE-9241 result in weaker lower bounds from
the relaxations, yielding a gap of 1.64% for this test case.

As shown in Appendices C and D , the optimal objective values for SDP-
@xmath and SDP- @xmath should be identical. With all objective values in
Table 7.2 matching to within @xmath , this is numerically validated.

For these test cases, SDP- @xmath is significantly faster (between a
factor of 1.60 and 3.31) than SDP- @xmath . This suggests that
exploiting the isomorphic structure of complex matrices in SDP- @xmath
is better than eliminating a row and column in SDP- @xmath .

#### Second-order conic relaxation

Table 7.3 shows the results of applying SOCP- @xmath and SOCP- @xmath to
the test cases. Unlike the Shor relaxation, the second-order conic
relaxation is not exact for any of the test cases. (SOCP- @xmath is
generally not exact with the exception of radial systems for which the
relaxation is provably exact when certain non-trivial technical
conditions are satisfied [ 70 ] .)

SOCP- @xmath provides better lower bounds and is computationally faster
than SOCP- @xmath . Specifically, lower bounds from SOCP- @xmath are
between @xmath and @xmath larger and solver times are faster by between
a factor of @xmath and @xmath than those from SOCP- @xmath .

#### Moment/sum-of-squares hierarchy

Relaxations from the real moment/sum-of-squares hierarchy globally solve
a broad class of optimal power flow problems [ 79 , 57 , 81 , 44 ] .
Previous work uses @xmath - @xmath by first converting the complex
formulation of the optimal power flow problem to real numbers.

We next summarize computational aspects of both the real and complex
hierarchies. The dense formulations of the hierarchies solve small
problems (up to approximately ten buses). Without also selectively
applying the higher-order relaxations’ constraints (i.e., @xmath ),
exploiting network sparsity enables solution of the second-order
relaxations for problems with up to approximately 40 buses.

Scaling to larger problems is accomplished by both exploiting network
sparsity and selectively applying the computationally intensive
higher-order relaxation constraints to specific “problematic” buses. To
better match the structure of the optimal power flow constraint
equations, we use the algorithm in [ 81 ] , which is slightly different
than that described in Section 7.3 . Rather than consider each
constraint individually, we use the mismatch in apparent power
injections at each bus rather than the active and reactive power
injection equations separately. The relaxation orders @xmath associated
with all constraints at a bus are changed together.

Specifically, mismatches for the active and reactive power injection
constraints at bus @xmath , denoted as @xmath and @xmath , are
calculated using ( 7.49b ). Problematic buses are identified as those
with large apparent power injection mismatch @xmath . Application of the
higher-order relaxation’s constraints to these problematic buses using
the iterative algorithm described in [ 81 ] (cf Section 7.3 ) results in
global solutions to many optimal power flow problems and enables
computational scaling to systems with thousands of buses [ 81 , 84 ] .
This section extends this approach to the complex hierarchy.

Tables 7.4 and 7.5 show the results of applying the algorithm from [ 81
] for both the real and complex hierarchies to several test cases with
tolerances @xmath and @xmath . ¹³ ¹³ 13 The algorithm in [ 81 ] has a
parameter @xmath specifying the maximum number of buses to increase the
relaxation order @xmath at each iteration. This parameter is set to two
for these examples. Additionally, bounds on the lifted variables @xmath
derived from the voltage magnitude limits are enforced to improve
numeric convergence. The optimal objective values in these tables match
to at least 0.007%, which is within the expected solver tolerance.
Further, the solutions for both the real and complex hierarchies match
the optimal objective values for the loss minimizing problems obtained
from M atpower shown in Table 7.1 to within 0.013%, providing an
additional numerical proof that these solutions are globally optimal.
Note, however, that local solvers do not always globally solve optimal
power flow problems [ 22 , 81 , 26 ] .

The test cases considered in Tables 7.4 and 7.5 minimize active power
losses rather than generation costs. Although the moment/sum-of-squares
hierarchy solves many small- and medium-size test cases which minimize
generation cost, application of the algorithm in [ 81 ] to larger
generation-cost-minimizing test cases often requires too many
higher-order constraints for tractability. See [ 72 , 84 , 83 ] for
related algorithms which often find feasible points that are nearly
globally optimal for such problems.

The feasible set of the optimal power flow problem is included is the
ball of radius @xmath so a slack variable and a sphere constraint may be
added as suggested in Section 7.3 . In order to preserve sparsity, a
slack variable and a sphere constraint may be added for each maximal
clique of the chordal extension of the network graph. Global convergence
is then guaranteed due to ( 7.32 ). However, the sphere constraint tends
to introduce numerical convergence challenges in problems with several
thousand buses, resulting in the need for higher-order constraints at
more buses and correspondingly longer solver times.

Interestingly, the examples in Table 7.5 converged without the slack
variables and sphere constraints, and the results therein correspond to
relaxations without sphere constraints. A potential way to account for
the success of the complex hierarchy without sphere constraints would be
to compute the Hermitian complexity [ 38 ] of the ideal generated by the
polynomials associated with equality constraints. A step in that
direction would be to assess the greatest number of distinct points
(possibly infinite) @xmath such that @xmath for all buses @xmath not
connected to a generator and for all @xmath . Note that the Hermitian
complexity of the ideal generated by @xmath as defined in ( 7.32 ) with
@xmath is equal to 1.

Despite being unnecessary for convergence of the hierarchies in Table
7.5 , the sphere constraint can tighten the relaxations of some optimal
power flow problems. Consider, for instance, the 9-bus example in [ 22 ]
. The dense second-order relaxations from the real and complex
hierarchies (both with and without the sphere constraint) yield the
global optimum of $3088/hour. Likewise, with second-order constraints
enforced at all buses, the sparse versions of the real hierarchy and the
complex hierarchy with the sphere constraint yield the global optimum.
However, the sparse version of the second-order complex hierarchy
without the sphere constraint only provided a lower bound of $2939/hour.
Thus, the sphere constraint tightens the sparse version of the
second-order complex hierarchy for this test case. Since the sparse
version of the third-order complex hierarchy without the sphere
constraint yields the global optimum, the sphere constraint is
unnecessary for convergence in this example.

Similar to the second-order conic relaxation, the results in Tables 7.4
and 7.5 show that the complex hierarchy generally has computational
advantages over the real hierarchy. For all the test cases except
PEGASE-1354, @xmath - @xmath solves between a factor of 1.31 and 21.42
faster than @xmath - @xmath . The most significant computational speed
improvements for the complex hierarchy over the real hierarchy are seen
for cases (e.g., PL-2383wp and PL-2746wop) where the higher-order
constraints account for a large portion of the solver times. The complex
hierarchy for these cases has significantly fewer terms in the
higher-order constraints than the real hierarchy.

Observe that several of the test cases (PL-3012wp, PL-3120sp,
PEGASE-1354, and PEGASE-2869) require more iterations of the algorithm
from [ 81 ] for @xmath - @xmath than for @xmath - @xmath . Nevertheless,
the improved speed per iteration results in faster overall solution
times for all of these test cases except for PEGASE-1354, for which six
additional iterations result in a factor of 2.78 slower solver time.

Both hierarchies were also applied to a variety of small test cases
(less than ten buses) from [ 85 , 22 , 67 , 78 ] for which the
first-order relaxations failed to yield the global optima. For all these
test cases, the dense versions of both @xmath - @xmath and @xmath -
@xmath converged at the same relaxation order. Section 7.3 demonstrates
that the @xmath - @xmath is at least as tight as @xmath - @xmath . The
results for small problems suggest that the hierarchies have the same
tightness for some class of polynomial optimization problems which
includes the optimal power flow problem with the sphere constraint (cf
Conjecture 7.19 ). The numerical results for some large test cases have
different numbers of iterations between the real and complex
hierarchies. Rather than differences in the theoretical tightness of the
relaxation hierarchies, we attribute this discrepancy in the number of
iterations to numerical convergence inaccuracies; not enforcing the
sphere constraint for the sparse complex hierarchy; and, in some cases,
the algorithm from [ 81 ] selecting different buses at which to enforce
the higher-order constraints.

### 7.5 Conclusion

We construct a complex moment/sum-of-squares hierarchy for complex
polynomial optimization and prove convergence toward the global optimum.
Theoretical and experimental evidence suggest that relaxing nonconvex
constraints before converting from complex to real numbers is better
than doing the operations in the opposite order. We conclude with the
question: is it possible to gain efficiency by transposing convex
optimization algorithms from real to complex numbers?
This chapter contains several appendices that may be found after Chapter
8 .

## Chapter 8 Conclusion and perspectives

The main challenge that prompted this doctoral project was to be able to
provide global solutions to the optimal power flow problem using
semidefinite programming when the Shor relaxation fails. Having realized
that the Lasserre hierarchy offers a solution to this challenge for
small networks, the goal of the dissertation became to apply the
Lasserre hierarchy to solve large-scale networks. The main contribution
was to adapt the Lasserre hierarchy to the complex structure of our
problem to enhance its tractability. This yielded a new general
approach, the complex moment/sum-of-squares hierarchy.

In Chapter 2 , it was shown that the Lasserre hierarchy solves
small-scale networks to global optimality. These networks could not be
solved using the Shor relaxation. Surprisingly, the hierarchy solves
them for low orders, generally the second or third order. However, the
second order relaxation can only be applied to about a dozen of
variables. With more variables, it becomes intractable.

In Chapter 3 , it was proven that there is no duality gap at each order
of the Lasserre hierarchy provided one the constraints is a ball
constraint. This result is relevant because Lasserre proposes to add a
redundant ball constraint to bounded feasible sets in order to guarantee
convergence of the hierarchy. As a corrolary, we obtained that there is
no duality gap at each order of the hierarchy applied to the optimal
power flow problem, without having to add a redundant ball constraint.
Note that the ball constraint is not needed in the case of our problem
of interest due to upper bound constraints on the variables, that is to
say upper voltage bounds. The property we’ve proven is necessary for
interior-point solvers to converge to solutions of the semidefinite
programs in the Lasserre hierarchy.

In Chapter 4 , new large-scale test cases are presented. They correspond
to sections of the European high-voltage transmission network and the
entire network. They can be viewed as quadratically-constrained
quadratic programs where the variables and data are complex numbers.
They consist in sparse problems with several thousand complex variables,
with 9,241 variables in the biggest test case. The new data are
representative of the size and complexity of real world power systems.
They can hence be used to validate new methods and tools, such as those
developed in this dissertation.

In Chapter 5 , the Lasserre hierarchy is applied to large-scale networks
by combining it with a penalization approach. As a result, nearly global
solutions are found to generation cost minizimation problems, with a
guarantee of how far the value is from the global value. For power loss
minimization problems, the objective function is convex. In those cases,
the Lasserre hierarchy finds the global solution. In all cases, the
sparsity of the problem is exploited using the notions of chordal graph
and maximal clique, as well as a technique to identify problematic
constraints. Higher-orders of the Lasserre hierarchy are then only
applied to those constraints, reducing computation time. Moreover, low
impedance lines are removed to cope with the inherent bad conditionning
of power systems data.

In Chapter 6 , a method for finding nearly global solutions to the
optimal power flow problem is proposed. It does so without having to
specify a parameter, which a major disadvantage of penalization
approaches. It is inspired by successful penalizations of the optimal
power flow, which we observed to be linked with Laplacian matrices of
the graph of the power network. Minimizing a quadratic form defined by
such a Laplacian matrix over the power flow equations promotes low rank
solutions. In fact, by iterative update of the weights of the Laplacian
matrix, the rank can be reduced to one for many large-scale test cases.
To guarantee near global optimality, the original objective function is
set as a constraint. It is constrained to be less than or equal to the
lower bound obtained by the Shor relaxation, plus a small fraction of
it. This is founded because in all practical test cases, the Shor
relaxation computes a lower bound of very high quality.

In Chapter 7 , the Lasserre hierarchy is transposed to complex numbers
in order to reduce the computional burden when solving polynomial
problems with complex data and variables. The motivation for this is
that the optimal power flow problem is a special case of complex
polynomial optimization. We introduce a complex hierarchy and prove its
convergence to the global solution for any complex polynomial problem
with a feasible set of known radius. The proof relies on recent
developments in algebraic geometry. The global solution to problems with
several thousand complex variables is retrieved with the complex
hierarchy. Sparsity is exploited by using chordal graphs techniques and
a mismatch procedure to identify problematic constraints.

There are various future research directions as a result of this
dissertation. One direction is to enhance the tractability of the
complex moment/sum-of-squares hierarchy. A way to accomplish this may be
to develop a solver in complex numbers. Interior point solvers involve
Cholesky factorizations, and Cholesky factorizations could be carried
out on the Hermitian matrices. Another speed-up could come from
developing a randomized complex hierarchy. This is based on an idea
proposed by Lasserre. Two polynomials are equal to one another with high
probability if they are equal on a randomly generated set of points.
Thus far, the complex hierarchy is only able to solve optimal power flow
problems which minimize active power loss, which is convex function of
voltage. By enhancing the tractability of the complex hierarchy, it will
hopefully be possible to tackle more general objective functions such as
generation cost minimization or minimum deviation from a generation
plan.

The complex hierarchy entails a trade-off. It is more tractable than the
real hierarchy at a given order, but provides a potentially lower bound.
It would interesting to know when the bounds generated by both
hierarchies are the same. That would correspond to the cases for which
it is certainly advantageous to use the complex hierarchy. In the case
of the optimal power flow problem, numerical results show it is
advantageous. It would be enviable to better understand why this is so.

Another research direction is to answer the following question. Do the
power flow equations possess the Quillen property? In other words, is
the complex hierarchy guaranteed to converge without having to add a
slack variable and a redundant sphere constraint? Numerical experiments
seem to show that this is true, but it is not clear why.

Lastly, transmission system operators are interested in optimization
tools that cope with discrete variables. Indeed, there are many
decisions which must be made from a finite number of possibilities: unit
commitment, tap of phase-shifting transformers, and changes in network
topology. The framework of real and complex polynomial optimization
encompasses such cases, so real and complex hierarchies are relevant
from a theoritical perspective. The Lasserre hierarchy is known to
provide the best bounds to hard combinatorial problems, so it makes
sense to try to apply real and complex hierarchies to the optimal power
flow problem with discrete variables.

## Appendix A Ring Homomorphism

It is shown here that the application @xmath defined by ( 7.3 ) is a
ring homomorphism.
Let @xmath denote the identity matrix of order @xmath . @xmath and if
@xmath , @xmath and

  -- -------- --
     @xmath
  -- -------- --

## Appendix B Rank-2 Condition

It is proven here that a Hermitian matrix @xmath is positive
semidefinite and has rank 1 if and only if @xmath is positive
semidefinite and has rank 2.
@xmath Say @xmath where real and imaginary parts are defined by @xmath
and @xmath . Then

  -- -------- -------- -- --------

     @xmath   @xmath      (B.1a)
              @xmath      (B.1b)
  -- -------- -------- -- --------

The rank of @xmath is equal to 2 since @xmath and @xmath are non-zero
orthogonal vectors.

@xmath Say @xmath where @xmath and @xmath are non-zero real vectors.
Consider the block structure @xmath and @xmath . For @xmath , it must be
that

  -- -------- -- --------

     @xmath      (B.2a)
     @xmath      (B.2b)
  -- -------- -- --------

Two cases can occur. The first is that @xmath in which case there exists
a real number @xmath such that

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

Equation ( B.2a ) implies that @xmath thus @xmath and @xmath . The
second case is that @xmath . Then, according to ( B.2b ), @xmath . If
either @xmath or @xmath , then ( B.2a ) implies that @xmath . If @xmath
, then ( B.2a ) implies that @xmath . If @xmath , then ( B.2a ) implies
that @xmath .

In any case, there exists @xmath such that

  -- -------- -- -------
     @xmath      (B.4)
  -- -------- -- -------

For @xmath it must be that

  -- -------- -- --------

     @xmath      (B.5a)
     @xmath      (B.5b)
  -- -------- -- --------

Moreover

  -- -------- -- -------
     @xmath      (B.6)
  -- -------- -- -------

It will now be shown that

  -- -------- -- -------
     @xmath      (B.7)
  -- -------- -- -------

It is obvious if @xmath . If @xmath , then ( B.5a )–( B.5b ) imply

  -- -------- -- --------

     @xmath      (B.8a)
     @xmath      (B.8b)
  -- -------- -- --------

If @xmath , it can be seen that ( B.7 ) holds. If not, ( B.8a ) implies
that there exists a real number @xmath such that

  -- -------- -- -------
     @xmath      (B.9)
  -- -------- -- -------

Further, ( B.8b ) implies that @xmath . This is impossible ( @xmath and
@xmath ). Thus, ( B.7 ) holds.

With the left hand side corresponding to @xmath and the right hand side
corresponding to ( B.1b ), equation ( B.7 ) implies that @xmath is equal
to ( B.1b ). Since the function @xmath is injective, it must be that
@xmath .

## Appendix C Invariance of Shor Relaxation Bound

It is shown here that the Shor relaxation bound obtained by relaxing
nonconvexities then converting from complex to real numbers is the same
as that obtained by converting from complex to real number then relaxing
nonconvexities.
We have val(CSDP- @xmath ) @xmath val(SDP- @xmath ) since the feasible
set is more tightly constrained due to @xmath . To prove the opposite
inequality, define @xmath for all @xmath using the block decomposition
in the left hand part of ( 7.4d ). It is proven here that if @xmath is a
feasible point of SDP- @xmath , then @xmath is a feasible point of CSDP-
@xmath with same objective value as @xmath . Firstly, @xmath satisfies (
7.4d ) because @xmath is a Hermitian matrix. Secondly, in order to show
that @xmath satisfies ( 7.4c ), notice that if @xmath then

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

Hence @xmath is equal to the sum of two positive semidefinite matrices.
Finally, to prove that @xmath satisfies ( 7.4b ) and has same objective
value as @xmath , notice that if @xmath and @xmath , then @xmath .
Completing the proof, for all @xmath , @xmath .

## Appendix D Invariance of SDP-@xmath Relaxation Bound

We consider the semidefinite problem obtained by converting from complex
to real numbers then relaxing nonconvexities. It is proven here that
setting the phase of one of the variables to zero does not affect the
relaxation bound.
We assume that @xmath is a feasible point of SDP- @xmath and construct a
feasible point of SDP- @xmath with same objective value and first
diagonal entry equal to 0. Consider the eigenvalue decomposition @xmath
for some @xmath and @xmath . For all @xmath , define

  -- -------- -- -------
     @xmath      (D.1)
  -- -------- -- -------

For @xmath , define @xmath such that @xmath . Construct @xmath whose
first diagonal entry is equal to 0. If @xmath , then @xmath .

## Appendix E Discrepancy Between Second-Order Conic Relaxation Bounds

It is shown here that the second-order conic relaxation bound obtained
by relaxing nonconvexities then converting from complex to real numbers
is different from that obtained by converting from complex to real
number then relaxing nonconvexities.
We have val(CSOCP- @xmath ) @xmath val(SOCP- @xmath ) since the feasible
set is more tightly constrained. The opposite inequality between optimal
values does not hold, and this can be proven by considering the example
QCQP- @xmath defined by @xmath . CSOCP- @xmath yields the globally
optimal value of @xmath , while SOCP- @xmath yields @xmath , as can be
seen below.

  -- -------- -- -------
     @xmath      (E.1)
  -- -------- -- -------

## Appendix F Five-Bus Illustrative Example for Exploiting Sparsity

To illustrate the selective application of second-order constraints,
consider the five-bus optimal power flow problem in [ 22 ] which is an
instance of QCQP- @xmath . Let @xmath denote the set of indices
corresponding to monomials of either the objective @xmath or constraint
functions @xmath . We have

  -- -------- -------- -------- -- -------
     @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath      (F.1)
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
     @xmath   @xmath   @xmath
  -- -------- -------- -------- -- -------

where the text in brackets indicates the origin of the constraint:
@xmath and @xmath for active and reactive power injection equality
constraints, @xmath and @xmath for lower limits on active and reactive
power injections, and @xmath and @xmath for squared voltage magnitude
limits at bus @xmath .

For brevity, the sphere constraints discussed in Section 7.3 are not
enforced in this example. Regardless, the complex hierarchy with @xmath
, @xmath converges to the global solution. The second-order constraints
are identified using the maximum power injection mismatch heuristic in [
81 ] .

The graph @xmath corresponding to ( F.1 ) is shown in Fig. F.1 . The
nodes correspond to the complex variables @xmath . Edges @xmath , which
are denoted by solid lines in Fig. F.1 , connect variables that appear
in the same monomial in any of the constraint equations or objective
function. The supergraph @xmath has edges @xmath comprised of @xmath
(solid lines in Fig. F.1 ) augmented with edges connecting all variables
within each constraint with @xmath (dashed lines in Fig. F.1 ). In this
case, @xmath is already chordal, so there is no need to form a chordal
extension @xmath .

The maximal cliques of @xmath are @xmath and @xmath . Clique @xmath is
the minimal covering clique for all second-order constraints @xmath .
The order associated with @xmath is two ( @xmath ) since the highest
order @xmath among all constraints for which @xmath is the minimal
covering clique is two. Clique @xmath is not the minimal covering clique
for any constraints with @xmath , so @xmath .

The globally optimal objective value obtained from the complex hierarchy
specified above is 946.8 with corresponding decision variable @xmath .

## Appendix G Complex Hierarchy Applied to Optimal Power Flow

We consider an example of power loss minimization. The system of Figure
G.1 links a generator to a load via a line of admittance @xmath while
respecting upper voltage constraints.

Minimizing power loss reads

  -- -------- -- -------
     @xmath      (G.1)

     @xmath      (G.2)
     @xmath      (G.3)
     @xmath      (G.4)
     @xmath      (G.5)
  -- -------- -- -------

The feasible set is included in the ball defined by @xmath . In
accordance with Section 7.3 , let’s add a slack variable @xmath and a
constraint

  -- -------- -- -------
     @xmath      (G.6)
  -- -------- -- -------

The first and second orders (i.e., @xmath - @xmath and @xmath - @xmath )
are written below where the notation @xmath is used to save space.
Example of @xmath - @xmath :

  -- -------- -- --------
     @xmath      (G.7)

     @xmath      (G.8)
     @xmath      (G.9)
     @xmath      (G.10)
     @xmath      (G.11)
     @xmath      (G.12)
     @xmath      (G.13)
     @xmath      (G.14)
  -- -------- -- --------

Example of @xmath - @xmath :

  -- -------- -- --------
     @xmath      (G.15)

     @xmath
     @xmath
     @xmath
     @xmath      (G.16)
     @xmath
     @xmath
     @xmath
     @xmath      (G.17)
     @xmath
     @xmath      (G.18)
     @xmath
     @xmath      (G.19)
     @xmath
     @xmath
     @xmath
     @xmath      (G.20)
                 (G.21)
     @xmath      (G.22)
  -- -------- -- --------
