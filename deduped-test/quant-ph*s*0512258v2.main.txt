##### Contents

-    1 Introduction
    -    1.1 Motivation
    -    1.2 Quantum key distribution: general facts
    -    1.3 Contributions
        -    1.3.1 New notions in quantum information theory
        -    1.3.2 Properties and implications of the security result
    -    1.4 Related work
    -    1.5 Outline of the thesis
    -    1.6 Outline of the security analysis of QKD
        -    1.6.1 Protocol
        -    1.6.2 Security criterion
        -    1.6.3 Security proof
-    2 Preliminaries
    -    2.1 Representation of physical systems
        -    2.1.1 Density operators, measurements, and operations
        -    2.1.2 Product systems and purifications
        -    2.1.3 Quantum and classical systems
        -    2.1.4 Distance between states
    -    2.2 Universal security of secret keys
        -    2.2.1 Standard security definitions are not universal
        -    2.2.2 A universal security definition
-    3 (Smooth) Min- and Max-Entropy
    -    3.1 Min- and max-entropy
        -    3.1.1 Definition of min- and max-entropy
        -    3.1.2 Basic properties of min- and max-entropy
        -    3.1.3 Chain rules for min-entropy
        -    3.1.4 Quantum operations can only increase min-entropy
        -    3.1.5 Min-entropy of superpositions
    -    3.2 Smooth min- and max-entropy
        -    3.2.1 Definition of smooth min- and max-entropy
        -    3.2.2 Basic properties of smooth min-entropy
        -    3.2.3 Chain rules for smooth min-entropy
        -    3.2.4 Smooth min-entropy of superpositions
        -    3.2.5 Smooth min-entropy calculus
    -    3.3 Smooth min- and max-entropy of products
        -    3.3.1 The classical case
        -    3.3.2 The quantum case
-    4 Symmetric States
    -    4.1 Definition and basic properties
        -    4.1.1 Symmetric subspace of @xmath
        -    4.1.2 Symmetric subspace along product states
    -    4.2 Symmetric purification
    -    4.3 De Finetti representation
    -    4.4 Smooth min-entropy of symmetric states
    -    4.5 Statistics of symmetric states
-    5 Privacy Amplification
    -    5.1 Bounding the norm of hermitian operators
    -    5.2 Distance from uniform
    -    5.3 Collision entropy
    -    5.4 Two-universal hashing
    -    5.5 Security of privacy amplification
    -    5.6 Characterization using smooth min-entropy
-    6 Security of QKD
    -    6.1 Preliminaries
        -    6.1.1 Two-party protocols
        -    6.1.2 Robustness of protocols
        -    6.1.3 Security definition for key distillation
    -    6.2 Parameter estimation
    -    6.3 Information reconciliation
        -    6.3.1 Definition
        -    6.3.2 Information reconciliation with minimum leakage
    -    6.4 Classical post-processing
    -    6.5 Quantum key distillation
        -    6.5.1 Description of the protocol
        -    6.5.2 Robustness
        -    6.5.3 Security
    -    6.6 Quantum key distribution
-    7 Examples
    -    7.1 Protocols based on two-level systems
        -    7.1.1 One-way protocols
        -    7.1.2 One-way protocols with noisy preprocessing
        -    7.1.3 Protocols with advantage distillation
    -    7.2 The six-state protocol
        -    7.2.1 Description
        -    7.2.2 Analysis
-    A Distance measures
    -    A.1 Fidelity
    -    A.2 @xmath -distance
-    B Various Technical Results
    -    B.1 Combinatorics
    -    B.2 Birkhoff’s Theorem
    -    B.3 Typical sequences
    -    B.4 Product spaces
    -    B.5 Nonnegative operators
    -    B.6 Properties of the function @xmath
-    C Efficient Information Reconciliation
    -    C.1 Preliminaries
    -    C.2 Information reconciliation based on codes
-    D Notation

## Chapter 1 Introduction

### 1.1 Motivation

What is needed to establish a secret key between two spatially separated
parties? Clearly, this question is of immediate interest for practical
cryptographic applications such as secure message transmission. ¹ ¹ 1
For example, using one-time pad encryption [ Ver26 ] , the problem of
secretly exchanging @xmath message bits reduces to the problem of
distributing a secret key consisting of @xmath bits. More importantly,
however, it is related to fundamental problems in (classical and
quantum) information theory. Is information physical? Is classical
information distinct from quantum information? In fact, it turns out
that the possibility of secret key agreement (over insecure channels)
strongly depends on the physical properties of information and that
there is indeed a fundamental difference between classical and quantum
information.

In this thesis, we address several basic question of quantum information
theory: What does secrecy mean in a quantum world? (Chapter 2 ) How can
knowledge and uncertainty be quantified? (Chapter 3 ) What is the role
of symmetry? (Chapter 4 ) Can any type of randomness be transformed into
uniform randomness? (Chapter 5 ) As we shall see, the answers to these
questions allow us to treat the problem of secret key agreement in a
very natural way (Chapters 6 and 7 ).

### 1.2 Quantum key distribution: general facts

##### Cryptographic setting

We consider a setting where two distant parties, traditionally called
Alice and Bob , want to establish a common secret key , i.e., a string
of random bits which is unknown to an adversary, Eve . Throughout this
thesis, we focus on information-theoretic security , which is actually
the strongest reasonable notion of security. ² ² 2 An example of a
weaker level of security is computational security , where one only
requires that it is difficult (i.e., time-consuming, but not impossible)
for an adversary to compute information on the key. It guarantees that
an adversary does not get any information correlated to the key, except
with negligible probability.

For the following, we assume that Alice and Bob already have at hand
some means to exchange classical messages in an authentic way. ³ ³ 3
Authentic means that, upon receiving a message, Bob can verify whether
the message was indeed sent by Alice, and vice-versa. In fact, only
relatively weak resources are needed to turn a completely insecure
communication channel into an authentic channel. For example, Alice and
Bob might invoke an authentication protocol (see, e.g., [ Sti91 , GN93 ]
) for which they need a short ⁴ ⁴ 4 The length of the key only grows
logarithmically in the length of the message to be authenticated.
initial key. Actually, as shown in [ RW03 , RW04 ] , it is even
sufficient for Alice and Bob to start with only weakly correlated and
partially secret information (instead of a short secret key).

##### Key agreement by quantum communication

Under the sole assumption that Alice and Bob are connected by a
classical authentic communication channel, secret communication—and thus
also the generation of a secret key—is impossible [ Sha49 , Mau93 ] .
This changes dramatically when quantum mechanics comes into the game.
Bennett and Brassard [ BB84 ] (see also [ Wie83 ] ) were the first to
propose a quantum key distribution (QKD) scheme which uses communication
over a (completely insecure) quantum channel (in addition to the
classical authentic channel). The scheme is commonly known as the BB84
protocol .

Quantum key distribution is generally based on the impossibility to
observe a quantum mechanical system without changing its state. An
adversary trying to wiretap the quantum communication between Alice and
Bob would thus inevitably leave traces which can be detected. A quantum
key distribution protocol thus achieves the following type of security:
As long as the adversary is passive, it generates an (arbitrarily long)
secret key. On the other hand, if the adversary tampers with the quantum
channel, the protocol recognizes the attack and aborts the computation
of the key. ⁵ ⁵ 5 More precisely, it is guaranteed that the protocol
does not abort as long as the adversary is passive (this is called
robustness ). Moreover, for any attack on the quantum channel, the
probability that the protocol does not abort and the adversary gets
information on the generated key is negligible (see Section 6.1.3 for
details). (Note that this is actually the best one can hope for: As the
quantum channel is completely insecure, an adversary might always
interrupt the quantum communication between Alice and Bob, in which case
it is impossible to generate a secret key.)

##### An example: the BB84 protocol

To illustrate the main principle of quantum key distribution, let us
have a closer look at the BB84 protocol . It uses an encoding of
classical bits in qubits , i.e., two-level quantum systems ⁶ ⁶ 6 For
example, the classical bits might be encoded into the spin orientation
of particles. . The encoding is with respect to one of two different
orthogonal bases, called the rectilinear and the diagonal basis . ⁷ ⁷ 7
See Section 7.2.1 for a definition. These two bases are mutually
unbiased , that is, a measurement in one of the bases reveals no
information on a bit encoded with respect to the other basis.

In the first step of the protocol, Alice chooses @xmath random bits
@xmath , encodes each of these bits into qubits using at random ⁸ ⁸ 8 In
the original proposal of the BB84 protocol, Alice and Bob choose the two
bases with equal probabilities. However, as pointed out in [ LCA05 ] ,
the efficiency of the protocol is increased if they select one of the
two bases with probability almost one. In this case, the choices of
Alice and Bob will coincide with high probability, which means that the
number of bits to be discarded in the sifting step is small. either the
rectilinear or the diagonal basis, and transmits them to Bob (using the
quantum channel). Bob measures each of the qubits he receives with
respect to—a random choice of—either the rectilinear or the diagonal
basis to obtain classical bits @xmath . The pair of classical bitstrings
@xmath and @xmath held by Alice and Bob after this step is called the
raw key pair.

The remaining part of the protocol is purely classical (in particular,
Alice and Bob only communicate classically). First, Alice and Bob apply
a sifting step, where they announce their choices of bases used for the
encoding and the measurement, respectively. They discard all bits of
their raw key for which the encoding and measurement bases are not
compatible. Then Alice and Bob proceed with a parameter estimation step.
They compare some (small) randomly chosen set of bits of their raw key
in order to get a guess for the error rate , i.e., the fraction of
positions @xmath in which @xmath and @xmath disagree. If the error rate
is too large—which might indicate the presence of an adversary—Alice and
Bob abort the protocol.

Let @xmath and @xmath be the remaining parts of the raw keys (i.e., the
bits of @xmath and @xmath that have neither been discarded in the
sifting step nor used for parameter estimation). These strings are now
used for the actual computation of the final key. In an information
reconciliation step, Alice sends certain error correcting information on
@xmath to Bob. ⁹ ⁹ 9 The information reconciliation step might also be
interactive. This, together with @xmath , allows him to compute a guess
for @xmath . (Note that, because of the parameter estimation step, it is
guaranteed that @xmath and @xmath only differ in a limited number of
positions.) In the final step of the protocol, called privacy
amplification , Alice and Bob use two-universal hashing ¹⁰ ¹⁰ 10 See
Section 5.4 for a definition of two-universality. to turn the (generally
only partially secret) string @xmath into a shorter but secure key.

The security of the BB84 protocol is based on the fact that an
adversary, ignorant of the actual encoding bases used by Alice, cannot
gain information about the encoded bits without disturbing the qubits
sent over the quantum channel. If the disturbance is too large, Alice
and Bob will observe a high error rate and abort the protocol in the
parameter estimation step. On the other hand, if the disturbance is
below a certain threshold, then the strings @xmath and @xmath held by
Alice and Bob are sufficiently correlated and secret in order to distill
a secret key.

In order to prove security, one thus needs to quantify the amount of
information that an adversary has on the raw key, given the disturbance
measured by Alice and Bob. It is a main goal of this thesis to develop
the information-theoretic techniques which are needed for this analysis.
(See also Section 1.6.3 for a sketch of the security proof.)

##### Alternative protocols

Since the invention of quantum cryptography, a considerable effort has
been taken to get a better understanding of its theoretical foundations
as well as to make it more practical. In the course of this research, a
large variety of alternative QKD protocols has been proposed. Some of
them are very efficient with respect to the secret-key rate , i.e., the
number of key bits generated per channel use [ Bru98 , BPG99 ] . Others
are designed to cope with high channel noise or noise in the detector,
which makes them more suitable for practical implementations [ SARG04 ]
.

The structure of these protocols is mostly very similar to the BB84
protocol described above. For example, the six-state protocol proposed
in [ Bru98 , BPG99 ] uses three different bases for the encoding (i.e.,
six different states), but otherwise is identical to the BB84 protocol.
On the other hand, the B92 protocol [ Ben92 ] is based on an encoding
with respect to only two non-orthogonal states.

##### QKD over noisy channels

Any realistic quantum channel is subject to intrinsic noise. Alice and
Bob will thus observe errors even if the adversary is passive. However,
as these errors are not distinguishable from errors caused by an attack,
the distribution of a secret key can only be successful if the noise
level of the channel is sufficiently low.

As an example, consider the BB84 protocol described above. In the
parameter estimation step, Alice and Bob compute a guess for the error
rate and abort the protocol if it exceeds a certain threshold. Hence,
the scheme only generates a key if the noise level of the channel is
below this threshold.

The amount of noise tolerated by a QKD scheme is an important measure
for its practicability. In fact, in an implementation, the level of
noise inevitably depends on the distance between Alice and Bob (i.e.,
the length of the optical fiber, for an implementation based on
photons). To characterize the efficiency of QKD schemes, one thus often
considers the relation between the channel noise and the secret-key rate
(see plots in Chapter 7 ). Typically, the secret-key rate decreases with
increasing noise level and becomes zero as soon as the noise reaches a
certain bound, called the maximum tolerated channel noise .

##### Quantum key distribution and distillation

Assume that Alice and Bob have access to some correlated quantum systems
(e.g., predistributed pairs of entangled particles). A quantum key
distillation protocol allows them to transform this correlation into a
common secret key, while using only classical authentic communication.

As explained below, a quantum key distribution (QKD) protocol can
generally be transformed into a key distillation protocol in such a way
that security of the latter implies security of the first. This is very
convenient for security proofs, as key distillation only involves
quantum states (instead of quantum channels) which are easier to analyze
(see [ Eke91 , BBM92 ] ).

The connection between key distillation and key distribution protocols
is based on the following observation: Let @xmath be a classical value
chosen according to a distribution @xmath and let @xmath be a quantum
encoding of @xmath . This situation could now equivalently be obtained
by the following two-step process: (i) prepare a bipartite quantum state
@xmath , where @xmath is some orthonormal basis of the first subsystem;
(ii) measure the first part of @xmath with respect to the basis @xmath .
In fact, it is easy to verify that the outcome @xmath is distributed
according to @xmath and that the remaining quantum system contains the
correct encoding of @xmath .

To illustrate how this observation applies to QKD, consider a protocol
where Alice uses the quantum channel to transmit an encoding @xmath of
some randomly chosen value @xmath to Bob (as, e.g., in the first step of
the BB84 protocol described above). According to the above discussion,
this can equivalently be achieved as follows: ¹¹ ¹¹ 11 More generally,
any arbitrary protocol step can be replaced by a coherent quantum
operation followed by some measurement. First, Alice locally prepares
the bipartite state @xmath defined above, keeps the first half of it,
and sends the second half over the quantum channel to Bob. Second, Alice
measures the quantum system she kept to get the classical value @xmath .
(Such a protocol is sometimes called an entanglement-based scheme.)

Note that, after the use of the quantum channel—but before the
measurement—Alice and Bob share some (generally entangled) quantum
state. The remaining part of the key distribution protocol is thus
actually a quantum key distillation protocol. Hence, if this key
distillation protocol is secure (for any predistributed entanglement)
then the original quantum key distribution protocol is secure (for any
arbitrary attack of Eve).

### 1.3 Contributions

This thesis makes two different types of contributions. First, we
introduce various concepts and prove results which are of general
interest in quantum information theory and cryptography. ¹² ¹² 12 For
example, our result on privacy amplification against quantum adversaries
is not only useful to prove the security of QKD. It has also found
interesting applications within other fields of cryptography, as for
instance in the context of multi-party computation (see, e.g., [ DFSS05
] for a result on bit commitment). These contributions are summarized in
Section 1.3.1 below. Second, we apply our techniques to QKD in order to
derive a general security criterion. Some aspects and implications of
this result are discussed in Section 1.3.2 .

#### 1.3.1 New notions in quantum information theory

##### Smooth min- and max-entropies as generalizations of von Neumann
entropy

The von Neumann entropy, as a measure for the uncertainty on the state
of a quantum system, plays an important role in quantum information
theory. This is mainly due to the fact that it characterizes fundamental
information-theoretic tasks such as randomness extraction or data
compression . For example, the von Neumann entropy of a source emitting
quantum states can be interpreted as the minimum space needed to encode
these states such that they can later be reconstructed with arbitrarily
small error. However, any such interpretation of the von Neumann entropy
only holds asymptotically in situations where a certain underlying
experiment is repeated many times independently. For the above example,
this means that the encoding is over many (sufficiently independent)
outputs of the source.

In the context of cryptography, where an adversary might corrupt parts
of a system in an arbitrary way, this independence can often not be
guaranteed. The von Neumann entropy is thus usually not an appropriate
measure—e.g., to quantify the uncertainty of an adversary—unless we put
some severe restrictions on her capabilities (e.g., that her attack
consists of many independent repetitions of the same action).

In this thesis, we introduce two entropy measures, called smooth min-
and max-entropy , which can be seen as generalizations of the von
Neumann entropy. While smooth min-entropy quantifies the amount of
uniform randomness that can be extracted from a quantum system, the
smooth max-entropy corresponds to the length of an optimal encoding of
the system’s state. Unlike the von Neumann entropy, however, this
characterization applies to arbitrary situations—including those for
which there is no underlying independently repeated experiment.

In the special case of many independent repetitions (that is, if the
system’s state is described by a density operator which has product
form), smooth min- and max-entropy both reduce to the von Neumann
entropy, as expected. Moreover, smooth min- and max-entropy inherit most
of the properties known from the von Neumann entropy, as for example the
strong subadditivity. (We refer to Section 1.5 for a summary of these
results.) On the other hand, because the von Neumann entropy is a
special case of smooth min- and max-entropy, its properties follow
directly from the corresponding properties of the smooth min- or
max-entropy. Interestingly, some of the proofs are surprisingly easy in
this general case. For example, the strong subadditivity of the smooth
min-entropy follows by a very short argument (cf.  Lemma 3.1.7 and Lemma
3.2.7 ). Note that this immediately gives a simple proof for the strong
subadditivity of the von Neumann entropy.

##### De Finetti representation theorem for finite symmetric quantum
states

An @xmath -partite density operator @xmath is said to be @xmath
-exchangeable , for @xmath , if it is the partial state (i.e., @xmath )
of an @xmath -partite density operator @xmath which is invariant under
permutations of the subsystems. Moreover, @xmath is
infinitely-exchangeable if it is @xmath -exchangeable for all @xmath .
The quantum de Finetti representation theorem [ HM76 ] (which is the
quantum version of a theorem in probability theory named after its
inventor Bruno de Finetti ¹³ ¹³ 13 See [ MC93 ] for a collection of de
Finetti’s original papers. ) makes a fundamental statement on such
symmetric operators. ¹⁴ ¹⁴ 14 See [ CFS02 ] for a nice proof of the
quantum de Finetti theorem based on its classical analogue. Namely, it
says that any infinitely-exchangeable operator @xmath can be written as
a convex combination (i.e., a mixture ) of product operators,

  -- -------- --
     @xmath   
  -- -------- --

We generalize the quantum de Finetti representation theorem for
infinitely exchangeable operators to the finite case. ¹⁵ ¹⁵ 15 The
result presented in this thesis is different from the one proposed in a
previous paper [ KR05 ] (see Section 1.5 for more details). More
precisely, we show that the above formula still holds approximatively if
@xmath is only @xmath -exchangeable for, some finite @xmath which is
sufficiently larger than @xmath . (We refer to Section 1.5 below for a
more detailed description of this statement.)

The de Finetti representation theorem turns out to be a useful tool in
quantum information theory. In fact, symmetric (and exchangeable) states
play an important role in many applications. For example, the operator
describing the joint state of @xmath particles selected at random from a
set of @xmath particles is @xmath -exchangeable. Hence, according to our
finite version of the de Finetti representation theorem, the analysis of
such states can be reduced to the analysis of product states—which is
often much easier than the general case. Following this idea, we will
use the finite de Finetti representation theorem to argue that, for
proving the security of a QKD scheme against arbitrary attacks, it
suffices to consider attacks that have a certain product structure
(so-called collective attacks , cf.  Section 1.3.2 ).

##### Universal security of keys in a quantum world

In quantum cryptography, the security of a secret key @xmath is
typically defined with respect to the classical information @xmath that
an adversary might obtain when measuring her quantum system @xmath .
More precisely, @xmath is said to be secure if, for any measurement of
the adversary’s system @xmath , the resulting outcome @xmath gives
virtually no information on @xmath . Although this definition looks
quite strong, we shall see that it is not sufficient for many
applications, e.g., if the key @xmath is used for one-time pad
encryption (see Section 2.2 ).

We propose a security definition which overcomes this problem. Roughly
speaking, we say that a key @xmath is @xmath -secure if, except with
probability @xmath , @xmath is equal to a perfect key which is uniformly
distributed and completely independent of the adversary’s quantum
system. In particular, our security definition is universal in the sense
that an @xmath -secure key can safely be used in any application, except
with probability @xmath . ¹⁶ ¹⁶ 16 Hence, our security definition fits
into general frameworks concerned with the universal security of quantum
protocols, as proposed by Ben-Or and Mayers [ BOM04 ] and Unruh [ Unr04
] (see Section 2.2 for more details).

##### Security of privacy amplification against quantum adversaries

Let @xmath be a classical random variable on which an adversary has some
partial information. Privacy amplification is the art of transforming
this partially secure @xmath into a fully secure key @xmath , and has
been studied extensively for the case where the adversary’s information
is purely classical. It has been shown [ BBR88 , ILL89 , BBCM95 ] that
it is always possible to generate an @xmath -bit key @xmath which is
secure against any adversary whose uncertainty on @xmath —measured in
terms of the collision entropy ¹⁷ ¹⁷ 17 The collision entropy , also
called Rényi entropy of order two , of a probability distribution @xmath
is the negative binary logarithm of its collision probability @xmath .
—is sufficiently larger than @xmath .

We generalize this classical privacy amplification theorem to include
quantum adversaries who might hold information on @xmath encoded in the
state of a quantum system. We show that, similar to the classical
result, @xmath can be transformed into a key of length @xmath which is
secure ¹⁸ ¹⁸ 18 We prove security according to the strong definition
proposed in Section 2.2 —i.e., the security is universal . if the
uncertainty of the adversary on @xmath —this time measured in terms of
the smooth min-entropy —is at least roughly @xmath . Because the smooth
min-entropy is generally larger than the collision entropy, this also
implies the above classical result.

Our privacy amplification theorem is optimal with respect to the maximum
length @xmath of the extractable secret key—i.e., smooth min-entropy
completely characterizes the number of secret key bits that can be
generated from a partially secret string (up to some small constant).
This also improves our previous results [ KMR05 , RK05 ] which are only
optimal in certain special cases. ¹⁹ ¹⁹ 19 The result proven in [ RK05 ]
is optimal if the density operator describing the initial string
together with the adversary’s quantum information has product form.

#### 1.3.2 Properties and implications of the security result

We provide a simple and general ²⁰ ²⁰ 20 The security criterion is
general in the sense that it applies to virtually all known protocols.
Note that this stands in contrast to previous security proofs, which are
mostly designed for specific protocols. criterion for the security of
QKD against any attack allowed by the laws of quantum physics. The
following is a summary of the most important properties and consequences
of this result. (For a more detailed description of the security
criterion and a proof sketch, we refer to Section 1.6 below.)

##### Coherent attacks are not stronger than collective attacks

An adversary might in principle apply an arbitrary operation on the
quantum states exchanged between Alice and Bob. In the case of the most
general, so-called coherent attacks , this operation could involve all
subsystems (particles) simultaneously, which makes it (seemingly)
difficult to analyze. One thus often considers a restricted class of
attacks, called collective attacks [ BM97b , BM97a ] , where the
adversary is assumed to apply the same transformation to each of the
subsystems that is sent over the channel. ²¹ ²¹ 21 An even more
restricted type of attacks are the so-called individual attacks where,
additionally, the adversary is supposed to apply some fixed measurement
operation to each of the subsystems sent through the channel. In
particular, this measurement cannot depend on the classical information
that Alice and Bob exchange for error correction and privacy
amplification. As shown in [ BMS96 ] , such individual attacks are
generally weaker than collective attacks. Hence, security against
individual attacks does not imply full security. A natural and
long-standing open question in this context is whether security against
collective attacks implies full security (see, e.g., [ BBB @xmath 02 ]
). Our result immediately answers this question in the positive, that
is, coherent attacks cannot be more powerful than collective attacks. ²²
²² 22 This statement holds for virtually any QKD protocol; the only
requirement is that the protocol is symmetric under permutations of the
channel uses (see Section 1.6 for more details).

##### Security of practical implementations

Because of technical limitations, practical implementations of QKD are
subject to many imperfections. In addition to noisy channels, these
might include faulty sources ²³ ²³ 23 For example, it is difficult to
design sources that emit perfect single-photon pulses. or detector
losses. Because of its generality, our security criterion can be used
for the analysis of such practical settings. ²⁴ ²⁴ 24 As there is no
restriction on the structure of the underlying Hilbert space, the
security criterion applies to any modeling of the physical system which
is used for the quantum communication between Alice and Bob.

##### Keys generated by QKD can safely be used in applications

The security result holds with respect to a so-called universal security
definition. This guarantees that the key generated by a QKD protocol can
safely be used in applications such as for one-time pad encryption. (As
mentioned above, this is not necessarily the case for many of the
standard security definitions.)

##### Improved bounds on the efficiency of concrete protocols

Our security result applies to protocols which could not be analyzed
with previously known techniques (e.g., a reduction to entanglement
purification schemes, as proposed in [ SP00 ] ). In particular, it
allows to compute the key rates for new variants of known protocols. ²⁵
²⁵ 25 E.g., we will analyze protocols that use an alternative method for
the processing of the raw key. For example, we propose an improved
version of the six-state protocol and show that it is more efficient
than previous variants. Moreover, we derive new bounds on the maximum
tolerated channel noise of the BB84 or the six-state protocol with
one-way post-processing.

##### Explicit bounds on the security of finite keys

The security criterion gives explicit (non-asymptotic) bounds on the
secrecy and the length of keys generated from any (finite) number of
invocations of the quantum channel. Moreover, it applies to schemes
which use arbitrary (not necessarily optimal) subprotocols for
information reconciliation. This is in contrast to most known security
results which—with a few exceptions ²⁶ ²⁶ 26 See, e.g., [ ILM01 ] for a
nice and very careful explicit analysis of the BB84 protocol. —only hold
asymptotically for large key sizes and for asymptotically optimal
information reconciliation.

### 1.4 Related work

The techniques developed in this thesis are partly motivated by ideas
known from classical information theory and, in particular, cryptography
(e.g., classical de Finetti-style theorems, privacy amplification
against classical adversaries, or universally composable security). For
a discussion of these notions and their relation to our results we refer
to Section 1.3 . In the following, we rather focus on work related to
the security of QKD.

Since Bennett and Brassard proposed the first QKD protocol in 1984 [
BB84 ] , it took more than a decade until Mayers [ May96 ] proved that
the scheme is secure against arbitrary attacks. ²⁷ ²⁷ 27 See also [
May01 ] for an improved version of Mayers’ proof. This result was
followed by various alternative proofs (see, e.g., [ CRE04 ] or [ LCA05
] for an overview).

One of the most popular proof techniques was proposed by Shor and
Preskill [ SP00 ] , based on ideas of Lo and Chau [ LC99 ] . It uses a
connection between key distribution and entanglement purification [ BBP
@xmath 96 ] pointed out by Ekert [ Eke91 ] (see also [ BBM92 ] ). The
proof technique of Shor and Preskill was later refined and applied to
other protocols (see, e.g., [ GL03 , TKI03 ] ).

In [ CRE04 ] , we have presented a general method for proving the
security of QKD which does not rely on entanglement purification.
Instead, it is based on a result on the security of privacy
amplification in the context of quantum adversaries [ KMR05 , RK05 ] .
Later, this method has been extended and applied to prove the security
of new variants of the BB84 and the six-state protocol [ RGK05 , KGR05 ]
. ²⁸ ²⁸ 28 In [ RGK05 , KGR05 ] we use an alternative technique
(different from the quantum de Finetti theorem) to show that collective
attacks are equivalent to coherent attacks for certain QKD protocols.
The security proof given in this thesis is based on ideas developed in
these papers.

Our new approach for proving the security of QKD has already found
various applications. For example, it is used for the analysis of
protocols based on continuous systems as well as to improve the analysis
of known (practical) protocols exploiting the fact that an adversary
cannot control the noise in the physical devices owned by Alice and Bob
(see, e.g., [ Gro05 , NA05 , Lo05 ] ).

### 1.5 Outline of the thesis

The following is a brief summary of the main results obtained in each
chapter.

##### Chapter 2: Preliminaries

The first part of this chapter (Section 2.1 ) is concerned with the
representation of physical (cryptographic) systems as mathematical
objects. We briefly review the density operator formalism which is used
to describe quantum mechanical systems. Moreover, we present some
variant of this formalism which is useful when dealing with physical
systems that consist of both classical and quantum parts.

The second part of Chapter 2 (Section 2.2 ) is devoted to the security
definition for secret keys. We first argue that many of the widely used
definitions are problematic—in the sense that they do not imply the
security of applications such as one-time pad encryption. Then, as a
solution to this problem, we introduce a so-called universal security
definition for secret keys and discuss its properties.

##### Chapter 3: Smooth min- and max-entropy

This chapter introduces and studies smooth min-entropy @xmath and smooth
max-entropy @xmath , which both are entropy measures for density
operators. We first discuss some basic properties (Sections 3.1 and 3.2
) which are actually very similar to those of the von Neumann entropy
(Theorem 3.2.12 ). For example, the smooth min-entropy is strongly
subadditive , that is, ²⁹ ²⁹ 29 We use a slightly simplified notation in
this summary. For example, we write @xmath to denote the smooth
min-entropy of a state @xmath given the second subsystem (instead of
@xmath which is used in the technical part).

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

and it obeys an inequality which can be interpreted as a chain rule ,

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

Moreover, if the states in the subsystems @xmath and @xmath are
independent conditioned on a classical value @xmath then

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

The second part of Chapter 3 (Section 3.3 ) treats the special case
where the density operators have product form. In this case, smooth min-
and max-entropy both reduce to the von Neumann entropy. Formally, the
smooth min-entropy @xmath of a product state @xmath satisfies

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

where @xmath is the (conditional) von Neumann entropy evaluated for the
operator @xmath (cf. Theorem 3.3.6 and Corollary 3.3.7 ).

##### Chapter 4: Symmetric states

This chapter is concerned with symmetric states, that is, states on
@xmath -fold product system @xmath that are invariant under permutations
of the subsystems. We first show that any permutation-invariant density
operator has a symmetric purification, which allows us to restrict our
attention to the analysis of pure symmetric states (Section 4.2 ).

The main result of this section is a finite version of the quantum de
Finetti representation theorem (Section 4.3 ). It says that symmetric
states can be approximated by a convex combination of states which have
“almost” product form (cf. Theorem 4.3.2 ). Formally, if @xmath is a
permutation-invariant operator on @xmath subsystems @xmath , then the
partial state @xmath on @xmath (obtained by tracing over @xmath
subsystems) is approximated by a mixture of operators @xmath , i.e.,

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

where the integral ranges over all density operators @xmath on one
single subsystem @xmath and @xmath is some probability measure on these
operators. Roughly speaking, the states @xmath are superpositions of
states which, on at least @xmath subsystems, for some small @xmath ,
have product form @xmath . Moreover, the distance ³⁰ ³⁰ 30 The distance
is measured with respect to the @xmath -distance, as defined in Section
2.1.4 . between the left and the right hand side of the approximation (
1.5 ) decreases exponentially fast in @xmath and @xmath . ³¹ ³¹ 31 Note
that this version of the finite quantum de Finetti representation
theorem—although the same in spirit—is distinct from the the one
proposed in [ KR05 ] : In [ KR05 ] , the decomposition is with respect
to perfect @xmath -fold product states @xmath —instead of states @xmath
which are products on only @xmath subsystems—but the approximation is
not exponential.

The properties of the states @xmath occurring in the convex
combination ( 1.5 ) are similar to those of perfect product states
@xmath . The main result of Section 4.4 can be seen as a generalization
of ( 1.4 ). It states that, for a state @xmath which has almost product
form @xmath (in the sense defined above, where @xmath is a bipartite
operator on @xmath ) the smooth min-entropy is given by

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

(see Theorem 4.4.1 ³² ³² 32 Note that Theorem 4.4.1 only implies one
direction ( @xmath ). The other direction ( @xmath ) follows from a
similar argument for the smooth max-entropy, which is an upper bound on
the smooth min-entropy. ).

Analogously, in Section 4.5 , we show that states @xmath which have
almost product form @xmath lead to similar statistics as perfect product
states @xmath if they are measured with respect to a product
measurement. Formally, let @xmath be the distribution of the outcomes
when measuring @xmath with respect to a POVM @xmath . Moreover, let
@xmath be the statistics (i.e., the frequency distribution) of the
outcomes @xmath of the product measurement @xmath applied to @xmath .
Then

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

(cf. Theorem 4.5.2 ).

##### Chapter 5: Privacy amplification

This chapter is on privacy amplification in the context of quantum
adversaries. The main result is an explicit expression for the secrecy
of a key @xmath which is computed from an only partially secure string
@xmath by two-universal hashing ³³ ³³ 33 That is, @xmath is the output
@xmath of a function @xmath which is randomly chosen from a so-called
two-universal family of hash functions (see Section 5.4 for a
definition). (Theorem 5.5.1 and Corollary 5.6.1 ). The result implies
that the key @xmath is secure under the sole condition that its length
@xmath is bounded by

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

where @xmath denotes the smooth min-entropy of @xmath given the
adversary’s initial information.

##### Chapter 6: Security of QKD

This chapter is devoted to the statement and proof of our main result on
the security of QKD. In particular, it contains an expression for the
key rate for a general class of protocols in terms of simple entropic
quantities (Theorem 6.5.1 and Corollary 6.5.2 ). (We refer to Section
1.6 for an overview on this result and its proof.)

##### Chapter 7: Examples

As an illustration, we apply the general result of Chapter 6 to specific
types of QKD protocols. The focus is on schemes which are based on
two-level systems. In particular, we analyze different versions of the
six-state QKD protocol and compute explicit values for their rates (see
Plots 7.1 – 7.5 ).

### 1.6 Outline of the security analysis of QKD

The following is a summary of our main result on the security of quantum
key distillation which—according to the discussion in Section 1.2 —also
implies the security of quantum key distribution. Moreover, we give a
sketch of the security proof, which is based on the technical results
summarized in Section 1.5 above. (For a complete description of the
security result and the full proof, we refer to Chapter 6 .)

#### 1.6.1 Protocol

We start with a brief characterization of the general type of quantum
key distillation protocols to which our security proof applies. For
this, we assume that Alice and Bob start with @xmath bipartite quantum
systems @xmath (describing, e.g., pairs of entangled particles). The
protocol then runs through the following steps in order to transform
this initial entanglement between Alice and Bob into a common secret
key.

-   Parameter estimation: Alice and Bob sacrifice some small number, say
    @xmath , subsystems @xmath in order to estimate their average
    correlation. For this, they both apply measurements with respect to
    different bases and publicly announce the outcomes (using the
    authentic classical communication channel). Depending on the
    resulting statistics, they either decide to proceed with the
    computation of the key or to abort the protocol.

-   Measurement: Alice and Bob both apply measurements to their parts of
    the remaining subsystems @xmath to obtain a pair of raw keys . (Note
    that these raw keys are generally only weakly correlated and
    partially secure.)

-   Block-wise processing: Alice and Bob might ³⁴ ³⁴ 34 In many
    protocols, this step is omitted, i.e., Alice and Bob directly
    proceed with information reconciliation. further process their raw
    key pair in order to improve its correlation or secrecy. We assume
    that this processing acts on @xmath blocks of size @xmath
    individually. For example, Alice and Bob might invoke a so-called
    advantage distillation protocol (see Section 7.1.3 ) whose purpose
    is to single out blocks of the raw key that are highly correlated.
    We denote by @xmath and @xmath the strings held by Alice and Bob
    after this step.

-   Information reconciliation: The purpose of this step is to transform
    the (possibly only weakly correlated) pair of strings @xmath and
    @xmath into a pair of identical strings. Typically, Alice sends
    certain error correcting information on @xmath to Bob which allows
    him to compute a guess @xmath of @xmath .

-   Privacy amplification: Alice and Bob use two-universal hashing to
    transform their strings @xmath and @xmath into secret keys of length
    @xmath .

Additionally, we assume that the action of the protocol is invariant
under permutations of the @xmath input systems. This does not restrict
the generality of our results, because any protocol can easily be turned
into a permutation-invariant one: Before starting with the parameter
estimation, Alice and Bob simply have to (publicly) agree on a random
permutation which they use to reorder their subsystems (see Section
1.6.3 below for more details).

#### 1.6.2 Security criterion

The security of a key distillation scheme depends on the actual choice
of various protocol parameters which we define in the following:

-   @xmath is the set of states on single subsystems which are not
    filtered by the parameter estimation subprotocol: More precisely,
    @xmath contains all density operators @xmath such that, when
    starting with the product state @xmath , the protocol does not
    abort.

-   @xmath is the CPM ³⁵ ³⁵ 35 See Section 2.1.1 for a definition of
    completely positive maps (CPM). on @xmath subsystems which describes
    the measurement together with the block-wise processing on blocks of
    size @xmath .

-   @xmath is the number of blocks of size @xmath that are used for the
    actual computation of the key (i.e., the number of blocks of
    subsystems that are left after the parameter estimation step).

-   @xmath denotes the length of the final key generated in the privacy
    amplification step.

In addition, the security of the scheme depends on the efficiency of the
information reconciliation subprotocol, i.e., the amount of information
that is leaked to Eve. However, for this summary, we assume that Alice
and Bob use an optimal ³⁶ ³⁶ 36 In Section 6.3 , we show that optimal
information reconciliation protocols exist. information reconciliation
protocol. In this case, the leakage is roughly equal to the entropy of
@xmath given @xmath . ³⁷ ³⁷ 37 We refer to Chapter 6 for the general
result which deals with arbitrary—not necessarily optimal—information
reconciliation schemes.

We are now ready to formulate a general security criterion for quantum
key distillation (cf. Theorem 6.5.1 ): The scheme described above is
secure (for any initial state) if ³⁸ ³⁸ 38 The approximation @xmath in (
1.9 ) indicates that the criterion holds asymptotically for increasing
@xmath . We refer to Chapter 6 for a non-asymptotic result.

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

where the minimum ranges over all states @xmath contained in the set
@xmath defined above and where @xmath and @xmath are the (conditional)
von Neumann entropies of

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a purification of @xmath . Note that, because the
operators @xmath are on single subsystems, formula ( 1.9 ) is usually
fairly easy to evaluate for concrete protocols (cf. Chapter 7 ).

Typically, the number @xmath of subsystem that are sacrificed for
parameter estimation is small compared to the total number @xmath of
initial subsystems. Hence, the number @xmath of blocks of size @xmath
that can be used for the actual computation of the key is roughly given
by @xmath . ³⁹ ³⁹ 39 This is also true for QKD protocols with a sifting
step (where Alice and Bob discard the subsystems for which they have
used incompatible encoding and decoding bases). In fact, as mentioned in
Section 1.2 , if Alice and Bob choose one of the bases with probability
close to one, the fraction of positions lost in the sifting step is
small. The criterion ( 1.9 ) can thus be turned into an expression for
the key rate of the protocol (i.e., the number of key bits generated per
channel use):

  -- -------- --
     @xmath   
  -- -------- --

#### 1.6.3 Security proof

We need to show that, for any initial state shared by Alice and Bob, the
probability that the protocol generates an insecure key is negligible.
⁴⁰ ⁴⁰ 40 Note that the protocol might abort if the initial state held by
Alice and Bob is not sufficiently correlated. Roughly speaking, the
proof consists of two parts. In the first (Steps 1--2) we argue that we
can restrict our analysis to a much smaller set of initial states,
namely those that have (almost) product form. In the second part (Steps
3–5) we show that for each such state either of the following holds:
(i) there is not sufficient correlation between Alice and Bob in which
case the protocol aborts during the parameter estimation or (ii) a
measurement applied to the state generates an outcome with sufficient
entropy such that the key computed from it is secure.

##### Step 1: Restriction to permutation-invariant initial states

As we assumed that the protocol is invariant under permutations of the
input systems, we can equivalently think of a protocol which starts with
the following symmetrization step: Alice chooses a permutation @xmath at
random and announces it to Bob, using the (insecure) classical
communication channel. Then Alice and Bob both permute the order of
their @xmath subsystems according to @xmath . Obviously, the state
@xmath of Alice and Bob’s system after this symmetrization step
(averaged over all choices of @xmath ) is invariant under permutations.

Because the state @xmath is invariant under permutations, it has a
purification @xmath (with an auxiliary system @xmath ) which is
symmetric as well (cf.  Lemma 4.2.2 ). As the pure state @xmath cannot
be correlated with anything else (cf. Section 2.1.2 ) we can assume
without loss of generality that the knowledge of a potential adversary
is fully described by the auxiliary system.

##### Step 2: Restriction to (almost) product states

Because @xmath is invariant under permutations, it is, according to our
finite version of the de Finetti representation theorem approximated by
a mixture of states which have “almost” product form @xmath —in the
sense described by formula ( 1.5 ).

##### Step 3: Smooth min-entropy of Alice and Bob’s raw keys

Assume for the moment that the joint initial state @xmath held by Alice,
Bob, and Eve has perfect product form @xmath . As Alice and Bob’s
measurement operation (including the block-wise processing) @xmath acts
on @xmath blocks of size @xmath individually, the density operator
@xmath which describes the situation before the information
reconciliation step is given by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath is Alice and Bob’s raw key, respectively.
Consequently, @xmath is the product of operators of the form

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

By ( 1.4 ), the smooth min-entropy of @xmath is approximated in terms of
the von Neumann entropy of @xmath , i.e.,

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

Using ( 1.6 ), this argument can easily be generalized to states @xmath
which have almost product form.

##### Step 4: Smooth min-entropy after information reconciliation

In the information reconciliation step, Alice sends error correcting
information @xmath about @xmath to Bob, using the authentic classical
communication channel. Eve might wiretap this communication which
generally decreases the smooth min-entropy of @xmath from her point of
view.

As mentioned above, we assume for this summary that the information
reconciliation subprotocol is optimal with respect to the amount of
information leaked to Eve. It follows from classical coding theory that
the number of bits that Alice has to send to Bob in order to allow him
to compute her value @xmath is given by the Shannon entropy of @xmath
conditioned on Bob’s knowledge @xmath . Formally, if @xmath has product
form @xmath then the communication @xmath satisfies

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

where @xmath is the Shannon entropy of @xmath given @xmath , evaluated
for the probability distribution defined by @xmath . (Note that the
entropy difference on the left hand side can be interpreted as a measure
for the information that @xmath gives on @xmath .)

Let us now compute a lower bound on the smooth min-entropy of @xmath
given Eve’s knowledge after the information reconciliation step. By the
chain rule ( 1.2 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Moreover, because @xmath is computed from @xmath , we can apply
inequality ( 1.3 ), i.e.,

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 1.12 ) gives

  -- -------- --
     @xmath   
  -- -------- --

Finally, using the approximation ( 1.11 ) for @xmath , we conclude

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

##### Step 5: Security of the key generated by privacy amplification

To argue that the key generated in the final privacy amplification step
is secure, we apply criterion ( 1.8 ). Because the adversary has access
to both the quantum system and the classical communication @xmath , this
security criterion reads

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

where @xmath is the length of the key.

As shown in Step 2, the state @xmath has almost product form @xmath .
Hence, according to ( 1.7 ), the statistics obtained by Alice and Bob in
the parameter estimation step corresponds to the statistics that they
would obtain if they started with a perfect product state @xmath . We
conclude that, by the definition of the set @xmath , the protocol aborts
whenever @xmath .

To bound the smooth min-entropy of the string held by Alice before
privacy amplification, it thus suffices to evaluate ( 1.13 ) for all
states @xmath contained in @xmath . Formally,

  -- -------- --
     @xmath   
  -- -------- --

where the minimum is over all (pure) states @xmath such that @xmath and
where @xmath and @xmath are the entropies of the state @xmath given by (
1.10 ). Combining this with criterion ( 1.14 ) concludes the proof.

## Chapter 2 Preliminaries

### 2.1 Representation of physical systems

#### 2.1.1 Density operators, measurements, and operations

Quantum mechanics, like any other physical theory, allows us to make
certain predictions about the behavior of physical systems. These are,
however, not deterministic—a system’s initial state merely determines a
probability distribution over all possible outcomes of an observation. ¹
¹ 1 With his famous statement “Gott würfelt nicht,” Einstein expressed
his doubts about the completeness of such a non-deterministic theory.

Mathematically, the state of a quantum mechanical system with @xmath
degrees of freedom is represented by a normalized nonnegative ² ² 2 An
operator @xmath on @xmath is nonnegative if it is hermitian and has
nonnegative eigenvalues. operator @xmath , called density operator , on
a @xmath -dimensional Hilbert space @xmath . The normalization is with
respect to the trace norm, i.e., @xmath . In the following, we denote by
@xmath the set of nonnegative operators on @xmath , i.e., @xmath is a
density operator on @xmath if and only if @xmath and @xmath .

Any observation of a quantum system corresponds to a measurement and is
represented mathematically as a positive operator valued measure (POVM)
, i.e., a family @xmath of nonnegative operators such that @xmath . The
theory of quantum mechanics postulates that the probability distribution
@xmath of the outcomes when measuring a system in state @xmath with
respect to @xmath is given by @xmath .

Consider a physical system whose state @xmath depends on the value
@xmath of a classical random variable @xmath with distribution @xmath .
For an observer which is ignorant of the value of @xmath , the state
@xmath of the system is given by the convex combination ³ ³ 3 Because a
measurement is a linear mapping from the set of density operators to the
set of probability distributions, this is consistent with the above
description. In particular, the distribution of the outcomes resulting
from a measurement of @xmath is the convex combination of the
distributions obtained from measurements of @xmath .

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

The decomposition ( 2.1 ) of a density operator @xmath is generally not
unique. Consider for example the fully mixed state defined by @xmath .
In the case of a two-level system, @xmath might represent a photon which
is polarized horizontally or vertically with equal probabilities; but
the same operator @xmath might also represent a photon which is
polarized according to one of the two diagonal directions with equal
probabilities. In fact, the two settings cannot be distinguished by any
measurement.

A physical process is most generally described by a linear mapping
@xmath , called a quantum operation , which takes the system’s initial
state @xmath to its final state @xmath . ⁴ ⁴ 4 A measurement can be seen
as a special case of a quantum operation where the outcome is classical
(see Section 2.1.3 ). Mathematically, a quantum operation @xmath is a
completely positive map (CPM) ⁵ ⁵ 5 Complete positivity means that any
extension @xmath of the map @xmath , where @xmath is the identity map on
the set of hermitian operators on some auxiliary Hilbert space @xmath ,
maps nonnegative operators to nonnegative operators. Formally, @xmath
for any @xmath . from the set of hermitian operators on a Hilbert space
@xmath to the set of hermitian operators on another Hilbert space @xmath
. Additionally, in order to ensure that the image @xmath of a density
operator @xmath is again a density operator, @xmath must be
trace-preserving , i.e., @xmath , for any @xmath . It can be shown that
any CPM @xmath can be written as

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where @xmath is a family of linear operators from @xmath to @xmath . On
the other hand, any mapping of the form ( 2.2 ) is a CPM. ⁶ ⁶ 6 This is
in fact a direct consequence of Lemma B.5.1 . Moreover, it is
trace-preserving if and only if @xmath .

As we have seen, the state of a quantum system might depend on some
classical event @xmath (e.g., that @xmath takes a certain value @xmath
). In this context, it is often convenient to represent both the
probability @xmath of @xmath and the state @xmath of the system
conditioned on @xmath as one single mathematical object, namely the
nonnegative operator @xmath . ⁷ ⁷ 7 The probability of the event @xmath
is then equal to the trace of @xmath , i.e., @xmath , and the system’s
state conditioned on @xmath is @xmath . For this reason, we formulate
most statements on quantum states in terms of general (not necessarily
normalized) nonnegative operators. Similarly, we often consider general
(not necessarily trace-preserving) CPMs @xmath . The quantity @xmath can
then be interpreted as the probability that the process represented by
@xmath occurs when starting with a system in state @xmath .

#### 2.1.2 Product systems and purifications

To analyze complex physical systems, it is often convenient to consider
a partitioning into a number of subsystems. This is particularly useful
if one is interested in the study of operations that act on the parts of
the system individually. ⁸ ⁸ 8 This is typically the case in the context
of cryptography, where various parties control separated subsystems.
Mathematically, the partition of a quantum system into subsystems
induces a product structure on the underlying Hilbert space. For
example, the state of a bipartite system is represented as a density
operator @xmath on a product space @xmath . The state of one part of a
product system is then obtained by taking the corresponding partial
trace of the overall state, e.g., @xmath for the first part of a
bipartite system.

A density operator @xmath on @xmath is said to be pure if it has rank ⁹
⁹ 9 The rank of a hermitian operator @xmath , denoted @xmath , is the
dimension of the support @xmath , i.e., the space spanned by the
eigenvectors of @xmath with nonzero eigenvalues. one, that is, @xmath ,
for some @xmath . If it is normalized, @xmath is a projector ¹⁰ ¹⁰ 10 A
hermitian operator @xmath is said to be a projector if @xmath . onto
@xmath . A pure density operator can only be decomposed trivially, i.e.,
for any decomposition of the form ( 2.2 ), @xmath holds for all @xmath .
According to the above interpretation, one could say that a pure state
contains no classical randomness, that is, it cannot be correlated with
any other system.

The fact that a pure state cannot be correlated with the environment
plays a crucial role in cryptography. It implies, for example, that the
randomness obtained from the measurement of a pure state is independent
of any other system and thus guaranteed to be secret. More generally,
let @xmath be an arbitrary operator on @xmath and let @xmath be a
purification of @xmath , i.e., @xmath is a pure state on a product
system @xmath such that @xmath . Then, because @xmath is uncorrelated
with any other system, the partial system @xmath comprises everything
that might possibly be correlated with the system @xmath (including the
knowledge of a potential adversary).

#### 2.1.3 Quantum and classical systems

Consider a classical random variable @xmath with distribution @xmath on
some set @xmath . In a quantum world, it is useful to view @xmath as a
special case of a quantum system. For this, one might think of the
classical values @xmath as being represented by orthogonal ¹¹ ¹¹ 11 The
orthogonality of the states @xmath guarantees that they can be
distinguished perfectly, as this is the case for classical values.
states @xmath on some Hilbert space @xmath . The state @xmath of the
quantum system is then defined by

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

We say that @xmath is the operator representation of the classical
distribution @xmath (with respect to the basis @xmath ) . ¹² ¹² 12 This
definition can easily be generalized to multi-partite nonnegative (not
necessarily normalized) functions (e.g., @xmath , where @xmath denotes
the set of nonnegative functions on @xmath ) in which case one gets
nonnegative operators on product systems (e.g., @xmath ).

On the other hand, any operator @xmath can be written in the form ( 2.3
) where @xmath are the eigenvalues of @xmath and @xmath are the
corresponding eigenvectors . The right hand side of ( 2.3 ) is called
the spectral decomposition of @xmath . Moreover, we say that @xmath is
the probability distribution defined by @xmath .

This notion can be extended to hybrid settings where the state @xmath of
a quantum system @xmath depends on the value @xmath of a classical
random variable @xmath (see, e.g., [ DW05 ] ). The joint state of the
system is then given by

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where @xmath .

We can also go in the other direction: If a density operator has the
form ( 2.4 ), for some basis @xmath , then the first subsystem can be
interpreted as the representation of a classical random variable @xmath
. This motivates the following definition: An operator @xmath is said to
be classical with respect to @xmath if there exists a family @xmath of
operators on @xmath , called (non-normalized) conditional operators ,
such that @xmath can be written in the form ( 2.4 ). Moreover, we say
that @xmath is classical on @xmath if there exists a basis @xmath of
@xmath such that @xmath is classical with respect to @xmath . ¹³ ¹³ 13
The operators @xmath , for @xmath , are uniquely defined by @xmath and
the basis @xmath . Moreover, because @xmath is nonnegative, the
operators @xmath , for @xmath , are also nonnegative.

A similar definition can be used to characterize quantum operations
(i.e., CPMs) whose outcomes are partly classical: A CPM @xmath from
@xmath to @xmath is said to be classical with respect to @xmath (or
simply classical on @xmath ) if it can be written as

  -- -------- --
     @xmath   
  -- -------- --

where, for any @xmath , @xmath is a CPM from @xmath to @xmath . Note
that a measurement on @xmath with outcomes in @xmath can be seen as a
CPM from @xmath to @xmath which is classical on @xmath .

#### 2.1.4 Distance between states

Intuitively, we say that two states of a physical system are similar if
any observation of them leads to identical results, except with small
probability. For two operators @xmath representing the state of a
quantum system, this notion of similarity is captured by the @xmath
-distance , i.e., the trace norm ¹⁴ ¹⁴ 14 The trace norm @xmath of a
hermitian operator @xmath on @xmath is defined by @xmath . @xmath of the
difference between @xmath and @xmath . ¹⁵ ¹⁵ 15 The @xmath -distance
between two operators is closely related to the trace distance , which
is usually defined with an additional factor @xmath . The @xmath
-distance for operators can be seen as the quantum version of the @xmath
-distance for probability distributions ¹⁶ ¹⁶ 16 The @xmath -distance
between classical probability distributions is also known as variational
distance or statistical distance (which are often defined with an
additional factor @xmath ). (or, more generally, nonnegative functions),
which is defined by @xmath , for @xmath . In particular, if @xmath and
@xmath are operator representations of probability distributions @xmath
and @xmath , respectively, then the @xmath -distance between @xmath and
@xmath is equal to the @xmath -distance between @xmath and @xmath .

Under the action of a quantum operation, the @xmath -distance between
two density operators @xmath and @xmath cannot increase (cf. Lemma A.2.1
). Because any measurement can be seen as a quantum operation, this
immediately implies that the distance @xmath between the distributions
@xmath and @xmath obtained from (identical) measurements of two density
operators @xmath and @xmath , respectively, is bounded by @xmath .

The following proposition provides a very simple interpretation of the
@xmath -distance: If two probability distributions @xmath and @xmath
have @xmath -distance at most @xmath , then the two settings described
by @xmath and @xmath , respectively, cannot differ with probability more
than @xmath .

###### Proposition 2.1.1.

Let @xmath be probability distributions. Then there exists a joint
distribution @xmath such that @xmath and @xmath are the marginals of
@xmath (i.e., @xmath , @xmath ) and, for @xmath chosen according to
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

In particular, if the @xmath -distance between two states is bounded by
@xmath , then they cannot be distinguished with probability more than
@xmath .

### 2.2 Universal security of secret keys

Cryptographic primitives (e.g., a secret key or an authentic
communication channel) are often used as components within a more
complex system. It is thus natural to require that the security of a
cryptographic scheme is not compromised when it is employed as part of
another system. This requirement is captured by the notion of universal
security . Roughly speaking, we say that a cryptographic primitive is
universally secure if it is secure in any arbitrary context. For
example, the universal security of a secret key @xmath implies that any
bit of @xmath remains secret even if some other part of @xmath is given
to an adversary.

In the past few years, universal security has attracted a lot of
interest and led to important new definitions and proofs (see, e.g., the
so-called universal composability framework of Canetti [ Can01 ] or
Pfitzmann and Waidner [ PW00 ] ). Recently, Ben-Or and Mayers [ BOM04 ]
and Unruh [ Unr04 ] have generalized Canetti’s notion of universal
composability to the quantum world.

Universal security definitions are usually based on the idea of
characterizing the security of a real cryptographic scheme by its
distance to an ideal system which (by definition) is perfectly secure.
For instance, a secret key @xmath is said to be secure if it is close to
a perfect key @xmath , i.e., a uniformly distributed string which is
independent of the adversary’s information. As we shall see, such a
definition immediately implies that any cryptosystem which is proven
secure when using a perfect key @xmath remains secure when @xmath is
replaced by the (real) key @xmath .

#### 2.2.1 Standard security definitions are not universal

Unfortunately, many security definitions that are commonly used in
quantum cryptography are not universal. For instance, the security of
the key @xmath generated by a QKD scheme is typically defined in terms
of the mutual information @xmath between @xmath and the classical
outcome @xmath of a measurement of the adversary’s system (see, e.g., [
LC99 , SP00 , NC00 , GL03 , LCA05 ] and also the discussion in [ BOHL
@xmath 05 ] and [ RK05 ] ). Formally, @xmath is said to be secure if,
for some small @xmath ,

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

where the maximum ranges over all measurements on the adversary’s system
with output @xmath . Such a definition—although it looks
reasonable—does, however, not guarantee that the key @xmath can safely
be used in applications. Roughly speaking, the reason for this flaw is
that criterion ( 2.5 ) does not account for the fact that an adversary
might wait with the measurement of her system until she learns parts of
the key. (We also refer to [ RK05 ] and [ BOHL @xmath 05 ] for a more
detailed discussion and an analysis of existing security definitions
with respect to this concern. ¹⁷ ¹⁷ 17 Note that the conclusions in [
BOHL @xmath 05 ] are somewhat different to ours: It is shown that
existing privacy conditions of the form ( 2.5 ) do imply universal
security, which seems to contradict the counterexample sketched below.
However, the result of [ BOHL @xmath 05 ] only holds if the parameter
@xmath in ( 2.5 ) is exponentially small in the key size, which is not
the case for most of the existing protocols. (In fact, the security
parameter @xmath can only be made exponentially small at the expense of
decreasing the key rate substantially.) )

Let us illustrate this potential problem with a concrete example: Assume
that we would like to use an @xmath -bit key @xmath as a one-time pad to
encrypt an @xmath -bit message @xmath . ¹⁸ ¹⁸ 18 That is, the ciphertext
@xmath is the bit-wise XOR of @xmath and @xmath , i.e., @xmath .
Furthermore, assume that an adversary is interested in the @xmath th bit
@xmath of the message, but already knows the first @xmath bits @xmath .
Upon observing the ciphertext, the adversary can easily determine ¹⁹ ¹⁹
19 Note that @xmath . the first @xmath bits of @xmath . Hence, in order
to guarantee the secrecy of the @xmath th message bit @xmath , we need
to ensure that the adversary still has no information on the @xmath th
key bit @xmath , even though she already knows all previous key bits
@xmath . This requirement, however, is not implied by the above
definition. Indeed, for any arbitrary @xmath and @xmath depending on
@xmath , it is relatively easy to construct examples which satisfy ( 2.5
) whereas an adversary—once she knows the first @xmath bits of the
key—can determine the @xmath th bit @xmath with certainty. For an
explicit construction and analysis of such examples, we refer to [ Bar05
] . ²⁰ ²⁰ 20 This phenomenon has also been studied in other contexts
(see, e.g., [ DHL @xmath 04 , HLSW04 ] ) where it is called as locking
of classical correlation .

#### 2.2.2 A universal security definition

Consider a key @xmath distributed according to @xmath and let @xmath be
the state of the adversary’s system given that @xmath takes the value
@xmath , for any element @xmath of the key space @xmath . According to
the discussion in Section 2.1.3 , the joint state of the classical key
@xmath and the adversary’s quantum system can be represented by the
density operator

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an orthonormal basis of some Hilbert space @xmath . We
say that @xmath is @xmath -secure with respect to @xmath if

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

where @xmath is the fully mixed state on @xmath .

The universal security of a key @xmath satisfying this definition
follows from a simple argument: Criterion ( 2.6 ) guarantees that the
real situation described by @xmath is @xmath -close—with respect to the
@xmath -distance—to an ideal situation where @xmath is replaced by a
perfect key @xmath which is uniformly distributed and independent of the
state of the system @xmath . Moreover, since the @xmath -distance cannot
increase when applying a quantum operation (cf. Lemma A.2.1 ), this also
holds for any further evolution of the world (where, e.g., the key is
used as part of a larger cryptographic system). In fact, it follows from
the discussion in Section 2.1.4 that an @xmath -secure key can be
considered identical to an ideal (perfect) key—except with probability
@xmath . ²¹ ²¹ 21 For this statement to hold, it is crucial that the
criterion ( 2.6 ) is formulated in terms of the @xmath -distance
(instead of other distance measures such as the fidelity). In
particular, an @xmath -secure key is secure within any reasonable
framework providing universal composability (e.g., [ BOM04 ] or [ Unr04
] ). ²² ²² 22 These frameworks are usually based on the so-called
simulatability paradigm . That is, a real cryptosystem is said to be as
secure as an ideal cryptosystem if any attack to the real scheme can be
simulated by an attack to the ideal scheme (see also [ MRH04 ] ). It is
easy to see that our security criterion is compatible with this
paradigm: Consider a (real) key agreement protocol and assume that, for
any possible attack of the adversary, the final key satisfies ( 2.6 ).
The adversary’s quantum state after the attack is then almost
independent of the key, that is, the adversary could simulate virtually
all her information without even interacting with the cryptosystem. The
real key agreement protocol is thus as secure as an ideal key agreement
scheme which, by definition, does not leak any information at all.

The security of a key according to ( 2.6 ) also implies security with
respect to most of the standard security definitions in quantum
cryptography. For example, if @xmath is @xmath -secure with respect to
@xmath then the mutual information between @xmath and the outcome of any
measurement applied to the adversary’s system is small (whereas the
converse is often not true, as discussed above). In particular, if the
adversary is purely classical, ( 2.6 ) reduces to a classical security
definition which has been proposed in the context of
information-theoretically secure key agreement (see, e,g., [ DM04 ] ).

## Chapter 3 (Smooth) Min- and Max-Entropy

Entropy measures are indispensable tools in classical and quantum
information theory. They quantify randomness , that is, the uncertainty
that an observer has on the state of a (quantum) physical system. In
this chapter, we introduce two entropic quantities, called
smooth min-entropy and smooth max-entropy . As we shall see, these are
useful to characterize randomness with respect to fundamental
information-theoretic tasks such as the extraction of uniform randomness
or data compression. ¹ ¹ 1 Randomness extraction is actually privacy
amplification and is the topic of Chapter 5 . Data compression is
closely related to information reconciliation which is treated in
Section 6.3 . Moreover, smooth min- and max-entropies have natural
properties which are similar to those known from the von Neumann entropy
and its classical special case, the Shannon entropy ² ² 2 The Shannon
entropy of a probability distribution @xmath is defined by @xmath ,
where @xmath denotes the binary logarithm. Similarly, the von Neumann
entropy of a density operator @xmath is @xmath . (Sections 3.1 and 3.2
). In fact, for product states, smooth min- and max-entropy are
asymptotically equal to the von Neumann entropy (Section 3.3 ).

Smooth min- and max-entropies are actually families of entropy measures
parameterized by some nonnegative real number @xmath , called smoothness
. In applications, the smoothness is related to the error probability of
certain information-theoretic tasks and is thus typically chosen to be
small. We first consider the “non-smooth” special case where @xmath
(Section 3.1 ). This is the basis for the general definition where the
smoothness @xmath is arbitrary (Section 3.2 ).

We will introduce a conditional version of smooth min- and max-entropy.
It is defined for bipartite operators @xmath on @xmath and measures the
uncertainty on the state of the subsystem @xmath given access to the
subsystem @xmath . Unlike the conditional von Neumann entropy @xmath ,
however, it cannot be written as a difference between two
“unconditional” entropy measures.

To illustrate our definition of (conditional) min- and max-entropy, let
us, as an analogy, consider an alternative formulation of the
conditional von Neumann entropy @xmath . Let

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

for some state @xmath on @xmath . This quantity can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the relative entropy ³ ³ 3 The relative entropy @xmath
is defined by @xmath . of @xmath to @xmath . Because @xmath cannot be
negative, this expression takes its maximum for @xmath , in which case
it is equal to @xmath . We thus have

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

where the supremum ranges over all density operators @xmath on @xmath .

The definitions of (smooth) min- and max-entropies are inspired by this
approach. We first introduce a quantity which corresponds to ( 3.1 )
(cf. Definitions 3.1.1 and 3.2.1 ) and then define our entropy measures
by a formula of the form ( 3.2 ) (Definitions 3.1.2 and 3.2.2 ).

### 3.1 Min- and max-entropy

This section introduce a “non-smooth” version of min- and max-entropy.
It is the basis for the considerations in Section 3.2 , where these
entropy measures are generalized. The focus is on min-entropy, which is
used extensively in the remaining part of the thesis. However, most of
the properties derived in the following also hold for max-entropy.

#### 3.1.1 Definition of min- and max-entropy

###### Definition 3.1.1.

Let @xmath and @xmath . The min-entropy of @xmath relative to @xmath is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the minimum real number such that @xmath is nonnegative.
The max-entropy of @xmath relative to @xmath is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the projector onto the support of @xmath .

###### Definition 3.1.2.

Let @xmath . The min-entropy and the max-entropy of @xmath given @xmath
are

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

respectively, where the supremum ranges over all @xmath with @xmath .

###### Remark 3.1.3.

It follows from Lemma B.5.3 that the min-entropy of @xmath relative to
@xmath , for @xmath invertible, can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the maximum eigenvalue of the argument.

If @xmath is the trivial space @xmath , we simply write @xmath and
@xmath to denote the min- and the max-entropy of @xmath , respectively.
In particular,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

##### The classical analogue

The above definitions can be specialized canonically to classical
probability distributions. ⁴ ⁴ 4 Similarly, the Shannon entropy can be
seen as the classical special case of the von Neumann entropy. More
precisely, for @xmath and @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath and @xmath are the operator representations of @xmath and
@xmath , respectively (cf. Section 2.1.3 ).

###### Remark 3.1.4.

Let @xmath and @xmath . Then ⁵ ⁵ 5 The support of a nonnegative function
@xmath , denoted @xmath , is the set of values @xmath such that @xmath .

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath denotes the function @xmath . In particular,

  -- -------- --
     @xmath   
  -- -------- --

#### 3.1.2 Basic properties of min- and max-entropy

##### Min-entropy cannot be larger than max-entropy

The following lemma gives a relation between min- and max-entropy. It
implies that, for a density operator @xmath , the min-entropy cannot be
larger than the max-entropy.

###### Lemma 3.1.5.

Let @xmath and @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be the projector onto the support of @xmath and let @xmath
such that @xmath , i.e., @xmath is nonnegative. Using the fact that the
trace of the product of two nonnegative operators is nonnegative (Lemma
B.5.2 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Hence,

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows by the definition of the max-entropy and the
choice of @xmath . ∎

##### Additivity of min- and max-entropy

The von Neumann entropy of a state which consists of two independent
parts is equal to the sum of the entropies of each part, i.e., @xmath .
This also holds for min- and max-entropy.

###### Lemma 3.1.6.

Let @xmath , @xmath and, similarly, @xmath , @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### Proof.

The statement follows immediately from Definition 3.1.1 . ∎

##### Strong subadditivity

The von Neumann entropy is subadditive, i.e., @xmath , which means that
the entropy cannot increase when conditioning on an additional
subsystem. This property can be generalized to min- and max-entropy.

###### Lemma 3.1.7.

Let @xmath and @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Note that, for min-entropy, the statement follows directly from the more
general fact that the entropy cannot decrease under certain quantum
operations (cf. Lemma 3.1.12 ).

###### Proof.

Let @xmath such that @xmath , i.e., @xmath is nonnegative. Because the
operator obtained by taking the partial trace of a nonnegative operator
is nonnegative, @xmath is also nonnegative. This immediately implies
@xmath and thus concludes the proof of the statement for min-entropy.

To show that the assertion also holds for max-entropy, let @xmath and
@xmath be the projectors on the support of @xmath and @xmath ,
respectively. Because the support of @xmath is contained in the tensor
product of the support of @xmath and @xmath (cf. Lemma B.4.1 ), the
operator @xmath is nonnegative. Moreover, because the trace of the
product of two nonnegative operators is nonnegative (cf. Lemma B.5.2 ),
we find

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows by the definition of the max-entropy. ∎

Note that the strong subadditivity of the max-entropy together with
Lemma 3.1.5 implies that @xmath , for density operators @xmath and
@xmath .

##### Conditioning on classical information

The min- and max-entropies of states which are partially classical can
be expressed in terms of the min- and max-entropies of the corresponding
conditional operators (see Section 2.1.3 ).

###### Lemma 3.1.8.

Let @xmath and @xmath be classical with respect to an orthonormal basis
@xmath of @xmath , and let @xmath and @xmath be the corresponding
(non-normalized) conditional operators. Then

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### Proof.

Because the vectors @xmath are mutually orthogonal, the equivalence

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

holds for any @xmath . The assertion for the min-entropy then follows
from the fact that the negative logarithm of the minimum @xmath
satisfying the left hand side and the right hand side of ( 3.3 ) are
equal to the quantities @xmath and @xmath , respectively.

To prove the statement for the max-entropy, let @xmath and @xmath , for
@xmath , be projectors onto the support of @xmath and @xmath ,
respectively. Because the vectors @xmath are mutually orthogonal, we
have

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows by the definition of the max-entropy. ∎

##### Classical subsystems have nonnegative min-entropy

Similarly to the conditional von Neumann entropy, the min- and
max-entropies of entangled systems can generally be negative. This is,
however, not the case for the entropy of a classical subsystem. Lemma
3.1.9 below implies that

  -- -------- --
     @xmath   
  -- -------- --

for any density operator @xmath which is classical on the first
subsystem ⁶ ⁶ 6 To see this, let @xmath be the trivial space @xmath and
set @xmath . . By Lemma 3.1.5 , the same holds for max-entropy.

###### Lemma 3.1.9.

Let @xmath be classical on @xmath and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath such that @xmath . Because @xmath is classical on @xmath ,
there exists an orthonormal basis @xmath and a family @xmath of
operators on @xmath such that @xmath . By the definition of @xmath , the
operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative. Hence, for any @xmath , the operator @xmath must also be
nonnegative. This implies that the operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative as well. We thus have @xmath , from which the assertion
follows. ∎

#### 3.1.3 Chain rules for min-entropy

The chain rule for the von Neumann entropy reads @xmath . In particular,
since @xmath cannot be larger than @xmath , we have @xmath . The
following lemma implies that a similar statement holds for min-entropy,
namely,

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 3.1.10.

Let @xmath , @xmath , and let @xmath be the fully mixed state on the
support of @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be the support of @xmath and let @xmath . The operator @xmath
can then be written as @xmath , where @xmath is the identity on @xmath .
Hence, because the support of @xmath is contained in @xmath (cf. Lemma
B.4.1 ), the operator @xmath is nonnegative if and only if the operator
@xmath is nonnegative. The assertion thus follows from the definition of
the min-entropy and the fact that @xmath . ∎

##### Data processing

Let @xmath , @xmath , and @xmath be random variables such that @xmath is
a Markov chain , i.e., the conditional probability distributions @xmath
have product form @xmath . The uncertainty on @xmath given @xmath is
then equal to the uncertainty on @xmath given @xmath and @xmath , that
is, in terms of Shannon entropy, @xmath . Hence, by the chain rule, we
get the equality @xmath .

The same equality also holds for quantum states @xmath on @xmath which
are classical on @xmath and where, analogously to the Markov condition,
the conditional density operators @xmath have product form, i.e., @xmath
. The following lemma generalizes this statement to min-entropy.

###### Lemma 3.1.11.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath such that the corresponding conditional operators @xmath , for
any @xmath , have product form and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath , let @xmath and let @xmath be the normalization of
@xmath . The operator @xmath can then be written as

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath such that @xmath , @xmath . Because the vectors @xmath are
mutually orthogonal, it follows immediately from the definition of the
min-entropy that the operators @xmath and @xmath are nonnegative, for
any @xmath . Consequently, the operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative as well. This implies

  -- -------- --
     @xmath   
  -- -------- --

from which the assertion follows by the definition of @xmath and @xmath
. ∎

#### 3.1.4 Quantum operations can only increase min-entropy

The min-entropy can only increase when applying quantum operations.
Because the partial trace is a quantum operation, this general statement
also implies the first assertion of Lemma 3.1.7 (strong subadditivity).

###### Lemma 3.1.12.

Let @xmath , @xmath , @xmath and let @xmath be a CPM from @xmath to
@xmath such that @xmath is nonnegative. Then, for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath such that @xmath , that is, the operator @xmath is
nonnegative. Because @xmath is a quantum operation, the operator @xmath
is also nonnegative. Combining this with the assumption that @xmath is
nonnegative, we conclude that the operator

  -- -------- --
     @xmath   
  -- -------- --

is also nonnegative. The assertion then follows by the definition of the
min-entropy. ∎

#### 3.1.5 Min-entropy of superpositions

Let @xmath be an orthonormal basis on @xmath , let @xmath be a family of
vectors on @xmath , and define

  -- -------- -------- -- -------
     @xmath   @xmath      (3.4)
     @xmath   @xmath      (3.5)
  -- -------- -------- -- -------

Note that, if the states @xmath are orthogonal then @xmath can be seen
as the state resulting from an orthogonal measurement of @xmath with
respect to the projectors along @xmath . While @xmath is a superposition
(linear combination) of vectors @xmath , @xmath is a mixture of vectors
@xmath . The following lemma gives a lower bound on the min-entropy of
@xmath in terms of the min-entropy of @xmath .

###### Lemma 3.1.13.

Let @xmath and @xmath be defined by ( 3.4 ) and ( 3.5 ), respectively,
and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume without loss of generality that, for all @xmath , @xmath is not
the zero vector. This implies @xmath . Moreover, let @xmath such that
@xmath . It then suffices to show that the operator

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

is nonnegative.

Let @xmath . By linearity, we have

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

Let @xmath be an orthonormal basis of @xmath and define @xmath . Then,
by the Cauchy-Schwartz inequality, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 3.7 ) and using Jensen’s inequality, we find

  -- -------- --
     @xmath   
  -- -------- --

By the choice of @xmath , the operator @xmath is nonnegative. Hence
@xmath and thus, by the above inequality, @xmath . Because this is true
for any vector @xmath , we conclude that the operator defined by ( 3.6 )
is nonnegative. ∎

###### Lemma 3.1.14.

Let @xmath , @xmath be defined by ( 3.4 ) and ( 3.5 ), respectively, and
let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The assertion follows from Lemma 3.1.13 together with Lemma 3.1.7 . ∎

### 3.2 Smooth min- and max-entropy

The min-entropy and the max-entropy, as defined in the previous section,
are discontinuous in the sense that a slight modification of the
system’s state might have a large impact on its entropy. To illustrate
this, consider for example a classical random variable @xmath on the set
@xmath which takes the values @xmath and @xmath with probability almost
one half, i.e., @xmath , for some small @xmath , whereas the other
values have equal probabilities, i.e., @xmath , for all @xmath . Then,
by the definition of the max-entropy, @xmath . On the other hand, if we
slightly change the probability distribution @xmath to some probability
distribution @xmath such that @xmath , for all @xmath , then @xmath . In
particular, for @xmath large, @xmath , while @xmath .

We will see later (cf. Section 6.3 ) that the max-entropy @xmath can be
interpreted as the minimum number of bits needed to encode @xmath in
such a way that its value can be recovered from the encoding without
errors. The above example is consistent with this interpretation.
Indeed, while we need at least @xmath bits to store a value @xmath
distributed according to @xmath , one single bit is sufficient to store
a value distributed according to @xmath . However, for most
applications, we allow some small error probability. For example, we
might want to encode @xmath in such a way that its value can be
recovered with probability @xmath . Obviously, in this case, one single
bit is sufficient to store @xmath even if it is distributed according to
@xmath .

The example illustrates that, given some probability distribution @xmath
, one might be interested in the maximum (or minimum) entropy of any
distribution @xmath which is close to @xmath . This idea is captured by
the notion of smooth min- and max-entropy.

#### 3.2.1 Definition of smooth min- and max-entropy

The definition of smooth min- and max-entropy is based on the
“non-smooth” version (Definition 3.1.1 ).

###### Definition 3.2.1.

Let @xmath , @xmath , and @xmath . The @xmath -smooth min-entropy and
the @xmath -smooth max-entropy of @xmath relative to @xmath are

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where the supremum and infimum ranges over the set @xmath of all
operators @xmath such that @xmath and @xmath .

###### Definition 3.2.2.

Let @xmath and let @xmath . The @xmath -smooth min-entropy and the
@xmath -smooth max-entropy of @xmath given @xmath are

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where the supremum ranges over all @xmath with @xmath .

Note that, similar to the description in Section 3.1 , these definitions
can be specialized to classical probability distributions.

##### Evaluating the suprema and infima

###### Remark 3.2.3.

If the Hilbert space @xmath has finite dimension, then the set of
operators @xmath as well as the set of operators @xmath with @xmath is
compact. Hence, the infima and suprema in the above definitions can be
replaced by minima and maxima, respectively.

###### Remark 3.2.4.

The supremum in the definition of the smooth min-entropy @xmath
(Definition 3.2.1 ) can be restricted to the set of operators @xmath
with @xmath .

Additionally, to compute @xmath where @xmath and @xmath are classical
with respect to an orthonormal basis @xmath on a subsystem @xmath , it
is sufficient to take the supremum over operators @xmath which are
classical with respect to @xmath .

Similarly, to compute @xmath where @xmath is classical on a subsystem
@xmath , the supremum can be restricted to states @xmath which are
classical on @xmath .

###### Proof.

For the first statement, we show that any operator @xmath can be
transformed to an operator @xmath which has at least the same amount of
min-entropy as @xmath and, additionally, has support on @xmath .

Let @xmath be the operation on @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

Because the operator @xmath is nonnegative, Lemma 3.1.12 implies that
the min-entropy can only increase under the action of @xmath . Moreover,
@xmath (cf. Lemma B.4.1 ) and thus @xmath . Because @xmath is a
projection, the @xmath -distance cannot increase under the action of
@xmath (cf. Lemma A.2.1 ), i.e.,

  -- -- --
        
  -- -- --

We thus have @xmath . The assertion then follows because we can assume
that @xmath is contained in @xmath (otherwise, the min-entropy is
arbitrarily negative and the statement is trivial) and thus @xmath .

The statements for @xmath and @xmath are proven similarly. ∎

###### Remark 3.2.5.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath . Then the supremum in the definition of the min-entropy @xmath
can be restricted to operators @xmath which are classical with respect
to @xmath .

###### Proof.

We show that for any @xmath and @xmath with @xmath there exists @xmath
and @xmath with @xmath such that @xmath is classical with respect to
@xmath and @xmath .

Let thus @xmath and @xmath be fixed. Define @xmath and @xmath where
@xmath is the projective measurement operation on @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath is classical with respect to @xmath and, because @xmath
is trace-preserving, @xmath . Similarly, @xmath . Moreover, because
@xmath and because the distance can only decrease when applying @xmath
(cf. Lemma A.2.1 ), we have

  -- -------- --
     @xmath   
  -- -------- --

which implies @xmath . Finally, using Lemma 3.1.12 , we find @xmath . ∎

#### 3.2.2 Basic properties of smooth min-entropy

##### Superadditivity

The following is a generalization of (one direction of) Lemma 3.1.6 to
smooth min-entropy.

###### Lemma 3.2.6.

Let @xmath , @xmath and, similarly, @xmath , @xmath , and let @xmath .
Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath , there exist @xmath and @xmath such that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Hence, by Lemma 3.1.6 ,

  -- -------- --
     @xmath   
  -- -------- --

Because this holds for any @xmath , it remains to verify that @xmath .
This is however a direct consequence of the triangle inequality, i.e.,

  -- -------- --
     @xmath   
  -- -------- --

∎

##### Strong subadditivity

The following statement is a generalization of Lemma 3.1.7 to smooth
min-entropy.

###### Lemma 3.2.7.

Let @xmath , @xmath , and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath , there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Hence, by Lemma 3.1.7 , applied to the operator @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Because this holds for any @xmath , it remains to show that @xmath .
This is however a direct consequence of the fact that the @xmath
-distance cannot increase when taking the partial trace (cf. Lemma A.2.1
), i.e.,

  -- -------- --
     @xmath   
  -- -------- --

∎

##### Conditioning on classical information

The following lemma generalizes (one direction of) Lemma 3.1.8 to smooth
min-entropy.

###### Lemma 3.2.8.

Let @xmath and @xmath be classical with respect to an orthonormal basis
@xmath of @xmath , let @xmath and @xmath be the corresponding
(non-normalized) conditional operators, and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath and @xmath , there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Let

  -- -------- --
     @xmath   
  -- -------- --

Using Lemma 3.1.8 , we find

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

Because this holds for any value of @xmath , it suffices to verify that
@xmath . This is however a direct consequence of

  -- -- --
        
  -- -- --

where the first equality follows from Lemma A.2.2 . ∎

#### 3.2.3 Chain rules for smooth min-entropy

The following lemma generalizes (one direction of) Lemma 3.1.10 to
smooth min-entropy.

###### Lemma 3.2.9.

Let @xmath , @xmath , let @xmath be the fully mixed state on the support
of @xmath , and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

According to Remark 3.2.4 , for any @xmath , there exists @xmath such
that

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

and @xmath . Hence, from Lemma B.4.2 , @xmath . Consequently, the
operator @xmath is arbitrarily close to an operator whose support is
equal to the support of @xmath . By continuity, we can thus assume
without loss of generality that @xmath , that is,

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

Moreover, since @xmath , we have

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Finally, because @xmath is the fully mixed state on @xmath , Lemma
3.1.10 , applied to the state @xmath , gives

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 3.9 ), ( 3.10 ), and ( 3.11 ) concludes the proof.
∎

##### Data processing

The following lemma is a generalization of Lemma 3.1.11 to smooth
min-entropy.

###### Lemma 3.2.10.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath such that the corresponding conditional operators @xmath , for
any @xmath , have product form, let @xmath , and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath , let @xmath and define @xmath . Because @xmath has
product form, we have

  -- -------- --
     @xmath   
  -- -------- --

According to Remark 3.2.4 , for any @xmath , there exists a nonnegative
operator @xmath such that

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

where @xmath is classical with respect to @xmath , that is, @xmath , for
some family @xmath of conditional operators on @xmath . Let @xmath be
defined by

  -- -------- --
     @xmath   
  -- -------- --

Because the operators @xmath are normalized, we have

  -- -------- --
     @xmath   
  -- -------- --

where the first and the last equality follow from Lemma A.2.2 . Because
@xmath , this implies @xmath and thus

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

Moreover, using Lemma 3.1.8 and the fact that, for any @xmath , the
operators @xmath and @xmath only differ by a factor @xmath , we have

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

Finally, applying Lemma 3.1.11 to the state @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 3.12 ), ( 3.13 ), and ( 3.14 ) concludes the
proof. ∎

#### 3.2.4 Smooth min-entropy of superpositions

The following statement generalizes Lemma 3.1.14 .

###### Lemma 3.2.11.

Let @xmath , @xmath be defined by ( 3.4 ) and ( 3.5 ), respectively, for
mutually orthogonal vectors @xmath , let @xmath , and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

###### Proof.

By Remark 3.2.4 , for any @xmath , there exists an operator @xmath which
is classical with respect to the basis @xmath such that

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

Let @xmath be the family of conditional operators defined by @xmath and
@xmath , i.e., @xmath . According to Lemma A.2.7 , for any @xmath ,
there exists a purification @xmath of @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath and define @xmath . By the triangle inequality, we find

  -- -------- --
     @xmath   
  -- -------- --

Hence, with Jensen’s inequality,

  -- -------- --
     @xmath   
  -- -------- --

where the equality follows from Lemma A.2.2 . Because the vectors @xmath
are orthogonal, we have @xmath . Consequently, since @xmath , we obtain

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

Assume without loss of generality that @xmath (otherwise, the assertion
is trivial). Then, because @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

and thus, by Lemma A.2.5 ,

  -- -------- --
     @xmath   
  -- -------- --

where the last inequality follows from ( 3.16 ). This implies

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

Note that @xmath can be seen as the operator obtained by taking the
partial trace of

  -- -------- --
     @xmath   
  -- -------- --

We can thus apply Lemma 3.1.14 to the operators @xmath and @xmath ,
which gives

  -- -------- --
     @xmath   
  -- -------- --

Finally, because the support of @xmath is contained in the support of
@xmath , we have @xmath and thus

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 3.17 ) and ( 3.15 ) concludes the proof. ∎

#### 3.2.5 Smooth min-entropy calculus

The properties proven so far are formulated in terms of the smooth
min-entropy @xmath relative to an operator @xmath (Definition 3.2.1 ).
The following theorem translates these statements to conditional smooth
min-entropy @xmath (Definition 3.2.2 ).

###### Theorem 3.2.12.

Let @xmath . Then the following inequalities hold:

-    (Super-)additivity:

      -- -------- -- --------
         @xmath      (3.18)
      -- -------- -- --------

    for @xmath and @xmath .

-    Strong subadditivity:

      -- -------- -- --------
         @xmath      (3.19)
      -- -------- -- --------

    for @xmath .

-    Conditioning on classical information:

      -- -------- -- --------
         @xmath      (3.20)
      -- -------- -- --------

    for @xmath normalized and classical on @xmath , and for normalized
    conditional operators @xmath .

-    Chain rule:

      -- -------- -- --------
         @xmath      (3.21)
      -- -------- -- --------

    for @xmath .

-    Data processing:

      -- -------- -- --------
         @xmath      (3.22)
      -- -------- -- --------

    for @xmath classical on @xmath such that the conditional operators
    @xmath have product form.

###### Proof.

The statements follow immediately from Lemmata 3.2.6 , 3.2.7 , 3.2.8 ,
3.2.9 , and 3.2.10 . ∎

### 3.3 Smooth min- and max-entropy of products

In this section, we show that the smooth min- and max-entropies of
product states are asymptotically equal to the von Neumann entropy. In a
first step, we consider a purely classical situation, i.e., we prove
that the smooth min- and max-entropies of a sequence of independent and
identically distributed random variables can be expressed in terms of
Shannon entropy (which is the classical analogue of the von Neumann
entropy). Then, in a second step, we generalize this statement to
quantum states (Section 3.3.2 ).

#### 3.3.1 The classical case

The proof of the main result of this section (Theorem 3.3.4 ) is based
on a Chernoff style bound (Theorem 3.3.3 ) which is actually a variant
of the asymptotic equipartition property (AEP) known from information
theory (see, e.g., [ CT91 ] ). It states that, with high probability,
the negative logarithm of the probability of an @xmath -tuple of values
chosen according to a product distribution @xmath is close to the
Shannon entropy of @xmath .

##### Typical sequences and their probabilities

###### Lemma 3.3.1.

Let @xmath be a probability distribution. Then, for any @xmath with
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where the expectation is taken over pairs @xmath chosen according to
@xmath .

###### Proof.

For any @xmath , let @xmath be the function on the open interval @xmath
defined by

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

We will use several properties of this function proven in Appendix B.6 .

For any @xmath and @xmath , let @xmath . If @xmath then

  -- -------- --
     @xmath   
  -- -------- --

where the inequality holds because @xmath is monotonically increasing on
the interval @xmath (Lemma B.6.1 ) and @xmath . Because @xmath and
because @xmath is concave on this interval (Lemma B.6.3 which can be
applied because @xmath ), Jensen’s inequality leads to

  -- -- --
        
  -- -- --

where @xmath denotes the expectation with respect to @xmath chosen
according to the distribution @xmath . Because @xmath and @xmath , we
obtain

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, because @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Finally, together with Lemma B.6.4 , since @xmath , we conclude

  -- -------- --
     @xmath   
  -- -------- --

The assertion follows because @xmath . ∎

###### Lemma 3.3.2.

Let @xmath be a probability distribution and let @xmath be the function
on @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

Then, for any @xmath with @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The assertion follows directly from Lemma 3.3.1 , that is,

  -- -- --
        
  -- -- --

###### Theorem 3.3.3.

Let @xmath be a probability distribution and let @xmath . Then, for any
@xmath and @xmath chosen according to @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and, similarly,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath , @xmath , and let @xmath be the function defined in Lemma
3.3.2 for the probability distribution @xmath . Then

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

Using Markov’s inequality, for any @xmath ,

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

Moreover, because the pairs @xmath are chosen independently,

  -- -- --
        
  -- -- --

where the inequality follows from Lemma 3.3.2 , for any @xmath .
Combining this with ( 3.25 ) gives

  -- -------- --
     @xmath   
  -- -------- --

With @xmath (note that @xmath because @xmath ), we conclude

  -- -------- --
     @xmath   
  -- -------- --

The first inequality of the lemma then follows from ( 3.24 ).

Similarly, if @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- --
     @xmath   
  -- -------- --

The second inequality follows with @xmath . ∎

##### Asymptotic equality of smooth entropy and Shannon entropy

###### Theorem 3.3.4.

Let @xmath be a probability distribution and let @xmath . Then, for any
@xmath and @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath .

###### Proof.

We first prove the bound on the (classical) smooth max-entropy @xmath .
For any @xmath with @xmath , let @xmath be the set of all @xmath -tuples
@xmath such that

  -- -- --
        
  -- -- --

Furthermore, let @xmath be the nonnegative function on @xmath defined by

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

We can assume without loss of generality that @xmath (otherwise, the
statement is trivial). Hence, by the first inequality of Theorem 3.3.3 ,
@xmath . This implies @xmath and thus

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

For any fixed @xmath with @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where the second inequality follows from the definition of the set
@xmath . Consequently, we have @xmath . Moreover, by the definition of
@xmath , the support of the function @xmath is contained in @xmath .
Hence, using Remark 3.1.4 ,

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 3.27 ) proves the first inequality of the lemma.

To prove the bound on the min-entropy @xmath , let @xmath , for any
@xmath with @xmath , be the set of @xmath -tuples @xmath such that

  -- -- --
        
  -- -- --

and let again @xmath be defined by ( 3.26 ). By the second inequality of
Theorem 3.3.3 , @xmath , which, similarly to the previous argument,
implies

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

Moreover, using Remark 3.1.4

  -- -------- --
     @xmath   
  -- -------- --

where the inequality follows from the definition of the set @xmath .
Combining this with ( 3.28 ) proves the second inequality of the lemma.
∎

Because the min-entropy @xmath cannot be larger than the max-entropy
@xmath (cf.  Lemma 3.1.5 ), Theorem 3.3.4 implies that

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

where asymptotically, for increasing @xmath , the approximation becomes
an equality.

###### Remark 3.3.5.

It is easy to see that Theorem 3.3.4 can be generalized to probability
distributions @xmath which are the product of not necessarily identical
distributions @xmath . That is, for any distribution of the form @xmath
, the approximation ( 3.29 ) still holds.

#### 3.3.2 The quantum case

The following theorem and its corollary can be seen as a quantum version
of Theorem 3.3.4 for smooth min-entropy (where the Shannon entropy is
replaced by the von Neumann entropy). The proof essentially follows the
same line as the classical argument described above. ⁷ ⁷ 7 An
alternative method to prove the statement @xmath is to use a chain rule
of the form @xmath . The entropies on the right hand side of this
inequality can be rewritten as the entropies of the classical
probability distributions defined by the eigenvalues of @xmath and
@xmath , respectively. The desired bound then follows from the classical
Theorem 3.3.4 . However, the results obtained with such an alternative
method are less tight and less general than Theorem 3.3.6 . A similar
argument shows that the statement also holds for smooth max-entropy.

###### Theorem 3.3.6.

Let @xmath , @xmath be density operators, and let @xmath . Then, for any
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

###### Proof.

Define @xmath . We show that there exists a density operator @xmath such
that

  -- -------- -- --------
     @xmath      (3.30)
  -- -------- -- --------

According to the definition of min-entropy, this is equivalent to saying
that the operator @xmath is nonnegative, for @xmath such that @xmath .

Let

  -- -------- --
     @xmath   
  -- -------- --

be a spectral decomposition of @xmath . We can assume without loss of
generality that there exists an order relation on the values @xmath such
that @xmath , for any @xmath . For any @xmath , let @xmath be the
projector defined by

  -- -------- --
     @xmath   
  -- -------- --

Moreover, let @xmath , for @xmath , be nonnegative coefficients such
that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Note that the spectral decomposition above can then be rewritten as

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

Let

  -- -------- --
     @xmath   
  -- -------- --

be a spectral decomposition of @xmath . In the following, we denote by
@xmath an element which is larger than any element of @xmath . Moreover,
let @xmath , for @xmath and @xmath , be nonnegative coefficients such
that, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We show that inequality ( 3.30 ) holds for the operator

  -- -------- --
     @xmath   
  -- -------- --

Note first that, by the definition of @xmath and @xmath , we have @xmath
, for any @xmath and @xmath , that is, the operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative. Using ( 3.31 ) and the fact that the operators @xmath
are projectors, we conclude that the operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative, which implies ( 3.30 ). It thus remains to be proven
that @xmath .

Using the above definitions and the convention that @xmath is the zero
matrix, we have

  -- -------- --
     @xmath   
  -- -------- --

We can use Lemma A.2.8 to bound the trace distance on the right hand
side of this inequality, that is,

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath is a density operator, the nonnegative coefficients
@xmath sum up to one. We can thus apply Jensen’s inequality which gives

  -- -------- -- --------
     @xmath      (3.32)
  -- -------- -- --------

The trace in the square root can be rewritten as

  -- -- --
        
  -- -- --

Because the terms in the sum are all nonnegative, the sum can only
become smaller if we restrict the set of values @xmath over which the
sum is taken. Consequently,

  -- -------- --
     @xmath   
  -- -------- --

By the definition of @xmath , we have @xmath , for any @xmath such that
@xmath , and hence

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath , this inequality can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

Recall that we need to prove that @xmath . Hence, combining ( 3.32 )
with the above bound on @xmath , it remains to be shown that

  -- -------- -- --------
     @xmath      (3.33)
  -- -------- -- --------

Let

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

be spectral decompositions of @xmath and @xmath , respectively.
Moreover, let @xmath be the probability distribution defined by

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath and @xmath , as used above, can be defined as @xmath
and @xmath . Similarly, we can set @xmath and @xmath . Then, the left
hand side of ( 3.33 ) can be rewritten as

  -- -------- -- --------
     @xmath      (3.34)
  -- -------- -- --------

for @xmath chosen according to the probability distribution @xmath .

By the definition of @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

for @xmath chosen according to @xmath . According to Birkhoff’s theorem
(cf. Theorem B.2.2 ) there exist nonnegative coefficients @xmath
parameterized by the bijections @xmath from @xmath to @xmath such that
@xmath and @xmath . The identity above can thus be rewritten as

  -- -------- -- --------
     @xmath      (3.35)
  -- -------- -- --------

For @xmath chosen according to @xmath ,

  -- -- --
        
  -- -- --

For any @xmath , let @xmath be the function defined by ( 3.23 ). The
last term in the sum above can then be bounded by

  -- -------- --
     @xmath   
  -- -------- --

where the inequality follows from the fact that, for all @xmath , @xmath
(Lemma B.6.2 ) and the fact that @xmath is monotonically increasing
(Lemma B.6.1 ) on the interval @xmath . Because @xmath and because
@xmath is concave on this interval (Lemma B.6.3 ) we can apply Jensen’s
inequality, which gives

  -- -------- -- --------
     @xmath      (3.36)
  -- -------- -- --------

Note that @xmath . As we can assume without loss of generality that
@xmath is restricted to the support of @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

Hence, together with ( 3.35 ), the bound ( 3.36 ) can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Furthermore, using the fact that @xmath we find

  -- -- --
        
  -- -- --

With Lemma B.6.4 , we conclude

  -- -------- -- --------
     @xmath      (3.37)
  -- -------- -- --------

Let now @xmath . Because the expectation of the product of independent
values is equal to the product of the expectation of these values, we
have, for @xmath chosen according to @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence, by Markov’s inequality, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and thus, using ( 3.37 ),

  -- -------- --
     @xmath   
  -- -------- --

Consequently, with @xmath ,

  -- -- --
        
  -- -- --

Combining this with ( 3.34 ) implies ( 3.33 ) and thus concludes the
proof. ∎

The following corollary specializes Theorem 3.3.6 to the case where the
first part of the state @xmath is classical and where @xmath .

###### Corollary 3.3.7.

Let @xmath be a density operator which is classical on @xmath . Then,
for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

###### Proof.

Assume without loss of generality that @xmath is invertible (the general
statement then follows by continuity). Because the operator

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative, we can apply Lemma B.5.4 which gives

  -- -------- --
     @xmath   
  -- -------- --

Hence, since @xmath is normalized,

  -- -------- --
     @xmath   
  -- -------- --

Using the fact that, for any @xmath , @xmath , we thus have

  -- -- --
        
  -- -- --

The assertion then follows directly from Theorem 3.3.6 with @xmath and
@xmath . ∎

## Chapter 4 Symmetric States

The state of an @xmath -partite quantum system is said to be symmetric
or permutation-invariant if it is unchanged under reordering of the
subsystems. Such states have nice properties which are actually very
similar to those of product states.

The chapter is organized as follows: We first review some basic
properties of symmetric subspaces of product spaces (Section 4.1 ) and
show that any permutation-invariant density operator has a purification
in such a space (Section 4.2 ). Next, we state our main result on the
structure of symmetric states, which generalizes the so-called de
Finetti representation theorem (Section 4.3 ). Based on this result, we
derive expressions for the smooth min-entropy (Section 4.4 ) and the
measurement statistics (Section 4.5 ) of symmetric states.

### 4.1 Definition and basic properties

#### 4.1.1 Symmetric subspace of @xmath

Let @xmath be a Hilbert space and let @xmath be the set of permutations
on @xmath . For any @xmath , we denote by the same letter @xmath the
unitary operation on @xmath which permutes the @xmath subsystems, that
is,

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath .

###### Definition 4.1.1.

Let @xmath be a Hilbert space and let @xmath . The symmetric subspace
@xmath of @xmath is the subspace of @xmath spanned by all vectors which
are invariant under permutations of the subsystems, that is,

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 4.1.2.

For any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Lemma 4.1.3 below provides an alternative characterization of the
symmetric subspace @xmath .

###### Lemma 4.1.3.

Let @xmath be a Hilbert space and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For a proof of this statement, we refer to the standard literature on
symmetric functions or representation theory (see, e.g., [ WG00 ] ). ∎

##### A basis of the symmetric subspace

Let @xmath be an @xmath -tuple of elements from @xmath . The frequency
distribution @xmath of @xmath is the probability distribution on @xmath
defined by the relative number of occurrences of each symbol, that is,

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath . In the following, we denote by @xmath the set of
frequency distributions of @xmath -tuples on @xmath , also called types
with denominator @xmath on @xmath . Moreover, for any type @xmath , we
denote by @xmath the corresponding type class , i.e., the set of all
@xmath -tuples @xmath with frequency distribution @xmath .

Let @xmath be an orthonormal basis of @xmath . For any @xmath , we
define the vector @xmath on @xmath by

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where, according to Lemma ( B.1.2 ), @xmath .

The vectors @xmath , for @xmath , are mutually orthogonal and
normalized. We will see below (cf.  Lemma 4.1.5 ) that the family @xmath
is a basis of @xmath . In particular, if @xmath has dimension @xmath ,
then @xmath (cf. Lemma B.1.1 ).

#### 4.1.2 Symmetric subspace along product states

Let @xmath be a Hilbert space, let @xmath be fixed, and let @xmath . We
denote by @xmath the set of vectors @xmath which, after some reordering
of the subsystems, are of the form @xmath , that is,

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

We will be interested in the subspace of @xmath which only consists of
linear combinations of vectors from @xmath .

###### Definition 4.1.4.

Let @xmath be a Hilbert space, let @xmath , and let @xmath . The
symmetric subspace @xmath of @xmath along @xmath is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the subset of @xmath defined by ( 4.2 ).

Note that @xmath , where equality holds if @xmath . In Section 4.4 and
4.5 , we shall see that, if @xmath is small compared to @xmath , then
the states in @xmath have similar properties as product states @xmath .

###### Lemma 4.1.5.

Let @xmath be a Hilbert space with orthonormal basis @xmath , let @xmath
for some @xmath , and let @xmath . Then the family

  -- -------- --
     @xmath   
  -- -------- --

of vectors @xmath defined by ( 4.1 ) is an orthonormal basis of @xmath .

Note that, for @xmath , Lemma 4.1.5 implies that the family @xmath is an
orthonormal basis of @xmath .

###### Proof.

For any @xmath , the vector @xmath is invariant under permutations of
the subsystems, that is, @xmath . Moreover, if @xmath then the sum on
the right hand side of ( 4.1 ) only runs over @xmath -tuples which
contain at least @xmath symbols @xmath , that is, each term of the sum
is contained in the set @xmath defined by ( 4.2 ) and hence @xmath .
This proves that all vectors @xmath are contained in @xmath . Moreover,
the vectors @xmath are mutually orthogonal and normalized.

It remains to be shown that @xmath is spanned by the vectors @xmath .
Let thus @xmath be fixed. Since @xmath is a basis of @xmath , there
exist coefficients @xmath , for @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath is invariant under permutations of the subsystems, the
coefficients @xmath can only depend on the frequency distribution @xmath
. This implies that there exist coefficients @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

To conclude the proof, we need to verify that this sum can be restricted
to frequency distributions @xmath such that @xmath . Observe that, for
any @xmath with @xmath , the vector @xmath is orthogonal to any vector
in @xmath and thus also to any vector in @xmath . The corresponding
coefficient @xmath must thus be zero. ∎

Any vector @xmath can be written as a linear combination of at most ¹ ¹
1 @xmath denotes the binary Shannon entropy function defined by @xmath .
@xmath vectors from the set @xmath defined by ( 4.2 ).

###### Lemma 4.1.6.

Let @xmath . Then there exists an orthonormal family @xmath of vectors
from @xmath with cardinality @xmath such that @xmath .

###### Proof.

Let @xmath be an orthonormal basis of @xmath such that @xmath . For any
@xmath -tuple @xmath , we denote by @xmath the vector @xmath . Because
@xmath , there exist coefficients @xmath , for @xmath , such that

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

Let @xmath be the set of all subsets @xmath of cardinality @xmath .
Moreover, for any @xmath with @xmath , let @xmath be a set of @xmath
indices from @xmath such that @xmath . Finally, for any @xmath , let

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

The sum in ( 4.3 ) can then be rewritten as @xmath , that is, @xmath .
Moreover, Lemma B.1.3 implies @xmath .

It remains to be shown that @xmath is an orthonormal family of vectors
from @xmath . Let thus @xmath be fixed and let @xmath be a permutation
such that @xmath . Hence, for any @xmath with @xmath , the vector @xmath
has the form @xmath , for some @xmath . By the definition ( 4.4 ), the
same holds for @xmath , i.e., @xmath . Furthermore, because for distinct
@xmath , the sum in ( 4.4 ) runs over disjoint sets of @xmath -tuples
@xmath , and because the vectors @xmath are mutually orthogonal, the
states @xmath are also mutually orthogonal. The assertion thus follows
by normalizing the vectors @xmath . ∎

### 4.2 Symmetric purification

An operator @xmath on @xmath is called permutation-invariant if @xmath ,
for any permutation @xmath . For example, the pure state @xmath , for
some vector @xmath of the symmetric subspace of @xmath , is
permutation-invariant. More generally, any mixture of symmetric pure
states is permutation-invariant.

The converse, however, is not always true. Consider for example the
fully mixed state @xmath on @xmath where @xmath . Because this operator
can be written as @xmath , it is invariant under permutations. However,
@xmath has rank @xmath , whereas the symmetric subspace of @xmath only
has dimension @xmath . Consequently, @xmath is not a mixture of
symmetric pure states.

Lemma 4.2.2 below establishes another connection between
permutation-invariant operators and symmetric pure states. We show that
any permutation-invariant operator @xmath on @xmath has a purification
on the symmetric subspace of @xmath .

To prove this result, we need a technical lemma which states that a
fully entangled state on two subsystems is unchanged when the same
unitary operation is applied to both subsystems.

###### Lemma 4.2.1.

Let @xmath be an orthonormal family of vectors on a Hilbert space @xmath
and define

  -- -------- --
     @xmath   
  -- -------- --

where, for any @xmath , @xmath denotes the complex conjugate of @xmath
(with respect to some basis of @xmath ). Let @xmath be a unitary
operation on the subspace spanned by @xmath and let @xmath be its
complex conjugate. Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

A simple calculation shows that, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The assertion follows because, obviously, @xmath is a basis of the
subspace of @xmath that contains @xmath . ∎

###### Lemma 4.2.2.

Let @xmath be permutation-invariant. Then there exists a purification of
@xmath on @xmath .

###### Proof.

Let @xmath be an (orthonormal) eigenbasis of @xmath and let @xmath be
the set of eigenvalues of @xmath . For any @xmath , let @xmath be the
corresponding eigenspace of @xmath , i.e., @xmath , for any @xmath .

Because @xmath is invariant under permutations, we have @xmath , for any
@xmath and @xmath . Applying the unitary operation @xmath to both sides
of this equality gives @xmath , that is, @xmath . This proves that the
eigenspaces @xmath of @xmath are invariant under permutations.

For any @xmath , we denote by @xmath the complex conjugate of @xmath
with respect to some product basis on @xmath . Moreover, for any
eigenvalue @xmath , let

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , i.e., @xmath is an orthonormal basis of the eigenspace
@xmath . Finally, we define the vector @xmath by

  -- -------- --
     @xmath   
  -- -------- --

It is easy to verify that the operator obtained by taking the partial
trace of @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

i.e., @xmath is a purification of @xmath . It thus remains to be shown
that @xmath is symmetric.

Let @xmath be a fixed permutation. Note that its complex conjugate
@xmath is equal to @xmath . (Recall that we defined the complex
conjugate with respect to a product basis of @xmath .) Moreover, because
@xmath is unitary on @xmath and, additionally, for any @xmath , the
subspace @xmath is invariant under @xmath , the restriction of @xmath to
@xmath is unitary as well. Hence, by Lemma 4.2.1 ,

  -- -------- --
     @xmath   
  -- -------- --

and thus, by linearity,

  -- -------- --
     @xmath   
  -- -------- --

Because this holds for any permutation @xmath on @xmath , we conclude
@xmath . ∎

### 4.3 De Finetti representation

While any product state @xmath on @xmath is permutation-invariant, the
converse is not true in general. Nevertheless, as we shall see, the
properties of permutation-invariant states @xmath are usually very
similar to those of product states.

The quantum de Finetti representation theorem makes this connection
explicit. In its basic version, it states that any density operator
@xmath on @xmath which is infinitely exchangeable, i.e., @xmath is the
partial state of a permutation-invariant operator @xmath on @xmath
subsystems, for all @xmath , can be written as a mixture of product
states @xmath .

In this section, we generalize the quantum de Finetti representation to
the finite case, where @xmath is only @xmath -exchangeable, i.e., @xmath
is the partial state of a permutation-invariant operator @xmath on
@xmath subsystems, for some fixed @xmath . Theorem 4.3.2 below states
that any pure density operator @xmath on @xmath which is @xmath
-exchangeable is close to a mixture of states @xmath which have almost
product form @xmath , for @xmath . More precisely, for any @xmath ,
@xmath is a pure state of the symmetric subspace of @xmath along @xmath
, for some small @xmath . Because of Lemma 4.2.2 , this statement also
holds for mixed states @xmath .

The proof of Theorem 4.3.2 is based on the following lemma which states
that the uniform mixture of product states @xmath , for all normalized
vectors @xmath , is equal to the fully mixed state on the symmetric
subspace of @xmath .

###### Lemma 4.3.1.

Let @xmath be a @xmath -dimensional Hilbert space and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the uniform probability measure on the unit sphere
@xmath .

Lemma 4.3.1 can be proven using techniques from representation theory,
in particular, Schur’s Lemma (see, e.g., [ WG00 ] ). In the following,
however, we propose an alternative proof.

###### Proof.

Let

  -- -------- --
     @xmath   
  -- -------- --

We first show that @xmath for some constant @xmath .

Because the space @xmath is spanned by vectors of the form @xmath
(cf. Lemma 4.1.3 ), it is sufficient to show that, for any @xmath ,

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

Let thus @xmath be fixed and define @xmath and @xmath , i.e., @xmath .
Then

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

Note that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Because, for any fixed value of @xmath , the integral runs over all
phases of @xmath (recall that @xmath and @xmath are orthogonal) and
because the probability measure @xmath is invariant under unitary
operations, this expression equals zero for any @xmath . The integral on
the right hand side of ( 4.6 ) can thus be rewritten as

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

Using again the fact that the probability measure @xmath is invariant
under unitary operations, we conclude that the integral on the right
hand side cannot depend on the vector @xmath , i.e., it is equal to a
constant @xmath . This implies ( 4.5 ) and thus proves that @xmath .

To determine the value of @xmath , ² ² 2 Alternatively, the constant
@xmath can be computed by an explicit evaluation of the integral on the
right hand side of ( 4.7 ). Remarkably, this can be used to prove Lemma
4.1.3 : Observe first that, by the arguments given in the proof, @xmath
must be equal to the dimension of the space spanned by the vectors of
the form @xmath . On the other hand, the explicit computation of @xmath
shows that @xmath equals @xmath , which is the dimension of @xmath .
Because the space spanned by the vectors @xmath is a subspace of @xmath
, it follows that these spaces are equal. observe that

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

where the last equality holds because @xmath is a probability measure on
@xmath . On the other hand, we have @xmath . Hence, @xmath , which
concludes the proof. ∎

We are now ready to state and prove a de Finetti style representation
theorem. Note that Theorem 4.3.2 is restricted to pure symmetric states.
The statement for general permutation-invariant states then follows
because any such state has a symmetric purification (see Lemma 4.2.2 ).

###### Theorem 4.3.2.

Let @xmath be a pure density operator on @xmath and let @xmath . Then
there exists a measure @xmath on @xmath and, for each @xmath , a pure
density operator @xmath on @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Because the density operator @xmath is pure, we have @xmath for some
@xmath . For any @xmath , let

  -- -- --
        
  -- -- --

where @xmath . Because @xmath is a subspace of @xmath (see Remark 4.1.2
), @xmath is contained in @xmath . Let @xmath , let @xmath be the
projector onto the subspace @xmath , and define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , i.e., @xmath is normalized and, because @xmath has rank
one, it is also pure. Finally, let @xmath be the measure defined by
@xmath , where @xmath is the uniform probability measure on @xmath . It
then suffices to show that

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

By the definition of @xmath , we have

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

and thus, by Lemma 4.3.1 ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Since @xmath is a subspace of @xmath , the vector @xmath is contained in
@xmath . The operation @xmath in the above expression thus leaves @xmath
unchanged. Because @xmath , we conclude

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

Using this representation of @xmath and the triangle inequality, the
distance @xmath defined by ( 4.9 ) can be bounded by

  -- -------- --
     @xmath   
  -- -------- --

Because the operators @xmath are projectors, we can apply Lemma A.2.8 to
bound the distance between @xmath and @xmath , which gives

  -- -------- --
     @xmath   
  -- -------- --

To bound the integral on the right hand side, we use the Cauchy-Schwartz
inequality for the scalar product defined by @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

Because of ( 4.11 ), the first integral on the right hand side equals
@xmath , that is,

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

Let @xmath be the projector orthogonal to @xmath , i.e., @xmath . With (
4.10 ), the term in the integral can be rewritten as

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

Let @xmath be fixed and let @xmath be an orthonormal basis of @xmath
with @xmath , for some @xmath . Moreover, for all frequency
distributions @xmath and @xmath , let @xmath and @xmath be the vectors
in @xmath and @xmath , respectively, defined by ( 4.1 ).

According to Lemma 4.1.5 , the family of vectors @xmath , for all @xmath
, is an orthonormal basis of @xmath . Moreover, the subfamily where
@xmath is a basis of @xmath . Consequently, the projector @xmath on the
space orthogonal to @xmath can be written as

  -- -------- --
     @xmath   
  -- -------- --

Identity ( 4.13 ) then reads

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

Because the family of vectors @xmath , for @xmath , is a basis of the
symmetric subspace @xmath (see again Lemma 4.1.5 ) there exist
coefficients @xmath such that

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

where the sum runs over all @xmath .

It is easy to verify that, for any @xmath and @xmath , the scalar
product @xmath equals zero unless

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

holds for all @xmath , in which case

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

Let @xmath with @xmath and let @xmath such that ( 4.16 ) holds. Then,
from ( 4.15 ) and ( 4.17 ),

  -- -- --
        
  -- -- --

where @xmath . Note that @xmath implies @xmath . Consequently, from (
4.14 ),

  -- -------- --
     @xmath   
  -- -------- --

where the last inequality follows from the fact that @xmath . The term
@xmath can be bounded by

  -- -------- --
     @xmath   
  -- -------- --

Defining @xmath and using the fact that, for any @xmath , @xmath , we
find

  -- -------- --
     @xmath   
  -- -------- --

Finally, because for any @xmath (note that, for @xmath , the assertion
is trivial) @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Inserting this into ( 4.12 ), the bound ( 4.9 ) follows because @xmath
is a probability measure on @xmath . ∎

If the symmetric state @xmath on @xmath has some additional structure
then the set of states that contribute to the mixture in the expression
of Theorem 4.3.2 can be restricted. Remark 4.3.3 below treats the case
where the subspaces @xmath are bipartite systems and where the partial
state on @xmath has product form.

###### Remark 4.3.3.

Let @xmath be a bipartite Hilbert space, let @xmath be a pure density
operator on @xmath such that @xmath , let @xmath , and let @xmath be the
measure defined by Theorem 4.3.2 . Then, for any @xmath , the set

  -- -- --
        
  -- -- --

has at most weight @xmath .

###### Proof.

Let @xmath and @xmath as defined in the proof of Theorem 4.3.2 . It then
suffices to show that

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

where @xmath is the uniform probability measure on the unit sphere
@xmath and @xmath .

Let @xmath be fixed, i.e., @xmath . Then, by ( 4.10 ),

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Since the fidelity cannot decrease when taking the
partial trace (cf. Lemma A.1.5 ) we get

  -- -------- --
     @xmath   
  -- -------- --

Because, by Lemma A.2.4 ,

  -- -------- --
     @xmath   
  -- -------- --

we conclude

  -- -------- --
     @xmath   
  -- -------- --

where we have used @xmath , for @xmath . Inequality ( 4.18 ) then
follows because @xmath is a probability measure. ∎

### 4.4 Smooth min-entropy of symmetric states

Let @xmath , let @xmath be a quantum operation from @xmath to @xmath ,
and define @xmath , for @xmath . Obviously, @xmath has product form,
i.e., @xmath , where @xmath . Hence, as demonstrated in Section 3.3
(Corollary 3.3.7 ), the smooth min-entropy of such a product state can
be expressed in terms of the von Neumann entropy, that is,

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

Theorem 4.4.1 below states that this still holds if the product state
@xmath is replaced by a state in the symmetric subspace of @xmath along
@xmath , for some @xmath .

###### Theorem 4.4.1.

Let @xmath , let @xmath and @xmath be normalized, and let @xmath be a
trace-preserving CPM from @xmath to @xmath which is classical on @xmath
. Define @xmath and @xmath . Then, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

###### Proof.

According to Lemma 4.1.6 , there exists a family @xmath of orthonormal
vectors from @xmath of size @xmath such that

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

where @xmath are coefficients with @xmath .

Let @xmath be the family of operators from @xmath to @xmath defined by
the CPM @xmath , i.e., @xmath , for any operator @xmath on @xmath .
Moreover, let @xmath be a Hilbert space with orthonormal basis @xmath
and let @xmath be the operator from @xmath to @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath is trace-preserving, i.e., @xmath , we have @xmath , that
is, @xmath is unitary. Furthermore, for any operator @xmath on @xmath ,

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

Let @xmath and, similarly, for any @xmath , let @xmath . Then, using (
4.20 ),

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath is unitary and the vectors @xmath are orthonormal, the
vectors @xmath are orthonormal as well. Moreover, using ( 4.21 ),

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath and define the operator @xmath on @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a Hilbert space with orthonormal basis @xmath . Lemma
3.2.11 then allows us to express the smooth min-entropy of @xmath in
terms of the smooth min-entropy of @xmath . Moreover, by Lemma 3.2.8 ,
the smooth min-entropy of @xmath is lower bounded by the min-entropy of
the operators @xmath , that is,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Using the fact that @xmath , we find

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

Let us now compute the min-entropies of the operators @xmath , for
@xmath . Since @xmath , the vector @xmath , after some appropriate
reordering of the subsystems, has the form @xmath , for some @xmath .
Hence, the same holds for the vector @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

Consequently, from ( 4.21 ) and the definition of @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Because @xmath is classical on @xmath , @xmath is also
classical on @xmath . Using the superadditivity of the smooth
min-entropy (Lemma 3.2.6 ) and the fact that the min-entropy of a
classical subsystem cannot be negative (Lemma 3.1.9 ) we find

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Furthermore, because @xmath is classical on @xmath , we can use
Corollary 3.3.7 to bound the smooth min-entropy of the product state in
terms of the von Neumann entropy,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath . Together with ( 4.22 ) and ( 4.24 ) we conclude

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

Moreover, from ( 4.23 ),

  -- -------- --
     @xmath   
  -- -------- --

and hence, using the fact that @xmath , for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Finally, because @xmath and @xmath , we find

  -- -------- --
     @xmath   
  -- -------- --

Inserting this into ( 4.25 ) concludes the proof. ∎

### 4.5 Statistics of symmetric states

Let @xmath be the outcomes of @xmath independent measurements of a state
@xmath with respect to a POVM @xmath . The law of large numbers tells us
that, for large @xmath , the statistics @xmath of the @xmath -tuple
@xmath is close to the probability distribution @xmath defined by @xmath
, for @xmath . Theorem 4.5.2 below states that the same is true if the
@xmath -tuple @xmath is the outcome of a product measurement @xmath
applied to a state @xmath of the symmetric subspace of @xmath along
@xmath , for some small @xmath .

For the proof of this result, we need the following technical lemma.

###### Lemma 4.5.1.

Let @xmath and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be a spectral decomposition of @xmath . For any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where we have used the Cauchy-Schwartz inequality in the last step.
Consequently,

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 4.5.2.

Let @xmath , let @xmath and @xmath be normalized, let @xmath be a POVM
on @xmath , and let @xmath be the probability distribution of the
outcomes of the measurement @xmath applied to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where the probability is taken over the outcomes @xmath of the product
measurement @xmath applied to @xmath .

###### Proof.

According to Lemma 4.1.6 , the vector @xmath can be written as a
superposition of orthonormal vectors @xmath , that is,

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

where @xmath is a set of size @xmath and where @xmath are coefficients
such that @xmath .

Let now @xmath be fixed. Because @xmath , there exists a permutation
@xmath which maps @xmath to a vector which, on the first @xmath
subsystems, has the form @xmath . We can thus assume without loss of
generality that @xmath , for some @xmath .

Let @xmath be the outcome of the measurement @xmath applied to @xmath
and define @xmath and @xmath . Clearly, @xmath is distributed according
to the product distribution @xmath . Hence, with high probability,
@xmath is a typical sequence, that is, by Corollary B.3.3 ,

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

for any @xmath . Moreover, because @xmath , we can apply the triangle
inequality which gives

  -- -------- --
     @xmath   
  -- -------- --

Using this inequality and the assumption @xmath , ( 4.27 ) implies that

  -- -------- -- --------
     @xmath      (4.28)
  -- -------- -- --------

where we write @xmath to indicate that @xmath is distributed according
to the outcomes of the measurement applied to @xmath and where @xmath is
the subset of @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath , for @xmath , be the linear operators defined by the POVM
@xmath . Then, using Lemma 4.5.1 , ( 4.26 ), and ( 4.28 ) we get

  -- -- --
        
  -- -- --

Hence, with @xmath ,

  -- -- --
        
  -- -- --

The assertion then follows from the fact that @xmath , for any @xmath
with @xmath , and from @xmath . ∎

## Chapter 5 Privacy Amplification

A fundamental problem in cryptography is to distill a secret key from
only partially secret data, on which an adversary might have information
encoded into the state of a quantum system. In this chapter, we propose
a general solution to this problem, which is called privacy
amplification : We show that the key computed as the output of a hash
function (chosen at random from a two-universal ¹ ¹ 1 See Section 5.4
for a definition. family of functions) is secure under the sole
condition that its length is smaller than the adversary’s uncertainty on
the input, measured in terms of (smooth) min-entropy.

We start with the derivation of various technical results (Sections 5.1
– 5.4 ). These are used for the proof of the main statement, which is
first formulated in terms of min-entropy (Section 5.5 ) and then
generalized to smooth min-entropy (Section 5.6 ).

### 5.1 Bounding the norm of hermitian operators

In this section, we derive an upper bound on the trace norm for
hermitian operators (Lemma 5.1.3 ). The bound only involves matrix
multiplications, which makes it easy to evaluate.

###### Lemma 5.1.1.

Let @xmath and @xmath be hermitian operators on @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath and @xmath be spectral decompositions of @xmath and @xmath ,
respectively. With the definition @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

On the other hand, @xmath and @xmath . It thus suffices to show that

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

It is easy to verify that @xmath is a bistochastic matrix. Hence,
according to Birkhoff’s theorem (cf.  Theorem B.2.2 ) there exist
nonnegative coefficients @xmath parameterized by the bijections @xmath
from @xmath to @xmath such that @xmath and, for any @xmath , @xmath ,
@xmath . We thus have

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

Furthermore, by the Cauchy-Schwartz inequality, for any fixed bijection
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

Inserting this into ( 5.2 ) implies ( 5.1 ) and thus concludes the
proof. ∎

###### Lemma 5.1.2.

Let @xmath be a hermitian operator on @xmath and let @xmath be a
nonnegative operator on @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be an eigenbasis of @xmath and let @xmath be a spectral
decomposition of @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, by Lemma 5.1.1 ,

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof. ∎

###### Lemma 5.1.3.

Let @xmath be a hermitian operator on @xmath and let @xmath be a
nonnegative operator on @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The assertion follows directly from Lemma 5.1.2 with @xmath and @xmath ,
that is, @xmath and @xmath . ∎

### 5.2 Distance from uniform

According to the discussion on universal security  in Section 2.2.2 ,
the security of a key is defined with respect to its @xmath -distance
from a perfect key which is uniformly distributed and independent of the
adversary’s state (see ( 2.6 )). This motivates the following
definition.

###### Definition 5.2.1.

Let @xmath . Then the @xmath -distance from uniform of @xmath given
@xmath is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the fully mixed state on @xmath .

For an operator @xmath defined by a classical probability distribution
@xmath , @xmath is the expectation (over @xmath chosen according to
@xmath ) of the @xmath -distance between the conditional distribution
@xmath and the uniform distribution. This property is generalized by the
following lemma.

###### Lemma 5.2.2.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath and let @xmath , for @xmath , be the corresponding
(non-normalized) conditional operators. Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be the fully mixed state on @xmath . Then, by Lemma A.2.2 ,

  -- -------- --
     @xmath   
  -- -------- --

∎

To derive our result on the security of privacy amplification, it is
convenient to consider an alternative measure for the distance from
uniform. Let @xmath and @xmath . The (conditional) @xmath -distance from
uniform of @xmath relative to @xmath is defined by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the fully mixed state on @xmath . Note that @xmath can
equivalently be written as

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

which proves that @xmath cannot be negative.

The @xmath -distance from uniform can be used to bound the @xmath
-distance from uniform.

###### Lemma 5.2.3.

Let @xmath . Then, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The assertion follows directly from Lemma 5.1.3 with @xmath and @xmath ,
where @xmath is the fully mixed state on @xmath . ∎

The following lemma provides an expression for the @xmath -distance from
uniform for the case where the first subsystem is classical.

###### Lemma 5.2.4.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath , let @xmath , for @xmath , be the corresponding (non-normalized)
conditional operators, and let @xmath . Then

  -- -- --
        
  -- -- --

###### Proof.

Let @xmath be the fully mixed state on @xmath . Because @xmath is
classical on @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- --
     @xmath   
  -- -------- --

Hence, since @xmath is an orthonormal basis,

  -- -------- --
     @xmath   
  -- -------- --

where the second equality holds because @xmath . The assertion then
follows from ( 5.3 ). ∎

### 5.3 Collision entropy

Definition 5.3.1 below can be seen as a generalization of the well-known
classical (conditional) collision entropy to quantum states.

###### Definition 5.3.1.

Let @xmath and @xmath . Then the collision entropy of @xmath relative to
@xmath is

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 5.3.2.

It follows immediately from Lemma B.5.3 that

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 5.3.3.

If @xmath is classical with respect to an orthonormal basis @xmath of
@xmath such that the (non-normalized) conditional operators @xmath on
@xmath , for @xmath , are orthogonal then

  -- -- --
        
  -- -- --

### 5.4 Two-universal hashing

###### Definition 5.4.1.

Let @xmath be a family of functions from @xmath to @xmath and let @xmath
be a probability distribution on @xmath . The pair @xmath is called
two-universal if @xmath , for any distinct @xmath and @xmath chosen at
random from @xmath according to the distribution @xmath .

In accordance with the standard literature on two-universal hashing, we
will, for simplicity, assume that @xmath is the uniform distribution on
@xmath . In particular, the family @xmath is said to be two-universal if
@xmath , for @xmath uniform, is two-universal. It is, however, easy to
see that all statements proven below also hold with respect to the
general definition where @xmath is arbitrary.

We will use the following lemma on the existence of two-universal
function families.

###### Lemma 5.4.2.

Let @xmath . Then there exists a two-universal family of hash functions
from @xmath to @xmath .

###### Proof.

For the proof of this statement we refer to [ CW79 ] or [ WC81 ] , where
explicit constructions of hash function families are given. ∎

Consider an operator @xmath which is classical with respect to an
orthonormal basis @xmath of @xmath and assume that @xmath is a function
from @xmath to @xmath . The density operator describing the classical
function output together with the quantum system @xmath is then given by

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

where @xmath is an orthonormal basis of @xmath .

Assume now that the function @xmath is randomly chosen from a family of
functions @xmath according to a probability distribution @xmath . The
function output @xmath , the state of the quantum system, and the choice
of the function @xmath is then described by the operator

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

on @xmath , where @xmath is a Hilbert space with orthonormal basis
@xmath .

The following lemma provides an upper bound on the expected @xmath
-distance from uniform of a key computed by two-universal hashing.

###### Lemma 5.4.3.

Let @xmath be classical on @xmath , let @xmath , and let @xmath be a
two-universal family of hash functions from @xmath to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for @xmath defined by ( 5.4 ) and @xmath chosen uniformly from @xmath .

###### Proof.

Since @xmath is classical on @xmath , we have, according to Lemma 5.2.4
,

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

where @xmath , for @xmath , are the conditional operators defined by (
5.4 ). The first term on the right hand side of ( 5.6 ) can be rewritten
as

  -- -- --
        
  -- -- --

Similarly, for the second term of ( 5.6 ) we find

  -- -------- --
     @xmath   
  -- -------- --

Hence,

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

Because @xmath is chosen at random from a two-universal family of hash
functions from @xmath to @xmath , we have, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Since the trace @xmath of two nonnegative operators @xmath cannot be
negative (cf.  Lemma B.5.2 ) the trace on the right hand side of ( 5.7 )
cannot be negative, for any @xmath . Consequently, when omitting all
terms with @xmath , the sum can only get larger, that is,

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows from Remark 5.3.3 . ∎

### 5.5 Security of privacy amplification

We are now ready to state our main result on privacy amplification in
the context of quantum adversaries. Let @xmath be a string and assume
that an adversary controls a quantum system @xmath whose state is
correlated with @xmath . Theorem 5.5.1 provides a bound on the security
of a key @xmath computed from @xmath by two-universal hashing. The bound
only depends on the uncertainty of the adversary on @xmath , measured in
terms of collision entropy, min-entropy (cf. Corollary 5.5.2 ), or
smooth min-entropy (Corollary 5.6.1 ), where the latter is (nearly)
optimal (see Section 5.6 ).

###### Theorem 5.5.1.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath , let @xmath , and let @xmath be a two-universal family of hash
function from @xmath to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for @xmath defined by ( 5.5 ).

###### Proof.

We use Lemma 5.2.2 to write the @xmath -distance from uniform as an
expectation value,

  -- -------- --
     @xmath   
  -- -------- --

With Lemma 5.2.3 , the term in the expectation can be bounded in terms
of the @xmath -distance from uniform, that is, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where we have used Jensen’s inequality. Finally, we apply Lemma 5.4.3 to
bound the @xmath -distance from uniform in terms of the collision
entropy, which gives

  -- -------- --
     @xmath   
  -- -------- --

###### Corollary 5.5.2.

Let @xmath be classical with respect to an orthonormal basis @xmath of
@xmath and let @xmath be a two-universal family of hash functions from
@xmath to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for @xmath defined by ( 5.5 ).

###### Proof.

The assertion follows directly from Theorem 5.5.1 and Remark 5.3.2 . ∎

### 5.6 Characterization using smooth min-entropy

The characterization of privacy amplification in terms of the collision
entropy or min-entropy is not optimal. ² ² 2 This also holds for the
classical result, as observed in [ BBCM95 ] . In fact, depending on the
probability distribution @xmath of the initial string @xmath , it might
be possible to extract a key whose length exceeds the collision entropy
of @xmath . Because of Remark 5.3.2 , the same problem arises if we
replace the collision entropy by the min-entropy (as in Corollary 5.5.2
). However, as we shall see, the statement of Theorem 5.5.1 still holds
if the uncertainty is measured in terms of smooth min-entropy. That is,
the key generated from @xmath by two-universal hashing is secure if its
length is slightly smaller than roughly @xmath , where @xmath is the
joint state of the initial string @xmath and the adversary’s knowledge.
This is essentially optimal, i.e., @xmath is also an upper bound on the
maximum number of key bits that can be generated from @xmath . ³ ³ 3 To
see this, let @xmath be an arbitrary hash function. It follows from
Lemma 3.1.9 that the smooth min-entropy cannot increase when applying a
function on @xmath , i.e., @xmath . Moreover, it is easy to verify that
the smooth min-entropy of a secret key given the adversary’s information
is roughly equal to its length. Hence, if @xmath is a secret key of
length @xmath , we have @xmath . Combining this with the above gives
@xmath .

###### Corollary 5.6.1.

Let @xmath be a density operator which is classical with respect to an
orthonormal basis @xmath of @xmath , let @xmath be a two-universal
family of hash functions from @xmath to @xmath , and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for @xmath defined by ( 5.5 ).

###### Proof.

Consider an arbitrary operator @xmath and let @xmath be the
corresponding operator defined by ( 5.5 ). Because the @xmath -distance
cannot increase when applying a trace-preserving quantum operation (cf. 
Lemma A.2.1 ), we have @xmath . Hence, by the triangle inequality,

  -- -- --
        
  -- -- --

where @xmath is the fully mixed state on @xmath . Corollary 5.5.2 ,
applied to @xmath , gives

  -- -------- --
     @xmath   
  -- -------- --

Because this holds for any @xmath , the assertion follows by the
definition of smooth min-entropy. ∎

## Chapter 6 Security of QKD

In this chapter, we use the techniques developed in Chapters 3 – 5 to
prove the security of QKD. ¹ ¹ 1 As discussed in Chapter 1 , we actually
consider quantum key distillation , which is somewhat more general than
quantum key distribution (QKD). (The reader is referred to Section 1.6
for a high-level description of the material presented in the following,
including a sketch of the security proof.) Typically, a QKD protocol is
built from several subprotocols, e.g., for parameter estimation,
information reconciliation, or privacy amplification. We first describe
and analyze these subprotocols (Sections 6.2 – 6.4 ) and then put the
parts together to get a general security criterion for quantum key
distillation (Section 6.5 ), which directly implies the security of
quantum key distribution (QKD) (Section 6.6 ).

### 6.1 Preliminaries

#### 6.1.1 Two-party protocols

A protocol @xmath between two parties, Alice and Bob, is specified by a
sequence of operations, called (protocol) steps , to be performed by
each of the parties. In the first protocol step, Alice and Bob might
take (classical or quantum) inputs @xmath and @xmath , respectively
(e.g., some correlated data). In each of the following steps, Alice and
Bob either perform local computations or exchange messages (using a
classical or a quantum communication channel). Finally, in the last
protocol step, Alice and Bob generate outputs @xmath and @xmath ,
respectively (e.g., a pair of secret keys).

We will mostly (except for Section 6.6 ) be concerned with the analysis
of protocols @xmath that only use communication over a classical and
authentic channel. In this case, Alice and Bob’s outputs as well as the
transcript of the communication do not depend on the attack of a
potential adversary. Let @xmath and @xmath be the density operators
describing Alice and Bob’s inputs @xmath and @xmath as well as their
outputs @xmath and @xmath together with the communication transcript
@xmath , respectively. The mapping that brings @xmath to @xmath , in the
following denoted by @xmath , is then uniquely defined by the protocol
@xmath . Moreover, because it must be physically realizable, @xmath is a
CPM (see Section 2.1.1 ).

To analyze the security of a protocol @xmath , we need to include Eve’s
information in our description. Let @xmath be the state of Alice and
Bob’s inputs as well as Eve’s initial information. Similarly, let @xmath
be the state of Alice and Bob’s outputs together with Eve’s information
after the protocol execution. As Eve might get a transcript @xmath of
the messages sent over the classical channel, the CPM that maps @xmath
to @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

#### 6.1.2 Robustness of protocols

Depending on its input, a protocol might be unable to produce the
desired output. For example, if a key distillation protocol starts with
uncorrelated randomness, it cannot generate a pair of secret keys. In
this case, the best we can hope for is that the protocol recognizes this
situation and aborts ² ² 2 Technically, the protocol might output a
certain predefined symbol which indicates that it is unable to
accomplish the task. (instead of generating an insecure result).

Clearly, one is interested in designing protocols that are successful on
certain inputs. This requirement is captured by the notion of robustness
.

###### Definition 6.1.1.

Let @xmath be a two-party protocol and let @xmath . We say that @xmath
is @xmath -robust on @xmath if, for inputs defined by @xmath , the
probability that the protocol aborts is at most @xmath .

Mathematically, we represent the state that describes the situation
after an abortion of the protocol as a zero operator. The CPM @xmath (as
defined in Section 6.1.1 ) is then a projection onto the space that
represents the outputs of successful protocol executions (i.e., where it
did not abort). The probability that the protocol is successful when
starting with an initial state @xmath is thus equal to the trace @xmath
of the operator @xmath . In particular, if @xmath is @xmath -robust on a
density operator @xmath then @xmath .

#### 6.1.3 Security definition for key distillation

A (quantum) key distillation protocol @xmath is a two-party protocol
with classical communication where Alice and Bob take inputs from @xmath
and @xmath , respectively, and either output classical keys @xmath ,
where @xmath is called the key space of @xmath , or abort the protocol.

###### Definition 6.1.2.

Let @xmath be a key distillation protocol and let @xmath . We say that
@xmath is @xmath -secure on @xmath if @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , for some family @xmath of orthonormal vectors
representing the values of the key space @xmath .

Moreover, we say that @xmath is @xmath -fully secure if it is @xmath
-secure on all density operators @xmath .

According to the discussion on universal security in Section 2.2.2 , ³ ³
3 If a key @xmath is @xmath -secure, one could define a perfectly secure
(independent and uniformly distributed) key @xmath such that @xmath (see
also Proposition 2.1.1 ). this definition has a very intuitive
interpretation: If the protocol is @xmath -fully secure then, for any
arbitrary input, the probability of the event that Alice and Bob do not
abort and the adversary gets information on the key pair ⁴ ⁴ 4 According
to Footnote 3 , one could say that the adversary gets information on a
key @xmath whenever the value of @xmath is not equal to the value of a
perfect key @xmath . is at most @xmath . ⁵ ⁵ 5 Note that the adversary’s
information on the key, conditioned on the event that Alice and Bob
generate a key, is not necessarily small. In fact, if, for a certain
input, the probability that Alice and Bob generate a key is very small
(e.g., smaller than @xmath ) then—conditioned on this rare event—the key
might be insecure (see also the discussion in [ BBB @xmath 05 ] ). In
other words, except with probability @xmath , Alice and Bob either abort
or generate a pair of keys which are identical to a perfect key.

###### Remark 6.1.3.

The above security definition for key distillation protocols @xmath can
be subdivided into two parts:

-   @xmath -correctness: @xmath , ⁶ ⁶ 6 @xmath is the probability of the
    event that Alice and Bob do not abort and the generated keys @xmath
    and @xmath are different. for @xmath and @xmath chosen according to
    the distribution defined by @xmath .

-   @xmath -secrecy of Alice’s key: @xmath . ⁷ ⁷ 7 See Definition 5.2.1
    .

In particular, if @xmath is @xmath -correct and @xmath -secret on @xmath
then it is @xmath -secure on @xmath .

### 6.2 Parameter estimation

The purpose of a parameter estimation is to decide whether the input
given to the protocol can be used for a certain task, e.g. to distill a
secret key. Technically, a parameter estimation protocol @xmath is
simply a two-party protocol where Alice and Bob take inputs from @xmath
and @xmath , respectively, and either output “accept” or abort the
protocol.

###### Definition 6.2.1.

Let @xmath be a parameter estimation protocol and let @xmath . We say
that @xmath @xmath -securely filters @xmath if, on input @xmath , the
protocol aborts except with probability @xmath .

Parameters:
@xmath : bipartite POVM @xmath on @xmath @xmath : set of frequency
distributions on @xmath {protocol} AliceBob \protno input space: @xmath
input space: @xmath
\protleftright @xmath meas. @xmath @xmath
@xmath \protno if @xmath
@xmath then abort
@xmath else output “acc.”

Fig. 6.1 Parameter estimation protocol @xmath .

A typical and generic example for parameter estimation is the protocol
@xmath depicted in Fig. 6.1 . Alice and Bob take inputs from an @xmath
-fold product space. Then they measure each of the @xmath subspaces
according to a POVM @xmath . ⁸ ⁸ 8 @xmath might be an arbitrary
measurement that can be performed by two distant parties connected by a
classical channel. Finally, they output “accept” if the frequency
distribution @xmath of the measurement outcomes @xmath is contained in a
certain set @xmath .

For the analysis of this protocol, it is convenient to consider the set
@xmath of density operators @xmath for which the measurement @xmath
leads to a distribution which has distance at most @xmath to the set
@xmath . Formally,

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

where @xmath denotes the probability distribution of the outcomes when
measuring @xmath according to @xmath , i.e., @xmath , for any @xmath .

Assume that the protocol @xmath takes as input a product state @xmath .
Then, by the law of large numbers, the measurement statistics @xmath
must be close to @xmath . In particular, if the protocol accepts with
non-negligible probability (i.e., @xmath is contained in @xmath ) then
@xmath is likely to be contained in @xmath , for some small @xmath . In
other words, the protocol aborts with high probability if @xmath is not
an element of the set @xmath . The following lemma generalizes this
statement to permutation-invariant inputs.

###### Lemma 6.2.2.

Let @xmath be a POVM on @xmath , let @xmath be a set of frequency
distributions on @xmath , let @xmath , and let @xmath . Moreover, let
@xmath and let @xmath be a density operator on @xmath . If @xmath is not
contained in the set @xmath defined by ( 6.1 ), for

  -- -------- --
     @xmath   
  -- -------- --

then the protocol @xmath defined by Fig. 6.1 @xmath -securely filters
@xmath .

###### Proof.

The assertion follows directly from Theorem 4.5.2 . ∎

Similarly to ( 6.1 ), we can define a set @xmath containing all density
operators @xmath for which the measurement @xmath leads to a
distribution which has distance at least @xmath to the complement of
@xmath . Formally,

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

Analogously to the above argument, one can show that the protocol @xmath
defined by Fig. 6.1 is @xmath -robust on product operators @xmath , for
any @xmath .

### 6.3 Information reconciliation

Assume that Alice and Bob hold weakly correlated classical values @xmath
and @xmath , respectively. The purpose of an information reconciliation
protocol is to transform @xmath and @xmath into a pair of fully
correlated strings, while leaking only a minimum amount of information
(on the final strings) to an eavesdropper (see, e.g., [ BS94 ] ).

#### 6.3.1 Definition

We focus on information reconciliation schemes where Alice keeps her
input value @xmath and where Bob outputs a guess @xmath for @xmath .
Hence, technically, an information reconciliation protocol @xmath is a
two-party protocol where Alice and Bob take classical inputs @xmath and
@xmath , respectively, and where Bob outputs a classical value @xmath or
aborts.

###### Definition 6.3.1.

Let @xmath and let @xmath . We say that an information reconciliation
protocol @xmath is @xmath -secure on @xmath if, for inputs @xmath and
@xmath chosen according to @xmath , the probability that Bob’s output
@xmath differs from Alice’s input @xmath is at most @xmath , i.e.,
@xmath . ⁹ ⁹ 9 We denote by @xmath the probability of the event that the
protocol does not abort and @xmath is different from @xmath .

Moreover, we say that @xmath is @xmath -fully secure if it is @xmath
-secure on all probability distributions @xmath .

The communication transcript of an information reconciliation scheme
@xmath generally contains useful information on Alice and Bob’s values.
If the communication channel is insecure, this information might be
leaked to Eve. Clearly, in the context of key agreement, one is
interested in information reconciliation schemes for which this leakage
is minimal.

###### Definition 6.3.2.

Let @xmath be an information reconciliation protocol where Alice and Bob
take inputs from @xmath and @xmath , respectively. Let @xmath be the set
of all possible communication transcripts @xmath and let @xmath be the
distribution of the transcripts @xmath conditioned on inputs @xmath .
Then the leakage of @xmath is

  -- -------- --
     @xmath   
  -- -------- --

where the infimum ranges over all @xmath .

Note that the leakage is independent of the actual distribution @xmath
of Alice and Bob’s values.

#### 6.3.2 Information reconciliation with minimum leakage

A typical information reconciliation protocol is the protocol @xmath
defined by Fig. 6.2 . It is a so-called one-way protocol where only
Alice sends messages to Bob. We show that the leakage of this protocol,
for appropriately chosen parameters, is roughly bounded by the
max-entropy of @xmath given @xmath (Lemma 6.3.3 ). This statement can be
extended to smooth max-entropy (Lemma 6.3.4 ), which turns out to be
optimal, i.e., the minimum leakage of an information reconciliation
protocol for @xmath is exactly characterized by @xmath . In particular,
for the special case where the input is chosen according to a product
distribution, we get an asymptotic expression in terms of Shannon
entropy (Corollary 6.3.5 ), which corresponds to the Shannon coding
theorem.

Parameters:
@xmath : family of sets @xmath parameterized by @xmath . @xmath : family
of hash functions from @xmath to @xmath .

{protocol}

AliceBob \protno input: @xmath input: @xmath
\protright @xmath
@xmath @xmath @xmath
@xmath \protno if @xmath
@xmath then @xmath
@xmath else @xmath \protno output @xmath

Fig. 6.2 Information reconciliation protocol @xmath .

###### Lemma 6.3.3.

Let @xmath and let @xmath . Then the information reconciliation protocol
@xmath defined by Fig. 6.2 , for an appropriate choice of the parameters
@xmath and @xmath , is @xmath -robust on @xmath , @xmath -fully secure,
and has leakage

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath and let @xmath be a two-universal family of hash functions
from @xmath to @xmath (which exists according to Lemma 5.4.2 ).
Furthermore, let @xmath be the family of sets defined by @xmath , where
@xmath denotes the support of the function @xmath .

For any pair of inputs @xmath and @xmath and for any communication
@xmath computed by Alice, Bob can only output a wrong value if the set
@xmath contains an element @xmath such that @xmath . Because @xmath is
chosen uniformly at random from the family of two-universal hash
functions @xmath , we have @xmath , for any @xmath . Hence, by the union
bound, for any fixed @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Because, by Remark 3.1.4 , @xmath , we conclude

  -- -------- --
     @xmath   
  -- -------- --

that is, @xmath is @xmath -secure on any probability distribution.

Moreover, if @xmath is chosen according to the distribution @xmath ,
then, clearly, @xmath is always contained in @xmath , that is, Bob never
aborts. This proves that the protocol is @xmath -robust.

Since @xmath is chosen uniformly at random and independently of @xmath
from the family of hash-functions @xmath , all nonzero probabilities of
the distribution @xmath are equal to @xmath . Hence, using the fact that
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The claimed bound on the leakage then follows by the definition of
@xmath . ∎

###### Lemma 6.3.4.

Let @xmath and let @xmath . Then the information reconciliation protocol
@xmath defined by Fig. 6.2 , for an appropriate choice of the parameters
@xmath and @xmath , is @xmath -robust on @xmath , @xmath -fully secure,
and has leakage

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For any @xmath there exists @xmath such that

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

According to Lemma 6.3.3 , there exists @xmath and @xmath such that
@xmath is @xmath -fully secure, @xmath -robust on @xmath , and has
leakage

  -- -------- --
     @xmath   
  -- -------- --

The stated bound on the leakage follows immediately from this inequality
and ( 6.4 ). Moreover, the bound on the robustness is a direct
consequence of the bound ( 6.3 ) and the fact that the protocol is
@xmath -robust on @xmath . ∎

###### Corollary 6.3.5.

Let @xmath be a probability distribution, let @xmath , and let @xmath .
Then there exists an information reconciliation protocol @xmath which is
@xmath -fully secure, @xmath -robust on the product distribution @xmath
, and has leakage

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Using Lemma 6.3.4 (with @xmath ) and Theorem 3.3.4 , we find

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath and @xmath . The last two terms on the right hand side of
this inequality are then upper bounded by @xmath , which holds because
@xmath . We can assume without loss of generality that @xmath
(otherwise, the statement is trivial). Then @xmath . The last two terms
in the above inequality are thus bounded by @xmath , which concludes the
proof. ∎

For practical applications, we are interested in protocols where Alice
and Bob’s computations can be done efficiently (e.g., in time that only
depends polynomially on the length of their inputs). This is, however,
not necessarily the case for the information reconciliation protocol
@xmath described above. While Alice’s task, i.e., the evaluation of the
hash function, can be done in polynomial time, ¹⁰ ¹⁰ 10 Recall that
Alice only has to evaluate a function which is randomly chosen from a
two-universal family of functions. For most known constructions of such
families (see, e.g., [ CW79 , WC81 ] ), this can be done efficiently. no
efficient algorithm is known for the decoding operation of Bob.
Nevertheless, based on a specific encoding scheme, one can show that
there exist information reconciliation protocols which only require
polynomial-time computations and for which the statement of Corollary
6.3.5 (asymptotically) still holds (see Appendix C ).

### 6.4 Classical post-processing

Classical post-processing is used to transform an only partially secure
¹¹ ¹¹ 11 That is, @xmath and @xmath are only weakly correlated and
partially secret strings. pair of raw keys @xmath and @xmath held by
Alice and Bob, respectively, into a fully secure key pair. A classical
post-processing protocol is thus actually a key distillation protocol
that starts with classical randomness.

In this section, we analyze the security of the generic post-processing
protocol depicted in Fig. 6.3 . It consists of an information
reconciliation subprotocol (see Section 6.3 ) followed by privacy
amplification (see Chapter 5 ).

Parameters:
@xmath : information reconciliation protocol. @xmath : family of hash
functions from @xmath to @xmath . {protocol} AliceBob \protno input:
@xmath input: @xmath
\protleftright @xmath @xmath @xmath
\protright @xmath @xmath \protno output @xmath output @xmath

Fig. 6.3 Classical post-processing protocol @xmath .

###### Lemma 6.4.1.

Let @xmath be an information reconciliation protocol and let @xmath be a
two-universal family of hash functions from @xmath to @xmath .
Additionally, let @xmath be a density operator which is classical on
@xmath and let @xmath . If @xmath is @xmath -secure on the distribution
defined by @xmath and if

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , then the key distillation protocol @xmath defined by Fig.
6.3 is @xmath -secure on @xmath .

###### Proof.

For simplicity, we assume in the following that the protocol @xmath is
one-way. It is straightforward to generalize this argument to arbitrary
protocols.

Note first that the keys @xmath and @xmath generated by Alice and Bob
can only differ if @xmath . Hence, because the information
reconciliation protocol @xmath is @xmath -secure on the distribution
defined by @xmath , the classical post-processing protocol @xmath is
@xmath -correct on @xmath . According to Remark 6.1.3 , it thus remains
to show that Alice’s key is @xmath -secret.

For this, we use the result on the security of privacy amplification by
two-universal hashing presented in Chapter 5 . Because @xmath is chosen
from a two-universal family of hash functions, Corollary 5.6.1 implies
that the key computed by Alice is @xmath -secret if

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

where @xmath is the operator describing the situation after the
execution of the information reconciliation protocol @xmath (where
@xmath is the transcript of @xmath ). It thus suffices to verify that
the bound on the entropy ( 6.5 ) holds.

Using the chain rule (cf. ( 3.21 ) of Theorem 3.2.12 ), the left hand
side of ( 6.5 ) can be bounded by

  -- -------- --
     @xmath   
  -- -------- --

Moreover, because the communication @xmath is computed only from @xmath
, the conditional operators @xmath have product form and thus (cf. (
3.22 ) of Theorem 3.2.12 )

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

Using the fact that @xmath and Lemma 3.1.8 , the last two terms in the
above expression can be bounded by

  -- -------- --
     @xmath   
  -- -------- --

where, for any @xmath , @xmath is the normalized conditional operator
defined by @xmath . Hence, by the definition of leakage,

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 6.6 ), we find

  -- -------- --
     @xmath   
  -- -------- --

which, by the assumption on the length of the final key @xmath ,
implies ( 6.5 ) and thus concludes the proof. ∎

### 6.5 Quantum key distillation

We are now ready to describe and analyze a general quantum key
distillation protocol, which uses parameter estimation and classical
post-processing as discussed above. (For a high-level description of the
content of this section, we refer to Section 1.6 .)

#### 6.5.1 Description of the protocol

Parameters:
@xmath : parameter estimation protocol on @xmath . @xmath : subprotocol
on @xmath with classical output in @xmath . @xmath : classical
post-processing protocol on @xmath . @xmath : Number of input systems (
@xmath ) {protocol} AliceBob \protno input space: @xmath input space:
@xmath
\protright @xmath @xmath \protno permute subsyst.permute subsyst.
\protleftright @xmath @xmath @xmath
@xmath
\protleftright @xmath
@xmath @xmath @xmath
@xmath )
\protleftright @xmath @xmath @xmath
\protno output @xmath output @xmath

Fig. 6.4 Quantum key distillation protocol @xmath .

  -------- ----------------------------------------------------
  @xmath   prot. on @xmath defined by Fig. 6.1
  @xmath   POVM on @xmath
  @xmath   set of freq. dist. on @xmath
  @xmath   prot. on @xmath with cl. output in @xmath
  @xmath   prot. on @xmath defined by Fig. 6.3
  @xmath   inf. rec. prot. on @xmath
  @xmath   two-univ. fam. of hash func. from @xmath to @xmath
  -------- ----------------------------------------------------

Table 6.1 Subprotocols used for @xmath (cf. Fig. 6.4 ).

Consider the quantum key distillation protocol @xmath depicted in Fig.
6.4 . Alice and Bob take inputs from product spaces @xmath and @xmath ,
respectively. Then, they subsequently run the following subprotocols
(see also Table 6.1 ):

-   Random permutation of the subsystems: Alice and Bob reorder their
    subsystems according to a commonly chosen random permutation @xmath
    .

-   Parameter estimation ( @xmath ): Alice and Bob sacrifice @xmath
    subsystems to perform some statistical checks. We assume that they
    do this using a protocol of the form @xmath (see Fig. 6.1 ), which
    is characterized by a POVM @xmath on @xmath and a set @xmath of
    valid frequency distributions on @xmath .

-   Block-wise measurement and processing ( @xmath ): In order to obtain
    classical data, Alice and Bob apply a measurement to the remaining
    @xmath subsystems, possibly followed by some further processing
    (e.g., advantage distillation). We assume here that Alice and Bob
    group their @xmath subsystems in @xmath blocks of size @xmath and
    then process each of these blocks independently, according to some
    subprotocol, denoted @xmath . Each application of @xmath to a block
    @xmath results in a pair of classical outputs @xmath and @xmath .

-   Classical post-processing ( @xmath ): Alice and Bob transform their
    classical strings @xmath and @xmath into a pair of secret keys. For
    this, they invoke a post-processing subprotocol of the form @xmath
    (see Fig. 6.3 ), for some (arbitrary) information reconciliation
    scheme @xmath and a two-universal family of hash functions @xmath
    for privacy amplification.

#### 6.5.2 Robustness

The usefulness of a key distillation protocol depends on the set of
inputs for which it is robust, i.e., from which it can successfully
distill secret keys. Obviously, the described protocol @xmath is robust
on all inputs for which none of its subprotocols @xmath , @xmath , or
@xmath aborts. Note that the post-processing @xmath only aborts if the
underlying information reconciliation scheme @xmath aborts.

Typically, the subprotocols @xmath and @xmath are chosen in such a way
that they are robust on any of the input states accepted by @xmath . In
this case, the key distillation protocol @xmath is successful whenever
it starts with an input for which @xmath is robust. According to the
discussion in Section 6.2 , the protocol @xmath is robust on product
states @xmath if @xmath is contained in the set @xmath defined by ( 6.2
). Consequently, @xmath is robust on all inputs of the form @xmath , for
@xmath .

#### 6.5.3 Security

The following is a generic criterion for the security of QKD.

###### Theorem 6.5.1.

Let @xmath be the quantum key distillation protocol defined by Fig. 6.4
and Table 6.1 , let @xmath , let @xmath , @xmath be defined by Table 6.2
, and let @xmath be defined by ( 6.1 ). Then @xmath is @xmath -fully
secure if the underlying information reconciliation protocol @xmath is
@xmath -fully secure and if

  -- -------- --
     @xmath   
  -- -------- --

where the entropy in the minimum is evaluated on

  -- -------- --
     @xmath   
  -- -------- --

for a purification @xmath of @xmath .

  -------- --------
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  -------- --------

Table 6.2 Security parameters for @xmath (cf. Fig. 6.4 ).

###### Proof.

Let @xmath be any state held by Alice and Bob after they have applied
the random permutation @xmath (averaged over all possible choices of
@xmath ). Because, obviously, @xmath is permutation-invariant, Lemma
4.2.2 implies that there exists a purification @xmath of @xmath on the
symmetric subspace of @xmath . We show that the remaining part of the
protocol is secure on @xmath . This is sufficient because any density
operator @xmath which has the property that taking the partial trace
over @xmath gives @xmath can be obtained from the pure state @xmath by a
trace-preserving CPM which only acts on Eve’s space.

Let @xmath be the operator obtained by taking the partial trace (over
@xmath subsystems @xmath ) of @xmath . It describes the joint state on
the @xmath subsystems used for parameter estimation and the @xmath
subsystems which are given as input to @xmath . According to the de
Finetti representation theorem (Theorem 4.3.2 ) this density operator is
approximated by a convex combination of density operators, where each of
them is on the symmetric subspace along vectors @xmath . More precisely,
with @xmath ,

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

where the integral runs over the set @xmath of normalized vectors in
@xmath and where, for any @xmath ,

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

We first analyze the situation after the parameter estimation is
completed. Let @xmath be the CPM which maps all density operators on
@xmath either to the scalar @xmath or @xmath , depending on whether the
parameter estimation protocol @xmath accepts or aborts. Moreover, define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Because of ( 6.8 ), we have

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

for any @xmath . Moreover, from ( 6.7 ) and the fact that the @xmath
-distance cannot increase when applying a quantum operation (Lemma A.2.1
) we have

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

According to Lemma 6.2.2 , the parameter estimation @xmath @xmath
-securely filters all states @xmath for which @xmath is not contained in
the set

  -- -------- --
     @xmath   
  -- -------- --

We can thus restrict the integral in ( 6.10 ) to the set @xmath ,
thereby only losing terms with total weight at most @xmath , i.e.,

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

To describe the situation after the measurement and blockwise processing
@xmath , we define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Using once again the fact that the @xmath -distance cannot decrease
under quantum operations (Lemma A.2.1 ), we conclude from ( 6.11 ) that

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

According to ( 6.9 ), the density operator @xmath lies in the symmetric
subspace of the @xmath -fold product space @xmath along @xmath , i.e.,
it has product form except on @xmath subsystems. Equivalently, we can
view @xmath as a density operator on the @xmath -fold product of
subsystems @xmath . It then has product form an all but (at most) @xmath
of these subsystems. That is, @xmath is contained in the symmetric
subspace of @xmath along @xmath , where @xmath . This allows us to apply
Theorem 4.4.1 in order to bound the entropy of the symmetric states
@xmath . With the definition

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , we obtain

  -- -------- --
     @xmath   
  -- -------- --

Consequently, using ( 6.12 ) together with the inequalities ( 3.19 )
and ( 3.20 ) of Theorem 3.2.12 ,

  -- -------- --
     @xmath   
  -- -------- --

Moreover, by the chain rule for smooth min-entropy (cf. ( 3.21 ) of
Theorem 3.2.12 )

  -- -------- --
     @xmath   
  -- -------- --

Finally, we use Lemma 6.4.1 which provides a criterion on the maximum
length @xmath such that the secret key computed by the post-processing
subprotocol @xmath is @xmath -secure,

  -- -- --
        
  -- -- --

The assertion then follows from

  -- -------- --
     @xmath   
  -- -------- --

the fact that @xmath if and only if the trace @xmath of @xmath is
contained in the set @xmath , and the definition of @xmath (cf. Table
6.2 ). ∎

Note that the protocol @xmath takes as input @xmath subsystems and
generates a key of a certain fixed length @xmath . In order to make
asymptotic statements, we need to consider a family @xmath of such
protocols, where, for any @xmath , the corresponding protocol takes
@xmath input systems and generates a key of length @xmath . The rate of
the protocol family is then defined by

  -- -------- --
     @xmath   
  -- -------- --

###### Corollary 6.5.2.

Let @xmath , a protocol @xmath acting on blocks of length @xmath , a
POVM @xmath , and a set @xmath of probability distributions on @xmath be
fixed, and let @xmath be the set defined by ( 6.1 ). Then there exist
@xmath and parameters @xmath such that the class of protocols @xmath
(parameterized by @xmath ) defined by Fig. 6.4 and Table 6.1 has rate

  -- -------- --
     @xmath   
  -- -------- --

where the entropies in the minimum are evaluated on

  -- -------- --
     @xmath   
  -- -------- --

for a purification @xmath of @xmath . Moreover, for any @xmath , the
protocol @xmath is @xmath -fully secure.

###### Proof.

The statement follows directly from Theorem 6.5.1 combined with
Corollary 6.3.5 . ∎

### 6.6 Quantum key distribution

As described in Section 1.2 , one can think of a quantum key
distribution (QKD) protocol as a two-step process where Alice and Bob
first use the quantum channel to distribute entanglement and then apply
a quantum key distillation scheme to generate the final key pair. To
prove security of a QKD protocol, it thus suffices to verify that the
underlying key distillation protocol is secure on any input. Hence, the
security results for key distillation protocols derived in the previous
section (Theorem 6.5.1 and Corollary 6.5.2 ) directly apply to QKD
protocols.

We can, however, further improve these results by taking into account
that the way Alice and Bob use the quantum channel in the first step
imposes some additional restrictions on the possible inputs to the
distillation protocol. For example, if Alice locally prepares entangled
states and then sends parts of them to Bob (note that this is actually
the case for most QKD protocols, viewed as entanglement-based schemes),
it is impossible for the adversary to tamper with the part belonging to
Alice. Formally, this means that the partial state on Alice’s subsystem
is independent of Eve’s attack.

Using this observation, we can restrict the set @xmath of states @xmath
(as defined by ( 6.1 )) over which the minimum is taken in the criterion
of Theorem 6.5.1 and Corollary 6.5.2 . In fact, it follows directly from
Remark 4.3.3 that it suffices to consider states @xmath such that @xmath
is fixed.

## Chapter 7 Examples

To illustrate the general results of the previous chapter, we analyze
certain concrete QKD protocols. We first specialize the formula for the
rate (cf.  Corollary 6.5.2 ) to protocols based on two-level quantum
systems (Section 7.1 ). Then, as an example, we analyze different
variants of the six-state protocol and compute explicit values for their
rates (Section 7.2 ).

### 7.1 Protocols based on two-level systems

A large class of QKD protocols, including the well-known BB84 protocol
or the six-state protocol, are based on an encoding of binary classical
values using the state of a two-level quantum system, such as the the
spin of a photon. For the corresponding key distillation protocol (see
Fig. 6.4 ), this means that Alice and Bob take inputs from (products of)
two-dimensional Hilbert spaces on which they apply binary measurements.
In the following, we analyze different variants of such protocols.

#### 7.1.1 One-way protocols

We start with a basic key distillation protocol which only uses
information reconciliation and privacy amplification (as described in
Section 6.4 ) to transform the raw key pair into a pair of secret keys.
More precisely, after the measurement of their subsystems, Alice and Bob
immediately invoke an information reconciliation protocol (e.g., the
protocol @xmath depicted in Fig. 6.2 ) such that Bob can compute a guess
of Alice’s values; the final key is then obtained by two-universal
hashing. Because this post-processing only requires communication from
Alice to Bob, such protocols are also called one-way key distillation
protocols . ¹ ¹ 1 Note, however, that bidirectional communication is
always needed for the parameter estimation step.

Clearly, the one-way key distillation protocol described above is a
special case of the general protocol @xmath depicted in Fig 6.4 , where
@xmath is the subprotocol describing the measurement operation of Alice
and Bob. Additionally, assume that the parameter estimation subprotocol
@xmath is the protocol @xmath depicted in Fig. 6.1 , where @xmath is a
POVM and @xmath is the set of statistics for which the protocol does not
abort. We can then use Corollary 6.5.2 to compute the rate of the
protocol, that is,

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

Here, the minimum ranges over the set

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

of all density operators @xmath on the @xmath -dimensional Hilbert space
@xmath such that the measurement with respect to @xmath gives a
probability distribution @xmath which is contained in the set @xmath .
Moreover, the von Neumann (or Shannon) entropies @xmath and @xmath are
evaluated for the operators

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a purification of @xmath .

Let @xmath and @xmath be the bases that Alice and Bob use for the
measurement @xmath . ² ² 2 @xmath describes the measurement that
generates the data used for the computation of the final key. It might
be different from the measurement @xmath which is used for parameter
estimation. Lemma 7.1.1 below provides an explicit lower bound on the
entropy difference on the right hand side of ( 7.1 ) as a function of
@xmath . The bound only depends on the diagonal values of @xmath with
respect to the Bell basis , which is defined by the vectors

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath .

###### Lemma 7.1.1.

Let both @xmath and @xmath be two-dimensional Hilbert spaces, let @xmath
be a density operator, and let @xmath be obtained from @xmath by
applying orthonormal measurements on @xmath and @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are the diagonal values of @xmath with respect to the Bell
basis (defined relative to the measurement basis).

###### Proof.

Let @xmath be the CPM defined by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are the Pauli operators

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

and let @xmath be a purification of @xmath . Moreover, let @xmath be an
arbitrary purification of @xmath with auxiliary system @xmath and define

  -- -------- --
     @xmath   
  -- -------- --

A straightforward calculation shows that the operator @xmath has the
form

  -- -------- --
     @xmath   
  -- -------- --

i.e., it is diagonal with respect to the Bell basis. Moreover, because
@xmath commutes with the measurement operation on @xmath , it is easy to
verify that the entropy @xmath evaluated for @xmath is upper bounded by
the corresponding entropy for @xmath . Similarly, because @xmath is a
purification of @xmath , the entropy @xmath evaluated for @xmath is
lower bounded by the entropy of @xmath . It thus suffices to show that
the inequality of the lemma holds for the operator @xmath , which is
obtained from the diagonal operator @xmath .

Let @xmath be an orthonormal basis of a @xmath -dimensional Hilbert
space @xmath . Then the operator @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

is a purification of @xmath . With the definition

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

the state @xmath can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

Because the operator @xmath is obtained from @xmath by orthonormal
measurements on @xmath and @xmath , we conclude

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

Using this representation of the operator @xmath , it is is easy to see
that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

from which the assertion follows. ∎

Using Lemma 7.1.1 , we conclude that the above described one-way
protocol can generate secret-key bits at rate

  -- -- -- -------
           (7.4)
  -- -- -- -------

where @xmath denotes the @xmath -tuples of diagonal entries (relative to
the Bell basis) of the operators @xmath , for @xmath defined by ( 7.2 ).

#### 7.1.2 One-way protocols with noisy preprocessing

The efficiency of the basic QKD protocol described in Section 7.1.1 can
be increased in different ways. We consider an extension of the protocol
where, before starting with information reconciliation, Alice applies
some local preprocessing operation to her raw key. A very simple—but
surprisingly useful—variant of preprocessing is to add noise, i.e.,
Alice flips each of her bits independently with some probability @xmath
. In the following, we call this noisy preprocessing .

To compute the rate of the one-way protocol enhanced with this type of
preprocessing, we need a generalization of Lemma 7.1.1 .

###### Lemma 7.1.2.

Let both @xmath and @xmath be two-dimensional Hilbert spaces, let @xmath
be a density operator, and let @xmath be obtained from @xmath by
applying orthonormal measurements on @xmath and @xmath where,
additionally, the outcome of the measurement on @xmath is flipped with
probability @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , @xmath , @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The statement follows by a straightforward extension of the proof of
Lemma 7.1.1 . ∎

Similarly to formula ( 7.4 ), the rate of the one-way protocol with
noisy preprocessing—where Alice additionally flips her bits with
probability @xmath —is given by the expression provided by Lemma 7.1.2 ,
minimized over all @xmath -tuples @xmath . It turns out that this rate
is generally larger than the rate of the corresponding one-way protocol
without preprocessing (see Section 7.2 below).

#### 7.1.3 Protocols with advantage distillation

To further increase the efficiency of the key distillation protocol
described above, one might insert an additional advantage distillation
step after the measurement @xmath , i.e., before the classical one-way
post-processing. ³ ³ 3 The concept of advantage distillation has first
been introduced in a purely classical context [ Mau93 ] , where a secret
key is generated from some predistributed correlated data. Its purpose
is to identify subsets of highly correlated bit pairs such as to
separate these from only weakly correlated information.

Parameters:
@xmath : block length {protocol} AliceBob \protno input: @xmath input:
@xmath
\protno @xmath \protright @xmath
@xmath @xmath if @xmath
@xmath
@xmath then @xmath \protleft @xmath \protno if @xmath
@xmath then output @xmath
@xmath else output @xmath if @xmath
@xmath then output @xmath
@xmath else output @xmath

Fig. 7.1 Advantage distillation protocol @xmath .

A typical advantage distillation protocol is depicted in Fig. 7.1 :
Alice and Bob split their bitstrings into blocks @xmath and @xmath of
size @xmath . Then, depending on a randomly chosen binary value @xmath ,
Alice announces to Bob either @xmath or @xmath (where @xmath denotes the
bitwise xor). Bob compares this information with his block @xmath and
accepts if it either differs in none or in all positions, i.e., if the
difference equals either @xmath or @xmath . In this case, Alice and Bob
both keep the first bit of their initial string. Otherwise, they output
some dummy symbol @xmath . ⁴ ⁴ 4 As suggested in [ Mau93 ] , the
efficiency of this advantage distillation protocol is further increased
if Alice and Bob, instead of acting on large blocks at once, iteratively
repeat the described protocol step on very small blocks (consisting of
only @xmath or @xmath bits). Obviously, if the error probability per bit
(i.e., the error rate of the channel) is @xmath then the probability
@xmath that advantage distillation on a block of length @xmath is
successful (i.e., Alice and Bob keep their bit) is @xmath .

Let us now consider the general protocol @xmath where the subprotocol
@xmath consists of @xmath binary measurements @xmath of Alice and Bob
followed by the advantage distillation protocol @xmath described in Fig.
7.1 , i.e.,

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

It is easy to see that the subprotocol @xmath commutes with the
measurement @xmath , that is, ( 7.5 ) can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

Moreover, a straightforward computation ⁵ ⁵ 5 For this computation, it
is convenient to use the mapping @xmath defined above, which allows to
restrict the argument to the special case where @xmath is Bell diagonal.
shows that, if @xmath has diagonal entries @xmath with respect to the
Bell basis then, with probability

  -- -------- --
     @xmath   
  -- -------- --

the advantage distillation @xmath is successful and the operation @xmath
induced by @xmath (conditioned on the event that it is successful) maps
@xmath to an operator @xmath with diagonal entries

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Inserting these coefficients into the expressions provided by Lemma
7.1.1 gives a bound on the entropy difference which can be inserted into
the formula for the rate ( 7.1 ). ⁶ ⁶ 6 Note that, conditioned on the
event that @xmath is not successful (i.e., Alice and Bob’s outputs are
@xmath ), the entropy difference is zero. We conclude that the key
distillation protocol enhanced with advantage distillation on blocks of
length @xmath can generate key bits at rate

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

where @xmath is the set defined by ( 7.2 ). Note that, in the special
case where the block size @xmath equals @xmath , the advantage
distillation is trivial, that is, @xmath , and ( 7.6 ) reduces to ( 7.4
).

Similarly to the discussion in Section 7.1.2 , one might enhance the
protocol with noisy preprocessing on Alice’s side, i.e., Alice flips her
bits with some probability @xmath after the advantage distillation step.
The rate is then given by a formula similar to ( 7.6 ), where the
expression in the minimum is replaced by the bound on the entropy
difference provided by Lemma 7.1.2 , evaluated for the coefficients
@xmath .

Note that, as the block size @xmath increases, the coefficients @xmath
and @xmath approach zero, while @xmath and @xmath both tend to @xmath .
To get an approximation, it is thus sufficient to evaluate the
expression of Lemma 7.1.2 up to small orders in @xmath and @xmath .

###### Lemma 7.1.3.

Let @xmath and @xmath be defined as in Lemma 7.1.2 , where @xmath ,
@xmath , @xmath for some @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

In particular, this quantity is positive if @xmath .

###### Proof.

The assertion follows immediately from a series expansion of the bound
provided by Lemma 7.1.2 about @xmath and @xmath . ∎

Lemma 7.1.3 can be used to compute a bound on the rate of the protocol
described above (advantage distillation followed by noisy
preprocessing). Under the assumption that the coefficients @xmath are of
the form

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

for some small @xmath , we get, analogously to ( 7.6 ),

  -- -- -- -------
           (7.7)
  -- -- -- -------

### 7.2 The six-state protocol

To illustrate the results of Section 7.1 , we apply them to different
variants of the six-state QKD protocol, for which we explicitly compute
the rate and the maximum tolerated channel noise. The six-state protocol
is one of the most efficient QKD schemes based on two-level systems,
that is, the rate at which secret key bits can be generated per channel
use is relatively close to the theoretical maximum. On the other hand,
it is not very suitable for practical implementations, as it requires
devices for preparing and measuring two-level quantum systems with
respect to six different states.

#### 7.2.1 Description

Instead of describing the actual six-state QKD protocol, we specify the
underlying key distillation scheme: Alice and Bob take as input
entangled two-level systems and measure each of them using at random one
of three mutually unbiased bases, which results in a pair of raw keys. ⁷
⁷ 7 Because each of the three bases consists of two orthonormal vectors,
the information is encoded into six different states, which explains the
name of the protocol. Usually, these are the rectilinear or @xmath
-basis @xmath , the diagonal or @xmath -basis @xmath , and the circular
or @xmath -basis @xmath , which are related by

  -- -------- --
     @xmath   
  -- -------- --

Next, in a sifting step, Alice and Bob compare their choices of bases
and discard all outcomes for which these do not agree. Note that, if
Alice and Bob choose one of the bases with probability almost one, they
only have to discard a small fraction of their raw keys (see discussion
in Section 1.2 ).

In the parameter estimation step, Alice and Bob compare the bit values
of their raw keys for a small fraction of randomly chosen positions.
They abort if the error rate @xmath —i.e., the fraction of positions for
which their bits differ—is larger than some threshold. For the following
analysis, we assume that Alice and Bob additionally check whether the
error @xmath is equally distributed among the different choices of the
measurement bases and symmetric under bitflips.

Finally, Alice and Bob use the remaining part of their raw key to
generate a pair of secret keys. For this, they might invoke different
variants of advantage distillation and one-way post-processing
subprotocols, as described in Section 7.1 .

#### 7.2.2 Analysis

To compute the rate of the six-state protocol (for different variants of
the post-processing) we use the formulas derived in Section 7.1 . The
set @xmath , as defined by ( 7.2 ), depends on the error rate @xmath .
For any fixed @xmath , we get six conditions on the operators @xmath
contained in @xmath , namely

  -- -------- -- -------
     @xmath      (7.8)
  -- -------- -- -------

for any @xmath and @xmath with @xmath . It is easy to verify that the
only density operator that satisfies these equalities is Bell-diagonal
and has eigenvalues @xmath , @xmath . @xmath is thus the set of all
density operators of the form (with respect to the Bell basis)

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath below some threshold.

##### One-way six-state protocol

In a basic version of the six-state QKD protocol, Alice and Bob apply
post-processing (i.e., information reconciliation followed by privacy
amplification) directly to their measured data, as described in Section
7.1.1 . The rate of this protocol can be computed using ( 7.4 ) where,
according to the above discussion, @xmath and @xmath . Plot 7.1 shows
the result of a numerical evaluation of this formula. In particular, the
maximum tolerated channel noise for which the key rate is nonzero is
@xmath .

Next, we consider the one-way six-state protocol enhanced with
additional noisy preprocessing as described in Section 7.1.2 . That is,
before the information reconciliation step, Alice applies random
bitflips with probability @xmath to her measurement outcomes. The rate
of this protocol can be computed with Lemma 7.1.2 . A little bit
surprisingly, it turns out that noisy preprocessing increases its
performance (see Plot 7.2 ). As shown in Plot 7.3 , the optimal value of
the bit-flip probability @xmath depends on the error rate of the channel
@xmath . The protocol can tolerate errors up to @xmath and thus beats
the basic version (without noisy preprocessing) described above. Note
that this result also improves on the previously best known lower bound
for the maximum error tolerance of the six-state protocol with one-way
processing, which was @xmath [ Lo00 ] . (Similarly, the same
preprocessing can be applied to the BB84 protocol, in which case we get
an error tolerance of @xmath , compared to the best known value of
@xmath [ SP00 ] .)

[ Plot 7.1 Rate of the basic one-way six-state protocol (without noisy
preprocessing) as a function of the error rate @xmath .]

[ Plot 7.2 Rate of the one-way six-state protocol with noisy
preprocessing (where Alice flips her bits with probability @xmath as
depicted in Plot 7.3 ).]

[ Plot 7.3 Optimal value of the bit-flip probability @xmath for the
noisy preprocessing used in the one-way six-state protocol.]

##### Six-state protocol with advantage distillation

The performance of the six-state protocol is increased if Alice and Bob
additionally use advantage distillation as described in Section 7.1.3 .
For example, Alice and Bob might invoke the protocol @xmath depicted in
Fig. 7.1 to process their measurement outcomes before the information
reconciliation and privacy amplification step. The rate of the protocol
is then given by ( 7.6 ). Because @xmath and @xmath , the coefficients
@xmath occurring in this formula are

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath . Plot 7.4 shows the result of this computation for a block
size of @xmath .

[ Plot 7.4 Rate of the six-state protocol with advantage distillation on
blocks of length @xmath .]

Finally, we have a look at an extended protocol which combines advantage
distillation and noisy preprocessing. That is, after the advantage
distillation @xmath , Alice flips her bits with probability @xmath (see
Plot 7.5 ). For large block sizes @xmath , the rate of the protocol is
given by ( 7.7 ), for

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

In particular, for @xmath approaching infinity, the secret-key rate is
positive if (see Lemma 7.1.3 )

  -- -------- --
     @xmath   
  -- -------- --

Some simple analysis shows that this inequality is satisfied (for large
@xmath ) if @xmath . We conclude that the protocol can tolerate errors
up to @xmath .

Note that this value coincides with the corresponding error tolerance of
another variant of the six-state protocol due to Chau [ Cha02 ] and is
actually optimal for this class of protocols (cf. [ ABB @xmath 04 ] ).
However, compared to Chau’s protocol, the above described variant of the
six-state protocol is simpler ⁸ ⁸ 8 Instead of adding noise, Chau’s
protocol uses xor operations between different bits of the raw key. and
has a higher key rate.

[ Plot 7.5 Rate of the six-state protocol with advantage distillation
(on blocks of optimal length) followed by (optimal) random bit-flips on
Alice’s side.]

## Appendix A Distance measures

### a.1 Fidelity

The fidelity between two (not necessarily normalized) states @xmath is
defined by

  -- -------- --
     @xmath   
  -- -------- --

In particular, if @xmath and @xmath are pure states,

  -- -------- --
     @xmath   
  -- -------- --

###### Remark A.1.1.

For any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

##### Fidelity of purifications

Uhlmann’s theorem states that the fidelity between two operators is
equal to the maximum fidelity of their purifications.

###### Theorem A.1.2 (Uhlmann).

Let @xmath and let @xmath be a purification of @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where the maximum is taken over all purifications @xmath of @xmath .

###### Proof.

The assertion follows directly from the corresponding statement for
normalized density operators (see, e.g., Theorem 9.4 in [ NC00 ] ) and
Remark A.1.1 . ∎

###### Remark A.1.3.

Because the fidelity @xmath does not depend on the phase of the vectors,
the vector @xmath which maximizes the expression of Theorem A.1.2 can
always be chosen such that @xmath is real and nonnegative.

##### Fidelity and quantum operations

The fidelity between two density operators is equal to the minimum
fidelity between the distributions of the outcomes resulting from a
measurement.

###### Lemma A.1.4.

Let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where the minimum ranges over all POVMs @xmath on @xmath and where
@xmath are defined by @xmath and @xmath , respectively.

###### Proof.

The statement follows directly from the corresponding statement for
normalized density operators (cf. formula (9.74) in [ NC00 ] ) and
Remark A.1.1 . ∎

The fidelity between two operators cannot decrease when applying the
same quantum operation to both of them.

###### Lemma A.1.5.

Let @xmath and let @xmath be a trace-preserving CPM on @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Theorem 9.6 of [ NC00 ] and Remark A.1.1 . ∎

### a.2 @xmath-distance

##### @xmath-distance and quantum operations

The @xmath -distance between two density operators cannot increase when
applying the same (trace-preserving) quantum operation to both of them.

###### Lemma A.2.1.

Let @xmath and let @xmath be a CPM such that @xmath for any @xmath .
Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

It suffices to show that @xmath , for any hermitian operator @xmath .
The assertion then follows with @xmath because @xmath is linear.

For any hermitian operator @xmath , let @xmath be the @xmath -operator
norm . Note that the @xmath -operator norm can equivalently be written
as

  -- -------- --
     @xmath   
  -- -------- --

Moreover, it is easy to see that for any hermitian operator @xmath

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

Let @xmath be the family of linear operators from @xmath to @xmath
defined by the CPM @xmath , i.e., @xmath , for any @xmath . Moreover,
let @xmath be the CPM defined by @xmath , for any hermitian operator
@xmath on @xmath . We then have the identity

  -- -------- --
     @xmath   
  -- -------- --

Hence

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

where the inequality holds because @xmath and @xmath , for any @xmath .
Using ( A.1 ), this implies that

  -- -------- --
     @xmath   
  -- -------- --

where the inequality follows from ( A.2 ).

∎

##### @xmath-distance of mixtures

###### Lemma A.2.2.

Let @xmath and @xmath be classical with respect to an orthonormal basis
@xmath of @xmath and let @xmath and @xmath be the corresponding
conditional operators. Then

  -- -- --
        
  -- -- --

###### Proof.

For any @xmath , let @xmath be an eigenbasis of @xmath . Then, the
family @xmath is an eigenbasis of @xmath . Hence,

  -- -- --
        
  -- -- --

##### @xmath-distance of pure operators in terms of vector distance

The scalar product of a Hilbert space @xmath induces a canonical norm,
defined by @xmath , for any @xmath . In particular, the norm of the
difference between two vectors @xmath and @xmath , @xmath , is a metric
on @xmath .

The following lemma relates the @xmath -distance between two pure states
@xmath and @xmath to the vector distance @xmath .

###### Lemma A.2.3.

Let @xmath such that @xmath is real. Then

  -- -- --
        
  -- -- --

###### Proof.

Define @xmath , @xmath and let @xmath , @xmath . We then have

  -- -------- --
     @xmath   
  -- -------- --

Moreover, because @xmath is real, the scalar product @xmath is real as
well. Using this, it is easy to verify that @xmath and @xmath are
eigenvectors of @xmath with eigenvalues @xmath and @xmath ,
respectively. Hence,

  -- -------- --
     @xmath   
  -- -------- --

where the last equality holds because the Cauchy-Schwartz inequality
implies @xmath . ∎

##### Upper bound on @xmath-distance in terms of fidelity

###### Lemma A.2.4.

Let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

It follows from Uhlmann’s theorem (see Theorem A.1.2 and remark
thereafter) that there exist purifications @xmath and @xmath of @xmath
and @xmath , respectively, such that @xmath is nonnegative and @xmath .
Using Lemma A.2.3 , a simple calculation leads to

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath , @xmath , and @xmath , this identity can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows from the fact that the @xmath -distance can
only decrease when taking the partial trace (cf.  Lemma A.2.1 ). ∎

##### Upper bound on @xmath-distance in terms of vector distance

The following lemma is a generalization of one direction of Lemma A.2.3
to mixed states.

###### Lemma A.2.5.

Let @xmath and let @xmath and @xmath be purifications of @xmath and
@xmath , respectively. Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath such that @xmath is nonnegative and define @xmath . Then,
from Lemma A.2.3 ,

  -- -- -- -------
           (A.3)
  -- -- -- -------

where the inequality follows from the triangle inequality for the norm
@xmath and @xmath . Moreover, since @xmath is nonnegative, it cannot be
smaller than the real value of the scalar product @xmath , that is,
@xmath , and thus

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( A.3 ) gives

  -- -- --
        
  -- -- --

The assertion follows from the fact that the @xmath -distance cannot
increase when taking the partial trace (cf.  Lemma A.2.1 ). ∎

##### Lower bound on @xmath-distance in terms of fidelity

The following statement is the converse of Lemma A.2.4 .

###### Lemma A.2.6.

Let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

The proof is a direct generalization of an argument given in [ NC00 ]
(see formula (9.109) of [ NC00 ] ).

###### Proof.

According to Lemma A.1.4 , there exists a POVM @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and @xmath defined by @xmath and @xmath . Using the
abbreviation @xmath and @xmath , we observe that

  -- -------- -- -------
     @xmath      (A.4)
  -- -------- -- -------

Moreover, because @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where the last inequality follows from the fact that the trace distance
cannot increase when applying a POVM (cf.  Lemma A.2.1 ). The assertion
then follows by combining this with ( A.4 ). ∎

##### Lower bound on @xmath-distance in terms of vector distance

The following statement can be seen as the converse of Lemma A.2.5 .

###### Lemma A.2.7.

Let @xmath and let @xmath be a purification of @xmath . Then there
exists a purification @xmath of @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Uhlmann’s theorem (see Theorem A.1.2 and remark thereafter) implies that
there exists a purification @xmath of @xmath such that @xmath . Hence,

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows from Lemma A.2.6 . ∎

##### @xmath-distance and trace

A slightly different variant of the following statement is known as the
Gentle Measurement Lemma [ Win99 ] .

###### Lemma A.2.8.

Let @xmath such that @xmath for some projector @xmath on @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We first show that the assertion holds if @xmath is normalized (i.e.,
@xmath ) and pure, that is, @xmath for some normalized vector @xmath .
Since @xmath is a projector, the vector @xmath can be written as a
weighted sum of two orthonormal vectors @xmath and @xmath , @xmath , for
@xmath , such that @xmath and @xmath . In particular, @xmath . A
straightforward calculation then shows that

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof for normalized pure states @xmath .

To show that the assertion holds for general operators @xmath , let
@xmath be a spectral decomposition of @xmath . In particular, @xmath .
Define @xmath and @xmath . By linearity, we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, using the triangle inequality and the fact that the assertion
holds for the normalized pure states @xmath , we find

  -- -------- --
     @xmath   
  -- -------- --

Moreover, with Jensen’s inequality we find

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof. ∎

## Appendix B Various Technical Results

### b.1 Combinatorics

For proofs of the following statements, we refer to the standard
literature on combinatorics.

###### Lemma B.1.1.

The set @xmath of types with denominator @xmath on a set @xmath has
cardinality

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma B.1.2.

Let @xmath be a type with denominator @xmath on a set @xmath . Then the
type class @xmath has cardinality

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma B.1.3.

A set of cardinality @xmath has at most @xmath subsets of cardinality
@xmath .

###### Proof.

A set of cardinality @xmath has exactly @xmath subsets of cardinality
@xmath . The assertion thus follows from the inequality ¹ ¹ 1 See, e.g.,
[ CT91 ] , Formula (12.40). @xmath . ∎

### b.2 Birkhoff’s Theorem

###### Definition B.2.1.

A matrix @xmath is bistochastic if @xmath , for any @xmath , @xmath ,
and @xmath .

It is easy to see that a matrix @xmath can only be bistochastic if
@xmath . The following theorem due to Birkhoff [ Bir46 ] states that any
bistochastic matrix can be written as a mixture of permutation matrices.
(See, e.g., [ HJ85 ] for a proof.)

###### Theorem B.2.2 (Birkhoff’s theorem).

Let @xmath be a bistochastic matrix. Then there exist nonnegative
coefficients @xmath , parameterized by the bijections @xmath from @xmath
to @xmath , such that @xmath and, for any @xmath , @xmath , ² ² 2 @xmath
denotes the Kronecker symbol which equals one if @xmath and zero
otherwise.

  -- -------- --
     @xmath   
  -- -------- --

It follows immediately from Birkhoff’s theorem that any sum of the form

  -- -------- --
     @xmath   
  -- -------- --

can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

### b.3 Typical sequences

Let @xmath be an @xmath -tuple chosen according to an @xmath -fold
product distribution @xmath . Then, with probability almost one, @xmath
is a typical sequence , i.e., its frequency distribution @xmath is close
to the distribution @xmath .

###### Theorem B.3.1.

Let @xmath be a probability distribution on @xmath and let @xmath be
chosen according to the @xmath -fold product distribution @xmath . Then,
for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Theorem 12.2.1 of [ CT91 ] . ∎

Theorem B.3.1 quantifies the distance between @xmath and @xmath with
respect to the relative entropy. To obtain a statement in terms of the
@xmath -distance, we need the following lemma.

###### Lemma B.3.2.

Let @xmath and @xmath be probability distributions. Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Lemma 12.6.1 of [ CT91 ] . ∎

###### Corollary B.3.3.

Let @xmath be a probability distribution on @xmath and let @xmath be
chosen according to the @xmath -fold product distribution @xmath . Then,
for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The assertion follows directly from Theorem B.3.1 combined with Lemma
B.3.2 . ∎

### b.4 Product spaces

###### Lemma B.4.1.

Let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume first that @xmath is pure, i.e., @xmath . Let @xmath be a Schmidt
decomposition of @xmath , i.e., @xmath and @xmath are families of
orthonormal vectors in @xmath and @xmath , respectively. Then

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath and @xmath the assertion follows.

To show that the statement also holds for mixed states, let @xmath be a
decomposition of @xmath into pure states @xmath , for @xmath . Then,
because the lemma holds for the states @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Lemma B.4.2.

Let @xmath such that @xmath . Then @xmath .

###### Proof.

Assume first that @xmath is pure, i.e., @xmath . Let @xmath be a Schmidt
decomposition of @xmath , i.e., @xmath and @xmath are families of
orthonormal vectors in @xmath and @xmath , respectively. Then @xmath .
Moreover, by Lemma B.4.1 ,

  -- -------- --
     @xmath   
  -- -------- --

i.e., @xmath . This implies @xmath , for any @xmath , and thus @xmath .
The assertion then follows because @xmath .

To show that the statement holds for mixed states, let @xmath be a
decomposition of @xmath into pure states @xmath , for @xmath . We then
have @xmath , for any @xmath , and thus, because the lemma holds for
pure states, @xmath . Consequently,

  -- -- --
        
  -- -- --

∎

### b.5 Nonnegative operators

###### Lemma B.5.1.

Let @xmath and let @xmath be a hermitian operator on @xmath . Then
@xmath is nonnegative.

###### Proof.

Let @xmath be a spectral decomposition of @xmath . Then, for any vector
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The assertion then follows because @xmath is hermitian. ∎

###### Lemma B.5.2.

Let @xmath . Then @xmath .

###### Proof.

The assertion is an immediate consequence of the fact that @xmath and
Lemma B.5.1 . ∎

###### Lemma B.5.3.

Let @xmath such that @xmath is invertible. Then the operator @xmath is
nonnegative if and only if

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

With @xmath , we have @xmath . Because of Lemma B.5.1 , this operator is
nonnegative if and only if @xmath is nonnegative, which is equivalent to
say that all eigenvalues of @xmath are upper bounded by @xmath . ∎

###### Lemma B.5.4.

Let @xmath such that @xmath is nonnegative and @xmath is invertible.
Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Assume without loss of generality that @xmath is invertible (otherwise,
the statement follows by continuity). Because the operator @xmath is
nonnegative, the same holds for @xmath (cf.  Lemma B.5.1 ). Hence, all
eigenvalues of @xmath are at least @xmath . Consequently, the
eigenvalues of the inverse @xmath cannot be larger than @xmath . ∎

### b.6 Properties of the function @xmath

The class of functions @xmath , for @xmath , is used in Section 3.3 for
the proof of a Chernoff style bound. In the following, we list some of
its properties.

###### Lemma B.6.1.

For any @xmath , the function @xmath is monotonically increasing on the
interval @xmath .

###### Proof.

The first derivative of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

The assertion follows because the term on the right hand side is
nonnegative for any @xmath . ∎

###### Lemma B.6.2.

For any @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Observe first that @xmath . It thus suffices to show that the statement
holds for @xmath . If @xmath , the assertion follows directly from Lemma
B.6.1 . For the case where @xmath and @xmath , let @xmath . Then @xmath
and @xmath . Because @xmath , we have @xmath , which implies @xmath .
The assertion then follows again from Lemma B.6.1 . ∎

###### Lemma B.6.3.

For any @xmath , the function @xmath is concave on the interval @xmath .

###### Proof.

We show that @xmath for any @xmath . Because @xmath , this is equivalent
to @xmath . It thus suffices to verify that

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath . Using some simple analysis, it is easy to see that the
term on the right hand side is monotonically increasing in @xmath on the
interval @xmath and thus takes its maximum at @xmath , in which case it
equals @xmath . ∎

###### Lemma B.6.4.

For any @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath . Then

  -- -------- -- -------
     @xmath      (B.1)
  -- -------- -- -------

We first show that the term on the right hand side of ( B.1 ) is
monotonically increasing in @xmath , that is,

  -- -------- --
     @xmath   
  -- -------- --

A simple calculation shows that this inequality can be rewritten as

  -- -------- --
     @xmath   
  -- -------- --

which holds because, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence, in order to find an upper bound on ( B.1 ), it is sufficient to
evaluate the right hand side of ( B.1 ) for the maximum value of @xmath
. By assumption, we have @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof. ∎

## Appendix C Computationally Efficient Information Reconciliation

In Section 6.3 , we have proposed a general one-way information
reconciliation scheme which is optimal with respect to its information
leakage. The scheme, however, requires the receiver of the
error-correcting information to perform some decoding operation for
which no efficient algorithm is known. In the following, we propose an
alternative information reconciliation scheme based on error-correcting
codes where all computations can be done efficiently.

### c.1 Preliminaries

To describe and analyze the protocol, we need some terminology and basic
results from the theory of channel coding. Let @xmath be a discrete
memoryless channel which takes inputs from a set @xmath and gives
outputs from a set @xmath . ¹ ¹ 1 A discrete memoryless channel @xmath
from @xmath to @xmath is defined by the conditional probability
distributions @xmath on @xmath , for any @xmath . An encoding scheme for
@xmath is a family of pairs @xmath parameterized by @xmath where @xmath
is a code on @xmath of length @xmath , i.e., a set of @xmath -tuples
@xmath , called codewords , and @xmath is a decoding function , i.e., a
mapping from @xmath to @xmath . The rate of the code @xmath is defined
by @xmath . Moreover, the maximum error probability of @xmath is defined
by

  -- -------- --
     @xmath   
  -- -------- --

where, for any @xmath , the probability is over all outputs @xmath of
@xmath parallel invocations of @xmath on input @xmath .

We will use the following fundamental theorem for channel coding (cf.,
e.g., [ CT91 ] , Section 8.7).

###### Proposition C.1.1.

Let @xmath be a discrete memoryless channel from @xmath to @xmath and
let @xmath . Then there exists an encoding scheme @xmath for @xmath such
that the following holds:

-   @xmath , for any @xmath . (The entropies in the maximum are computed
    for the distribution @xmath of an input/output pair @xmath of @xmath
    , where @xmath is chosen according to @xmath .)

-   @xmath .

### c.2 Information reconciliation based on codes

Let us now consider an information reconciliation protocol based on
channel coding. For this, we assume that Alice’s and Bob’s inputs are
strings @xmath and @xmath , respectively. Our protocol shall be secure
if the inputs @xmath are distributed according to a product distribution
@xmath .

Let @xmath be the channel which maps any @xmath to @xmath , where the
pair @xmath is chosen according to the probability distribution @xmath
and where @xmath is a group operation on @xmath . For any @xmath , let
@xmath be the information reconciliation protocol specified by Fig. C.1
, where @xmath is the code and @xmath the decoding function defined by
Proposition C.1.1 .

It is easy to see that @xmath holds whenever @xmath decodes to the
correct value @xmath . Hence, the information reconciliation protocol
@xmath is @xmath -secure, for @xmath . Because, by Proposition C.1.1 ,
the maximum error probability @xmath of @xmath goes to zero, for @xmath
approaching infinity, the protocol @xmath is asymptotically secure.

Parameters:
@xmath : set of codewords from @xmath @xmath : decoding function from
@xmath to @xmath @xmath : group operation on @xmath (with inverse @xmath
). {protocol} AliceBob \protno input: @xmath input: @xmath \protright
@xmath
@xmath @xmath @xmath \protno if decoding not succ.
@xmath then abort \protno output @xmath

Fig. C.1 Information reconciliation protocol @xmath .

Moreover, by Proposition C.1.1 ,

  -- -------- --
     @xmath   
  -- -------- --

Using the fact that the input @xmath is chosen independently of the
randomness of the channel @xmath , a simple information-theoretic
computation shows that the entropy difference in the maximum can be
rewritten as @xmath . Hence, because @xmath , we find

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

The communication @xmath of the protocol is contained in the set @xmath
. Furthermore, because @xmath is chosen uniformly at random from @xmath
, the distribution @xmath of the communication @xmath , conditioned on
any input @xmath , is uniform over a set of size @xmath . The leakage of
@xmath is thus given by

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( C.1 ) we conclude

  -- -------- --
     @xmath   
  -- -------- --

Because Proposition C.1.1 also holds for efficient ² ² 2 An encoding
scheme @xmath is said to be efficient if there exist polynomial-time
algorithms (in @xmath ) for sampling a codeword from the set @xmath and
for evaluating the decoding function @xmath . encoding schemes (see,
e.g., [ Dum98 ] ), Corollary 6.3.5 is asymptotically still true if we
restrict to computationally efficient protocols (see also [ HR05 ] ).
More precisely, this result can be formulated as follows.

###### Proposition C.2.1.

Let @xmath be a probability distribution and let @xmath . Then there
exists a family of computationally efficient information reconciliation
protocols @xmath (parameterized by @xmath ) which are @xmath -fully
secure, @xmath -robust on the product distribution @xmath , and have
leakage @xmath , for any @xmath , where @xmath .

## Appendix D Notation

  General   
  --------- -----------------------------------------------------
  @xmath    binary logarithm
  @xmath    natural logarithm
  @xmath    Kronecker symbol: @xmath , @xmath iff @xmath
  @xmath    complex conjugate of @xmath
  @xmath    real value of @xmath
  @xmath    set of nonnegative functions on the set @xmath
  @xmath    set of permutations on the set @xmath
  @xmath    expectation of @xmath over random choices of @xmath
  @xmath    support of the function @xmath
  @xmath    set of real numbers @xmath such that @xmath
  @xmath    set of real numbers @xmath such that @xmath

  Frequency distributions and types   
  ----------------------------------- --------------------------------------------------------
  @xmath                              frequency distribution of the @xmath -tuple @xmath
  @xmath                              set of types with denominator @xmath on the set @xmath
  @xmath                              type class of the type @xmath with denominator @xmath

  Vectors   
  --------- -------------------------------------------------
  @xmath    space spanned by the set of vectors @xmath
  @xmath    scalar product of the vectors @xmath and @xmath
  @xmath    norm of the vector @xmath
  @xmath    projector onto the vector @xmath
  @xmath    set of normalized vectors on @xmath

  Operators   
  ----------- -----------------------------------------------------
  @xmath      set of nonnegative operators on @xmath
  @xmath      identity
  @xmath      trace of the hermitian operator @xmath
  @xmath      support of the hermitian operator @xmath
  @xmath      rank of the hermitian operator @xmath
  @xmath      maximum eigenvalue of the hermitian operator @xmath
  @xmath      trace norm of the hermitian operator @xmath

  Distance measures for operators   
  --------------------------------- ------------------------------------------------------------
  @xmath                            @xmath -distance between @xmath and @xmath
  @xmath                            fidelity between @xmath and @xmath .
  @xmath                            @xmath -distance from uniform of @xmath given @xmath
  @xmath                            @xmath -distance from uniform of @xmath relative to @xmath

  Entropies   
  ----------- ---------------------------------------------------------
  @xmath      Shannon entropy of the probability distribution @xmath
  @xmath      binary Shannon entropy with bias @xmath
  @xmath      von Neumann entropy of the density operator @xmath
  @xmath      conditional entropy @xmath
  @xmath      relative entropy of @xmath to @xmath
  @xmath      min-entropy of @xmath relative to @xmath
  @xmath      max-entropy of @xmath relative to @xmath
  @xmath      @xmath -smooth min-entropy of @xmath relative to @xmath
  @xmath      @xmath -smooth max-entropy of @xmath relative to @xmath
  @xmath      @xmath -smooth min-entropy of @xmath given @xmath
  @xmath      @xmath -smooth max-entropy of @xmath given @xmath
  @xmath      abbreviation for @xmath
  @xmath      abbreviation for @xmath
  @xmath      collision entropy of @xmath relative to @xmath

  Symmetric spaces   
  ------------------ -------------------------------------------
  @xmath             Symmetric subspace of @xmath
  @xmath             Symmetric subspace of @xmath along @xmath