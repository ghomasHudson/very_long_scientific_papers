#

I de blindas rike, är den enögde kung.

Niccolò Machiavelli

###### Contents

-    Abstract
-    Introduction
-    \thechapter The Standard Model Top Quark
    -    1 Production of the Top Quark
    -    2 Decay of the Top Quark
    -    3 Mass of the Top Quark
    -    4 Experimental Tests of the Standard Model Top Quark Sector
        -    4.1 Top Quark Pair Production Cross Section
        -    4.2 Top Quark Decay Branching Ratio
        -    4.3 @xmath Boson Helicity
        -    4.4 Resonances and Rare Decays
        -    4.5 Top Quark Spin Correlations
        -    4.6 The Standard Model Higgs Boson
-    \thechapter The DØ Detector
    -    5 The DØ Coordinate System
    -    6 The Central Tracking System
        -    6.1 The Silicon Microvertex Tracker
        -    6.2 The Central Fiber Tracker
    -    7 The Preshower Detectors
    -    8 The Calorimeter
        -    8.1 The Inter-Cryostat Detector
    -    9 The Muon Spectrometer
    -    10 Luminosity Monitoring
    -    11 The Trigger System
-    \thechapter Event Reconstruction
    -    12 Event Signatures
        -    12.1 Experimental Signature of @xmath Production
        -    12.2 Background Signature
    -    13 Tracks
    -    14 Primary Vertex
    -    15 Muons
    -    16 Electrons
    -    17 Jets
        -    17.1 Jet Identification
        -    17.2 Jet Energy Scale
        -    17.3 Jet Energy Resolution
        -    17.4 @xmath -Quark Jets
    -    18 Missing Transverse Energy
    -    19 Monte Carlo Simulation
        -    19.1 Simulated Samples
-    \thechapter Determination of the Electric Charge of the Top Quark
    -    20 Overview of the Method
    -    21 Signal Sample
        -    21.1 Trigger Selection
        -    21.2 Preselection
            -    21.2.1 Preselections specific to the @xmath channel
            -    21.2.2 Preselections specific to the @xmath channel
            -    21.2.3 Preselected Sample
        -    21.3 Final Event Selection
            -    21.3.1 Sample Composition
    -    22 Jet Charge Algorithms
        -    22.1 Jet Charge Algorithm Definition
        -    22.2 Optimization
    -    23 Jet Charge Calibration on Data
        -    23.1 Dijet Data Samples
        -    23.2 Extraction of Jet Charge Templates from Dijet Data
        -    23.3 Fraction of @xmath -Quark Jets in the Dijet Samples
        -    23.4 Determination of the Tagging Muon Charge Flip Fraction
            -    23.4.1 Cross-check of tagging muon charge flip
        -    23.5 Correction for Kinematical Differences in the Signal
            and Dijet Samples
            -    23.5.1 Jet Kinematical Weighting
            -    23.5.2 Derivation of the Kinematical Correction
        -    23.6 Final Jet Charge Distributions Extracted from Data
    -    24 Top Quark Charge Observables
        -    24.1 Associating SVT-Tagged Jets to the Correct @xmath
            Boson
            -    24.1.1 Kinematic Fit
        -    24.2 Expected Charge Templates in the Standard Model and
            Exotic Scenarios
            -    24.2.1 Standard Model Charge Template
            -    24.2.2 Exotic Scenario Charge Template
        -    24.3 Backgrounds
    -    25 Systematic Uncertainties
        -    25.0.1 Dependence on the Fragmentation Model
        -    25.0.2 Additional Jet Dependence
        -    25.0.3 Tagging Efficiency in Data and Monte Carlo
        -    25.0.4 Dependence on the Primary Vertex Position
        -    25.0.5 Fraction of @xmath -Tagged Jets in the Dijet and
            Signal Sample
        -    25.0.6 Fraction of @xmath -Quark Jets in the Dijet Samples
        -    25.0.7 Fraction of Muon Charge Sign Change in the Dijet and
            Monte Carlo Samples
        -    25.0.8 Statistical Uncertainty on the Kinematic Weighting
        -    25.0.9 Statistical Uncertainty on the Kinematic Correction
        -    25.0.10 Statistical Uncertainty on the Jet Charge Templates
        -    25.0.11 Top Quark Mass Uncertainty
        -    25.0.12 Jet Energy Scale
        -    25.0.13 Jet Energy Resolution
        -    25.0.14 Jet Reconstruction and Identification Efficiency
        -    25.0.15 Composition of the Signal Sample
        -    25.0.16 @xmath Production Mechanism
        -    25.0.17 @xmath Signal Modeling
    -    26 Results
        -    26.1 Discrimination Between Charge 2e/3 Top Quark and
            Charge 4e/3 Exotic Quark Production Scenarios
            -    26.1.1 Likelihood Ratio
            -    26.1.2 Generation of Pseudo-experiments
            -    26.1.3 Confidence Level
        -    26.2 Fraction of Charge @xmath Top Quark and Charge @xmath
            Exotic Quarks
            -    26.2.1 Maximum Likelihood Fit
            -    26.2.2 Interpretation of the Result to a Confidence
                Interval
            -    26.2.3 Validation of the Fit Procedure
            -    26.2.4 Systematic Uncertainties
            -    26.2.5 Results from Data
-    \thechapter Conclusion and Outlook
-    Acknowledgements

## Introduction

It is widely believed that the new particle discovered at Fermilab in
1995 discovery is the long-sought top quark. Its currently measured
properties are consistent with the Standard Model (SM) expectations for
the top quark, but many of its properties are still poorly known. In
particular, the electric charge, which is a fundamental quantity
characterizing a particle, has not yet been measured for this quark. It
still remains not only to confirm that the discovered quark has charge
@xmath and hence the expected SM quantum numbers, but also to measure
the strength of its electromagnetic (EM) coupling to rule out anomalous
contributions to its EM interactions. Indeed, one alternative
interpretation has not yet been ruled out: that the new particle is a
charge @xmath quark. In the published top quark analyses of the CDF and
DO collaborations top_review , the pairing of the @xmath quarks and the
W bosons in @xmath processes are not determined. As a result, there is a
twofold ambiguity in the electric charge assignment of the “top quark”.
In addition to the SM assignment @xmath , @xmath is also conceivable, in
which case the “top quark” would actually be an exotic quark with charge
@xmath . The analysis presented in this thesis is not carried out within
the framework of any extension to the SM. Nevertheless interpreting the
particle found at Fermilab as a charge @xmath quark is consistent with
current precision electroweak data. Current @xmath and @xmath data can
be fitted with a top quark of mass @xmath GeV, provided that the
right-handed @xmath -quark mixes with the isospin +1/2 component of an
exotic doublet of charge @xmath and @xmath quarks, @xmath
exotic_top_paper . If the top quark had a mass of @xmath GeV, it would
so far have escaped detection at the Fermilab Tevatron. The CDF
collaboration has carried out a search for a heavy @xmath -quark using
@xmath pb @xmath of data and excludes masses up to @xmath GeV
CDF_4th_quark_search . With data sets beyond @xmath fb @xmath and
combining DØ and CDF, the Tevatron will be capable of detecting @xmath
-quarks with masses of @xmath GeV and more. It should also be noted that
a mass of @xmath GeV merely corresponds to the best fit to SM precision
electroweak data in these models and the mass of such a heavy fermion
could still be above @xmath GeV.

In this thesis, the first determination of the electric charge of the
top quark using @xmath pb @xmath of @xmath data collected with the DØ 
experiment is presented. The result of the measurement is described in
the paper

  DØ Collaboration, V. M. Abazov et. al , ”Experimental discrimination
  between charge @xmath top quark and charge @xmath exotic quark
  production scenarios” , hep-ex/0608044, submitted to Phys. Rev. Lett.

The thesis is outlined as follows: chapter \thechapter gives an overview
of the SM and the top quark. The DØ detector is described in chapter
\thechapter and the object reconstruction is presented in chapter
\thechapter . The analysis to determine the top quark charge is
described in chapter \thechapter followed by a conclusion and outlook in
chapter \thechapter .

### Authors Contribution

In this thesis the result of my work at the DØ experiment at Fermilab
between February 2004 and summer 2006 is presented. Arriving at Fermilab
I quickly started working in the top quark group with a feasibility
study to determine the possibility and the amount of data needed for a
determination of the electric charge of the top quark. The top quark
charge had not been measured before and was considered very difficult
due to the low statistic sample of top quarks.

I have been responsible for the entire analysis from the first day. This
analysis was developed through intense collaboration with Dr. Christophe
Clément and Dr. David Milstead. At the start, most work went into
studying various jet charge algorithms and their optimization as
described in Sec. 22 . In autumn 2004, I showed that a measurement
should be possible with the data that was collected during this period
and the work was accelerated towards forming a full analysis. During
winter 2004 and spring 2005 most of my work went into defining and
validating the jet charge calibration discussed in Sec. 23 and finding
and studying various sources of systematic uncertainties. Based on the
result of the top quark pair cross section, the top quark charge
measurement was first presented as a preliminary result at the PANIC05
conference in October 2005. During winter 2005 and spring of 2006 I
worked mostly on refining the data calibration method but also to
develop the method of a simultaneous measurement of the fraction of
exotic quarks in the sample. The result was finally submitted to
Physical Review Letters for publication in the summer of 2006.

During 2005 I was involved in studies of the jet reconstruction
efficiency and energy calibration, especially studying the out-of-cone
radiation correction described in chapter \thechapter . During spring
2006 the DØ detector was upgraded, extending the silicon vertex detector
with an additional layer allowing for an improved tracking of charge
particles. I was responsible for upgrading and developing the online
software displaying the silicon tracking detector status.

### Notation

As mentioned earlier, the particle discovered at Fermilab is widely
believed to be the SM top quark. To this date, many of its parameters
are poorly known. Until all its properties are determined with high
precision, exotic scenarios (not included in the SM) are not excluded
and only measurements such as the one presented in this thesis can
finally decide if the particle is the SM top quark or an exotic quark.
This thesis has no preconceived opinion on the true nature of the
particle discovered. From now on, the name “top” in this thesis is
simply a notation chosen for consistency with other papers referenced.
The “top” quark refers to the SM top quark only when specifically
indicated or when a comparison of the exotic quark scenario with the SM
scenario is carried out.

## Chapter \thechapter The Standard Model Top Quark

Elementary particle physics research is the quest for understanding the
smallest constituents of matter and their interactions. The SM is the
theoretical framework used to describe the known elementary particles
and their interactions. The current view is that all matter is made up
of three kinds of particles: leptons, quarks and mediators. In the SM
the particle matter consists of spin-1/2 quarks and leptons, which, down
to a scale of around @xmath m appear elementary ¹ ¹ 1 Elementary means
here that they don’t have any internal structure. . There are six
“flavors” of quarks and leptons arranged in three generations. There are
four fundamental forces through which these elementary particles
interact; gravity, electromagnetic, weak and the strong force. The
electromagnetic- and weak force are manifestations of one single force,
called the electroweak force, in the Glashow-Weinberg-Salam (GWS) model
and the number of forces are then reduced to three. The SM is a quantum
field theory (QFT) based on the symmetry group @xmath ; all particles
are described as fields and forces between them are interpreted as being
due to the exchange of mediator particles. These particles are known as
gauge bosons, which are spin-1 particles ² ² 2 The graviton is
postulated to mediate the gravitational force and have spin-2 but is yet
to be observed. . The building blocks of the SM are summarized in Tab. 1
. For a pedagogical introduction to elementary particle physics and the
Standard Model, see e.g. Ref. griffiths .

The SM has been extremely successful and agrees with nearly all
experimental data so far PDG . However, the SM is a not a complete
theory of particle physics. For example, it does not incorporate
gravity, nor can it account for so-called dark matter and energy. Many
theoretical extensions of the SM have been postulated which predict the
existence of hitherto-undiscovered fundamental particles including
exotic quarks and leptons frank_mod_article .

The top quark is the partner to the bottom quark in the weak isospin
doublet in the SM. Unless otherwise specified, in this chapter the term
“top quark” refers to the SM top quark, the discovery of which was
announced by the DØ and CDF experiments around a decade ago discovery .
This is in contrast to the notation discussed in the introductory
chapter. The existence of the top quark was expected since the discovery
of the bottom ( @xmath ) quark in 1977 implied the existence of a
further quark to complete the quark sector with a three generation
structure. This chapter describes the current experimental status of the
discovered quark and the notation is adapted to simplify the discussion.
The first direct studies of the top quark were performed during Run I of
the Tevatron at center-of-mass energy of @xmath TeV and continued during
Run II with higher-statistic samples. The Tevatron remains to date the
only top factory. The top quark mass was predicted from precision
electroweak measurements from LEP, SLD, NuTeV and @xmath colliders
EWprecLetterB before its discovery. Due to the limited number of top
quarks observed so far its properties are less well experimentally
determined than those of other known quarks. However, most existing
results are consistent with the particle possessing the quantum numbers
of the SM-top quark PDG .

There are several reasons why the top quark is interesting in the
framework of the SM and possible physics beyond it:

-   The top quark production and decay properties are poorly known and
    provide important tests of the SM at the Tevatron.

-   The short expected lifetime of the top quark implies that it is the
    only quark that will decay before it hadronizes.

-   The top quark mass is an important parameter in precision
    electroweak fits and can thus constrain theoretical models of
    physics beyond the SM EWphysicsReport2004 .

-   The top quark may have special dynamics related to new particles
    beyond the SM due to its large coupling to the Higgs boson.

-   The large mass of the top quark and the increasing production cross
    section at higher energies implies that top quark production will be
    one of the principal sources of background when searching for
    evidence of New Physics processes at the Large Hadron Collider,
    which will collide protons at @xmath TeV from 2008 onwards.

### 1 Production of the Top Quark

Evidence for the direct production of the top quark has been obtained by
the DØ and CDF collaboration solely via the measurement of @xmath
pair-production processes. The two main processes are @xmath and @xmath
, as shown in Fig. 1 .

The quark and gluon content of the proton is described by so-called
parton distribution functions. These describe the probability to find a
gluon or a quark of a certain flavor carrying a fraction @xmath of the
proton’s (or anti-proton’s) momentum. The value of @xmath required for
production of top quarks decreases with increasing collision energy. At
the Tevatron energy, the top quark pairs are produced approximately in
85% of the events by quark anti-quark fusion @xmath and in 15% from
gluon fusion @xmath top_prod_theory . The top quark is also produced
singly via the weak interaction via the so called @xmath - and @xmath
-channel. Discovering single top production is more experimentally
challenging due to a less distinctive event signature and larger
backgrounds. No experimental evidence for production of single top
quarks has been found so far top_single_production .

The total top quark pair and single production cross section in the SM
at a center-of-mass energy of @xmath TeV is calculated to be @xmath pb
and @xmath pb respectively top_single_prod_theory .

### 2 Decay of the Top Quark

In the SM the top quark is predicted ³ ³ 3 Assuming only three families
and unitarity of the flavor mixing matrix (called
Cabibbo-Kobayashi-Maskawa matrix or CKM in short) @xmath . to decay to a
@xmath boson and a @xmath -quark with a branching ratio of @xmath PDG .
The large decay width ( @xmath GeV) corresponds to a lifetime of around
@xmath s. This lifetime is shorter than the corresponding time for
hadronization and thus no bound states with @xmath or @xmath exists
tt_quarkonium .

### 3 Mass of the Top Quark

The top quark is heavier than any other elementary particle found so
far. The mass of the top quark have been measured to the best relative
precision of all the quarks. Combining the results from both experiments
at the Tevatron the world-average top quark mass is @xmath GeV. More
information on the techniques and results from the top quark mass
analyzes can be found in topmass_average . The precision electroweak
measurements from e.g. LEP can be used to make an indirect prediction of
the top quark mass. The result, @xmath GeV, is consistent with the
direct measurements.

### 4 Experimental Tests of the Standard Model Top Quark Sector

To put the work in this thesis into perspective a summary of the world
measurements in the top quark sector is given.

#### 4.1 Top Quark Pair Production Cross Section

Both DØ and CDF have measured the @xmath production cross section. It is
extracted by counting the number of observed events, estimating the
number of background events and measuring the integrated luminosity
(taking into account the acceptance). Any abnormal top quark decay such
as @xmath can result in a lower cross section than predicted by the SM.
A higher than expected cross section would hint at new unknown
production mechanisms. One example can be found in Ref. technicolor .

So far all direct measurements of the @xmath production cross sections
are in agreement with the SM prediction. Figure 2 shows the measured
cross sections from the DØ collaboration.

The full list of cross section measurements at the Tevatron can be found
in PDG .

#### 4.2 Top Quark Decay Branching Ratio

As discussed above, within the SM the dominant decay mode for the top
quark is @xmath . The CKM matrix CKM_org element @xmath (with @xmath )
determines the coupling between the top quark and other flavors. The
@xmath and @xmath decay modes are suppressed by the square of the mixing
matrix elements. The predicted values of the mixing matrix can be tested
by determining the ratio @xmath of branching ratios @xmath for the
processes,

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

The SM prediction ⁴ ⁴ 4 This ratio can be expressed in the elements of
the mixing matrix elements as @xmath . is @xmath at @xmath % confidence
level and the current best measurement Vtb is @xmath , in good agreement
with the SM.

#### 4.3 @xmath Boson Helicity

New physics has been searched for in the dominant top quark decay vertex
@xmath where the helicity of the @xmath boson is sensitive to anomalous
contributions from new physics beyond the SM. In the SM the right-handed
fraction of @xmath bosons is suppressed compared to the longitudinal
fraction ( @xmath %). By studying the angular distribution of the @xmath
boson decay products with respect to the top quark direction, DØ puts an
upper limit of @xmath on the fraction of right-handed @xmath bosons at
95% confidence level W_hel_d0 . Direct measurements of the longitudinal
fraction give a value of @xmath W_hel_cdf_f0 and @xmath W_hel_d0_f0 .

#### 4.4 Resonances and Rare Decays

Due to its large mass there are various physics models topcondensate ;
topasstechnicolor beyond the SM in which the top quark plays a central
role. In these models, a heavy particle decaying to @xmath can be
produced with cross sections large enough to be visible at the Tevatron.
The DØ and CDF collaborations have searched for @xmath production via an
intermediate particle state by looking for narrow-width peaks in the
spectrum of the invariant mass of @xmath events. DØ and CDF report no
evidence for such an intermediate state and exclude masses of such a
state up to @xmath GeV ttbarresonance .

#### 4.5 Top Quark Spin Correlations

The top quarks in @xmath pairs produced from unpolarized incoming
particles in @xmath annihilation are expected to be unpolarized.
However, their spin is expected to be highly correlated with a higher
fraction of events in which the spins are aligned rather than
anti-aligned. DØ measured the spin correlation in a low statistics
sample in Run I and found no deviation from the SM prediction spincorr .

#### 4.6 The Standard Model Higgs Boson

A key concept of the SM is the so-called gauge invariance, which can be
interpreted as a transformation of fields in such a way that they do not
change (they are gauge invariant). It can be be shown that to keep a
theory like QED gauge invariant an additional interaction must be
introduced, i.e. the photon. From gauge invariance it can be shown that
the SM predicts massless mediator bosons (and also massless fermions),
while the @xmath and @xmath bosons are known to have a large mass. By
postulating another field, the Higgs field, that all particles interact
with, this problem is taken into account and all masses are consistent
with the theory. This additional field implies the existence of the
Higgs boson as the mediator of the field and is today the only
undiscovered particle in the SM. For a good introduction to gauge
theories and spontaneous symmetry breaking, see e.g. griffiths .

Although the couplings of the Higgs boson to other particles are
predicted the mass of the Higgs boson is not. It can however be inferred
from high precision measurements of the @xmath boson mass where virtual
loop corrections involving both the Higgs boson and the top quark
contribute. The same principle used when predicting the top quark mass
before its discovery. Figure 3 shows the dependence of the Higgs boson
mass on the top quark and @xmath boson masses.

Although the uncertainty on the prediction of the Higgs boson mass is
large, it is evident that the experiments imply a low-mass Higgs boson
mass. The 95% lower confidence limit on the Higgs mass from direct
searches is @xmath GeV and the upper 95% confidence limit is @xmath GeV
(including the direct search lower limit increases the upper limit to
@xmath GeV) EWWG_summer05_combination .

The search for evidence of the existence of the Higgs boson is currently
one of the largest efforts in the particle physics community and will be
addressed at the LHC.

## Chapter \thechapter The DØ Detector

The DØ detector was proposed in 1983 to study proton anti-proton
collisions at the Fermilab Tevatron accelerator. The purpose was to
study a wide range of phenomena focusing on high-mass states and high-
@xmath processes. The DØ detector performed well during Run I of the
Tevatron, which lasted from 1992 to 1996. Among many impressive results
was the discovery of the long sought top quark and measurements of its
mass. During Run I, the Tevatron operated with six bunches of protons
and anti-protons with @xmath ns between each bunch-crossing. The
center-of-mass energy was @xmath TeV and the peak instantaneous
luminosity was typically around @xmath cm @xmath s @xmath . The data
recorded by the DØ experiment in Run I amounted to approximately @xmath
pb @xmath . Following the completion of the Fermilab Main Injector and
other substantial Tevatron upgrades, the DØ experiment was running again
in 2001. In this phase, called Run II, the Tevatron is operated with
@xmath bunches of protons and anti-protons with @xmath ns between each
bunch-crossing and a center-of-mass energy of @xmath TeV. The
instantaneous luminosity increased by a factor of ten.

To take advantage of the increased luminosity and center-of-mass energy
delivered by the Tevatron the DØ experiment was greatly upgraded during
1996-2001. Among the major upgrades it is important to note that the
tracking system from Run I which lacked a magnetic field and suffered
from radiation damage was replaced with a silicon microstrip tracker and
a fiber tracking detector in a @xmath T magnetic field. The detector
consists of three major subsystems: the central tracking detectors, a
uranium/liquid-argon calorimeter and a muon spectrometer. A side-view of
the upgraded DØ detector is shown in Fig. 4 .

This chapter gives a brief description of the upgraded DØ detector and
those components most pertinent to the analysis presented in this
thesis. A more detailed description can be found in Ref. d0_detector .

### 5 The DØ Coordinate System

In the detector description and the data analysis, the standard
DØ collaboration coordinate system is used where the positive @xmath
-axis points in the direction of the proton beam, the positive @xmath
-axis points radially outward from the Tevatron center and the positive
y-axis is pointing upwards. To specify a direction in the detector, the
polar and azimuthal angles @xmath and @xmath can be used. Since the
angle @xmath is not invariant under Lorentz transformations along the
@xmath -axis it is common to use the pseudorapidity @xmath instead.
@xmath approximates the true rapidity @xmath in the kinematic region
where the mass is negligible, i.e. when @xmath . The separation between
two objects labeled 1 and 2 can be expressed as the distance @xmath
between them in the ( @xmath ) plane, defined as @xmath . The term
“forward” is commonly used to describe regions of the detector at large
@xmath . Since the initial momentum along the beam axis is unknown and
some particles escape detection close to the beam axis the measured
variables are in general quantities transverse to the beampipe
direction, such as transverse momentum ( @xmath ) or energy ( @xmath ),
and missing transverse energy, @xmath , from neutrinos escaping the
detector.

### 6 The Central Tracking System

The measurement of tracks of charged particles and the reconstruction of
a production or decay vertex is an important part of experimental
studies at collider experiments. A precisely determined primary
interaction vertex allows accurate measurements of lepton @xmath , jet
@xmath and @xmath . Using the tracking information it is possible to
identify jets containing decay products of a @xmath -quark by finding
tracks emanating from a secondary vertex which is displaced with respect
to the primary interaction vertex. This is especially important for top
quark physics were the dominant top quark decay is to a @xmath -quark
and a @xmath boson. The central tracking system in DØ was completely
replaced after Run I. The new system consists of two parts: The Silicon
Microvertex Tracker (SMT) and the Central Fiber Tracker (CFT) enclosed
in a magnetic field oriented along the beam axis. The @xmath T magnetic
field is provided by a @xmath m long superconducting solenoid magnet
with a radius of approximately @xmath cm. Charged particles produced in
the collision are bent around the field lines in a magnetic field of
strength @xmath . The radius @xmath of the particle trajectory can be
used to calculate the @xmath through kleinknecht :

  -- -------- -- -----
     @xmath      (2)
  -- -------- -- -----

Combined, the SMT and CFT locates the primary interaction vertex with a
resolution of @xmath m along the beam direction. They provide an impact
parameter ⁵ ⁵ 5 The impact parameter is defined as the distance of
closest approach ( @xmath ) of the track to the primary vertex in the
plane transverse to the beamline. The impact parameter significance is
defined as @xmath , where @xmath is the uncertainty on @xmath .
resolution of about @xmath m in the @xmath plane for particles with
@xmath GeV in the central region d0_detector . In addition, they also
provide information on track @xmath to the trigger system for fast event
decisions. A schematic view of the central tracking system is shown in
Fig. 5 .

#### 6.1 The Silicon Microvertex Tracker

The Silicon Microvertex Tracker (SMT) is the innermost part of the
DØ detector. Its purpose is to provide both high-quality vertex finding
and high resolution tracking. Its design is primarily dictated by the
accelerator environment. For example the length of the device is
determined based on the length of the interaction region, @xmath cm.
Since the SMT has to cover a significant solid angle it is difficult to
ensure that the detector planes are always perpendicular to the outgoing
particle trajectories. Therefore, the SMT has a barrel design
interspersed with discs in the central region, while the forward region
consists primarily of disks. There are six barrels, each with four
silicon readout layers. Each barrel is attached (at the high @xmath
side) to a disk with wedge detectors. At the outside of the barrel-disk
assembly three disks are mounted. In the forward region four larger
disks provide tracking capabilities up to @xmath , see Fig. 6 .

Particles with low pseudorapidities are mainly measured by the barrels
while particles with larger pseudorapidities are also measured by the
disks.

There are several different types of silicon sensors. Both the disks and
barrels uses a combination of single-sided and double-sided sensors
depending on the location in the SMT (varying with both layer and @xmath
for the barrel). The SMT has in total 912 readout modules, with 792,576
channels. Most of the sensors have a pitch of @xmath m and the hit
resolution is approximately @xmath m (improving from the @xmath
dependence due to the pulse height information). The resolution in
@xmath -direction varies depending on the detector type in the various
part of the SMT ranging from around @xmath m to @xmath m for @xmath and
@xmath stereo angle detectors respectively. The @xmath resolution for
central tracks with @xmath varies with momentum from @xmath % at track
momentum of around @xmath GeV to @xmath % for tracks with approximately
@xmath GeV momentum. The resolution degrades fast in the forward region
up to @xmath % for tracks around @xmath GeV at @xmath .

#### 6.2 The Central Fiber Tracker

The Central Fiber Tracker (CFT) surrounds the SMT and covers the radial
space from @xmath to @xmath cm from the center of the beampipe as shown
in Fig. 5 . The essential part of the CFT is the scintillating fiber
system. Each fiber is @xmath m in diameter (including cladding which is
approximately @xmath m thick) and oriented along the beam pipe in
doublet layers on eight concentric cylinders. The innermost two
cylinders are @xmath m long and the outer six are @xmath m long. The
fibers in each doublet layer are separated by half the fiber diameter to
achieve total coverage. Each cylinder supports one axial (oriented along
the beam axis) doublet layer, see Fig. 7 , and a second doublet layer
oriented with @xmath stereo angle.

The scintillating fibers are arranged in a multiclad structure using
polystyrene as core material and paraterphenyl as the light-emitting
material. To get the light out a second wavelength-shifter material is
added and the light is transported via a clear fiber to the Visible
Light Photon Counters (VLPC’s) connected to one end of the fibers where
the light is converted to an electric pulse and read out. The CFT has in
total 76,800 channels of VLPC read out and the hit resolution is around
@xmath m. Approximately @xmath km of scintillating and @xmath km of
clear fiber is used in the CFT in total.

The CFT’s axial layers are part of the fast Level 1 trigger which aid in
finding the interesting collisions discussed in more detail in Sec 11 .

The @xmath resolution achieved combining SMT and CFT is studied using
@xmath events and resolutions of @xmath have been obtained pt_res .

### 7 The Preshower Detectors

The preshower detectors provide an early energy sampling and good
position measurement. The detectors are designed to help in electron
identification and to correct for the energy lost in the upstream
material (mainly the solenoid). The fast response also allows the
preshower detectors to be part of the event trigger.

The design consists of two similar detectors, the Central Preshower
Detector (CPS) and the Forward Preshower Detector (FPS). The CPS (FPS)
consists of three (two) layers of triangular strips of scintillating
material interleaved to remove any gaps.

The central preshower detector (CPS) is placed in the @xmath cm gap
between the solenoid magnet and the central calorimeter covering @xmath
as shown in Fig. 5 . Inside the CPS, a lead radiator about one radiation
length, @xmath , thick (corresponding to @xmath cm) and @xmath cm long
is inserted. The solenoid and the lead radiator together comprise about
two radiation lengths (the solenoid is @xmath thick) for normal incident
particles increasing to about four radiation lengths at maximum CPS
coverage. Electrons and photons are converted into showers in the
upstream material and this provides a discrimination between electrons
or photons and pions, where the latter mostly passes through without
showering.

The two (north and south) forward preshower detectors are mounted on the
inner part of the end cap calorimeter (see Fig. 5 ) covering @xmath .
Each detector consists of a two radiation lengths thick stainless steel
radiator sandwiched between two layers of scintillating strips. This
design allows for position measurements as well as possible
discrimination between electrons or photons and pions.

### 8 The Calorimeter

The calorimeter absorbs and measures particle energy and the position of
the deposited energy. It consists of a central calorimeter (CC) and two
(north and south) end cap calorimeters (EC), see Fig. 8 . The Run II
calorimeter is essentially the same calorimeter as in Run I but with
upgraded electronics adapted to the new accelerator environment, i.e.
the higher bunch crossing frequency.

The CC covers a region up to @xmath and the two end cap calorimeters
extend the coverage to @xmath , as shown in Fig. 9 . The CC and EC are
constructed in three parts; the electromagnetic section (EM) closest to
the beam pipe followed by the fine hadronic section (FH) and the coarse
hadronic (CH) section. The active medium for all the calorimeters is
liquid argon and the three calorimeters are enclosed in a cryostat at a
temperature of approximately @xmath K. Different locations have
different absorber plates. The main absorber used in the EM calorimeter
is nearly pure depleted uranium assembled into thin plates ( @xmath mm)
in both CC and EC. The fine hadronic section uses @xmath mm thick
uranium alloy plates (both in the CC and EC) and the coarse hadronic
section uses @xmath mm thick copper (stainless steel) plates in the CC
(EC).

The readout cells of the calorimeter are arranged in sizes such that
each cell covers @xmath , which is comparable to the transverse sizes of
showers: @xmath cm for EM showers and about @xmath cm for hadronic
showers. Longitudinal depth segmentation is important when
distinguishing between electrons or photons and hadrons. In the EM
calorimeter there are four depth layers (in both EC and CC). The third
layer is placed at the expected shower maximum and is twice as finely
segmented in the lateral direction for increased spatial resolution. The
amount of material (tracking, cryostats, solenoid, etc.) between the
interaction region and the first active gap in the EM calorimter at
amounts to approximately @xmath in the CC and @xmath in the EC. The EM
calorimeter contains uranium comparable to approximately 20 radiation
lengths ( @xmath mm) to capture the overwhelming part of the
electromagnetic shower. As the nuclear interaction length is much larger
than the radiation length ( @xmath ) the hadronic particles typically
deposits most of its energy in the hadronic part of the calorimeter.

The calorimeter provides trigger information to all three trigger
levels. The Level 1 and Level 2 triggers are based on analog sums of
energy in special trigger towers.

The energy resolution of a sampling calorimeter can be parametrized by

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

The parameter @xmath is called the “constant term” and comes from
calibration errors or other systematic effects, @xmath is an energy
independent “noise term” including contributions from uranium decays and
electronic noise. The largest contribution comes from the “sampling
term”, @xmath , which is the statistical error in the sampling
procedure. For the Run II detector, preliminary studies shows a
degradation of the calorimeter resolution from several sources e.g.
worse noise characteristics of the detector electronics, shorter pulse
shaping due to the increased bunch crossing frequency, large
cell-to-cell miscalibrations and more upstream material from the new
tracking system, degrading the sampling term. The jet energy resolution
is described in Sec. 17.3 .

#### 8.1 The Inter-Cryostat Detector

Due to the fact that the calorimeter is contained in three separate
cryostats it has incomplete coverage in the region @xmath . Therefore,
scintillation counters with a cell size matching the calorimeter as well
as single cell structured scintillation counters are inserted in this
region. These detectors allow for a sampling of the inter-cryostat
region improving the energy resolution.

### 9 The Muon Spectrometer

Muons lose only a small fraction of their energy in the central tracking
system and calorimeter. The DØ muon system muon_detector is located
around the calorimeter and is used to trigger and to measure muon @xmath
and charge independently of the tracking system. An overview of the muon
system is shown in Fig. 10 .

The system is divided into a central and forward detector. A @xmath T
magnetic field is supplied by a @xmath cm thick iron toroid magnet,
built in three sections to allow for easier access to the inner part of
the detector. The central magnet is located at a radial distance of
@xmath cm from the beam line covering the region @xmath . The forward
toroids are located at @xmath cm. The muon detectors consist of
proportional drift tubes (PDT’s), mini drift tubes (MDT’s) and
scintillation counters. The PDT’s are rectangular volumes filled with
gas and cover @xmath . A charged particle ionizes the gas and the
electrons are amplified at the @xmath m thick anode wire. The Vernier
cathode pads above and below the wire are segmented to provide
information on the ionization position along the wire. The maximum
electron drift velocity is @xmath ns and gives a single wire resolution
of around @xmath mm in the radial direction of the wire for @xmath cm
wide drift cells. The MDTs extend the coverage up to @xmath and consist
of drift tubes with shorter electron drift times ( @xmath ns) than the
PDTs (the MDT cell width is @xmath mm and the length ranges from @xmath
to @xmath m). The radial resolution for single wires is @xmath mm.

Both the central and forward drift chambers consist of three layers, A,
B and C. The A layer is located inside the toroid magnet while the B and
C layers are outside. Each layer also has a sheet of scintillating
pixels (except layer B in the central region) used for triggering,
cosmic muon (and other background) rejection and track reconstruction.
The scintillator geometry is matched to the central fiber tracker
trigger read out to provide matching of tracks from the central tracking
system to the muon system at the first trigger level. The scintillation
counters allow for triggering on muons with @xmath down to @xmath GeV
(the A layer drift tubes and scintillation counters also allow for
triggering on muons that do not penetrate the toroid magnet). The muon
system drift tubes are shown in Fig. 11 .

Directly below the DØ detector, the support structure and the readout
electronics causes the muon system to have only partial coverage in this
region. The forward C layer of scintillation detectors are shown in Fig.
12 .

The overall momentum resolution, including information from the silicon
microvertex tracker and central fiber tracker, is defined by the central
tracking system for muons with momentum up to approximately @xmath GeV.
The muon spectrometer improves the resolution only for very high energy
muons.

### 10 Luminosity Monitoring

The number of observed events @xmath for a certain class of process in a
collider is given by,

  -- -------- -- -----
     @xmath      (4)
  -- -------- -- -----

where @xmath is the acceptance, @xmath is the cross section for the
process and @xmath the probability to record the event if it is within
the acceptance region (i.e. the efficiency). For a cross section
measurement e.g. @xmath production, the efficiency and acceptance for
@xmath events (and background) is calculated and the only unknown in Eq.
4 is @xmath and the proportionality factor called instantaneous
luminosity @xmath . The luminosity is defined by the beam parameters of
the Tevatron accelerator e.g. the number of protons and anti-protons in
each bunch, the bunch crossing frequency, the lateral bunch size, the
bunch overlap in the collision region etc.

From Eq. 4 the instantaneous luminosity can be calculated by counting
the number of observed events for a process with known cross section. At
DØ d0_lumi , the process used is the inelastic @xmath cross section
@xmath , i.e.

  -- -------- -- -----
     @xmath      (5)
  -- -------- -- -----

The inelastic @xmath cross section has been measured by several
experiments inel_ppbar_xsec to be @xmath mb. The detectors used for
counting the interaction rate are the Luminosity Monitors (LM)
consisting of two arrays of 24 plastic scintillators located at @xmath
cm from the center of the detector covering the region @xmath as shown
in Fig. 13 . They are attached to the inner part of the cryostat housing
the end cap calorimeters, see Fig. 5 .

In addition to measuring the luminosity, the LM is used to provide a
fast measurement of the position of the primary interaction vertex, used
by the fast Level 1 trigger. The time-of-flight difference between
particles in the @xmath collision is calculated with a resolution of
@xmath ns and the resolution of the vertex position in the @xmath
-direction is @xmath cm d0_detector .

### 11 The Trigger System

Bunch crossings at the Tevatron occur at 2.5MHz rate. This immense rate
is needed as the overwhelming majority of @xmath encounters result in
collisions of little interest. The production of heavy objects like the
top quark, @xmath or @xmath bosons or collisions that could indicate the
existence of New Physics processes occur at very low rate. The trigger
system allows for a fast event-by-event decision on whether or not the
collision was interesting and reduces the output rate to @xmath Hz, more
suitable for writing to disk.

The trigger is a 3-tiered system where each tier (Level 1, Level 2 and
Level 3) investigates the event in larger detail than the preceding one
and restricts the amount of data sent to the next level. An event can
fail the trigger because: It did not fulfill the trigger requirements
and was declared uninteresting, it was mistaken for an uninteresting
event (trigger inefficiency) or the trigger system was busy processing
previous events (dead time).

The Level 1 (L1) Trigger is built from specialized hardware
investigating every event for interesting features. Pipelines mounted on
the front-end electronic boards allows for an event decision in @xmath
s. The L1 trigger receives input from several subdetectors: The
calorimeter L1 trigger looks for patterns of large transverse energy
deposits in special trigger towers ⁶ ⁶ 6 Due to noise considerations not
all trigger towers are used in the L1 calorimeter trigger. , the Central
Fiber Tracker L1 trigger looks for tracks exceeding predetermined
thresholds in transverse momentum, the L1 muon trigger searches for muon
candidates with a matched track from the CFT, an indication of the
collision point is given by the luminosity monitors. The L1 reduces the
rate from @xmath MHz to about @xmath kHz.

The level 2 (L2) trigger stage has an event decision time of
approximately @xmath s and further analyzes the event by two stages upon
a L1 trigger accept: A preprocessing stage that analyzes the data into
simple physics objects e.g. track clusters, and a global stage that
combines trigger information from different subdetectors e.g. matching
tracks from the inner detector to electromagnetic clusters in the
calorimeter. The output rate of the L2 trigger is about @xmath kHz.

The last trigger level, Level 3 (L3), is a software trigger which
reduces the event rate from to @xmath Hz to allow for writing the
interesting events to disk for later offline processing. The L3 trigger
is fully programmable using algorithms based on complete physics objects
which are as sophisticated as those available during the offline
reconstruction phase. A L3 decision is based on full event information
with complex variables such as spatial separation between jets and
electrons, invariant masses of objects, displaced tracks from the
primary vertex, etc.

## Chapter \thechapter Event Reconstruction

The data in a single event collected from the DØ detector is the
immediate detector response from nearly a million detector readout
channels. To find evidence for the products of the collision and measure
their properties these signals needs to be processed carefully. To
reduce the huge amount of data from the experiment the information is
handled by a chain of sophisticated software algorithms which create and
define physics objects that represent the particles originating from the
@xmath interaction. Each algorithm is designed to identify a particular
object often based on the required efficiency and purity. The analysis
presented here is based on the @xmath @xmath final state which requires
identification of the primary vertex, tracks, leptons (electrons and
muons), jets and their flavors and missing transverse energy @xmath .

This chapter describes the event signature of top quark pair production
and the most important background processes. A short description of the
identification and reconstruction of the different physics objects is
also given.

### 12 Event Signatures

#### 12.1 Experimental Signature of @xmath Production

Since the top quark decays almost exclusively through @xmath , the final
state of the top quark pair production can be characterized by the decay
of the two @xmath bosons. The @xmath boson decays leptonically via
@xmath , @xmath or @xmath with a branching fraction of @xmath % each or
to hadrons with @xmath %. The decay modes of the @xmath bosons are
reflected in the experimental search channels:

-    All jets channel
    Both @xmath bosons decay hadronically into @xmath pairs and the
    final state is characterized by two @xmath -quark jets and at least
    four jets from the hadronization of the @xmath pairs. No significant
    @xmath is expected. This channel has the largest branching fraction
    but suffers from large multijet backgrounds.

-    lepton-plus-jets channels
    One @xmath boson decays hadronically and the other leptonically. The
    final state is characterized by two @xmath -quark jets, at least two
    jets from the @xmath pair, one charged lepton and significant @xmath
    due to the neutrino from the leptonically decaying @xmath boson.
    This decay chain provides a clean signature of a single isolated
    lepton with high transverse momentum and large @xmath . Together
    with the large branching fraction this channel is most promising for
    measurements of top quark properties and is also the one used to
    determine the electric charge of the top quark in the the present
    analysis. This channel is also referred to as @xmath +jets and
    @xmath +jets separately depending on the flavor of the charged high
    transverse momentum lepton or @xmath collectively.

-    dilepton channels
    Both @xmath bosons decay leptonically. The final state is
    characterized by two @xmath -quark jets, two charged leptons and
    large @xmath . These channels has an excellent signal-to-background
    ratios but suffer from small branching fractions.

The top quark pair decay channels and their branching ratios are
summarized in Fig. 14 .

Note that the top quark pair analysis in DØ includes the leptonically
decaying @xmath in the @xmath and dilepton channels since this gives a
similar experimental signature.

Figure 15 shows a schematical view of a @xmath event. Additional jets
can be produced in all channels due to initial (ISR) and final state
radiation (FSR) discussed below.

In summary, the main feature of a @xmath event is the presence of one
charged isolated lepton produced centrally in the detector with high
transverse momentum, a neutrino with comparable momentum giving rise to
a significant @xmath and several jets.

#### 12.2 Background Signature

At hadron colliders, QCD multijet production has a large cross section
and is initially the largest background. This strong production of jets
contain no genuinely isolated leptons nor missing transverse energy.
However, these can be faked by instrumental effects. A jet fluctuating
to a high electromagnetic content can fake an electron. In addition,
semi-leptonic decay modes of @xmath - and @xmath -quarks can give rise
to fake isolated leptons if the associated jet is not reconstructed,
either due to a low energy deposition in the calorimeter or inefficiency
of the jet reconstruction. In combination, fake missing transverse
energy can arise due to unreconstructed jets, the neutrino from the
heavy flavor decay or a mismeasurement of the lepton momentum. However,
even an unreconstructed jet deposits a small amount of energy in the
calorimeter and gives signal in the tracking detectors. Thus, a good
handle to suppress this background is to require that the lepton is
isolated from other activity in the detector.

The main source of @xmath boson production at the Tevatron is due to
quark anti-quark fusion. In this process gluon radiation from the
incoming quark lines (ISR) can give the @xmath boson transverse momentum
and add more partons to the final state. Partons are a common used
notation, remaining from the 70’s, for the constituents of a hadron
(quarks and gluons). Figure 16 shows examples of @xmath production with
an additional parton in the final state, called @xmath ⁷ ⁷ 7 Here the
additional partons in the final state are assumed to hadronize into
jets. .

Processes leading to even higher number of partons in the final state
can be produced by gluon radiation of the quark and gluon lines in the
initial or final state. Computation of @xmath boson production in
association with up to four partons in the final state has been
performed to leading order alpgen_manual with different techniques to
handle the immense amount of Feynman diagrams contributing to the
process.

Due to the similar experimental signature as @xmath events, the
production of @xmath (with subsequent leptonic decay) in association
with four partons in the final state is the dominant background in this
analysis after standard preselection of @xmath boson candidates. Even
though the objects in the final state are the same as in a @xmath event,
there are significant differences in several aspects of the event that
can be exploited to separate @xmath events from this background. The
analyzes measuring the @xmath production cross section utilize the fact
that; ( i ) @xmath bosons produced from the decay of top quarks have on
average larger transverse momentum and are produced at lower @xmath ( ii
) the additional jets are mainly produced by gluon radiation, resulting
in jet with lower transverse momenta and at higher @xmath
xsec_240_ljets_topo_publ . Another way to discriminate between a @xmath
and a @xmath event is to exploit the fact that a @xmath event has a
higher fraction of @xmath -quarks in the final state. The @xmath -quarks
in a @xmath event hadronize into @xmath hadrons and the event is
expected to have at least two heavy flavor jets originating from @xmath
-quarks (see Sec. 17.4 ). As discussed in more detail in Sec. 21 , the
dominant background in the @xmath channel after the requirement of at
least two jets identified as @xmath -quark jets is the production of a
@xmath boson in association with four jets out of which two are @xmath
-quark jets (denoted as @xmath ).

### 13 Tracks

Charged particles traversing the inner detector deposit energy in the
silicon layers of the SMT and produce scintillation light in the CFT ⁸ ⁸
8 In reality, tracks do not always have hits in all layers of the SMT
and CFT. . The hits in the different inner detector layers together with
the bending in the magnetic field allows for the reconstruction of the
particle’s trajectory. The track reconstruction algorithm groups
together hits in different detectors into clusters which are then fitted
to find a possible physical path of the particle kalman_fitter .

### 14 Primary Vertex

In proton anti-proton collisions several interactions between the
constituent partons are possible. The primary interaction vertex (PV)
are the point were the hard scattering (high transverse momentum)
interaction took place. The spread of the interaction point in the (
@xmath ) plane, transverse to the beam line, is small due to the
transverse size of the Tevatron beam which is of the order of @xmath m.
In @xmath -direction, the spread of the PV position extends up to @xmath
cm following a Gaussian distribution with a width of approximately
@xmath cm. Finding the primary vertex (PV) is crucial for all @xmath
-tagging algorithms and in order to determine if a lepton originates
from the PV.

The PV algorithm pv_alg_p14 used by DØ starts by fitting all
reconstructed tracks to a common vertex and removes bad track fits until
a predefined value of the goodness of fit is reached. The same procedure
is repeated for the tracks that were removed until all tracks are
assigned to a PV. There are two similar implementations of the PV
algorithm , DØ reco and DØ root , with the difference that DØ root has
an additional step of clustering tracks in the @xmath -direction and
slightly tighter track selection criteria (the @xmath significance is
required to be @xmath compared to @xmath ). In both algorithms, only
tracks with @xmath GeV are considered and at least two hits in the SMT
detector. If more than one PV is found, the hard scatter vertex is
selected by observing that hard scatter vertices have on average tracks
with larger transverse momentum associated to it than minimum bias
vertices pv_prob_p14 .

The performance of the PV selection algorithms are comparable. There are
on average 20 tracks in a generic QCD multijet event and the average PV
reconstruction efficiency is 98%. This efficiency is about 100% in the
central @xmath region of the SMT fiducial region ( @xmath for the
barrel) and drops quickly outside of this region due to the requirement
of at least two SMT hits for tracks forming the PV.

### 15 Muons

Muons are identified in the drift chambers and scintillation counters by
matching hits in the layers on either side of the toroid magnet. The
DØ muon group has established a set of standard muon identification
criteria applied to the candidate muon p14muonid :

-   At least two A layer wire hits,

-   at least one A layer scintillator hit,

-   at least two BC layer wire hits,

-   at least one BC scintillator hit(except for central muons with less
    than four BC wire hits),

-   to be inconsistent with a cosmic muon based on timing information
    from the scintillator hits.

A muon identified in the above fashion is the basis for the muon
reconstruction. The superior track resolution of the central tracker
(SMT and CFT) is used to improve the muon’s momentum resolution.
Therefore, in addition to the above criteria, a track consistent with
originating from the PV is required to be spatially matched to the muon
candidate.

Muon tracks with no hits in the SMT (which have been shown to have a
worse fit and thus a worse resolution) are re-fitted constraining the
muon track to the PV in order to improve their momentum resolution.

The muon momentum scale and resolution was determined by reconstructing
the @xmath boson invariant mass peak in @xmath events. Comparison of the
invariant mass peak in data and simulation reveals a significantly
better resolution in the simulation than in data as well as a shifted
peak position. This is accounted for by smearing the reconstructed muon
momenta in simulated events to match the resolution in data
xsec_note240_mujets_topological .

### 16 Electrons

The ability to identify and reconstruct high @xmath electrons is
essential for many analyzes, including top quark measurements,
electroweak processes and searches for New Physics. Being charged
particles, electrons deposit energy in the central tracking detectors
before showering predominantly in the EM section of the calorimeter. The
main backgrounds to reconstructed true electrons (so-called “fake”
electrons) are:

-   @xmath showers overlapping with a track from a charged particle,

-   photons which convert to @xmath pairs,

-   @xmath which undergo charge exchange in the detector material,

-   fluctuations of hadronic showers.

At DØ electron identification involves three steps. First, electron
candidates are searched for by looking for clusters in the EM
calorimeter. Secondly, a track in the central tracking system that is
spatially matched to the EM cluster is searched for and finally the
electron has to pass a likelihood test based on shower shape variables.
To handle all the sources of backgrounds while keeping the efficiency to
reconstruct real electrons high, several variables are used:

-   The fraction of energy deposited in the electromagnetic part of the
    calorimeter is required to be above 90% of the total deposited
    energy in the calorimeter inside the cone of @xmath .

-   Electrons tend to be isolated from other activity in the
    calorimeter. Therefore, at most 15% of the energy of the cluster is
    allowed to be deposited in a hollow cone ( @xmath ) around the
    electron’s direction.

-   The shower shape of candidate EM clusters is compared to the
    expected shape from electrons emlhood_p14_org .

-   A track is required to point to the EM cluster.

-   A seven parameter likelihood is built that rejects background-like
    EM candidates emlhood_p14 .

-   The electron candidate is required to be in the central calorimeter,
    since the fake electron background is not completely understood in
    the end cap calorimeters.

The electron momentum scale and resolution was studied by reconstructing
the @xmath boson invariant mass peak in @xmath events. The comparison of
data with simulation further revealed a higher resolution in the
simulation and a corresponding scale factor and smearing is applied to
simulated electrons to reproduce the measured quantities. Detailed
information on the selection criteria, electron momentum scale and
resolution can be found in Ref. xsec_note240_ejets_topological .

### 17 Jets

In the analysis presented in this thesis, jets form an essential
ingredient in the event selection. Each event is required to have at
least four jets out of which two are identified as @xmath -quark jets.
This section describes the identification and energy calibration of jets
and explains the identification of jets originating from the
hadronization of @xmath -quarks.

#### 17.1 Jet Identification

Jets are reconstructed based on finding calorimeter towers with an
energy above a predefined threshold of @xmath GeV which are further
collected into clusters which form candidate jets cone_algorithm . The
jet cone size is @xmath and the uncalibrated transverse energy
reconstruction threshold is @xmath GeV. Before any calorimeter physics
object (jets, electrons, photon or @xmath ) are reconstructed a special
calorimeter algorithm is applied to remove measured cell energies likely
to arise from noise T42_1 ; T42_2 ; T42_3 .

After jets have been reconstructed it is important to reject those that
are poorly reconstructed or are electrons or photons mis-identified as
jets. Therefore, several additional requirements based on the expected
properties of jets are applied: The probability for a jet to deposit a
large fraction of its energy in the coarse hadronic section of the
calorimeter is low (and the coarse hadronic section is subject to a
higher noise level due to its larger cell size) and the energy
deposition in this section is required to be below 40%. Electrons and
photons typically deposits all of their energy in the EM section and
therefore the fraction of energy deposited in the EM part for jets is
required to be between 5% and 95%. Jets reconstructed from few or single
cells containing a large fraction of the jets total energy are likely to
be fake jets due to noise in the cell. Therefore, jets are rejected if
one cell contains above 90% of the total energy or the ratio of the cell
with the highest energy to the next-to-highest is above @xmath . Since
the Level 1 calorimeter trigger has an independent readout chain it has
been proven to be a powerful handle to reject fake jets due to noise in
the precision readout electronics. Therefore, the sum of energy in the
Level 1 calorimeter trigger towers is required to be above 24-40%
(12-20%) in the central and end cap calorimeter (inter-cryostat) regions
depending on the fraction of total energy deposited in the coarse
hadronic section. If a jet overlaps with EM candidates (which are also
reconstructed as jets if their energy is above @xmath GeV) an ambiguity
appears about which energy scale that should be applied. The solution is
to reject jets that overlap with electrons or photons within @xmath .
The minimum transverse momentum after scale and corrections described
below is required to be @xmath GeV.

#### 17.2 Jet Energy Scale

Quarks and gluons from the hard interaction hadronize into jets and
deposits energy in the calorimeter as shown schematically in Fig. 17 .

The goal of the Jet Energy Scale (JES) is to correct the measured jet
energy in the calorimeter back to the stable-particle energy before
interacting with the calorimeter. Various effects cause the measured
energy to be different from the particle jet e.g. the use of a sampling
calorimeter, noise and dead-material.

The JES is derived using @xmath events in a back-to-back configuration
jes_nim . Using the fact that the electromagnetic energy scale is known
to high precision ⁹ ⁹ 9 The EM energy scale can be calibrated by
calculating the invariant mass of electrons or photons in inclusive
samples such as @xmath , @xmath and @xmath . the JES can be extracted
from the transverse momentum imbalance in such an event.

The JES is divided into different subcorrections applied in order of
appearance to jets: The offset correction corrects for energy not part
of the hard scatter (detector and electronic noise, pile-up and energy
from the underlying event, see Sec. 19 for a description of pile-up and
underlying event). This luminosity dependent offset correction is
calculated in data using events triggered by the luminosity monitors,
signaling a possible inelastic @xmath collision (minimum-bias events).
The response correction is a correction for the non-uniform response of
parts of the detector (dominated by the ICD region) and an absolute
response for a uniform treatment of jet energies derived from well
defined @xmath events in a back-to-back configuration. The last
correction is the showering correction which attempts to correct for
particles inside the jet that deposits their energy outside the jet cone
(or the reverse process). This correction is extracted from jet profiles
in @xmath events.

The final result is a JES correction factor shown in Fig. 18 and 19 for
data and simulation respectively.

#### 17.3 Jet Energy Resolution

The Jet Energy Resolution (JER) can be determined by studying the @xmath
imbalance in dijet events jer_jetcorr5.3 . The asymmetry variable @xmath
is calculated and the jet resolution can be inferred from the width of
the asymmetry @xmath as,

  -- -------- -- -----
     @xmath      (6)
  -- -------- -- -----

At lower energies ( @xmath GeV) @xmath events are used. ¹⁰ ¹⁰ 10 This
because the triggers used to select dijet events are inefficient for jet
energies below @xmath GeV. . The asymmetry variable @xmath is calculated
as @xmath and the JER can be expressed as,

  -- -------- -- -----
     @xmath      (7)
  -- -------- -- -----

The JER measured using the procedure above is then parametrized as (see
Sec. 8 ),

  -- -------- -- -----
     @xmath      (8)
  -- -------- -- -----

and the results for data and simulation are shown in Tab. 2 and Tab. 3
respectively.

More details can be found in jer_jetcorr5.3 . The resolution is clearly
better in the simulation and simulated jets are therefore smeared to
match the resolution in data.

#### 17.4 @xmath-Quark Jets

Jets can further be classified by their flavor. A jet originating from
the hadronization of a gluon ( @xmath ), @xmath -, @xmath - or @xmath
-quark or from the a @xmath - or @xmath -quark is referred to as a light
jet or a heavy flavor jet respectively. There are two techniques to
distinguishing between light and heavy flavor jets: Soft Lepton Tagging
uses the presence of a lepton within a jet as a signature for a
semi-leptonic decay of a heavy flavor hadron. The branching fraction for
a semi-leptonic ( @xmath or @xmath ) @xmath hadron decay is @xmath % for
each lepton mode PDG . Lifetime Tagging uses the the fact that hadrons
containing a @xmath -quark have a lifetime of approximately @xmath ps. A
@xmath hadron originating from the primary vertex will therefore travel
a significant distance from the primary vertex before decaying (the
average flight length is around @xmath mm for @xmath GeV hadron).
Approximately 70% of the @xmath mesons with a decay length dl greater
than @xmath mm have more than @xmath displaced tracks from its decay
products with an impact parameter significance above three bid_group .
The lifetime tagging algorithm therefore searches for tracks
significantly displaced from the primary vertex as shown schematically
in Fig. 20 .

In this analysis both ways to identify heavy flavor jets are used. A jet
tagged by the lifetime tagging algorithm is called a “ @xmath -tagged
jet” or simply a “tagged jet”. A jet tagged by the soft lepton tagging
algorithm is called a “ @xmath -tagged jet”. Due the difficulty of
identifying an electron within a jet, the soft lepton tagging algorithm
uses only the muonic semi-leptonic decay mode. Note that a @xmath
-tagged jet is not necessarily a jet originating from the hadronization
of a @xmath -quark or even a @xmath -quark. The tagging technique may
wrongly tag light jets as discussed below in more detail. In this thesis
a jet from a @xmath -quark ( @xmath ) is called @xmath -quark jet ¹¹ ¹¹
11 Here the notation for a jet originating from e.g. a @xmath or @xmath
-quark is called @xmath -quark jet collectively. In later sections the
difference between a @xmath or @xmath -quark jet is exploited and the
notation will be obvious. or gluon jets for gluon initiated jets.

To separate the performance of the different algorithms from detector
effects, such as calorimeter noise and tracking inefficiencies, the
probability for a jet to be tagged using lifetime tagging is broken down
into two components: (i) The probability for a jet to be taggable (also
called taggability ) and (ii) the probability for a taggable jet to be
tagged (also called tagging efficiency ). The DØ @xmath -identification
group bid_group defines a taggable calorimeter jet as a jet
reconstructed in the calorimeter matched to a track-based jet
(track-jet) within @xmath . A track-jet is defined by the following
track requirements: @xmath GeV (where at least one track has @xmath
GeV), at least one hit in the central part of the SMT detector and
matched to the primary vertex within @xmath in @xmath space and within
@xmath cm in the @xmath -direction.

The taggability is determined directly from data and parameterized as a
function of the jet @xmath and @xmath . Due to the requirement of hits
in the central region of the SMT the taggability is expected to have a
large dependence on the @xmath -position of the primary vertex. The
taggability is shown in Fig. 21 for the preselected data sample (see
Sec. 21 for the sample definition).

There are several ways of tagging a jet using lifetime tagging bid_group
. In this analysis the Secondary Vertex Tagger (SVT) algorithm is used.
The SVT algorithm finds tracks with large impact parameters within the
matched track-jets and reconstructs secondary vertices that are within
@xmath of the calorimeter jet direction. A calorimeter jet is tagged by
the SVT algorithm (SVT-tagged) if it has at least one secondary vertex
with decay length significance dl greater than @xmath . More information
on the exact definition of the SVT tagging algorithm can be found in
Ref. SVT and on the selections used in this analysis in Ref.
xsec_240_ljets_btag_publ . The simulation is unable to describe the
details of the tracking and is thus overestimating the tagging
efficiency for simulated jets. Therefore the tagging efficiency is
measured on data with as little input as possible from simulation.

To determine the SVT tagging efficiency for @xmath -quark jets in data,
a sample enriched in @xmath -quark jets is selected by requiring at
least one @xmath -tagged jet in the event. The measured SVT tagging
efficiency of jets in this sample is called “semi-leptonic” and is
parametrized as a function of jet @xmath and @xmath as shown in Fig. 22
.

In order to find the tagging efficiency for inclusive @xmath -quark jets
in data a scale factor is derived. This scale factor is the ratio of the
measured semi-leptonic tagging efficiency in data and the semi-leptonic
tagging efficiency in simulated events. The tagging efficiency for
inclusive jets in the simulation is then multiplied with the scale
factor to find the tagging efficiency for inclusive @xmath -quark jets
in data. Assuming that the scale factor for @xmath - and @xmath -quark
jets are the same, the @xmath -quark jet tagging efficiency in data can
be calculated in a similar way and varies between 7-12%. Due to the
limited track resolution and/or mis-reconstructed tracks, light jets can
be wrongly tagged. The probability for a light jet to be tagged (“mistag
rate”) is derived on a QCD data sample (which dominantly consists of
light jets) and parametrized again as function of jet @xmath and @xmath
. The mistag rate is of the order of 1%.

### 18 Missing Transverse Energy

In the final state of a @xmath event the neutrino can only be detected
by the measurement of the imbalance of momentum in the transverse plane.
This imbalance is measured by the vector sum of all energy depositions
in calorimeter cells. Cells in the coarse hadronic section of the
calorimeter are excluded if they are not part of a reconstructed jet.
This has been shown to improve the missing transverse energy resolution
due to the higher noise level in those cells. The vector opposite to
this total visible momentum is the raw missing transverse energy (
@xmath ).

The calorimeter response to electromagnetic particles such as electrons
and photons is different than for hadronic particles, and in particular
jets. This difference propagates directly to the @xmath if the energy
depositions are not calibrated correctly. All jets are corrected for the
jet energy scale and the correction is also propagated to the @xmath .
The same procedure is used for the EM calibration. After all
corrections, the resulting missing transverse energy is called the
“calorimeter missing transverse energy”.

Muons are minimal ionizing particles and traverse the whole detector if
the muon momentum exceeds a few GeV and their measured transverse
momentum must be added to the missing transverse energy. The muon
deposits only a small fraction of its total energy in the calorimeter
which is estimated and subtracted from the missing transverse energy
vector. This fully corrected missing transverse energy is denoted simply
as @xmath .

### 19 Monte Carlo Simulation

The detailed study of proton anti-proton collisions requires a detailed
understanding of all aspects of the event. Monte Carlo simulation of
such collisions are necessary to provide this knowledge.These
simulations includes the hard scattering interaction, hadronization,
detector response and digitization, allowing for a detailed comparison
between simulated events and data.

The hard scatter interaction is modeled using alpgen 1.3.3 alpgen_manual
that calculates the leading order matrix element. The set of parton
distribution functions used is CTEQ5L pdf_fit_cteq .

The complexity of @xmath collisions is due to the fact that the
colliding (anti-)protons are composite states of many partons. As a
consequence, an interesting hard (high transverse momentum) interaction
is accompanied by what is called the underlying event . It consists of
the beam-beam remnants , which are what is left over after a parton has
been knocked out of the initial incoming (anti-)proton, and multiple
parton interactions where in addition to the hard scattering interaction
there are one or more semi-hard interaction in the same event. A study
of the transverse momentum distribution of charged particles has led to
the so-called “Tune A” tuneA tuning of the Pythia underlying event model
parameters to better describe data.

In each bunch crossing of protons and anti-protons more than one hard
scatter @xmath collision may occur. These multiple interactions are
modeled by superimposing simulated events with minimum bias data. This
data is collected by selecting real collider events with minimum
activity in the detector i.e. not triggered by a high transverse
momentum lepton, jet or missing transverse momentum. In addition @xmath
collisions from consecutive bunch-crossings can sometimes be
reconstructed in the same event. This process, called Pile-up , is taken
into account in the simulation. At long distances, QCD becomes
non-perturbative and in this domain the colored partons are transformed
into colorless hadrons, a process called fragmentation ¹² ¹² 12 The
fragmentation and decay of particles are often collectively called
hadronization. . There exist several phenomenological models describing
this process, PYTHIA uses the Lund string model lund_model for
fragmentation. Heavy quark fragmentation is an important aspect in this
analysis and two models ( Bowler bowler and Peterson peterson
fragmentation) with alternative heavy quark fragmentation schemes are
used as a cross-check in the analysis presented in this thesis. The
decay of @xmath mesons are handled by EVTGEN ref_evtgen and other decays
are handled by PYTHIA . The important simulation of the detector
response to charged and neutral particles is simulated using DØ gstar
d0gstar , a GEANT3 ref_geant model describing the material and geometry
of the DØ detector. The simulated signal produced by the detector is
digitized using the software package DØ sim . From this point onwards
events from the simulattion and data can be treated in a uniform way.
The DØ event reconstruction software packages ( DØ reco ) transform the
detector signals into reconstructed physics objects such as
electromagnetic clusters, muon candidates, tracks, etc. Finally, the
TopAnalyze topanalyze program processes the reconstructed events further
with algorithms and object identification selections specific for the
DØ top quark working group and produces ROOT root files. Throughout the
analysis presented in this thesis, ROOT is used as analysis tool.

#### 19.1 Simulated Samples

The Monte Carlo samples used in the analysis are listed in Tab. 4 . The
samples are generated with parameters given in Ref.
topphysics_winter2004_note using ALPGEN as primary generator. Due to the
uncertainty in the modeling of initial state radiation in @xmath events,
a @xmath sample with a jet in the initial state is produced to estimate
this effect.

## Chapter \thechapter Determination of the Electric Charge of the Top
Quark

### 20 Overview of the Method

The determination of the electric charge of the top quark proceeds in
three steps. First a pure sample of events in the @xmath channel is
selected in data. This final state provides a sample with a
signal-to-background ratio of @xmath . The jet charge algorithm is
sensitive to poorly simulated tracking, and is therefore only applied to
jets tagged by the SVT algorithm. Only events with four or more
reconstructed jets are considered, two of which are required to be
SVT-tagged further increasing the purity of the sample
(signal-to-background ratio @xmath ). Each of the selected @xmath events
have two “legs”, one with a leptonically decaying @xmath boson ( @xmath
) and one with a hadronically decaying @xmath boson ( @xmath ), see Fig.
24 .

The second step of the analysis consists of assigning the correct jets
and leptons to the two “legs” of the event. To make this assignment the
same constrained kinematic fit package as for measurements of the top
quark mass is used hitfit . The goal of the analysis presented in this
thesis is to discriminate between two hypotheses: The SM top quark
charge of @xmath or an exotic quark with charge @xmath . In fact, the
analysis is only sensitive to the modulus of the quark’s charge ( @xmath
or @xmath ). This limitation does not lead to any loss of information
since it is always assumed that charge is conserved and every event
contains one quark and one anti-quark. It also allows for an equivalent
treatment of the quark and anti-quark. In each @xmath event, the
absolute value of the charge of the quark and anti-quark are computed,
which are assumed to be the same. Thus, each @xmath candidate event has
two observables @xmath which are built in the following way: The first
combines the charged of the lepton from the @xmath decay and the charge
of the @xmath -quark jet associated to the leptonic side of the event by
the kinematic fit. The charge of the @xmath -quark jet is computed using
a jet charge algorithm and simply added to the lepton charge and the
absolute value of this number is taken. The second observable is the
charge of the second “leg” of the event. It is obtained by taking the
charge of the second @xmath -quark jet and subtracting the charge of the
lepton. This procedure is almost equivalent to the doubling of the
dataset size in terms of statistical sensitivity. Any mistake in the
assignment of the lepton and the @xmath -quark jet due to the kinematic
fit will automatically propagate to both legs of the event, therefore
the two charge measurements are not uncorrelated. Nevertheless, the
measurement of the @xmath -quark jet charge is applied twice since it
improves the sensitivity of the measurement.

The jet charge distributions for @xmath - and @xmath -quark jets are
extracted from data and used to derive the expected distribution for the
SM and the exotic scenarios. The distribution of @xmath observed in the
selected @xmath data sample is then compared to the SM and exotic
expectations for @xmath .

In the next section the @xmath event selection and the sample
composition are presented. Section 22 is devoted to the description of
the jet charge algorithm. A method is developed to derive the
performance of the jet charge algorithm for SVT-tagged jets using data.
This is presented in Sec. 23 . Section 24 gives a detailed description
of the method to discriminate between the @xmath and @xmath scenarios by
combining the kinematic fit with the jet charge algorithm. The
systematic uncertainties are reviewed in Sec. 25 . The final result is
presented in Sec. 26 together with an upper limit on the fraction of
exotic quark pairs in the data set.

### 21 Signal Sample

As discussed earlier only a fraction of the collisions delivered by the
Fermilab Tevatron is recorded. Furthermore, well known variables in the
data are continuously monitored by detector experts and only the data
marked by these experts as good is used. This analysis uses data
collected by the DØ experiment in a period from June 2002 to August
2004. The total integrated luminosity amounts to approximately @xmath pb
@xmath and @xmath pb @xmath in the @xmath and @xmath channels
respectively. The difference between the two channels is due to the
different signal triggers used. In this section the selection of a data
sample enriched in @xmath events is described. The signal event
signature consists of:

-   One charged high transverse momentum lepton (electron or muon,
    either prompt or from a leptonically decaying @xmath ),

-   large missing transverse energy,

-   two jets from the hadronization of the @xmath -quarks from the top
    and anti-top quark decay,

-   two jets from the hadronically decaying @xmath boson.

The requirement of one high transverse momentum electron or muon and
large missing transverse energy rejects most multijet backgrounds. Other
physics processes, like @xmath , have the same signature.

There are three stages of the event selection: The first stage is to
make sure that the interesting events fulfilling the @xmath event
signature are written to disk. Therefore a set of trigger requirements
is defined. Secondly, a set of selection criteria is defined to select a
sample enriched in events with isolated high @xmath leptons (composed
primarily of @xmath +multijet and @xmath events). This second stage is
referred to as the preselection and is mostly concerned with selections
based on lepton requirements. In the third and last stage the @xmath
events are separated from most of the backgrounds by requiring the
presence of two @xmath -tagged jets in the event.

#### 21.1 Trigger Selection

The triggers used to record the signal sample require a lepton and at
least one jet and are different for the @xmath and @xmath channels ¹³ ¹³
13 The specific trigger requirements are divided into well defined
trigger lists. These trigger lists change with time to accommodate
detector and luminosity changes. .

The signal trigger for the @xmath requires at Level 1, at least one
electromagnetic calorimeter (EM) tower with transverse energy @xmath
above @xmath GeV and one additional calorimeter tower (EM+H) with @xmath
above @xmath GeV. At Level 2 an EM candidate with electromagnetic
fraction above 85% and @xmath above @xmath GeV is required. Level 3
requires an EM candidate with @xmath above @xmath GeV, passing a
transverse shower shape criteria and one Level 3 jet with @xmath above
@xmath GeV.

For the @xmath the signal trigger requires a calorimeter trigger tower
above @xmath GeV at Level 1. At Level 2, the calorimeter trigger varies
depending on the period when the data was collected and changes from no
requirement to at least one Level 2 jet with @xmath above @xmath GeV.
The Level 3 calorimeter trigger requirement is one jet candidate with
@xmath above @xmath or @xmath GeV depending on the period of data
taking. The muon trigger uses information from both Level 1 and Level 2.
At Level 1, a candidate is required two have a coincidence between at
least two layers of scintillators and similar requirements for Level 2
with the additional requirement of hits in the drift tubes.

The probability for a @xmath event to pass all the trigger requirements
is expressed in the @xmath trigger efficiency. The per muon, electron
and jet probabilities to fire the trigger are derived on data. The
@xmath trigger efficiency is then obtained by folding per lepton and per
jet efficiencies with the @xmath and @xmath of the lepton and jets in
simulated events. The @xmath trigger efficiency in the @xmath ( @xmath )
channel is @xmath % ( @xmath %) in events with four or more
reconstructed jets.

More detailed information on the specific trigger requirements used and
the measurement of the trigger efficiency can be found in
xsec_note240_mujets_topological ; xsec_note240_ejets_topological ;
top_trigger_package .

#### 21.2 Preselection

Apart from requirements on the charged lepton the preselection in both
channels are identical. The preselection in this analysis are the same
as in Ref. xsec_note360_ljets_btag where a more detailed discussion can
be found.

The common event preselection criteria for both @xmath and @xmath
channel are:

-   At least four jets with @xmath GeV and @xmath . All additional jets
    in the event are subject to the same @xmath and @xmath requirements,

-   missing transverse energy @xmath GeV,

-   a primary vertex with at least three tracks fitted to it and a
    @xmath coordinate @xmath within the fiducial volume of the SMT
    detector ( @xmath cm) ,

-   the distance in the @xmath -direction between the primary vertex and
    the lepton track has to be less than @xmath cm.

##### 21.2.1 Preselections specific to the @xmath channel

The event preselection criteria specific for the @xmath channel are:

-   One muon with @xmath GeV and @xmath .

-   The muon is required to be separated ( @xmath ) from reconstructed
    jets and also isolated from activity in the calorimeter by requiring
    that the scalar sum of @xmath of calorimeter clusters in a hollow
    cone between @xmath and @xmath away from the muon is less than
    @xmath % of the muon @xmath .

-   The matched muon track is required to be isolated from other
    activity in the central tracker by requiring that the sum of @xmath
    of all tracks inside a cone of @xmath around the muon is less than
    @xmath % of the muon @xmath .

-   The missing transverse energy direction must be separated from the
    direction of the muon in @xmath . The missing transverse energy in
    QCD events passing the muon isolation requirements is found mostly
    in or opposite the muon direction. This can be explained by @xmath
    production where one or both @xmath hadrons decay semi-leptonically
    and the jet is not reconstructed.

-   Reject events with an electron with @xmath GeV in the central or the
    end-cap calorimeter ensuring orthogonality between the @xmath +jets,
    @xmath +jets and @xmath channel.

-   Reject events with a second muon with @xmath GeV. This ensures
    orthogonality between the @xmath +jets channel and the @xmath
    channel and also rejects @xmath events.

##### 21.2.2 Preselections specific to the @xmath channel

The event preselections specific to the @xmath channel are:

-   The presence of an electron with @xmath GeV and @xmath .

-   The missing transverse energy direction must be separated from the
    direction of the electron in @xmath in order to eliminate events in
    which a jet was misidentified as an electron.

-   Reject events with a second electron with @xmath GeV ensuring
    orthogonality between the @xmath +jets and @xmath channels. This
    also rejects @xmath events.

-   Reject events with a muon with @xmath GeV thus ensuring
    orthogonality between @xmath , @xmath and @xmath channels.

##### 21.2.3 Preselected Sample

The number of preselected events in the @xmath ( @xmath ) channel are
shown in Tab. 5 ( 6 ) together with the expected contribution of QCD and
@xmath events.

To estimate the fraction of QCD events a sample with a ‘‘looser’’
selection criteria is defined ¹⁴ ¹⁴ 14 In the @xmath channel, the muon
isolation is loosened by only requiring the muon to be isolated from
jets in a cone of @xmath . In the @xmath channel, the requirement on the
electron likelihood is dropped. . By calculating the probability for
events that pass the “looser” selection to also pass the normal
preselection requirement (for both QCD events and events with a true
isolated lepton e.g. @xmath and ), the fraction of QCD events in the
preselected sample can be estimated. More information on how to estimate
the QCD background can be found in Ref. xsec_240_ljets_topo_publ .

The preselection efficiency for @xmath events is calculated from
simulated events and scale factors are applied to take into account
significant data-to-simulation discrepancies. The efficiency to select
@xmath events is @xmath % ( @xmath %) in the @xmath ( @xmath ) channel
requiring at least four or more jets. Other backgrounds than @xmath and
QCD have preselection efficiencies less than 1% except single top quark
and @xmath dilepton backgrounds which have preselection efficiencies
around @xmath %.

#### 21.3 Final Event Selection

The majority of the backgrounds does not contain @xmath -quark jets and
thus the identification of @xmath -quark jets can be used to
preferentially select @xmath events while removing background events.
This is used to obtain a pure sample of @xmath events in the last stage
of the event selection:

  The event must contain at least two jets tagged by the SVT algorithm.

##### 21.3.1 Sample Composition

The composition of the data sample after double-tagging (called signal
sample) is determined in Ref. xsec_note360_ljets_btag starting from the
preselected sample and the predicted number of @xmath +jets and QCD
events. This is further multiplied by the probability for an event to
contain jets that are @xmath -tagged. To obtain an estimate of the
number and type of events after applying @xmath -tagging on the
preselected sample, the probability for an event to have two or more
@xmath -tagged jets must be calculated. This event tagging probability
depends strongly on the topology and jet flavors in the event. It is
determined from Monte Carlo simulations, applying to each jet the per
jet @xmath -tagging efficiency derived from data (as described in Sec.
17.4 ). The QCD background contribution to the signal sample is
estimated to be @xmath events. To estimate the @xmath +jets contribution
to the signal sample, the predicted number of @xmath +jets events in the
preselected sample is split into its expected flavor composition as
predicted by ALPGEN . The @xmath background in the preselected sample is
dominated by non-heavy flavor jets (81%) due to the low production cross
section of a @xmath boson in association with heavy flavor jets. The low
probability to tag light jets leads to an effective rejection of @xmath
in the signal sample ( @xmath events). The only sizable @xmath +jets
background remaining is the production of a @xmath boson in association
with a @xmath pair which has an event tagging probability ( @xmath %) on
the same order as a @xmath event ( @xmath %).

Other physics backgrounds that contributes to the signal sample are
diboson production ( @xmath ), single top production and @xmath ( @xmath
and @xmath ). The @xmath +jets background has a similar event signature
as @xmath but is suppressed due to no physical source of @xmath . For a
given process @xmath , the number of events @xmath in the preselected
sample is determined by @xmath , where @xmath , @xmath , @xmath and
@xmath are, respectively, the cross section, the preselection
efficiency, the branching fraction for the specific process and the
integrated luminosity. The expected number of events in the signal
sample is estimated by multiplying @xmath with the event tagging
probability for that specific process. The only non-negligible
backgrounds are the single top quark production and the @xmath
processes.

After all selections, 21 data events remain. Table 7 and 8 summarizes
the sample composition according to predicted signal and background
contributions in the @xmath and @xmath channel respectively. It should
be noted that in the analysis presented in this thesis, only events with
four or more jets are used.

### 22 Jet Charge Algorithms

In this section a method to use tracks inside jets to form a variable
which is capable to discriminate between jets arising from the
hadronization of @xmath - and @xmath -quarks is presented.

#### 22.1 Jet Charge Algorithm Definition

Various algorithms to discriminate between @xmath - and @xmath -quark
jets have been used in the past jet_charge_aleph ; jet_charge_cdf ;
jet_charge_delphi ; jet_charge_l3 ; jet_charge_opal . The idea is to use
the particle tracks reconstructed by the central tracker, associate them
with a reconstructed jet in the calorimeter and compute the collected
charge of the jet. In the hadronization, the initial quark transverse
momentum is shared in a multi-stage process between many particles. A
common feature of the modeling of this process is that in most jets
arising from the hadronization of a @xmath - or @xmath -quark, the
tracks with highest @xmath are the decay products of the @xmath hadron
in the jet. A weighted sum of the charges of the tracks are therefore
used in most algorithms. The weights are usually functions of the track
momentum or its projection along a certain direction. In designing such
a jet charge algorithm one needs to decide:

-   What tracks are associated with the jet, within a cone in @xmath or
    in a whole hemisphere,

-   the quality criteria of the tracks to be considered,

-   what weight to give each track.

In this analysis, only tracks that fulfill the following criteria are
considered:

1.  Track @xmath GeV,

2.  distance between the track and jet axis must be less than 0.5 in
    @xmath ,

3.  a distance to the primary vertex in the @xmath -direction of less
    than @xmath cm unless the track is fitted to a secondary vertex.

At least four jets are present in the @xmath events and it is therefore
important to consider only tracks that are associated with the
corresponding jet. Also, in this analysis the interest is to calculate
only the jet charge for the jets originating from the @xmath - and
@xmath -quarks in the @xmath decay. The SVT algorithm determines what
jets should be considered and only tracks within a @xmath cone (studied
below) of the jet axis are considered.

The performance of two algorithms is evaluated, algorithm I:

  -- -------- -- -----
     @xmath      (9)
  -- -------- -- -----

and algorithm II:

  -- -------- -- ------
     @xmath      (10)
  -- -------- -- ------

where the subscript @xmath runs over all charged tracks passing the
track quality cuts described above and that are located within a cone of
@xmath from the jet axis. Each track has a charge @xmath and a
transverse momentum @xmath , while @xmath represent the projection of
the track momentum along the jet axis. The parameter @xmath is an
arbitrary number which is optimized from simulated @xmath events. For
@xmath , the weight given to each track is equal to one and hence,
@xmath independent, while @xmath is equivalent to considering solely the
highest @xmath track. Figure 25 shows the jet charge distribution for
SVT-tagged @xmath - and @xmath -quarks in simulated @xmath events.

#### 22.2 Optimization

A simple optimization of the jet charge algorithm parameters using
@xmath - and @xmath -quark jets in simulated @xmath events is performed.
In order to quantify the separation between @xmath - and @xmath -quark
jets, a variable called discriminating (or discriminant) power @xmath
was defined as:

  -- -------- -- ------
     @xmath      (11)
  -- -------- -- ------

where @xmath and @xmath are the mean and variance of the jet charge
distributions obtained for @xmath - and @xmath -quark jets respectively.

The purpose of the algorithm is to discriminate between @xmath - and
@xmath -quark jets from the decay of top quarks in @xmath events. The
optimization is carried out using simulated @xmath events. In the
optimization, a reconstructed jet is labeled as a true @xmath -quark (
@xmath -quark) jet if a @xmath -quark ( @xmath -quark) at parton level
in the Monte Carlo history is found within a cone of @xmath with respect
to the jet axis. If more than one heavy flavor ( @xmath or @xmath )
parton was inside the cone, the closest one is used. Only SVT-tagged
jets are considered. To avoid biases from the event topology, the events
were required to have at least four reconstructed jets with @xmath GeV
and @xmath (in the simulated @xmath events used for comparison below,
exactly two jets were required).

In the optimization, the parameter @xmath was varied between @xmath and
@xmath in steps of @xmath and the size of the jet cone was varied
between @xmath and @xmath in steps of @xmath . Figure 26 shows the
discriminating power for the

algorithms I and II as function of @xmath and @xmath . Little difference
is found between the two algorithms and algorithm I is chosen for the
remaining of this analysis. It is found that the highest discriminating
power is obtained for @xmath and @xmath .

In general, tracks originating from the hadronization are expected to
come from the primary vertex unless they come from the decay products of
the @xmath hadron and consequently displaced. Therefore, the maximum
distance of the tracks to the primary vertex in the @xmath -direction
was studied. Tracks determined to originate from a displaced @xmath
hadron vertex are not included. In this study using simulated events,
the discriminating power increases when loosening this requirement. This
is expected to be a variable heavily affected by the detailed modeling
of the tracking which is known to be poor. Therefore, a conservative
requirement of @xmath cm is used to ensure that tracks only close to the
primary vertex are considered.

In Fig. 27 the discriminating power is shown as function of the minimum
requirement of the @xmath of the tracks.

This variable is also expected to exhibit the same critical dependence
on the correct modeling of the tracking. Therefore, the minimum @xmath
requirement was chosen to be @xmath GeV to ensure the quality of the
tracks. The requirements on the minimum track @xmath and maximum
distance from the track to the primary vertex are kept in the rest of
this analysis.

### 23 Jet Charge Calibration on Data

The Monte Carlo description of the DØ tracking system includes the
detailed geometry of the detector and a modeling of the electronic
noise. Nevertheless, the Monte Carlo simulations are unable to describe
fine details of track quality distributions such as @xmath , hit
multiplicities and tracking efficiency within jets. Physics analyzes in
DØ that use the tracking detectors for @xmath -tagging determine the
performance of the @xmath -tagging algorithms on data, or with as little
input from simulation as possible. A similar approach is chosen in this
analysis.

The goal of the present section is to show that the jet charge
distribution templates for SVT-tagged @xmath -, @xmath -, @xmath - and
@xmath -quark jets can be extracted from data. The jet charge
distributions are then used to derive the expected distributions of the
charge observables in the SM top and exotic quark scenarios.

The difficulty is to find the true flavor of the particle initiating a
jet in data. Therefore, a data sample enriched in @xmath pairs is
selected. In such an event with exactly two jets back-to-back in
azimuth, called dijet event, one of the jets is required to contain a
muon from the semi-leptonic decay of a @xmath hadron and is referred to
as the tag -jet, the muon associated with the tag -jet is referred to as
the tag -muon or simply tagging muon. Studies rick_field ;
cdf_b_production_runI ; dzero_thesis have shown that the mechanism for
@xmath production at the Tevatron depends heavily on the azimuthal
distance between the jets, with large distances dominated by flavor
creation. In such an event, the charge of the muon can be used to find
the type of quark initiating the tag -jet and, consequently, also the
other jet in the event (referred to as the probe -jet) as given in Tab.
9 .

The method above is called the tag -and- probe method.

The starting point are the dijet samples (defined below in Sec. 23.1 )
dominated by @xmath - and @xmath -quark jets. The dijet samples
(illustrated in Fig. 28 ) contain a jet with a @xmath - and a SVT-tag on
one side and a SVT-tagged jet on the other side of the event.

The goal is to find the jet charge templates for @xmath - and @xmath
-quark jets in general, not necessarily @xmath -tagged jets and
therefore the jet charge distribution is extracted from the probe -jet.

In the simplified case, when there is no @xmath mixing PDG , nor
contamination of the sample by @xmath -quark jets or light-jets, and all
the tagging muons were coming from a direct @xmath hadron decay, the
charge of the tagging muon would reliably tell if the tag -jet was
initiated by a @xmath - or a @xmath -quark. According to this procedure,
the two distributions of jet charge for jets that are believed to be
@xmath -quark jets and those that are believed to be @xmath -quark jets
can be extracted by plotting separately @xmath for the @xmath and @xmath
samples. This ideal scenario is complicated by a number of issues in
data. First the sample is not pure @xmath production, but contains a
small fraction of @xmath production. Therefore the observed @xmath - and
@xmath -quark jet charge distributions from the probe -jet are a mixture
of the jet charge for @xmath -quark jets and for @xmath -quark jets. The
contamination by @xmath -quark jets in the dijet samples is determined
in Sec. 23.3 .

The tagging muon can also arise from a decay which is not a direct
@xmath hadron decay. This sort of muon is referred to as a cascade muon.
It can either arise from the decay of a @xmath meson or lighter hadrons.
In this case, the relation between the charge of the tagging muon and
the type of @xmath -quark in the probe -jet is not given by Tab. 9
anymore. @xmath mixing on the side of the tag -jet can also destroy the
correlation between the muon sign and the type of @xmath -quark
initiating the probe -jet. The @xmath meson on the probe -jet side can
also mix, but this does not matter, since in the end the data-derived
@xmath -quark jet charge distributions is applied to the @xmath -quark
from the decay of the top quarks in @xmath events, not the @xmath meson.
Another effect that can destroy the correlation between the muon sign
and the type of @xmath -quark initiating the probe -jet is an
incorrectly measured the muon charge.

To illustrate the effect of the @xmath mixing, cascade decay and @xmath
-contamination, Fig. 29 shows a comparison of the discriminating power
of the jet charge distributions between:

-   Simulated @xmath events where the true @xmath -type ( @xmath or
    @xmath ) is extracted from the Monte Carlo truth to sort between the
    @xmath - and @xmath -quark jet charge. Note that we look for the
    @xmath - or @xmath -quark in the Monte Carlo history that is closest
    in @xmath to the jet axis.

-   simulated @xmath events using the tag -and- probe method,

-   a dijet sample (defined in Sec. 23.1 ) using the tag -and- probe
    method.

As expected the discriminating power in case i ) is much better than in
either case ii ) and iii ) which both suffer from cascade decays and
@xmath mixing. Data also suffers from contamination by @xmath events and
from poorer tracking than the simulated events.

The amount of contamination from cascade decay and @xmath -quark jets
can be changed by requiring a high @xmath , defined as the relative
momentum of the tagging muon with respect to the jet axis, see Fig. 30 .
@xmath is expected to be larger for @xmath -quark jets than from @xmath
-quark or light jets due to the larger @xmath -quark mass.

This effect is illustrated in Fig. 31 .

The goal is to extract the jet charge distributions of the probe -jet.
The tagging muon only serves as the source to find the true type of
quark initiating the jet. Thus, after taking into account all sources
that affect the charge of the tagging muon (that can destroy the
correlation between the charge and the type of quark) the extracted jet
charge distributions from the probe -jet should be independent of the
specific requirement on the minimum @xmath of the tagging muon. As a
cross-check, the extraction of the jet charge distributions are
therefore performed with different requirements of the minimum @xmath of
the tagging muon. The different requirements are however later shown to
give similar results. The final jet charge distributions are derived
without a @xmath requirement on the tagging muon in order to minimize
the statistical uncertainty.

#### 23.1 Dijet Data Samples

To calibrate the jet charge algorithm using data a sample enriched in
@xmath -quark jets is selected as discussed above. The data sample is
based on a generally selected sample requiring a muon matched to a jet.
The following additional requirements are used to further enhance the
sample in events with @xmath production:

-   The event must have exactly two jets @xmath and @xmath with @xmath
    GeV and @xmath .

-   The azimuthal distance ( @xmath ) between @xmath and @xmath is
    larger than @xmath .

-   @xmath and @xmath must be @xmath -tagged using the SVT algorithm,

-   @xmath must be associated with a muon within @xmath from the jet
    axis.

In summary, this sample has exactly two jets in a back-to-back
configuration in @xmath , one jet @xmath being both SVT-tagged and
@xmath -tagged and the second jet @xmath being SVT-tagged as shown
schematically in Fig. 28 . This sample is referred to as the “ tight
dijet sample ”.

Similarly, the “ Loose Dijet sample ” is defined in the same way as the
“tight dijet sample” apart from the requirement of the SVT-tag for
@xmath which is removed. Thus, the “tight dijet sample” is a subset of
the “loose dijet sample”.

#### 23.2 Extraction of Jet Charge Templates from Dijet Data

In the ideal case where the tagging muon comes from a direct @xmath
hadron decay without @xmath mixing, the tag -and- probe method would in
fact yield the true jet charge distributions. In practice when the tag
muons are for example of positive sign the probe -jets are in majority
from @xmath -quark jets but mixed with a certain fraction of @xmath -,
@xmath -, and @xmath -quark jets.

The jet charge distributions of the probe -jet obtained in the tight
dijet sample are denoted: @xmath and @xmath where the subscript @xmath
indicates the sign of the tagging muon. Similarly, @xmath and @xmath
denotes the jet charge distributions for @xmath and @xmath -quark jets,
these are the distributions we want to extract from the data.

In absence of @xmath mixing, if the fraction of @xmath -quark jets were
zero and if all tagging muons were coming from a direct @xmath decay,
then the jet charge distributions for @xmath - and @xmath -quark jets
would simply be given by: @xmath and @xmath .

In reality, care has to be taken to the processes which change the sign
of the tagging muon. In the tight dijet sample @xmath is defined as the
fraction of tagging muons which do not have the same sign as the parent
@xmath hadron due to cascade decay, or because it originates from a kaon
or pion decay.

If this is the only process that affects the correlation between the
sign of the tagging muon and the quark that initiated the probe -jet,
@xmath and @xmath can be written as:

  -- -------- -- ------
     @xmath      (12)
     @xmath      (13)
  -- -------- -- ------

where @xmath is simply @xmath .

The tight dijet sample contains also a fraction of @xmath - and @xmath
-quark jets. Therefore the jet charge templates @xmath and @xmath
contain also a fraction of the jet charge distributions @xmath and
@xmath for @xmath - and @xmath -quark jets respectively. The fraction of
@xmath -quark jets in the tight dijet sample is denoted @xmath .
Equation 13 can therefore be rewritten as

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (14)
  -- -------- -------- -------- -- ------

Note that the fraction of @xmath ( @xmath ) jets contributing to @xmath
( @xmath ) are neglected. These contributions are at most of the order
of @xmath relative to the flipped muon contributions from direct @xmath
decays. In addition, the muons from @xmath meson decays have
significantly lower momenta and are less likely to pass the muon
momentum requirement in the dijet samples. Therefore the component of
@xmath ( @xmath ) jets contributing to @xmath ( @xmath ) is further
suppressed.

Equations 14 provides two equations with four unknowns ( @xmath , @xmath
, @xmath , @xmath ). To be able to extract these four jet charge
distributions another two equations are needed. This is achieved by
using the loose dijet sample, which has a different fraction of @xmath
-quark jets, that we denote @xmath because of the relaxation of the
SVT-tag on the tag -jet.

In the same fashion as for the tight dijet sample, @xmath and @xmath are
the jet charge distributions observed for the probe -jet in the loose
dijet data when the tag muon is positive or negative respectively. The
equivalent of equations 14 in the loose dijet sample are:

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (15)
  -- -------- -------- -------- -- ------

Using Eq. 15 and 14 the system of equation can be solved for @xmath ,
@xmath , @xmath and @xmath provided that the fraction of @xmath -quark
jets and the fraction of times the measured tagging muon charge is
changed with respect to the quark initiating the jet. The procedure to
determine the fraction of @xmath -quark jets in both samples is
described in Sec. 23.3 and the calculation of fraction of events with
changed muon charge sign @xmath and @xmath is described in Sec. 23.4 .

The solutions to Eq. 14 and are 15 :

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (16)
  -- -------- -------- -------- -- ------

#### 23.3 Fraction of @xmath-Quark Jets in the Dijet Samples

The difference in mass between the @xmath -quark, @xmath -quark and
light quarks implies that the momentum distribution of muons within jets
from semi-leptonic decays of @xmath -, @xmath - and light mesons are
different. This property is utilized to extract the respective fraction
of @xmath -quark, @xmath -quark and light jets in the dijet samples
which were used to extract the jet charge distributions for @xmath - and
@xmath -quark jets above.

The expected @xmath spectra from @xmath - and @xmath -quark jets found
from Monte Carlo simulation are used to fit the observed @xmath spectra
in the dijet samples. The light flavor contribution is assumed to be
negligible. This is also confirmed a posteriori by the fact that the
fitted fraction of @xmath -quark jets is small and that the light jet
tagging efficiency is @xmath times lower than than the @xmath -quark
tagging efficiency (see Sec. 17.4 ).

The expected @xmath -quark jet @xmath spectrum is determined using
simulated @xmath events including cascade decays ( @xmath ) and the
expected @xmath -quark jet @xmath spectrum is determined from simulated
@xmath events. @xmath templates in three bins of muon @xmath : @xmath
GeV @xmath GeV, @xmath GeV @xmath GeV and @xmath GeV and in three bins
of jet @xmath : @xmath GeV @xmath GeV, @xmath GeV @xmath GeV and @xmath
GeV are constructed. The jet flavor in the Monte Carlo simulated events
is determined by matching the direction of the reconstructed jet to the
heaviest hadron flavor within a cone of @xmath . If there is more than
one hadron found within the cone, the jet is considered to be a @xmath
-quark jet if the cone contains at least one @xmath hadron. It is called
a @xmath -quark jet if there is at least one @xmath meson in the cone
and no @xmath hadron. The fitted parameter is the fraction of @xmath
-quark jets among the tag -jets of the dijet samples.

The @xmath template fits are shown in Fig. 32 and Fig. 33 for the loose
and tight dijet samples respectively.

The fitted fractions of @xmath - and @xmath -quark jets are presented in
Tab. 10 and 11 respectively. The fit also takes into account the
statistical uncertainty on the @xmath spectra obtained from simulated
events as well as the uncertainty from the observed spectrum.

The total fraction of of @xmath - and @xmath -quark jets in the dijet
samples can be extracted by the sum of the measured fraction in each bin
weighted by the event population in each bin. As expected, removing the
requirement of a SVT-tag on the tag -jet enhances the fraction of @xmath
-quark jets.

#### 23.4 Determination of the Tagging Muon Charge Flip Fraction

The total fraction of times the tagging muon charge sign is “flipped”
compared to the quark that initiated the jet in the tight (loose) dijet
sample is given by the variable @xmath ( @xmath ). The value of @xmath
is measured from simulated @xmath events where the Monte Carlo truth
information allows for a determination of the correlation between the
tagging muon and the quark sign. The fraction of times the tagging muon
changes sign depends on the @xmath spectrum of the jets. At lower jet
@xmath , the probability that a cascade muon is found above the
reconstruction threshold is lower and the fraction of cascade muons thus
increases as a function of increasing jet @xmath . The fraction of times
the tagging muon changes sign determined from simulated events is
therefore weighted to the @xmath spectrum observed in the tight dijet
sample. The result is shown in Tab 12 .

Any topological differences between the loose and tight dijet sample
such as the jet @xmath spectrum could lead to a difference between
@xmath and @xmath . Therefore, the tag -jet @xmath and @xmath spectra
are compared (see Fig. 34 ) but no significant differences were found
and @xmath is thus used.

##### 23.4.1 Cross-check of tagging muon charge flip

The fraction of times the tagging muon in the loose and tight dijet
samples changes sign calculated above can be cross-checked with data by
requiring that the probe -jet in the tight dijet sample contain a muon
track (with the same quality as the tagging muon). If @xmath is the
total number of events in this sample, @xmath is the number of events
with two opposite sign muons and @xmath the number of events with two
same sign muons, the following relationships can be used to predict the
number of @xmath and @xmath in this sample given the flip fraction
estimated above,

  -- -------- -- ------
     @xmath      (17)
  -- -------- -- ------

  -- -------- -- ------
     @xmath      (18)
  -- -------- -- ------

The prediction gives @xmath and @xmath while the observation is @xmath
and @xmath which is consistent within the statistical uncertainty. The
caveat of this cross-check is that a rather broad range of @xmath is
allowed before conflicting with the statistical uncertainties.

#### 23.5 Correction for Kinematical Differences in the Signal and Dijet
Samples

The jet charge templates were derived from the dijet data samples above.
The aim is to extract the jet charge templates for @xmath - and @xmath
-quark jets in @xmath events. Figure 35

shows a comparison of the jet @xmath and @xmath for the probe -jet in
the tight dijet sample and the SVT-tagged @xmath -quark jets in
simulated @xmath events. The @xmath -quark jet from the top quark decay
has as expected harder @xmath and more central @xmath spectra. From the
correlation between jet @xmath and the number of tracks associated with
the jet one can expect that the discriminating power depends on the jet
@xmath . A dependence on jet @xmath is also expected due to the geometry
of the inner tracking detector where particles around @xmath traverses
more layers in the SMT ( a similar behavior exists for the tracking
efficiency in Fig. 22 in Sec. 17.4 ). The jet @xmath and @xmath
dependences of the jet charge algorithm are shown in Fig. 36 .

As the jet charge algorithm performance is improving with increasing jet
@xmath and mostly decreasing with increasing @xmath the conclusion is
that the jet charge templates derived on the dijet samples are
underestimating the jet charge algorithm discriminating power when
applied to @xmath -quark jets in @xmath events.

This section describes how to correct for this by weighting simulated
@xmath events to have the same @xmath -quark jet @xmath and @xmath
spectrum as the dijet samples. A correction function is then extracted
based on the deviation of the weighted compared to the unweighted jet
charge templates. This correction is subsequently applied to the jet
charged templates derived from the dijet samples to extract the expected
jet charge templates for @xmath - and @xmath -quark jets in @xmath
events.

##### 23.5.1 Jet Kinematical Weighting

To fully take into account the kinematical differences for @xmath -quark
jets in the dijet samples and @xmath both the difference in jet @xmath
and @xmath and their correlations have to considered. This can be
achieved by weighting the @xmath -quark jet @xmath spectrum of @xmath to
the probe -jet @xmath spectrum in the tight dijet sample (this direction
of weighting is the only possible due to the low statistics at high
@xmath in the dijet samples). Figure 37 shows the weight and the result
is shown in Fig. 38 .

The weighting of the @xmath spectrum does not take into account the
differences in @xmath spectrum between the two samples. This difference
is treated in a similar fashion. The simulated @xmath events are
weighted again but this time with respect to the @xmath -quark jet
@xmath spectrum. The weight as a function of @xmath is shown in Fig. 39
.

After applying both weights the jet @xmath and @xmath spectrum of the
different samples agree as can be seen in Fig. 40 , confirming the
validity of the assumption of uncorrelated @xmath and @xmath .

##### 23.5.2 Derivation of the Kinematical Correction

The correction is extracted as the ratio between the @xmath -quark jet
charge templates in normal and re-weighted simulated events. The jet
charge templates can be seen as probability densities to observe a
certain jet charge given the true charge and type of quark. In the
following, the jet charge templates are modeled as functions of the
measured jet charge @xmath defined in Eq. 9 . Further, we denote:

-   @xmath the @xmath -quark jet charge template obtained directly from
    dijet data (as described in Sec. 23.2 ) before any correction,

-   @xmath the @xmath -quark jet charge template from simulated @xmath
    events passing signal selections,

-   @xmath the @xmath -quark jet charge template from simulated @xmath
    events passing signal selections re-weighted as discussed in the
    previous section,

-   @xmath the jet charge distribution from the tight dijet data,
    corrected to reproduce the jet charge distribution for jets with the
    same @xmath and @xmath as the simulated @xmath events.

The corrected distribution is obtained in the following way:

  -- -------- -- ------
     @xmath      (19)
  -- -------- -- ------

The correction for the @xmath -quark jet charge template is derived in a
similar way. The correction functions are shown in Fig. 41 for both
@xmath - and @xmath -quark jets.

As expected, the corrections decrease the width of the jet charge
templates since a higher jet @xmath give a larger probability to observe
a higher number of tracks associated with the jet. The more tracks
associated with the jet means less probability to observe @xmath close
to one. Figure 42 shows the discriminating power for @xmath -quark jets
before and after the kinematical correction.

#### 23.6 Final Jet Charge Distributions Extracted from Data

After applying the correction for the kinematical differences in the
dijet and signal samples the final @xmath -, @xmath -, @xmath and @xmath
-quark jet charge templates shown in Fig. 43 are obtained.

The jet charge templates are normalized to an area of one and can be
seen as the probability density to measure a certain jet charge @xmath ,
given the type of quark ( @xmath , @xmath , @xmath or @xmath )
initiating the SVT-tagged jet. These templates are subsequently used to
derive the expected charge templates for the SM top and the exotic
quark.

Figure 44 shows the discriminating power of the final @xmath -quark jet
charge templates compared to the tight dijet sample after basic
selections.

The error band is the combined systematic uncertainty related to the
extraction of the templates which is propagated to the final result. As
required, the discriminating power of the extracted jet charge templates
is independent of the minimum @xmath requirement on the tagging muon
(remember that the final jet charge templates are derived with no
requirement on the @xmath of the opposite tagging muon). As expected,
the jet charge algorithm is less efficient for data than for Monte Carlo
events where the Monte Carlo history is available to obtain the true
type of quark initiating the jet.

### 24 Top Quark Charge Observables

In order to discriminate between the charge @xmath SM top quark and the
charge @xmath exotic quark scenarios an event observable and an
expectation of this observable for the two different hypotheses is
needed. The charge @xmath SM top quark and the charge @xmath exotic
quark scenarios will simply be refereed to as the SM and exotic
scenarios respectively.

The observable is based on reconstructing the charge of the decay
products of the top quark, assuming as mentioned earlier the decay
@xmath (and similarly in the exotic charge scenario @xmath ). Since
there are two top quarks in each event, the top quark charge can be
measured twice in each event.

One top quark charge is constructed as the sum of the charge of the
charged isolated lepton (referred to as the charged lepton if not
otherwise specified) and the jet charge of the @xmath -quark jet from
the same top quark. The second top quark charge in the event is
constructed as the sum of the second @xmath -quark jet charge minus the
charge of the charged lepton. The two observables in each event are
defined as:

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      (20)
     @xmath   @xmath   @xmath      
                                   
  -- -------- -------- -------- -- ------

where @xmath is the charge of the charged lepton, @xmath is the charge
of the @xmath -quark jet on the leptonic leg of the event (defined in
Sec. 20 ) and @xmath is the charge of the @xmath -quark jet in the
hadronic leg of the event. The charges of the SVT-tagged jets @xmath and
@xmath are obtained by applying the jet charge algorithm discussed
earlier. The next section describes how the two @xmath -quark jets are
assigned to the two legs of the event.

#### 24.1 Associating SVT-Tagged Jets to the Correct @xmath Boson

Recall that the final state objects from the decay of @xmath pair in the
@xmath channel are two jets from the decay of the @xmath boson and a
@xmath -quark jet from the hadronic side of the event and a @xmath
-quark jet together with a charged lepton and a neutrino from the
leptonic side of the event. In order to compute the top quark charge
observables, the two @xmath -quarks in the event needs to be assigned to
two reconstructed jets. This is done using a kinematic fitting algorithm
initially developed to measure the top quark mass topmass_runI_PRL .
Below, the main features of the kinematic fit is described, more
detailed information can be found in Ref. hitfit .

##### 24.1.1 Kinematic Fit

The algorithm used performs a kinematic fit of top quark pair candidate
events in the @xmath topology. If the event contains the decay of a
@xmath pair, with four jets (the issue regarding events with more than
four jets is discussed below) in addition to the charged lepton and
neutrino, the three jets (two light jets from the @xmath boson and a
@xmath -quark jet) forming the invariant mass of the “hadronic” top
quark (the top quark on the hadronic side of the event) is expected to
be equal to the invariant mass formed by the charged lepton, neutrino
and remaining @xmath -quark jet (the leptonic side of the event). In
addition to this constraint, two jets (out of three) on the hadronic
side of the event is expected to form the invariant mass of the @xmath
boson as is the charged lepton and the neutrino on the leptonic side of
the event. Together with the overall energy-momentum conservation in the
collision this over-constrains the problem.

The input variables to the kinematic fit are:

-   The measured energy (or momentum) of the four jets and the charged
    lepton ( @xmath components each) and their directions. The masses of
    the jets are fixed to zero except for the jets assigned as @xmath
    -quark jets which are given a mass of @xmath GeV.

-   The @xmath and @xmath components of the measured missing transverse
    energy, @xmath , represents the transverse momentum of the neutrino.
    Note that the neutrino momentum in the longitudinal direction (
    @xmath ) cannot be inferred from momentum imbalance in a similar way
    due to the spectator quarks in the colliding @xmath pair which
    carries away a large fraction of the momentum in this direction
    which is mostly unmeasured close to the beam direction.

The conclusion is that there are @xmath measured and one unmeasured
variable (the neutrino momentum in the @xmath direction) under subject
to three constraints when reconstructing the top quark event,

  -- -------- -- ------
     @xmath      (21)
     @xmath      (22)
     @xmath      (23)
  -- -------- -- ------

which makes the problem twice over-constrained ¹⁵ ¹⁵ 15 There are @xmath
particles in the event, 4 jets, two leptons, the @xmath pair, @xmath ,
the @xmath pair and an additional pseudo-particle @xmath to obtain total
four-momentum balance which gives @xmath variables. The constraints come
from the quarks, lepton and @xmath giving @xmath constraints. The @xmath
pair gives an additional @xmath , four-momentum conservation in all
@xmath vertices gives @xmath , the known masses of @xmath gives @xmath
and @xmath gives one constraint. This leads in total to @xmath
constraints for @xmath variables and thus twice over-constrained. . In
this analysis, which is not concerned with measuring the mass of the top
quark, the top quark mass itself is used as an additional constraint and
fixed to @xmath GeV (which is the top quark mass used in the generation
of the simulated @xmath events).

If the correspondence between jets and partons were known, a kinematic
fit would not be needed. In general, this is not known. Therefore, the
algorithm tries all @xmath possible permutations of jets and the “best”
one can be chosen (there are @xmath permutations for four jets but the
exchange of the two jet from the @xmath boson leaves the fit unchanged).
To quantify “best”, a “ @xmath ” is defined which reflects to what
degree it is possible to satisfy the given constraints for each jet
permutation. The kinematic fit iteratively changes the measured and
assigned kinematic variables based on their uncertainties and their
impact on the @xmath . For a given jet permutation the variables are
pulled until the @xmath stops changing and the constraints are
satisfied.

For events with more than four jets the additional jets are assumed to
originate from initial (ISR) or final state radiation (FSR). The number
of permutations grows fast when including extra jets in the fit (note
that if the extra jet is assumed to be FSR it must be merged with
another jet in the event and 5 jets give 140 permutations, 6 jets give
1020, etc.). As in the top mass analyses topmass_runI_PRL , this
analysis uses only the four highest @xmath jets in the fit. Other jets
are assumed to arise from ISR hitfit .

Consider now @xmath events where exactly two of the jets in the event
are SVT-tagged. These @xmath -tagged jets are denoted as @xmath , …,
@xmath , with @xmath and the other jets @xmath …, @xmath , with @xmath .
If @xmath and @xmath are denoted as the @xmath -quark jets from the
leptonic and hadronic leg of the event respectively, and @xmath and
@xmath the two jets from the hadronic @xmath decay, then each
permutation considered by the kinematic fit associates one jet ( @xmath
, @xmath , @xmath and @xmath ) to each of the jets @xmath , @xmath ,
@xmath and @xmath . There are exactly 12 combinations, but only two for
which the SVT-tagged jets are associated to the two jets @xmath and
@xmath from the @xmath -quarks of the leptonic and hadronic legs:

1.  @xmath @xmath @xmath and @xmath @xmath @xmath , or

2.  @xmath @xmath @xmath and @xmath @xmath @xmath .

For an event with more than two SVT-tagged jets the number of
permutations for which the kinematic fit can associate SVT-tagged jets
to @xmath or @xmath is multiplied. Note that only 1% of @xmath events in
Monte Carlo passing preselection have three or more SVT-tagged jets.

  Only permutations for which @xmath and @xmath are associated to
  SVT-tagged jets are considered.

Sometimes the input kinematic variables are very far from the
constraints and the fit may therefore fail to pull the variables enough
to satisfy the constraints or it does not find a stable @xmath and fails
to converge. The kinematic fit fails to converge in @xmath % of
simulated @xmath events passing signal selections for any of the two
permutations where the SVT-tagged jets are associated to @xmath and
@xmath , see Tab. 13 .

One should note that it is not seldom that the @xmath decay contains a
@xmath -quark jet, and the SVT-tagged jets do not correspond to 100% of
actual @xmath -quark jets, see Tab. 14 .

Finally, out of the permutations for which the kinematic fit assigns the
SVT-tagged jet to @xmath and @xmath , only the permutation with the
lowest @xmath is used. Based on the Monte Carlo history, it is observed
that the lowest @xmath permutation is the correct one in @xmath % of the
cases. In the signal sample, 21 events are selected, out of which 16
have at least one converged permutation where both SVT-tagged jets are
assigned to @xmath and @xmath . This is statistically consistent with
the prediction @xmath % from simulated events.

#### 24.2 Expected Charge Templates in the Standard Model and Exotic
Scenarios

The expected charge distribution templates in both scenarios are derived
from simulated @xmath events and the jet charge templates derived from
data earlier.

##### 24.2.1 Standard Model Charge Template

The estimated charge distribution of the SM top and the exotic quark
depends on how well the @xmath - and @xmath -quark jets can be
identified but also the assignment of the correct @xmath -quark jet to
correct @xmath boson in the event. Therefore, it is necessary that the
kinematic fit is applied to the simulated events in an equivalent way as
to data in order to extract the expected distributions.

The procedure to obtain the expected SM top quark charge distribution is
explained below:

1.  Apply signal selection criteria as defined in Sec. 21 on simulated
    @xmath events.

2.  Fit the event using the constrained kinematic fit.

3.  Select the lowest @xmath combination for which the jets @xmath and
    @xmath are associated to SVT-tagged jets @xmath and @xmath .

4.  Determine the true flavor of the jets @xmath and @xmath using
    jet-parton matching. The true flavor can be: @xmath -, @xmath -,
    @xmath - , @xmath - or light ( @xmath , @xmath , @xmath ) jet.

5.  The jet charges @xmath and @xmath is set to one randomly chosen
    value according to the probability density function @xmath derived
    from data depending on the flavor of the jet e.g. if the flavor is
    @xmath , then the probability density function @xmath . If it is a
    light jet, then a random value from the corresponding jet charge
    probability density function is used, derived from Monte Carlo ¹⁶ ¹⁶
    16 It is very seldom we need to sample the light jet charge
    templates due to the low probability to tag a light jet ( @xmath %),
    see Tab. 14 .

6.  Compute the two observables @xmath = @xmath and @xmath = @xmath .

7.  Make an entry for @xmath and another entry for @xmath in a histogram
    to store the expected charge distribution for the SM top quark.

To decrease the statistical uncertainty due to the sampling of the jet
charge distributions step 5 , steps 6 and 7 are carried out 200 times
per event. The predicted SM top quark charge distribution referred to as
@xmath is shown in Fig. 45 .

##### 24.2.2 Exotic Scenario Charge Template

The estimated charge distribution template for the exotic scenario is
derived in a similar way as for the SM top quark. From Fig. 24 it can be
seen that it can be obtained by simply replacing the above step 6 by the
following

1.  . The two expected observables are derived by permuting the jet
    charge of the SVT-tagged jet on the leptonic and hadronic leg of the
    event: @xmath = @xmath and @xmath = @xmath .

The expected charge template for the exotic scenario is also shown in
Fig. 45 . Note that with this procedure the charge template for the
exotic scenario is a mirror distribution of the Standard Model top quark
charge template.

#### 24.3 Backgrounds

The signal sample contains in addition to @xmath events also a small
fraction of background processes, mostly @xmath boson production in
association with a @xmath pair and two or more jets ( @xmath ) but also
some expected single top quark events. Details about the sample
composition is described in Sec. 21 . The observed charge in the signal
sample is to be compared with a combination of the expected SM top quark
and exotic quark charge templates described above and of the charge
contribution from the background processes. Due to the large
signal-to-background ratio in the signal sample ( @xmath ), the effect
of adding the charge contribution from the background processes is
small. The backgrounds considered are the @xmath and single top
production while the other background processes are neglected. Two
assumptions are made: i) the charge of the isolated high @xmath lepton
is uncorrelated with the @xmath -quark jets in @xmath events, ii) the
@xmath -quark jet charge in @xmath events are the same as for the @xmath
-quark jets in @xmath events. Due to the low expected contribution from
the single top background ( @xmath events) it is simply modeled by the
same charge template as the @xmath background.

Figure 46 shows the background charge template contribution and the
expected SM and exotic templates.

The SM and exotic templates are normalized to an area of one and can be
seen as the probability density functions to observe a certain charge
@xmath in the SM and exotic scenarios. In the rest of this thesis we
denote these probability density functions by @xmath and @xmath for the
SM top quark and the exotic quark scenario respectively.

### 25 Systematic Uncertainties

In this section the sources of systematic uncertainties and the method
to evaluate them are briefly described. A systematic uncertainty can
affect the measurement in two ways: It can change the jet charge
templates derived from data or it can affect the kinematic fit that
assigns the SVT-tagged jets in the event to the correct @xmath boson.
The result in the end is an uncertainty on the SM top and exotic quark
templates. Thus, for each systematic uncertainty, the SM top and exotic
quark charge templates are re-derived taking into account the
uncertainty considered. The result is a set of varied SM top and exotic
quark templates for each systematic which is taken into account when
extracting the final result.

##### 25.0.1 Dependence on the Fragmentation Model

This analysis use as little input as possible from the Monte Carlo
simulation in deriving the jet charge algorithm performance. For
instance, the extraction of the correction function in Sec. 23.5.2 ,
uses the ratio of Monte Carlo modeled variables as input. Nevertheless,
the dependence of a different model for the fragmentation of @xmath
-quark jets has been investigated. As discussed in Sec. 19 , the
fragmentation of partons is modeled by the Lund string model. Figure 47
and 48 shows the difference in discriminating power between @xmath - and
@xmath -quark jet charge distributions compared to the alternative
Bowler and Peterson fragmentation models respectively.

No systematic uncertainty due to the fragmentation model needs to be
accounted for since the @xmath - and @xmath -quark jet charge templates
are derived from data and as noted above, the kinematic corrections are
ratios of Monte Carlo distributions, resulting in a large cancellation
of any existing difference among the fragmentation models.

##### 25.0.2 Additional Jet Dependence

The jet charge templates are derived from dijet samples where exactly
two reconstructed jets are required while @xmath events have at least
four jets. More activity in the event could affect the jet charge
templates due to a higher number of tracks and possible overlap between
tracks originating from different jets. This dependence is studied in
Fig. 49 by comparing the discriminating power for @xmath - and @xmath
-quark jets in simulated @xmath and @xmath events where only two jets
are expected (additional jets can arise due to ISR and FSR).

No sizable difference is found and thus no systematic uncertainty is
considered.

##### 25.0.3 Tagging Efficiency in Data and Monte Carlo

The @xmath -tagging efficiencies are known to be different in simulated
events compared to data. The method to determine the expected charge
distributions for the SM top and exotic quark charge scenarios depends
on the tagging efficiency for different jet flavors e.g. a SVT-tagged
jet in a @xmath event is not always a @xmath -quark jet but sometimes a
@xmath -quark jet from the @xmath boson decay. In addition the rate at
which the various types of jets are SVT-tagged are different in data and
simulated events. For this analysis, only the relative fraction of
SVT-tagged jets of different flavors are important and not the absolute
efficiencies.

To make sure that the procedure to find the flavor of the SVT-tagged
jets in simulated @xmath events is correct, it is repeated but relying
on the tagging efficiencies derived from data to predict which of the
jets in the event that are SVT-tagged. The expected SM top and exotic
quark charge templates were re-derived using this alternative procedure
and the change was negligible.

##### 25.0.4 Dependence on the Primary Vertex Position

The tracking efficiency and other tracking related variables depends on
the geometry of the tracking detectors. Since samples with different PV
distributions are used to extract the jet charge templates for jets in
the signal sample, the discriminating power for @xmath - and @xmath
-quark jets was calculated with respect to the PV position. No
significant dependence was found (see Fig. 50 ) which may be related to
the fact that only SVT-tagged jets are considered.

SVT-tagged jets are by definition associated with a set of well defined
tracks (see Sec. 17.4 ).

##### 25.0.5 Fraction of @xmath-Tagged Jets in the Dijet and Signal
Sample

The jet charge algorithm considers all tracks satisfying the standard
quality cuts in Sec. 22.1 . All jets are required to be tagged by the
SVT algorithm but no veto is applied to reject @xmath -tagged jets. The
muon track usually has significantly higher transverse momentum than
other tracks in the same jet, and the jet charge distribution for @xmath
-quark jets containing a muon is significantly different. The jet charge
templates are derived on a different sample than the signal sample and
therefore a possible bias may exists due to different fraction of @xmath
-tagged jets in the samples. Table 15 shows the fraction of the
SVT-tagged jets that also has a muon associated to it.

A systematic uncertainty due to this discrepancy is obtained by
re-deriving the jet charge templates for @xmath - and @xmath -quark jets
with a veto on any probe -jet that has a muon matched to it within a
cone of @xmath .

##### 25.0.6 Fraction of @xmath-Quark Jets in the Dijet Samples

The uncertainty on the fraction of @xmath -quark jets in the dijet
samples originates from the uncertainty of the @xmath fit. The @xmath -
and @xmath -quark jet charge distributions are re-derived varying the
fraction of @xmath -quark jets according to this uncertainty.

##### 25.0.7 Fraction of Muon Charge Sign Change in the Dijet and Monte
Carlo Samples

The amount of cascade decay passing the loose and tight dijet selections
depends on the jet @xmath . The simulated @xmath events and the dijet
samples have similar but not equal jet @xmath and @xmath spectrum.
Therefore, there is still the possibility that the fraction of cascade
muons is different in the dijet samples and simulated @xmath events,
that are used to extract the fraction of times the muon charge sign is
different from the quark initiating the jet. This uncertainty is taken
into account by re-deriving the jet charge templates by varying the
fraction of times the muon charge changes sign, @xmath (calculated in
Sec. 23.4 ), according to the uncertainty on the weighted average.

The measured charge of the muon can be different from the quark that
initiated the jet simply because the muon track was poorly
reconstructed. This effect exists also in the simulated events and we
observe that it affects about @xmath % of the muons inside jets in
simulated @xmath events. The rate at which the muon charge is measured
incorrectly might be different in data and simulation. This potential
difference between data and simulation is taken into account by varying
how often the charge is misidentified between @xmath % and @xmath %.

##### 25.0.8 Statistical Uncertainty on the Kinematic Weighting

The procedure to weight the @xmath Monte Carlo events to reproduce the
jet @xmath and @xmath spectrum of the dijet samples has a number of
uncertainties associated with it. By using the @xmath band in the fits,
the statistical uncertainty can be evaluated. There are two weights that
are applied, the jet @xmath and @xmath weights, both with a statistical
uncertainty associated with them. Conservatively, the uncertainties are
added in quadrature and the jet charge templates are re-derived varying
this uncertainty.

##### 25.0.9 Statistical Uncertainty on the Kinematic Correction

There is an additional systematic uncertainty related to the kinematic
correction which arises from the limited statistics used in the
correction. This systematic is evaluated by using the @xmath bands on
the kinematic correction fit shown in Fig. 41 and re-deriving the jet
charge templates using these varied correction functions.

##### 25.0.10 Statistical Uncertainty on the Jet Charge Templates

The extraction of the jet charge template in Sec. 23.2 leads to a
statistical uncertainty on the jet charge distributions. This
uncertainty is evaluated by fitting the jet charge distributions with
Gaussian functions and varying the fitted parameters within their
uncertainties to produce @xmath templates. The fit for @xmath - and
@xmath -quark jet charge distributions are shown in Fig. 51 and 52
respectively.

The validity of this procedure was estimated by allowing each bin of the
jet charge distributions to vary according to a Gaussian centered on the
bin content and a width according to the error of that bin. After
varying all bins in the jet charge templates the discriminating power is
calculated and put in a histogram. This procedure is repeated @xmath
times and the resulting distribution is fitted with a Gaussian where the
width is compared to the difference in discriminating power between the
@xmath varied jet charge distributions. The varied jet charge templates
have a discriminating power that agrees with the width of the Gaussian
and the statistical uncertainty on the templates are thus reasonable.

##### 25.0.11 Top Quark Mass Uncertainty

The constrained kinematic fit uses the top quark mass as an additional
constraint at a value of @xmath GeV. This value is chosen to be
consistent with the mass used in the generation of the simulated events.
Top quark mass is known only to a certain precision and constraining the
mass in the fit to an alternative value might affect the fit
performance. To take this into account, the SM top and exotic quark
charge templates are re-derived using simulated @xmath events generated
with different masses, while keeping the same top mass constraint in the
fit. Events generated with a top quark mass of @xmath and @xmath GeV are
used to evaluate this systematic uncertainty. The current world average
uncertainty in the top mass is @xmath GeV topmass_average and therefore
the SM top and exotic quark charge templates obtained from the @xmath
and @xmath GeV samples are scaled corresponding to this uncertainty.

##### 25.0.12 Jet Energy Scale

The jet energy scale correction is an attempt to correct the measured
jet energies in the calorimeter back to the stable-particle level before
interacting with the detector as described in Sec. 17.2 and is applied
to all jets. The jet energy scale correction is different for jets in
data and in simulated events as shown in Fig. 18 and 19 . The
uncertainty from the jet energy scale is found by adding the
uncertainties from data and simulation in quadrature, conservatively
treating them totally uncorrelated. This uncertainty changes the jet
energies in the event and may consequently affect the kinematic fit. The
SM top and exotic quark charge templates are re-derived using the varied
jet energy scale correction.

##### 25.0.13 Jet Energy Resolution

The observed @xmath spectrum of jets in simulated events is smeared to
match the resolution measured in data. The uncertainties on the
parametrization of the jet energy introduces an uncertainty not taken
into account by the jet energy scale. To account for this, the
parametrization is varied according to the uncertainty and the SM top
and exotic quark charge templates are re-derived.

##### 25.0.14 Jet Reconstruction and Identification Efficiency

The efficiency to reconstruct a jet subject to all requirements in Sec.
17.1 is higher in simulated events than in data
xsec_note240_mujets_topological . The discrepancy is most prominent in
the low @xmath region ( @xmath GeV). Therefore, a @xmath dependent
data-to-simulation scale factor is derived and jets in simulated events
are removed to reproduce the jet reconstruction efficiency observed in
data. This scale factor is varied according to its uncertainty to take
into account any effect on the kinematic fit and the SM top and exotic
quark charge templates are re-derived.

##### 25.0.15 Composition of the Signal Sample

The signal sample composition discussed in Sec. 21 has some uncertainty.
Due to the large signal-to-background ratio this uncertainty has a small
net effect on the analysis. It is evaluated by taking into account the
statistical and systematic uncertainty when extracting the final result.
A more detailed description is given in Sec 26 .

##### 25.0.16 @xmath Production Mechanism

The dominant @xmath production mechanism in the dijet samples is assumed
to be flavor creation. Other processes contributing to the production of
@xmath pairs (flavor excitation and gluon splitting) destroy the
correlation between the sign of the tagging muon and the quark
initiating the probe -jet. The fraction of flavor creation is sensitive
to the azimuthal distance between the jets. Therefore, the jet charge
templates are re-derived with the requirement of @xmath instead of
@xmath on the azimuthal distance between the two jets in the dijet
samples to take this uncertainty into account.

##### 25.0.17 @xmath Signal Modeling

In the kinematic fit it is assumed that the four highest @xmath jets in
the event are the result of the hadronization of the partons from the
@xmath decay. As discussed before, additional jets can arise from ISR
and FSR. When @xmath events are produced in association with a jet, the
additional jet can be misinterpreted as a decay product from the @xmath
pair. To assess the uncertainty in the modeling of these effects, events
has been generated using a dedicated simulation of the production of
@xmath events together with an additional parton using ALPGEN . The
fraction of such events is estimated not to be larger than @xmath %
top_mass_matrix_element_PRD . The SM top and exotic quark charge
templates are re-derived using this sample and systematic uncertainty of
@xmath % of the difference between this and the default simulated @xmath
sample is quoted.

###

To estimate the effect of the individual sources of systematic
uncertainties, the discriminating power between the varied SM top and
exotic quark charge templates is calculated and shown in Tab. 16 .

### 26 Results

The underlying models in this analysis are the two hypotheses of a SM
top quark with a charge of @xmath or an exotic quark with charge @xmath
referred to in the following as @xmath and @xmath respectively. A
hypothesis test is performed in Sec. 26.1 to assess the validity of the
different hypotheses using a likelihood ratio test. However, the
hypothesis test only provides the confidence in rejecting any of the two
discrete scenarios, it does not assess the probability of a mixture of
quarks with charge @xmath and @xmath in the signal sample. Therefore, in
Sec. 26.2 the fraction of quarks with the exotic charge @xmath is
estimated using the method of maximum likelihood.

#### 26.1 Discrimination Between Charge 2e/3 Top Quark and Charge 4e/3
Exotic Quark Production Scenarios

In data a certain set of charges @xmath and @xmath are observed in the
leptonic and hadronic leg of the @xmath event respectively. There are 21
selected events in the signal sample. In 16 events, the kinematic fit
converges in at least one of the permutations where the two jets @xmath
and @xmath are associated to SVT-tagged jets. Each of the 16 events
provides two observations of the charge, giving 16 observations of
@xmath and 16 observations of @xmath , i.e. a total of 32 charge
observations. Figure 53 shows the binned and unbinned distribution of
measured charges in the data overlaid with the expected SM top and
exotic quark charge templates.

As can be seen from the figures, the observed data prefers the SM
hypothesis. Below, a procedure to quantify the discrimination between
the two hypotheses is described.

##### 26.1.1 Likelihood Ratio

Often when discriminating between two scenarios it is useful to define a
test statistics. If the set of 32 measured values @xmath and @xmath are
denoted by a vector @xmath then the test statistics, denoted @xmath ,
can be a single number or a vector with fewer components than @xmath .
@xmath is a function of the data and its value reflects the level of
agreement between the data and the hypothesis. Under assumption of each
hypothesis different @xmath will be obtained for repeated experiments.

The goodness is quantified by the @xmath -value, which is the
probability to find @xmath in the region of equal or lesser
compatibility assuming a hypothesis @xmath than the level of
compatibility observed with the real data @xmath . In this analysis, the
test statistics @xmath is the ratio of the likelihoods @xmath for the
two different hypotheses @xmath and @xmath given a vector of data @xmath

  -- -------- -- ------
     @xmath      (24)
  -- -------- -- ------

where the likelihood functions are defined as

  -- -------- -- ------
     @xmath      (25)
     @xmath      (26)
  -- -------- -- ------

Here the probability density functions (p.d.f.s) @xmath and @xmath are
the SM top and exotic quark charge templates derived in Sec. 24.2 and
the subscript @xmath runs from @xmath .

Under the assumption that the distribution of @xmath follows a
hypothesis @xmath , the p.d.f. @xmath will be determined for the test
statistics. Here, the two hypotheses gives:

  -- -------- -- ------
     @xmath      (27)
     @xmath      (28)
  -- -------- -- ------

Given the definition of the test statistic, the @xmath -value for the
exotic scenario is

  -- -------- -- ------
     @xmath      (29)
  -- -------- -- ------

The likelihood ratio obtained from Eq. 24 with the set @xmath of 32
observed charges in the signal sample is,

  -- -------- --
     @xmath   
  -- -------- --

##### 26.1.2 Generation of Pseudo-experiments

The @xmath -value is not the probability of the hypothesis but rather
the probability under the assumption of the hypothesis of obtaining data
as incompatible with the hypothesis as the data observed. Thus, in order
to calculate the @xmath -value for the exotic scenario defined in Eq. 29
, the p.d.f. @xmath has to be computed.

This can be determined by the generation of pseudo-experiments which in
an idealized world would correspond to building a set of new experiments
and measure the charge under the assumption of @xmath . The procedure is
as follows:

1.   Signal and background fraction
    The signal and background fractions are allowed to fluctuate
    according to the statistical and systematic uncertainties: The
    number of background events @xmath is obtained from a Binomial
    distribution with a mean at the prediction given by a Gaussian
    distribution with a mean of @xmath (the central prediction) and a
    standard deviation equal to the total uncertainty on the number of
    background events (see Fig. 54 ).

2.   Systematic uncertainties
    The various sources of systematic uncertainties affect the template
    distributions and have to be taken into account. The method used
    here allows the systematic uncertainties to change the default (or
    best guess) template. All systematic uncertainties @xmath are
    assumed to follow Gaussian distributions with widths @xmath . Each
    systematic uncertainty is modeled by a free parameter @xmath called
    nuisance parameter nuisance_params . If the default SM top quark
    template is characterized by a function @xmath and if @xmath and
    @xmath are the @xmath varied templates for the source of error
    @xmath , then the SM top quark template (and similar for the exotic
    quark charge template) as a function of all systematic uncertainties
    can be written as:

      -- -------- -- ------
         @xmath      (30)
         @xmath      (31)
      -- -------- -- ------

    and similar for the exotic template. @xmath follow Gaussian
    distributions with mean zero and standard deviation one.

3.   Pseudo-measurements
    The number of pseudo-measurements has to be equal to the total
    number of observed charges and thus @xmath is randomly sampled
    @xmath times and the background template (given in Sec. 24.3 )
    @xmath times to obtain a set of pseudo-measurements @xmath .

4.   Likelihood ratio
    Given the set of pseudo-measurements @xmath , the likelihood ratio
    is calculated using the generated @xmath and @xmath to take into
    account the systematic uncertainties.

By repeating steps 1 - 4 @xmath times (each time with a new background
fraction and new set of nuisance parameters @xmath ), @xmath can be
determined. In a similar way, the p.d.f. @xmath can be determined by
sampling the @xmath charge template in step 2 . Both @xmath and @xmath
are shown in Fig. 55 together with the observed @xmath in data.

##### 26.1.3 Confidence Level

From Fig. 55 it is clear that the observed set of charges is more SM
like than exotic like. The calculation of what confidence level @xmath
the observed charges excludes the hypothesis of 100% quarks with the
exotic @xmath charge in the signal sample is simply done by observing
that

  -- -------- -- ------
     @xmath      (32)
  -- -------- -- ------

The confidence level is therefore extracted by calculating the @xmath
-value as defined in Eq. 29

  -- -------- -- ------
     @xmath      (33)
  -- -------- -- ------

and the corresponding confidence level is @xmath %.

The probability that the exotic hypothesis gives a set of charges as
incompatible with the observed median of @xmath is also calculated. This
can be thought of as an expected confidence level and is given by:

  -- -------- -- ------
     @xmath      (34)
  -- -------- -- ------

which gives the expected confidence level @xmath % in good agreement
with the observed @xmath %.

The effect of the systematic uncertainties on the confidence level can
be seen in Tab. 17 where the cumulative and individual effect of
including systematic uncertainties are shown.

#### 26.2 Fraction of Charge @xmath Top Quark and Charge @xmath Exotic
Quarks

The exclusion at @xmath % confidence level that the set of data @xmath
arose from the decay of a quark with the exotic @xmath electric charge
does not address the possibility that the set of data results from a
mixture of a @xmath and a @xmath charge quark. In this section the
fraction of exotic @xmath charge quarks in the signal sample is
estimated.

##### 26.2.1 Maximum Likelihood Fit

To extract as estimate of the fraction of exotic quarks @xmath the
method of maximum likelihood is used. If @xmath is the p.d.f. from where
the measurements @xmath arises, the estimated fraction of exotic quarks
is the value of @xmath that maximizes the likelihood function,

  -- -------- -- ------
     @xmath      (35)
  -- -------- -- ------

The p.d.f.s @xmath for a specific fraction of exotic quarks @xmath is
found by mixing the pure SM top quark charge template @xmath and the
pure exotic quark charge template @xmath with the appropriate fraction.

  -- -------- -- ------
     @xmath      (36)
  -- -------- -- ------

For each value of @xmath (taken to be @xmath ) the unbinned likelihood
that the data @xmath is consistent with the sum of signal and background
is computed as described in Eq. 35 . The @xmath is minimized for the 32
observed charges in data and the result is a set of @xmath points versus
@xmath . The result can be fitted with a parabola to find the maximum
likelihood estimator of @xmath .

##### 26.2.2 Interpretation of the Result to a Confidence Interval

For Gaussian errors, @xmath has a parabolic shape and the confidence
region (the probability that this region contains the true value of
@xmath ) is given by,

  -- -------- -- ------
     @xmath      (37)
  -- -------- -- ------

and the @xmath % ( @xmath %) standard deviation confidence intervals are
given by @xmath PDG .

The result is also reported using a Bayesian approach where the prior
p.d.f. @xmath characterizes the prior knowledge of the true value of
@xmath . Using Bayes theorem,

  -- -------- -- ------
     @xmath      (38)
  -- -------- -- ------

the Bayesian confidence interval can be determined by computing the
interval @xmath which contain a given fraction @xmath of the
probability,

  -- -------- -- ------
     @xmath      (39)
  -- -------- -- ------

In this analysis, a flat prior p.d.f. according to the physical region
is used i.e. it is one in the interval @xmath and zero elsewhere. Using
this, the calculation of the Bayesian interval is given by finding the
interval @xmath such that the probability of @xmath is,

  -- -------- -- ------
     @xmath      (40)
  -- -------- -- ------

where @xmath is the fraction at the minimum of the parabola (i.e. the
fitted fraction). If @xmath is outside the physical region a one-sided
confidence interval is reported as,

  -- -------- -- ------
     @xmath      (41)
  -- -------- -- ------

if @xmath or,

  -- -------- -- ------
     @xmath      (42)
  -- -------- -- ------

if @xmath .

##### 26.2.3 Validation of the Fit Procedure

Before applying the maximum likelihood fit to the selected signal sample
the fit procedure is validated by performing pseudo-experiments where
the input fraction of exotic quarks is known. Ideally, the fit returns
the same fraction without any deviations together with information on
the expected statistical sensitivity.

One pseudo-experiment is built by randomly sampling the p.d.f. @xmath
for a specific exotic fraction @xmath to obtain pseudo-data. In this
procedure, the correct signal and background fractions are taken into
account. A maximum likelihood fit is then performed with the same
procedure as applied to the real data. By performing a large number of
these pseudo-experiments for each input fraction @xmath the performance
of the fit can be evaluated. The fitted versus input fraction shown in
Fig. 56 is consistent with offset zero and slope one. The pull and the
width of the fitted pull functions are shown in Fig. 57 .

For each pseudo-experiment, a confidence interval can be calculated.
Figure 58 shows the expected confidence intervals (taken as the mean of
the confidence intervals for all pseudo-experiments) versus input
fraction for both methods described above.

The Bayesian mean value is constrained by the prior assumption of @xmath
. The conclusion is that the expected width of the @xmath % confidence
interval is approximately @xmath .

##### 26.2.4 Systematic Uncertainties

Sources of systematic uncertainties affect the fitted fraction in two
ways: they can either change the fraction of signal and background or
they can change the templates @xmath . The first is taken into account
by allowing the predicted background fraction to vary according to its
total uncertainty, constrained to the total number of events observed in
data. The effect of the other systematic uncertainties are estimated by
performing pseudo-experiment using the default p.d.f. @xmath but with
pseudo-data randomly sampled from the varied templates. The average
observed shift in the fitted fraction for each systematic uncertainty
(averaged over two input fractions) is added in quadrature to obtain the
final shift from the systematic uncertainties. Table 18 shows the
estimated systematic uncertainties.

##### 26.2.5 Results from Data

Applying the maximum likelihood fit to the observed charges @xmath
results in the fit shown in Fig. 59 .

The maximum likelihood estimator that minimizes the @xmath function is
@xmath , in good agreement with the SM expectation. The effect of
including systematic uncertainties in the @xmath function is shown in
Fig. 60 . The systematic uncertainties are taken into account by
convoluting the @xmath function with a Gaussian centered on the minimum
( @xmath ) and a width equal to the total systematic uncertainty
calculated above.

The upper limit on the fraction of exotic quarks in the signal sample is
@xmath ( @xmath ) at @xmath % ( @xmath %)C.L. The confidence intervals
are shown in Tab. 19 with statistical uncertainty only and in Tab. 20
including systematic uncertainties.

## Chapter \thechapter Conclusion and Outlook

The first determination of the electric charge of the top quark is
presented in this thesis. A data sample from @xmath collisions at @xmath
TeV recorded with the DØ detector at the Fermilab Tevatron collider
corresponding to an integrated luminosity of @xmath pb @xmath was used.
The top quark decays predominantly to @xmath ( @xmath % PDG . The
predicted electric charge of the top quark is @xmath in the SM. The top
quark electromagnetic coupling is however, not measured and since the
correlation between the charge sign of the decay products, i.e. @xmath
and @xmath or @xmath and @xmath , was not known an exotic quark with
electric charge @xmath exotic_top_paper was not excluded.

A pure sample of @xmath candidate events was selected in the @xmath
channel characterized by one high @xmath charged lepton from the @xmath
boson decay and four jets out of which two are tagged using a @xmath
-tagging algorithm. A jet charge algorithm for @xmath -quark jets based
on the @xmath weighted sum of charges of the tracks associated with the
jet was developed to distinguish between @xmath - and @xmath -quark
jets. The algorithm was calibrated using dijet data dominated by @xmath
events. Template distributions to discriminate between the SM top and
exotic quark charge scenarios were obtained by reconstructing the charge
of the decay products: The charge of the high @xmath lepton and the
@xmath -tagged jets where the charge was extracted using the jet charge
algorithm. A kinematic fit was performed to associate one of the @xmath
-quark jets to the charged lepton.

A likelihood ratio test to discriminate between the SM and the exotic
charge hypothesis shows good agreement with the SM. The possibility that
100% of the selected events are exotic quarks with electric charge
@xmath is ruled out to 92% C.L. Nevertheless, the candidate heavy quarks
could still be a mixture of two particles with the different charges.
Using a Bayesian method to estimate the confidence intervals including
both statistical and and systematic uncertainties, the fraction of
exotic charges @xmath in the selected sample is

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

The fraction of exotic quarks in the selected sample is consistent with
zero, the SM prediction.

The recorded integrated luminosity at the Tevatron is presently above
@xmath fb @xmath which together with another year of data taking should
allow for an exclusion of the exotic charge scenario close to @xmath %.

The Large Hadron Collider (LHC) at CERN is planned to start data taking
during 2007. It will increase the luminosity with a factor of @xmath and
the center-of-mass to @xmath TeV. The top quark production cross-section
is more than a factor of @xmath larger and the top quark pair production
rate will be approximately 8 million per year atlas_tdr allowing for a
possible determination of the top quark electromagnetic coupling baur .

In general the top quark will play a major role in the physics program
at LHC due to its the large mass, possibly playing a key role in
electroweak symmetry breaking. The LHC is devoted to search for New
Physics and any signature involving high @xmath leptons, jets and @xmath
are bound to have the top quark as a major background. In addition, the
two jets from the hadronic decay of the W boson in a @xmath event may be
used to calibrate the jet energy scale by reconstructing the invariant
mass of the @xmath boson.

## Acknowledgements

  I begin with thanking my supervisor Bengt Lund-Jensen for his decision
  to give me this position at KTH. Although sometimes far away from the
  analysis work he has always made sure that I was taken care of, not
  only research- and financial-wise, but also in my everyday life as a
  “doktorand”.
  When I started at KTH I was sent to Fermilab to work in the top
  working group. Christophe Clément became my supervisor and teammate
  for this project and has guided me from square one. Thank you
  Christophe: for your brains, for teaching me physics, for explaining
  all the details, for your company during long nights at Fermilab, for
  the lunch excursions, for the smooth collaboration and for your
  friendship.
  David Milstead has been of excellent help in my work and taking time
  to discuss and telling me how things really works. Thank you for
  getting me back on track when I was lost and for your cool english
  style. Thank you Sten Hellman for inspiring us to start this project.
  I would like to thank the whole DØ collaboration for running the
  experiment. In the top working group Regina Demina, Aurelio Juste,
  Chris Tully, Erich Varnes and Martijn Mulders made numerous comments
  and suggestions concerning this analysis. Sergey Burdin helped with
  @xmath -physics related issues. In particular, I would like to mention
  the excellent people in the Swedish Consortium who made me feel
  welcome from the start: Jonas Strandberg, thank you for helping me
  with DØ code and answering all my questions about @xmath -tagging.
  Thank you for your attempts to help me understand baseball. Nils
  Gollub, thank you for the root-help, the many discussions and the fun
  times which hopefully continues in the coming years. Your
  proof-reading is much appreciated. Sara Strandberg always listened to
  my questions and helped me with everyday life at the lab. Thank you
  for lending me your car. I’m also very grateful to Barbro Åsman who
  not only helped me with my travel arrangements to Fermilab and the
  DØ administration but also allowed me to drive her sports car (until
  Nils borrowed it and it broke down).
  My good friends Paul DiTuro and Alejandro Daleo helped me to stay in
  shape at Fermilab and got me out from the lab occassionally. I will
  never forget the crazy nights in Chicago, not only (!) because of the
  “TVR”-scar. Christian Schwanenberger was the only one putting up with
  my ice hockey babble.
  Thank you everybody in the particle physics group at KTH. Tore
  Ersmark, my roommate, has been my excellent computer support. Thank
  you Jens Lund for the laughs and (inappropriate) jokes and Sara
  Bergenius Gavler who kept organizing despite the workaholic crew. I
  would also like to thank Mark Pearce, Janina Östling, Jan Conrad, Erik
  Fredenberg, Karl-Johan Grahn, Silvio Orsi, Cecilia Marini Bettolo and
  Petter Hofvenberg for their nice company and lively discussions.
  A big thanks goes to Christopher Engman who provided lodging and to
  Hanna Källman and Therese Nordlund who are always there for me. Svalan
  made sure I thought about other things than physics from time to time,
  thank you.
  Without the full support and love of my parents, Kaj and Thory, this
  thesis would not have been possible. Thank you for raising me and
  allowing me to find my interests. I love you.
  I also would like to thank my brother and best friend Björn for all
  the discussions, the good times, the trips and general “hets”. You are
  the best.
  Finally, without my wonderful Anna this thesis would have been a lot
  shorter. She has always supported me and accepted my absence many
  evenings and weekends. You mean the world to me!