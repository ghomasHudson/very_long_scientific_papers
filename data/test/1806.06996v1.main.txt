##### Acknowledgements. I would first like to thank my adviser, Amir
Ali Ahmadi. I can safely say that I would never have written a PhD
thesis, nor pursued a career in academia, if it had not been for my
great good luck in having Amir Ali as an adviser. Amir Ali, thank you
for being a wonderful person and mentor. Thank you for believing in me
when I did not believe in myself, for not giving up on me when I was
giving up on the program, and for making me feel comfortable and
confident in an environment where I never expected to feel that way.
Thank you for giving me the opportunity to see how a truly brilliant
mind works—if I have only taken away from this PhD a fragment of your
clarity of thought, your attention to detail, and your unbridled
creativity, then it will have been a success. Thank you for investing so
much time in helping me grow, reading over my papers until they were
perfect, listening to my practice talks for hours on end, working with
me to perfect the way I answer questions during talks, and giving me
feedback on my proofs and my ideas. I know of no other adviser like you,
so kind, altruistic, and gifted. Our 4-year collaboration has been a
source of great inspiration and pleasure to me and I hope that it will
continue past this PhD, until we are both old and grey (a time that may
come earlier to some than others!). I would also like to thank my thesis
readers and committee members, Anirudha Majumdar, Bob Vanderbei, and
Mengdi Wang. It has been a great honor to interact with you over the
years within Princeton and without. Thank you to my co-authors, Emmanuel
Abbe, Afonso Bandeira, Mihaela Curmei, Sanjeeb Dash, Etienne de Klerk,
Ameesh Makadia, Antonis Papachristodoulou, James Saunderson, Vikas
Sindhwani, and Yang Zheng. It was a real pleasure to work with you all.
I learnt so much from my interactions with you. A special thank you to
Afonso Bandeira for introducing me to Amir Ali and to Sébastien Bubeck
for advising me during my second year at Princeton University. I am
extremely grateful to the people who wrote letters of recommendations
for me, for job applications, fellowships, and otherwise: Emmanuel Abbe,
Rene Carmona, Erhan Cinlar, Sanjeeb Dash, Etienne de Klerk, and Leo
Liberti. I would also like to acknowledge Sanjeeb Dash, Jean-B.
Lasserre, Leo Liberti, Daniel Kuhn, Antonis Papachristodoulou, Pablo
Parrilo, and Bernd Sturmfels, for inviting me to give seminars and
offering help and advice when I was faced with important decisions. Je
remercie mes professeurs de mathématiques, M. Aiudi, M. Técourt, et M.
Koen, ainsi que mon professeur de physique de classes preparatoires, M.
Cervera, pour leur soutien. Sans eux, je n’aurais jamais eu la passion
que j’ai pour les sciences, ni la rigueur que j’ai acquise avec eux pour
les étudier. I would like to thank my incredible friends back home for
the Skypes over the years, for visiting me, and for finding the time to
see me whenever I went home: Alice, Brice, Florian, JG, Joachim, Jorge,
Mathieu, Marie B., Marie G., Martin, Noémie, Paul, Sacha, Timtim,
Valentine. Elise (and Sean!), merci de m’avoir soutenue pendant mes
deuxième et troisième annees — tu es une amie formidable. Hâte de vous
voir tous beaucoup plus maintenant que je rentre! Thank you to my
fantastic ORFE officemates and teammates, as well as all the people I
was lucky enough to TA with over the years: Bachir, Cagin, Cemil,
Chenyi, Donghwa, Elahe, Firdevs, Han, Jeff (who will remind me to
register to conferences and book tickets now?), Joane, Junwei, Kaizheng,
Kevin W., Sinem, Tianqi, Thomas P., Yutong, Yuyan, Zongxi. I would also
like to acknowledge the wonderful students I have had the opportunity to
teach over the years and particularly those with whom I worked on senior
theses: Ellie, Mihaela, Salena, and Tin. Thank you to Kim for being a
great department coordinator, and to Carol and Melissa for helping me
with my receipts! To my other friends in Princeton, you made the
toughest times not only bearable but fun: Adam, Adrianna, Amanda, Alex,
Carly, Chamsi, Daniel J., Genna, Hiba, Ingrid, Jessica, Kelsey, Lili,
Kobkob, Marte, Matteo, Roger, Sachin, Sara, Thomas F. Last but not
least, I am lucky enough to have the most supportive family anyone could
ever ask for. Kevin, ta capacité a voir le côté humouristique dans
toutes les situations et a dédramatiser mes problèmes les plus
compliqués m’ont permis de rester saine. Merci pour tout. Luey, que dire
de plus si ce n’est que tu es allée m’acheter tout un pack de survie
avant mon entretien a l’INSEAD. Chaque fois qu’on se voit (#Disney) ou
qu’on s’appelle, ma journée devient that much better. Tom, merci d’avoir
été Team Georgi jusqu’au bout. Mutts and Dads, thanks for being the best
parents ever. Your unconditional support and the fact that you were
willing to learn about a whole new area just to keep up with me meant so
much to me. Thank you. \dedication To Mutts and Dads. \makefrontmatter

### Chapter 1 Introduction

This thesis concerns itself broadly with the problem of optimizing over
nonnegative polynomials . In its simplest form, this problem involves
(i) decision variables that are the coefficients of a multivariate
polynomial of a given degree, (ii) an objective function that is linear
in the coefficients, (iii) constraints that are affine in the
coefficients, and (iv) a constraint that the multivariate polynomial be
nonnegative over a closed basic semialgebraic set , i.e., a set defined
by a finite number of polynomial inequalities. We write:

  -- -- -------- -------- -------- -------- -------
        @xmath            @xmath            (1.1)
                                   @xmath   
                 @xmath                     
  -- -- -------- -------- -------- -------- -------

where @xmath here denotes the coefficients of a multivariate polynomial
@xmath of some degree @xmath , @xmath is a linear functional over the
coefficients of @xmath , @xmath is a linear map that maps the
coefficients of @xmath to @xmath , @xmath is a vector in @xmath , and
@xmath , are multivariate polynomials.

This problem appears under different forms in a wide range of
applications. One such application is polynomial optimization , which is
the problem of minimizing a polynomial function over a closed basic
semialgebraic set:

  -- -- -------- -- -------- --
        @xmath      @xmath   
                    @xmath   
  -- -- -------- -- -------- --

Indeed, the optimal value of this problem is equivalent to the largest
lower bound on @xmath over the set @xmath . In other words, we can find
the optimal value of the problem above by solving the following “dual”
problem:

  -- -- -------- -- -------- --
        @xmath      @xmath   
                    @xmath   
  -- -- -------- -- -------- --

This is exactly a problem of optimizing over nonnegative polynomials.
Polynomial optimization problems, or POPs, feature in different areas:
in power engineering via the optimal power flow problem [ 99 ] , in
discrete and combinatorial optimization [ 115 , 80 ] , in economics and
game theory [ 183 ] , and in distance geometry [ 146 ] , just to name a
few. Other applications of the problem of optimizing over nonnegative
polynomials appear in control, in particular for searching for Lyapunov
functions for dynamical systems [ 154 , 152 , 90 , 1 ] , robotics [ 8 ]
, and machine learning and statistics [ 111 ] , among other areas.

All these applications motivate the question as to whether ( 1.1 ) can
be solved efficiently. The answer is unfortunately negative in general.
In fact, simply testing whether a given polynomial of degree-4 is
nonnegative over @xmath is NP-hard [ 143 ] . Past work has hence focused
on replacing the nonnegativity condition in ( 1.1 ) with a stronger, but
more tractable, condition. The idea is that the optimization problem
thus obtained can be efficiently solved and upper bounds on the optimal
value of ( 1.1 ) can be obtained (note that the set over which we would
be optimizing would be an inner approximation of the initial feasible
set).

A well-known sufficient condition for (global) nonnegativity of a
polynomial @xmath is that it be a sum of squares (sos), i.e., that it
have a decomposition of the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are polynomials. Sum of squares polynomials have a long
history that dates back at least to the end of the @xmath century. In
1888, Hilbert showed that not all nonnegative polynomials are sums of
squares by proving that these two notions are only equivalent when some
conditions on the degree of the polynomial at hand and the number of its
variables are met [ 92 ] . His proof was not constructive and it would
be another 80 years before the first example of a nonnegative but
non-sum of squares polynomial would be presented by Motzkin [ 141 ] .
Hilbert’s research on sum of squares polynomials led him to include a
related question in the list of so-called “Hilbert problems”, a famous
list of 23 open questions, that Hilbert put forward in the year 1900.
His @xmath problem poses the question as to whether every nonnegative
polynomial can be written as the ratio of two sums of squares
polynomials. This was answered affirmatively by Artin [ 19 ] in 1927.

The beginning of the @xmath century brought with it a renewed interest
in sum of squares polynomials, but from the optimization community this
time, rather than the pure mathematics community. This was largely due
to the discovery that sum of squares polynomials and semidefinite
programming are intimately related [ 145 , 153 , 114 ] . We remind the
reader that semidefinite programming (SDP) is a class of optimization
problems where one optimizes a linear objective function over the
intersection of the cone of positive semidefinite matrices and an affine
subspace, i.e., a problem of the type

  -- -- -------- -------- -------- -------- -------
        @xmath            @xmath            (1.2)
                                   @xmath   
                 @xmath                     
  -- -- -------- -------- -------- -------- -------

where @xmath denotes the set of @xmath symmetric matrices, @xmath
denotes the trace of a matrix, and @xmath are input matrices of size
respectively @xmath Semidefinite programming comprises a large class of
problems (including, e.g., all linear programs), and can be solved to
arbitrary accuracy in polynomial time using interior point methods. (For
a more detailed description of semidefinite programming and its
applications, we refer the reader to [ 192 ] .) The key result linking
semidefinite programming and sos polynomials is the following: a
polynomial @xmath of degree @xmath is sos if and only if it can be
written as

  -- -------- --
     @xmath   
  -- -------- --

for some positive semidefinite matrix @xmath . Here, @xmath is the
vector of standard monomials of degree @xmath . Such a matrix @xmath is
sometimes called the Gram matrix of the polynomial @xmath and it is of
size @xmath if @xmath is of degree @xmath and has @xmath variables. This
result implies that one can optimize over the cone of sos polynomials of
fixed degree in polynomial time to arbitrary accuracy. Indeed, searching
for the coefficients of a polynomial @xmath subject to the constraint
that @xmath be sos can be rewritten as the problem of searching for a
positive semidefinite matrix @xmath whose entries can be expressed as
linear combinations of the coefficients of @xmath (this is a consequence
of the fact that two polynomials are equal everywhere if and only if
their coefficients are equal). In other words, any sos program , i.e., a
linear optimization problem over the intersection of the cone of sos
polynomials with an affine subspace, can be recast as an SDP. (We remark
that it is also true that any SDP can be written as an sos program—in
fact, this sos program need only involve quadratic polynomials.)

How can sos programs be used to solve problems like ( 1.1 )? It turns
out that one can produce certificates of nonnegativity of a polynomial
@xmath over a closed basic semialgebraic set

  -- -------- --
     @xmath   
  -- -------- --

via sum of squares polynomials. Such certificates are called
Positivstellensätze. We briefly mention one such Positivstellensatz here
to illustrate the point we aim to make. Other Positivstellensätze as
well as additional context is given in Chapter 4 of this thesis. The
following Positivstellensatz is due to Putinar [ 162 ] : under a
technical assumption slightly stronger than compactness of @xmath (see
Theorem 4.1.3 for the exact statement), if @xmath is positive on @xmath
, then there exist sos polynomials @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

(Conversely, it is clear that if such a representation holds, then
@xmath must be nonnegative on @xmath .) Hence, one can replace the
condition that @xmath be nonnegative over @xmath in ( 1.1 ) by a
“Putinar certificate” and obtain the following optimization problem:

  -- -- -------- -------- -------- -------- -------
        @xmath            @xmath            (1.3)
                                   @xmath   
                 @xmath                     
                 @xmath                     
  -- -- -------- -------- -------- -------- -------

Note that when the degrees of the polynomials @xmath are fixed, this
problem is an sos program, which can be recast as an SDP and solved in
polynomial time to arbitrary accuracy. This provides an upper bound on
the optimal value of ( 1.1 ). As the degree of the sos polynomials
increases, one obtains a sequence of upperbounds on the optimal value of
( 1.1 ) that is nonincreasing. Putinar’s Positivstellensatz tells us
that if one keeps increasing the degrees of the sos polynomials, one
will eventually (and maybe asymptotically) recover the optimal value of
( 1.1 ), the caveat being that the degrees needed to recover this
optimal value are not known a priori.

We remark that the semidefinite programs arising in this hierarchy can
be quite large, particularly if the number of variables and the degrees
of @xmath are high. Hence, they can be quite slow to solve as
semidefinite programs are arguably the most expensive class of convex
optimization problems to solve, with a running time that grows quickly
with the dimension of the problem [ 192 ] .

As a consequence, recent research has focused on making sum of squares
optimization more scalable. One research direction has focused on
exploiting structure in SDPs [ 46 , 56 , 72 , 168 , 191 , 201 ] or
developing new solvers that scale more favorably compared to interior
point methods [ 28 , 119 , 148 , 200 ] . Another direction involves
finding cheaper alternatives to semidefinite programming that rely,
e.g., on linear programming or second order cone programming. This, as
well as methods to derive certificates of positivity over closed basic
semialgebraic sets from certificates of global positivity, is the focus
of the first part of this thesis. The second part of this thesis focuses
on a special case of the problem of optimizing over nonnegative
polynomials: that of optimizing over convex polynomials, and
applications thereof. In the next section, we describe the contents and
contributions of each part of this thesis more precisely.

#### 1.1 Outline of this thesis

###### Part I: LP, SOCP, and Optimization-Free Approaches to
Semidefinite and Sum of Squares Programming.

The first part of this thesis focuses on linear programming, second
order cone programming, and optimization-free alternatives to sums of
squares (and semidefinite) programming.

Chapter 2 and Chapter 3 are computational in nature and propose new
algorithms for approximately solving semidefinite programs. These rely
on generating and solving adaptive and improving sequences of linear
programs and second order cone programs.

Chapter 4 is theoretical in nature: we show that any inner approximation
to the cone of nonnegative homogeneous polynomials that is arbitrarily
tight can be turned into a converging hierarchy for general polynomial
optimization problems with compact feasible sets. We also use a
classical result of Polyá on global positivity of even forms to
construct an “optimization-free” converging hierarchy for general
polynomial optimization problems (POPs) with compact feasible sets. This
hierarchy only requires polynomial multiplication and checking
nonnegativity of coefficients of certain fixed polynomials that arise as
products.

We emphasize that the goals in Chapters 2 , 3 , and 4 are different,
though they both work with more tractable (but smaller) subclasses of
nonnegative polynomials than sum of squares polynomials. For the first
two chapters, the goal is to solve in a fast and more efficient manner
the sos program given in ( 1.3 ) approximately. In the third chapter,
the goal is to provide new converging hierarchies for POPs with compact
feasible sets that rely on simpler certificates.

###### Part II: Optimizing over convex polynomials.

The second part of the thesis focuses on an important subcase of the
problem of optimizing over the cone of nonnegative polynomials: that of
optimizing over the cone of convex polynomials. The relationship between
nonnegative polynomials and convex polynomials may not be obvious at
first sight but it be seen easily, e.g., as a consequence of the
second-order characterization of convexity: a polynomial @xmath is
convex if and only if its Hessian matrix @xmath is positive semidefinite
for all @xmath . This is in turn equivalent to requiring that the
polynomial @xmath in @xmath variables @xmath be nonnegative. Hence, just
as the notion of sum of squares was used as a surrogate for
nonnegativity, one can define the notion of sum of squares-convexity (
sos-convexity ), i.e., @xmath be sos, as a surrogate for convexity. One
can then replace any constraint requiring that a polynomial be convex,
by a requirement that it be sos-convex. The program thus obtained will
be an sos program which can be recast as an SDP. Chapters 5 , 6 , 7 ,
and 8 all present different theoretical and applied questions around
this problem.

In Chapter 5 , this framework is used for a theoretical study of
optimization problems known as difference of convex (dc) programs ,
i.e., optimization problems where both the objective and the constraints
are given as a difference of convex functions. Restricting ourselves to
polynomial functions, we are able to show that any polynomial can be
written as the difference of two convex polynomial functions and that
such a decomposition can be found efficiently. As this decomposition is
non-unique, we then consider the problem of finding a decomposition that
is optimized for the performance of the most-widely used heuristic for
solving dc programs.

In Chapter 6 , we are interested in understanding when a homogeneous
polynomial @xmath of degree @xmath generates a norm. We show that the
@xmath root of any strictly convex polynomial is a norm. Such norms are
termed polynomial norms . We show that they can approximate any norm to
arbitrary accuracy. We also show that the problem of testing whether a
polynomial of degree @xmath gives rise to a polynomial norm is NP-hard.
We consequently provide SDP-based hierarchies to test membership to and
optimize over the set of polynomial norms. Some applications in
statistics and dynamical systems are also discussed.

In Chapter 7 , we consider a problem that arises frequently in motion
planning and robotics: that of modeling complex objects in an
environment with simpler representations. The goal here is to contain a
cloud of 3D-points within shapes of minimum volume described by
polynomial sublevel sets. A new heuristic for minimizing the volume of
these sets is introduced, and by appropriately parametrizing these
sublevel sets, one is also able to control their convexity.

In Chapter 8 , we consider an important application in statistics and
machine learning: that of shape-constrained regression . In this setup,
unlike unconstrained regression, we are not solely interested in fitting
a (polynomial) regressor to data so as to minimize a convex loss
function such as least-squares error. We are also interested in imposing
shape constraints, such as monotonicity and convexity to our regressor
over a certain region. Motivated by this problem, we study the
computational complexity of testing convexity or monotonicity of a
polynomial over a box and show that this is NP-hard already for cubic
polynomials. The NP-hardness results presented in this chapter are of
independent interest, and in the case of convexity are a follow-up
result to the main theorem in [ 12 ] which shows that it is NP-hard to
test whether a quartic polynomial is convex globally . These
computational complexity considerations motivate us to further study
semidefinite approximations of the notions of monotonicity and
convexity. We prove that any @xmath (resp. @xmath ) function with given
monotonicity (resp. convexity) properties can be approximated
arbitrarily well by a polynomial function with the same properties,
whose monotonicity (resp. convexity) are moreover certified via sum of
squares proofs.

Finally, we remark that for the convenience of the reader, each chapter
is written to be completely self-contained.

#### 1.2 Related publications

The material presented in this thesis is based on the following papers.

###### Chapter 2.

A. A. Ahmadi, S. Dash, and G. Hall. Optimization over structured subsets
of positive semidefinite matrices via column generation (2017). In
Discrete Optimization, 24, pp. 129-151.

###### Chapter 3.

A. A. Ahmadi and G. Hall. Sum of squares basis pursuit with linear and
second order cone programming (2016). In Algebraic and Geometric Methods
in Discrete Mathematics, Contemporary Mathematics.

###### Chapter 4.

A. A. Ahmadi and G. Hall. On the construction of converging hierarchies
for polynomial optimization based on certificates of global positivity
(2017). Under second round of review in Mathematics of Operations
Research.

###### Chapter 5.

A. A. Ahmadi and G. Hall. DC decomposition of nonconvex polynomials with
algebraic techniques (2015). In Mathematical Programming, 6, pp.1-26.

###### Chapter 6.

A. A. Ahmadi, E. de Klerk, and G. Hall. Polynomial norms (2017). Under
review. Available at ArXiv:1704.07462.

###### Chapter 7.

A. A. Ahmadi, G. Hall, A. Makadia, A., and V. Sindhwani. Geometry of 3D
environments and sum of squares polynomials (2017). In the proceedings
of Robotics: Science and Systems.

###### Chapter 8.

A. A. Ahmadi, M. Curmei, G. Hall. Nonnegative polynomials and
shape-constrained regression (2018). In preparation.

In addition to these papers, the following papers were written during
the graduate studies of the author but are not included in this thesis.

A. A. Ahmadi, G. Hall, A. Papachristodoulou, J. Saunderson, and Y.
Zheng. Improving efficiency and scalability of sum of squares
optimization:recent advances and limitations (2017). In the proceedings
of the 56th Conference on Decision and Control.

E. Abbe, A. Bandeira, and G. Hall. Exact recovery in the stochastic
block model (2016). In IEEE Transactions on Information Theory, vol. 62,
no. 1.

## Part I LP, SOCP, and Optimization-Free Approaches to Semidefinite and
Sum of Squares Programming

### Chapter 2 Optimization over Structured Subsets of Positive
Semidefinite Matrices via Column Generation

#### 2.1 Introduction

Semidefinite programming is a powerful tool in optimization that is used
in many different contexts, perhaps most notably to obtain strong bounds
on discrete optimization problems or nonconvex polynomial programs. One
difficulty in applying semidefinite programming is that state-of-the-art
general-purpose solvers often cannot solve very large instances reliably
and in a reasonable amount of time. As a result, at relatively large
scales, one has to resort either to specialized solution techniques and
algorithms that employ problem structure, or to easier optimization
problems that lead to weaker bounds. We will focus on the latter
approach in this chapter.

At a high level, our goal is to not solve semidefinite programs (SDPs)
to optimality, but rather replace them with cheaper conic relaxations—
linear and second order cone relaxations to be precise—that return
useful bounds quickly. Throughout the chapter, we will aim to find lower
bounds (for minimization problems); i.e., bounds that certify the
distance of a candidate solution to optimality. Fast, good-quality lower
bounds are especially important in the context of branch-and-bound
schemes, where one needs to strike a delicate balance between the time
spent on bounding and the time spent on branching, in order to keep the
overall solution time low. Currently, in commercial integer programming
solvers, almost all lower bounding approaches using branch-and-bound
schemes exclusively produce linear inequalities. Even though
semidefinite cuts are known to be stronger, they are often too expensive
to be used even at the root node of a branch-and-bound tree. Because of
this, many high-performance solvers, e.g., IBM ILOG CPLEX [ 47 ] and
Gurobi [ 79 ] , do not even provide an SDP solver and instead solely
work with LP and SOCP relaxations. Our goal in this chapter is to offer
some tools that exploit the power of SDP-based cuts, while staying
entirely in the realm of LP and SOCP. We apply these tools to classical
problems in both nonconvex polynomial optimization and discrete
optimization.

Techniques that provide lower bounds on minimization problems are
precisely those that certify nonnegativity of objective functions on
feasible sets. To see this, note that a scalar @xmath is a lower bound
on the minimum value of a function @xmath on a set @xmath if and only if
@xmath for all @xmath . As most discrete optimization problems
(including those in the complexity class NP) can be written as
polynomial optimization problems, the problem of certifying
nonnegativity of polynomial functions, either globally or on basic
semialgebraic sets, is a fundamental one. A polynomial @xmath is said to
be nonnegative , if @xmath for all @xmath . Unfortunately, even in this
unconstrained setting, the problem of testing nonnegativity of a
polynomial @xmath is NP-hard even when its degree equals four. This is
an immediate corollary of the fact that checking if a symmetric matrix
@xmath is copositive—i.e., if @xmath ---is NP-hard. ¹ ¹ 1 Weak
NP-hardness of testing matrix copositivity is originally proven by Murty
and Kabadi [ 143 ] ; its strong NP-hardness is apparent from the work of
de Klerk and Pasechnik [ 55 ] . Indeed, @xmath is copositive if and only
if the homogeneous quartic polynomial @xmath is nonnegative.

Despite this computational complexity barrier, there has been great
success in using sum of squares (SOS) programming [ 153 ] , [ 109 ] , [
145 ] to obtain certificates of nonnegativity of polynomials in
practical settings. It is known from Artin’s solution [ 18 ] to
Hilbert’s 17th problem that a polynomial @xmath is nonnegative if and
only if

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

for some polynomials @xmath . When @xmath is a quadratic polynomial,
then the polynomials @xmath are not needed and the polynomials @xmath
can be assumed to be linear functions. In this case, by writing @xmath
as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an @xmath symmetric matrix, checking nonnegativity of
@xmath reduces to checking the nonnegativity of the eigenvalues of
@xmath ; i.e., checking if @xmath is positive semidefinite.

More generally, if the degrees of @xmath and @xmath are fixed in ( 2.1
), then checking for a representation of @xmath of the form in ( 2.1 )
reduces to solving an SDP, whose size depends on the dimension of @xmath
, and the degrees of @xmath and @xmath [ 153 ] . This insight has led to
significant progress in certifying nonnegativity of polynomials arising
in many areas. In practice, the “first level” of the SOS hierarchy is
often the one used, where the polynomials @xmath are left out and one
simply checks if @xmath is a sum of squares of other polynomials. In
this case already, because of the numerical difficulty of solving large
SDPs, the polynomials that can be certified to be nonnegative usually do
not have very high degrees or very many variables. For example, finding
a sum of squares certificate that a given quartic polynomial over @xmath
variables is nonnegative requires solving an SDP involving roughly
@xmath constraints and a positive semidefinite matrix variable of size
@xmath . Even for a handful of or a dozen variables, the underlying
semidefinite constraints prove to be expensive. Indeed, in the absence
of additional structure, most examples in the literature have less than
10 variables.

Recently other systematic approaches to certifying nonnegativity of
polynomials have been proposed which lead to less expensive optimization
problems than semidefinite programming problems. In particular, Ahmadi
and Majumdar [ 9 ] , [ 7 ] introduce “DSOS and SDSOS” optimization
techniques, which replace semidefinite programs arising in the
nonnegativity certification problem by linear programs and second-order
cone programs. Instead of optimizing over the cone of sum of squares
polynomials, the authors optimize over two subsets which they call
“diagonally dominant sum of squares” and “scaled diagonally dominant sum
of squares” polynomials (see Section 3.2.1 for formal definitions). In
the language of semidefinite programming, this translates to solving
optimization problems over the cone of diagonally dominant matrices and
scaled diagonally dominant matrices. These can be done by LP and SOCP
respectively. The authors have had notable success with these techniques
in different applications. For instance, they are able to run these
relaxations for polynomial optimization problems of degree 4 in 70
variables in the order of a few minutes. They have also used their
techniques to push the size limits of some SOS problems in controls;
examples include stabilizing a model of a humanoid robot with 30 state
variables and 14 control inputs [ 132 ] , or exploring the real-time
applications of SOS techniques in problems such as collision-free
autonomous motion planning [ 8 ] .

Motivated by these results, our goal in this chapter is to start with
DSOS and SDSOS techniques and improve on them. By exploiting ideas from
column generation in large-scale linear programming, and by
appropriately interpreting the DSOS and SDSOS constraints, we produce
several iterative LP and SOCP-based algorithms that improve the quality
of the bounds obtained from the DSOS and SDSOS relaxations.
Geometrically, this amounts to optimizing over structured subsets of sum
of squares polynomials that are larger than the sets of diagonally
dominant or scaled diagonally dominant sum of squares polynomials. For
semidefinite programming, this is equivalent to optimizing over
structured subsets of the cone of positive semidefinite matrices. An
important distinction to make between the DSOS/SDSOS/SOS approaches and
our approach, is that our approximations iteratively get larger in the
direction of the given objective function, unlike the DSOS, SDSOS, and
SOS approaches which all try to inner approximate the set of nonnegative
polynomials irrespective of any particular direction.

In related literature, Krishnan and Mitchell use linear programming
techniques to approximately solve SDPs by taking a semi-infinite LP
representation of the SDP and applying column generation [ 105 ] . In
addition, Kim and Kojima solve second order cone relaxations of SDPs
which are closely related to the dual of an SDSOS program in the case of
quadratic programming [ 104 ] ; see Section 2.3 for further discussion
of these two papers.

The organization of the rest of the chapter is as follows. In the next
section, we review relevant notation, and discuss the prior literature
on DSOS and SDSOS programming. In Section 2.3 , we give a high-level
overview of our column generation approaches in the context of a general
SDP. In Section 2.4 , we describe an application of our ideas to
nonconvex polynomial optimization and present computational experiments
with certain column generation implementations. In Section 2.5 , we
apply our column generation approach to approximate a copositive program
arising from a specific discrete optimization application (namely the
stable set problem). All the work in these sections can be viewed as
providing techniques to optimize over subsets of positive semidefinite
matrices. We then conclude in Section 2.6 with some future directions,
and discuss ideas for column generation which allow one to go beyond
subsets of positive semidefinite matrices in the case of polynomial and
copositive optimization.

#### 2.2 Preliminaries

Let us first introduce some notation on matrices. We denote the set of
real symmetric @xmath matrices by @xmath . Given two matrices @xmath and
@xmath in @xmath , we denote their matrix inner product by @xmath . The
set of symmetric matrices with nonnegative entries is denoted by @xmath
. A symmetric matrix @xmath is positive semidefinite (psd) if @xmath for
all @xmath ; this will be denoted by the standard notation @xmath , and
our notation for the set of @xmath psd matrices is @xmath . A matrix
@xmath is copositive if @xmath for all @xmath . The set of copositive
matrices is denoted by @xmath . All three sets @xmath are convex cones
and we have the obvious inclusion @xmath . This inclusion is strict if
@xmath [ 38 ] , [ 37 ] . For a cone @xmath of matrices in @xmath , we
define its dual cone @xmath as @xmath .

For a vector variable @xmath and a vector @xmath , let a monomial in
@xmath be denoted as @xmath , and let its degree be @xmath . A
polynomial is said to be homogeneous or a form if all of its monomials
have the same degree. A form @xmath in @xmath variables is nonnegative
if @xmath for all @xmath , or equivalently for all @xmath on the unit
sphere in @xmath . The set of nonnegative (or positive semidefinite)
forms in @xmath variables and degree @xmath is denoted by @xmath . A
form @xmath is a sum of squares (sos) if it can be written as @xmath for
some forms @xmath . The set of sos forms in @xmath variables and degree
@xmath is a cone denoted by @xmath . We have the obvious inclusion
@xmath , which is strict unless @xmath , or @xmath , or @xmath [ 92 ] .
Let @xmath be the vector of all monomials of degree exactly @xmath ; it
is well known that a form @xmath of degree @xmath is sos if and only if
it can be written as @xmath , for some psd matrix @xmath [ 153 ] , [ 152
] . The size of the matrix @xmath , which is often called the Gram
matrix , is @xmath . At the price of imposing a semidefinite constraint
of this size, one obtains the very useful ability to search and optimize
over the convex cone of sos forms via semidefinite programming.

##### 2.2.1 DSOS and SDSOS optimization

In order to alleviate the problem of scalability posed by the SDPs
arising from sum of squares programs, Ahmadi and Majumdar [ 9 ] , [ 7 ]
² ² 2 The work in [ 9 ] is currently in preparation for submission; the
one in [ 7 ] is a shorter conference version of [ 9 ] which has already
appeared. The presentation of the current chapter is meant to be
self-contained. recently introduced similar-purpose LP and SOCP-based
optimization problems that they refer to as DSOS and SDSOS programs .
Since we will be building on these concepts, we briefly review their
relevant aspects to make our chapter self-contained.

The idea in [ 9 ] , [ 7 ] is to replace the condition that the Gram
matrix @xmath be positive semidefinite with stronger but cheaper
conditions in the hope of obtaining more efficient inner approximations
to the cone @xmath . Two such conditions come from the concepts of
diagonally dominant and scaled diagonally dominant matrices in linear
algebra. We recall these definitions below.

###### Definition 2.2.1.

A symmetric matrix @xmath is diagonally dominant (dd) if @xmath for all
@xmath . We say that @xmath is scaled diagonally dominant (sdd) if there
exists a diagonal matrix @xmath , with positive diagonal entries, such
that @xmath is diagonally dominant.

We refer to the set of @xmath dd (resp. sdd) matrices as @xmath (resp.
@xmath ). The following inclusions are a consequence of Gershgorin’s
circle theorem:

  -- -------- --
     @xmath   
  -- -------- --

We now use these matrices to introduce the cones of “dsos” and “sdsos”
forms and some of their generalizations, which all constitute special
subsets of the cone of nonnegative forms. We remark that in the interest
of brevity, we do not give the original definitions of dsos and sdsos
polynomials as they appear in [ 9 ] (as sos polynomials of a particular
structure), but rather an equivalent characterization of them that is
more useful for our purposes. The equivalence is proven in [ 9 ] .

###### Definition 2.2.2 ([9, 7]).

Recall that @xmath denotes the vector of all monomials of degree exactly
@xmath . A form @xmath of degree @xmath is said to be

1.  diagonally-dominant-sum-of-squares (dsos) if it admits a
    representation as
    @xmath , where @xmath is a dd matrix,

2.  scaled-diagonally-dominant-sum-of-squares (sdsos) if it admits a
    representation as
    @xmath , where @xmath is an sdd matrix,

3.  @xmath -diagonally-dominant-sum-of-squares ( @xmath -dsos) if there
    exists a positive integer @xmath such that
    @xmath is dsos,

4.  @xmath -scaled diagonally-dominant-sum-of-squares ( @xmath -sdsos)
    if there exists a positive integer @xmath such that
    @xmath is sdsos.

We denote the cone of forms in @xmath variables and degree @xmath that
are dsos, sdsos, @xmath -dsos, and @xmath -sdsos by @xmath , @xmath ,
@xmath , and @xmath respectively. The following inclusion relations are
straightforward:

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

The multiplier @xmath should be thought of as a special denominator in
the Artin-type representation in ( 2.1 ). By appealing to some theorems
of real algebraic geometry, it is shown in [ 9 ] that under some
conditions, as the power @xmath increases, the sets @xmath (and hence
@xmath ) fill up the entire cone @xmath We will mostly be concerned with
the cones @xmath and @xmath , which correspond to the case where @xmath
. From the point of view of optimization, our interest in all of these
algebraic notions stems from the following theorem.

###### Theorem 2.2.3 ([9, 7]).

For any integer @xmath , the cone @xmath is polyhedral and the cone
@xmath has a second order cone representation. Moreover, for any fixed
@xmath and @xmath , one can optimize a linear function over @xmath
(resp. @xmath ) by solving a linear program (resp. second order cone
program) of size polynomial in @xmath .

The “LP part” of this theorem is not hard to see. The equality @xmath
gives rise to linear equality constraints between the coefficients of
@xmath and the entries of the matrix @xmath (whose size is polynomial in
@xmath for fixed @xmath and @xmath ). The requirement of diagonal
dominance on the matrix @xmath can also be described by linear
inequality constraints on @xmath . The “SOCP part” of the statement
comes from the fact, shown in [ 9 ] , that a matrix @xmath is sdd if and
only if it can be expressed as

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath is an @xmath symmetric matrix with zeros everywhere
except for four entries @xmath , which must make the @xmath matrix
@xmath symmetric and positive semidefinite. These constraints are
rotated quadratic cone constraints and can be imposed using SOCP [ 15 ]
, [ 124 ] :

  -- -------- --
     @xmath   
  -- -------- --

We refer to optimization problems with a linear objective posed over the
convex cones @xmath , @xmath , and @xmath as DSOS programs, SDSOS
programs, and SOS programs respectively. In general, quality of
approximation decreases, while scalability increases, as we go from SOS
to SDSOS to DSOS programs. Depending on the size of the application at
hand, one may choose one approach over the other.
In related work, Ben-Tal and Nemirovski [ 26 ] and Vielma, Ahmed and
Nemhauser [ 194 ] approximate SOCPs by LPs and produce approximation
guarantees.

#### 2.3 Column generation for inner approximation of positive
semidefinite cones

In this section, we describe a natural approach to apply techniques from
the theory of column generation [ 23 ] , [ 58 ] in large-scale
optimization to the problem of optimizing over nonnegative polynomials.
Here is the rough idea: We can think of all SOS/SDSOS/DSOS approaches as
ways of proving that a polynomial is nonnegative by writing it as a
nonnegative linear combination of certain “atom” polynomials that are
already known to be nonnegative. For SOS, these atoms are all the
squares (there are infinitely many). For DSOS, there is actually a
finite number of atoms corresponding to the extreme rays of the cone of
diagonally dominant matrices (see Theorem 2.3.1 below). For SDSOS, once
again we have infinitely many atoms, but with a specific structure which
is amenable to an SOCP representation. Now the column generation idea is
to start with a certain “cheap” subset of atoms (columns) and only add
new ones—one or a limited number in each iteration—if they improve our
desired objective function. This results in a sequence of monotonically
improving bounds; we stop the column generation procedure when we are
happy with the quality of the bound, or when we have consumed a
predetermined budget on time.

In the LP case, after the addition of one or a few new atoms, one can
obtain the new optimal solution from the previous solution in much less
time than required to solve the new problem from scratch. However, as we
show with some examples in this chapter, even if one were to resolve the
problems from scratch after each iteration (as we do for all of our
SOCPs and some of our LPs), the overall procedure is still relatively
fast. This is because in each iteration, with the introduction of a
constant number @xmath of new atoms, the problem size essentially
increases only by @xmath new variables and/or @xmath new constraints.
This is in contrast to other types of hierarchies—such as the rDSOS and
rSDSOS hierarchies of Definition 3.2.2 —that blow up in size by a factor
that depends on the dimension in each iteration.

In the next two subsections we make this general idea more precise.
While our focus in this section is on column generation for general
SDPs, the next two sections show how the techniques are useful for
approximation of SOS programs for polynomial optimization (Section 2.4
), and copositive programs for discrete optimization (Section 2.5 ).

##### 2.3.1 LP-based column generation

Consider a general SDP

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.2)
                       @xmath   
  -- -------- -------- -------- -------

with @xmath as input, and its dual

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.3)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Our goal is to inner approximate the feasible set of ( 2.2 ) by
increasingly larger polyhedral sets. We consider LPs of the form

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.4)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Here, the matrices @xmath are some fixed set of positive semidefinite
matrices (our psd “atoms”). To expand our inner approximation, we will
continually add to this list of matrices. This is done by considering
the dual LP

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.5)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

which in fact gives a polyhedral outer approximation (i.e., relaxation)
of the spectrahedral feasible set of the SDP in ( 2.3 ). If the optimal
solution @xmath of the LP in ( 2.5 ) is already psd, then we are done
and have found the optimal value of our SDP. If not, we can use the
violation of positive semidefiniteness to extract one (or more) new psd
atoms @xmath . Adding such atoms to ( 2.4 ) is called column generation
, and the problem of finding such atoms is called the pricing subproblem
. (On the other hand, if one starts off with an LP of the form ( 2.5 )
as an approximation of ( 2.3 ), then the approach of adding inequalities
to the LP iteratively that are violated by the current solution is
called a cutting plane approach, and the associated problem of finding
violated constraints is called the separation subproblem .) The simplest
idea for pricing is to look at the eigenvectors @xmath of @xmath that
correspond to negative eigenvalues. From each of them, one can generate
a rank-one psd atom @xmath , which can be added with a new variable
(“column”) @xmath to the primal LP in ( 2.4 ), and as a new constraint
(“cut”) to the dual LP in ( 2.5 ). The subproblem can then be defined as
getting the most negative eigenvector, which is equivalent to minimizing
the quadratic form @xmath over the unit sphere @xmath . Other possible
strategies are discussed later in the chapter.

This LP-based column generation idea is rather straightforward, but what
does it have to do with DSOS optimization? The connection comes from the
extreme-ray description of the cone of diagonally dominant matrices,
which allows us to interpret a DSOS program as a particular and
effective way of obtaining @xmath initial psd atoms.

Let @xmath denote the set of vectors in @xmath which have at most @xmath
nonzero components, each equal to @xmath , and define @xmath to be the
set of matrices

  -- -------- --
     @xmath   
  -- -------- --

For a finite set of matrices @xmath , let

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 2.3.1 (Barker and Carlson [22]).

@xmath

This theorem tells us that @xmath has exactly @xmath extreme rays. It
also leads to a convenient representation of the dual cone:

  -- -------- --
     @xmath   
  -- -------- --

Throughout the chapter, we will be initializing our LPs with the DSOS
bound; i.e., our initial set of psd atoms @xmath will be the @xmath
rank-one matrices @xmath in @xmath . This is because this bound is often
cheap and effective. Moreover, it guarantees feasibility of our initial
LPs (see Theorems 2.4.1 and 2.5.1 ), which is important for starting
column generation. One also readily sees that the DSOS bound can be
improved if we were to instead optimize over the cone @xmath , which has
@xmath atoms. However, in settings that we are interested in, we cannot
afford to include all these atoms; instead, we will have pricing
subproblems that try to pick a useful subset (see Section 2.4 ).

We remark that an LP-based column generation idea similar to the one in
this section is described in [ 105 ] , where it is used as a subroutine
for solving the maxcut problem. The method is comparable to ours
inasmuch as some columns are generated using the eigenvalue pricing
subproblem. However, contrary to us, additional columns specific to max
cut are also added to the primal. The initialization step is also
differently done, as the matrices @xmath in ( 2.4 ) are initially taken
to be in @xmath and not in @xmath . (This is equivalent to requiring the
matrix @xmath to be diagonal instead of diagonally dominant in ( 2.4 ).)

Another related work is [ 179 ] . In this chapter, the initial LP
relaxation is obtained via RLT (Reformulation-Linearization Techniques)
as opposed to our diagonally dominant relaxation. The cuts are then
generated by taking vectors which violate positive semidefiniteness of
the optimal solution as in ( 2.5 ). The separation subproblem that is
solved though is different than the ones discussed here and relies on an
@xmath decomposition of the solution matrix.

##### 2.3.2 SOCP-based column generation

In a similar vein, we present an SOCP-based column generation algorithm
that in our experience often does much better than the LP-based
approach. The idea is once again to optimize over structured subsets of
the positive semidefinite cone that are SOCP representable and that are
larger than the set @xmath of scaled diagonally dominant matrices. This
will be achieved by working with the following SOCP

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.6)
                                
                       @xmath   
  -- -------- -------- -------- -------

Here, the positive semidefiniteness constraints on the @xmath matrices
can be imposed via rotated quadratic cone constraints as explained in
Section 3.2.1 . The @xmath matrices @xmath are fixed for all @xmath .
Note that this is a direct generalization of the LP in ( 2.4 ), in the
case where the atoms @xmath are rank-one. To generate a new SOCP atom,
we work with the dual of ( 2.6 ):

  -- -------- -------- -------- -------
     @xmath   @xmath            (2.7)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Once again, if the optimal solution @xmath is psd, we have solved our
SDP exactly; if not, we can use @xmath to produce new SOCP-based cuts.
For example, by placing the two eigenvectors of @xmath corresponding to
its two most negative eigenvalues as the columns of an @xmath matrix
@xmath , we have produced a new useful atom. (Of course, we can also
choose to add more pairs of eigenvectors and add multiple atoms.) As in
the LP case, by construction, our bound can only improve in every
iteration.

We will always be initializing our SOCP iterations with the SDSOS bound.
It is not hard to see that this corresponds to the case where we have
@xmath initial @xmath atoms @xmath , which have zeros everywhere, except
for a 1 in the first column in position @xmath and a 1 in the second
column in position @xmath . We denote the set of all such @xmath
matrices by @xmath .

The first step of our procedure is carried out already in [ 104 ] for
approximating solutions to QCQPs. Furthermore, the work in [ 104 ] shows
that for a particular class of QCQPs, its SDP relaxation and its SOCP
relaxation (written respectively in the form of ( 2.3 ) and ( 2.7 )) are
exact.

Figure 2.1 shows an example of both the LP and SOCP column generation
procedures. We produced two @xmath random symmetric matrices @xmath and
@xmath . The outer most set is the feasible set of an SDP with the
constraint @xmath (Here, @xmath is the @xmath identity matrix.) The SDP
wishes to maximize @xmath over this set. The innermost set in Figure
2.1(a) is the polyhedral set where @xmath is dd. The innermost set in
Figure 2.1(b) is the SOCP-representable set where @xmath is sdd. In both
cases, we do 5 iterations of column generation that expand these sets by
introducing one new atom at a time. These atoms come from the most
negative eigenvector (resp. the two most negative eigenvectors) of the
dual optimal solution as explained above. Note that in both cases, we
are growing our approximation of the positive semidefinite cone in the
direction that we care about (the northeast). This is in contrast to
algebraic hierarchies based on “positive multipliers” (see the rDSOS and
rSDSOS hierarchies in Definition 3.2.2 for example), which completely
ignore the objective function.

#### 2.4 Nonconvex polynomial optimization

In this section, we apply the ideas described in the previous section to
sum of squares algorithms for nonconvex polynomial optimization. In
particular, we consider the NP-hard problem of minimizing a form (of
degree @xmath ) on the sphere. Recall that @xmath is the vector of all
monomials in @xmath variables with degree @xmath . Let @xmath be a form
with @xmath variables and even degree @xmath , and let @xmath be the
vector of its coefficients with the monomial ordering given by @xmath .
Thus @xmath can be viewed as @xmath . Let @xmath . With this notation,
the problem of minimizing a form @xmath on the unit sphere can be
written as

  -- -- -------- -------- -------- -------
        @xmath   @xmath            (2.8)
                          @xmath   
  -- -- -------- -------- -------- -------

With the SOS programming approach, the following SDP is solved to get
the largest scalar @xmath and an SOS certificate proving that @xmath is
nonnegative:

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

The sum of squares certificate is directly read from an eigenvalue
decomposition of the solution @xmath to the SDP above and has the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Since all sos polynomials are nonnegative, the optimal
value of the SDP in ( 2.4 ) is a lower bound to the optimal value of the
optimization problem in ( 2.8 ). Unfortunately, before solving the SDP,
we do not have access to the vectors @xmath in the decomposition of the
optimal matrix @xmath . However, the fact that such vectors exist hints
at how we should go about replacing @xmath by a polyhedral restriction
in ( 2.4 ): If the constraint @xmath is changed to

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

where @xmath is a finite set, then ( 2.4 ) becomes an LP. This is one
interpretation of Ahmadi and Majumdar’s work in [ 9 , 7 ] where they
replace @xmath by @xmath . Indeed, this is equivalent to taking @xmath
in ( 2.10 ), as shown in Theorem 2.3.1 . We are interested in extending
their results by replacing @xmath by larger restrictions than @xmath . A
natural candidate for example would be obtained by changing @xmath to
@xmath . However, although @xmath is finite, it contains a very large
set of vectors even for small values of @xmath and @xmath . For
instance, when @xmath and @xmath , @xmath has over 66 million elements.
Therefore we use column generation ideas to iteratively expand @xmath in
a manageable fashion. To initialize our procedure, we would like to
start with good enough atoms to have a feasible LP. The following result
guarantees that replacing @xmath with @xmath always yields an initial
feasible LP in the setting that we are interested in.

###### Theorem 2.4.1.

For any form @xmath of degree @xmath , there exists @xmath such that
@xmath is dsos.

###### Proof.

As before, let @xmath . We observe that the form @xmath is strictly in
the interior of @xmath . Indeed, by expanding out the expression we see
that we can write @xmath as @xmath , where @xmath is a diagonal matrix
with all diagonal entries positive. So @xmath is in the interior of
@xmath , and hence @xmath is in the interior of @xmath . This implies
that for @xmath small enough, the form

  -- -------- --
     @xmath   
  -- -------- --

will be dsos. Since @xmath is a cone, the form

  -- -------- --
     @xmath   
  -- -------- --

will also be dsos. By taking @xmath to be smaller than or equal to
@xmath , the claim is established. ∎

As @xmath , the theorem above implies that replacing @xmath with @xmath
also yields an initial feasible SOCP. Motivated in part by this theorem,
we will always start our LP-based iterative process with the restriction
that @xmath . Let us now explain how we improve on this approximation
via column generation.

Suppose we have a set @xmath of vectors in @xmath , whose outerproducts
form all of the rank-one psd atoms that we want to consider. This set
could be finite but very large, or even infinite. For our purposes
@xmath always includes @xmath , as we initialize our algorithm with the
dsos relaxation. Let us consider first the case where @xmath is finite:
@xmath Then the problem that we are interested in solving is

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

Suppose @xmath has @xmath monomials and let the @xmath th monomial in
@xmath have coefficient @xmath , i.e., @xmath . Also let @xmath be the
@xmath th entry in @xmath . We rewrite the previous problem as

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

where @xmath is a matrix that collects entries of @xmath that contribute
to the @xmath monomial in @xmath , when @xmath is expanded out. The
above is equivalent to

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

The dual problem is

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

In the column generation framework, suppose we consider only a subset of
the primal LP variables corresponding to the matrices @xmath for some
@xmath (call this the reduced primal problem). Let @xmath stand for an
optimal solution of the reduced primal problem and let @xmath stand for
an optimal dual solution. If we have

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

then @xmath is an optimal dual solution for the original larger primal
problem with columns @xmath . In other words, if we simply set @xmath ,
then the solution of the reduced primal problem becomes a solution of
the original primal problem. On the other hand, if ( 2.12 ) is not true,
then suppose the condition is violated for some @xmath . We can augment
the reduced primal problem by adding the variable @xmath , and repeat
this process.

Let @xmath . We can test if ( 2.12 ) is false by solving the pricing
subproblem :

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

If @xmath , then there is an element @xmath in @xmath such that the
matrix @xmath violates the dual constraint written in ( 2.12 ). Problem
( 2.13 ) may or may not be easy to solve depending on the set @xmath For
example, an ambitious column generation strategy to improve on dsos
(i.e., @xmath ), would be to take @xmath ; i.e., the set all vectors in
@xmath consisting of zeros, ones, and minus ones. In this case, the
pricing problem ( 2.13 ) becomes

  -- -------- --
     @xmath   
  -- -------- --

Unfortunately, the above problem generalizes the quadratic unconstrained
boolean optimization problem (QUBO) and is NP-hard. Nevertheless, there
are good heuristics for this problem (see e.g., [ 34 ] , [ 52 ] ) that
can be used to find near optimal solutions very fast. While we did not
pursue this pricing subproblem, we did consider optimizing over @xmath .
We refer to the vectors in @xmath as “triples” for obvious reasons and
generally refer to the process of adding atoms drawn from @xmath as
optimizing over “triples”.

Even though one can theoretically solve ( 2.13 ) with @xmath in
polynomial time by simple enumeration of @xmath elements, this is very
impractical. Our simple implementation is a partial enumeration and is
implemented as follows. We iterate through the triples (in a fixed
order), and test to see whether the condition @xmath is violated by a
given triple @xmath , and collect such violating triples in a list. We
terminate the iteration when we collect a fixed number of violating
triples (say @xmath ). We then sort the violating triples by increasing
values of @xmath (remember, these values are all negative for the
violating triples) and select the @xmath most violated triples (or fewer
if less than @xmath are violated overall) and add them to our current
set of atoms. In a subsequent iteration we start off enumerating triples
right after the last triple enumerated in the current iteration so that
we do not repeatedly scan only the same subset of triples. Although our
implementation is somewhat straightforward and can be obviously
improved, we are able to demonstrate that optimizing over triples
improves over the best bounds obtained by Ahmadi and Majumdar in a
similar amount of time (see Section 2.4.2 ).

We can also have pricing subproblems where the set @xmath is infinite.
Consider e.g. the case @xmath in ( 2.13 ). In this case, if there is a
feasible solution with a negative objective value, then the problem is
clearly unbounded below. Hence, we look for a solution with the smallest
value of “violation” of the dual constraint divided by the norm of the
violating matrix. In other words, we want the expression @xmath to be as
small as possible, where is the Euclidean norm of the vector consisting
of all entries of @xmath . This is the same as minimizing @xmath . The
eigenvector corresponding to the smallest eigenvalue yields such a
minimizing solution. This is the motivation behind the strategy
described in the previous section for our LP column generation scheme.
In this case, we can use a similar strategy for our SOCP column
generation scheme. We replace @xmath by @xmath in ( 2.4 ) and
iteratively expand @xmath by using the “two most negative eigenvector
technique” described in Section 2.3.2 .

##### 2.4.1 Experiments with a 10-variable quartic

We illustrate the behaviour of these different strategies on an example.
Let @xmath be a degree-four form defined on 10 variables, where the
components of @xmath are drawn independently at random from the normal
distribution @xmath . Thus @xmath and @xmath , and the form @xmath is
‘fully dense’ in the sense that @xmath has essentially all nonzero
components. In Figure 2.2 , we show how the lower bound on the optimal
value of @xmath over the unit sphere changes per iteration for different
methods. The @xmath -axis shows the number of iterations of the column
generation algorithm, i.e., the number of times columns are added and
the LP (or SOCP) is resolved. The @xmath -axis shows the lower bound
obtained from each LP or SOCP. Each curve represents one way of adding
columns. The three horizontal lines (from top to bottom) represent,
respectively, the SDP bound, the 1SDSOS bound and the 1DSOS bound. The
curve DSOS @xmath gives the bound obtained by solving LPs, where the
first LP has @xmath and subsequent columns are generated from a single
eigenvector corresponding to the most negative eigenvalue of the dual
optimal solution as described in Section 2.3.1 . The LP triples curve
also corresponds to an LP sequence, but this time the columns that are
added are taken from @xmath and are more than one in each iteration (see
the next subsection). This bound saturates when constraints coming from
all elements of @xmath are satisfied. Finally, the curve SDSOS @xmath
gives the bound obtained by SOCP-based column generation as explained
just above.

##### 2.4.2 Larger computational experiments

In this section, we consider larger problem instances ranging from 15
variables to 40 variables: these instances are again fully dense and
generated in exactly the same way as the @xmath example of the previous
subsection. However, contrary to the previous subsection, we only apply
our “triples” column generation strategy here. This is because the
eigenvector-based column generation strategy is too computationally
expensive for these problems as we discuss below.

To solve the triples pricing subproblem with our partial enumeration
strategy, we set @xmath to 300,000 and @xmath to 5000. Thus in each
iteration, we find up to 300,000 violated triples, and add up to 5000 of
them. In other words, we augment our LP by up to 5000 columns in each
iteration. This is somewhat unusual as in practice at most a few dozen
columns are added in each iteration. The logic for this is that primal
simplex is very fast in reoptimizing an LP when a small number of
additional columns are added to an LP whose optimal basis is known.
However, in our context, we observed that the associated LPs are very
hard for the simplex routines inside our LP solver (CPLEX 12.4) and take
much more time than CPLEX’s interior point solver. We therefore use
CPLEX’s interior point (“barrier”) solver not only for the initial LP
but for subsequent LPs after adding columns. Because interior point
solvers do not benefit significantly from warm starts, each LP takes a
similar amount of time to solve as the initial LP, and therefore it
makes sense to add a large number of columns in each iteration to
amortize the time for each expensive solve over many columns.

Table 2.1 is taken from the work of Ahmadi and Majumdar [ 9 ] , where
they report lower bounds on the minimum value of fourth-degree forms on
the unit sphere obtained using different methods, and the respective
computing times (in seconds).

In Table 2.2 , we give our bounds for the same problem instances. We
report two bounds, obtained at two different times (if applicable). In
the first case ( rows labeled R1), the time taken by 1SDSOS in Table 2.1
is taken as a limit, and we report the bound from the last column
generation iteration occuring before this time limit; the 1SDSOS bound
is the best non-SDP bound reported in the experiments of Ahmadi and
Majumdar. In the rows labeled as R2, we take 600 seconds as a limit and
report the last bound obtained before this limit. In a couple of
instances ( @xmath and @xmath ), our column generation algorithm
terminates before the 600 second limit, and we report the termination
time in this case.

We observe that in the same amount of time (and even on a slightly
slower machine), we are able to consistently beat the 1SDSOS bound,
which is the strongest non-SDP bound produced in [ 9 ] . We also
experimented with the eigenvalue pricing subproblem in the LP case, with
a time limit of 600 seconds. For @xmath , we obtain a bound of @xmath
after adding only @xmath columns in 600 seconds. For @xmath , we are
only able to add 6 columns and the lower bound obtained is @xmath . Note
that this bound is worse than the triples bound given in Table 2.2 . The
main reason for being able to add so few columns in the time limit is
that each column is almost fully dense (the LPs for n=25 have 20,475
rows, and 123,410 rows for @xmath ). Thus, the LPs obtained are very
hard to solve after a few iterations and become harder with increasing
@xmath . As a consequence, we did not experiment with the eigenvalue
pricing subproblem in the SOCP case as it is likely to be even more
computationally intensive.

#### 2.5 Inner approximations of copositive programs and the maximum
stable set problem

Semidefinite programming has been used extensively for approximation of
NP-hard combinatorial optimization problems. One such example is finding
the stability number of a graph. A stable set (or independent set) of a
graph @xmath is a set of nodes of @xmath , no two of which are adjacent.
The size of the largest stable set of a graph @xmath is called the
stability number (or independent set number) of @xmath and is denoted by
@xmath Throughout, @xmath is taken to be an undirected, unweighted graph
on @xmath nodes. It is known that the problem of testing if @xmath is
greater than a given integer @xmath is NP-hard [ 102 ] . Furthermore,
the stability number cannot be approximated to a factor of @xmath for
any @xmath unless P @xmath NP [ 86 ] . The natural integer programming
formulation of this problem is given by

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.14)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Although this optimization problem is intractable, there are several
computationally-tractable relaxations that provide upper bounds on the
stability number of a graph. For example, the obvious LP relaxation of (
2.14 ) can be obtained by relaxing the constraint @xmath to @xmath :

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.15)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

This bound can be improved upon by adding the so-called clique
inequalities to the LP, which are of the form @xmath when nodes @xmath
form a clique in @xmath . Let @xmath be the set of all @xmath -clique
inequalities in @xmath . This leads to a hierarchy of LP relaxations:

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.16)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Notice that for @xmath this simply corresponds to ( 2.15 ), in other
words, @xmath .

In addition to LPs, there are also semidefinite programming (SDP)
relaxations that provide upper bounds to the stability number. The most
well-known is perhaps the Lovász theta number @xmath [ 128 ] , which is
defined as the optimal value of the following SDP:

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.17)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Here @xmath is the all-ones matrix and @xmath is the identity matrix of
size @xmath . The Lovász theta number is known to always give at least
as good of an upper bound as the LP in ( 2.15 ), even with the addition
of clique inequalities of all sizes (there are exponentially many); see,
e.g., [ 116 , Section 6.5.2] for a proof. In other words,

  -- -------- --
     @xmath   
  -- -------- --

An alternative SDP relaxation for stable set is due to de Klerk and
Pasechnik. In [ 55 ] , they show that the stability number can be
obtained through a conic linear program over the set of copositive
matrices. Namely,

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.18)
                       @xmath   
  -- -------- -------- -------- --------

where @xmath is the adjacency matrix of @xmath . Replacing @xmath by the
restriction @xmath , one obtains the aforementioned relaxation through
the following SDP

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.19)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

This latter SDP is more expensive to solve than the Lovász SDP ( 2.17 ),
but the bound that it obtains is always at least as good (and sometimes
strictly better). A proof of this statement is given in [ 55 , Lemma
5.2] , where it is shown that ( 2.19 ) is an equivalent formulation of
an SDP of Schrijver [ 174 ] , which produces stronger upper bounds than
( 2.17 ).

Another reason for the interest in the copositive approach is that it
allows for well-known SDP and LP hierarchies—developed respectively by
Parrilo [ 152 , Section 5] and de Klerk and Pasechnik [ 55 ] —that
produce a sequence of improving bounds on the stability number. In fact,
by appealing to Positivstellensatz results of Pólya [ 158 ] , and Powers
and Reznick [ 160 ] , de Klerk and Pasechnik show that their LP
hierarchy produces the exact stability number in @xmath number of steps
[ 55 , Theorem 4.1] . This immediately implies the same result for
stronger hierarchies, such as the SDP hierarchy of Parrilo [ 152 ] , or
the rDSOS and rSDSOS hierarchies of Ahmadi and Majumdar [ 9 ] .

One notable difficulty with the use of copositivity-based SDP
relaxations such as ( 2.19 ) in applications is scalibility. For
example, it takes more than 5 hours to solve ( 2.19 ) when the input is
a randomly generated Erdós-Renyi graph with 300 nodes and edge
probability @xmath . ³ ³ 3 The solver in this case is MOSEK [ 140 ] and
the machine used has 3.4GHz speed and 16GB RAM; see Table 2.4 for more
results. The solution time with the popular SDP solver SeDuMi [ 182 ]
e.g. would be several times larger. Hence, instead of using ( 2.19 ), we
will solve a sequence of LPs/SOCPs generated in an iterative fashion.
These easier optimization problems will provide upper bounds on the
stability number in a more reasonable amount of time, though they will
be weaker than the ones obtained via ( 2.19 ).

We will derive both our LP and SOCP sequences from formulation ( 2.18 )
of the stability number. To obtain the first LP in the sequence, we
replace @xmath by @xmath (instead of replacing @xmath by @xmath as was
done in ( 2.19 )) and get

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.20)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

This is an LP whose optimal value is a valid upper bound on the
stability number as @xmath .

###### Theorem 2.5.1.

The LP in ( 2.20 ) is always feasible.

###### Proof.

We need to show that for any @xmath adjacency matrix @xmath , there
exists a diagonally dominant matrix @xmath , a nonnegative matrix @xmath
, and a scalar @xmath such that

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

Notice first that @xmath is a matrix with @xmath on the diagonal and at
entry @xmath , if @xmath is an edge in the graph, and with @xmath at
entry @xmath if @xmath is not an edge in the graph. If we denote by
@xmath the degree of node @xmath , then let us take @xmath and @xmath a
matrix with diagonal entries @xmath and off-diagonal entries equal to
@xmath if there is an edge, and @xmath if not. This matrix is diagonally
dominant as there are at most @xmath minus ones on each row.
Furthermore, if we take @xmath to be a matrix with @xmath at the entries
@xmath where @xmath is an edge in the graph, then ( 2.21 ) is satisfied
and @xmath . ∎

Feasibility of this LP is important for us as it allows us to initiate
column generation. By contrast, if we were to replace the diagonal
dominance constraint by a diagonal constraint for example, the LP could
fail to be feasible. This fact has been observed by de Klerk and
Pasechnik in [ 55 ] and Bomze and de Klerk in [ 32 ] .

To generate the next LP in the sequence via column generation, we think
of the extreme-ray description of the set of diagonally dominant
matrices as explained in Section 2.3 . Theorem 2.3.1 tells us that these
are given by the matrices in @xmath and so we can rewrite ( 2.20 ) as

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.22)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

The column generation procedure aims to add new matrix atoms to the
existing set @xmath in such a way that the current bound @xmath
improves. There are numerous ways of choosing these atoms. We focus
first on the cutting plane approach based on eigenvectors. The dual of (
2.22 ) is the LP

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.23)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

If our optimal solution @xmath to ( 2.23 ) is positive semidefinite,
then we are obtaining the best bound we can possibly produce, which is
the SDP bound of ( 2.19 ). If this is not the case however, we pick our
atom matrix to be the outer product @xmath of the eigenvector @xmath
corresponding to the most negative eigenvalue of @xmath . The optimal
value of the LP

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.24)
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

that we derive is guaranteed to be no worse than @xmath as the feasible
set of ( 2.24 ) is smaller than the feasible set of ( 2.23 ). Under mild
nondegeneracy assumptions (satisfied, e.g., by uniqueness of the optimal
solution to ( 2.23 )), the new bound will be strictly better. By
reiterating the same process, we create a sequence of LPs whose optimal
values @xmath are a nonincreasing sequence of upper bounds on the
stability number.

Generating the sequence of SOCPs is done in an analogous way. Instead of
replacing the constraint @xmath in ( 2.19 ) by @xmath , we replace it by
@xmath and get

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.25)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Once again, we need to reformulate the problem in such a way that the
set of scaled diagonally dominant matrices is described as some
combination of psd “atom” matrices. In this case, we can write any
matrix @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are variables making the @xmath matrix psd, and the @xmath
’s are our atoms. Recall from Section 2.3 that the set @xmath consists
of all @xmath matrices which have zeros everywhere, except for a 1 in
the first column in position @xmath and a 1 in the second column in
position @xmath . This gives rise to an equivalent formulation of ( 2.25
):

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.26)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Just like the LP case, we now want to generate one (or more) @xmath
matrix @xmath to add to the set @xmath so that the bound @xmath
improves. We do this again by using a cutting plane approach originating
from the dual of ( 2.26 ):

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.27)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Note that strong duality holds between this primal-dual pair as it is
easy to check that both problems are strictly feasible. We then take our
new atom to be

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are two eigenvectors corresponding to the two
most negative eigenvalues of @xmath , the optimal solution of ( 2.27 ).
If @xmath only has one negative eigenvalue, we add a linear constraint
to our problem; if @xmath , then the bound obtained is identical to the
one obtained through SDP ( 2.19 ) and we cannot hope to improve. Our
next iterate is therefore

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.28)
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Note that the optimization problems generated iteratively in this
fashion always remain SOCPs and their optimal values form a
nonincreasing sequence of upper bounds on the stability number.

To illustrate the column generation method for both LPs and SOCPs, we
consider the complement of the Petersen graph as shown in Figure 2.3(a)
as an example. The stability number of this graph is 2 and one of its
maximum stable sets is designated by the two white nodes. In Figure
2.3(b) , we compare the upper bound obtained via ( 2.19 ) and the bounds
obtained using the iterative LPs and SOCPs as described in ( 2.24 ) and
( 2.28 ).

Note that it takes 3 iterations for the SOCP sequence to produce an
upper bound strictly within one unit of the actual stable set number
(which would immediately tell us the value of @xmath ), whereas it takes
13 iterations for the LP sequence to do the same. It is also interesting
to compare the sequence of LPs/SOCPs obtained through column generation
to the sequence that one could obtain using the concept of @xmath -dsos/
@xmath -sdsos polynomials. Indeed, LP ( 2.20 ) (resp. SOCP ( 2.25 )) can
be written in polynomial form as

  -- -------- -------- -------- --------
     @xmath   @xmath            (2.29)
                       @xmath   
  -- -------- -------- -------- --------

Iteration @xmath in the sequence of LPs/SOCPs would then correspond to
requiring that this polynomial be @xmath -dsos or @xmath -sdsos. For
this particular example, we give the 1-dsos, 2-dsos, 1-sdsos and 2-sdsos
bounds in Table 2.3 .

Though this sequence of LPs/SOCPs gives strong upper bounds, each
iteration is more expensive than the iterations done in the column
generation approach. Indeed, in each of the column generation
iterations, only one constraint is added to our problem, whereas in the
rDSOS/rSDSOS hierarchies, the number of constraints is roughly
multiplied by @xmath at each iteration.

Finally, we investigate how these techniques perform on graphs with a
large number of nodes, where the SDP bound cannot be found in a
reasonable amount of time. The graphs we test these techniques on are
Erdös-Rényi graphs @xmath ; i.e. graphs on @xmath nodes where an edge is
added between each pair of nodes independently and with probability
@xmath . In our case, we take @xmath to be between @xmath and @xmath ,
and @xmath to be either @xmath or @xmath so as to experiment with both
medium and high density graphs. ⁴ ⁴ 4 All instances used for these tests
are available online at http://aaa.princeton.edu/software .

In Table 2.4 , we present the results of the iterative SOCP procedure
and contrast them with the SDP bounds. The third column of the table
contains the SOCP upper bound obtained through ( 2.27 ); the solver time
needed to obtain this bound is given in the fourth column. The fifth and
sixth columns correspond respectively to the SOCP iterative bounds
obtained after 5 mins solving time and 10 mins solving time. Finally,
the last two columns chart the SDP bound obtained from ( 2.19 ) and the
time in seconds needed to solve the SDP. All SOCP and SDP experiments
were done using Matlab, the solver MOSEK [ 140 ] , the SPOTLESS toolbox
[ 137 ] , and a computer with 3.4 GHz speed and 16 GB RAM.

From the table, we note that it is better to run the SDP rather than the
SOCPs for small @xmath , as the bounds obtained are better and the times
taken to do so are comparable. However, as @xmath gets bigger, the SOCPs
become valuable as they provide good upper bounds in reasonable amounts
of time. For example, for @xmath and @xmath , the SOCP obtains a bound
that is only twice as big as the SDP bound, but it does so 30 times
faster. The sparser graphs don’t do as well, a trend that we will also
observe in Table 2.5 . Finally, notice that the improvement in the first
5 mins is significantly better than the improvement in the last 5 mins.
This is partly due to the fact that the SOCPs generated at the beginning
are sparser, and hence faster to solve.

In Table 2.5 , we present the results of the iterative LP procedure used
on the same instances. All LP results were obtained using a computer
with 2.3 GHz speed and 32GB RAM and the solver CPLEX 12.4 [ 47 ] . The
third and fourth columns in the table contain the LP bound obtained with
( 2.23 ) and the solver time taken to do so. Columns 5 and 6 correspond
to the LP iterative bounds obtained after 5 mins solving time and 10
mins solving time using the eigenvector-based column generation
technique (see discussion around ( 2.24 )). The seventh and eighth
columns are the standard LP bounds obtained using ( 2.16 ) and the time
taken to obtain the bound. Finally, the last column gives bounds
obtained by column generation using “triples”, as described in Section
2.4.2 . In this case, we take @xmath and @xmath .

We note that in this case the upper bound with triples via column
generation does better for this range of @xmath than eigenvector-based
column generation in the same amount of time. Furthermore, the iterative
LP scheme seems to perform better in the dense regime. In particular,
the first iteration does significantly better than the standard LP for
@xmath , even though both LPs are of similar size. This would remain
true even if the 3-clique inequalities were added as in ( 2.16 ), since
the optimal value of @xmath is always at least @xmath . This is because
the vector @xmath is feasible to the LP in ( 2.16 ) with @xmath . Note
that this LP would have order @xmath constraints, which is more
expensive than our LP. On the contrary, for sparse regimes, the standard
LP, which hardly takes any time to solve, gives better bounds than ours.

Overall, the high-level conclusion is that running the SDP is worthwhile
for small sizes of the graph. As the number of nodes increases, column
generation becomes valuable, providing upper bounds in a reasonable
amount of time. Contrasting Tables 2.4 and 2.5 , our initial experiments
seem to show that the iterative SOCP bounds are better than the ones
obtained using the iterative LPs. It may be valuable to experiment with
different approaches to column generation however, as the technique used
to generate the new atoms seems to impact the bounds obtained.

#### 2.6 Conclusions and future research

For many problems of discrete and polynomial optimization, there are
hierarchies of SDP-based sum of squares algorithms that produce provably
optimal bounds in the limit [ 153 ] , [ 109 ] . However, these
hierarchies can often be expensive computationally. In this chapter, we
were interested in problem sizes where even the first level of the
hierarchy is too expensive, and hence we resorted to algorithms that
replace the underlying SDPs with LPs or SOCPs. We built on the recent
work of Ahmadi and Majumdar on DSOS and SDSOS optimization [ 9 ] , [ 7 ]
, which serves exactly this purpose. We showed that by using ideas from
linear programming column generation, the performance of their
algorithms is improvable. We did this by iteratively optimizing over
increasingly larger structured subsets of the cone of positive
semidefinite matrices, without resorting to the more expensive rDSOS and
rSDSOS hierarchies.

There is certainly a lot of room to improve our column generation
algorithms. In particular, we only experimented with a few types of
pricing subproblems and particular strategies for solving them. The
success of column generation often comes from good “engineering”, which
fine-tunes the algorithms to the problem at hand. Developing warm-start
strategies for our iterative SOCPs for example, would be a very useful
problem to work on in the future.

Here is another interesting research direction, which for illustrative
purposes we outline for the problem studied in Section 2.4 ; i.e.,
minimizing a form on the sphere. Recall that given a form @xmath of
degree @xmath , we are trying to find the largest @xmath such that
@xmath is a sum of squares. Instead of solving this sum of squares
program, we looked for the largest @xmath for which we could write
@xmath as a conic combination of a certain set of nonnegative
polynomials. These polynomials for us were always either a single square
or a sum of squares of polynomials. There are polynomials, however, that
are nonnegative but not representable as a sum of squares. Two classic
examples [ 141 ] , [ 44 ] are the Motzkin polynomial

  -- -------- --
     @xmath   
  -- -------- --

and the Choi-Lam polynomial

  -- -------- --
     @xmath   
  -- -------- --

Either of these polynomials can be shown to be nonnegative using the
arithmetic mean-geometric mean (am-gm) inequality, which states that if
@xmath , then

  -- -------- --
     @xmath   
  -- -------- --

For example, in the case of the Motzkin polynomial, it is clear that the
monomials @xmath and @xmath are nonnegative for all @xmath , and letting
@xmath stand for these monomials respectively, the am-gm inequality
implies that

  -- -------- --
     @xmath   
  -- -------- --

These polynomials are known to be extreme in the cone of nonnegative
polynomials and they cannot be written as a sum of squares (sos) [ 165 ]
.

It would be interesting to study the separation problems associated with
using such non-sos polynomials in column generation. We briefly present
one separation algorithm for a family of polynomials whose nonnegativity
is provable through the am-gm inequality and includes the Motzkin and
Choi-Lam polynomials. This will be a relatively easy-to-solve integer
program in itself, whose goal is to find a polynomial @xmath amongst
this family which is to be added as our new “nonnegative atom”.

The family of @xmath -variate polynomials under consideration consists
of polynomials with only @xmath nonzero coefficients, with @xmath of
them equal to one, and one equal to @xmath . (Notice that the Motzkin
and the Choi-Lam polynomials are of this form with @xmath equal to three
and four respectively.) Let @xmath be the number of monomials in @xmath
. Given a dual vector @xmath of ( 2.4 ) of dimension @xmath , one can
check if there exists a nonnegative degree @xmath polynomial @xmath in
our family such that @xmath This can be done by solving the following
integer program (we assume that @xmath ):

  -- -------- -- -------- -- --------
     @xmath      @xmath      (2.30)
                 @xmath      
                 @xmath      
                 @xmath      
                 @xmath      
  -- -------- -- -------- -- --------

Here, we have @xmath and the variables @xmath form the coefficients of
the polynomial @xmath . The above integer program has @xmath variables,
but only @xmath constraints (not counting the integer constraints). If a
polynomial @xmath with a negative objective value is found, then one can
add it as a new atom for column generation. In our specific randomly
generated polynomial optimization examples, such polynomials did not
seem to help in our preliminary experiments. Nevertheless, it would be
interesting to consider other instances and problem structures.

Similarly, in the column generation approach to obtaining inner
approximations of the copositive cone, one need not stick to positive
semidefinite matrices. It is known that the @xmath “Horn matrix” [ 38 ]
for example is extreme in the copositive cone but cannot be written as
the sum of a nonnegative and a positive semidefinite matrix. One could
define a separation problem for a family of Horn-like matrices and add
them in a column generation approach. Exploring such strategies is left
for future research.

### Chapter 3 Sum of Squares Basis Pursuit with Linear and Second Order
Cone Programming

#### 3.1 Introduction

In recent years, semidefinite programming [ 192 ] and sum of squares
optimization [ 153 , 109 , 145 ] have proven to be powerful techniques
for tackling a diverse set of problems in applied and computational
mathematics. The reason for this, at a high level, is that several
fundamental problems arising in discrete and polynomial optimization [
115 , 80 , 8 ] or the theory of dynamical systems [ 152 , 90 , 1 ] can
be cast as linear optimization problems over the cone of nonnegative
polynomials. This observation puts forward the need for efficient
conditions on the coefficients @xmath of a multivariate polynomial

  -- -------- --
     @xmath   
  -- -------- --

that ensure the inequality @xmath for all @xmath . If @xmath is a
quadratic function, @xmath then nonnegativity of @xmath is equivalent to
the @xmath symmetric matrix

  -- -------- --
     @xmath   
  -- -------- --

being positive semidefinite and this constraint can be imposed by
semidefinite programming. For higher degrees, however, imposing
nonnegativity of polynomials is in general an intractable computational
task. In fact, even checking if a given quartic polynomial is
nonnegative is NP-hard [ 59 ] . A particularly popular and seemingly
powerful sufficient condition for a polynomial @xmath to be nonnegative
is for it to decompose as a sum of squares of other polynomials:

  -- -------- --
     @xmath   
  -- -------- --

This condition is attractive for several reasons. From a computational
perspective, for fixed-degree polynomials, a sum of squares
decomposition can be checked (or imposed as a constraint) by solving a
semidefinite program of size polynomial in the number of variables. From
a representational perspective, such a decomposition certifies
nonnegativity of @xmath in terms of an easily verifiable algebraic
identity. From a practical perspective, the so-called “sum of squares
relaxation” is well-known to produce powerful (often exact) bounds on
optimization problems that involve nonnegative polynomials; see, e.g., [
155 ] . The reason for this is that constructing examples of nonnegative
polynomials that are not sums of squares in relatively low dimensions
and degrees seems to be a difficult task ¹ ¹ 1 See [ 165 ] for explicit
examples of nonnegative polynomials that are not sums of squares. ,
especially when additional structure arising from applications is
required.

We have recently been interested in leveraging the attractive features
of semidefinite programs (SDPs) and sum of squares (SOS) programs, while
solving much simpler classes of convex optimization problems, namely
linear programs (LPs) and second order cone programs (SOCPs). Such a
research direction can potentially lead to a better understanding of the
relative power of different classes of convex relaxations. It also has
obvious practical motivations as simpler convex programs come with
algorithms that have better scalability and improved numerical
conditioning properties. This chapter is a step in this research
direction. We present a scheme for solving a sequence of LPs or SOCPs
that provide increasingly accurate approximations to the optimal value
and the optimal solution of a semidefinite (or a sum of squares)
program. With the algorithms that we propose, one can use one of many
mature LP/SOCP solvers such as [ 47 , 79 , 140 ] , including
simplex-based LP solvers, to obtain reasonable approximations to the
optimal values of these more difficult convex optimization problems.

The intuition behind our approach is easy to describe with a contrived
example. Suppose we would like to show that the degree-4 polynomial

  -- -------- --
     @xmath   
  -- -------- --

has a sum of squares decomposition. One way to do this is to attempt to
write @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

is the standard (homogeneous) monomial basis of degree 2 and the matrix
@xmath , often called the Gram matrix , is symmetric and positive
semidefinite. The search for such a @xmath can be done with semidefinite
programming; one feasible solution e.g. is as follows:

  -- -------- --
     @xmath   
  -- -------- --

Suppose now that instead of the basis @xmath in ( 3.1 ), we pick a
different basis

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

With this new basis, we can get a sum of squares decomposition of @xmath
by writing it as

  -- -------- --
     @xmath   
  -- -------- --

In effect, by using a better basis, we have simplified the Gram matrix
and made it diagonal. When the Gram matrix is diagonal, its positive
semidefiniteness can be imposed as a linear constraint (diagonals should
be nonnegative).

Of course, the catch here is that we do not have access to the magic
basis @xmath in ( 3.2 ) a priori. Our goal will hence be to “pursue”
this basis (or other good bases) by starting with an arbitrary basis
(typically the standard monomial basis), and then iteratively improving
it by solving a sequence of LPs or SOCPs and performing some efficient
matrix decomposition tasks in the process. Unlike the intentionally
simplified example we gave above, we will not ever require our Gram
matrices to be diagonal. This requirement is too strong and would
frequently lead to our LPs and SOCPs being infeasible. The underlying
reason for this is that the cone of diagonal matrices is not full
dimensional in the cone of positive semidefinite matrices. Instead, we
will be after bases that allow the Gram matrix to be diagonally dominant
or scaled diagonally dominant (see Definition 5.3.1 ). The use of these
matrices in polynomial optimization has recently been proposed by Ahmadi
and Majumdar [ 9 , 7 ] . We will be building on and improving upon their
results in this chapter.

##### 3.1.1 Organization of this chapter

The organization of the rest of the chapter is as follows. In Section
3.2 , we introduce some notation and briefly review the concepts of
“dsos and sdsos polynomials” which are used later as the first step of
an iterative algorithm that we propose in Section 3.3 . In this section,
we explain how we inner approximate semidefinite (Subsection 3.3.1 ) and
sum of squares (Subsection 3.3.2 ) cones with LP and SOCP-based cones by
iteratively changing bases. In Subsection 3.3.3 , we give a different
interpretation of our LPs in terms of their corner description as
opposed to their facet description. Subsection 3.3.4 is about duality,
which is useful for iteratively outer approximating semidefinite or sum
of squares cones.

In Section 3.4 , we apply our algorithms to the Lovász semidefinite
relaxation of the maximum stable set problem. It is shown numerically
that our LPs and SOCPs converge to the SDP optimal value in very few
iterations and outperform some other well-known LP relaxations on a
family of randomly generated examples. In Section 3.5 , we consider the
partition problem from discrete optimization. As opposed to the stable
set problem, the quality of our relaxations here is rather poor. In
fact, even the sum of squares relaxation fails on some completely
trivial instances. We show this empirically on random instances, and
formally prove it on one representative example (Subsection 3.5.1 ). The
reason for this failure is existence of a certain family of quartic
polynomials that are nonnegative but not sums of squares.

#### 3.2 Preliminaries

We denote the set of real symmetric @xmath matrices by @xmath . Given
two matrices @xmath and @xmath in @xmath , their standard matrix inner
product is denoted by @xmath . A symmetric matrix @xmath is positive
semidefinite (psd) if @xmath for all @xmath ; this will be denoted by
the standard notation @xmath , and our notation for the set of @xmath
psd matrices is @xmath . We say that @xmath is positive definite (pd) if
@xmath for all @xmath . Any psd matrix @xmath has an upper triangular
Cholesky factor @xmath satisfying @xmath . When @xmath is pd, the
Cholesky factor is unique and has positive diagonal entries. For a cone
of matrices in @xmath , we define its dual cone @xmath as @xmath .

For a vector variable @xmath and a vector @xmath , let a monomial in
@xmath be denoted as @xmath which by definition has degree @xmath . A
polynomial is said to be homogeneous or a form if all of its monomials
have the same degree. A form @xmath in @xmath variables is nonnegative
if @xmath for all @xmath , or equivalently for all @xmath on the unit
sphere in @xmath . The set of nonnegative (or positive semidefinite)
forms in @xmath variables and degree @xmath is denoted by @xmath . A
form @xmath is a sum of squares (sos) if it can be written as @xmath for
some forms @xmath . The set of sos forms in @xmath variables and degree
@xmath is denoted by @xmath . We have the obvious inclusion @xmath ,
which is strict unless @xmath , or @xmath , or @xmath [ 92 ] . Let
@xmath be the vector of all monomials of degree exactly @xmath ; it is
well known that a form @xmath of degree @xmath is sos if and only if it
can be written as @xmath , for some psd matrix @xmath [ 153 , 152 ] . An
SOS optimization problem is the problem of minimizing a linear function
over the intersection of the convex cone @xmath with an affine subspace.
The previous statement implies that SOS optimization problems can be
cast as semidefinite programs.

##### 3.2.1 DSOS and SDSOS optimization

In recent work, Ahmadi and Majumdar introduce more scalable alternatives
to SOS optimization that they refer to as DSOS and SDSOS programs [ 9 ,
7 ] ² ² 2 The work in [ 9 ] is currently in preparation for submission;
the one in [ 7 ] is a shorter conference version of [ 9 ] which has
already appeared. The presentation of the current chapter is meant to be
self-contained. . Instead of semidefinite programming, these
optimization problems can be cast as linear and second order cone
programs respectively. Since we will be building on these concepts, we
briefly review their relevant aspects to make our chapter
self-contained.

The idea in [ 9 , 7 ] is to replace the condition that the Gram matrix
@xmath be positive semidefinite with stronger but cheaper conditions in
the hope of obtaining more efficient inner approximations to the cone
@xmath . Two such conditions come from the concepts of diagonally
dominant and scaled diagonally dominant matrices in linear algebra. We
recall these definitions below.

###### Definition 3.2.1.

A symmetric matrix @xmath is diagonally dominant (dd) if @xmath for all
@xmath . We say that @xmath is scaled diagonally dominant (sdd) if there
exists a diagonal matrix @xmath , with positive diagonal entries, which
makes @xmath diagonally dominant.

We refer to the set of @xmath dd (resp. sdd) matrices as @xmath (resp.
@xmath ). The following inclusions are a consequence of Gershgorin’s
circle theorem [ 73 ] :

  -- -------- --
     @xmath   
  -- -------- --

Whenever it is clear from the context, we may drop the subscript @xmath
from our notation. We now use these matrices to introduce the cones of
“dsos” and “sdsos” forms which constitute special subsets of the cone of
sos forms. We remark that in the interest of brevity, we do not give the
original definition of dsos and sdsos polynomials as it appears in [ 9 ]
(as sos polynomials of a particular structure), but rather an equivalent
characterization of them that is more useful for our purposes. The
equivalence is proven in [ 9 ] .

###### Definition 3.2.2 ([9, 7]).

Recall that @xmath denotes the vector of all monomials of degree exactly
@xmath . A form @xmath of degree @xmath is said to be

-   diagonally-dominant-sum-of-squares (dsos) if it admits a
    representation as @xmath , where @xmath is a dd matrix.

-   scaled-diagonally-dominant-sum-of-squares (sdsos) if it admits a
    representation as @xmath , where @xmath is an sdd matrix.

The definitions for non-homogeneous polynomials are exactly the same,
except that we replace the vector of monomials of degree exactly @xmath
with the vector of monomials of degree @xmath . We observe that a
quadratic form @xmath is dsos/sdsos/sos if and only if the matrix @xmath
is dd/sdd/psd. Let us denote the cone of forms in @xmath variables and
degree @xmath that are dsos and sdsos by @xmath , @xmath . The following
inclusion relations are straightforward:

  -- -------- --
     @xmath   
  -- -------- --

From the point of view of optimization, our interest in all of these
algebraic notions stems from the following theorem.

###### Theorem 3.2.3 ([9, 7]).

For any fixed @xmath , optimization over the cones @xmath (resp. @xmath
) can be done with linear programming (resp. second order cone
programming) of size polynomial in @xmath .

The “LP part” of this theorem is not hard to see. The equality @xmath
gives rise to linear equality constraints between the coefficients of
@xmath and the entries of the matrix @xmath (whose size is @xmath and
hence polynomial in @xmath for fixed @xmath ). The requirement of
diagonal dominance on the matrix @xmath can also be described by linear
inequality constraints on @xmath . The “SOCP part” of the statement
comes from the fact, shown in [ 9 ] , that a matrix @xmath is sdd if and
only if it can be expressed as

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

where each @xmath is an @xmath symmetric matrix with zeros everywhere
except for four entries @xmath , which must make the @xmath matrix
@xmath symmetric and positive semidefinite. These constraints are
rotated quadratic cone constraints and can be imposed using SOCP [ 15 ,
124 ] :

  -- -------- --
     @xmath   
  -- -------- --

We refer to linear optimization problems over the convex cones @xmath ,
@xmath , and @xmath as DSOS programs, SDSOS programs, and SOS programs
respectively. In general, quality of approximation decreases, while
scalability increases, as we go from SOS to SDSOS to DSOS programs. What
we present next can be thought of as an iterative procedure for moving
from DSOS/SDSOS relaxations towards SOS relaxations without increasing
the problem size in each step.

#### 3.3 Pursuing improved bases

Throughout this section, we consider the standard SDP

  -- -------- -------- -------- -------
     @xmath   @xmath            (3.4)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

which we assume to have an optimal solution. We denote the optimal value
by @xmath since we think of a semidefinite program as a sum of squares
program over quadratic forms (recall that @xmath ). This is so we do not
have to introduce additional notation to distinguish between degree-2
and higher degree SOS programs. The main goal of this section is to
construct sequences of LPs and SOCPs that generate bounds on the optimal
value of ( 3.4 ). Section 3.3.1 focuses on providing upper bounds on (
3.4 ) while Section 3.3.4 focuses on lower bounds.

##### 3.3.1 Inner approximations of the psd cone

To obtain upper bounds on ( 3.4 ), we need to replace the constraint
@xmath by a stronger condition. In other words, we need to provide inner
approximations to the set of psd matrices.

First, let us define a family of cones

  -- -------- --
     @xmath   
  -- -------- --

parametrized by an @xmath matrix @xmath . Optimizing over the set @xmath
is an LP since @xmath is fixed, and the defining constraints are linear
in the coefficients of the two unknowns @xmath and @xmath . Furthermore,
the matrices in @xmath are all psd; i.e., @xmath @xmath .

The iteration number @xmath in the sequence of our LPs consists of
replacing the condition @xmath by @xmath :

  -- -------- -------- -------- -------
     @xmath   @xmath            (3.5)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

To define the sequence @xmath , we assume that an optimal solution
@xmath to ( 3.5 ) exists for every iteration. As it will become clear
shortly, this assumption will be implied simply by assuming that only
the first LP in the sequence is feasible. The sequence @xmath is then
given recursively by

  -- -------- -------- -------- -------
     @xmath   @xmath            (3.6)
              @xmath   @xmath   
  -- -------- -------- -------- -------

Note that the first LP in the sequence optimizes over the set of
diagonally dominant matrices as in the work of Ahmadi and Majumdar [ 9 ,
7 ] . By defining @xmath as a Cholesky factor of @xmath , improvement of
the optimal value is guaranteed in each iteration. Indeed, as @xmath ,
and the identity matrix @xmath is diagonally dominant, we see that
@xmath and hence is feasible for iteration @xmath . This entails that
the optimal value at iteration @xmath is at least as good as the optimal
value at the previous iteration; i.e., @xmath . Since the sequence
@xmath is lower bounded by @xmath and monotonic, it must converge to a
limit @xmath . We have been unable to formally rule out the possibility
that @xmath . In all of our numerical experiments, convergence to @xmath
happens (i.e., @xmath ), though the speed of convergence seems to be
problem dependent (contrast e.g. the results of Section 3.4 with Section
3.5 ). What is easy to show, however, is that if @xmath is positive
definite ³ ³ 3 This would be the case whenever our inner approximation
is not touching the boundary of the psd cone in the direction of the
objective. As far as numerical computation is concerned, this is of
course always the case. , then the improvement from step @xmath to
@xmath is actually strict .

###### Theorem 3.3.1.

Let @xmath (resp. @xmath ) be an optimal solution of iterate @xmath
(resp. @xmath ) of ( 3.5 ) and assume that @xmath is pd and @xmath .
Then,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We show that for some @xmath , the matrix @xmath is feasible to the LP
in iteration number @xmath . We would then have that

  -- -------- --
     @xmath   
  -- -------- --

as we have assumed that @xmath To show feasibility of @xmath to LP
number @xmath , note first that as both @xmath and @xmath satisfy the
affine constraints @xmath , then @xmath must also. Since @xmath and
@xmath is pd, @xmath must have positive diagonal entries and is
invertible. Let

  -- -------- --
     @xmath   
  -- -------- --

For @xmath small enough the matrix @xmath will be dd since we know the
identity matrix is strictly diagonally dominant. Hence, the matrix

  -- -------- --
     @xmath   
  -- -------- --

is feasible to LP number @xmath . ∎

A few remarks are in order. First, instead of the Cholesky
decomposition, we could have worked with some other decompositions such
as the LDL decomposition @xmath or the spectral decomposition @xmath
(where @xmath has the eigenvectors of @xmath as columns). Aside from the
efficiency of the Cholesky decomposition, the reason we made this choice
is that the decomposition allows us to write @xmath as @xmath and the
identity matrix @xmath is at the analytic center of the set of
diagonally dominant matrices [ 35 , Section 8.5.3] . Second, the reader
should see that feasibility of the first LP implies that all future LPs
are feasible and lower bounded. While in most applications that we know
of the first LP is automatically feasible (see, e.g., the stable set
problem in Section 3.4 ), sometimes the problem needs to be modified to
make this the case. An example where this happens appears in Section 3.5
(see Theorem 3.5.4 ), where we apply an SOS relaxation to the partition
problem.

Alternatively, one can first apply our iterative procedure to a Phase-I
problem

  -- -------- -------- -------- -------
     @xmath   @xmath            (3.7)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

with @xmath defined as in ( 3.6 ). Indeed, for @xmath large enough, the
initial problem in ( 3.7 ) (i.e., with @xmath ) is feasible. Thus all
subsequent iterations are feasible and continually decrease @xmath . If
for some iteration @xmath we get @xmath then we can start the original
LP sequence ( 3.5 ) with the matrix @xmath obtained from the last
iteration of the Phase-I algorithm.

In an analogous fashion, we can construct a sequence of SOCPs that
provide upper bounds on @xmath . This time, we define a family of cones

  -- -------- --
     @xmath   
  -- -------- --

parameterized again by an @xmath matrix @xmath . For any @xmath ,
optimizing over the set @xmath is an SOCP and we have @xmath . This
leads us to the following iterative SOCP sequence:

  -- -------- -------- -------- -------
     @xmath   @xmath            (3.8)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Assuming existence of an optimal solution @xmath at each iteration, we
can once again define the sequence @xmath iteratively as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The previous statements concerning strict improvement of the LP sequence
as described in Theorem 3.3.1 , as well as its convergence carry through
for the SOCP sequence. In our experience, our SOCP bounds converge to
the SDP optimal value often faster than our LP bounds do. While it is
always true that @xmath (as @xmath ), the inequality can occasionally
reverse in future iterations.

An illustration of both procedures is given in Figure 3.1 . We generated
two random symmetric matrices @xmath and @xmath of size @xmath . The
outermost set is the feasible set of an SDP with the constraint @xmath .
The goal is to maximize the function @xmath over this set. The set
labeled @xmath in Figure 3.1(a) (resp. @xmath in Figure 3.1(b) )
consists of the points @xmath for which @xmath is dd (resp. sdd). Let (
@xmath ) (resp. ( @xmath )) be optimal solutions to the problem of
maximizing @xmath over these sets. The set labeled @xmath in Figure
3.1(a) (resp. @xmath in Figure 3.1(b) ) consists of the points @xmath
for which @xmath (resp. @xmath )) where @xmath (resp. @xmath )
corresponds to the Cholesky decomposition of @xmath (resp. @xmath ).
Notice the interesting phenomenon that while the new sets happen to
shrink in volume, they expand in the direction that we care about.
Already in one iteration, the SOCP gives the perfect bound here.

In Figure 3.2(a) , instead of showing the improvement in just the
North-East direction, we show it in all directions. This is done by
discretizing a large set of directions @xmath on the unit circle and
optimizing along them. More concretely, for each @xmath , we maximize
@xmath over the set @xmath . We extract an optimal solution every time
and construct a matrix @xmath from its Cholesky decomposition. We then
maximize in the same direction once again but this time over the set
@xmath . The set of all new optimal solutions is what is plotted with
the thick blue line in the figure. We proceed in exactly the same way
with our SOCPs to produce Figure 3.2(b) . Notice that both inner
approximations after one iteration improve substantially. The SOCP in
particular fills up almost the entire spectrahedron.

##### 3.3.2 Inner approximations to the cone of nonnegative polynomials

A problem domain where inner approximations to semidefinite programs can
be useful is in sum of squares programming. This is because the goal of
SOS optimization is already to inner approximate the cone of nonnegative
polynomials. So by further inner approximating the SOS cone, we will get
bounds in the same direction as the SOS bounds.

Let @xmath be the vector of monomials of degree up to @xmath . Define a
family of cones of degree- @xmath polynomials

  -- -------- --
     @xmath   
  -- -------- --

parameterized by an @xmath matrix @xmath . We can think of this set as
the cone of polynomials that are dsos in the basis @xmath . If an SOS
program has a constraint “ @xmath sos”, we will replace it iteratively
by the constraint @xmath . The sequence of matrices @xmath is again
defined recursively with

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath is an optimal Gram matrix of iteration @xmath .

Likewise, let

  -- -------- --
     @xmath   
  -- -------- --

This set can also be viewed as the set of polynomials that are sdsos in
the basis @xmath . To construct a sequence of SOCPs that generate
improving bounds on the sos optimal value, we replace the constraint
@xmath sos by @xmath , where @xmath is defined as above.

In Figure 3.3 , we consider a parametric family of polynomials

  -- -------- --
     @xmath   
  -- -------- --

The outermost set in both figures corresponds to the set of pairs @xmath
for which @xmath is sos. As @xmath is a bivariate quartic, this set
coincides with the set of @xmath for which @xmath is nonnegative. The
innermost sets in the two subfigures correspond to @xmath for which
@xmath is dsos (resp. sdsos). The thick blue lines illustrate the
optimal points achieved when maximizing in all directions over the sets
obtained from a single Cholesky decomposition. (The details of the
procedure are exactly the same as Figure 3.2 .) Once again, the inner
approximations after one iteration improve substantially over the DSOS
and SDSOS approximations.

##### 3.3.3 Extreme-ray interpretation of the change of basis

In this section, we present an alternative but equivalent way of
expressing the LP and SOCP-based sequences. This characterization is
based on the extreme-ray description of the cone of diagonally
dominant/scaled diagonally dominant matrices. It will be particularly
useful when we consider outer approximations of the psd cone in Section
3.3.4 .

###### Lemma 3.3.2 (Barker and Carlson [22]).

A symmetric matrix @xmath is diagonally dominant if and only if it can
be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the set of all nonzero vectors in @xmath with at most
@xmath nonzero components, each equal to @xmath .

The vectors @xmath are the extreme rays of the @xmath cone. This
characterization of the set of diagonally dominant matrices leads to a
convenient description of the dual cone:

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

which we will find to be useful in the next subsection. Using Lemma
3.3.2 , we can rewrite the sequence of LPs given in ( 3.5 ) as

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.10)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Let @xmath be an optimal solution to the LP in iteration @xmath . The
sequence of matrices @xmath is defined just as before:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

In the first iteration, a linear map is sending (or intuitively
“rotating”) the extreme rays @xmath of the dd cone to a new set of
extreme rays @xmath . This procedure keeps repeating itself without ever
changing the number of extreme rays.

As the sequence of LPs defined in ( 3.10 ) is equivalent to the sequence
defined in ( 3.5 ), the optimal value of ( 3.10 ) improves in each
iteration. This can be seen directly: Indeed, @xmath is feasible for
iteration @xmath of ( 3.10 ) by taking @xmath when @xmath has exactly
one nonzero entry equal to @xmath and @xmath otherwise. This
automatically implies that @xmath Moreover, the improvement is strict
under the assumptions of Theorem 3.3.1 .

The set of scaled diagonally dominant matrices can be described in a
similar fashion. In fact, from ( 3.3 ), we know that any scaled
diagonally dominant matrix @xmath can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an @xmath matrix whose columns each contain exactly one
nonzero element which is equal to @xmath and @xmath is a @xmath
symmetric psd matrix.

This characterization of @xmath gives an immediate description of the
dual cone

  -- -------- --
     @xmath   
  -- -------- --

which will become useful later. Our SOCP sequence in explicit form is
then

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.11)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

If @xmath is an optimal solution at step @xmath , the matrix sequence
@xmath is defined as before:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The interpretation of ( 3.11 ) is similar to that of ( 3.10 ).

##### 3.3.4 Outer approximations of the psd cone

In Section 3.3.1 , we considered inner approximations of the psd cone to
obtain upper bounds on ( 3.4 ). In many applications, semidefinite
programming is used as a “relaxation” to provide outer approximations to
some nonconvex sets. This approach is commonly used for relaxing
quadratic programs; see, e.g., Section 3.4 , where we consider the
problem of finding the largest stable set of a graph. In such scenarios,
it does not make sense for us to inner approximate the psd cone: to have
a valid relaxation, we need to outer approximate it. This can be easily
achieved by working with the dual problems, which we will derive
explicitly in this section.

Since @xmath , the first iteration in our LP sequence for outer
approximation will be

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

By the description of the dual cone in ( 3.9 ), we know this can be
equivalently written as

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.12)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

where the @xmath ’s are the extreme rays of the set of diagonally
dominant matrices as described in Section 3.3.3 ; namely, all vectors
with at most two nonzero elements which are either @xmath or @xmath .
Recall that when we were after inner approximations (Subsection 3.3.1 ),
the next LP in our sequence was generated by replacing the vectors
@xmath by @xmath , where the choice of @xmath was dictated by a Cholesky
decomposition of an optimal solution of the previous iterate. In the
outer approximation setting, we seemingly do not have access to a psd
matrix that would provide us with a Cholesky decomposition. However, we
can simply get this from the dual of ( 3.12 )

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

by taking @xmath . We then replace @xmath by @xmath in ( 3.12 ) to get
the next iterate and proceed. In general, the sequence of LPs can be
written as

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath is a sequence of matrices defined recursively as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The vector @xmath here is an optimal solution to the dual problem at
step @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

This algorithm again strictly improves the objective value at each
iteration. Indeed, from LP strong duality, we have

  -- -------- --
     @xmath   
  -- -------- --

and Theorem 3.3.1 applied to the dual problem states that

  -- -------- --
     @xmath   
  -- -------- --

The sequence of SOCPs for outer approximation can be constructed in an
analogous manner:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath ’s are @xmath matrices containing exactly one 1 in each
column, and @xmath is a sequence of matrices defined as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Here again, the vector @xmath is an optimal solution to the dual SOCP at
step @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where each @xmath is a @xmath unknown symmetric matrix.

###### Remark 3.3.3.

Let us end with some concluding remarks about our algorithm. There are
other ways of improving the DSOS and SDSOS bounds. For example, Ahmadi
and Majumdar [ 9 , 132 ] propose the requirement that @xmath be dsos or
sdsos as a sufficient condition for nonnegativity of @xmath . As @xmath
increases, the quality of approximation improves, although the problem
size also increases very quickly. Such hierarchies are actually commonly
used in the sum of squares optimization literature. But unlike our
approach, they do not take into account a particular objective function
and may improve the inner approximation to the PSD cone in directions
that we do not care about. Nevertheless, these hierarchies have
interesting theoretical implications. Under some assumptions, one can
prove that as @xmath , the underlying convex programs succeed in
optimizing over the entire set of nonnegative polynomials; see, e.g., [
164 , 57 , 152 , 9 ] .

Another approach to improve on the DSOS and SDSOS bounds appears in
Chapter LABEL:chap:bp . We show there how ideas from column generation
in large-scale integer and linear programming can be used to iteratively
improve inner approximations to semidefinite cones. The LPs and SOCPs
proposed in that work take the objective function into account and
increase the problem size after each iteration by a moderate amount. By
contrast, the LPs and SOCPs coming from our Cholesky decompositions in
this chapter have exactly the same size in each iteration. We should
remark however that the LPs from iteration two and onwards are typically
more dense than the initial LP (for DSOS) and slower to solve. A
worthwhile future research direction would be to systematically compare
the performance of the two approaches and to explore customized solvers
for the LPs and the SOCPs that arise in our algorithms.

#### 3.4 The maximum stable set problem

A classic problem in discrete optimization is that of finding the
stability number of a graph. The graphs under our consideration in this
section are all undirected and unweighted. A stable set (or independent
set ) of a graph @xmath is a set of nodes of @xmath no two of which are
adjacent. The stability number of @xmath , often denoted by @xmath , is
the size of its maximum stable set(s). The problem of determining @xmath
has many applications in scheduling (see, e.g., [ 74 ] ) and coding
theory [ 128 ] . As an example, the maximum number of final exams that
can be scheduled on the same day at a university without requiring any
student to take two exams is given by the stability number of a graph.
This graph has courses IDs as nodes and an edge between two nodes if and
only if there is at least one student registered in both courses.
Unfortunately, the problem of testing whether @xmath is greater than a
given integer @xmath is well known to be NP-complete [ 102 ] .
Furthermore, the stability number cannot be approximated within a factor
@xmath for any @xmath unless P @xmath NP [ 86 ] .

A straightforward integer programming formulation of @xmath is given by

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The standard LP relaxation for this problem is obtained by changing the
binary constraint @xmath to the linear constraint @xmath :

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.13)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Solving this LP results in an upper bound on the stability number. The
quality of this upper bound can be improved by adding the so-called
clique inequalities . The set of @xmath -clique inequalities, denoted by
@xmath , is the set of constraints of the type @xmath , if @xmath form a
clique (i.e., a complete subgraph) of @xmath . Observe that these
inequalities must be satisfied for binary solutions to the above LP, but
possibly not for fractional ones. Let us define a family of LPs indexed
by @xmath :

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.14)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

Note that @xmath by construction and @xmath for all @xmath . We will be
comparing the bound obtained by some of these well-known LPs with those
achieved via the new LPs that we propose further below.

A famous semidefinite programming based upper bound on the stability
number is due to Lovász [ 128 ] :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath here is the all ones matrix and @xmath is the identity
matrix. The optimal value @xmath is called the Lovász theta number of
the graph. We have the following inequalities

  -- -------- --
     @xmath   
  -- -------- --

The fact that @xmath is easily seen by noting that if @xmath is a stable
set of maximum size and @xmath is its indicator vector, then the
rank-one matrix @xmath is feasible to the SDP and gives the objective
value @xmath . The other inequality states that this SDP-based bound is
stronger than the aforementioned LP bound even with all the clique
inequalities added (there are exponentially many). A proof can be found
e.g. in [ 116 , Section 6.5.2] .

Our goal here is to obtain LP and SOCP based sequences of upper bounds
on the Lovász theta number. To do this, we construct a series of outer
approximations of the set of psd matrices as described in Section 3.3.4
. The first bound in the sequence of LPs is given by:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In view of ( 3.9 ), this LP can be equivalently written as

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.15)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

where @xmath is a vector with at most two nonzero entries, each nonzero
entry being either @xmath or @xmath . This LP is always feasible (e.g.,
with @xmath ). Furthermore, it is bounded above. Indeed, the last
constraints in ( 3.15 ) imply in particular that for all @xmath , we
must have

  -- -------- --
     @xmath   
  -- -------- --

This, together with the constraint @xmath , implies that the objective
@xmath must remain bounded. As a result, the first LP in our iterative
sequence will give a finite upper bound on @xmath .

To progress to the next iteration, we will proceed as described in
Section 3.3.4 . The new basis for solving the problem is obtained
through the dual ⁴ ⁴ 4 The reader should not be confused to see both the
primal and the dual as maximization problems. We can make the dual a
minimization problem by changing the sign of @xmath . of ( 3.15 ):

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.16)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

The second constraint in this problem is equivalent to requiring that
@xmath be dd. We can define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are optimal solutions to ( 3.16 ). We then solve

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

to obtain our next iterate. The idea remains exactly the same for a
general iterate @xmath : We construct the dual

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an optimal solution to the dual. The updated primal is
then

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.17)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

As stated in Section 3.3.4 , the optimal values of ( 3.17 ) are
guaranteed to strictly improve as a function of @xmath . Note that to
get the bounds, we can just work with the dual problems throughout.

An analoguous technique can be used to obtain a sequence of SOCPs. For
the initial iterate, instead of requiring that @xmath in ( 3.15 ), we
require that @xmath . This problem must also be bounded and feasible as

  -- -------- --
     @xmath   
  -- -------- --

Then, for a given iterate @xmath , the algorithm consists of solving

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where as explained in Section 3.3.3 each @xmath is an @xmath matrix
whose columns contain exactly one nonzero element which is equal to
@xmath . The matrix @xmath here is fixed and obtained by first
constructing the dual SOCP

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

(each @xmath is a symmetric @xmath matrix decision variable) and then
taking

  -- -------- --
     @xmath   
  -- -------- --

Once again, one can just work with the dual problems to obtain the
bounds.

As our first example, we apply both techniques to the problem of finding
the stability number of the complement of the Petersen graph (see Figure
3.4(a) ). The exact stability number here is 2 and an example of a
maximum stable set is illustrated by the two white nodes in Figure
3.4(a) . The Lovász theta number is 2.5 and has been represented by the
continuous line in Figure 3.4(b) . The dashed lines represent the
optimal values of the LP and SOCP-based sequences of approximations for
7 iterations. Notice that already within one iteration, the optimal
values are within one unit of the true stability number, which is good
enough for knowing the exact bound (the stability number is an integer).
From the fifth iteration onwards, they differ from the Lovász theta
number by only @xmath .

Finally, in Table 3.1 , we have generated 100 instances of 20-node
Erdös-Rényi graphs with edge probability @xmath . For each instance, we
compute the bounds from the Lovász SDP, the standard LP in ( 3.13 ), the
standard LP with all 3-clique inequalities added ( @xmath in ( 3.14 )),
and our LP/SOCP iterative sequences. We focus here on iterations 3,4 and
5 because there is no need to go further. We compare our bounds with the
standard LP and the standard LP with 3-clique inequalities because they
are LPs of roughly the same size. If any of these bounds are within one
unit of the true stable set number, we count this as a success and
increment the counter. As can be seen in Table 3.1 , the Lovász theta
number is always within a unit of the stable set number, and so are our
LP and SOCP sequences ( @xmath ) after four or at most five iterations.
If we look just at the bound after 3 iterations, the success rate of
SDSOS is noticeably higher than the success rate of DSOS. Also note that
the standard LP with or without the three clique inequalities never
succeeds in giving a bound within one unit of @xmath . ⁵ ⁵ 5 All
numerical experiments in this chapter have been parsed using either SPOT
[ 137 ] or YAMIP [ 125 ] and solved using the LP/SOCP/SDP solver of
MOSEK [ 140 ] .

#### 3.5 Partition

The partition problem is arguably the simplest NP-complete problem to
state: Given a list of positive integers @xmath , is it possible to
split them into two sets with equal sums? We say that a partition
instance is feasible if the answer is yes (e.g.,
{5,2,1,6,3,8,5,4,1,1,10}) and infeasible if the answer is no (e.g.,
{47,20,13,15,36,7,46}). The partition problem is NP-complete but only
weakly. In fact, the problem admits a pseudopolynomial time algorithm
based on dynamic programming that can deal with rather large problem
sizes efficiently. This algorithm has polynomial running time on
instances where the bit size of the integers @xmath are bounded by a
polynomial in @xmath [ 71 ] . In this section, we investigate the
performance and mostly limitations of algebraic techniques for refuting
feasibility of partition instances.

Feasibility of a partition instance can always be certified by a short
proof (the partition itself). However, unless P=co-NP, we do not expect
to always have short certificates of infeasibility. Nevertheless, we can
try to look for such a certificate through a sum of squares
decomposition. Indeed, given an instance @xmath , it is not hard to see
⁶ ⁶ 6 This equivalence is apparent in view of the zeros of the
polynomial on the right hand side of ( 3.18 ) corresponding to a
feasible partition. that the following equivalence holds:

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

So if for some @xmath we could prove that @xmath is nonnegative, we
would have refuted the feasibility of our partition instance.

###### Definition 3.5.1.

An instance of partition @xmath is said to be sos-refutable if there
exists @xmath such that @xmath is sos.

Obviously, any instance of partition that is sos-refutable is
infeasible. This suggests that we can consider solving the following
semidefinite program

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.19)
                       @xmath   
  -- -------- -------- -------- --------

and examining its optimal value. Note that the optimal value of this
problem is always greater than or equal to zero as @xmath is sos by
construction. If the optimal value is positive, we have succeeded in
proving infeasibility of the partition instance @xmath .

We would like to define the notions of dsos-refutable and
sdsos-refutable instances analogously by replacing the condition @xmath
sos by the condition @xmath dsos or sdsos. Though ( 3.19 ) is guaranteed
to always be feasible by taking @xmath , this is not necessarily the
case for dsos/sdsos versions of ( 3.19 ). For example, the optimization
problem

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

on the instance @xmath is infeasible. ⁷ ⁷ 7 Under other structures on a
polynomial, the same type of problem can arise for sos. For example,
consider the Motzkin polynomial [ 141 ] @xmath which is nonnegative
everywhere. The problem @xmath is infeasible. This is a problem for us
as we need the first LP to be feasible to start our iterations. We show,
however, that we can get around this issue by modeling the partition
problem with homogeneous polynomials.

###### Definition 3.5.2.

Let @xmath be as in ( 3.18 ). An instance of partition @xmath is said to
be dsos-refutable (resp. sdsos-refutable ) if there exists @xmath such
that the quartic form

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

is dsos (resp. sdsos).

Notice that @xmath is indeed a polynomial as it can be equivalently
written as

  -- -------- --
     @xmath   
  -- -------- --

What we are doing here is homogenizing a polynomial that does not have
odd monomials by multiplying its lower degree monomials with appropriate
powers of @xmath . The next theorem tells us how we can relate
nonnegativity of this polynomial to feasibility of partition.

###### Theorem 3.5.3.

A partition instance @xmath is infeasible if and only if there exists
@xmath for which the quartic form @xmath defined in ( 3.21 ) is
nonnegative.

###### Proof.

For ease of reference, let us define

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

Suppose partition is feasible, i.e, the integers @xmath can be placed in
two sets @xmath and @xmath with equal sums. Let @xmath =1 if @xmath is
placed in set @xmath and @xmath if @xmath is placed in set @xmath . Then
@xmath and @xmath . This implies that

  -- -------- --
     @xmath   
  -- -------- --

and hence having @xmath would make

  -- -------- --
     @xmath   
  -- -------- --

If partition is infeasible, then @xmath . In view of ( 3.22 ) we see
that @xmath on the sphere @xmath of radius @xmath . Since @xmath is
continuous, its minimum @xmath on the compact set @xmath is achieved and
must be positive. So we must have

  -- -------- --
     @xmath   
  -- -------- --

By homogeneity, this implies that @xmath is nonnegative everywhere. ∎

Consider now the LP

  -- -- -------- -------- --------
        @xmath            (3.23)
                 @xmath   
  -- -- -------- -------- --------

###### Theorem 3.5.4.

The LP in ( 3.23 ) is always feasible.

###### Proof.

Let @xmath and recall that @xmath denotes the vector of all monomials of
degree exactly @xmath . We can write

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is in the strict interior of the @xmath cone (i.e., its
entries @xmath satisfy @xmath ). Furthermore, let @xmath be a symmetric
matrix such that @xmath Then

  -- -------- --
     @xmath   
  -- -------- --

As @xmath is in the strict interior of @xmath , @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Taking @xmath , @xmath will be diagonally dominant and @xmath will be
dsos. ∎

As an immediate consequence, the SOCP

  -- -- -------- -------- --------
        @xmath            (3.24)
                 @xmath   
  -- -- -------- -------- --------

is also always feasible. We can now define our sequence of LPs and SOCPs
as we have guaranteed feasibility of the first iteration. This is done
following the strategy and notation of Section 3.3.2 :

  -- -------- -------- -------- --------
     @xmath   @xmath            (3.25)
                       @xmath   
  -- -------- -------- -------- --------

where @xmath is a sequence of matrices recursively defined with @xmath
and @xmath defined as the Cholesky factor of an optimal dd (resp. sdd)
Gram matrix of the optimization problem in iteration @xmath .

We illustrate the performance of these LP and SOCP-based bounds on the
infeasible partition instance @xmath . The results are in Figure 3.5 .
We can use the sum of squares relaxation to refute the feasibility of
this instance by either solving ( 3.19 ) (the “non-homogenized version”)
or solving ( 3.23 ) with dsos replaced with sos (the “homogenized
version”). Both approaches succeed in refuting this partition instance,
though the homogenized version gives a slightly better (more positive)
optimal value. As a consequence, we only plot the homogeneous bound,
denoted by @xmath , in Figure 3.5 . Notice that the LP and SOCP-based
sequences refute the instance from the @xmath iteration onwards.

As our final experiment, we generate 50 infeasible instances of
partition with 6 elements randomly generated between 1 and 15. These
instances are trivially infeasible because we made sure that @xmath is
an odd number. In the first column of Table 3.2 , we count the number of
successes for sos-refutability (non homogeneous version as defined in
Definition 3.5.1 ), where a failure is defined as the optimal value of (
3.19 ) being 0 up to numerical precision. The second column corresponds
to the number of successes for sos-refutability (homogeneous version).
The last 4 columns show the success rate of the LP and SOCP-based
sequences as defined in ( 3.25 ), after 20 iterations and 40 iterations.

From the experiments, the homogeneous and non-homogeneous versions of (
3.19 ) have the same performance in terms of their ability to refute
feasibility. However, we observe that they both fail to refute a large
number of completely trivial instances! We prove why this is the case
for one representative instance in the next section. The LP and
SOCP-based sequences also perform poorly and their convergence is much
slower than what we observed for the maximum stable set problem in
Section 3.4 .

##### 3.5.1 Failure of the sum of squares relaxation on trivial
partition instances.

For complexity reasons, one would expect there to be infeasible
instances of partition that are not sos-refutable. What is surprising
however is that the sos relaxation is failing on many instances that are
totally trivial to refute as the sum of their input integers is odd. We
present a proof of this phenomenon on an instance which is arguably the
simplest one. ⁸ ⁸ 8 If we were to instead consider the instance [1,1,1],
sos would succeed in refuting it.

###### Proposition 3.5.5.

The infeasible partition instance @xmath is not sos-refutable.

###### Proof.

Let @xmath be the polynomial defined in ( 3.18 ). To simplify notation,
we let @xmath represent @xmath for @xmath . We will show that @xmath is
on the boundary of the SOS cone even though we know it is strictly
inside the PSD cone. This is done by presenting a dual functional @xmath
that vanishes on @xmath takes a nonnegative value on all quartic sos
polynomials, and a negative value on @xmath for any @xmath (See Figure
3.6 for an intuitive illustration of this.)

The polynomial @xmath when expanded out reads

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

Consider the vector of coefficients of @xmath with the ordering as
written in ( 3.26 ):

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

This is a reduced representation of the vector of coefficients of @xmath
, in that there are many zeros associated with all other monomials of
degree less than or equal to 4, which we are not writing out.

Our goal is to find a vector @xmath that satisfies

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.28)
  -- -------- -------- -- --------

If such a @xmath exists and its first element is nonzero (which by
rescaling can then be taken to be 1), then @xmath . This provides us
with the required functional that separates @xmath from the set of sos
polynomials.

Selecting the same reduced basis as the one used in ( 3.27 ), we take

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the all ones vector of size @xmath . The subscript
“reduced” denotes the fact that in @xmath , only the elements of @xmath
needed to verify @xmath are presented. Unlike @xmath , the entries of
@xmath corresponding to the other monomials are not all zero. This can
be seen from the entries of the matrix @xmath that appears further down.

We now show how ( 3.28 ) holds. Consider any sos polynomial @xmath of
degree less than or equal to 4. We know that it can be written as

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , and a vector of monomials

  -- -------- --
     @xmath   
  -- -------- --

It is not difficult to see that

  -- -------- --
     @xmath   
  -- -------- --

where by @xmath , we mean a matrix where each monomial in @xmath is
replaced with the corresponding element of the vector @xmath . This
yields the matrix

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath . We can check that @xmath . This, together with
the fact that @xmath implies that ( 3.28 ) holds. ⁹ ⁹ 9 It can be shown
in a similar fashion that @xmath is not sos-refutable in the homogeneous
formulation of ( 3.21 ) either. ∎

##### 3.5.2 Open problems

We showed in the previous subsection that the infeasible partition
instance @xmath was not sos-refutable. Many more randomly-generated
partition instances that we knew to be infeasible (their sum being odd)
also failed to be sos-refutable. This observation motivates the
following open problem:

###### Open Problem 1

Characterize the set of partition instances @xmath that have an odd sum
but are not sos-refutable (see Definition 3.5.1 ).

Our second open problem has to do with the power of higher order sos
relaxations for refuting feasibility of partition instances.

###### Open Problem 2

For a positive integer @xmath , let us call a partition instance @xmath
@xmath -sos-refutable if @xmath such that @xmath is sos. Note that this
is also a certificate of infeasibility of the instance. Even though the
@xmath instance is not sos-refutable, it is @xmath -sos-refutable.
Furthermore, we have numerically observed that the instance @xmath
(vector of all ones of length 7) is not sos-refutable or @xmath
-sos-refutable, but it is @xmath -sos-refutable. If we consider the
instance consisting of @xmath ones with @xmath odd, and define @xmath to
be the minimum @xmath such that @xmath becomes @xmath -sos-refutable, is
it true that @xmath must grow with @xmath ?

### Chapter 4 On the Construction of Converging Hierarchies for
Polynomial Optimization Based on Certificates of Global Positivity

#### 4.1 Introduction

A polynomial optimization problem (POP) is an optimization problem of
the form

  -- -- -------- -- -------- -------- -------
        @xmath      @xmath            (4.1)
                             @xmath   
  -- -- -------- -- -------- -------- -------

where @xmath are polynomial functions in @xmath variables @xmath and
with real coefficients. It is well-known that polynomial optimization is
a hard problem to solve in general. For example, simply testing whether
the optimal value of problem ( 4.1 ) is smaller than or equal to some
rational number @xmath is NP-hard already when the objective is
quadratic and the constraints are linear [ 151 ] . Nevertheless, these
problems remain topical due to their numerous applications throughout
engineering, operations research, and applied mathematics (see, e.g., [
111 , 30 , 8 ] ). In this chapter, we are interested in obtaining lower
bounds on the optimal value of problem ( 4.1 ). We focus on a class of
methods which construct hierarchies of tractable convex optimization
problems whose optimal values are lowerbounds on the optimal value of (
4.1 ), with convergence to it as the sequence progresses. This implies
that even though the original POP is nonconvex, one can obtain
increasingly accurate lower bounds on its optimal value by solving
convex optimization problems. One method for constructing these
hierarchies of optimization problems that has gained attention in recent
years relies on the use of Positivstellensätze (see, e.g., [ 115 ] for a
survey). Positivstellensätze are algebraic identities that certify
infeasibility of a set of polynomial inequalities, or equivalently ¹ ¹ 1
Note that the set @xmath is empty if and only if @xmath on the set
@xmath . , positivity of a polynomial on a basic semialgebraic set.
(Recall that a basic semialgebraic set is a set defined by finitely many
polynomial inequalities.) These Positivstellensätze can be used to prove
lowerbounds on POPs. Indeed, if we denote the feasible set of ( 4.1 ) by
@xmath , the optimal value of problem ( 4.1 ) is equivalent to

  -- -- -------- -- -------- -------- -------
        @xmath      @xmath            (4.2)
                             @xmath   
  -- -- -------- -- -------- -------- -------

Hence if @xmath is a strict lower bound on ( 4.1 ), we have that @xmath
on @xmath , a fact that can be certified using Positivstellensätze. At a
conceptual level, hierarchies that provide lower bounds on ( 4.1 ) are
constructed thus: we fix the “size of the certificate” at each level of
the hierarchy and search for the largest @xmath such that the
Positivstellensätze at hand can certify positivity of @xmath over @xmath
with a certificate of this size. As the sequence progresses, we increase
the size of the certificates allowed, hence obtaining increasingly
accurate lower bounds on ( 4.1 ).

Below, we present three of the better-known Positivstellensätze, given
respectively by Stengle [ 181 ] , Schmüdgen [ 173 ] , and Putinar [ 162
] . These all rely on sum of squares certificates. We recall that a
polynomial is a sum of squares (sos) if it can be written as a sum of
squares of other polynomials. We start with Stengle’s
Positivstellensatz, which certifies infeasibility of a set of polynomial
inequalities. It is sometimes referred to as “the Positivstellensatz” in
related literature as it requires no assumptions, contrarily to
Schmüdgen and Putinar’s theorems which can be viewed as refinements of
Stengle’s result under additional assumptions.

###### Theorem 4.1.1 (Stengle’s Positivstellensatz [181]).

The basic semialgebraic set

  -- -------- --
     @xmath   
  -- -------- --

is empty if and only if there exist sum of squares polynomials @xmath ,
@xmath , @xmath , @xmath , @xmath , @xmath , @xmath , @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

The next two theorems, due to Schmüdgen and Putinar, certify positivity
of a polynomial @xmath over a basic semialgebraic set @xmath . They
impose additional compactness assumptions comparatively to Stengle’s
Positivstellensatz.

###### Theorem 4.1.2 (Schmüdgen’s Positivstellensatz [173]).

Assume that the set

  -- -------- --
     @xmath   
  -- -------- --

is compact. If a polynomial @xmath is positive on @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , @xmath , @xmath , @xmath , @xmath , @xmath , @xmath ,
@xmath are sums of squares.

###### Theorem 4.1.3 (Putinar’s Positivstellensatz [162]).

Let

  -- -------- --
     @xmath   
  -- -------- --

and assume that @xmath satisfy the Archimedean property, i.e., there
exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are sums of squares. If a polynomial @xmath is positive on
@xmath , then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are sums of squares.

Note that these three Positivstellensätze involve in their expressions
sum of squares polynomials of unspecified degree. To construct
hierarchies of tractable optimization problems for ( 4.2 ), we fix this
degree: at level @xmath , we search for the largest @xmath such that
positivity of @xmath over @xmath can be certified using the
Positivstellensätze where the degrees of all sos polynomials are taken
to be less than or equal to @xmath . Solving each level of these
hierarchies is then a semidefinite program (SDP). This is a consequence
of the fact that one can optimize over (or test membership to) the set
of sum of squares polynomials of fixed degree using semidefinite
programming [ 153 , 152 , 109 ] . Indeed, a polynomial @xmath of degree
@xmath and in @xmath variables is a sum of squares if and only if there
exists a symmetric matrix @xmath such that @xmath , where @xmath is the
standard vector of monomials in @xmath variables and of degree less than
or equal to @xmath . We remark that the hierarchy obtained from
Stengle’s Positivstellensatz was proposed and analyzed by Parrilo in [
153 ] ; the hierarchy obtained from Putinar’s Positivstellensatz was
proposed and analyzed by Lasserre in [ 109 ] . There have been more
recent works that provide constructive proofs of Schmüdgen and Putinar’s
Positivstellensätze; see [ 20 , 175 , 177 ] . These proofs rely on other
Positivstellensätze, e.g., a result by Polyá (see Theorem 4.1.6 below)
in [ 175 , 177 ] , and the same result by Polyá, Farkas’ lemma, and
Stengle’s Positivstellensatz in [ 20 ] . There has further been an
effort to derive complexity bounds for Schmüdgen and Putinar’s
Positivstellensätze in recent years; see [ 147 , 176 ] .

On a historical note, Stengle, Schmüdgen, and Putinar’s
Positivstellensätze were derived in the latter half of the 20th century.
As mentioned previously, they all certify positivity of a polynomial
over an arbitrary basic semialgebraic set (modulo compactness
assumptions). By contrast, there are Positivstellensätze from the early
20th century that certify positivity of a polynomial globally. Perhaps
the most well-known Positivstellensatz of this type is due to Artin in
1927, in response to Hilbert’s 17th problem. Artin shows that any
nonnegative polynomial is a sum of squares of rational functions. Here
is an equivalent formulation of this statement:

###### Theorem 4.1.4 (Artin [18]).

For any nonnegative polynomial @xmath , there exists an sos polynomial
@xmath such that @xmath is a sum of squares.

To the best of our knowledge, in this area, all converging hierarchies
of lower bounds for POPs are based off of Positivstellensätze that
certify nonnegativity of a polynomial over an arbitrary basic
semialgebraic set. In this chapter, we show that in fact, under
compactness assumptions, it suffices to have only global certificates of
nonnegativity (such as the one given by Artin) to produce a converging
hierarchy for general POPs. As a matter of fact, even weaker statements
that apply only to globally positive (as opposed to globally
nonnegative) forms are enough to derive converging hierarchies for POPs.
Examples of such statements are due to Habicht [ 81 ] and Reznick [ 164
] . With such an additional positivity assumption, more can usually be
said about the structure of the polynomial @xmath in Artin’s result.
Below, we present the result by Reznick.

###### Theorem 4.1.5 (Reznick [164]).

For any positive definite form @xmath , there exists @xmath such that
@xmath is a sum of squares.

We show in this chapter that this Positivstellensatz also gives rise to
a converging hierarchy for POPs with a compact feasible set similarly to
the one generated by Artin’s Positivstellensatz.

Through their connections to sums of squares, the two hierarchies
obtained using the theorems of Reznick and Artin are semidefinite
programming-based. In this chapter, we also derive an
“optimization-free” converging hierarchy for POPs with compact feasible
sets where each level of the hierarchy only requires that we be able to
test nonnegativity of the coefficients of a given fixed polynomial. To
the best of our knowledge, this is the first converging hierarchy of
lower bounds for POPs which does not require that convex optimization
problems be solved at each of its levels. To construct this hierarchy,
we use a result of Polyá [ 158 ] , which just like Artin’s and Reznick’s
Positivstellensätze, certifies global positivity of forms. However this
result is restricted to even forms. Recall that a form @xmath is even if
each of the variables featuring in its individual monomials has an even
power. This is equivalent (see [ 54 , Lemma 2] ) to @xmath being
invariant under change of sign of each of its coordinates, i.e.,

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 4.1.6 (Polyá [158]).

For any positive definite even form @xmath , there exists @xmath such
that @xmath has nonnegative coefficients. ² ² 2 A perhaps better-known
but equivalent formulation of this theorem is the following: for any
form @xmath that is positive on the standard simplex, there exists
@xmath such that @xmath has nonnegative coefficients. The two
formulations are equivalent by simply letting @xmath .

Our aforementioned hierarchy enables us to obtain faster-converging
linear programming (LP) and second-order cone programming (SOCP)-based
hierarchies for general POPs with compact feasible sets that rely on the
concepts of dsos and sdsos polynomials. These are recently introduced
inner approximations to the set of sos polynomials that have shown much
better scalability properties in practice [ 9 ] .

As a final remark, we wish to stress the point that the goal of this
chapter is first and foremost theoretical, i.e., to provide methods for
constructing converging hierarchies of lower bounds for POPs using as
sole building blocks certificates of global positivity. We do not make
any claims that these hierarchies can outperform the popular existing
hierarchies due, e.g., to Lasserre [ 109 ] and Parrilo [ 153 ] . We do
believe however that the optimization-free hierarchy presented in
Section 4.4.1 could potentially be of interest in large-scale
applications where the convex optimization problems appearing in
traditional hierarchies are too cumbersome to solve.

##### 4.1.1 Outline of the chapter

The chapter is structured as follows. In Section 4.2 , we show that if
one can inner approximate the cone of positive definite forms
arbitrarily well (with certain basic properties), then one can produce a
converging hierarchy of lower bounds for POPs with compact feasible sets
(Theorem 4.2.4 ). This relies on a reduction (Theorem 4.2.1 ) that
reduces the problem of certifying a strict lower bound on a POP to that
of proving positivity of a certain form. In Section 4.3 , we see how
this result can be used to derive semidefinite programming-based
converging hierarchies (Theorems 4.3.2 and 4.3.4 ) from the
Positivstellensätze by Artin (Theorem 6.4.2 ) and Reznick (Theorem 4.1.5
). In Section 4.4 , we derive an optimization-free hierarchy (Theorem
4.4.1 ) from the Positivstellensatz of Polyá (Theorem 4.1.6 ) as well as
LP and SOCP-based hierarchies which rely on dsos/sdsos polynomials
(Corollary 4.4.8 ). We conclude with a few open problems in Section 4.5
.

##### 4.1.2 Notation and basic definitions

We use the standard notation @xmath to denote that a symmetric matrix
@xmath is positive semidefinite. Recall that a form is a homogeneous
polynomial, i.e., a polynomial whose monomials all have the same degree.
We denote the degree of a form @xmath by @xmath . We say that a form
@xmath is nonnegative (or positive semidefinite) if @xmath , for all
@xmath (we write @xmath ). A form @xmath is positive definite (pd) if
@xmath for all nonzero @xmath in @xmath (we write @xmath ). Throughout
the chapter, we denote the set of forms (resp. the set of nonnegative
forms) in @xmath variables and of degree @xmath by @xmath (resp @xmath
). We denote the ball of radius @xmath and centered at the origin by
@xmath and the unit sphere in @xmath -space, i.e., @xmath , by @xmath .
We use the shorthand @xmath for @xmath to denote @xmath We say that a
scalar @xmath is a strict lower bound on ( 4.1 ) if @xmath . Finally, we
ask the reader to carefully read Remark 4.2.3 which contains the details
of a notational overwriting occurring before Theorem 4.2.4 and valid
from then on throughout the chapter. This overwriting makes the chapter
much simpler to parse.

#### 4.2 Constructing converging hierarchies for POP using global
certificates of positivity

Consider the polynomial optimization problem in ( 4.1 ) and denote its
optimal value by @xmath . Let @xmath be such that @xmath is the smallest
even integer larger than or equal to the maximum degree of @xmath . We
denote the feasible set of our optimization problem by

  -- -------- --
     @xmath   
  -- -------- --

and assume that @xmath is contained within a ball of radius @xmath .
From this, it is easy to provide (possibly very loose) upper bounds on
@xmath over the set @xmath : as @xmath is contained in a ball of radius
@xmath , we have @xmath , for all @xmath . We then use this to upper
bound each monomial in @xmath and consequently @xmath itself. We use the
notation @xmath to denote these upper bounds, i.e., @xmath , for all
@xmath and for all @xmath . Similarly, we can provide an upperbound on
@xmath . We denote such a bound by @xmath , i.e., @xmath @xmath

The goal of this section is to produce a method for constructing
converging hierarchies of lower bounds for POPs if we have access to
arbitrarily accurate inner approximations of the set of positive
definite forms. The first theorem (Theorem 4.2.1 ) connects lower bounds
on ( 4.1 ) to positive definiteness of a related form. The second
theorem (Theorem 4.2.4 ) shows how this can be used to derive a
hierarchy for POPs.

###### Theorem 4.2.1.

Consider the general polynomial optimization problem in ( 4.1 ) and
recall that @xmath is such that @xmath is the smallest even integer
larger than or equal to the maximum degree of @xmath . Suppose @xmath
for some positive scalar @xmath . Let @xmath (resp. @xmath ) be any
finite upper bounds on @xmath (resp. @xmath ).

Then, a scalar @xmath is a strict lower bound on ( 4.1 ) if and only if
the homogeneous sum of squares polynomial

  -- -------- -------- -------- -------
     @xmath   @xmath            (4.3)
                       @xmath   
  -- -------- -------- -------- -------

of degree @xmath and in @xmath variables @xmath is positive definite.

###### Proof.

It is easy to see that @xmath is a strict lower bound on ( 4.1 ) if and
only if the set

  -- -------- --
     @xmath   
  -- -------- --

is empty. Indeed, if @xmath is nonempty, then there exists a point
@xmath such that @xmath . This implies that @xmath cannot be a strict
lower bound on ( 4.1 ). Conversely, if @xmath is empty, the intersection
of @xmath with @xmath is empty, which implies that @xmath , @xmath .

We now define the set:

  -- -------- -------- -------
     @xmath            (4.4)
              @xmath   
  -- -------- -------- -------

Note that @xmath is empty if and only if @xmath is empty. Indeed, if
@xmath is nonempty, then there exists @xmath and @xmath such that the
three sets of equations are satisfied. This obviously implies that
@xmath and that @xmath , for all @xmath It further implies that @xmath
as by assumption, if @xmath , then @xmath is in a ball of radius @xmath
. Conversely, suppose now that @xmath is nonempty. There exists @xmath
such that @xmath , @xmath for @xmath , and @xmath Hence, there exist
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Combining the fact that @xmath and the fact that @xmath , @xmath (resp.
@xmath ) are upperbounds on @xmath (resp. @xmath ), we obtain:

  -- -------- --
     @xmath   
  -- -------- --

By raising both sides of the inequality to the power @xmath , we show
the existence of @xmath .

We now show that @xmath is empty if and only if @xmath is positive
definite. Suppose that @xmath is nonempty, i.e., there exists @xmath
such that the equalities given in ( 4.4 ) hold. Note then that @xmath .
As @xmath is nonzero, this implies that @xmath is not positive definite.

For the converse, assume that @xmath is not positive definite. As @xmath
is a sum of squares and hence nonnegative, this means that there exists
nonzero @xmath such that @xmath . We proceed in two cases. If @xmath ,
it is easy to see that @xmath and @xmath is nonempty. Consider now the
case where @xmath . The third square in @xmath being equal to zero gives
us:

  -- -------- --
     @xmath   
  -- -------- --

This implies that @xmath and that @xmath which contradicts the fact that
@xmath is nonzero. ∎

###### Remark 4.2.2.

Note that Theorem 4.2.1 implies that testing feasibility of a set of
polynomial inequalities is no harder than checking whether a homogeneous
polynomial that is sos has a zero. Indeed, as mentioned before, the
basic semialgebraic set

  -- -------- --
     @xmath   
  -- -------- --

is empty if and only if @xmath is a strict lower bound on the POP

  -- -- -------- -- -------- --
        @xmath      @xmath   
                    @xmath   
  -- -- -------- -- -------- --

In principle, this reduction can open up new possibilities for
algorithms for testing feasibility of a basic semialgebraic set. For
example, the work in [ 2 ] shows that positive definiteness of a form
@xmath is equivalent to global asymptotic stability of the polynomial
vector field @xmath One could as a consequence search for Lyapunov
functions, as is done in [ 2 , Example 2.1.] , to certify positivity of
forms. Conversely, simulating trajectories of the above vector field can
be used to minimize @xmath and potentially find its nontrivial zeros,
which, by our reduction, can be turned into a point that belongs to the
basic semialgebraic set at hand.

We further remark that one can always take the degree of the sos form
@xmath in ( 4.3 ) whose positivity is under consideration to be equal to
four. This can be done by changing the general POP in ( 4.1 ) to only
have quadratic constraints and a quadratic objective via an iterative
introduction of new variables and new constraints in the following
fashion: @xmath .

###### Remark 4.2.3 (Notational remark).

As a consequence of Theorem 4.2.1 , we now know that certifying lower
bounds on ( 4.1 ) is equivalent to proving positivity of the form @xmath
that appears in ( 4.3 ). To simplify notation, we take this form to have
@xmath variables and be of degree @xmath from now on (except for our
Positivstellensätze in Corollaries 4.3.5 and 4.4.5 which stand on their
own). To connect back to problem ( 4.1 ) and the original notation, the
reader should replace every occurrence of @xmath and @xmath in the
future as follows:

  -- -------- --
     @xmath   
  -- -------- --

Recall that @xmath was previously the dimension of the decision variable
of problem ( 4.1 ), @xmath was such that @xmath is the smallest even
integer larger than or equal to the maximum degree of @xmath and @xmath
in ( 4.1 ), and @xmath was the number of constraints of problem ( 4.1 ).

Our next theorem shows that, modulo some technical assumptions, if one
can inner approximate the set of positive definite forms arbitrarily
well (conditions (a) and (b)), then one can construct a converging
hierarchy for POPs.

###### Theorem 4.2.4.

Let @xmath be a sequence of sets (indexed by @xmath ) of homogeneous
polynomials in @xmath variables and of degree @xmath with the following
properties:

1.  @xmath and there exists a pd form @xmath

2.   If @xmath , then @xmath such that @xmath

3.  @xmath , @xmath .

4.   If @xmath , then @xmath , @xmath

Recall the definition of @xmath given in ( 4.3 ). Consider the hierarchy
of optimization problems indexed by @xmath :

  -- -------- -------- -- -------- -------- -------
     @xmath   @xmath      @xmath            (4.5)
                                   @xmath   
  -- -------- -------- -- -------- -------- -------

Then, @xmath for all @xmath , @xmath is nondecreasing, and @xmath

###### Proof.

We first show that the sequence @xmath is upperbounded by @xmath .
Suppose that a scalar @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

We then have @xmath using (a). This implies that @xmath , and hence
@xmath is pd as @xmath is pd. From Theorem 4.2.1 , it follows that
@xmath has to be a strict lower bound on ( 4.1 ). As any such @xmath
satisfies @xmath , we have that @xmath for all @xmath .

We now show monotonicity of the sequence @xmath . Let @xmath be such
that

  -- -------- --
     @xmath   
  -- -------- --

We have the following identity:

  -- -------- --
     @xmath   
  -- -------- --

Now, using the assumption and properties (c) and (d), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

This implies that @xmath and that @xmath

Note that as the sequence @xmath is upperbounded and nondecreasing, it
converges. Let us show that the limit of this sequence is @xmath . To do
this, we show that for any strict lower bound @xmath on ( 4.1 ), there
exists a positive integer @xmath such that @xmath . By Theorem 4.2.1 ,
as @xmath is a strict lower bound, @xmath is positive definite. Hence,
by continuity, there exists a positive integer @xmath such that @xmath
is positive definite. Using (b), this implies that there exists a
positive integer @xmath such that

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

We now proceed in two cases. If @xmath , we take @xmath and use property
(c) to conclude. If @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

We take @xmath and use ( 4.6 ) and properties (c) and (d) to conclude. ∎

###### Remark 4.2.5.

Note that condition (d) is subsumed by the more natural condition that
@xmath be a convex cone for any @xmath and @xmath . However, there are
interesting and relevant cones which we cannot prove to be convex though
they trivially satisfy condition (d) (see Theorem 4.3.2 for an example).

#### 4.3 Semidefinite programming-based hierarchies obtained from
Artin’s and Reznick’s Positivstellensätze

In this section, we construct two different semidefinite
programming-based hierarchies for POPs using Positivstellensätze derived
by Artin (Theorem 6.4.2 ) and Reznick (Theorem 4.1.5 ). To do this, we
introduce two sets of cones that we call the Artin and Reznick cones.

###### Definition 4.3.1.

We define the Reznick cone of level @xmath to be

  -- -------- --
     @xmath   
  -- -------- --

Similarly, we define the Artin cone of level @xmath to be

  -- -------- --
     @xmath   
  -- -------- --

We show that both of these cones produce hierarchies of the type
discussed in Theorem 4.2.4 . Recall that @xmath is the optimal value of
problem ( 4.1 ) and that @xmath is defined as in ( 4.3 ) with the change
of notation discussed in Remark 4.2.3 .

###### Theorem 4.3.2.

Consider the hierarchy of optimization problems indexed by @xmath :

  -- -------- -------- -- -------- -------- -------
     @xmath   @xmath      @xmath            (4.7)
                                   @xmath   
  -- -------- -------- -- -------- -------- -------

Then, @xmath for all @xmath , @xmath is nondecreasing, and @xmath

###### Proof.

It suffices to show that the Reznick cones @xmath satisfy properties
(a)-(d) in Theorem 4.2.4 . The result will then follow from that
theorem. For property (a), it is clear that, as @xmath and @xmath is a
sum of squares and hence nonnegative, @xmath must be nonnegative, so
@xmath Furthermore, the form @xmath belongs to @xmath and is positive
definite. Property (b) is verified as a consequence of Theorem 4.1.5 .
For (c), note that if @xmath is sos, then @xmath is sos since the
product of two sos polynomials is sos. Finally, for property (d), note
that @xmath is a convex cone. Indeed, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

is sos if @xmath and @xmath are in @xmath . Combining the fact that
@xmath is a convex cone and the fact that @xmath , we obtain (d). ∎

###### Remark 4.3.3.

To solve a fixed level @xmath of the hierarchy given in Theorem 4.3.2 ,
one must proceed by bisection on @xmath Bisection here would produce a
sequence of upper bounds @xmath and lower bounds @xmath on @xmath as
follows. At iteration @xmath , we test whether @xmath is feasible for (
4.7 ). If it is, then we take @xmath and @xmath . If it is not, we take
@xmath and @xmath . We stop when @xmath , where @xmath is a prescribed
accuracy, and the algorithm returns @xmath Note that @xmath and that to
obtain @xmath , one needs to take a logarithmic (in @xmath ) number of
steps using this method.

Hence, solving the @xmath level of this hierarchy using bisection can be
done by semidefinite programming. Indeed, for a fixed @xmath and @xmath
given by the bisection algorithm, one simply needs to test membership of

  -- -------- --
     @xmath   
  -- -------- --

to the set of sum of squares polynomials. This amounts to solving a
semidefinite program. We remark that all semidefinite programming-based
hierarchies available only produce an approximate solution to the
optimal value of the SDP solved at level @xmath in polynomial time. This
is independent of whether they use bisection (e.g., such as the
hierarchy given in Theorem 4.3.2 or the one based on Stengle’s
Positivstellensatz) or not (e.g., the Lasserre hierarchy).

Our next theorem improves on our previous hierarchy by freeing the
multiplier @xmath and taking advantage of our ability to search for an
optimal multiplier using semidefinite programming.

###### Theorem 4.3.4.

Recall the definition of Artin cones from Definition 4.3.1 . Consider
the hierarchy of optimization problems indexed by @xmath :

  -- -------- -------- -- -------- -------- -------
     @xmath   @xmath      @xmath            (4.8)
                                   @xmath   
  -- -------- -------- -- -------- -------- -------

Then, @xmath for all @xmath , @xmath is nondecreasing, and @xmath

###### Proof.

Just as the previous theorem, it suffices to show that the Artin cones
@xmath satisfy properties (a)-(d) of Theorem 4.2.4 . The proof of
property (a) follows the proof given for Theorem 4.3.2 . Property (b) is
satisfied as a (weaker) consequence of Artin’s result (see Theorem 6.4.2
). For (c), we have that if @xmath is sos for some sos polynomial of
degree @xmath , then @xmath is sos, and @xmath has degree @xmath .
Finally, for (d), suppose that @xmath . Then there exists an sos form
@xmath such that @xmath is sos. We have

  -- -------- --
     @xmath   
  -- -------- --

which is sos as the product (resp. sum) of two sos polynomials is sos. ∎

Note that again, for any fixed @xmath , the level @xmath of the
hierarchy can be solved using bisection which leads to a sequence of
semidefinite programs.

Our developments in the past two sections can be phrased in terms of a
Positivstellensatz.

###### Corollary 4.3.5 (A new Positivstellensatz).

Consider the basic semialgebraic set

  -- -------- --
     @xmath   
  -- -------- --

and a polynomial @xmath . Suppose that @xmath is contained within a ball
of radius @xmath . Let @xmath and @xmath be any finite upperbounds on
@xmath and, respectively, @xmath over the set @xmath . ³ ³ 3 As
discussed at the beginning of Section 4.2 , such bounds are very easily
computable. Let @xmath be such that @xmath is the smallest integer
larger than or equal to the maximum degree of @xmath . Then, @xmath for
all @xmath if and only if there exists a positive integer @xmath such
that

  -- -------- --
     @xmath   
  -- -------- --

is a sum of squares, where the form @xmath in variables @xmath is as
follows:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

###### Proof.

This is an immediate corollary of arguments given in the proof of
Theorem 4.2.1 and in the proof of Theorem 4.3.2 for the case where
@xmath ∎

#### 4.4 Polyá’s theorem and hierarchies for POPs that are
optimization-free, LP-based, and SOCP-based

In this section, we use a result by Polyá on global positivity of even
forms to obtain new hierarchies for polynomial optimization problems. In
Section 4.4.1 , we present a hierarchy that is optimization-free , in
the sense that each level of the hierarchy only requires multiplication
of two polynomials and checking if the coefficients of the resulting
polynomial are nonnegative. In Section 4.4.2 , we use the previous
hierarchy to derive linear programming and second-order cone
programming-based hierarchies with faster convergence. These rely on the
recently developed concepts of dsos and sdsos polynomials (see
Definition 4.4.7 and [ 9 ] ), which are alternatives to sos polynomials
that have been used in diverse applications to improve scalability; see
[ 9 , Section 4] .

##### 4.4.1 An optimization-free hierarchy of lower bounds for POPs

The main theorem in this section presents an optimization-free hierarchy
of lower bounds for general POPs with compact feasible sets:

###### Theorem 4.4.1.

Recall the definition of @xmath as given in ( 4.3 ), with @xmath and
@xmath Let @xmath and define

  -- -- -------- -------- -------- -- -------
        @xmath            @xmath      (4.9)
                 @xmath               
  -- -- -------- -------- -------- -- -------

Consider the hierarchy of optimization problems indexed by @xmath :

  -- -------- -------- -- -------- -------- --------
     @xmath   @xmath      @xmath            (4.10)
                                   @xmath   
  -- -------- -------- -- -------- -------- --------

Let @xmath . Then @xmath for all @xmath , @xmath is nondecreasing, and
@xmath .

As before, we use bisection to obtain the optimal value @xmath of the
@xmath level of the hierarchy up to a fixed precision @xmath (see Remark
4.3.3 ). At each step of the bisection algorithm, one simply needs to
multiply two polynomials together and check nonnegativity of the
coefficients of the resulting polynomial to proceed to the next step. As
a consequence, this hierarchy is optimization-free as we do not need to
solve (convex) optimization problems at each step of the bisection
algorithm. To the best of our knowledge, no other converging hierarchy
of lower bounds for general POPs dispenses altogether with the need to
solve convex subprograms. We also provide a Positivstellensatz
counterpart to the hierarchy given above (see Corollary 4.4.5 ). This
corollary implies in particular that one can always certify
infeasibility of a basic semialgebraic set by recursively multiplying
polynomials together and simply checking nonnegativity of the
coefficients of the resulting polynomial.

We now make a few remarks regarding the techniques used in the proof of
Theorem 4.4.1 . Unlike Theorems 4.3.2 and 4.3.4 , we do not show that
@xmath satisfies properties (a)-(d) as given in Theorem 4.2.4 due to
some technical difficulties. It turns out however that we can avoid
showing properties (c) and (d) by using a result by Reznick and Powers [
160 ] that we present below. Regarding properties (a) and (b), we show
that a slightly modified version of (a) holds and that (b), which is the
key property in Theorem 4.2.4 , goes through as is. We note though that
obtaining (b) from Polyá’s result (Theorem 4.1.6 ) is not as immediate
as obtaining (b) from Artin’s and Reznick’s results. Indeed, unlike the
theorems by Artin and Reznick (see Theorems 6.4.2 and 4.1.5 ) which
certify global positivity of any form, Polyá’s result only certifies
global positivity of even forms. To make this latter result a statement
about general forms, we work in an appropriate lifted space. This is
done by replacing any form @xmath in variables @xmath by the even form
@xmath in variables @xmath . This lifting operation preserves
nonnegativity, but unfortunately it does not preserve positivity: even
if @xmath is pd, @xmath always has zeros (e.g., when @xmath ). Hence,
though we now have access to an even form, we still cannot use Polyá’s
property as @xmath is not positive. This is what leads us to consider
the slightly more complicated form @xmath in ( 4.9 ).

###### Theorem 4.4.2 (Powers and Reznick [160]).

Let @xmath , @xmath , and write @xmath Denote the standard simplex by
@xmath . Assume that @xmath is a form of degree @xmath that is positive
on @xmath and let

  -- -------- --
     @xmath   
  -- -------- --

Define @xmath We have:

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath . ⁴ ⁴ 4 As defined, @xmath is a submultiplicative norm; see [
176 ] .

Then, the coefficients of

  -- -------- --
     @xmath   
  -- -------- --

are nonnegative for @xmath .

Note that here the bound is given in the case where one considers the
alternative (but equivalent) formulation of Polyá’s Positivstellensatz
to the one given in Theorem 4.1.6 , i.e., when one is concerned with
positivity of a form over the simplex. The result can easily be adapted
to the formulation where one considers global positivity of an even form
as shown below.

###### Lemma 4.4.3.

Let @xmath be an even form of degree @xmath that is positive definite.
Let @xmath be its minimum on @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

has nonnegative coefficients for @xmath .

###### Proof.

Let @xmath . Since @xmath on @xmath , then @xmath on @xmath Indeed, by
contradiction, suppose that there exists @xmath such that @xmath (where
@xmath ) and let @xmath . Note that as @xmath , we have @xmath .
Furthermore, @xmath which contradicts the assumption. Hence, using
Theorem 6.4.3 , we have that when @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

has nonnegative coefficients. Hence,

  -- -------- --
     @xmath   
  -- -------- --

also has nonnegative coefficients. ∎

Before we proceed with the proof of Theorem 4.4.1 , we need the
following lemma.

###### Lemma 4.4.4.

Let

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

where @xmath is defined as in ( 4.3 ) and let

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is positive definite, there exists @xmath such that @xmath ,
for all @xmath .

###### Proof.

As @xmath is positive definite, there exists a positive integer @xmath
such that @xmath is positive definite for all @xmath and hence

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

is nonnegative for all @xmath . Recall now that @xmath is a norm for
@xmath and that

  -- -------- --
     @xmath   
  -- -------- --

This implies that

  -- -------- --
     @xmath   
  -- -------- --

and hence in view of ( 4.12 ) and the definition of @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

This enables us to conclude that

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

Further, notice that using properties of the norm, we have the following
chain of inequalities for any positive integer @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

As a consequence, combining this with the definition of @xmath and (
4.13 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Now taking @xmath , we have @xmath ∎

We now proceed with the proof of Theorem 4.4.1 .

###### Proof.

(Proof of Theorem 4.4.1 ) By definition, the sequence @xmath is
nondecreasing. We show that it is upperbounded by @xmath by showing that
if @xmath is such that

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , then @xmath must be positive definite. Then Theorem
4.2.1 gives us that @xmath is a strict lower bound on ( 4.1 ). As @xmath
for any such @xmath , we have that @xmath and hence @xmath

Assume that @xmath is such that

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath . By definition of @xmath and as @xmath is nonnegative,
we get that the form

  -- -------- --
     @xmath   
  -- -------- --

is nonnegative. This implies that

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

which gives

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

Indeed, suppose that there exists @xmath such that ( 4.15 ) does not
hold. Then, let @xmath and @xmath . Note that both @xmath and @xmath are
nonnegative so we can take @xmath and @xmath We further have that as
@xmath and @xmath , @xmath . Substituting @xmath by @xmath in ( 4.15 )
then violates ( 4.14 ). Using ( 4.15 ), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

and that @xmath is positive definite.

We now show that the hierarchy converges, i.e., that @xmath . To do
this, we show that if @xmath is a strict lower bound on ( 4.1 ), or
equivalently from Theorem 4.2.1 , if @xmath is positive definite, then
there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is pd, there exists a positive integer @xmath such that
@xmath is pd for any @xmath . This implies that @xmath is nonnegative
and

  -- -------- --
     @xmath   
  -- -------- --

is positive definite for @xmath . Using Lemma 4.4.3 and the definition
of @xmath in Lemma 4.4.4 , for any @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

has nonnegative coefficients. From Lemma 4.4.4 , there exists @xmath
such that @xmath implies @xmath Taking @xmath and considering @xmath as
defined in ( 4.11 ), we get that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

has nonnegative coefficients, which is the desired result. This is
because

  -- -------- --
     @xmath   
  -- -------- --

has nonnegative coefficients as @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

has nonnegative coefficients as @xmath , and that the product of two
polynomials with nonnegative coefficients has nonnegative coefficients.
∎

###### Corollary 4.4.5 (An optimization-free Positivstellensatz).

Consider the basic semialgebraic set

  -- -------- --
     @xmath   
  -- -------- --

and a polynomial @xmath . Suppose that @xmath is contained within a ball
of radius @xmath . Let @xmath and @xmath be any finite upperbounds on
@xmath and, respectively, @xmath over the set @xmath . ⁵ ⁵ 5 Once again,
as discussed at the beginning of Section 4.2 , such bounds are very
easily computable. Let @xmath be such that @xmath is the smallest even
integer larger than or equal to the maximum degree of @xmath . Then,
@xmath for all @xmath if and only if there exists a positive integer
@xmath such that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

has nonnegative coefficients, where the form @xmath in variables

  -- -------- --
     @xmath   
  -- -------- --

is as follows:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

###### Proof.

This is an immediate corollary of arguments given in the proof of
Theorem 4.2.1 and in the proof of Theorem 4.4.1 for the case where
@xmath ∎

##### 4.4.2 Linear programming and second-order cone programming-based
hierarchies for POPs

In this section, we present a linear programming and a second-order cone
programming-based hierarchy for general POPs which by construction
converge faster than the hierarchy presented in Section 4.4.1 . These
hierarchies are based on the recently-introduced concepts of dsos and
sdsos polynomials [ 9 ] which we briefly revisit below to keep the
presentation self-contained.

###### Definition 4.4.6.

A symmetric matrix @xmath is said to be

-   diagonally dominant (dd) if @xmath for all @xmath .

-   scaled diagonally dominant (sdd) if there exists a diagonal matrix
    @xmath with positive diagonal entries, such that @xmath is dd.

We have the following implications as a consequence of Gershgorin’s
circle theorem:

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

Requiring @xmath to be dd (resp. sdd) can be encoded via a linear
program (resp. a second-order cone program) (see [ 9 ] for more
details). These notions give rise to the concepts of dsos and sdsos
polynomials.

###### Definition 4.4.7 ([9]).

Let @xmath be the vector of monomials in @xmath of degree @xmath . A
form @xmath is said to be

-   diagonally-dominant-sum-of-squares (dsos) if it admits a
    representation

      -- -------- --
         @xmath   
      -- -------- --

-   scaled-diagonally-dominant-sum-of-squares (sdsos) if it admits a
    representation

      -- -------- --
         @xmath   
      -- -------- --

The following implications are a consequence of ( 5.10 ):

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

Given the fact that our Gram matrices and polynomials are related to
each other via linear equalities, it should be clear that optimizing
over the set of dsos (resp. sdsos) polynomials is an LP (resp. SOCP).

We now present our LP and SOCP-based hierarchies for POPs.

###### Corollary 4.4.8.

Recall the definition of @xmath as given in ( 4.3 ), with @xmath and
@xmath , and let @xmath be as in ( 4.11 ). Consider the hierarchy of
optimization problems indexed by @xmath :

  -- -------- -------- -------- -------- -------- --------
     @xmath   @xmath            @xmath            (4.18)
                                         @xmath   
                       @xmath                     
  -- -------- -------- -------- -------- -------- --------

Let @xmath . Then, @xmath for all @xmath , @xmath is nondecreasing, and
we have @xmath .

###### Proof.

This is an immediate consequence of the fact that any even form @xmath
with nonnegative coefficients can be written as @xmath where @xmath is
diagonal and has nonnegative (diagonal) entries. As such a @xmath is dd
(and also sdd), we conclude that @xmath is dsos (and also sdsos). The
corollary then follows from Theorem 4.4.1 . ∎

Note that similarly to our previous hierarchies, one must proceed by
bisection on @xmath to solve the level @xmath of the hierarchy. At each
step of the hierarchy, we solve a linear program (resp. second-order
cone program) that searches for the coefficients of @xmath that make
@xmath dsos (resp. sdsos) and @xmath dsos (resp. sdsos).

There is a trade-off between the hierarchies developed in this
subsection and the one developed in the previous subsection: the
hierarchy of Section 4.4.1 is optimization-free whereas those of Section
4.4.2 use linear or second-order cone programming. Hence the former
hierarchy is faster to run at each step. However, the latter hierarchies
could potentially take fewer levels to converge. This is similar to the
trade-off observed between the hierarchies presented in Theorems 4.3.2
and 4.3.4 .

#### 4.5 Open problems

To conclude, we present two open problems spawned by the writing of this
chapter. The first one concerns the assumptions needed to construct our
hierarchies.

###### Open problem 1

Theorems 4.2.1 and 4.2.4 require that the feasible set @xmath of the POP
given in ( 4.1 ) be contained in a ball of radius @xmath . Can these
theorems be extended to the case where there is no compactness
assumption on @xmath ?

The second open problem is linked to the Artin and Reznick cones
presented in Definition 4.3.1 .

###### Open problem 2

As mentioned before, Reznick cones @xmath are convex for all @xmath . We
are unable to prove however that Artin cones @xmath are convex (even
though they satisfy properties (a)-(d) of Theorem 4.2.4 like Reznick
cones do). Are Artin cones convex for all @xmath ? We know that they are
convex for @xmath and for @xmath large enough as they give respectively
the sos and psd cones (see [ 126 ] for the latter claim). However, we do
not know the answer already for @xmath .

## Part II Optimizing over Convex Polynomials

### Chapter 5 DC Decomposition of Nonconvex Polynomials with Algebraic
Techniques

#### 5.1 Introduction

A difference of convex (dc) program is an optimization problem of the
form

  -- -- -------- -------- -------
        @xmath            (5.1)
                 @xmath   
  -- -- -------- -------- -------

where @xmath are difference of convex functions; i.e.,

  -- -- -------- -- -------
        @xmath      (5.2)
  -- -- -------- -- -------

and @xmath are convex functions. The class of functions that can be
written as a difference of convex functions is very broad containing for
instance all functions that are twice continuously differentiable [ 85 ]
, [ 94 ] . Furthermore, any continuous function over a compact set is
the uniform limit of a sequence of dc functions; see, e.g., reference [
98 ] where several properties of dc functions are discussed.

Optimization problems that appear in dc form arise in a wide range of
applications. Representative examples from the literature include
machine learning and statistics (e.g., kernel selection [ 17 ] , feature
selection in support vector machines [ 95 ] , sparse principal component
analysis [ 123 ] , and reinforcement learning [ 157 ] ), operations
research (e.g., packing problems and production-transportation problems
[ 189 ] ), communications and networks [ 16 ] , [ 127 ] , circuit design
[ 123 ] , finance and game theory [ 76 ] , and computational chemistry [
66 ] . We also observe that dc programs can encode constraints of the
type @xmath by replacing them with the dc constraints @xmath . This
entails that any binary optimization problem can in theory be written as
a dc program, but it also implies that dc problems are hard to solve in
general.

As described in [ 184 ] , there are essentially two schools of thought
when it comes to solving dc programs. The first approach is global and
generally consists of rewriting the original problem as a concave
minimization problem (i.e., minimizing a concave function over a convex
set; see [ 190 ] , [ 188 ] ) or as a reverse convex problem (i.e., a
convex problem with a linear objective and one constraint of the type
@xmath where @xmath is convex). We refer the reader to [ 187 ] for an
explanation on how one can convert a dc program to a reverse convex
problem, and to [ 93 ] for more general results on reverse convex
programming. These problems are then solved using branch-and-bound or
cutting plane techniques (see, e.g., [ 189 ] or [ 98 ] ). The goal of
these approaches is to return global solutions but their main drawback
is scalibility. The second approach by contrast aims for local solutions
while still exploiting the dc structure of the problem by applying the
tools of convex analysis to the two convex components of a dc
decomposition. One such algorithm is the Difference of Convex Algorithm
(DCA) introduced by Pham Dinh Tao in [ 185 ] and expanded on by Le Thi
Hoai An and Pham Dinh Tao. This algorithm exploits the duality theory of
dc programming [ 186 ] and is popular because of its ease of
implementation, scalability, and ability to handle nonsmooth problems.

In the case where the functions @xmath and @xmath in ( 5.2 ) are
differentiable, DCA reduces to another popular algorithm called the
Convex-Concave Procedure (CCP) [ 107 ] . The idea of this technique is
to simply replace the concave part of @xmath (i.e., @xmath ) by a linear
overestimator as described in Algorithm 1 . By doing this, problem ( 5.1
) becomes a convex optimization problem that can be solved using tools
from convex analysis. The simplicity of CCP has made it an attractive
algorithm in various areas of application. These include statistical
physics (for minimizing Bethe and Kikuchi free energy functions [ 198 ]
), machine learning [ 123 ] , [ 70 ] , [ 40 ] , and image processing [
196 ] , just to name a few. In addition, CCP enjoys two valuable
features: (i) if one starts with a feasible solution, the solution
produced after each iteration remains feasible, and (ii) the objective
value improves in every iteration, i.e., the method is a descent
algorithm. The proof of both claims readily comes out of the description
of the algorithm and can be found, e.g., in [ 123 , Section 1.3.] ,
where several other properties of the method are also laid out. Like
many iterative algorithms, CCP relies on a stopping criterion to end.
This criterion can be chosen amongst a few alternatives. For example,
one could stop if the value of the objective does not improve enough, or
if the iterates are too close to one another, or if the norm of the
gradient of @xmath gets small.

1: @xmath

2: @xmath

3: while stopping criterion not satisfied do

4: Convexify: @xmath

5: Solve convex subroutine: @xmath , s.t. @xmath

6: @xmath

7: @xmath

8: end while

9: @xmath

Algorithm 1 CCP

Convergence results for CCP can be derived from existing results found
for DCA, since CCP is a subcase of DCA as mentioned earlier. But CCP can
also be seen as a special case of the family of
majorization-minimization (MM) algorithms. Indeed, the general concept
of MM algorithms is to iteratively upperbound the objective by a convex
function and then minimize this function, which is precisely what is
done in CCP. This fact is exploited by Lanckriet and Sriperumbudur in [
107 ] and Salakhutdinov et al. in [ 170 ] to obtain convergence results
for the algorithm, showing, e.g., that under mild assumptions, CCP
converges to a stationary point of the optimization problem ( 5.1 ).

##### 5.1.1 Motivation and organization of the chapter

Although a wide range of problems already appear in dc form ( 5.2 ),
such a decomposition is not always available. In this situation,
algorithms of dc programming, such as CCP, generally fail to be
applicable. Hence, the question arises as to whether one can
(efficiently) compute a difference of convex decomposition (dcd) of a
given function. This challenge has been raised several times in the
literature. For instance, Hiriart-Urruty [ 94 ] states “All the proofs
[of existence of dc decompositions] we know are “constructive” in the
sense that they indeed yield [ @xmath ] and [ @xmath ] satisfying ( 5.2
) but could hardly be carried over [to] computational aspects”. As
another example, Tuy [ 189 ] writes: “The dc structure of a given
problem is not always apparent or easy to disclose, and even when it is
known explicitly, there remains for the problem solver the hard task of
bringing this structure to a form amenable to computational analysis.”

Ideally, we would like to have not just the ability to find one dc
decomposition, but also to optimize over the set of valid dc
decompositions. Indeed, dc decompositions are not unique: Given a
decomposition @xmath , one can produce infinitely many others by writing
@xmath for any convex function @xmath . This naturally raises the
question whether some dc decompositions are better than others, for
example for the purposes of CCP.

In this chapter we consider these decomposition questions for
multivariate polynomials. Since polynomial functions are finitely
parameterized by their coefficients, they provide a convenient setting
for a computational study of the dc decomposition questions. Moreover,
in most practical applications, the class of polynomial functions is
large enough for modeling purposes as polynomials can approximate any
continuous function on compact sets with arbitrary accuracy. It could
also be interesting for future research to explore the potential of dc
programming techniques for solving the polynomial optimization problem.
This is the problem of minimizing a multivariate polynomial subject to
polynomial inequalities and is currently an active area of research with
applications throughout engineering and applied mathematics. In the case
of quadratic polynomial optimization problems, the dc decomposition
approach has already been studied [ 33 ] , [ 96 ] .

With these motivations in mind, we organize the chapter as follows. In
Section 5.2 , we start by showing that unlike the quadratic case, the
problem of testing if two given polynomials @xmath form a valid dc
decomposition of a third polynomial @xmath is NP-hard (Proposition 5.2.2
). We then investigate a few candidate optimization problems for finding
dc decompositions that speed up the convex-concave procedure. In
particular, we extend the notion of an undominated dc decomposition from
the quadratic case [ 33 ] to higher order polynomials. We show that an
undominated dcd always exists (Theorem 5.2.6 ) and can be found by
minimizing a certain linear function of one of the two convex functions
in the decomposition. However, this optimization problem is proved to be
NP-hard for polynomials of degree four or larger (Proposition 5.2.7 ).
To cope with intractability of finding optimal dc decompositions, we
propose in Section 5.3 a class of algebraic relaxations that allow us to
optimize over subsets of dcds. These relaxations will be based on the
notions of dsos-convex, sdsos-convex, and sos-convex polynomials (see
Definition 5.3.3 ), which respectively lend themselves to linear, second
order cone, and semidefinite programming . In particular, we show that a
dc decomposition can always be found by linear programming (Theorem
5.3.5 ). Finally, in Section 5.4 , we perform some numerical experiments
to compare the scalability and performance of our different algebraic
relaxations.

#### 5.2 Polynomial dc decompositions and their complexity

To study questions around dc decompositions of polynomials more
formally, let us start by introducing some notation. A multivariate
polynomial @xmath in variables @xmath is a function from @xmath to
@xmath that is a finite linear combination of monomials:

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where the sum is over @xmath -tuples of nonnegative integers @xmath .
The degree of a monomial @xmath is equal to @xmath . The degree of a
polynomial @xmath is defined to be the highest degree of its component
monomials. A simple counting argument shows that a polynomial of degree
@xmath in @xmath variables has @xmath coefficients. A homogeneous
polynomial (or a form ) is a polynomial where all the monomials have the
same degree. An @xmath -variate form @xmath of degree @xmath has @xmath
coefficients. We denote the set of polynomials (resp. forms) of degree
@xmath in @xmath variables by @xmath (resp. @xmath ).

Recall that a symmetric matrix @xmath is positive semidefinite (psd) if
@xmath for all @xmath ; this will be denoted by the standard notation
@xmath Similarly, a polynomial @xmath is said to be nonnegative or
positive semidefinite if @xmath for all @xmath . For a polynomial @xmath
, we denote its Hessian by @xmath . The second order characterization of
convexity states that @xmath is convex if and only if @xmath , @xmath

###### Definition 5.2.1.

We say a polynomial @xmath is a dcd of a polynomial @xmath if @xmath is
convex and @xmath is convex.

Note that if we let @xmath , then indeed we are writing @xmath as a
difference of two convex functions @xmath It is known that any
polynomial @xmath has a (polynomial) dcd @xmath . A proof of this is
given, e.g., in [ 196 ] , or in Section 5.3.2 , where it is obtained as
corollary of a stronger theorem (see Corollary 5.3.6 ). By default, all
dcds considered in the sequel will be of even degree. Indeed, if @xmath
is of even degree @xmath , then it admits a dcd @xmath of degree @xmath
. If @xmath is of odd degree @xmath , it can be viewed as a polynomial
@xmath of even degree @xmath with highest-degree coefficients which are
0. The previous result then remains true, and @xmath admits a dcd of
degree @xmath .

Our results show that such a decomposition can be found efficiently
(e.g., by linear programming); see Theorem 5.3.7 . Interestingly enough
though, it is not easy to check if a candidate @xmath is a valid dcd of
@xmath .

###### Proposition 5.2.2.

Given two @xmath -variate polynomials @xmath and @xmath of degree 4,
with @xmath , it is strongly NP-hard ¹ ¹ 1 For a strongly NP-hard
problem, even a pseudo-polynomial time algorithm cannot exist unless
P=NP [ 71 ] . to determine whether @xmath is a dcd of @xmath . ² ² 2 If
we do not add the condition on the input that @xmath , the problem would
again be NP-hard (in fact, this is even easier to prove). However, we
believe that in any interesting instance of this question, one would
have @xmath .

###### Proof.

We will show this via a reduction from the problem of testing
nonnegativity of biquadratic forms, which is already known to be
strongly NP-hard [ 122 ] , [ 10 ] . A biquadratic form @xmath in the
variables @xmath and @xmath is a quartic form that can be written as

  -- -------- --
     @xmath   
  -- -------- --

Given a biquadratic form @xmath , define the @xmath polynomial matrix
@xmath by setting @xmath and let @xmath be the largest coefficient in
absolute value of any monomial present in some entry of @xmath .
Moreover, we define

  -- -------- --
     @xmath   
  -- -------- --

It is proven in [ 10 , Theorem 3.2.] that @xmath is nonnegative if and
only if

  -- -------- --
     @xmath   
  -- -------- --

is convex. We now give our reduction. Given a biquadratic form @xmath ,
we take @xmath and @xmath . If @xmath is nonnegative, from the theorem
quoted above, @xmath is convex. Furthermore, it is straightforward to
establish that @xmath is convex, which implies that @xmath is also
convex. This means that @xmath is a dcd of @xmath . If @xmath is not
nonnegative, then we know that @xmath is not convex. This implies that
@xmath is not convex, and so @xmath cannot be a dcd of @xmath . ∎

Unlike the quartic case, it is worth noting that in the quadratic case,
it is easy to test whether a polynomial @xmath is a dcd of @xmath .
Indeed, this amounts to testing whether @xmath and @xmath which can be
done in @xmath time.

As mentioned earlier, there is not only one dcd for a given polynomial
@xmath , but an infinite number. Indeed, if @xmath with @xmath and
@xmath convex then any convex polynomial @xmath generates a new dcd
@xmath . It is natural then to investigate if some dcds are better than
others, e.g., for use in the convex-concave procedure.

Recall that the main idea of CCP is to upperbound the non-convex
function @xmath by a convex function @xmath . These convex functions are
obtained by linearizing @xmath around the optimal solution of the
previous iteration. Hence, a reasonable way of choosing a good dcd would
be to look for dcds of @xmath that minimize the curvature of @xmath
around a point. Two natural formulations of this problem are given
below. The first one attempts to minimize the average ³ ³ 3 Note that
@xmath (resp. @xmath ) gives the average (resp. maximum) of @xmath over
@xmath . curvature of @xmath at a point @xmath over all directions:

  -- -- -------- -------- -------
        @xmath            (5.4)
                 @xmath   
  -- -- -------- -------- -------

The second one attempts to minimize the worst-case ^(†) ^(†)
footnotemark: curvature of @xmath at a point @xmath over all directions:

  -- -- -------- -------- -------
        @xmath            (5.5)
                 @xmath   
  -- -- -------- -------- -------

A few numerical experiments using these objective functions will be
presented in Section 5.4.2 .

Another popular notion that appears in the literature and that also
relates to finding dcds with minimal curvature is that of undominated
dcds. These were studied in depth by Bomze and Locatelli in the
quadratic case [ 33 ] . We extend their definition to general
polynomials here.

###### Definition 5.2.3.

Let @xmath be a dcd of @xmath . A dcd @xmath of @xmath is said to
dominate @xmath if @xmath is convex and nonaffine. A dcd @xmath of
@xmath is undominated if no dcd of @xmath dominates @xmath .

Arguments for chosing undominated dcds can be found in [ 33 ] , [ 62 ,
Section 3] . One motivation that is relevant to CCP appears in
Proposition 5.2.4 ⁴ ⁴ 4 A variant of this proposition in the quadratic
case appears in [ 33 , Proposition 12] . . Essentially, the proposition
shows that if we were to start at some initial point and apply one
iteration of CCP, the iterate obtained using a dc decomposition @xmath
would always beat an iterate obtained using a dcd dominated by @xmath .

###### Proposition 5.2.4.

Let @xmath and @xmath be two dcds of @xmath . Define the convex
functions @xmath and @xmath , and assume that @xmath dominates @xmath .
For a point @xmath in @xmath , define the convexified versions of @xmath

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Then, we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As @xmath dominates @xmath , there exists a nonaffine convex polynomial
@xmath such that @xmath . We then have @xmath and @xmath , and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The first order characterization of convexity of @xmath then gives us

  -- -------- --
     @xmath   
  -- -------- --

∎

In the quadratic case, it turns out that an optimal solution to ( 5.4 )
is an undominated dcd [ 33 ] . A solution given by ( 5.5 ) on the other
hand is not necessarily undominated. Consider the quadratic function

  -- -------- --
     @xmath   
  -- -------- --

and assume that we want to decompose it using ( 5.5 ). An optimal
solution is given by @xmath and @xmath with @xmath This is clearly
dominated by @xmath as @xmath which is convex.

When the degree is higher than 2, it is no longer true however that
solving ( 5.4 ) returns an undominated dcd. Consider for example the
degree-4 polynomial

  -- -------- --
     @xmath   
  -- -------- --

A solution to ( 5.4 ) with @xmath is given by @xmath and @xmath (as
@xmath ). This is dominated by the dcd @xmath and @xmath as @xmath is
clearly convex.

It is unclear at this point how one can obtain an undominated dcd for
higher degree polynomials, or even if one exists. In the next theorem,
we show that such a dcd always exists and provide an optimization
problem whose optimal solution(s) will always be undominated dcds. This
optimization problem involves the integral of a polynomial over a sphere
which conveniently turns out to be an explicit linear expression in its
coefficients.

###### Proposition 5.2.5 ([67]).

Let @xmath denote the unit sphere in @xmath . For a monomial @xmath ,
define @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the gamma function, and @xmath is the rotation
invariant probability measure on @xmath

###### Theorem 5.2.6.

Let @xmath Consider the optimization problem

  -- -------- -------- -------- -------
     @xmath   @xmath            (5.6)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

where @xmath is a normalization constant which equals the area of @xmath
. Then, an optimal solution to ( 5.6 ) exists and any optimal solution
is an undominated dcd of @xmath .

Note that problem ( 5.6 ) is exactly equivalent to ( 5.4 ) in the case
where @xmath and so can be seen as a generalization of the quadratic
case.

###### Proof.

We first show that an optimal solution to ( 5.6 ) exists. As any
polynomial @xmath admits a dcd, ( 5.6 ) is feasible. Let @xmath be a dcd
of @xmath and define @xmath Consider the optimization problem given by (
5.6 ) with the additional constraints:

  -- -------- -------- -------- -------
     @xmath   @xmath            (5.7)
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Notice that any optimal solution to ( 5.7 ) is an optimal solution to (
5.6 ). Hence, it suffices to show that ( 5.7 ) has an optimal solution.
Let @xmath denote the feasible set of ( 5.7 ). Evidently, the set @xmath
is closed and @xmath is continuous. If we also show that @xmath is
bounded, we will know that the optimal solution to ( 5.7 ) is achieved.
To see this, assume that @xmath is unbounded. Then for any @xmath ,
there exists a coefficient @xmath of some @xmath that is larger than
@xmath . By absence of affine terms in @xmath , @xmath features in an
entry of @xmath as the coefficient of a nonzero monomial. Take @xmath
such that this monomial evaluated at @xmath is nonzero: this entails
that at least one entry of @xmath can get arbitrarily large. However,
since @xmath is continuous and @xmath , @xmath such that @xmath , @xmath
. This, combined with the fact that @xmath , implies that @xmath , which
contradicts the fact that an entry of @xmath can get arbitrarily large.

We now show that if @xmath is any optimal solution to ( 5.6 ), then
@xmath is an undominated dcd of @xmath . Suppose that this is not the
case. Then, there exists a dcd @xmath of @xmath such that @xmath is
nonaffine and convex. As @xmath is a dcd of @xmath , @xmath is feasible
for ( 5.6 ). The fact that @xmath is nonaffine and convex implies that

  -- -------- --
     @xmath   
  -- -------- --

which contradicts the assumption that @xmath is optimal to ( 5.6 ). ∎

Although optimization problem ( 5.6 ) is guaranteed to produce an
undominated dcd, we show that unfortunately it is intractable to solve.

###### Proposition 5.2.7.

Given an n-variate polynomial @xmath of degree 4 with rational
coefficients, and a rational number @xmath , it is strongly NP-hard to
decide whether there exists a feasible solution to ( 5.6 ) with
objective value @xmath .

###### Proof.

We give a reduction from the problem of deciding convexity of quartic
polynomials. Let @xmath be a quartic polynomial. We take @xmath and
@xmath . If @xmath is convex, then @xmath is trivially a dcd of @xmath
and

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

If @xmath is not convex, assume that there exists a feasible solution
@xmath for ( 5.6 ) that satisfies ( 5.8 ). From ( 5.8 ) we have

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

But from ( 5.6 ), as @xmath is convex, @xmath Together with ( 5.9 ),
this implies that

  -- -------- --
     @xmath   
  -- -------- --

which in turn implies that @xmath . To see this, note that @xmath is a
nonnegative polynomial which must be identically equal to @xmath since
its integral over the sphere is @xmath . As @xmath , we get that @xmath
Thus, @xmath , which is not possible as @xmath is convex and @xmath is
not. ∎

We remark that solving ( 5.6 ) in the quadratic case (i.e., @xmath ) is
simply a semidefinite program.

#### 5.3 Alegbraic relaxations and more tractable subsets of the set of
convex polynomials

We have just seen in the previous section that for polynomials with
degree as low as four, some basic tasks related to dc decomposition are
computationally intractable. In this section, we identify three subsets
of the set of convex polynomials that lend themselves to polynomial-time
algorithms. These are the sets of sos-convex, sdsos-convex , and
dsos-convex polynomials, which will respectively lead to semidefinite,
second order cone, and linear programs. The latter two concepts are to
our knowledge new and are meant to serve as more scalable alternatives
to sos-convexity. All three concepts certify convexity of polynomials
via explicit algebraic identities, which is the reason why we refer to
them as algebraic relaxations.

##### 5.3.1 DSOS-convexity, SDSOS-convexity, SOS-convexity

To present these three notions we need to introduce some notation and
briefly review the concepts of sos, dsos, and sdsos polynomials.

We denote the set of nonnegative polynomials (resp. forms) in @xmath
variables and of degree @xmath by @xmath (resp. @xmath ). A polynomial
@xmath is a sum of squares (sos) if it can be written as @xmath for some
polynomials @xmath . The set of sos polynomials (resp. forms) in @xmath
variables and of degree @xmath is denoted by @xmath (resp. @xmath ). We
have the obvious inclusion @xmath (resp. @xmath ), which is strict
unless @xmath , or @xmath , or @xmath (resp. @xmath , or @xmath , or
@xmath ) [ 92 ] , [ 165 ] .

Let @xmath (resp. @xmath ) denote the vector of all monomials in @xmath
of degree up to (resp. exactly) @xmath ; the length of this vector is
@xmath (resp. @xmath ). It is well known that a polynomial (resp. form)
@xmath of degree @xmath is sos if and only if it can be written as
@xmath (resp. @xmath ), for some psd matrix @xmath [ 153 ] , [ 152 ] .
The matrix @xmath is generally called the Gram matrix of @xmath . An SOS
optimization problem is the problem of minimizing a linear function over
the intersection of the convex cone @xmath with an affine subspace. The
previous statement implies that SOS optimization problems can be cast as
semidefinite programs.

We now define dsos and sdsos polynomials, which were recently proposed
by Ahmadi and Majumdar [ 9 ] , [ 7 ] as more tractable subsets of sos
polynomials. When working with dc decompositions of @xmath -variate
polynomials, we will end up needing to impose sum of squares conditions
on polynomials that have @xmath variables (see Definition 5.3.3 ). While
in theory the SDPs arising from sos conditions are of polynomial size,
in practice we rather quickly face a scalability challenge. For this
reason, we also consider the class of dsos and sdsos polynomials, which
while more restrictive than sos polynomials, are considerably more
tractable. For example, Table 5.2 in Section 5.4.2 shows that when
@xmath , dc decompositions using these concepts are about 250 times
faster than an sos-based approach. At @xmath variables, we are unable to
run the sos-based approach on our machine. With this motivation in mind,
let us start by recalling some concepts from linear algebra.

###### Definition 5.3.1.

A symmetric matrix @xmath is said to be diagonally dominant (dd) if
@xmath for all @xmath , and strictly diagonally dominant if @xmath for
all @xmath . We say that @xmath is scaled diagonally dominant (sdd) if
there exists a diagonal matrix @xmath with positive diagonal entries,
such that @xmath is dd.

We have the following implications from Gershgorin’s circle theorem

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

Furthermore, notice that requiring @xmath to be dd can be encoded via a
linear program (LP) as the constraints are linear inequalities in the
coefficients of @xmath . Requiring that @xmath be sdd can be encoded via
a second order cone program (SOCP). This follows from the fact that
@xmath is sdd if and only if

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath is an @xmath symmetric matrix with zeros everywhere
except four entries @xmath which must make the @xmath matrix @xmath
symmetric positive semidefinite [ 9 ] . These constraints are rotated
quadratic cone constraints and can be imposed via SOCP [ 15 ] .

###### Definition 5.3.2 ([9]).

A polynomial @xmath is said to be

-   diagonally-dominant-sum-of-squares (dsos) if it admits a
    representation @xmath , where @xmath is a dd matrix.

-   scaled-diagonally-dominant-sum-of-squares (sdsos) it it admits a
    representation @xmath where @xmath is an sdd matrix.

Identical conditions involving @xmath instead of @xmath define the sets
of dsos and sdsos forms.

The following implications are again straightforward:

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

Given the fact that our Gram matrices and polynomials are related to
each other via linear equalities, it should be clear that optimizing
over the set of dsos (resp. sdsos, sos) polynomials is an LP (resp.
SOCP, SDP).

Let us now get back to convexity.

###### Definition 5.3.3.

Let @xmath be a vector of variables. A polynomial @xmath is said to be

-   dsos-convex if @xmath is dsos (as a polynomial in @xmath and @xmath
    ).

-   sdsos-convex if @xmath is sdsos (as a polynomial in @xmath and
    @xmath ).

-   sos-convex if @xmath is sos (as a polynomial in @xmath and @xmath ).
    ⁵ ⁵ 5 The notion of sos-convexity has already appeared in the study
    of semidefinite representability of convex sets [ 89 ] and in
    applications such as shaped-constrained regression in statistics [
    130 ] .

We denote the set of dsos-convex (resp. sdsos-convex, sos-convex,
convex) forms in @xmath by @xmath (resp. @xmath , @xmath , @xmath ).
Similarly, @xmath (resp. @xmath , @xmath , @xmath ) denote the set of
dsos-convex (resp. sdsos-convex, sos-convex, convex) polynomials in
@xmath .

The following inclusions

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

are a direct consequence of ( 5.11 ) and the second-order necessary and
sufficient condition for convexity which reads

  -- -------- --
     @xmath   
  -- -------- --

Optimizing over @xmath (resp. @xmath , @xmath ) is an LP (resp. SOCP,
SDP). The same statements are true for @xmath , @xmath and @xmath .

Let us draw these sets for a parametric family of polynomials

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

Here, @xmath and @xmath are parameters. It is known that for bivariate
quartics, all convex polynomials are sos-convex; i.e., @xmath ⁶ ⁶ 6 In
general, constructing polynomials that are convex but not sos-convex
seems to be a nontrivial task [ 11 ] . A complete characterization of
the dimensions and degrees for which convexity and sos-convexity are
equivalent is given in [ 12 ] . To obtain Figure 5.1 , we fix @xmath to
some value and then plot the values of @xmath and @xmath for which
@xmath is s/d/sos-convex. As we can see, the quality of the inner
approximation of the set of convex polynomials by the sets of
dsos/sdsos-convex polynomials can be very good (e.g., @xmath ) or less
so (e.g., @xmath ).

##### 5.3.2 Existence of difference of s/d/sos-convex decompositions of
polynomials

The reason we introduced the notions of s/d/sos-convexity is that in our
optimization problems for finding dcds, we would like to replace the
condition

  -- -------- --
     @xmath   
  -- -------- --

with the computationally tractable condition

  -- -------- --
     @xmath   
  -- -------- --

The first question that needs to be addressed is whether for any
polynomial such a decomposition exists. In this section, we prove that
this is indeed the case. This in particular implies that a dcd can be
found efficiently.

We start by proving a lemma about cones.

###### Lemma 5.3.4.

Consider a vector space @xmath and a full-dimensional cone @xmath .
Then, any @xmath can be written as @xmath where @xmath

###### Proof.

Let @xmath . If @xmath , then we take @xmath and @xmath . Assume now
that @xmath and let @xmath be any element in the interior of the cone
@xmath . As @xmath , there exists @xmath such that @xmath Rewriting the
previous equation, we obtain

  -- -------- --
     @xmath   
  -- -------- --

By taking @xmath and @xmath , we observe that @xmath and @xmath . ∎

The following theorem is the main result of the section.

###### Theorem 5.3.5.

Any polynomal @xmath can be written as the difference of two dsos-convex
polynomials in @xmath

###### Corollary 5.3.6.

Any polynomial @xmath can be written as the difference of two
sdsos-convex, sos-convex, or convex polynomials in @xmath .

###### Proof.

This is straightforward from the inclusions

  -- -------- --
     @xmath   
  -- -------- --

∎

In view of Lemma 5.3.4 , it suffices to show that @xmath is full
dimensional in the vector space @xmath to prove Theorem 5.3.5 . We do
this by constructing a polynomial in @xmath for any @xmath .

Recall that @xmath (resp. @xmath ) denotes the vector of all monomials
in @xmath of degree exactly (resp. up to) @xmath . If @xmath is a vector
of variables of length @xmath , we define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath Analogously, we define

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 5.3.7.

For all @xmath , there exists a polynomial @xmath such that

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

where @xmath is strictly dd.

Any such polynomial will be in @xmath . Indeed, if we were to pertub the
coefficients of @xmath slightly, then each coefficient of @xmath would
undergo a slight perturbation. As @xmath is strictly dd, @xmath would
remain dd, and hence @xmath would remain dsos-convex.

We will prove Theorem 5.3.7 through a series of lemmas. First, we show
that this is true in the homogeneous case and when @xmath (Lemma 5.3.8
). By induction, we prove that this result still holds in the
homogeneous case for any @xmath (Lemma 5.3.9 ). We then extend this
result to the nonhomogeneous case.

###### Lemma 5.3.8.

For all @xmath , there exists a polynomial @xmath such that

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

for some strictly dd matrix @xmath .

We remind the reader that Lemma 5.3.8 corresponds to the base case of a
proof by induction on @xmath for Theorem 5.3.7 .

###### Proof.

In this proof, we show that there exists a polynomial @xmath that
satisfies ( 5.15 ) for some strictly dd matrix @xmath in the case where
@xmath , and for any @xmath

First, if @xmath , we simply take @xmath as @xmath and the identity
matrix is strictly dd. Now, assume @xmath . We consider two cases
depending on whether @xmath is divisible by @xmath .

In the case that it is, we construct @xmath as

  -- -------- --
     @xmath   
  -- -------- --

with the sequence @xmath defined as follows

  -- -------- -------- -------- --------
     @xmath   @xmath            (5.16)
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --------

Let

  -- -------- -------- -------- --------
     @xmath   @xmath            (5.17)
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --------

We claim that the matrix @xmath defined as

  -- -- --
        
  -- -- --

is strictly dd and satisfies ( 5.15 ) with @xmath ordered as

  -- -------- --
     @xmath   
  -- -------- --

To show ( 5.15 ), one can derive the Hessian of @xmath , expand both
sides of the equation, and verify equality. To ensure that the matrix is
strictly dd, we want all diagonal coefficients to be strictly greater
than the sum of the elements on the row. This translates to the
following inequalities

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Replacing the expressions of @xmath and @xmath in the previous
inequalities using ( 5.17 ) and the values of @xmath given in ( 5.16 ),
one can easily check that these inequalities are satisfied.

We now consider the case where @xmath is not divisable by 2 and take

  -- -------- --
     @xmath   
  -- -------- --

with the sequence @xmath defined as follows

  -- -------- -------- -------- --------
     @xmath   @xmath            (5.18)
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --------

Again, we want to show existence of a strictly dd matrix @xmath that
satisfies ( 5.15 ). Without changing the definitions of the sequences
@xmath , @xmath and @xmath , we claim this time that the matrix @xmath
defined as

  -- -- --
        
  -- -- --

satisfies ( 5.15 ) and is strictly dd. Showing ( 5.15 ) amounts to
deriving the Hessian of @xmath and checking that the equality is
verified. To ensure that @xmath is strictly dd, the inequalities that
now must be verified are

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

These inequalities can all be shown to hold using ( 5.18 ).

∎

###### Lemma 5.3.9.

For all @xmath there exists a form @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and @xmath is a strictly dd matrix.

###### Proof.

We proceed by induction on @xmath with fixed and arbitrary @xmath . The
property is verified for @xmath by Lemma 5.3.8 . Suppose that there
exists a form @xmath such that

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

for some strictly dd matrix @xmath We now show that

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- -------- -------- --------
     @xmath   @xmath            (5.20)
              @xmath   @xmath   
  -- -------- -------- -------- --------

and @xmath small enough, verifies

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

for some strictly dd matrix @xmath . Equation ( 5.21 ) will actually be
proved using an equivalent formulation that we describe now. Recall that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the standard vector of monomials in @xmath of degree
exactly @xmath . Let @xmath be a vector containing all monomials from
@xmath that include up to @xmath variables in @xmath and @xmath be a
vector containing all monomials from @xmath with exactly @xmath
variables in @xmath . Obviously, @xmath is equal to

  -- -------- --
     @xmath   
  -- -------- --

up to a permutation of its entries. If we show that there exists a
strictly dd matrix @xmath such that

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

then one can easily construct a strictly dd matrix @xmath such that (
5.21 ) will hold by simply permuting the rows of @xmath appropriately.

We now show the existence of such a @xmath . To do this, we claim and
prove the following:

-   Claim 1: there exists a strictly dd matrix @xmath such that

      -- -------- -- --------
         @xmath      (5.23)
      -- -------- -- --------

-   Claim 2: there exist a symmetric matrix @xmath , and @xmath (where
    @xmath is the length of @xmath ) such that

      -- -------- -- --------
         @xmath      (5.24)
      -- -------- -- --------

Using these two claims and the fact that @xmath , we get that

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

As @xmath is strictly dd, we can pick @xmath small enough such that
@xmath is strictly dd. This entails that @xmath is strictly dd, and (
5.22 ) holds.

It remains to prove the two claims to be done.

Proof of Claim 1: Claim 1 concerns the polynomial @xmath , defined as
the sum of polynomials @xmath . Note from ( 5.19 ) that the Hessian of
each of these polynomials has a strictly dd Gram matrix in the monomial
vector @xmath However, the statement of Claim 1 involves the monomial
vector @xmath . So, we start by linking the two monomial vectors. If we
denote by

  -- -------- --
     @xmath   
  -- -------- --

then @xmath is exactly equal to @xmath as the entries of both are
monomials of degree 1 in @xmath and of degree @xmath and in @xmath
variables of @xmath

By definition of @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

We now claim that there exists a strictly dd matrix @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

This matrix is constructed by padding the strictly dd matrices @xmath
with rows of zeros and then adding them up. The sum of two rows that
verify the strict diagonal dominance condition still verifies this
condition. So we only need to make sure that there is no row in @xmath
that is all zero. This is indeed the case because @xmath

Proof of Claim 2: Let @xmath and @xmath be the @xmath element of @xmath
. To prove ( 5.24 ), we need to show that

  -- -------- -------- --------
     @xmath            (5.25)
              @xmath   
  -- -------- -------- --------

can equal

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

for some symmetric matrix @xmath and positive scalars @xmath . We first
argue that all monomials contained in @xmath appear in the expansion (
5.26 ). This means that we do not need to use any other entry of the
Gram matrix in ( 5.24 ). Since every monomial appearing in the first
double sum of ( 5.25 ) involves only even powers of variables, it can be
obtained via the diagonal entries of @xmath together with the entries
@xmath Moreover, since the coefficient of each monomial in this double
sum is positive and since the sum runs over all possible monomials
consisting of even powers in @xmath variables, we conclude that @xmath ,
for @xmath

Consider now any monomial contained in the second double sum of ( 5.25
). We claim that any such monomial can be obtained from off-diagonal
entries in @xmath To prove this claim, we show that it can be written as
the product of two monomials @xmath and @xmath with @xmath or fewer
variables in @xmath . Indeed, at least two variables in the monomial
must have degree less than or equal to @xmath . Placing one variable in
@xmath and the other variable in @xmath and then filling up @xmath and
@xmath with the remaining variables (in any fashion as long as the
degrees at @xmath and @xmath equal @xmath ) yields the desired result.

∎

###### of Theorem 5.3.7.

Let @xmath be the form constructed in the proof of Lemma 5.3.9 which is
in the interior of @xmath Let @xmath denote the strictly diagonally
dominant matrix which was constructed to satisfy

  -- -------- --
     @xmath   
  -- -------- --

To prove Theorem 5.3.7 , we take

  -- -------- --
     @xmath   
  -- -------- --

We have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

We observe that @xmath is strictly dd, which shows that @xmath ∎

###### Remark 5.3.10.

If we had only been interested in showing that any polynomial in @xmath
could be written as a difference of two sos-convex polynomials, this
could have been easily done by showing that @xmath . However, this form
is not dsos-convex or sdsos-convex for all @xmath (e.g., for @xmath and
@xmath ). We have been unable to find a simpler proof for existence of
sdsos-convex dcds that does not go through the proof of existence of
dsos-convex dcds.

###### Remark 5.3.11.

If we solve problem ( 5.6 ) with the convexity constraint replaced by a
dsos-convexity (resp. sdsos-convexity, sos-convexity) requirement, the
same arguments used in the proof of Theorem 5.2.6 now imply that the
optimal solution @xmath is not dominated by any dsos-convex (resp.
sdsos-convex, sos-convex) decomposition.

#### 5.4 Numerical results

In this section, we present a few numerical results to show how our
algebraic decomposition techniques affect the convex-concave procedure.
The objective function @xmath in all of our experiments is generated
randomly following the ensemble of [ 155 , Section 5.1.] . This means
that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a random polynomial of total degree @xmath whose
coefficients are random integers uniformly sampled from @xmath An
advantage of polynomials generated in this fashion is that they are
bounded below and that their minimum @xmath is achieved over @xmath We
have intentionally restricted ourselves to polynomials of degree equal
to @xmath in our experiments as this corresponds to the smallest degree
for which the problem of finding a dc decomposition of @xmath is hard,
without being too computationally expensive. Experimenting with higher
degrees however would be a worthwhile pursuit in future work. The
starting point of CCP was generated randomly from a zero-mean Gaussian
distribution.

One nice feature of our decomposition techniques is that all the
polynomials @xmath in line 4 of Algorithm 1 in the introduction are
sos-convex. This allows us to solve the convex subroutine of CCP exactly
via a single SDP [ 53 , Remark 3.4.] , [ 110 , Corollary 2.3.] :

  -- -- -------- -------- --------
        @xmath            (5.27)
                 @xmath   
                 @xmath   
  -- -- -------- -------- --------

The degree of @xmath here is taken to be the maximum degree of @xmath .
We could have also solved these subproblems using standard descent
algorithms for convex optimization. However, we are not so concerned
with the method used to solve this convex problem as it is the same for
all experiments. All of our numerical examples were done using MATLAB,
the polynomial optimization library SPOT [ 137 ] , and the solver MOSEK
[ 140 ] .

##### 5.4.1 Picking a good dc decomposition for CCP

In this subsection, we consider the problem of minimizing a random
polynomial @xmath over a ball of radius @xmath , where @xmath is a
random integer in @xmath The goal is to compare the impact of the dc
decomposition of the objective on the performance of CCP. To monitor
this, we decompose the objective in 4 different ways and then run CCP
using the resulting decompositions. These decompositions are obtained
through different SDPs that are listed in Table 5.1 .

The first SDP in Table 5.1 is simply a feasibility problem. The second
SDP minimizes the largest eigenvalue of @xmath at the initial point
@xmath inputed to CCP. The third minimizes the largest eigenvalue of
@xmath over the ball @xmath of radius @xmath . Indeed, let @xmath Notice
that @xmath and if @xmath , then @xmath . This implies that @xmath The
fourth SDP searches for an undominated dcd.

Once @xmath has been decomposed, we start CCP. After @xmath mins of
total runtime, the program is stopped and we recover the objective value
of the last iteration. This procedure is repeated on 30 random instances
of @xmath and @xmath , and the average of the results is presented in
Figure 5.2 .

From the figure, we can see that the choice of the initial decomposition
impacts the performance of CCP considerably, with the region formulation
of @xmath and the undominated decomposition giving much better results
than the other two. It is worth noting that all formulations have gone
through roughly the same number of iterations of CCP (approx. 400).
Furthermore, these results seem to confirm that it is best to pick an
undominated decomposition when applying CCP.

##### 5.4.2 Scalibility of s/d/sos-convex dcds and the multiple
decomposition CCP

While solving the last optimization problem in Table 5.1 usually gives
very good results, it relies on an sos-convex dc decomposition. However,
this choice is only reasonable in cases where the number of variables
and the degree of the polynomial that we want to decompose are low. When
these become too high, obtaining an sos-convex dcd can be too
time-consuming. The concepts of dsos-convexity and sdsos-convexity then
become interesting alternatives to sos-convexity. This is illustrated in
Table 5.2 , where we have reported the time taken to solve the following
decomposition problem:

  -- -- -------- -------- --------
        @xmath            (5.28)
                 @xmath   
  -- -- -------- -------- --------

In this case, @xmath is a random polynomial of degree @xmath in @xmath
variables. We also report the optimal value of ( 5.28 ) (we know that (
5.28 ) is always guaranteed to be feasible from Theorem 5.3.7 ).

Notice that for @xmath , it takes over 30 hours to obtain an sos-convex
decomposition, whereas the run times for s/dsos-convex decompositions
are still in the range of 10 seconds. This increased speed comes at a
price, namely the quality of the decomposition. For example, when @xmath
, the optimal value obtained using sos-convexity is nearly 10 times
lower than that of sdsos-convexity.

Now that we have a better quantitative understanding of this tradeoff,
we propose a modification to CCP that leverages the speed of
s/dsos-convex dcds for large @xmath . The idea is to modify CCP in such
a way that one would compute a new s/dsos-convex decomposition of the
functions @xmath after each iteration. Instead of looking for dcds that
would provide good global decompositions (such as undominated sos-convex
dcds), we look for decompositions that perform well locally. From
Section 5.2 , candidate decomposition techniques for this task can come
from formulations ( 5.4 ) and ( 5.5 ) that minimize the maximum
eigenvalue of the Hessian of @xmath at a point or the trace of the
Hessian of @xmath at a point. This modified version of CCP is described
in detail in Algorithm 2 . We will refer to it as multiple decomposition
CCP .

We compare the performance of CCP and multiple decomposition CCP on the
problem of minimizing a polynomial @xmath of degree 4 in @xmath
variables, for varying values of @xmath . In Figure 5.3 , we present the
optimal value (averaged over 30 instances) obtained after 4 mins of
total runtime. The “SDSOS” columns correspond to multiple decomposition
CCP (Algorithm 2 ) with sdsos-convex decompositions at each iteration.
The “SOS” columns correspond to classical CCP where the first and only
decomposition is an undominated sos-convex dcd. From Figure 5.2 , we
know that this formulation performs well for small values of @xmath .
This is still the case here for @xmath and @xmath . However, this
approach performs poorly for @xmath as the time taken to compute the
initial decomposition is too long. In contrast, multiple decomposition
CCP combined with sdsos-convex decompositions does slightly worse for
@xmath and @xmath , but significantly better for @xmath .

1: @xmath

2: @xmath

3: while stopping criterion not satisfied do

4: Decompose: @xmath find @xmath s/d/sos-convex that min. @xmath , s.t.
@xmath s/dd ⁸ ⁸ 8 Here dd and sdd matrices refer to notions introduced
in Definition 5.3.1 . Note that any @xmath which makes @xmath dd or sdd
gives an upperbound on @xmath By formulating the problem this way
(instead of requiring @xmath ) we obtain an LP or SOCP instead of an
SDP. and @xmath

5: Convexify: @xmath

6: Solve convex subroutine: @xmath , s.t. @xmath

7: @xmath

8: @xmath

9: end while

10: @xmath

Algorithm 2 Multiple decomposition CCP ( @xmath version)

In conclusion, our overall observation is that picking a good dc
decomposition noticeably affects the perfomance of CCP. While optimizing
over all dc decompositions is intractable for polynomials of degree
greater or equal to @xmath , the algebraic notions of sos-convexity,
sdsos-convexity and dsos-convexity can provide valuable relaxations. The
choice among these options depends on the number of variables and the
degree of the polynomial at hand. Though these classes of polynomials
only constitute subsets of the set of convex polynomials, we have shown
that even the smallest subset of the three contains dcds for any
polynomial.

### Chapter 6 Polynomials Norms

#### 6.1 Introduction

A function @xmath is a norm if it satisfies the following three
properties:

1.  positive definiteness: @xmath and @xmath .

2.  @xmath -homogeneity: @xmath .

3.  triangle inequality: @xmath

Some well-known examples of norms include the @xmath -norm, @xmath , the
@xmath -norm, @xmath , and the @xmath -norm, @xmath Our focus throughout
this chapter is on norms that can be derived from multivariate
polynomials. More specifically, we are interested in establishing
conditions under which the @xmath root of a homogeneous polynomial of
degree @xmath is a norm, where @xmath is an even number. We refer to the
norm obtained when these conditions are met as a polynomial norm . It is
easy to see why we restrict ourselves to @xmath roots of degree- @xmath
homogeneous polynomials. Indeed, nonhomogeneous polynomials cannot hope
to satisfy the homogeneity condition and homogeneous polynomials of
degree @xmath are not 1-homogeneous unless we take their @xmath root.
The question of when the square root of a homogeneous quadratic
polynomial is a norm (i.e., when @xmath ) has a well-known answer (see,
e.g., [ 35 , Appendix A] ): a function @xmath is a norm if and only if
the symmetric @xmath matrix @xmath is positive definite. In the
particular case where @xmath is the identity matrix, one recovers the
@xmath -norm. Positive definiteness of @xmath can be checked in
polynomial time using for example Sylvester’s criterion (positivity of
the @xmath leading principal minors of @xmath ). This means that testing
whether the square root of a quadratic form is a norm can be done in
polynomial time. A similar characterization in terms of conditions on
the coefficients are not known for polynomial norms generated by forms
of degree greater than 2. In particular, it is not known whether one can
efficiently test membership or optimize over the set of polynomial
norms.

###### Outline and contributions.

In this chapter, we study polynomial norms from a computational
perspective. In Section 6.2 , we give two different necessary and
sufficient conditions under which the @xmath root of a degree- @xmath
form @xmath will be a polynomial norm: namely, that @xmath be strictly
convex (Theorem 6.2.2 ), or (equivalently) that @xmath be convex and
postive definite (Theorem 6.2.1 ). Section 6.3 investigates the
relationship between general norms and polynomial norms: while many
norms are polynomial norms (including all @xmath -norms with @xmath
even), some norms are not (consider, e.g., the @xmath -norm). We show,
however, that any norm can be approximated to arbitrary precision by a
polynomial norm (Theorem 6.3.1 ). In Section 6.4 , we move on to
complexity results and show that simply testing whether the @xmath root
of a quartic form is a norm is strongly NP-hard (Theorem 6.4.1 ). We
then provide a semidefinite programming-based test for checking whether
the @xmath root of a degree @xmath form is a norm (Theorem 6.4.4 ) and a
semidefinite programming-based hierarchy to optimize over a subset of
the set of polynomial norms (Theorem 6.4.20 ). The latter is done by
introducing the concept of @xmath -sum of squares-convexity (see
Definition 6.4.6 ). We show that any form with a positive definite
Hessian is @xmath -sos-convex for some value of @xmath , and present a
lower bound on that value (Theorem 6.4.7 ). We also show that the level
@xmath of the semidefinite programming hierarchy cannot be bounded as a
function of the number of variables and the degree only (Theorem 6.4.18
). Finally, we cover a few applications of polynomial norms in
statistics and dynamical systems in Section 6.5 . In Section 6.5.1 , we
compute approximations of two different types of norms, polytopic gauge
norms and @xmath -norms with @xmath noneven, using polynomial norms. The
techniques described in this section can be applied to norm regression.
In Section 6.5.2 , we use polynomial norms to prove stability of a
switched linear system, a task which is equivalent to computing an
upperbound on the joint spectral radius of a family of matrices.

#### 6.2 Two equivalent characterizations of polynomial norms

We start this section with two theorems that provide conditions under
which the @xmath root of a degree- @xmath form is a norm. These will be
useful in Section 6.4 to establish semidefinite programming-based
approximations of polynomial norms. Note that throughout this chapter,
@xmath is taken to be an even positive integer.

###### Theorem 6.2.1.

The @xmath root of a degree- @xmath form @xmath is a norm if and only if
@xmath is convex and positive definite.

###### Proof.

If @xmath is a norm, then @xmath is positive definite, and so is @xmath
. Furthermore, any norm is convex and the @xmath power of a nonnegative
convex function remains convex.

Assume now that @xmath is convex and positive definite. We show that
@xmath is a norm. Positivity and homogeneity are immediate. It remains
to prove the triangle inequality. Let @xmath . Denote by @xmath and
@xmath the 1-sublevel sets of @xmath and @xmath respectively. It is
clear that

  -- -------- --
     @xmath   
  -- -------- --

and as @xmath is convex, @xmath is convex and so is @xmath . Let @xmath
We have that @xmath and @xmath . From convexity of @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Homogeneity of @xmath then gives us

  -- -------- --
     @xmath   
  -- -------- --

which shows that triangle inequality holds. ∎

###### Theorem 6.2.2.

The @xmath root of a degree- @xmath form @xmath is a norm if and only if
@xmath is strictly convex, i.e.,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We will show that a degree-d form @xmath is strictly convex if and only
@xmath is convex and positive definite. The result will then follow from
Theorem 6.2.1 .

Suppose @xmath is strictly convex, then the first-order characterization
of strict convexity gives us that

  -- -------- --
     @xmath   
  -- -------- --

For @xmath , the inequality becomes @xmath , as @xmath and @xmath .
Hence, @xmath is positive definite. Of course, a strictly convex
function is also convex.

Suppose now that @xmath is convex, positive definite, but not strictly
convex, i.e., there exists @xmath with @xmath , and @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath Note that @xmath is a restriction of @xmath to a line and,
consequently, @xmath is a convex, positive definite, univariate
polynomial in @xmath . We now define

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

Similarly to @xmath , @xmath is a convex univariate polynomial as it is
the sum of two convex univariate polynomials. We also know that @xmath .
Indeed, by convexity of @xmath , we have that @xmath and @xmath . This
inequality holds in particular for @xmath and @xmath , which proves the
claim. Observe now that @xmath . By convexity of @xmath and its
nonnegativity over @xmath , we have that @xmath on @xmath which further
implies that @xmath . Hence, from ( 6.1 ), @xmath is an affine function.
As @xmath is positive definite, it cannot be that @xmath has a nonzero
slope, so @xmath has to be a constant. But this contradicts that @xmath
To see why this limit must be infinite, we show that @xmath As @xmath
and @xmath , this implies that @xmath To show that @xmath , let

  -- -------- --
     @xmath   
  -- -------- --

By positive definiteness of @xmath , @xmath Let @xmath be any positive
scalar and define @xmath . Then for any @xmath such that @xmath , we
have

  -- -------- --
     @xmath   
  -- -------- --

where the second inequality holds by homogeneity of @xmath Thus @xmath .
∎

#### 6.3 Approximating norms by polynomial norms

It is easy to see that not all norms are polynomial norms. For example,
the 1-norm @xmath is not a polynomial norm. Indeed, all polynomial norms
are differentiable at all but one point (the origin) whereas the 1-norm
is nondifferentiable whenever one of the components of @xmath is equal
to zero. In this section, we show that, though not every norm is a
polynomial norm, any norm can be approximated to arbitrary precision by
a polynomial norm (Theorem 6.3.1 ). The proof of this theorem is
inspired from a proof by Ahmadi and Jungers in [ 3 , 6 ] . A related
result is given by Barvinok in [ 24 ] . In that chapter, he shows that
any norm can be approximated by the @xmath -th root of a nonnegative
degree- @xmath form, and quantifies the quality of the approximation as
a function of @xmath and @xmath . The form he obtains however is not
shown to be convex. In fact, in a later work [ 25 , Section 2.4] ,
Barvinok points out that it would be an interesting question to know
whether any norm can be approximated by the @xmath root of a convex form
with the same quality of approximation as for @xmath -th roots of
nonnegative forms. The result below is a step in that direction though
no quantitative result on the quality of approximation is given.
Throughout, @xmath denotes the unit sphere in @xmath

###### Theorem 6.3.1.

Let @xmath be any norm on @xmath For any @xmath , there exist an even
integer @xmath and a convex positive definite form @xmath of degree
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Note that, from Theorem 6.2.1 , @xmath is a polynomial norm as @xmath is
a convex positive definite form. To show this result, we start with the
following lemma.

###### Lemma 6.3.2.

Let @xmath be any norm on @xmath . For any @xmath , there exist an even
integer @xmath and an @xmath -variate convex positive definite form
@xmath of degree @xmath such that

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

###### Proof.

Throughout, we let @xmath When @xmath , we drop the subscript and simply
denote by @xmath the unit ball of @xmath . We will also use the notation
@xmath to denote the boundary of a set @xmath and @xmath to denote its
interior. Let @xmath . The crux of the proof lies in proving that there
exists an integer @xmath and a positive definite convex form @xmath of
degree @xmath such that

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

If we prove this, then Lemma 6.3.2 can be obtained as follows. Let
@xmath To show the first inequality in ( 6.2 ), we proceed by
contradiction. Suppose that @xmath . If @xmath , then @xmath while
@xmath . (If @xmath then @xmath and the inequality holds.) Hence,

  -- -------- --
     @xmath   
  -- -------- --

but @xmath which contradicts ( 6.3 ). To prove the second inequality in
( 6.2 ), note that the first inclusion of @xmath gives us @xmath , which
is equivalent to @xmath Multiplying by @xmath on both sides gives us the
result.

We now focus on showing the existence of a positive definite convex form
@xmath that satisfies ( 6.3 ). The proof is a simplification of the
proof of Theorem 3.2. in [ 3 , 6 ] with some modifications.

Let @xmath . To any such @xmath , we associate a dual vector @xmath
orthogonal to a supporting hyperplane of @xmath at @xmath . By
definition of a supporting hyperplane, we have that @xmath , @xmath ,
and, as @xmath , we have

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

Let

  -- -------- --
     @xmath   
  -- -------- --

It is easy to see that @xmath is an open subset of the boundary @xmath
of @xmath . Futhermore, since @xmath , @xmath which implies that @xmath
is nonempty and that the family of sets @xmath (as @xmath ranges over
@xmath is a covering of @xmath . As @xmath is an open covering of the
compact set @xmath , there exists a finite covering of @xmath , i.e.,
one can choose @xmath in such a way that @xmath

For ease of notation, we now let @xmath for all @xmath . From ( 6.4 ),
we have that @xmath for any @xmath and for any @xmath ¹ ¹ 1 Note that
@xmath , @xmath . In fact, we have @xmath To see this, recall that by
definition of a supporting hyperplane, @xmath and @xmath , for all
@xmath . In particular, there exists @xmath such that @xmath . Hence,
@xmath . Since @xmath is compact, we get @xmath . Hence, there exists an
integer @xmath such that

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

We now define

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

where @xmath is any integer satisfying ( 6.5 ). The form @xmath is
convex as a sum of even powers of linear forms. Let

  -- -------- --
     @xmath   
  -- -------- --

By ( 6.5 ), it is straightforward to see that @xmath

We now show that @xmath Let @xmath , then @xmath If a sum of nonnegative
terms is less than or equal to 1, then each term has to be less than or
equal to @xmath , which implies that @xmath , for all @xmath From this,
we deduce that @xmath . Indeed, if @xmath , there exists @xmath such
that @xmath as @xmath is a cover of @xmath . But, by definition of
@xmath , we would have @xmath which contradicts the previous statement.
We have that @xmath as a consequence. However, as @xmath and @xmath both
contain the zero vector, this implies that @xmath Note that the previous
inclusion guarantees positive definiteness of @xmath . Indeed, if @xmath
were not positive definite, @xmath would be unbounded and could not be a
subset of @xmath (which is bounded). ∎

###### Proof of Theorem 6.3.1.

Let @xmath and denote by @xmath . By Lemma 6.3.2 , there exists an
integer @xmath and a convex form @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

This is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

For @xmath , as @xmath , this inequality becomes

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Remark 6.3.3.

We remark that the polynomial norm constructed in Theorem 6.3.1 is the
@xmath -root of an sos-convex polynomial. Hence, one can approximate any
norm on @xmath by searching for a polynomial norm using semidefinite
programming. To see why the polynomial @xmath in ( 6.6 ) is sos-convex,
observe that linear forms are sos-convex and that an even power of an
sos-convex form is sos-convex.

#### 6.4 Semidefinite programming-based approximations of polynomial
norms

##### 6.4.1 Complexity

It is natural to ask whether testing if the @xmath root of a given
degree- @xmath form is a norm can be done in polynomial time. In the
next theorem, we show that, unless @xmath , this is not the case even
when @xmath .

###### Theorem 6.4.1.

Deciding whether the @xmath root of a quartic form is a norm is strongly
NP-hard.

###### Proof.

The proof of this result is adapted from a proof in [ 10 ] . Recall that
the CLIQUE problem can be described thus: given a graph @xmath and a
positive integer @xmath , decide whether @xmath contains a clique of
size at least @xmath . The CLIQUE problem is known to be NP-hard [ 71 ]
. We will give a reduction from CLIQUE to the problem of testing
convexity and positive definiteness of a quartic form. The result then
follows from Theorem 6.2.1 . Let @xmath be the clique number of the
graph at hand, i.e., the number of vertices in a maximum clique of
@xmath . Consider the following quartic form

  -- -------- --
     @xmath   
  -- -------- --

In [ 10 ] , using in part a result in [ 122 ] , it is shown that

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

is convex and @xmath is positive semidefinite. Here, @xmath is a
positive constant defined as the largest coefficient in absolute value
of any monomial present in some entry of the matrix @xmath . As @xmath
is positive definite and as we are adding this term to a positive
semidefinite expression, the resulting polynomial is positive definite.
Hence, the equivalence holds if and only if the quartic on the
righthandside of the equivalence in ( 6.7 ) is convex and positive
definite. ∎

Note that this also shows that strict convexity is hard to test for
quartic forms (this is a consequence of Theorem 6.2.2 ). A related
result is Proposition 3.5. in [ 10 ] , which shows that testing strict
convexity of a polynomial of even degree @xmath is hard. However, this
result is not shown there for forms , hence the relevance of the
previous theorem.

Theorem 6.4.1 motivates the study of tractable sufficient conditions to
be a polynomial norm. The sufficient conditions we consider next are
based on semidefinite programming.

##### 6.4.2 Sum of squares polynomials and semidefinite programming
review

We start this section by reviewing the notion of sum of squares
polynomials and related concepts such as sum of squares-convexity . We
say that a polynomial @xmath is a sum of squares (sos) if @xmath , for
some polynomials @xmath . Being a sum of squares is a sufficient
condition for being nonnegative. The converse however is not true, as is
exemplified by the Motzkin polynomial

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

which is nonnegative but not a sum of squares [ 141 ] . The sum of
squares condition is a popular surrogate for nonnegativity due to its
tractability. Indeed, while testing nonnegativity of a polynomial of
degree greater or equal to 4 is a hard problem, testing whether a
polynomial is a sum of squares can be done using semidefinite
programming. This comes from the fact that a polynomial @xmath of degree
@xmath is a sum of squares if and only if there exists a positive
semidefinite matrix @xmath such that @xmath , where @xmath is the
standard vector of monomials of degree up to @xmath (see, e.g., [ 152 ]
). As a consequence, any optimization problem over the coefficients of a
set of polynomials which includes a combination of affine constraints
and sos constraints on these polynomials, together with a linear
objective can be recast as a semidefinite program. These type of
optimization problems are known as sos programs .

Though not all nonnegative polynomials can be written as sums of
squares, the following theorem by Artin [ 18 ] circumvents this problem
using sos multipliers.

###### Theorem 6.4.2 (Artin [18]).

For any nonnegative polynomial @xmath , there exists an sos polynomial
@xmath such that @xmath is sos.

This theorem in particular implies that if we are given a polynomial
@xmath , then we can always check its nonnegativity using an sos program
that searches for @xmath (of a fixed degree). However, the condition
does not allow us to optimize over the set of nonnegative polynomials
using an sos program (as far as we know). This is because, in that
setting, products of decision varibles arise from multiplying
polymomials @xmath and @xmath , whose coefficients are decision
variables.

By adding further assumptions on @xmath , Reznick showed in [ 164 ] that
one could further pick @xmath to be a power of @xmath .

###### Theorem 6.4.3 (Reznick [164]).

Let @xmath be a positive definite form of degree @xmath in @xmath
variables and define

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , then @xmath is a sum of squares.

Motivated by this theorem, the notion of @xmath -sos polynomials can be
defined: a polynomial @xmath is said to be @xmath -sos if @xmath is sos.
Note that it is clear that any @xmath -sos polynomial is nonnegative and
that the set of @xmath -sos polynomials is included in the set of @xmath
-sos polynomials. The Motzkin polynomial in ( 6.8 ) for example is
@xmath -sos although not sos.

To end our review, we briefly touch upon the concept of sum of
squares-convexity (sos-convexity), which we will build upon in the rest
of the section. Let @xmath denote the Hessian matrix of a polynomial
@xmath . We say that @xmath is sos-convex if @xmath is a sum of squares
(as a polynomial in @xmath and @xmath ). As before, optimizing over the
set of sos-convex polynomials can be cast as a semidefinite program. Sum
of squares-convexity is obviously a sufficient condition for convexity
via the second-order characterization of convexity. However, there are
convex polynomials which are not sos-convex (see, e.g., [ 11 ] ). For a
more detailed overview of sos-convexity including equivalent
characterizations and settings in which sos-convexity and convexity are
equivalent, refer to [ 12 ] .

###### Notation

Throughout, we will use the notation @xmath (resp. @xmath ) to denote
the set of forms (resp. positive semidefinite, aka nonnegative, forms)
in @xmath variables and of degree @xmath . We will futhermore use the
falling factorial notation @xmath and @xmath for a positive integer
@xmath .

##### 6.4.3 A test for validity of polynomial norms

In this subsection, we assume that we are given a form @xmath of degree
@xmath and we would like to test whether @xmath is a norm using
semidefinite programming.

###### Theorem 6.4.4.

Let @xmath be a degree- @xmath form. Then @xmath is a polynomial norm if
and only if there exist @xmath , @xmath , and an sos form @xmath such
that @xmath is sos and @xmath is sos. Furthermore, this condition can be
checked using semidefinite programming.

###### Proof.

It is immediate to see that if there exist such a @xmath , @xmath , and
@xmath , then @xmath is convex and positive definite. From Theorem 6.2.1
, this means that @xmath is a polynomial norm.

Conversely, if @xmath is a polynomial norm, then, by Theorem 6.2.1 ,
@xmath is convex and positive definite. As @xmath is convex, the
polynomial @xmath is nonnegative. Using Theorem 6.4.2 , we conclude that
there exists an sos polynomial @xmath such that @xmath is sos. We now
show that, as @xmath is positive definite, there exist @xmath and @xmath
such that @xmath is sos. Let @xmath denote the minimum of @xmath on the
sphere. As @xmath is positive definite, @xmath We take @xmath and
consider @xmath . We have that @xmath is a positive definite form:
indeed, if @xmath is a nonzero vector in @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

by homogeneity of @xmath and definition of @xmath . Using Theorem 6.4.3
, @xmath such that @xmath is sos.

For fixed @xmath , a given form @xmath , and a fixed degree @xmath , one
can search for @xmath and an sos form @xmath of degree @xmath such that
@xmath is sos and @xmath is sos using semidefinite programming. This is
done by solving the following semidefinite feasibility problem:

  -- -- -------- -------- -------
        @xmath            (6.9)
                 @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- -------

where the unknowns are the coefficients of @xmath and the real number
@xmath . ∎

###### Remark 6.4.5.

We remark that we are not imposing @xmath in the semidefinite program
above. This is because, in practice, especially if the semidefinite
program is solved with interior point methods, the solution returned by
the solver will be in the interior of the feasible set, and hence @xmath
will automatically be positive. One can slightly modify ( 6.9 ) however
to take the constraint @xmath into consideration explicitely. Indeed,
consider the following semidefinite feasibility problem where both the
degree of @xmath and the integer @xmath are fixed:

  -- -- -------- -- --------
        @xmath      
        @xmath      
        @xmath      
        @xmath      (6.10)
  -- -- -------- -- --------

It is easy to check that ( 6.10 ) is feasible with @xmath if and only if
the last constraint of ( 6.9 ) is feasible with @xmath . To see this,
take @xmath and note that @xmath can never be zero.

To the best of our knowledge, we cannot use the approach described in
Theorem 6.4.4 to optimize over the set of polynomial norms with a
semidefinite program. This is because of the product of decision
variables in the coefficients of @xmath and @xmath . The next subsection
will address this issue.

##### 6.4.4 Optimizing over the set of polynomial norms

In this subsection, we consider the problem of optimizing over the set
of polynomial norms. To do this, we introduce the concept of @xmath
-sos-convexity. Recall that the notation @xmath references the Hessian
matrix of a form @xmath .

###### Positive definite biforms and r-sos-convexity

###### Definition 6.4.6.

For an integer @xmath , we say that a polynomial @xmath is @xmath
-sos-convex if @xmath is sos.

Observe that, for fixed @xmath , the property of @xmath -sos-convexity
can be checked using semidefinite programming (though the size of this
SDP gets larger as @xmath increases). Any polynomial that is @xmath
-sos-convex is convex. Note that the set of @xmath -sos-convex
polynomials is a subset of the set of @xmath -sos-convex polynomials and
that the case @xmath corresponds to the set of sos-convex polynomials.

It is natural to ask whether any convex polynomial is @xmath -sos-convex
for some @xmath . Our next theorem shows that this is the case under a
mild assumption.

###### Theorem 6.4.7.

Let @xmath be a form of degree @xmath such that @xmath for @xmath . Let

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , then @xmath is @xmath -sos-convex.

###### Remark 6.4.8.

Note that @xmath can also be interpreted as

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 6.4.9.

Theorem 6.4.7 is a generalization of Theorem 6.4.3 by Reznick. Note
though that this is not an immediate generalization. First, @xmath is
not a positive definite form (consider, e.g., @xmath and any nonzero
@xmath ). Secondly, note that the multiplier is @xmath and does not
involve the @xmath variables. (As we will see in the proof, this is
essentially because @xmath is quadratic in @xmath .)

###### Remark 6.4.10.

Theorem 6.4.7 can easily be adapted to biforms of the type @xmath where
@xmath ’s are forms of degree @xmath in @xmath and @xmath ’s are forms
of degree @xmath in @xmath . In this case, there exist integers @xmath
such that

  -- -------- --
     @xmath   
  -- -------- --

is sos. For the purposes of this chapter however and the connection to
polynomial norms, we will show the result in the particular case where
the biform of interest is @xmath

We associate to any form @xmath , the @xmath -th order differential
operator @xmath , defined by replacing each occurence of @xmath with
@xmath . For example, if @xmath where @xmath and @xmath , then its
differential operator will be

  -- -------- --
     @xmath   
  -- -------- --

Our proof will follow the structure of the proof of Theorem 6.4.3 given
in [ 164 ] and reutilize some of the results given in the chapter which
we quote here for clarity of exposition.

###### Proposition 6.4.11 ([164], see Proposition 2.6).

For any nonnegative integer @xmath , there exist nonnegative rationals
@xmath and integers @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

For simplicity of notation, we will let @xmath and @xmath . Hence, we
will write @xmath to mean @xmath .

###### Proposition 6.4.12 ([164], see Proposition 2.8).

If @xmath and @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

###### Proposition 6.4.13 ([164], see Theorem 3.7 and 3.9).

For @xmath and @xmath , we define @xmath by

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

The inverse @xmath of @xmath exists and this is a map verifying @xmath

###### Proposition 6.4.14 ([164], see Theorem 3.12 ).

Suppose @xmath is a positive definite form in @xmath variables and of
degree @xmath and let

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , then @xmath

We will focus throughout the proof on biforms of the following structure

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

where @xmath , for all @xmath , and some even integer @xmath . Note that
the polynomial @xmath (where @xmath is some form) has this structure. We
next present three lemmas which we will then build on to give the proof
of Theorem 6.4.7 .

###### Lemma 6.4.15.

For a biform @xmath of the structure in ( 6.12 ), define the operator
@xmath as

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is positive semidefinite (i.e., @xmath ), then, for any @xmath
, the biform

  -- -------- --
     @xmath   
  -- -------- --

is a sum of squares.

###### Proof.

Using Proposition 6.4.11 , we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath Hence, applying Proposition 6.4.12 , we get

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (6.13)
  -- -------- -------- -- --------

Notice that @xmath is a quadratic form in @xmath which is positive
semidefinite by assumption, which implies that it is a sum of squares
(as a polynomial in @xmath ). Furthermore, as @xmath and @xmath is an
even power of a linear form, we have that @xmath is a sum of squares (as
a polynomial in @xmath ). Combining both results, we get that ( 6.13 )
is a sum of squares. ∎

We now extend the concept introduced by Reznick in Proposition 6.4.13 to
biforms.

###### Lemma 6.4.16.

For a biform @xmath of the structure as in ( 6.12 ), we define the
biform @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is as in ( 6.11 ). Define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the inverse of @xmath . Then, we have

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

###### Proof.

We start by showing that ( 6.14 ) holds:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

We now show that ( 6.15 ) holds:

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Lemma 6.4.17.

For a biform @xmath of the structure in ( 6.12 ), which is positive on
the bisphere, let

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , then @xmath is positive semidefinite.

###### Proof.

Fix @xmath and consider @xmath , which is a positive definite form in
@xmath of degree @xmath . From Proposition 6.4.14 , if

  -- -------- --
     @xmath   
  -- -------- --

then @xmath is positive semidefinite. As @xmath for any @xmath , we have
that if

  -- -------- --
     @xmath   
  -- -------- --

then @xmath is positive semidefinite, regardless of the choice of @xmath
Hence, @xmath is positive semidefinite (as a function of @xmath and
@xmath ).

∎

###### Proof of Theorem 6.4.7.

Let @xmath , let @xmath , and let

  -- -------- --
     @xmath   
  -- -------- --

We know by Lemma 6.4.17 that @xmath is positive semidefinite. Hence,
using Lemma 6.4.15 , we get that

  -- -------- --
     @xmath   
  -- -------- --

is sos. Lemma 6.4.16 then gives us:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

As a consequence, @xmath is sos.

∎

The last theorem of this section shows that one cannot bound the integer
@xmath in Theorem 6.4.7 as a function of @xmath and @xmath only.

###### Theorem 6.4.18.

For any integer @xmath , there exists a form @xmath in 3 variables and
of degree 8 such that @xmath , but @xmath is not @xmath -sos-convex.

###### Proof.

Consider the trivariate octic:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

It is shown in [ 11 ] that @xmath has positive definite Hessian, and
that the @xmath entry of @xmath , which we will denote by @xmath , is
1-sos but not sos. We will show that for any @xmath , one can find
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

satisfies the conditions of the theorem.

We start by showing that for any @xmath , @xmath has positive definite
Hessian. To see this, note that for any @xmath , we have:

  -- -------- --
     @xmath   
  -- -------- --

As @xmath for any @xmath , this is in particular true when @xmath and
when @xmath , which gives us that the Hessian of @xmath is positive
definite for any @xmath

We now show that for a given @xmath , there exists @xmath such that
@xmath is not sos. We use the following result from [ 166 , Theorem 1] :
for any positive semidefinite form @xmath which is not sos, and any
@xmath , there exists @xmath such that @xmath is not sos. As @xmath is
1-sos but not sos, we can apply the previous result. Hence, there exists
a positive integer @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

is not sos. This implies that @xmath is not sos. Indeed, if @xmath was
sos, then @xmath would be sos with @xmath But, we have

  -- -------- --
     @xmath   
  -- -------- --

which is not sos. Hence, @xmath is not sos, and @xmath is not @xmath
-sos-convex. ∎

###### Remark 6.4.19.

Any form @xmath with @xmath is strictly convex but the converse is not
true.

To see this, note that any form @xmath of degree @xmath with a positive
definite Hessian is convex (as @xmath ) and positive definite (as, from
a recursive application of Euler’s theorem on homogeneous functions,
@xmath ). From the proof of Theorem 6.2.2 , this implies that @xmath is
strictly convex.

To see that the converse statement is not true, consider the strictly
convex form @xmath . We have

  -- -------- --
     @xmath   
  -- -------- --

which is not positive definite e.g., when @xmath .

###### Optimizing over a subset of polynomial norms with
@xmath-sos-convexity

In the following theorem, we show how one can efficiently optimize over
the set of forms @xmath with @xmath , @xmath Comparatively to Theorem
6.4.4 , this theorem allows us to impose as a constraint that the @xmath
root of a form be a norm, rather than simply testing whether it is. This
comes at a cost however: in view of Remark 6.4.19 and Theorem 6.2.2 , we
are no longer considering all polynomial norms, but a subset of them
whose @xmath power has a positive definite Hessian.

###### Theorem 6.4.20.

Let @xmath be a degree- @xmath form. Then @xmath if and only if @xmath
such that @xmath is @xmath -sos-convex. Furthermore, this condition can
be imposed using semidefinite programming.

###### Proof.

If there exist @xmath such that @xmath is @xmath -sos-convex, then
@xmath , @xmath As the Hessian of @xmath is positive definite for any
nonzero @xmath and as @xmath , we get @xmath , @xmath

Conversely, if @xmath , @xmath , then @xmath on the bisphere (and
conversely). Let

  -- -------- --
     @xmath   
  -- -------- --

We know that @xmath is attained and is positive. Take @xmath and
consider

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- --
     @xmath   
  -- -------- --

Note that, by Cauchy-Schwarz, we have @xmath . If @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath and there exists @xmath such that @xmath is @xmath
-sos-convex from Theorem 6.4.7 .

For fixed @xmath , the condition that there be @xmath such that @xmath
is @xmath -sos-convex can be imposed using semidefinite programming.
This is done by searching for coefficients of a polynomial @xmath and a
real number @xmath such that

  -- -- -------- -------- --------
        @xmath            (6.16)
                 @xmath   
  -- -- -------- -------- --------

Note that both of these conditions can be imposed using semidefinite
programming. ∎

###### Remark 6.4.21.

Note that we are not imposing @xmath in the above semidefinite program.
As mentioned in Section 6.4.3 , this is because in practice the solution
returned by interior point solvers will be in the interior of the
feasible set.

In the special case where @xmath is completely free ² ² 2 This is the
case of our two applications in Section 6.5 . (i.e., when there are no
additional affine conditions on the coefficients of @xmath ), one can
take @xmath in ( 6.16 ) instead of @xmath . Indeed, if there exists
@xmath , an integer @xmath , and a polynomial @xmath such that @xmath is
@xmath -sos-convex, then @xmath will be a solution to ( 6.16 ) with
@xmath replacing @xmath .

#### 6.5 Applications

##### 6.5.1 Norm approximation and regression

In this section, we study the problem of approximating a
(non-polynomial) norm by a polynomial norm. We consider two different
types of norms: @xmath -norms with @xmath noneven (and greater than 1)
and gauge norms with a polytopic unit ball. For @xmath -norms, we use as
an example @xmath . For our polytopic gauge norm, we randomly generate
an origin-symmetric polytope and produce a norm whose 1-sublevel
corresponds to that polytope. This allows us to determine the value of
the norm at any other point by homogeneity (see [ 35 , Exercise 3.34]
for more information on gauge norms, i.e., norms defined by convex,
full-dimensional, origin-symmetric sets). To obtain our approximations,
we proceed in the same way in both cases. We first sample @xmath points
@xmath on the sphere @xmath that we denote by @xmath . We then solve the
following optimization problem with @xmath fixed:

  -- -- -------- -- -------- -------- --------
        @xmath      @xmath            (6.17)
                             @xmath   
  -- -- -------- -- -------- -------- --------

Problem ( 6.17 ) can be written as a semidefinite program as the
objective is a convex quadratic in the coefficients of @xmath and the
constraint has a semidefinite representation as discussed in Section
6.4.2 . The solution @xmath returned is guaranteed to be convex.
Moreover, any sos-convex form is sos (see [ 89 , Lemma 8] ), which
implies that @xmath is nonnegative. One can numerically check to see if
the optimal polynomial is in fact positive definite (for example, by
checking the eigenvalues of the Gram matrix of a sum of squares
decomposition of @xmath ). If that is the case, then, by Theorem 6.2.1 ,
@xmath is a norm. Futhermore, note that we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where the first inequality is a consequence of concavity of @xmath and
the second is a consequence of the inequality @xmath . This implies that
if the optimal value of ( 6.17 ) is equal to @xmath , then the sum of
the squared differences between @xmath and @xmath over the sample is
less than or equal to @xmath .

It is worth noting that in our example, we are actually searching over
the entire space of polynomial norms of a given degree. Indeed, as
@xmath is bivariate, it is convex if and only if it is sos-convex [ 12 ]
. In Figure 6.2 , we have drawn the 1-level sets of the initial norm
(either the @xmath -norm or the polytopic gauge norm) and the optimal
polynomial norm obtained via ( 6.17 ) with varying degrees @xmath . Note
that when @xmath increases, the approximation improves.

A similar method could be used for norm regression . In this case, we
would have access to data points @xmath corresponding to noisy
measurements of an underlying unknown norm function. We would then solve
the same optimization problem as the one given in ( 6.17 ) to obtain a
polynomial norm that most closely approximates the noisy data.

##### 6.5.2 Joint spectral radius and stability of linear switched
systems

As a second application, we revisit a result from Ahmadi and Jungers
from [ 3 , 6 ] on upperbounding the joint spectral radius of a finite
set of matrices. We first review a few notions relating to dynamical
systems and linear algebra. The spectral radius @xmath of a matrix
@xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

The spectral radius happens to coincide with the eigenvalue of @xmath of
largest magnitude. Consider now the discrete-time linear system @xmath ,
where @xmath is the @xmath state vector of the system at time @xmath .
This system is said to be asymptotically stable if for any initial
starting state @xmath , @xmath when @xmath A well-known result
connecting the spectral radius of a matrix to the stability of a linear
system states that the system @xmath is asymptotically stable if and
only if @xmath .

In 1960, Rota and Strang introduced a generalization of the spectral
radius to a set of matrices. The joint spectral radius (JSR) of a set of
matrices @xmath is defined as

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

Analogously to the case where we have just one matrix, the value of the
joint spectral radius can be used to determine stability of a certain
type of system, called a switched linear system. A switched linear
system models an uncertain and time-varying linear system, i.e., a
system described by the dynamics

  -- -------- --
     @xmath   
  -- -------- --

where the matrix @xmath varies at each iteration within the set @xmath .
As done previously, we say that a switched linear system is
asymptotically stable if @xmath when @xmath , for any starting state
@xmath and any sequence of products of matrices in @xmath . One can
establish that the switched linear system @xmath is asymtotically stable
if and only if @xmath [ 101 ] .

Though they may seem similar on many points, a key difference between
the spectral radius and the joint spectral radius lies in difficulty of
computation: testing whether the spectral radius of a matrix @xmath is
less than equal (or strictly less) than @xmath can be done in polynomial
time. However, already when @xmath , the problem of testing whether
@xmath is undecidable [ 31 ] . An active area of research has
consequently been to obtain sufficient conditions for the JSR to be
strictly less than one, which, for example, can be checked using
semidefinite programming. The theorem that we revisit below is a result
of this type. We start first by recalling a Theorem linked to stability
of a linear system.

###### Theorem 6.5.1 (see, e.g., Theorem 8.4 in [91]).

Let @xmath . Then, @xmath if and only if there exists a contracting
quadratic norm; i.e., a function @xmath of the form @xmath with @xmath ,
such that @xmath

The next theorem (from [ 3 , 6 ] ) can be viewed as an extension of
Theorem 6.5.1 to the joint spectral radius of a finite set of matrices.
It is known that the existence of a contracting quadratic norm is no
longer necessary for stability in this case. This theorem show however
that the existence of a contracting polynomial norm is.

###### Theorem 6.5.2 (adapted from [3, 6], Theorem 3.2 ).

Let @xmath be a family of @xmath matrices. Then, @xmath if and only if
there exists a contracting polynomial norm; i.e., a function @xmath ,
where @xmath is an n-variate convex and positive definite form of degree
@xmath , such that @xmath and @xmath

We remark that in [ 5 ] , Ahmadi and Jungers show that the degree of
@xmath cannot be bounded as a function of @xmath and @xmath . This is
expected from the undecidability result mentioned before.

###### Example 6.5.3.

We consider a modification of Example 5.4. in [ 4 ] as an illustration
of the previous theorem. We would like to show that the joint spectral
radius of the two matrices

  -- -------- --
     @xmath   
  -- -------- --

is strictly less that one.

To do this, we search for a nonzero form @xmath of degree @xmath such
that

  -- -- -------- -------- --------
        @xmath            (6.19)
                 @xmath   
  -- -- -------- -------- --------

If problem ( 6.19 ) is feasible for some @xmath , then @xmath . A quick
computation using the software package YALMIP [ 125 ] and the SDP solver
MOSEK [ 140 ] reveals that, when @xmath or @xmath , problem ( 6.19 ) is
infeasible. When @xmath however, the problem is feasible and we obtain a
polynomial norm @xmath whose 1-sublevel set is the outer set plotted in
Figure 6.3 . We also plot on Figure 6.3 the images of this 1-sublevel
set under @xmath and @xmath . Note that both sets are included in the
1-sublevel set of @xmath as expected. From Theorem 6.5.2 , the existence
of a polynomial norm implies that @xmath and hence, the pair @xmath is
asymptotically stable.

###### Remark 6.5.4.

As mentioned previously, problem ( 6.19 ) is infeasible for @xmath .
Instead of pushing the degree of @xmath up to 6, one could wonder
whether the problem would have been feasible if we had asked that @xmath
of degree @xmath be @xmath -sos-convex for some fixed @xmath . As
mentioned before, in the particular case where @xmath (which is the case
at hand here), the notions of convexity and sos-convexity coincide; see
[ 12 ] . As a consequence, one can only hope to make problem ( 6.19 )
feasible by increasing the degree of @xmath .

#### 6.6 Future directions

In this chapter, we provided semidefinite programming-based conditions
under which we could test whether the @xmath root of a degree- @xmath
form is a polynomial norm (Section 6.4.3 ), and semidefinite
programming-based conditions under which we could optimize over the set
of forms with positive definite Hessians (Section 6.4.4 ). A clear gap
emerged between forms which are strictly convex and those which have a
positive definite Hessian, the latter being a sufficient (but not
necessary) condition for the former. This leads us to consider the
following two open problems.

###### Open Problem 6.6.1.

We have given a semidefinite programming hierarchy for optimizing over a
subset of polynomial norms. Is there a semidefinite programming
hierarchy that optimizes over all polynomial norms?

###### Open Problem 6.6.2.

Helton and Nie have shown in [ 89 ] that sublevel sets of forms that
have positive definite Hessians are SDP-representable. This means that
we can optimize linear functions over these sets using semidefinite
programming. Is the same true for sublevel sets of all polynomial norms?

On the application side, it might be interesting to investigate how one
can use polynomial norms to design regularizers in machine learning
applications. Indeed, a very popular use of norms in optimization is as
regularizers, with the goal of imposing additional structure (e.g.,
sparsity or low-rankness) on optimal solutions. One could imagine using
polynomial norms to design regularizers that are based on the data at
hand in place of more generic regularizers such as the 1-norm.
Regularizer design is a problem that has already been considered (see,
e.g., [ 21 , 39 ] ) but not using polynomial norms. This can be worth
exploring as we have shown that polynomial norms can approximate any
norm with arbitrary accuracy, while remaining differentiable everywhere
(except at the origin), which can be beneficial for optimization
purposes.

### Chapter 7 Geometry of 3D Environments and Sum of Squares Polynomials

#### 7.1 Introduction

A central problem in robotics, computer graphics, virtual and augmented
reality (VR/AR), and many applications involving complex physics
simulations is the accurate, real-time determination of proximity
relationships between three-dimensional objects [ 64 ] situated in a
cluttered environment. In robot navigation and manipulation tasks, path
planners need to compute a dynamically feasible trajectory connecting an
initial state to a goal configuration while avoiding obstacles in the
environment. In VR/AR applications, a human immersed in a virtual world
may wish to touch computer generated objects that must respond to
contacts in physically realistic ways. Likewise, when collisions are
detected, 3D gaming engines and physics simulators (e.g., for molecular
dynamics) need to activate appropriate directional forces on interacting
entities. All of these applications require geometric notions of
separation and penetration between representations of three-dimensional
objects to be continuously monitored.

A rich class of computational geometry problems arises in this context,
when 3D objects are outer approximated by convex or nonconvex bounding
volumes [ 75 , 134 , 108 ] . In the case where the bounding volumes are
convex, the Euclidean distance between them can be computed very
precisely, providing a reliable certificate of safety for the objects
they enclose. In the case where the bounding volumes are nonconvex,
distance computation can be done either approximately via convex
decomposition heuristics [ 120 , 133 ] which cover the volumes by a
finite union of convex shapes, or exactly by using more elaborate
algebraic optimization hierarchies that we discuss in this chapter. When
3D objects overlap, quantitative measures of degree of penetration are
needed in order to optimally resolve collisions, e.g., by a
gradient-based trajectory optimizer. Multiple such measures have been
proposed in the literature. The penetration depth is the minimum
magnitude translation that brings the overlapping objects out of
collision. The growth distance [ 150 ] is the minimum shrinkage of the
two bodies required to reduce volume penetration down to merely surface
touching. Efficient computation of penetration measures is also a
problem of interest to this chapter.

##### 7.1.1 Contributions and organization of the chapter

In this work, we propose to represent the geometry of a given 3D
environment comprising multiple static or dynamic rigid bodies using
sublevel sets of polynomials. The chapter is organized as follows: In
Section 7.2 , we provide an overview of the algebraic concepts of sum of
squares (sos) and sum of squares-convex (sos-convex) polynomials as well
as their relation to semidefinite programming and polynomial
optimization. In Section 7.3 , we consider the problem of containing a
cloud of 3D points with tight-fitting convex or nearly convex sublevel
sets of polynomials. In particular, we propose and justify a new volume
minimization heuristic for these sublevel sets which empirically results
in tighter fitting polynomials than previous proposals [ 130 ] , [ 113 ]
. Additionally, we give a procedure for explicitly tuning the extent of
convexity imposed on these sublevel set bounding volumes using sum of
squares optimization techniques. If convexity is imposed, we refer to
them as sos-convex bodies ; if it is not, we term them simply as
sos-bodies . (See Section 7.2 for a more formal definition.) We show
that the bounding volumes we obtain are highly compact and adapt to the
shape of the data in more flexible ways than canned convex primitives
typically used in standard bounding volume hierarchies; see Table 7.1 .
The construction of our bounding volumes involves small-scale
semidefinite programs (SDPs) that can fit, in an offline preprocessing
phase, 3D meshes with tens of thousands of data points in a few seconds.
In Section 7.4 , we give sum of squares algorithms for measuring notions
of separation or penetration, including Euclidean distance and growth
distance [ 150 ] , of two bounding volumes representing obstacles. We
show that even when convexity is lacking, we can efficiently compute
(often tight) lower bounds on these measures. In Section 7.5 , we
consider the problem of grouping several obstacles (i.e., bounding
volumes) within one, with the idea of making a map of the 3D environment
with a lower level of resolution. A semidefinite programming based
algorithm for this purpose is proposed and demonstrated via an example.

##### 7.1.2 Preview of some experiments

Figure 7.1 gives a preview of some of the methods developed in this
chapter using as an example a 3D chair point cloud. On the left, we
enclose the chair within the 1-sublevel set of three sos-convex
polynomials with increasing degree ( @xmath , @xmath and @xmath )
leading to correspondingly tighter fits. The middle plot presents the
1-sublevel set of three degree-6 sos polynomials with increasing
nonconvexity showing how tighter representations can be obtained by
relaxing convexity. The right plot shows the 2, 1, and 0.75 sublevel
sets of a single degree-6 sos polynomial; the 1-sublevel set colored
green encloses the chair, while greater or lower values of the level set
define grown and shrunk versions of the object. The computation of
Euclidean distances and sublevel-based measures of separation and
penetration can be done in a matter of milliseconds with techniques
described in this chapter.

#### 7.2 Sum of squares and sos-convexity

In this section, we briefly review the notions of sum of squares
polynomials , sum of squares-convexity, and polynomial optimization
which will all be central to the geometric problems we discuss later. We
refer the reader to the recent monograph [ 112 ] for a more detailed
overview of the subject.

Throughout, we will denote the set of @xmath symmetric matrices by
@xmath and the set of degree- @xmath polynomials with real coefficients
by @xmath . We say that a polynomial @xmath is nonnegative if @xmath .
In many applications (including polynomial optimization that we will
cover later), one would like to constrain certain coefficients of a
polynomial so as to make it nonnegative. Unfortunately, even testing
whether a given polynomial (of degree @xmath ) is nonnegative is
NP-hard. As a consequence, we would like to replace the intractable
condition that @xmath be nonnegative by a sufficient condition for it
that is more tractable. One such condition is for the polynomial to have
a sum of squares decomposition. We say that a polynomial @xmath is a sum
of squares (sos) if there exist polynomials @xmath such that @xmath .
From this definition, it is clear that any sos polynomial is
nonnegative, though not all nonnegative polynomials are sos; see, e.g.,
[ 165 ] , [ 115 ] for some counterexamples. Furthermore, requiring that
a polynomial @xmath be sos is a computationally tractable condition as a
consequence of the following characterization: A polynomial @xmath of
degree @xmath is sos if and only if there exists a positive semidefinite
matrix @xmath such that @xmath where @xmath is the vector of all
monomials of degree up to @xmath [ 152 ] . The matrix @xmath is
sometimes called the Gram matrix of the sos decomposition and is of size
@xmath . (Throughout the chapter, we let @xmath ) The task of finding a
positive semidefinite matrix @xmath that makes the coefficients of
@xmath all equal to the coefficients of @xmath is a semidefinite
programming problem, which can be solved in polynomial time to arbitrary
accuracy [ 192 ] .

The concept of sum of squares can also be used to define a sufficient
condition for convexity of polynomials known as sos-convexity . We say
that a polynomial @xmath is sos-convex if the polynomial @xmath in
@xmath variables @xmath and @xmath is a sum of squares. Here, @xmath
denotes the Hessian of @xmath , which is a symmetric matrix with
polynomial entries. For a polynomial of degree @xmath in @xmath
variables, one can check that the dimension of the Gram matrix
associated to the sos-convexity condition is @xmath . It follows from
the second order characterization of convexity that any sos-convex
polynomial is convex, as @xmath being sos implies that @xmath The
converse however is not true, though convex but not sos-convex
polynomials are hard to find in practice; see [ 12 ] . Through its link
to sum of squares, it is easy to see that testing whether a given
polynomial is sos-convex is a semidefinite program. By contrast, testing
whether a polynomial of degree @xmath is convex is NP-hard [ 10 ] .

A polynomial optimization problem is a problem of the form

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

where the objective @xmath is a (multivariate) polynomial and the
feasible set @xmath is a basic semialgebraic set; i.e., a set defined by
polynomial inequalities:

  -- -------- --
     @xmath   
  -- -------- --

It is straightforward to see that problem ( 7.1 ) can be equivalently
formulated as that of finding the largest constant @xmath such that
@xmath It is known that, under mild conditions (specifically, under the
assumption that @xmath is Archimedean [ 115 ] ), the condition @xmath ,
is equivalent to the existence of sos polynomials @xmath such that
@xmath . Indeed, it is at least clear that if @xmath , i.e., @xmath ,
then @xmath which means that @xmath . The converse is less trivial and
is a consequence of the Putinar Positivstellensatz [ 162 ] . Using this
result, problem ( 7.1 ) can be rewritten as

  -- -------- -- -------
     @xmath      
     @xmath      (7.2)
     @xmath      
  -- -------- -- -------

For any fixed upper bound on the degrees of the polynomials @xmath ,
this is a semidefinite programming problem which produces a lower bound
on the optimal value of ( 7.1 ). As the degrees of @xmath increase,
these lower bounds are guaranteed to converge to the true optimal value
of ( 7.1 ). Note that we are making no convexity assumptions about the
polynomial optimization problem and yet solving it globally through a
sequence of semidefinite programs.

Sum of squares and polynomial optimization in robotics. We remark that
sum of squares techniques have recently found increasing applications to
a whole host of problems in robotics, including constructing Lyapunov
functions [ 13 ] , locomotion planning [ 106 ] , design and verification
of provably safe controllers [ 131 , 132 ] , grasping and manipulation [
50 , 159 , 202 ] , robot-world calibration [ 88 ] , and inverse optimal
control [ 156 ] , among others.

We also remark that a different use of sum of squares optimization for
finding minimum bounding volumes that contain semialgebraic sets has
been considered in [ 49 , 48 ] along with some interesting control
applications (see Section 7.5 for a brief description).

#### 7.3 3D point cloud containment

Throughout this section, we are interested in finding a body of minimum
volume, parametrized as the 1-sublevel set of a polynomial of degree
@xmath , which encloses a set of given points @xmath in @xmath .

##### 7.3.1 Convex sublevel sets

We focus first on finding a convex bounding volume. Convexity is a
common constraint in the bounding volume literature and it makes certain
tasks (e.g., distance computation among the different bodies) simpler.
In order to make a set of the form @xmath convex, we will require the
polynomial @xmath to be convex. (Note that this is a sufficient but not
necessary condition.) Furthermore, to have a tractable formulation, we
will replace the convexity condition with an sos-convexity condition as
described previously. Even after these relaxations, the problem of
minimizing the volume of our sublevel sets remains a difficult one. The
remainder of this section discusses several heuristics for this task.

###### The Hessian-based approach

In [ 130 ] , Magnani et al. propose the following heuristic to minimize
the volume of the 1-sublevel set of an sos-convex polynomial:

  -- -- -------- -------- -- -------- -------
        @xmath                        (7.3)
                             @xmath   
                 @xmath               
                 @xmath               
  -- -- -------- -------- -- -------- -------

where @xmath is a vector of monomials in @xmath and @xmath of degree
@xmath in @xmath and @xmath in @xmath . This problem outputs a
polynomial @xmath whose 1-sublevel set corresponds to the bounding
volume that we are interested in. A few remarks on this formulation are
in order:

-   The last constraint simply ensures that all the data points are
    within the 1-sublevel set of @xmath as required.

-   The second constraint imposes that @xmath be sos-convex. The matrix
    @xmath is the Gram matrix associated with the sos condition on
    @xmath .

-   The first constraint requires that the polynomial @xmath be sos.
    This is a necessary condition for boundedness of ( 7.3 ) when @xmath
    is parametrized with affine terms. To see this, note that for any
    given positive semidefinite matrix @xmath , one can always pick the
    coefficients of the affine terms in such a way that the constraint
    @xmath for @xmath be trivially satisfied. Likewise one can pick the
    remaining coefficients of @xmath in such a way that the
    sos-convexity condition is satisfied. The restriction to sos
    polynomials, however, can be done without loss of generality.
    Indeed, suppose that the minimum volume sublevel set was given by
    @xmath where @xmath is an sos-convex polynomial. As @xmath is convex
    and nonaffine, @xmath such that @xmath for all @xmath . Define now
    @xmath We have that @xmath , but here, @xmath is sos as it is
    sos-convex and nonnegative [ 89 , Lemma 8] .

The objective function of the above formulation is motivated in part by
the degree @xmath case. Indeed, when @xmath , the sublevel sets of
convex polynomials are ellipsoids of the form @xmath and their volume is
given by @xmath . Hence, by minimizing @xmath , we would exactly
minimize volume. As the matrix @xmath above is none other than the
Hessian of the quadratic polynomial @xmath (up to a multiplicative
constant), this partly justifies the formulation given in [ 130 ] .
Another justification for this formulation is given in [ 130 ] itself
and relates to curvature of the polynomial @xmath . Indeed, the
curvature of @xmath at a point @xmath along a direction @xmath is
proportional to @xmath . By imposing that @xmath with @xmath , and then
maximizing @xmath , this formulation seeks to increase the curvature of
@xmath along all directions so that its 1-sublevel set can get closer to
the points @xmath . Note that curvature maximization in all directions
without regards to data distribution can be counterproductive in terms
of tightness of fit, particularly in regions where the data geometry is
flat (an example of this is given in Figure 7.3 ).

A related minimum volume heuristic that we will also experiment with
replaces the @xmath objective with a linear one. More specifically, we
introduce an extra decision variable @xmath and minimize @xmath while
adding an additional constraint @xmath Using the Schur complement, the
latter constraint can be rewritten as @xmath . As a consequence, this
trace formulation minimizes the sum of the inverse of the eigenvalues of
@xmath whereas the @xmath formulation described in ( 7.3 ) minimizes the
product of the inverse of the eigenvalues.

###### Our approach

We propose here an alternative heuristic for obtaining a tight-fitting
convex body containing points in @xmath Empirically, we validate that it
tends to consistently return convex bodies of smaller volume than the
ones obtained with the methods described above (see Figure 7.3 below for
an example). It also generates a relatively smaller convex optimization
problem. Our formulation is as follows:

  -- -------- -- -------
     @xmath      
                 
     @xmath      
     @xmath      (7.4)
     @xmath      
  -- -------- -- -------

One can also obtain a trace formulation of this problem by replacing the
@xmath objective by a trace one as it was done in the previous
paragraph.

Note that the main difference between ( 7.3 ) and ( 7.4 ) lies in the
Gram matrix chosen for the objective function. In ( 7.3 ), the Gram
matrix comes from the sos-convexity constraint, whereas in ( 7.4 ), the
Gram matrix is generated by the sos constraint.

In the case where the polynomial is quadratic and convex, we saw that
the formulation ( 7.3 ) is exact as it finds the minimum volume
ellipsoid containing the points. It so happens that the formulation
given in ( 7.4 ) is also exact in the quadratic case, and, in fact, both
formulations return the same optimal ellipsoid. As a consequence, the
formulation given in ( 7.4 ) can also be viewed as a natural extension
of the quadratic case.

To provide more intuition as to why this formulation performs well, we
interpret the 1-sublevel set

  -- -------- --
     @xmath   
  -- -------- --

of @xmath as the preimage of some set whose volume is being minimized.
More precisely, consider the set

  -- -------- --
     @xmath   
  -- -------- --

which corresponds to the image of @xmath under the monomial map @xmath
and the set

  -- -------- --
     @xmath   
  -- -------- --

for a positive semidefinite matrix @xmath such that @xmath Then, the set
@xmath is simply the preimage of the intersection of @xmath and @xmath
through the mapping @xmath . Indeed, for any @xmath , we have @xmath .
The hope is then that by minimizing the volume of @xmath , we will
minimize volume of the intersection @xmath and hence that of its
preimage through @xmath , i.e., the set @xmath

We illustrate this idea in Figure 7.2 . Here, we have generated a random
@xmath positive semidefinite matrix @xmath and a corresponding bivariate
degree-4 sos polynomial @xmath , where @xmath is a map from @xmath to
@xmath . We have drawn in red the image of @xmath under @xmath and in
green the ellipsoid @xmath The preimage of the intersection of both sets
seen in Figure 7.2 on the right corresponds to the 1-sublevel set of
@xmath

##### 7.3.2 Relaxing convexity

Though containing a set of points with a convex sublevel set has its
advantages, it is sometimes necessary to have a tighter fit than the one
provided by a convex body, particularly if the object of interest is
highly nonconvex. One way of handling such scenarios is via convex
decomposition methods [ 120 , 133 ] , which would enable us to represent
the object as a union of sos-convex bodies. Alternatively, one can aim
for problem formulations where convexity of the sublevel sets is not
imposed. In the remainder of this subsection, we first review a recent
approach from the literature to do this and then present our own
approach which allows for controlling the level of nonconvexity of the
sublevel set.

###### The inverse moment approach

In very recent work [ 113 ] , Lasserre and Pauwels propose an approach
for containing a cloud of points with sublevel sets of polynomials (with
no convexity constraint). Given a set of data points @xmath , it is
observed in that paper that the sublevel sets of the degree @xmath sos
polynomial

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

tend to take the shape of the data accurately. Here, @xmath is the
vector of all monomials of degree up to @xmath and @xmath is the moment
matrix of degree @xmath associated with the empirical measure @xmath
defined over the data. This is an @xmath symmetric positive semidefinite
matrix which can be cheaply constructed from the data @xmath (see [ 113
] for details). One very nice feature of this method is that to
construct the polynomial @xmath in ( 7.5 ) one only needs to invert a
matrix (as opposed to solving a semidefinite program as our approach
would require) after a single pass over the point cloud. The approach
however does not a priori provide a particular sublevel set of @xmath
that is guaranteed to contain all data points. Hence, once @xmath is
constructed, one could slowly increase the value of a scalar @xmath and
check whether the @xmath -sublevel set of @xmath contains all points.

###### Our approach and controlling convexity

An advantage of our proposed formulation ( 7.4 ) is that one can easily
drop the sos-convexity assumption in the constraints and thereby obtain
a sublevel set which is not necessarily convex. This is not an option
for formulation ( 7.3 ) as the Gram matrix associated to the
sos-convexity constraint intervenes in the objective.

Note that in neither this formulation nor the inverse moment approach of
Lasserre and Pauwels, does the optimizer have control over the shape of
the sublevel sets produced, which may be convex or far from convex. For
some applications, it is useful to control in some way the degree of
convexity of the sublevel sets obtained by introducing a parameter which
when increased or decreased would make the sets more or less convex.
This is what our following proposed optimization problem does via the
parameter @xmath , which corresponds in some sense to a measure of
convexity:

  -- -------- -- -------
     @xmath      
                 
     @xmath      (7.6)
     @xmath      
     @xmath      
  -- -------- -- -------

Note that when @xmath , the problem we are solving corresponds exactly
to ( 7.4 ) and the sublevel set obtained is convex. When @xmath , we
allow for nonconvexity of the sublevel sets. Note that this is a
consequence of @xmath being a strictly convex function, which can offset
the nonconvexity of @xmath . As we decrease @xmath towards zero, we
obtain sublevel sets which get progressively more and more convex.

##### 7.3.3 Bounding volume numerical experiments

Figure 7.1 (left) shows the 1-sublevel sets of sos-convex bodies with
degrees @xmath , @xmath , and @xmath . A degree- @xmath polynomial gives
a much tighter fit than an ellipsoid (degree 2). In the middle figure,
we freeze the degree to be @xmath and increase the convexity parameter
@xmath in the relaxed convexity formulation of problem ( 7.6 ); the
1-sublevel sets of the resulting sos polynomials with @xmath are shown.
It can be seen that the sublevel sets gradually bend to better adapt to
the shape of the object. The right figure shows the @xmath and @xmath
sublevel sets of a degree- @xmath polynomial obtained by fixing @xmath
in problem ( 7.6 ): the shape is retained as the body is expanded or
contracted.

Figure 7.3 shows 1-sublevel sets of two degree-6 sos-convex polynomials.
In red, we have plotted the sublevel set corresponding to maximizing
curvature as explained in Section 7.3.1 . In green, we have plotted the
sublevel set generated by our approach as explained in Section 7.3.1 .
Note that our method gives a tighter-fitting sublevel set, which is in
part a consequence of the flat data geometry for which the maximum
curvature heuristic does not work as well.

In Table 7.1 , we provide a comparison of various bounding volumes on
Princeton Shape Benchmark datasets [ 180 ] . It can be seen that
sos-convex bodies generated by higher degree polynomials provide much
tighter fits than spheres or axis-aligned bounding boxes (AABB) in
general. The proposed minimum volume heuristic of our formulation in (
7.4 ) works better than that proposed in [ 130 ] (see ( 7.3 )). In both
formulations, typically, the log-determinant objective outperforms the
trace objective. The convex hull is the tightest possible convex body.
However, for smooth objects like the vase, the number of vertices
describing the convex hull can be a substantial fraction of the original
number of points in the point cloud. When convexity is relaxed, a
degree-6 sos polynomial compactly described by just @xmath coefficients
gives a tighter fit than the convex hull. For the same degree, solutions
to our formulation ( 7.6 ) with a positive value of @xmath outperform
the inverse moment construction of [ 113 ] .

The bounding volume construction times are shown in Figure 7.4 for
sos-convex chair models. In comparison to the volume heuristics of [ 130
] , our heuristic runs noticeably faster as soon as degree exceeds
@xmath . We believe that this may come from the fact that the decision
variable featuring in the objective in our case is a matrix of size
@xmath , where @xmath , whereas the decision variable featuring in the
objective of [ 130 ] is of size @xmath where @xmath Our implementation
uses YALMIP [ 125 ] with the splitting conic solver (SCS) [ 149 ] as its
backend SDP solver (run for 2500 iterations). Note that the inverse
moment approach of [ 113 ] is the fastest as it does not involve any
optimization and makes just one pass over the point cloud. However, this
approach is not guaranteed to return a convex body, and for nonconvex
bodies, tighter fitting polynomials can be estimated using
log-determinant or trace objectives on our problem ( 7.6 ).

#### 7.4 Measures of separation and penetration

##### 7.4.1 Euclidean distance

In this section, we are interested in computing the Euclidean distance
between two basic semialgebraic sets

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

(where @xmath and @xmath are polynomials). This can be written as the
following polynomial optimization problem:

  -- -------- -- -------
     @xmath      (7.7)
  -- -------- -- -------

We will tackle this problem by applying the sos hierarchy described at
the end of Section 7.2 . This will take the form of the following
hierarchy of semidefinite programs

  -- -- -------- -------- -------
        @xmath            (7.8)
                 @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- -------

where in the @xmath -th level of the hierarchy, the degree of all
polynomials @xmath and @xmath is upper bounded by @xmath . Observe that
the optimal value of each SDP produces a lower bound on ( 7.7 ) and that
when @xmath increases, this lower bound can only improve.

Amazingly, in all examples we tried (independently of convexity of
@xmath and @xmath ), the 0-th level of the hierarchy was already exact
(though we were unable to prove this). By this we mean that the optimal
value of ( 7.8 ) exactly matched that of ( 7.7 ), already when the
degree of the polynomials @xmath and @xmath was zero; i.e., when @xmath
and @xmath were nonnegative scalars. An example of this phenomenon is
given in Figure 7.5 where the green bodies are each a (highly nonconvex)
sublevel set of a quartic polynomial.

When our SDP relaxation is exact, we can recover the points @xmath and
@xmath where the minimum distance between sets is achieved from the
eigenvector corresponding to the zero eigenvalue of the Gram matrix
associated with the first sos constraint in ( 7.8 ). This is what is
done in Figure 7.5 .

The sos-convex case. One important special case where we know that the
0-th level of the sos hierarchy in ( 7.8 ) is guaranteed to be exact is
when the defining polynomials @xmath and @xmath of @xmath and @xmath are
sos-convex . This is a corollary of the fact that the 0-th level sos
relaxation is known to be tight for the general polynomial optimization
problem in ( 7.1 ) if the polynomials @xmath and @xmath involved in the
description of @xmath there are sos-convex; see [ 110 ] . An example of
the computation of the minimum distance between two degree-6 sos-convex
bodies enclosing human and chair 3D point clouds is given below,
together with the points achieving the minimum distance.

Using MATLAB’s fmincon active-set solver, the time required to compute
the distance between two sos-convex bodies ranges from around 80
milliseconds to 340 milliseconds seconds as the degree is increased from
@xmath to @xmath ; see Table 7.2 . We believe that the execution time
can be improved by an order of magnitude with more efficient polynomial
representations, warm starts for repeated queries, and reduced
convergence tolerance for lower-precision results.

##### 7.4.2 Penetration measures for overlapping bodies

As another application of sos-convex polynomial optimization problems,
we discuss a problem relevant to collision avoidance. Here, we assume
that our two bodies @xmath , @xmath are of the form @xmath and @xmath
where @xmath are sos-convex. As shown in Figure 7.1 (right), by varying
the sublevel value, we can grow or shrink the sos representation of an
object. The following convex optimization problem, with optimal value
denoted by @xmath , provides a measure of separation or penetration
between the two bodies:

  -- -------- -- -------
     @xmath      
     @xmath      (7.9)
  -- -------- -- -------

Note that the measure is asymmetric, i.e., @xmath . It is clear that

  -- -------- --
     @xmath   
  -- -------- --

In other words, the sets @xmath and @xmath do not overlap. As a
consequence, the optimal value of ( 7.9 ) gives us a measure of how much
we need to shrink the level set defined by @xmath to eventually move out
of contact of the set @xmath assuming that the “seed point”, i.e., the
minimum of @xmath , is outside @xmath . It is clear that,

-   if @xmath , the bounding volumes are separated.

-   if @xmath , the bounding volumes touch.

-   if @xmath , the bounding volumes overlap.

These measures are closely related to the notion of growth models and
growth distances [ 150 ] . Note that similarly to what is described for
the sos-convex case in Section 7.4.1 , the optimal solution @xmath to (
7.9 ) can be computed exactly using semidefinite programming, or using a
generic convex optimizer. The two leftmost subfigures of Figure 7.7 show
a chair and a human bounded by 1-sublevel sets of degree 6 sos-convex
polynomials (in green). In both cases, we compute @xmath and @xmath and
plot the corresponding minimizers. In the first subfigure, the level set
of the chair needs to grow in order to touch the human and vice-versa,
certifying separation. In the second subfigure, we translate the chair
across the volume occupied by the human so that they overlap. In this
case, the level sets need to contract. In the third subfigure, we plot
the optimal value of the problem in ( 7.9 ) as the chair is translated
from left to right, showing how the growth distances dip upon
penetration and rise upon separation. The final subfigure shows the time
taken to solve ( 7.9 ) when warm started from the previous solution. The
time taken is of the order of 150 milliseconds without warm starts to 10
milliseconds with warm starts.

#### 7.5 Containment of polynomial sublevel sets

In this section, we show how the sum of squares machinery can be used in
a straightforward manner to contain polynomial sublevel sets (as opposed
to point clouds) with a convex polynomial level set. More specifically,
we are interested in the following problem: Given a basic semialgebraic
set

  -- -------- -- --------
     @xmath      (7.10)
  -- -------- -- --------

find a convex polynomial @xmath of degree @xmath such that

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

Moreover, we typically want the unit sublevel set of @xmath to have
small volume. Note that if we could address this question, then we could
also handle a scenario where the unit sublevel set of @xmath is required
to contain the union of several basic semialgebraic sets (simply by
containing each set separately). For the 3D geometric problems under our
consideration, we have two applications of this task in mind:

-    Convexification: In some scenarios, one may have a nonconvex outer
    approximation of an obstacle (e.g., obtained by the computationally
    inexpensive inverse moment approach of Lasserre and Pauwels as
    described in Section 7.3.2 ) and be interested in containing it with
    a convex set. This would e.g. make the problem of computing
    distances among obstacles more tractable; cf. Section 7.4 .

-    Grouping multiple obstacles: For various navigational tasks
    involving autonomous agents, one may want to have a mapping of the
    obstacles in the environment in varying levels of resolution. A
    relevant problem here is therefore to group obstacles: this would
    lead to the problem of containing several polynomial sublevel sets
    with one.

In order to solve the problem laid out above, we propose the following
sos program:

  -- -- -------- -- --------
        @xmath      
        @xmath      
        @xmath      (7.12)
        @xmath      (7.13)
        @xmath      (7.14)
  -- -- -------- -- --------

It is straightforward to see that constraints ( 7.13 ) and ( 7.14 )
imply the required set containment criterion in ( 7.11 ). As usual, the
constraint in ( 7.12 ) ensures convexity of the unit sublevel set of
@xmath . The objective function attempts to minimize the volume of this
set. A natural choice for the degree @xmath of the polynomials @xmath is
@xmath , though better results can be obtained by increasing this
parameter.

An analoguous problem is discussed in recent work by Dabbene, Henrion,
and Lagoa [ 48 , 49 ] . In the paper, the authors want to find a
polynomial @xmath of degree @xmath whose 1-superlevel set @xmath
contains a semialgebraic set @xmath and has minimum volume. Assuming
that one is given a set @xmath containing @xmath and over which the
integrals of polynomials can be efficiently computed, their method
involves searching for a polynomial @xmath of degree @xmath which
minimizes @xmath while respecting the constraints @xmath on @xmath and
@xmath on @xmath . Note that the objective is linear in the coefficients
of @xmath and that these last two nonnegativity conditions can be made
computationally tractable by using the sum of squares relaxation. The
advantage of such a formulation lies in the fact that when the degree of
the polynomial @xmath increases, the objective value of the problem
converges to the true volume of the set @xmath .

Example. In Figure 7.8 , we have drawn in black three random ellipsoids
and a degree-4 convex polynomial sublevel set (in yellow) containing the
ellipsoids. This degree-4 polynomial was the output of the optimization
problem described above where the sos multipliers @xmath were chosen to
have degree @xmath .

We end by noting that the formulation proposed here is backed up
theoretically by the following converse result.

###### Theorem 7.5.1.

Suppose the set @xmath in ( 7.10 ) is Archimedean and that @xmath Then
there exists an integer @xmath and sum of squares polynomials @xmath of
degree at most @xmath such that

  -- -------- -- --------
     @xmath      (7.15)
  -- -------- -- --------

is a sum of squares.

###### Proof.

The proof follows from a standard application of Putinar’s
Positivstellensatz [ 162 ] and is omitted. ∎

### Chapter 8 Nonnegative polynomials and shape-constrained regression

Unlike the other chapters in this thesis, the paper on which this
chapter is based is still in preparation. We recommend that future
readers read the submitted version of this chapter if it is available at
the time of reading.

#### 8.1 Introduction

Regression is a key problem in statistics and machine learning. Its goal
is to estimate relationships between an explained variable (e.g., the
price of a second-hand car) and a vector of explanatory variables (e.g.,
the make, brand, mileage, power, or age of this car). In many
applications, one can observe a monotonous dependency between the
explained variable and the explanatory variables. Examples arise in many
different areas, including medicine, e.g., loss of hippocampus gray
matter with respect to age [ 100 ] or survival rate with respect to
white blood cell count in patients fighting leukemia [ 171 ] ; biology
and environmental engineering, e.g., frequency of occurrence of a
specific plant as a function of environment pollution [ 142 ] ;
electrical and computer engineering, e.g., failure rate of software as a
function of number of bugs [ 139 ] ; economics, e.g., production output
of a competitive firm as a function of its inputs, [ 14 ] ; and civil
engineering, e.g., total shaded area on the floor of a room as a
function of length of a blind over the window in that room [ 41 ] , to
name a few.

In addition or in parallel to monotonicity, one may also wish to impose
convexity or concavity constraints on the regressor. Examples where such
a need arises are given, e.g., in [ 197 ] . They include geometric
programming [ 35 ] , computed tomography [ 161 ] , target reconstruction
[ 117 ] , circuit design [ 83 ] , queuing theory [ 42 ] , and utility
function estimation in economics [ 138 ] .

In the following, we refer to the problem of fitting a convex or
monotonous regressor to data as shape-constrained regression . As
evidenced above, this problem appears ubiquitously in applications and
has consequently been widely studied. We review prior literature on both
monotone and convex regression below. We focus on polynomial regression
as this will be the subject of interest throughout this chapter.

###### Prior work on monotone regression.

Past work on monotonically-constrained polynomial regression has by and
large focused on univariate polynomials. Methods that enforce
monotonicity include specific parametrizations of polynomial families
(see [ 63 ] and [ 136 ] ) or iterative algorithms that leverage
geometric properties of univariate polynomials (in [ 87 ] for example,
the derivative of the polynomial is constrained to be zero at inflection
points). Extensions to multivariate polynomials involve adding
univariate polynomials together to get a (separable) multivariate
polynomial, which ignores interactions between explanatory variables
(see [ 136 ] ). Furthermore, all the methods considered in this
paragraph impose monotonicity of the regressor globally, as opposed to
over a given set, which may be too restrictive.

Another way of obtaining monotonous (but not necessarily polynomial)
predictive models is via the use of artificial neural networks (ANNs).
The easiest way to guarantee that an ANN outputs an increasing function
with respect to all features is to keep the edge weights in the neural
net nonnegative, see [ 195 , 103 , 60 , 61 , 199 ] . However, it has
been shown in [ 51 ] that in order for a neural network with nonnegative
weights to approximate any monotonically increasing function in @xmath
features arbitrarily well, the ANN must have @xmath fully connected
hidden layers, which can lead to computational limitations and requires
a large training dataset.

Interpolated look-up tables are another popular approach to monotone
regression (see, e.g., [ 78 ] ). Here, the feature space is discretized
into different cells, and each point in the feature space @xmath is
associated to a vector of linear interpolation weights @xmath , which
reflects the distance of @xmath to each vertex of the specific cell it
belongs to. The function we wish to learn is then given by a linear
combination of @xmath , i.e., @xmath , and the parameter @xmath is
obtained by solving @xmath , where @xmath is a convex loss function. If
the entries of @xmath satisfy some pairwise constraints, then the
function @xmath is guaranteed to be monotonous. We remark that in this
approach, the size of @xmath , and so the number of variables, is
exponential in the number of features.

Finally, we mention two other research directions which also involve
breaking down the feature domain into smaller subsets. These are
regression trees and isotonic regression . In the first, the feature
domain is recursively partitioned into smaller subdomains, where
interactions between features are more manageable. On each subdomain, a
fit to the data is computed, and to obtain a function over the whole
domain, the subdomain fits are aggregated, via, e.g., gradient boosting;
see [ 36 , 68 , 167 , 69 ] . To obtain monotone regressors, one enforces
monotonicity on each subregion, as aggregation maintains this structural
property [ 43 , 97 ] . In the second method, a piecewise constant
function @xmath is fitted to the data in such a way that @xmath if
@xmath and @xmath are breakpoints of the function and @xmath , where
@xmath is some partial or total ordering. Both of these methods present
some computational challenges in the sense that, much like interpolated
look-up tables, they scale poorly in the number of features. In the case
of the second method, the function produced also lacks some desirable
analytic properties, such as smoothness and differentiability.

###### Prior work on convex regression.

The work by Magnani, Lall, and Boyd in [ 130 ] is the closest to what is
presented in this chapter. Similarly to what is done here, a sum of
squares approach to impose convexity of their polynomial regressor is
used in that reference. However, contrarily to us, convexity is imposed
globally, and not locally. Furthermore, our focus in this chapter is on
approximation results and computational complexity analysis, which is
not a focus of their work. Other methods for computationally efficient
convex regression involve fitting a piecewise linear model to data. This
is done, e.g., in [ 84 , 129 ] . Other related work in the area consider
convex regression from a more statistical viewpoint. The reference in [
77 ] for example, studies maximum likelihood estimation for univariate
convex regression whereas [ 178 ] , [ 121 ] , and more recently [ 135 ]
study the multivariate case. In particular, the first two papers show
consistency of the maximum likelihood estimator whereas the latter paper
provides a more efficient and scalable framework for its computation.

##### 8.1.1 Outline

The outline of the chapter is as follows. In Section 8.2 , we specify
our problem formulation in more detail. In particular, we define the
notion of monotonicity profile (which encodes how the polynomial
regressor varies depending on each variable) in Definition 8.2.3 . In
Section 8.3 , we show that both the problem of testing whether a
polynomial has a certain monotonicity profile over a box and the problem
of testing whether a polynomial is convex over a box are NP-hard already
for cubic polynomials (Theorems 8.3.1 and 8.3.2 ). This motivates our
semidefinite programming-based relaxations for fitting a polynomial that
is constrained to be monotone or convex to data. These are presented in
Section 8.4 . Among other things, we show that any monotone (resp.
convex) function can be approximated to arbitrary accuracy by monotone
(resp. convex) polynomials, with sum of squares certificates of these
properties (Theorems 8.4.1 and 8.4.6 ). In Section 8.5 , we show how our
methods perform on synthetic regression problems as well as real-world
problems (namely predicting interest rates for personal loans and
predicting weekly wages). In particular, we show that in both real-world
problems, the shape-constrained regressor provides a lower root mean
squared error on testing data than the unconstrained regressor.

##### 8.1.2 Notation

We briefly introduce some notation that will be used in the rest of the
chapter. A matrix @xmath is said to be positive semidefinite (psd) if
@xmath for all @xmath We write @xmath to signify that @xmath is psd. We
will denote by @xmath (resp. @xmath ) the largest (resp. smallest)
eigenvalue of @xmath . Given positive integers @xmath and @xmath , we
let @xmath and @xmath be the matrices of dimension @xmath which contain
respectively all zeros, or all ones. We will write @xmath for the
identity matrix and @xmath for the @xmath basis vector, i.e., a vector
in @xmath of all zeros, except for the @xmath component which is equal
to 1. Finally, we denote the Hessian matrix of a twice continuously
differentiable function @xmath by @xmath .

#### 8.2 Problem formulation

In this chapter, we consider the problem of polynomial regression ,
i.e., the problem of fitting a polynomial function @xmath to data points
@xmath , @xmath . Here, @xmath is a vector in @xmath , often called the
feature vector or vector of explanatory variables , and @xmath is a
scalar corresponding to the response. To obtain our regressor @xmath ,
we fix its degree and search for its coefficients such that @xmath
minimizes some convex loss function. This could be, e.g., the least
squares error ,

  -- -------- --
     @xmath   
  -- -------- --

or, the least absolute deviation error ,

  -- -------- --
     @xmath   
  -- -------- --

In our setting, we would additionally like to add shape constraints to
our regressor, such as monotonicity or convexity. More specifically, we
consider the model we outline next. We assume that @xmath is a
measurement of an underlying unknown (not necessarily polynomial)
function @xmath at point @xmath corrupted by some noise @xmath . In
other words, we have

  -- -------- -- -------
     @xmath      (8.1)
  -- -------- -- -------

We further assume that we possess prior knowledge regarding the shape of
@xmath , e.g., increasing in variable @xmath or convex over a certain
region. We would then like our regressor @xmath to have the same
attributes. This is a very natural problem when considering applications
such as those discussed in the introduction of this chapter.

Throughout the chapter, we assume that our feature vectors @xmath belong
to a box

  -- -------- -- -------
     @xmath      (8.2)
  -- -------- -- -------

where @xmath are real numbers satisfying @xmath . In practice, this is
often, if not always, the case, as features are generally known to lie
within certain ranges. We would like to mention nevertheless that the
techniques presented in this chapter can be extended to any feature
domain that is basic semialgebraic , i.e., defined by a finite number of
polynomial equalities and inequalities. The shape constraints we define
next are assumed to hold over this box: they are, respectively,
monotonicity over @xmath with respect to a feature and convexity over
@xmath .

###### Definition 8.2.1 (Monotonicity over a box with respect to a
variable).

We say that a function @xmath is monotonically increasing ¹ ¹ 1
Throughout this chapter, we will use the terminology increasing (resp.
decreasing) to describe a property which is perhaps more commonly
referred to as nondecreasing (resp. nonincreasing). This is to avoid
potential confusion arising from the use of a negation. over a box
@xmath with respect to a variable @xmath if

  -- -------- --
     @xmath   
  -- -------- --

for any fixed @xmath , @xmath with @xmath . Similarly, we say that
@xmath is monotonically decreasing over @xmath with respect to variable
@xmath if

  -- -------- --
     @xmath   
  -- -------- --

for any fixed @xmath , @xmath with @xmath .

For differentiable functions, an equivalent definition of monotonicity
with respect to a variable—and one we will use more frequently—is given
below.

###### Lemma 8.2.2.

A differentiable function @xmath is monotonically increasing (resp.
decreasing) over a box @xmath with respect to a variable @xmath if and
only if @xmath (resp. @xmath ) for all @xmath

###### Proof.

We prove the increasing version of the theorem as the decreasing version
is analogous. Suppose that @xmath is monotonically increasing with
respect to variable @xmath . This implies that for any fixed @xmath and
for any @xmath with @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

which is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

By taking the limit as @xmath , we obtain that @xmath for all @xmath

Suppose now that @xmath for all @xmath Fix any point @xmath . There
exists @xmath such that @xmath By Taylor’s formula with an integral
remainder, we have

  -- -------- --
     @xmath   
  -- -------- --

which is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath and @xmath is a box, @xmath for any @xmath . Hence

  -- -------- --
     @xmath   
  -- -------- --

As we are integrating a nonnegative integrand, we get that @xmath for
any nonnegative @xmath . This concludes our proof as @xmath implies that
@xmath for some @xmath . ∎

We now define a notion that encapsulates how a differentiable function
varies with respect to each of its variables.

###### Definition 8.2.3 (Monotonicity profile).

For any differentiable function @xmath , its monotonicity profile over a
box @xmath is a vector in @xmath with entries defined as follows:

  -- -------- --
     @xmath   
  -- -------- --

When we assume that we have prior knowledge with respect to monotonicity
of our underlying function @xmath in ( 8.1 ), we in fact mean that we
have access to the monotonicity profile of @xmath .

We now consider another type of shape constraint that we are interested
in: convexity over a box.

###### Definition 8.2.4 (Convexity over a box).

We say that a function @xmath is convex over a box @xmath if

  -- -------- --
     @xmath   
  -- -------- --

###### Proposition 8.2.5.

A twice-differentiable function @xmath is convex over a box @xmath if
and only if @xmath for all @xmath .

The proof of this proposition readily follows from the proof of the
analogous proposition for global convexity; see, e.g., Theorem 22.5 in [
45 ] .

#### 8.3 Computational complexity results

As mentioned previously, we would like to optimize some convex loss
function over the set of polynomial regressors constrained to be convex
or monotonous over a box @xmath . In this section, we show that, unless
P=NP, one has no hope of doing this in a tractable fashion as even the
problem of testing if a given polynomial has these properties is
NP-hard.

###### Theorem 8.3.1.

Given a cubic polynomial @xmath , a box @xmath , and a monotonicity
profile @xmath , it is NP-hard to test whether @xmath has profile @xmath
over @xmath .

###### Proof.

We provide a reduction from the MAX-CUT problem, which is well known to
be NP-hard [ 71 ] . Consider an unweighted undirected graph @xmath with
no self-loops. A cut in @xmath is a partition of the @xmath nodes of the
graph into two sets, @xmath and @xmath . The size of the cut is the
number of edges connecting a node in @xmath to a node in @xmath .
MAX-CUT is the following decision problem: given a graph @xmath and an
integer @xmath , test whether @xmath has a cut of size at least @xmath .
We denote the adjacency matrix of the graph @xmath by @xmath , i.e.,
@xmath is an @xmath matrix such that @xmath if @xmath and @xmath
otherwise. We let

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath is an integer and an upper bound on the largest
eigenvalue of @xmath from Gershgorin’s circle theorem [ 73 ] .

We will show that testing whether @xmath has a cut of size at least
@xmath is equivalent to testing whether the polynomial

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

has monotonicity profile @xmath over @xmath .

First, note that @xmath has profile @xmath over @xmath if and only if

  -- -------- --
     @xmath   
  -- -------- --

We have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Hence, testing whether @xmath has profile @xmath over @xmath is
equivalent to testing whether the optimal value of the quadratic program

  -- -- -------- -- -------- -------- -------
        @xmath      @xmath            (8.3)
                             @xmath   
  -- -- -------- -- -------- -------- -------

is greater or equal to @xmath . As @xmath is an upperbound on the
maximum eigenvalue of @xmath , we have @xmath , which implies that
@xmath is a concave function. It is straightforward to show (see, e.g.,
[ 27 , Property 12] ) that the minimum of a concave function over a
compact set is attained at an extreme point of the set. As a
consequence, one can rewrite ( 8.3 ) as

  -- -- -------- -- -------- --
        @xmath      @xmath   
                    @xmath   
  -- -- -------- -- -------- --

As @xmath when @xmath , testing whether @xmath has profile @xmath over
@xmath is in fact equivalent to testing whether

  -- -------- -------- -- -------- -------- -------
     @xmath   @xmath      @xmath            (8.4)
                                   @xmath   
  -- -------- -------- -- -------- -------- -------

is greater or equal to @xmath .

It is easy to check that the size of the maximum cut in @xmath is equal
to @xmath . Testing whether @xmath contains a cut of size at least
@xmath is hence equivalent to testing whether

  -- -------- --
     @xmath   
  -- -------- --

As shown above, this is exactly equivalent to testing whether @xmath has
profile @xmath over @xmath , which concludes the proof.

∎

We remark that this theorem is minimal in the degree of the polynomial
in the sense that testing whether a quadratic polynomial @xmath has a
given monotonicity profile @xmath over a box @xmath is a computationally
tractable problem. Indeed, this simply amounts to testing whether the
linear function @xmath is nonnegative over @xmath for all @xmath This
can be done by solving a sequence of linear programs (in polynomial
time) indexed by @xmath —where the objective is @xmath and the
constraints are given by the box—and testing if the optimal value is
negative for some @xmath .

###### Theorem 8.3.2.

Given a cubic polynomial @xmath and a box @xmath , it is NP-hard to test
whether @xmath is convex over @xmath .

The proof of this theorem will use the following result of Nemirovskii [
144 ] .

###### Lemma 8.3.3 (cf. proof of Proposition 2.1. in [144]).

Given a positive integer @xmath and an @xmath -dimensional vector @xmath
with rational positive entries and with @xmath , let @xmath and @xmath
where @xmath is the smallest common denominator of all entries of @xmath
. Then, it is NP-hard to decide whether

  -- -------- -- -------
     @xmath      (8.5)
  -- -------- -- -------

Furthermore, for any vector @xmath , either ( 8.5 ) holds (i.e., @xmath
, @xmath ) or there exists @xmath with @xmath such that @xmath

###### Proof of Theorem 8.3.2.

We show this result via a reduction from the NP-hard problem given in
Lemma 8.3.3 . Let @xmath be a positive integer and @xmath be an @xmath
-dimensional vector with rational entries. Let @xmath to be an @xmath
matrix as defined in ( 8.5 ) and set @xmath to be the @xmath matrix of
mixed partial derivatives of the cubic polynomial @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

Note that the entries of @xmath are linear in @xmath . Consider now the
matrix @xmath , which is a symmetric matrix with entries quadratic in
@xmath , i.e., its @xmath -entry is given by @xmath , where @xmath , for
all @xmath , is an @xmath matrix. Denote by @xmath the maximum entry in
absolute value of the matrix @xmath and set

  -- -- -------- -------- -------
        @xmath            (8.6)
                 @xmath   
                 @xmath   
  -- -- -------- -------- -------

Consider the cubic polynomial

  -- -------- --
     @xmath   
  -- -------- --

and the box

  -- -------- --
     @xmath   
  -- -------- --

We will show that @xmath is convex over @xmath if and only if @xmath for
all @xmath Note that the Hessian of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an @xmath diagonal matrix with the vector @xmath on its
diagonal. Hence, we need to show that @xmath over @xmath if and only if
@xmath over @xmath

We start by showing that if @xmath is not positive semidefinite over
@xmath , then @xmath is not positive semidefinite over @xmath . As
@xmath is not positive semidefinite over @xmath , from Lemma 8.3.3 ,
there exists @xmath such that @xmath Let @xmath and observe that @xmath
Let

  -- -------- --
     @xmath   
  -- -------- --

We have

  -- -------- -------- -------- -------
     @xmath   @xmath            (8.7)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- -------

Since @xmath and @xmath , we have

  -- -------- -- -------
     @xmath      (8.8)
  -- -------- -- -------

Furthermore,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where we have used in the last two inequalities the facts that @xmath
@xmath , and @xmath . Combining this with ( 8.7 ) and ( 8.8 ), we get

  -- -------- --
     @xmath   
  -- -------- --

Replacing @xmath by its expression in ( 8.6 ), we obtain:

  -- -------- --
     @xmath   
  -- -------- --

and conclude that @xmath is not positive semidefinite over @xmath .

Suppose now that @xmath for all @xmath We will show that @xmath for all
@xmath As @xmath , we equivalently show, using the Schur complement,
that

  -- -------- --
     @xmath   
  -- -------- --

As @xmath for any @xmath , it remains to show that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath Fix @xmath . Note that

  -- -------- --
     @xmath   
  -- -------- --

and that @xmath . Recall that entry @xmath of @xmath is given by @xmath
and that @xmath is the maximum entry in absolute value of @xmath .
Simple algebra and the fact that @xmath show that @xmath . We then have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the first inequality is a consequence of Gershgorin’s circle
theorem [ 73 ] . We deduce that

  -- -------- --
     @xmath   
  -- -------- --

Replacing @xmath by its expression given in ( 8.6 ), we get that

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof. ∎

Note that again this theorem is minimal in the degree of the polynomial.
Indeed testing whether a quadratic polynomial is convex over a box is
equivalent to testing if a quadratic form is convex over @xmath (this is
a consequence of the Hessian being constant). The latter condition can
be tested by checking if its (constant) Hessian matrix is positive
semidefinite. This can be done in polynomial time [ 143 ] .

Independently of shape-constrained regression, we would like to remark
that Theorem 8.3.2 is interesting in its own right. It has been shown in
[ 10 ] that testing whether a quartic polynomial is convex over @xmath
is an NP-hard problem. One could wonder if this problem would get any
easier over a region. This theorem answers the question in the negative,
and shows that this problem is hard even for lower-degree polynomials.
This is particularly relevant as subroutines of some optimization
software (e.g., BARON [ 169 ] ) involve testing convexity of functions
over a set (typically a box). The result presented here shows that
efficient algorithms for testing convexity over a box are very unlikely
to always return the correct answer.

#### 8.4 Semidefinite programming-based relaxations

In light of the previous hardness results, we provide tractable
relaxations of the previous concepts, i.e., monotonocity over a box and
convexity over a box, involving semidefinite programming. These
relaxations are based on the notion of sum of squares polynomials, which
we provide a brief exposition of below.

##### 8.4.1 Review of sum of squares polynomials

A polynomial @xmath is a sum of squares (sos) if it can be written as a
sum of squares of other polynomials, i.e., @xmath where @xmath are some
polynomials. Being a sum of squares is obviously a sufficient condition
for nonnegativity. It is not however necessary, as the Motzkin
polynomial (which is nonnegative but not sos) can attest to [ 141 ] .
Sum of squares polynomials are widely used as a surrogate for
nonnegative polynomials as one can optimize over the set of sos
polynomials using semidefinite programming (SDP) contrarily to
nonnegative polynomials, which form an intractable set to optimize over.
The fact that one can optimize over the set of sos polynomials using
semidefinite programming is the consequence of the following theorem: a
polynomial @xmath of degree @xmath is a sum of squares if and only if
there exists a positive semidefinite matrix @xmath such that @xmath ,
where @xmath is the vector of standard monomials of degree @xmath . We
say that an @xmath polynomial matrix @xmath is an sos-matrix if there
exists a polynomial matrix @xmath of size @xmath , where @xmath is some
integer, such that @xmath . This is equivalent to the polynomial @xmath
in @xmath variables @xmath being a sum of squares.

##### 8.4.2 Relaxations and approximation results

In this section, we revisit the task of fitting a polynomial function
@xmath to data @xmath generated from noisy measurements of a function
@xmath :

  -- -------- -- -------
     @xmath      (8.9)
  -- -------- -- -------

With no constraints on the regressor, this fit can be obtained by
minimizing some convex loss function such as the least squares error
@xmath Here, we consider two different cases of constrained regression,
corresponding to two shape constraints on the function @xmath in ( 8.9 )
that generates the data. For concreteness, we will throughout use the
least squares error as our convex loss function, though our algorithms
can be extended to hold for other convex loss functions such as the
least absolute deviation function or any sos-convex polynomial loss
function.

###### Monotonically-constrained polynomial regression

We assume that the monotonicity profile @xmath of @xmath in ( 8.9 ) as
well as a box @xmath which contains the feature vectors are given. We
wish to fit a polynomial @xmath to data @xmath generated using @xmath ,
such that @xmath also has monotonicity profile @xmath over @xmath . In
other words, we are interested in solving the following optimization
problem:

  -- -------- -------- -- -------- -------- --------
     @xmath   @xmath      @xmath            (8.10)
                                   @xmath   
  -- -------- -------- -- -------- -------- --------

Theorem 8.3.1 suggests that this problem cannot be solved efficiently
unless @xmath . We present here a relaxation of this problem with some
formal guarantees.

###### Theorem 8.4.1.

Let @xmath be a @xmath function with monotonicity profile @xmath over a
box

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

For any @xmath , there exists an integer @xmath and a polynomial @xmath
of degree @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and such that @xmath has same monotonicity profile @xmath over @xmath .
Furthermore, this monotonicity profile can be certified using sums of
squares certificates.

Note that the definition of the box given here is slightly different to
the one given in ( 8.2 ). The way the feature box is described actually
comes into play in the structure of the certificate of nonnegativity of
the derivative of @xmath which we wish to obtain for Theorem 8.4.1 . A
similar result to the one given above can be obtained using the
definition of the box given in ( 8.2 ). We will discuss this distinction
further in Remark 8.4.4 .

The proof of this theorem uses Putinar’s Positivstellensatz [ 162 ] ,
which we repeat for completeness after the following lemma.

###### Lemma 8.4.2.

Let @xmath be a nonnegative integer and assume that @xmath , i.e.,
@xmath has continuous derivatives of order up to @xmath . Let @xmath be
a multi-index such that @xmath and let

  -- -------- --
     @xmath   
  -- -------- --

Then, for any @xmath , there exists a positive integer @xmath and a
polynomial @xmath of degree @xmath such that for any @xmath , with
@xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

This lemma is a straightforward consequence of Theorem 6.7 in [ 65 ] ,or
equivalently, Theorem 4 in [ 193 ] . These theorems state that under the
assumptions of the lemma, for any @xmath such that @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the Bernstein polynomial approximation to @xmath of
order @xmath , defined over @xmath . This is the following polynomial

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

To obtain the lemma, we let @xmath , where @xmath is the degree of the
Bernstein polynomial needed to obtain @xmath when @xmath is a given set
of indices. The result then follows by translating and scaling the
variables that define the multivariate Bernstein polynomial so that it
is defined over the box @xmath rather than @xmath . ∎

###### Theorem 8.4.3 (Putinar’s Positivstellensatz [162]).

Let

  -- -------- --
     @xmath   
  -- -------- --

and define by

  -- -------- --
     @xmath   
  -- -------- --

Assume that @xmath satisfy the Archimedean property, i.e., that there
exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

If a polynomial @xmath is positive on @xmath , then @xmath

We now prove Theorem 8.4.1 using these results.

###### Proof of Theorem 8.4.1.

Let @xmath be a function in @xmath , @xmath be a box as in ( 8.11 ), and
@xmath Without loss of generality, we will assume that @xmath , i.e.,

  -- -------- --
     @xmath   
  -- -------- --

The same results can be obtained for any other monotonicity profile.

Let @xmath From Theorem 8.4.2 , there must exist a polynomial @xmath of
degree @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath For all @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Furthermore, as @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

for all @xmath . Hence, there exists a polynomial @xmath with the same
monotonicity profile as @xmath such that @xmath

Furthermore, as @xmath over @xmath , there exists an integer @xmath and
sum of squares polynomials @xmath of degree @xmath such that

  -- -------- -- --------
     @xmath      (8.12)
  -- -------- -- --------

This is a consequence of Theorem 8.4.3 as @xmath as defined is
Archimedean. Indeed,

  -- -------- --
     @xmath   
  -- -------- --

hence, if @xmath , we get that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Remark 8.4.4.

The format of the sum of squares certificate of positivity of @xmath
over the box @xmath depends on the representation that one uses to
represent the box. If the box had been defined instead as

  -- -------- --
     @xmath   
  -- -------- --

then we would have had

  -- -------- -- --------
     @xmath      (8.13)
  -- -------- -- --------

where @xmath and @xmath are sos. Indeed the set of polynomials

  -- -------- --
     @xmath   
  -- -------- --

satisfy the Archimdean property as well. To see this assume wlog that
@xmath and note that:

  -- -------- --
     @xmath   
  -- -------- --

and hence

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , we then have

  -- -------- --
     @xmath   
  -- -------- --

We have chosen to use the formulation given in ( 8.12 ) rather than the
one in ( 8.13 ) as one need only search for @xmath sos polynomials in (
8.12 ) rather than @xmath , in ( 8.13 ).

###### Corollary 8.4.5.

Recall the definition of @xmath as given in ( 8.10 ). Consider the
following hierarchy of semidefinite programs indexed by @xmath :

  -- -------- -------- -------- --------
     @xmath   @xmath            (8.14)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

We have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As @xmath is decreasing and lower bounded by @xmath , it converges to
some constant @xmath . Suppose by way of contradiction that @xmath for
some @xmath By definition of @xmath in ( 8.10 ), there exists @xmath of
degree @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Consider the continuous function

  -- -------- --
     @xmath   
  -- -------- --

and note that @xmath and @xmath . Hence there exists @xmath such that
@xmath . Similarly to the proof of Theorem 8.4.1 , we now define

  -- -------- --
     @xmath   
  -- -------- --

We have, for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

which implies from Theorem 8.4.3 that @xmath is feasible for ( 8.14 ).
But we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

which contradicts the fact that @xmath . ∎

###### Polynomial regressors constrained to be convex

In this section, we assume that it is known that @xmath is convex over a
box @xmath , which is given to us. The goal is then to fit a polynomial
@xmath to the data @xmath such that @xmath is also convex over @xmath .
In other words, we wish to solve the following optimization problem:

  -- -------- -------- -- -------- -------- --------
     @xmath   @xmath      @xmath            (8.15)
                                   @xmath   
  -- -------- -------- -- -------- -------- --------

Again, Theorem 8.3.2 suggests that this problem cannot be solved
efficiently unless @xmath

###### Theorem 8.4.6.

Let @xmath be a @xmath function which is convex over a box

  -- -------- -- --------
     @xmath      (8.16)
  -- -------- -- --------

For any @xmath , there exists an integer @xmath and a polynomial @xmath
of degree @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and such that @xmath is also convex over @xmath . Furthermore, convexity
of @xmath over @xmath can be certified using a sum of squares
certificate.

This proof uses the following lemma, which is a generalization of
Putinar’s Positivstellensatz for matrices.

###### Lemma 8.4.7 (Theorem 2 in [172]).

Let

  -- -------- --
     @xmath   
  -- -------- --

and assume that @xmath satisfy the Archimedean property (see Theorem
8.4.3 ). If the symmetric-valued polynomial matrix @xmath is positive
definite on @xmath , then there exist sos-matrices @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof of Theorem 8.4.6.

Let @xmath be a function in @xmath , @xmath be a box as in ( 8.16 ), and
@xmath Assume that

  -- -------- --
     @xmath   
  -- -------- --

and let @xmath From Lemma 8.4.2 , we know that there exists a polynomial
@xmath of degree @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- --------
     @xmath      (8.17)
  -- -------- -- --------

We denote by @xmath As @xmath and @xmath are in @xmath , the entries of
@xmath are continuous in @xmath . This implies that

  -- -------- --
     @xmath   
  -- -------- --

is continuous since the minimum eigenvalue of a matrix is continuous
with respect to its entries [ 29 , Corollary VI.1.6] . Let

  -- -------- --
     @xmath   
  -- -------- --

and note that @xmath , for all @xmath As the minimum is attained over
@xmath , there exists @xmath such that @xmath From ( 8.17 ), we know
that the absolute value of each entry of @xmath is upperbounded by
@xmath Recalling that for a matrix @xmath with entries @xmath , @xmath ,
this implies that

  -- -------- --
     @xmath   
  -- -------- --

By equivalence of norms, we have

  -- -------- --
     @xmath   
  -- -------- --

and as @xmath we deduce that

  -- -------- --
     @xmath   
  -- -------- --

This implies that

  -- -------- --
     @xmath   
  -- -------- --

and so @xmath for all @xmath Let

  -- -------- --
     @xmath   
  -- -------- --

We have, for any @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

As @xmath , @xmath , and @xmath , we also have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

We conclude that there exists a polynomial @xmath which is convex over
@xmath and such that

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, from Lemma 8.4.7 , this implies that there exist sum of
squares polynomials @xmath , @xmath of degree @xmath in @xmath and
quadratic in @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Corollary 8.4.8.

Recall the definition of @xmath as given in ( 8.15 ). Consider the
following hierarchy of semidefinite programs indexed by @xmath :

  -- -------- -------- -------- --------
     @xmath   @xmath            (8.18)
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --------

We have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The proof of this theorem is analogous to that of Corollary 8.4.5 and
hence left to the reader. ∎

##### 8.4.3 Cases where the semidefinite programming-based relaxations
are exact

In Corollaries 8.4.5 and 8.4.8 , we have replaced the original problem
of finding polynomial regressors which are convex or monotone over
@xmath with sum of squares-based relaxations. In both cases, we have
asymptotic guarantees on the quality of these relaxations, i.e., we are
guaranteed to recover the solutions of ( 8.10 ) and ( 8.15 ) if the
degree of the sos polynomials involved is arbitrarily high. (We remark
that no explicit bound on this degree can be given as a function of the
number of variables and the degree only [ 164 ] .) In two particular
cases (which we cover below), one can in fact come up with semidefinite
programming-based relaxations which are exact : this means that the
degree of the sum of squares polynomials needed to recover the true
solution is explicitly known. Hence, one can write a semidefinite
program that exactly solves ( 8.10 ) and ( 8.15 ). We review these two
cases below.

###### The quadratic case

In this particular case, we wish to solve ( 8.10 ) and ( 8.15 ) with
@xmath .

We first consider the case where we would like to constrain @xmath to
have a certain monotonicity profile, i.e., we would like to solve ( 8.10
). As @xmath is quadratic, each of its partial derivatives is a linear
function. Requiring that a linear function be nonnegative over a box can
be done using the following lemma, which is a variant of the Farkas
lemma.

###### Lemma 8.4.9 (See, e.g., Proposition I.1 in [82]).

Let @xmath be a bounded polyhedron with nonempty interior defined by
@xmath , where @xmath are linear forms ( @xmath and @xmath ). If @xmath
is a linear form, nonnegative over @xmath , then there exist nonnegative
scalars @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

From this lemma, it follows that, when @xmath is quadratic, solving (
8.10 ) is exactly equivalent to solving

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which is a convex quadratic program.

In the case where we would like to solve ( 8.15 ), note that the Hessian
of any quadratic function is constant. Hence, as written, problem ( 8.15
) is a semidefinite program.

###### The separable case

Recall that a function @xmath is said to be separable if

  -- -------- --
     @xmath   
  -- -------- --

for some univariate functions @xmath

We first consider the case where we would like to solve ( 8.10 ),
assuming that @xmath is separable, i.e., @xmath . Note that we have

  -- -------- --
     @xmath   
  -- -------- --

In other words, one can replace ( 8.10 ) by

  -- -------- -------- -- -------- --
     @xmath   @xmath      @xmath   
                          @xmath   
  -- -------- -------- -- -------- --

where @xmath is a univariate polynomial. We then use the following
lemma.

###### Lemma 8.4.10 (Theorem 3.72 in [30]).

Let @xmath . Then the univariate polynomial @xmath is nonnegative over
@xmath if and only if it can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are sum of squares polynomials. In the first case, we have
@xmath and @xmath and @xmath . In the second case, we have @xmath and
@xmath and @xmath

Depending on the degrees of @xmath , we use Lemma 8.4.10 to rewrite the
previous optimization problem as a semidefinite program. For example, in
the case where the degrees of @xmath are all odd and equal to @xmath ,
we would get:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

To illustrate this, we have generated data @xmath with @xmath which we
would like to fit a univariate polynomial @xmath of degree @xmath to.
(Note that the univariate case is a special case of the separable case.)
For visualization purposes, we restrict ourselves to a parametric family
of polynomials whose coefficients are indexed by @xmath and @xmath :

  -- -------- -- --------
     @xmath      (8.19)
  -- -------- -- --------

We have plotted in Figure 8.1 the values of @xmath and @xmath for which:

1.  @xmath in dark gray,

2.  @xmath and @xmath is nondecreasing over @xmath in light gray.

As a sanity check, we plot in Figure 8.2 the fits that we obtain when
@xmath and when @xmath . Note that the first fit is not monotonous,
whereas the second one is, which is what we expect from Figure 8.1 .

We now consider the case where we would like to solve ( 8.15 ), i.e.,
where we constrain @xmath to be convex over @xmath . We assume that we
are searching over the set of separable polynomials of degree @xmath .
Note here that if @xmath , then @xmath is a diagonal matrix with
diagonal entry @xmath corresponding to @xmath Hence, the condition
@xmath is equivalent to requiring that @xmath , for all @xmath , @xmath
. Once again, we use Lemma 8.4.10 to rewrite the previous optimization
problem as a semidefinite program. For example, in the case where the
degrees of @xmath are all even and equal to @xmath , we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

To illustrate these results, we have generated data @xmath with @xmath
which we would like to fit a univariate polynomial @xmath of degree
@xmath to. (Note again that the univariate case is a special case of the
separable case.) For visualization purposes, we restrict ourselves again
to a parametric family of polynomials whose coefficients are indexed by
@xmath and @xmath :

  -- -------- -- --------
     @xmath      (8.20)
  -- -------- -- --------

We have plotted in Figure 8.3 the values of @xmath and @xmath for which:

1.  @xmath in dark gray,

2.  @xmath and @xmath is convex over @xmath in light gray.

As a sanity check, we plot in Figure 8.4 the fits that we obtain when
@xmath and when @xmath . Note that the first fit is not convex, whereas
the second one is, which is what we expect from Figure 8.3 .

#### 8.5 Experimental results

We now provide some illustrations of our methods on different datasets.
In the first part of this section, we consider synthetic datasets. This
will enable us to compare the advantages and limitations of our
relaxations in terms of performance metrics such as training and testing
accuracy, robustness, flexibility and scalability. In the second part of
this section, we look at how our methods perform on real-life datasets.

##### 8.5.1 Synthetic regression problems

For the synthetic experiments, we analyze the performance of 4 different
algorithms: UPR, which corresponds to unconstrained polynomial
regression, MCPR, which corresponds to polynomial regression with
monotonicity constraints, CCPR which corresponds to polynomial
regression with convexity constraints, and MCPR+CCPR, which corresponds
to polynomial regression with both monotonicity and convexity
constraints. The underlying function for this experiment as described in
( 8.9 ) is a multivariate exponential:

  -- -------- --
     @xmath   
  -- -------- --

The function @xmath is monotonically increasing in all directions, thus,
it has a monotonicity profile @xmath . Furthermore, @xmath is convex.

###### Data Generation

We denote by @xmath the feature matrix, i.e., the matrix obtained by
concatenating the @xmath feature vectors @xmath of length @xmath . Each
column or @xmath corresponds to a feature and each row is an observation
of all the @xmath features. Hence, @xmath is an @xmath matrix. For our
synthetic datasets, we generate each entry of @xmath uniformly at random
in an interval @xmath , where @xmath and @xmath . The feature domain in
this case is taken to be

  -- -------- --
     @xmath   
  -- -------- --

We compute the response variable @xmath by evaluating @xmath at each
column @xmath of @xmath , which we corrupt by some noise, whose scaling
@xmath we vary in order to test for robustness. As a consequence, if we
denote by @xmath the @xmath vector containing @xmath and by @xmath the
@xmath vector obtained by applying @xmath to each row of @xmath , we
have @xmath where @xmath is a vector with each entry taken to be iid and
Gaussian of mean zero and standard deviation @xmath . Here @xmath is the
variance of the set of random points obtained when varying the input
@xmath to @xmath and @xmath is a fixed constant, which we use to
parametrize noise (e.g., @xmath is low noise, whereas @xmath is high
noise).

In the following, we wish to fit a polynomial @xmath of degree @xmath to
the data, such that the mean squared error (which is a normalization of
the least squared error)

  -- -------- --
     @xmath   
  -- -------- --

is minimized.

###### Comparative performance

One of the biggest drawbacks of unconstrained polynomial regression is
the algorithmic instability to noise. Here we want to compare the four
algorithms listed above with respect to robustness to noise. To do this,
we fit polynomials of varying degrees to the data in both high-noise (
@xmath as described previously) and low-noise ( @xmath ) settings. We
then compare the Root Mean Squared Error (RMSE)

  -- -------- --
     @xmath   
  -- -------- --

on the testing and training samples. The results are given in Figure 8.5
. Note that the thin light blue constant line listed as “Reference” is
the reference RMSE, i.e., the value obtained when one computes the RMSE
for the function @xmath itself.

As expected, from Figure 8.5 , we see that UPR tends to overfit. This
can be observed by comparing the RMSE of UPR to the Reference RMSE:
anything below the reference can be considered to be overfitting. Note
that for both training sets, and particularly when the degree of the
polynomials is high, the data points corresponding to UPR are well below
those given by the Reference. Introducing monotonicity or convexity
constraints improves both the accuracy on the test data as well as
robustness to noise, in the sense that the RMSE of these algorithms
remains moderate, even in high noise environments. When both
monotonicity and convexity are imposed, the benefits compound. Indeed,
MCPR+CCPR has similar performance for both the testing and the training
data, and the RMSE obtained with this algorithm is the closest to the
reference line. Note that MCPR+CCPR performs well both in low noise as
well as high noise settings, which indicates the ability to robustly
learn the true underlying distribution.

Lastly we compare qualitatively the robustness of UCR, MCPR, CCPR, and
MCPR+CCPR with respect to the true underlying function. The plots in
Figure 8.6 are obtained by projecting the 4 fitted functions and the
underlying function onto one of the features (this is done by fixing all
the other features to some arbitrary values in their range). We consider
the case where the polynomials are of degree @xmath and of degree @xmath
.

The results obtained confirm our previous observations. First, UPR tends
to overfit, particularly when the noise scaling factor is high and when
the degree of the polynomial fit is large (this is because, as the
degree increases, the polynomials gain in expressiveness). Having
monotonicity and convexity constraints proves to be a very efficient way
of regularizing the polynomial fit, even in high noise settings: the
fits obtained are very close to the true function. Furthermore, though
their performance does deteriorate slightly in the high noise and high
degree regime, the overall shape of the projection stays close to that
of the underlying function, and that of lower degrees. This in contrast
to the unconstrained fit whose shape is very unstable when the degree
and the noise varies.

##### 8.5.2 Applications to real regression problems

In this section we present two applications of our methods to real
datasets. Our first example uses monotonically constrained polynomial
regression (MPCR) to predict interest rates for personal loans. The
second example is a hybrid regression setting with a mixture of
monotonicity and convexity constraints which is used to predict weekly
wages from a set of features.

##### 8.5.3 Predicting interest rates for personal loans

In this subsection, we study data for loans issued between the years
2007-2011 by Lending Club [ 118 ] . We decided to focus on the
particular category of home loans so as to avoid having to deal with
categorical variables such as loan type. The updated dataset has @xmath
observations and 32 numerical features. Though the MCPR algorithm has
run time polynomial in the number of features, we encounter issues with
memory for too large a number of features. Hence, some data
preprocessing is necessary to reduce the number of features. This was
done by eliminating highly correlated covariates and running some
canonical feature selection procedures. In the end, we consider six
features. The response variable in this case is the interest rate on
home loans. The features along with their monotonicity signs and their
descriptions are presented below:

-    dti:+1  - Ratio of the borrower’s total monthly debt payments an
    the self-reported monthly income. A borrower with high dti is
    perceived to be riskier, which typically corresponds to higher
    interest rates.

-    delinq_2yrs:+1  - The number of past-due delinquencies in the past
    2 years. The interest rate is monotonically increasing with respect
    to the number of delinquencies.

-    pub_rec:+1  - Number of derogatory public records. The interest
    rate is monotonically increasing with respect to this feature.

-    out_prncp:+1  - Remaining outstanding principal. This feature has a
    monotonically increasing relationship with the interest rate.

-    total_rec_prncp:-1  - Principal received to date with a
    monotonically decreasing dependency.

-    total_rec_int:-1  - Interest received to date. The interest rate is
    monotonically decreasing with respect to this feature.

We compute the average RMSE for testing and training sets through a
10-fold cross validation. We compare in Figure 8.7 the results for
fitting polynomials of different degrees in both the unconstrained and
monotonically constrained settings.

The best performance was achieved by a degree 4, monotonically
constrained polynomial regression with average RMSE of @xmath and
standard error of @xmath . Already for degree @xmath , the unconstrained
regression runs into numerical problems as it becomes rank deficient,
i.e., the number of coefficients that needs to be determined is larger
than the number of data points. Therefore, monotonicity constraints can
be an efficient way of ensuring robustness in settings where the number
of datapoints is relatively small, but the relationship between the
covariates is complex.

##### 8.5.4 Predicting weekly wages

In this section, we analyze data from the 1988 Current Population
Survey. This data is freely available under the name ex1029 in the
Sleuth2 R package [ 163 ] . The data contains @xmath observations and 2
numerical features: years of experience and years of education. We
expect wages to increase with respect to years of education and be
concave with respect to years of experience. We compare the performance
of this hybrid constrained regression problem with the unconstrained
case, as well as the CAP algorithm proposed by Hannah [ 84 ] . Similarly
to the previous example we compute the RMSEs with 10-fold cross
validation. In addition we time our algorithm in order to compare the
runtimes with the CAP algorithm. The results are presented in Figure 8.8
.

The best performing algorithm is the monotonically and convexly
constrained degree 2 polynomial with average test RMSE: @xmath and
standard error @xmath . The algorithm with the smallest standard error,
therefore the one with the most consistent performance is the degree 3
hybrid polynomial with test RMSE: @xmath . In comparison, the CAP and
Fast CAP algorithm have test RMSE: @xmath . Our algorithm does not only
perform better in terms of RMSE, it also has a better runtime
performance. For the degree 2 hybrid regression, the run time is @xmath
seconds, and for degree 3, the hybrid regresion runtime is @xmath
seconds. In contrast, the CAP algorithm takes @xmath seconds and the
Fast CAP algorithm takes @xmath seconds.