# Riassunto

Il principale argomento di questa tesi è l’analisi delle equazioni
dell’evoluzione che riflettono questioni di ecologia e di dinamica della
popolazione. Nell’ambito della modellizzazione matematica, l’impatto
degli elementi ambientali e delle interazioni tra le specie viene
studiato mediante il ruolo dell’eterogeneità nelle equazioni e nelle
interazioni nei sistemi accoppiati. In questa direzione, indaghiamo tre
problemi distinti corrispondenti a tre capitoli di questa tesi.

Il primo problema riguarda l’evoluzione di una singola popolazione che
vive in un ambiente con una linea di diffusione rapida. Dal punto di
vista matematico, lo studio riguarda un sistema di due equazioni di
reazione-diffusione accoppiate, che lavorano su domini di dimensioni
diverse, chiamato come in [ 20 ] un modello “campo-strada”. Introduciamo
una dipendenza periodica in direzione della linea di diffusione per il
termine di reazione, che nell’interpretazione ecologica corrisponde alla
presenza di zone più e meno favorevoli alla crescita della popolazione.
Le condizioni necessarie e sufficienti per la persistenza o l’estinzione
della popolazione e gli effetti della presenza della strada sono
analizzati attraverso lo studio di un adeguato autovalore principale
generalizzato, recentemente definito in [ 16 ] . Tramite il confronto
con la letteratura in mezzi periodici, si mostra che la presenza della
strada non ha alcun impatto sulle possibilità di sopravvivenza della
popolazione, nonostante l’effetto deleterio che ci si aspetta dalla
frammentazione.

La seconda indagine riguarda un modello che descrive la competizione tra
due popolazioni in una situazione di aggressione asimmetrica, in cui una
popolazione aggredisce una seconda. Deriviamo un sistema di ODE da
alcune assunzioni fondamentali, ottenendo un modello Lotka-Volterra
modificato che si basa su parametri strutturali come la fitness della
popolazione e la frequenza e l’efficacia degli attacchi. L’analisi della
dinamica mostra due possibili scenari, in cui una sola delle due
popolazioni sopravvive. Dopodiché, l’interpretazione di uno dei
parametri come l’aggressività della prima popolazione solleva in modo
naturale un problema di controllabilità. Tramite argomentazioni
geometriche caratterizziamo l’insieme delle condizioni iniziali
permettendo, con un’adeguata strategia eventualmente variabile nel
tempo, la vittoria della popolazione che attacca. Infatti, dimostriamo
che le funzioni di tipo bang-bang sono sufficienti a raggiungere
l’obiettivo e talvolta sono necessarie rispetto a funzioni costanti.
Infine, trattiamo una questione di minimizzazione nel tempo.

La terza e ultima parte analizza il decadimento nel tempo in equazioni
di evoluzione con una possibile derivata temporale frazionaria.
Proseguendo un’analisi iniziata in [ 43 ] , trattiamo equazioni
d’evoluzione con una combinazione di derivata temporale di Caputo e
classica. Utilizzando metodi d’energia, dimostriamo stime quantitative
di tipo polinomiale o esponenziale; il diverso comportamento dipende
principalmente dalla scelta della derivata temporale. I risultati di
decadimento si applicano ad una vasta classe di operatori di diffusione,
comprendendone alcuni locali, non locali, reali, complessi e anche non
lineari, di cui forniamo esempi concreti.

## Résumé

Le sujet principal de cette thèse est l’analyse des équations
d’évolution reflétant les questions d’écologie et de dynamique des
populations. En modélisation, la compréhension de l’impact des éléments
environnementaux et de l’interaction entre les espèces dépend de la
compréhension du rôle de l’hétérogénéité dans les équations et les
interactions dans les systèmes couplés. Dans cette direction, nous
étudions trois problèmes indépendents correspondant à trois chapitres de
cette thèse.

Le premier problème concerne l’évolution d’une seule population vivant
dans un environnement avec une ligne de diffusion rapide. L’analyse
porte sur un système de deux équations de réaction-diffusion couplées,
travaillant sur des domaines de dimensions différentes, qui est appelé
comme dans [ 20 ] un modèle “champ-route”. Nous introduisons une
dépendance périodique dans la direction de la ligne de diffusion pour le
terme de réaction, qui, dans l’interprétation écologique, correspond à
la présence de zones plus ou moins favorables à la croissance de la
population. Les conditions nécessaires et suffisantes pour la
persistance ou l’extinction de la population et les effets de la
présence de la route sont analysés par l’étude de la valeur propre
principale généralisée appropriée, définie pour la première fois dans [
16 ] . Par comparaison avec des études similaires dans des
environnements périodiques, nous prouvons que la présence de la route
n’a aucun impact sur les chances de persistence de la population, malgré
l’effet délétère attendu lié à la fragmentation.

La deuxième étude porte sur un modèle décrivant l’interaction
compétitive et agressive entre deux populations. Nous dérivons un
système d’EDO à partir de principes de base, en obtenant un modèle
Lotka-Volterra modifié reposant sur des paramètres structurels comme la
fertilité de la population et la fréquence et l’efficacité des attaques.
L’analyse de la dynamique donne deux scénarios possibles, où une seule
population survit. Ensuite, l’interprétation d’un des paramètres comme
étant l’agressivité de la première population soulève tout naturellement
des questions de contrôlabilité. Grâce à des arguments géométriques,
nous caractérisons l’ensemble des conditions initiales permettant la
victoire de la première population avec une stratégie appropriée
éventuellement dépendante du temps. En effet, nous prouvons que les
stratégies de bang-bang sont suffisantes et parfois nécessaires face à
des contrôles constants. Enfin, nous traitons une question de
minimisation du temps.

La troisième et dernière partie de la thèse analyse la décroissance dans
le temps pour des solutions d’une classe d’équations d’évolution avec
dérivées temporelles fractionnaires et classiques. Poursuivant une
analyse commencée dans [ 43 ] , nous traitons des équations d’évolution
avec une combinaison linéaire des dérivées temporelles Caputo et
classiques. En utilisant des méthodes d’énérgie, nous prouvons des
estimations quantitatives de type polynomial ou exponentiel ; le
comportement différent dépend fortement du choix de la dérivée
temporelle. Les résultats de la décroissance s’appliquent à une large
classe d’opérateurs de diffusion, comprenant des opérateurs locaux, non
locaux, réels, complexes et même non linéaires, dont nous fournissons
des exemples concrets.

## Ringraziamenti

Per primi vorrei ringraziare i miei relatori, Luca Rossi ed Enrico
Valdinoci, senza i quali questo lavoro non sarebbe stato possibile. Luca
mi segue già da molti anni e le esperienze positive con lui sono state
determinanti sulla mia scelta di intraprendere il dottorato. Ha
continuato a seguirmi con attenzione e meticolosità durante questi tre
anni. Enrico fin dal primo giorno ha avuto fiducia in me e mi ha
suggerito le migliori possibilità per lo sviluppo della mia carriera,
incoraggiandomi, finanziandomi e aiutandomi quando il compito mi
risultava troppo difficile. A entrabi devo i miei ringraziamenti più
sinceri.

Un ringraziamento speciale va anche a Serena Dipierro, che è stata molto
presente nel mio dottorato, come collaboratrice e quasi come un terzo
relatore, si è impegnata a coinvolgermi e promuovermi nella comunità
matematica. Ringrazio moltissimo anche Henri Berestycki, per la grande
ispirazione che mi ha dato, per i suoi preziosi consigli e per aver
aiutato me e i miei relatori a formare l’accordo di cotutela.

I would like to thank the two anonymous referees for their precious time
and their nice comments on the report. I am also happy to thank the
members of the defence commission, Luis Almeida, Sepideh Mirrhaimi,
Fabiana Leoni and again Henri Berestycki, for accepting the task and
devoting their valuable time to me.

Ringrazio anche per l’accoglienza il Dipartimento di Matematica
dell’Università degli Studi di Milano, in particolare nelle persone di
Vieri Mastropietro, coordinatore del corso di dottorato, e di Stefania
Leonardi. Sono molto riconoscente anche a Daniela Lipari per avermi
aitato a stringere l’accordo di cotutela. Un grande ringraziamento va
anche ai miei colleghi dottorandi, per avermi condiviso con me gioie e
dolori del dottorato e per aver reso molto più divertente il tempo a
Milano. Dedico un pensiero particolare agli altri dottorandi (ormai
dottori!) e postdoc di Enrico e Serena, che mi hanno accompagnato in
numerose conferenze in giro per il mondo e nei due mesi in Australia,
facendomi sentire sempre a casa: Pietro, Luca, Claudia, Giorgio, Matteo,
Matteo, Julien.

Je suis reconnaissante également à Sorbonne Université et au laboratoire
CAMS pour m’avoir accueilli, déjà depuis mon stage de M2. Un grand merci
à Sandrine Nadal, Nathalie Brusseaux, Jean-François Venuti, Corentin
Lacombe et Patricia Zizzo pour leur travail administratif, et à tous les
personnes du labo  pour la belle ambiance, les discussions
passionnantes, et pour m’avoir appris beaucoup sur la culture et la
langue française. Ici aussi un grand groupe de doctorants et postdoc
m’ont aidé avec leurs conseils et leur amitié, pendant ma thèse et le
stage: merci à Romain, Samuel, Charles, Alessandro, Benedetta, 
Federico, Julien, François, Noemi, Imke, Jérémie, Milim, José, Elisa.

Vorrei ringraziare tutti gli amici anche al di fuori dell’università che
mi hanno sostenuto in questi anni di viaggi, conferenze e traslochi
sfrenati tra Padova, Milano, Parigi e Stoccolma, e tutti gli amici che
c’erano da molto prima che il mio dottorato iniziasse. Sono divisa tra
la felicità di aver conosciuto così tante persone meravigliose e il
rammarico di non aver passato abbastanza tempo con ciascuno.

Per la mia famiglia, il mondo dell’università e della matematica sono
sempre stati estranei, ma questo non ha impedito loro di sostenermi e di
avere fiducia in me. Grazie a mio fratello Andrea per avermi insegnato
le sottrazioni e aver sopportato le mie domande sugli strani simboli che
apparivano nei suoi libri di matematica. Grazie anche a Emanuela, Nicolò
e Matteo per aver arricchito la nostra famiglia con tanta gioia e
affetto. Grazie a mamma e papà per avermi dato tutto, senza mai chiedere
niente.

Ad Andrea potrei dedicare intere pagine di ringraziamenti, ma credo sia
meglio farglieli di persona.

###### Contents

-    1 Introduction
    -    1.1 General historic background
    -    1.2 The road-field model in a periodic medium
        -    1.2.1 Reaction diffusion equations in the literature
        -    1.2.2 A KPP model with a fast diffusion line in a periodic
            medium
        -    1.2.3 Our results
    -    1.3 A new model for aggressive competition
        -    1.3.1 Lotka-Volterra models: a literature overview
        -    1.3.2 A model of Lotka-Volterra type for aggressive
            competition and analysis of the strategies
        -    1.3.3 Our results
    -    1.4 Evolution equations with classical and fractional
        derivatives
        -    1.4.1 Fractional derivatives in evolution equations
        -    1.4.2 Decay estimates for evolution equations with
            classical and fractional derivatives
        -    1.4.3 Our Results
-    2 A Fisher-KPP model with a fast diffusion line in periodic media
    -    2.1 Setting and main results
        -    2.1.1 The model
        -    2.1.2 State of the art
        -    2.1.3 Main results
        -    2.1.4 Organisation of the chapter
    -    2.2 Generalised principal eigenvalues and their properties
        -    2.2.1 Eigenvalues in periodic media
        -    2.2.2 Generalised principal eigenvalues for the system with
            and without the road and some properties
        -    2.2.3 The periodic generalised principal eigenvalue for the
            road-field system
    -    2.3 Ordering of the eigenvalues
        -    2.3.1 Proof of Theorem 2.6
        -    2.3.2 Further inequalities between the eigenvalues
        -    2.3.3 Proof of Theorem 2.4
    -    2.4 Large time behaviour for a periodic medium and @xmath
        -    2.4.1 Persistence
        -    2.4.2 Extinction
-    3 A New Lotka-Volterra Competitive System
    -    3.1 Introduction
        -    3.1.1 Motivations and derivation of the model
        -    3.1.2 Some notation and basic results on the dynamics of
            system ( 3.1 )
        -    3.1.3 Dynamics of system ( 3.1 ) for constant strategies
        -    3.1.4 Dynamics of system ( 3.1 ) for variable strategies
            and optimal strategies for the first population
        -    3.1.5 Organization of the chapter
    -    3.2 First results on the dynamics and proofs of Proposition 3.1
        and Theorem 3.2
        -    3.2.1 Characterization of @xmath when @xmath
        -    3.2.2 Characterization of @xmath when @xmath
        -    3.2.3 Completion of the proof of Theorem 3.2
    -    3.3 Dependence of the dynamics on the parameters
        -    3.3.1 Dependence of the dynamics on the parameter @xmath
        -    3.3.2 Dependence of the dynamics on the parameter @xmath
        -    3.3.3 Dependence of the dynamics on the parameter @xmath
    -    3.4 Analysis of the strategies for the first population
        -    3.4.1 Construction of winning non-constant strategies
        -    3.4.2 Proof of Theorem 3.3
        -    3.4.3 Proof of Theorem 3.4
        -    3.4.4 Proof of Theorem 3.5
        -    3.4.5 Bounds on winning initial positions under pointwise
            constraints for the possible strategies
        -    3.4.6 Minimization of war duration: proof of Theorem 3.7
-    4 Decay estimates for evolution equations with classical and
    fractional time-derivatives
    -    4.1 Introduction and main results
        -    4.1.1 Setting of the problem
        -    4.1.2 Notation and structural assumptions
        -    4.1.3 Main results
        -    4.1.4 Applications
    -    4.2 Proofs

## Chapter 1 Introduction

The main motivation behind research is to enhance mankind ability to
predict and keep under control natural and artificial processes. To this
purpose, mathematical models have revealed to be a very compelling
instrument. A mathematical model is a simplified representation of a
phenomenon through several meaningful, quantitative parameters evolving
with analytical laws. Once some faithful evolution equations are
established, the role of mathematics is to provide as much information
as possible on the solutions, even if often only qualitative properties
can be derived. That is, mathematics does not study the reality, but the
language in which we read it.

On the other side, given a model, people often find the mathematical
challenges interesting in themselves. It is natural that some questions
on the mathematical tools arise, or that variations of the model are
proposed and discussed. This way, knowledge of mathematics is expanded,
and more equipment is available to write new models.

At present, the problem of climate change and environment anthropization
is a great concern for humankind. In order to activate effective
countermeasures against biodiversity loss, it is important to understand
as deeply as possible what conditions would entail such event. These
conditions depend on quantitative and qualitative properties of the
environment where the species lives, on a population’s resilience to
changes, but also on its interaction with other species sharing the same
habitat. We still know too little about the effects that these elements
and their alteration have on the survival chances of species.

This thesis is far from giving a solution to these dreadful problems but
aims to give a contribution to the field of evolution equations and
systems with possible application to population dynamics.

##### Topics and aims of the thesis

The thesis consists of three parts, each treating a different problem.

In the first part, corresponding to Chapter 2 , we start from a
reaction-diffusion model in a periodic environment with a fast diffusion
line. The aim is to find conditions entailing survival or extinction of
the population and to understand the influence of the line and the
environment on the dynamics. Our analysis permits a comparison with the
scenario where the fast diffusion line is not present for the general
case of a medium with heterogeneity in one direction. The content of
Chapter 2 is reflects the content of the paper [ 2 ] by the author of
this thesis.

The second part, contained in Chapter 3 , is consecrated to a model of
aggressive, asymmetric competition between two populations, derived from
a Lotka-Volterra system. The presence of the aggression term naturally
leads to a control problem, where a population tries to prevail on the
other using an appropriate strategy. Hence, once the dynamics of the
system is understood, we investigate conditions for the victory of the
aggressive population, which quite surprisingly is not always possible.
Moreover it is found that, depending on the initial condition, either a
bang-bang or a constant strategy leads to the desired scenario. Chapter
3 corresponds to the paper [ 3 ] by Serena Dipierro, Luca Rossi, Enrico
Valdinoci and the author of this thesis.

The last part of this thesis deals with a more abstract and general
problem; we investigate asymptotic behaviour for a class of evolution
equations with both fractional and classical time derivatives. Our
setting consists of an homogeneous evolution equation working on a
bounded set. The framework comprehends both real and complex, local and
nonlocal diffusion operators, and allow us to evaluate the impact of
time derivatives on the decay of solutions. Depending on the type of
time derivative, polynomial or exponential decays are entailed. The
results of Chapter 4 are presented in the paper [ 5 ] in collaboration
with Enrico Valdinoci and the note [ 4 ] in collaboration with Serena
Dipierro and Enrico Valdinoci.

##### Organisation of the manuscript

In this introductory chapter, we make the reader familiar with the
problems we investigate and the framework they are enclosed in.
Following the historical path, we start by a general introduction that
then branches in three sections corresponding to the precise research
niches of our problems. In each section, after an overview of the state
of the art of the topic, we introduce the corresponding problem in
details and provide precise statements of our results.

As mentioned before, the rest of the manuscript consists of three
chapters, corresponding respectively and in the same order to the topics
we introduce in this introduction. Each chapter is meant to be a
self-standing script.

### 1.1 General historic background

For apparent reasons of population control and resource organisation,
one of the first themes for which modelisation has been used is
population dynamics. The first example in this sense was written by
Leonardo Fibonacci in Liber Abaci and treats the size of a population of
rabbits. Fibonacci supposed that each couple of rabbits that are older
than one month gives birth to another couple of rabbits; calling @xmath
the size of the population at the @xmath th month, under the previous
hypothesis one deduces that

  -- -------- --
     @xmath   
  -- -------- --

Staring with @xmath , it can be deduced that @xmath has an exponential
behaviour [ 8 ] . This deduction corresponds to the reality only as long
as the food is abundant for all the individuals; moreover, the relation
is involved and not easy to treat.

Another discrete model was proposed by Euler in the treatise
Introduction to the Analysis of the Infinite , published in 1748 [ 8 ] .
He assumed the annual growth rate to be a fixed quantity @xmath . Then,
calling @xmath the size of the population at the year @xmath , one has
that

  -- -------- --
     @xmath   
  -- -------- --

so one derives, calling @xmath the population at the initial time,

  -- -------- --
     @xmath   
  -- -------- --

The sequence @xmath is called a geometric sequence, and its behaviour is
again exponential. Thanks to these formulae, Euler treated some problems
linked to the growth of urban population and he investigated the
reliability of the biblical story of the Float. However, his model
involve many computations that were hard to perform before the
introduction of computers.

Thomas Malthus, in his work Essay on the Principle of Population [ 81 ]
, used a simpler relation to represent the evolution of a population
size; he supposed the growth of a population to be proportional to its
size, that is, the growth rate to be a fixed constant, @xmath .
Moreover, as simplification, he assumed the size of the population to
evolve in a continuous fashion with respect to time. With these
hypothesis, the evolution of @xmath follows the law

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

The solutions to equation ( 1.1 ) are exponentials, in accordance with
the result of Fibonacci.

Again in [ 81 ] , Malthus pointed out that the growth of a population is
limited by the quantity of resources. This idea was taken into the
equation by Verhulst [ 120 ] . He considered the number @xmath of
individuals that the environment can support indefinitely with the
available resources; this is called carrying capacity of the
environment. Then, he corrected Malthus’s equation ( 1.1 ) with the
following:

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

Equation ( 1.2 ) presents two equilibria: @xmath , that is repulsive,
and @xmath , which is attractive. In fact, for all @xmath , one has
@xmath , while for @xmath , it holds @xmath ; in both cases, the
solution tends to get closer to the value @xmath . This means that,
independently of the starting condition, as long as the initial datum is
positive, the population size evolves approaching the value @xmath ,
which is the maximum number of individuals that the environment can
sustain. The logistic model is much more realistic that the previous
estimates. It is considered the precursor of interesting mathematical
branches, including Lotka-Volterra systems and reaction-diffusion
equations.

### 1.2 The road-field model in a periodic medium

#### 1.2.1 Reaction diffusion equations in the literature

One important feature that is not taken into account in the logistic
equation is dependence on space. The first effect to take into account
for a space structured model is the fact that a population is subject to
dispersion . This is a result of the free movement for animals and of
the dispersion of seeds for plants. The first hypothesis in the
literature was to consider the individuals to move with random brownian
walk, as particles of a gas. Without taking account reproduction,
calling @xmath the size of a population and considering it in continuous
dependence on time, the dispersal would follow the well-known heat
equation

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

Note that when speaking of population denisties and sizes, we only
consider nonnegative solutions.

The first mathematicians who added a reaction term to equation ( 1.3 )
were Fisher [ 50 ] and Kolmogorov, Petrovsky and Piskunov [ 72 ] . They
considered a function @xmath representing the concentration of an
advantageous gene in a population; it was supposed that the population
lives in a one-dimensional environment and that the individuals move
randomly. Taking these hypothesis, once the gene was introduced, it
spreads according to the equation

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

where @xmath is a function such that

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

moreover it is monostable , that is,

  -- -------- --
     @xmath   
  -- -------- --

and respects the condition called KPP hypothesis

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

The function @xmath represents the birth-death rate of individuals
carrying the gene. The fact that @xmath is a very natural assumption: if
no individuals are present, no new individual is generated. On the other
hand, the choice @xmath suggests a saturation at the size @xmath . The
hypothesis ( 1.6 ) reflects the fact that the growth rate decreases as
the size of the population grows, as it is the case for the logistic
equation ( 1.2 ). Actually, Fisher supposed @xmath for @xmath , which is
exactly the nonlinearity proposed by Verhulst, while Kolmogorov,
Petrovsky and Piskunov selected @xmath .

For a large class of initial data, among which the Heaviside functions,
the solutions to ( 1.4 ) asymptotically converge to a function of the
shape

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

Solutions of the form ( 1.7 ) are called travelling waves and the
quantity @xmath is called speed of propagation of the travelling wave.
The travelling wave found in [ 50 ] and [ 72 ] has speed corresponding
to @xmath ; actually, a travelling wave exists for all @xmath and @xmath
corresponds to the minimal speed.

The main questions addressed in [ 50 ] and [ 72 ] have been later asked
for larger and larger class of nonlinearites. These questions concerns
the existence of stationary solutions, the existence of travelling
fronts and the asymptotic speed of propagation for the Cauchy problem.

For the sake of completeness, we must here name other two important
settings. In [ 48 ] and in [ 7 ] for the multidimensional case, Fife and
McLeod and Aronson and Weinberger treated equation ( 1.4 ) in the case
of a function @xmath satisfying the hypothesis ( 1.5 ) and such that
there exists a value @xmath for which

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

A function satisfying ( 1.8 ) is called bistable , from the fact that
the related equation has two attractive states, @xmath and @xmath . This
type of nonlinearity is particularly interesting because it embodies an
important phenomenon in population dynamics, called the Allee effect
from the name of the scientist who discover it in the ’30s. It happens
that in social animals, aggregation increases the survival rate of
individuals; therefore, when the size of a population is under a certain
threshold, the growth rate is negative; when the group size passes the
threshold, the growth rate becomes positive.

A third important setting is the combustion case, in which there exists
a quantity @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

This type of nonlinearity is used for ignition models, where to activate
the combustion process the temperature must pass a threshold.

As a matter of fact, Aronson and Weinberger investigated the equation

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

and asked under which conditions on the function @xmath , other than (
1.5 ), and on the initial datum @xmath one has invasion or spreading ,
that is,

  -- -------- --
     @xmath   
  -- -------- --

The opposite behaviour is called extinction , and it occurs when

  -- -------- --
     @xmath   
  -- -------- --

We point out that for extinction a uniform convergence is required,
otherwise, in some scenarios, one could have a positive mass escaping
further and further in space as @xmath goes to infinity. The authors
found that for a compactly supported initial datum which is
“sufficiently large” (depending on the nonlinearity), invasion occurs if
and only if

  -- -------- --
     @xmath   
  -- -------- --

Let us give more details on the minimal requirements for the initial
datum. In the monostable case, it is sufficient for @xmath to be greater
than a positive constant in @xmath in a large enough ball. Moreover, if
@xmath , then all solutions issued from a non zero, non negative initial
datum converges to 1 as @xmath goes to infinity; this is called hair
trigger effect . In the bistable and monostable cases, the positive
constant is necessarily greater than the threshold @xmath .

Equation ( 1.4 ) was the first example of a whole class of PDEs, the
reaction-diffusion equations. From the initial works [ 50 , 72 , 48 , 7
] , the literature on reaction-diffusion equations and the study on
travelling waves have flourished. What is present here is a
circumscribed niche, which is handy to provide context to our work.

##### Reaction-diffusion equations in periodic media

One of the other natural applications of equations ( 1.4 ) and ( 1.9 )
is of course population dynamics. Skellam [ 109 ] was one of the firsts
to study the effects of random dispersion on a population subject to the
malthusian law, after noticing that the framework given by [ 50 ] and [
72 ] could be adapted to this problem.

In the optic of studying the survival and the distribution of a
population in space, a homogeneous environment is not satisfying and one
expects the growth of the population to vary according to the habitat
conditions. On the other hand, from a mathematical point of view,
heterogeneity in the nonlinearity creates great difficulties. Many new
techniques were required to overcome these obstacles.

A first analysis was carried out by Shigesada, Kawasaki and Teramoto in
[ 108 , 107 ] . The authors observed that natural environments are a
mosaic of different habitats, such as forests, meadows, brush,
cultivated fields and villages. This led them to consider an environment
which consists of two periodically alternating homogeneous habitats, one
favourable, @xmath , and one unfavourable, @xmath , for the considered
species. The heterogeneity of the living conditions is reflected by the
birth-death rate, which they chose to be

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath . Moreover, they also consider possibly varying
diffusivity, hence they took

  -- -------- --
     @xmath   
  -- -------- --

This is due to the observation of increased speed in unfavourable
environments; hence we expect @xmath for a real population. Then, the
authors studied in [ 108 ] the equation

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

This is known as the patch model ; they investigated long time
behaviour, convergence to travelling fronts and propagation speeds.
Actually, since @xmath is no longer an equilibrium for equation ( 1.10
), we have to modify our definition for species survival; from now on,
we intend that persistence occurs if @xmath approaches a non null
stationary solution locally uniformly as @xmath tends to infinity.

By making use of numerical simulations, it was found that the stability
of the trivial solution @xmath plays a key role in determining if the
population survives or not. It was already known (see [ 35 ] ) that a
negative or positive sign of the principal eigenvalue resulting from the
linearisation around @xmath entails respectively stability or
instability of the @xmath solution. In [ 108 ] , it was shown
numerically that the stability of the trivial solution entails
extinction, while its instability causes persistence of the population.
The authors also studied the sign of the eigenvalue depending on the
values of @xmath , the measures of @xmath and @xmath and the values of
the parameters; this was possible because of the simplicity of the
framework.

Equation ( 1.10 ) was later considered in [ 70 ] and [ 18 ] for general
@xmath and @xmath depending on @xmath in a continuous fashion and
perdiodically of period @xmath for some @xmath . In this second article,
Berestycki, Hamel and Roques comprehended that the extinction or
persistence of the population depends on the sign of a periodic
eigenvalue @xmath , that is the unique real number such that the problem

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

where @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

has a solution @xmath . It was proved that when @xmath extinction
occurs. On the other hand, when @xmath there is persistence; moreover,
there exists a unique stationary solution to ( 1.10 ), that is periodic
of period @xmath , and attracts all the solutions starting from a non
negative, non zero bounded initial datum.

The studies on the patch model [ 108 , 107 ] and the ones on periodic
media [ 70 , 18 ] evidenced also the effect of fragmentation on the
survival chances of a population. It was found that @xmath decreases as
the homogeneity increases, that is, a species has better survival
chances when the environment is less fragmented.

##### The case of a changing climate

A new aspect that one may consider while studying ecological problems is
a changing climate. If the environment changes in time, so does the
fitness of a population. In this paragraph, we are going to analyse the
difficulties produced by the new type on nonlinearity and how it has
been overcome.

A 1-dimensional model for population persistence under climate change
was first proposed by Berestycki, Diekmann, Nagelkerke and Zegeling in [
15 ] . The authors first imagined that a population lives in a
favourable region enclosed into disadvantageous environment. Assuming
that a global warming is in place, and that the population lives in the
Boreal Emisphere, the authors imagined that the favourable region moves
to the north, so that for every favourable area lost in the South, an
equivalent favourable area is gained in the North. The resulting
equation is

  -- -------- --
     @xmath   
  -- -------- --

Later, in [ 21 ] , Berestycki and Rossi presented a model for climate
change in @xmath and for a larger class of nonlinearites; they dealt
with equation

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

with @xmath a direction in @xmath and @xmath . The authors focused on
solutions in the form of a travelling waves @xmath which solve the
equation

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

This second equation is more treatable: in fact, the dependence in time
of the nonlinearity, which poses a lot of problems, is transformed into
a transport term; now, the equation has a nonlinearity depending only on
space, and techniques for this type of heterogeneity are more familiar.

The main question is if the population keeps pace with the shifting
climate, that is, if a large enough group is able to migrate with the
same speed of the climate. The answer to this question is positive if a
solution to ( 1.13 ) exists; as happened for the periodic equation (
1.10 ), this depends on the sign of the principal eigenvalue coming from
the linearisation in @xmath .

##### The road-field model

Spatial heterogeneity in natural environments may be the consequence not
only of the diversity of the habitats, but also of the presence of
obstacles or fast diffusion channels that affects the fitness and the
mobility of individuals.

In recent years, humans activity has caused drastic changes in the
environment, causing different species to become invasive in areas they
were not present [ 107 ] . In the case of the Processionary pine tree
caterpillar, the diffusion in France has been even faster than
anticipated. It has been observed that the insect was incidentally
transported by humans from town to town, and from these settlements it
spread in the surroundings [ 103 ] . This in not the only example of
ecological diffusion acceleration by fast diffusion lines. In Western
Canadian Forest, GPS observations on wolves proved that the animals
exploit seismic lines, that are straight roads used by the oil companies
to test reservoirs, to move faster and therefore to increase their
probability of meeting a prey [ 83 ] .

Roads play a strong role also in the spreading of epidemics. The “black
death” plague in the 14th century was one of the most devastating
epidemics known in Europe. It is known that the plague was transported
by animals and humans along the commercial trade line of the silk road,
and from that spread all over Europe. More recently, a similar effect
has been conjectured for the COVID-19 infection. By tracing the
spreading in Northen Italy in early March 2020, it was found that the
diffusion occurred first along highways and then spread in the
surrounding territory [ 52 ] .

Inspired by this behaviour, Berestycki, Roquejoffre and Rossi proposed
in [ 20 ] a model of spreading in an environment presenting a fast
diffusion channel. As a simplification, they considered the channel to
be a straight line in @xmath , the @xmath axis @xmath . Their idea was
to split the population into two groups; the first one, of density
@xmath , occupies the one dimensional environment @xmath representing
the road, and the second one, of density @xmath , occupies the
surrounding territory; by symmetry, they considered just one half of the
plan, thus @xmath , which they called “the field”. These two groups
continuously exchange along the road: a fraction @xmath of the
population in @xmath at @xmath passes in the road, and a fraction @xmath
of the population in the road passes in the field. The diffusivity is
different in the two environments; its values are @xmath on the road and
@xmath on the field, both positive. Moreover, it is supposed that
population reproduces only in the field and that the environment is
homogeneous; the corresponding function @xmath is required to satisfy (
1.5 ), @xmath and a stronger version of the KPP hypothesis, that is

  -- -------- --
     @xmath   
  -- -------- --

The resulting system, called road-field model , is

  -- -- -- --------
           (1.14)
  -- -- -- --------

The authors of [ 20 ] found that invasion occurs for any non negative,
non zero initial datum, so the hair trigger effect holds; solutions
converge to the unique steady state @xmath . Moreover, they studied
spreading speeds and found that it is enhanced by the presence of the
road. In a second paper [ 19 ] , the same authors investigated system (
1.14 ) with a transport term and a reaction term on the line.

Many variations of the road-field model were proposed. In [ 94 , 95 ] ,
the system was modified by introducing nonlocal exchanges between the
road and the field. The case of a general nonlocal diffusion has been
treated in [ 14 , 13 ] . Different geometric settings have also been
considered; in [ 105 ] , the model was extended in higher dimensions.
For a complete list, we refer to the chapter in [ 112 ] by Tellini.

Treating system ( 1.14 ) poses some difficulties because of the
interaction between functions living in different dimensions and the
unusual boundary condition. Adding some heterogeneity in space increases
the difficulties. This is why very few studies of this type have carried
on so far, a part from an article by Giletti, Monsaingeon and Zhou [ 58
] , where the authors considered the case of exchanges terms depending
periodically on @xmath .

Recently, Berestycki, Ducasse and Rossi introduced in [ 16 ] a new
generalised principal eigenvalue fitting road-field models for a
possibly heterogeneous reaction term. Hence, they considered the system

  -- -- --
        
  -- -- --

Calling

  -- -------- --
     @xmath   
  -- -------- --

this eigenvalue is defined as

  -- -- -- --------
           (1.15)
  -- -- -- --------

with @xmath belonging to @xmath . Together with the definition, many
interesting properties and bounds were studied.

Thanks to that, the same authors were able to investigate the case of a
favourable ecological niche, possibly facing climate change, in [ 17 ] .
It was proven that the sign of @xmath characterises the extinction or
the persistence of the population; moreover, comparing the results with
the ones found for the model without the road, in the absence of climate
change a deleterious effect of the road on the survival chances was
found. On the other hand, if the ecological niche shifts, the road has
in some cases a positive effect on the persistence.

#### 1.2.2 A KPP model with a fast diffusion line in a periodic medium

We are now ready to introduce in details the first problem dealt with in
this thesis. We are going to investigate a road-field model in a
periodic medium. This problem combines the interests of studying the
effect of a fast diffusion line with the one of treating a heterogeneous
nonlinearity, that, as we pointed out before, reflects a natural
territory in a more realistic way than a homogeneous term. From a
technical point of view, it also combines the difficulties of the two
settings.

##### The model

We have already presented the road-field model. In our problem, we treat
a road-field system with possible climate change and with a reaction
term depending on the spatial variable @xmath ; in particular, we will
focus on the case of periodic dependence. There is no dependence in the
variable @xmath , the heterogeneity in that direction is only due to the
presence of the road.

Keeping the notation used so far, the system we investigate reads

  -- -------- -- --------
     @xmath      (1.16)
  -- -------- -- --------

Recall that @xmath , @xmath , @xmath , @xmath are positive constants and
@xmath . The function @xmath is always supposed to be @xmath in @xmath ,
locally in @xmath , and Lipschitz in @xmath , uniformly in @xmath ;
moreover we suppose that the value @xmath is an equilibrium, that is

  -- -------- -- --------
     @xmath      (1.17)
  -- -------- -- --------

and that

  -- -------- -- --------
     @xmath      (1.18)
  -- -------- -- --------

which indicates that there is a saturation level. We will derive some
inequalities on the generalised principal eigenvalue of ( 1.16 ) for the
general case of @xmath respecting these hypothesis and @xmath possibly
nonzero.

The characterisation of extinction or persistence of the species is
addressed in the case of @xmath and @xmath a periodic function,
reflecting the periodicity of the environment in which the population
diffuses, as we require with the forthcoming hypothesis. We will analyse
the case of a KPP nonlinearity, that is, we require that

  -- -------- -- --------
     @xmath      (1.19)
  -- -------- -- --------

Then, we suppose that there exists @xmath such that

  -- -------- -- --------
     @xmath      (1.20)
  -- -------- -- --------

To study the effect of the line of fast diffusion, we will compare the
behaviour of ( 1.16 ) to the one of the system

  -- -------- -- --------
     @xmath      (1.21)
  -- -------- -- --------

whose solution is a function @xmath that can be extended by symmetry to
the whole plane. It is natural to consider system ( 1.21 ) as the
counterpart of system ( 1.16 ) in the case without the road, since it
presents the same geometry, including the same boundary condition,
exception made for the exchange terms that are in place for the case of
a fast diffusion channel.

#### 1.2.3 Our results

We are now ready to present the main results of this part of the thesis.

###### The case of a periodic @xmath.

Here, we consider the case of a nonlinearity that respects the KPP
hypothesis and is periodic in the direction of the road. Moreover, we
consider @xmath .

We begin by the following result on the long time behaviour for
solutions of system ( 1.16 ). As already seen for similar problems, the
key point lies in the stability of the @xmath solution. This is linked
to the sign of the generalised principal eigenvalue for the road-field
model, that we have defined in ( 1.15 ). With this notation, we have the
following:

###### Theorem 1.1.

Let @xmath satisfy ( 1.17 )-( 1.20 ) and @xmath . Then the following
holds:

1.   if @xmath , then extinction occurs.

2.   if @xmath , then persistence occurs and the positive stationary
    solution @xmath is unique and periodic in @xmath .

Next, we compare the behaviour of solutions of the system ( 1.16 ) with
the ones of ( 1.21 ), or, equivalently, after extension by symmetry to
the whole plane, of

  -- -------- -- --------
     @xmath      (1.22)
  -- -------- -- --------

Recalling the results of [ 18 ] , we know that the persistence or
extinction of a population for a periodic equation in the whole @xmath
depends on the sign of the periodic eigenvalue @xmath , that was defined
in ( 1.11 ) for a general case. We obtain the following:

###### Theorem 1.2.

Assume @xmath fulfils hypotheses ( 1.17 )-( 1.20 ) and let @xmath .
Then:

1.   if @xmath , then @xmath , that is, if persistence occurs for the
    system “without the road” ( 1.22 ), then it occurs also for system
    “with the road” ( 1.16 ).

2.   if @xmath , then @xmath , that is, if extinction occurs for the
    system “without the road” ( 1.22 ), then it occurs also for system
    “with the road” ( 1.16 ).

Theorem 1.2 asserts that the road has no negative impact on the survival
chances of the population in the case of a medium depending periodically
on with respect to variable in the direction of the road.

We recall the fact that fragmentation lowers the survival possibilities
of a species (see [ 18 , 108 ] ); also, even if we are not in the
framework of an ecological niche, we remember from [ 17 ] the fact that
a road has a negative impact in the setting without climate change. For
those reasons, the result in Theorem 1.2 may be somehow unexpected.
However, despite the fact that no reproduction takes place on the road,
in the case of periodic media the presence of the fast diffusion channel
does not interfere with the long time behaviour of the population, which
depends only on the environment of a periodicity cell. As seen in [ 18 ]
, where the dependence of persistence on the amplitude of fragmentation
was studied, if the favourable zones are sufficiently large, the
population will eventually spread in all of them; the presence of the
road does not cause loss of favourable environment and consequently of
persistence chances. However, we expect the spreading speed to be
influenced by the presence of the road, as it has been already proven in
the case of homogeneous environment.

We point out that Theorem ( 1.1 ) completes and is in accordance with
the results on long time behaviour found in [ 20 ] for a homogeneous
reaction function, which we can consider as a particular case of
periodicity, satisfying a positive KPP request (thanks to the hypothesis
@xmath ). In [ 20 ] , Theorem 4.1 states the convergence of any positive
solution to the unique positive stationary solution of the system. Since
it is well known that for the homogeneous case it holds @xmath , the
hypothesis gives that @xmath and, as a consequence of Theorem 1.1 , that
persistence occurs. Instead if @xmath , then we would be in the first
case of Theorem 1.1 , yielding extinction of the population.

###### Effects of amplitude of heterogeneity

One may ask if the presence of a road may alter the complex interaction
between more favourable and less favourable zones; in particular, one
could wonder if this could penalise the persistence, since it was shown
that populations prefer a less fragmented environment. Nevertheless,
owing from Theorem 1.2 that the road has no effect on the survival
chances of the species, we can recover all the results on the effect of
fragmentation.

Take a parameter @xmath and consider system ( 1.16 ) with nonlinearity

  -- -------- -- --------
     @xmath      (1.23)
  -- -------- -- --------

To highlight the dependence on @xmath , we will call @xmath the
generalised principal eigenvalue defined in ( 1.15 ) with nonlinearity
@xmath . As a direct consequence of our Theorem 1.2 and of Theorem 2.12
in [ 18 ] , we have the following result on the amplitude of
heterogeneity:

###### Corollary 1.3.

Assume @xmath is defined as in ( 1.23 ), @xmath satisfies ( 1.17 )-(
1.20 ), and @xmath . Then:

1.   if @xmath , or if @xmath and @xmath , then for all @xmath we have
    @xmath .

2.   if @xmath , then @xmath for @xmath small enough; if moreover there
    exists @xmath such that @xmath , then for all @xmath large enough
    @xmath .

###### A climate change setting for a general @xmath.

We consider now a general nonlinearity that depends on the variable in
the direction of the road. We stress the fact that we do not suppose any
periodicity, but the case of a periodic @xmath is a particular case of
this setting. Moreover, the following results are done in the general
framework of a possible climate change, so the parameter @xmath may be
different from @xmath .

Comparison between the systems with and without the road, in the general
case, are done through comparison between @xmath and the generalised
principal eigenvalue of system ( 1.21 ), given by

  -- -------- -- --------
     @xmath      (1.24)
  -- -------- -- --------

for @xmath . With this notation, we have the following:

###### Theorem 1.4.

Assume @xmath as in ( 1.24 ) and @xmath as in ( 1.15 ); then @xmath .

In the special case @xmath , some information on the relations between
@xmath and @xmath was already available in [ 17 ] : Proposition 3.1
gives that if @xmath then @xmath . Thanks to that and Theorem 1.4 , the
following result holds:

###### Corollary 1.5.

If @xmath , we have @xmath if and only if @xmath .

As already pointed out in [ 16 ] , even for @xmath it is not true that
@xmath . In fact, it has been found that @xmath , while playing with
@xmath one can have @xmath as large as desired. However, the fact that
they have the same sign reveals that they are profoundly linked.

##### Perspectives

The next problem to tackle for system ( 1.16 ) in a periodic medium
regards the existence of travelling fronts and the study of their speed
in all the direction of the plane. We point out that, with respect to
the classical case, there are great difficulties linked to the
anisotropy of the space, due both to the road and to the periodicity of
the medium. An acceleration effect due to the presence of the road is
expected to be found when @xmath ; however, the repercussions of the
periodicity of the medium on the spreading speed in a general direction
is hard to predict.

We also mention that it would be nice to extend the current results to
the case of heterogeneous exchange terms, periodic in @xmath , as
already treated in [ 58 ] . The key point for attacking that problem is
in the generalisation of the definition of @xmath for non homogeneous
coefficients.

### 1.3 A new model for aggressive competition

#### 1.3.1 Lotka-Volterra models: a literature overview

Another issue that is overlooked in the logistic equation is the
interaction of a species with the other ones living in the same
environment. In the ’20s, Lotka [ 78 ] and Volterra [ 121 ] observed
independently some curios transitory oscillations in the concentration
of chemicals during a reaction and in the population sizes of fishes.

They formulated the following model; let @xmath be the quantity of a
species of plants present in the environment and @xmath the size of a
population of herbivores. It is supposed that the plants have a constant
growth rate at all times, @xmath . The herbivorous feed exclusively on
the observed plant and have limitless appetite. The consumption of
plants eaten by the animals is supposed to depend on the probability of
meeting of the two, represented by @xmath ; the actual loss of the
plants is @xmath and the gain for the herbivores is @xmath with @xmath ,
owning the fact that some plants could be torn but not consumed.
Moreover, as in the malthusian equation, the increase of a population is
suppose to depend on its size. It is also supposed that the environment
conditions are stable and than no mutation in the behaviour of the two
species is possible.

Then, the model reads

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

This system has two equilibria, @xmath and @xmath . If the initial datum
is any point of positive coordinates distinct from the equilibrium, the
population sizes oscillate in time, running on a closed curve on the
phase portrait.

##### Competitive Lotka-Volterra models

Since the pioneer works, many studies on the interaction between
populations were carried out. In particular, after the studies of Gause
[ 54 ] , another model has been employed to investigate the dynamics
between two populations in competition, that is, exploiting at least
partly the same resources. We propose here its construction using the
example of two population of squirrels, the grey one and the red one,
following the work in [ 90 ] . These two species, one of the two
recently introduced in Britain, both inhabit hardwood forests and rely
on the same resources to live. Keeping in mind the derivation of the
logistic equation, we realize that the resource term in this scenario
depends on the size of both population. Moreover, we take into
consideration the fact that, due to the social organisation and
sometimes the segregation between competing species, the presence of
individuals of the rival group may obstruct food collection; if this is
the case, there is an additional decrease of the available resources for
both population. Adding these corrections to the logistic of both
groups, the Lotka-Volterra competitive system reads

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

where @xmath , @xmath , @xmath , @xmath , @xmath and @xmath are
nonnegative real numbers. The coefficients @xmath and @xmath are the
intrinsic growth rates of the two population; @xmath and @xmath
represent the carrying capacities of the environment for the two groups.
The coefficients @xmath and @xmath represent the competition between
individuals of different species, and indeed they appear multiplied by
the term @xmath , which represents a probability of meeting. Taking the
example of the squirrels, we expect that @xmath . However, for other
couple of populations relying on only partially overlapping food sets,
one could have also @xmath . If finally the first population feeds on a
subset of the resources of the second one, it would be @xmath and @xmath
.

For the sake of completeness, we recall that in the case of species
mutually benefiting from the presence of the other, which is not part of
the competitive framework, the dynamics prescribes negative values for
@xmath and @xmath .

The dynamics of system ( 1.26 ) depends indeed on the values of the
interspecific competition terms: if @xmath , then the first species
@xmath has an advantage over the second one @xmath and will eventually
prevail; if @xmath , then the first population that penetrates the
environment (that is, the one that has a greater size at the initial
time) will persist while the other will extinguish; if @xmath , there
exists an attractive coexistence steady state. The fact that, if two
populations’ ecological niches completely overlap, then one of the two
species gets extinct, is exactly the statement of the Gause principle, a
well-established law in ecology.

The Lotka-Volterra models of ODEs have been extended in many ways and
its applications range from technology substitution to business
competition. In the stochastic analysis community, system ( 1.25 ) with
additioned noise terms has been largely studied [ 62 ] . Another branch
were these systems have been of huge influence is, of course,
reaction-diffusion equations. In the next paragraph we are spending some
words on the results for diffusive Lotka-Volterra competitive systems.

##### Competitive Lotka-Volterra model with diffusion

In the interaction between different population, as already happens in
the dynamic of a single species, spatial organisation plays an important
role. A great literature has been devoted to the competitive
Lotka-Volterra system with diffusion, that is, up to a rescaling,

  -- -------- -- --------
     @xmath      (1.27)
  -- -------- -- --------

for some @xmath , @xmath , @xmath , @xmath positive constants. Richer
dynamics and more questions naturally arise for system ( 1.27 ) but,
unsurprisingly, the study of these involves many more difficulties. Just
to give some flavour of those, we provide some details on the study of
the speed of propagation of travelling waves connecting the steady
states @xmath and @xmath , to which many studies have been consecrated.
From the works of Lewis, Li and Weinberger [ 75 , 76 ] the minimal speed
of propagation of a monotonic wave is called @xmath . Even it the
simplest case stated in ( 1.27 ), the exact value of @xmath is still not
known. Calling @xmath the minimal speed of diffusion for the second
equation under the assumption @xmath , it holds that @xmath , but the
inequality may be strict depending on the parameters [ 64 , 65 ] .

Nevertheless, system ( 1.27 ) is one of the simplest among many
possibilities; in the literature one finds systems considering nonlocal
diffusion [ 91 ] , free boundary [ 44 ] , cross diffusion [ 79 ] , and
many other variations.

#### 1.3.2 A model of Lotka-Volterra type for aggressive competition and
analysis of the strategies

Among the several models dealing with the dynamics of biological
systems, the case of populations in open hostility seems to be rather
unexplored. Our model considers the case of two populations competing
for the same resource with one aggressive population which attacks the
other: concretely, one may think of a situation in which two populations
live together in the same territory and share the same environmental
resources, till one population wants to prevail and try to overwhelm the
other. We consider this situation as a “civil war”, since the two
populations share land and resources.

##### The model

We now describe in further detail our model of conflict between the two
populations and the attack strategies pursued by the aggressive
population. Given the lack of reliable data related to civil wars, the
equations were derived by deduction from the principles of population
dynamics. Our idea is to modify the Lotka-Volterra competitive system
for two populations with density @xmath and @xmath , adding to the usual
competition for resources the fact that both populations suffer some
losses as an outcome of the attacks. The key point in our analysis is
that the clashes do not depend on the chance of meeting of the two
populations, given by the quantity @xmath , as it happens in many other
works in the literature, but they are sought by the first population and
depend only on the size @xmath of the first population and on its level
of aggressiveness @xmath . The resulting model is

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

where @xmath , @xmath and @xmath are nonnegative real numbers. Here, the
coefficient @xmath models the fitness of the second population with
respect to the first one. The parameter @xmath here stands for the
quotient of endured per inflicted damages for the first population.

##### Behaviour of solutions

We denote by @xmath a solution of ( 1.28 ) starting from a point @xmath
. We will also refer to the orbit of @xmath as the collection of points
@xmath for @xmath , thus both positive and negative times, while the
trajectory is the collection of points @xmath for @xmath .

From the equations in ( 1.28 ), one promptly sees that @xmath is not an
equilibrium, hence, @xmath can reach the value @xmath and even negative
values in finite time. From a modelling point of view, negative values
of @xmath are not acceptable, being it a population density. However, we
will suppose that the dynamics stops when the value @xmath is reached
for the first time. At this point, the conflict ends with the victory of
the first population @xmath , that can continue its evolution with a
classical Lotka-Volterra equation of the form

  -- -------- --
     @xmath   
  -- -------- --

and that would certainly fall into the attractive equilibrium @xmath .

In order to state our first result on the dynamics of the system ( 1.28
), we first observe that, in a real-world situation, the value of @xmath
would probably be non-constant and discontinuous, so we allow this
coefficient to take values in the class @xmath defined as follows:

  -- -------- -- --------
     @xmath      (1.29)
  -- -------- -- --------

A solution related to a strategy @xmath is a pair @xmath , which is
@xmath outside the discontinuity points of @xmath and solves system (
1.28 ). Moreover, once the initial datum is imposed, the solution is
assumed to be continuous at @xmath .

In this setting, we establish the existence of the solutions to
problem ( 1.28 ) and we classify their behavior with respect to the
possible exit from the domain @xmath . Given @xmath and @xmath , two
scenarios are possible for a solution @xmath with @xmath of system (
1.28 ) starting at @xmath :

1.  The solution @xmath issued from @xmath belongs to @xmath for all
    @xmath .

2.  There exists @xmath such that the solution @xmath issued from @xmath
    exists unique for all @xmath , and @xmath and @xmath .

As a consequence, we can define the the stopping time of the solution
@xmath as

  -- -------- -- --------
     @xmath      (1.30)
  -- -------- -- --------

From now on, we will implicitly consider solutions @xmath only for
@xmath .

We call victory of the first population the scenario where @xmath , that
corresponds to the case where @xmath and @xmath . On the other hand, we
call victory of the second population the scenario where @xmath tends to
@xmath as @xmath tends to infinity.

Now we are going to analyze the dynamics of ( 1.28 ) with a particular
focus on possible strategies. To do this, we now define the basins of
attraction . The first one is the basin of attraction of the point
@xmath , that is

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

namely the set of the initial points for which the first population gets
extinct (in infinite time) and the second one survives. The other one is

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

namely the set of initial points for which we have the victory of the
first population and the extinction of the second one.

##### A control problem

In a rational, or at least well-organised population, one may expect
that the parameter @xmath , representing aggressiveness, is subject to
control; we are suggesting that a population, by performing premeditated
attacks, may control its strategy in the conflict and would be able to
choose the most appropriate one.

From now on, we may refer to the parameter @xmath as the strategy , that
may also depend on time, and we will say that it is winning if it leads
to victory of the first population. We also notice that, with this
choice, ( 1.28 ) is a control-affine system.

The main problems that we deal with are:

1.  The characterization of the initial conditions for which there
    exists a winning strategy .

2.  The success of the constant strategies , compared to all possible
    strategies.

3.  The construction of a winning strategy for a given initial datum.

4.  The existence of a single winning strategy independently of the
    initial datum .

5.  The existence of a winning strategy minimizing duration of the war .

The first question is a problem of target reachability for a
control-affine system. The second point regards the choice of a suitable
functional space where to choose the strategy. We also construct an
actual winning strategy when victory is possible, answering the third
and fourth question. The last question results to be an optimisation
problem.

#### 1.3.3 Our results

##### Dynamics for a constant strategy

The first step towards the understanding of the dynamics of the system
in ( 1.28 ) is is to analyze the behavior of the system for constant
coefficients.

To this end, we introduce some notation. Following the terminology on
pages 9-10 in [ 123 ] , we say that an equilibrium point (or fixed
point) of the dynamics is a (hyperbolic) sink if all the eigenvalues of
the linearized map have strictly negative real parts, a (hyperbolic)
source if all the eigenvalues of the linearized map have strictly
positive real parts, and a (hyperbolic) saddle if some of the
eigenvalues of the linearized map have strictly positive real parts and
some have negative real parts (since in this problem we work in
dimension @xmath , saddles correspond to linearized maps with one
eigenvalue with strictly positive real part and one eigenvalue with
strictly negative real part). We also recall that sinks are
asymptotically stable (and sources are asymptotically stable for the
reversed-time dynamics), see e.g. Theorem 1.1.1 in [ 123 ] .

With this terminology, we state the following theorem:

###### Theorem 1.6 (Dynamics of system (1.28)).

For @xmath , @xmath and @xmath the system ( 1.28 ) has the following
features:

-    When @xmath , the system has 3 equilibria: @xmath is a source,
    @xmath is a sink, and

      -- -------- -- --------
         @xmath      (1.33)
      -- -------- -- --------

    is a saddle.

-    When @xmath , the system has 2 equilibria: @xmath is a sink and
    @xmath is a saddle.

-    When @xmath , the system has 2 equilibria: @xmath is a sink and
    @xmath corresponds to a strictly positive eigenvalue and a null one.

-    We have

      -- -------- -- --------
         @xmath      (1.34)
      -- -------- -- --------

    where @xmath and @xmath are defined in ( 1.31 ) and ( 1.32 ),
    respectively, and @xmath is a smooth curve.

-    The trajectories starting in @xmath tend to @xmath if @xmath , and
    to @xmath if @xmath as @xmath goes to @xmath .

More precisely, one can say that the curve @xmath in Theorem 1.6 is the
stable manifold of the saddle point @xmath when @xmath , and of the
saddle point @xmath when @xmath . The case @xmath needs a special
treatment, due to the degeneracy of one eigenvalue, and in this case the
curve @xmath corresponds to the center manifold of @xmath , and an
ad-hoc argument will be exploited to show that also in this degenerate
case orbits that start in @xmath are asymptotic in the future to @xmath
. As a matter of fact, @xmath acts as a dividing wall between the two
basins of attraction @xmath and @xmath , as described in (iv) of Theorem
1.6 .

From a modelling point of view, Theorem 1.6 shows that, also for our
model, the Gause principle of exclusion is respected; that is, in
general, two competing populations cannot coexist in the same territory,
see e.g. [ 47 ] .

One peculiar feature of our system is that, if the aggressiveness is too
strong, the equilibrium @xmath changes its “stability” properties,
passing from a source (as in (i) of Theorem 1.6 ) to a saddle point (as
in (ii) of Theorem 1.6 ). This shows that the war may have
self-destructive outcomes, therefore it is important for the first
population to analyze the situation in order to choose a proper level of
aggressiveness. Figure 1.1 shows one example of dynamics for each case.

The dedicated chapter contains further results on the dependence of
@xmath and @xmath on the parameters @xmath and @xmath . The parameter
@xmath , a part from having a more intricate influence on the system,
may be interpreted not as a biological constant but rather as a choice
of the first population. Therefore, we perform a deeper analysis, whose
result are presented in the next paragraph.

##### Dynamics for variable strategies and optimisation results

We now introduce some terminology. Recalling ( 1.29 ), for any @xmath ,
we set

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

where @xmath denotes the set of initial data @xmath such that @xmath ,
when the coefficient @xmath in ( 1.28 ) is replaced by the function
@xmath . Namely, @xmath represents the set of initial conditions for
which @xmath is able to win by choosing a suitable strategy in @xmath ;
we call @xmath the victory set with admissible strategies in @xmath . We
also say that @xmath is a winning strategy for the point @xmath if
@xmath .

Moreover, we will call

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

Notice that @xmath is the limit point as @xmath tends to @xmath of the
sequence of saddle points @xmath defined in ( 1.33 ).

With this notation, the first question that we address is for which
initial configurations it is possible for the population @xmath to have
a winning strategy, that is, to characterize the victory set. For this,
we allow the strategy to take all the values in @xmath . In this
setting, we have the following result:

###### Theorem 1.7.

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (1.37)
      -- -------- -- --------

    with the convention that the last line in ( 1.37 ) is not present if
    @xmath .

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (1.38)
      -- -------- -- --------

    where

      -- -------- --
         @xmath   
      -- -------- --

    and we use the convention that the last line in ( 1.38 ) is not
    present if @xmath .

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (1.39)
      -- -------- -- --------

    where

      -- -------- -- --------
         @xmath      (1.40)
      -- -------- -- --------

    and we use the convention that the last line in ( 1.39 ) is not
    present if @xmath .

Theorem 1.7 implies that the problem is not controllable , that is, for
some initial conditions the first population is not able to reach its
target.

In practice, constant strategies could be certainly easier to implement
and it is therefore natural to investigate whether or not it suffices to
restrict the control to constant strategies without altering the
possibility of victory. The next result addresses this problem by
showing that when @xmath constant strategies are as good as all
strategies, but instead when @xmath victory cannot be achieved by only
exploiting constant strategies:

###### Theorem 1.8.

Let @xmath be the set of constant functions. Then the following holds:

-    For @xmath , we have that @xmath for all @xmath ;

-    For @xmath , we have that @xmath .

The result of Theorem 1.8 , part (i), reveals a special rigidity of the
case @xmath in which the victory depends only on the initial conditions,
but it is independent of the strategy @xmath . Instead, as stated in
Theorem 1.8 , part (ii), for @xmath the choice of @xmath plays a crucial
role in determining which population is going to win and constant
strategies do not exhaust all the possible winning scenarios. We stress
that @xmath plays also a special role in the biological interpretation
of the model, since in this case the two populations have the same
fitness to the environmental resource, and hence, in a sense, they are
indistinguishable, up to the possible aggressive behavior of the first
population.

Next, we show that for all points in the set @xmath we can choose an
appropriate piecewise constant strategy with at most one discontinuity;
functions with these properties are called Heaviside functions.

###### Theorem 1.9.

There holds that @xmath , where @xmath is the set of Heaviside
functions.

The proof of Theorem 1.9 solves also the third question mentioned in the
introduction. As a matter of fact, it proves that for each point we
either have a constant winning strategy or a winning strategy of type

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , and for suitable values @xmath , @xmath such that one
is very small and the other one very large, the order depending on
@xmath . The construction that we give also puts in light the fact that
the choice of the strategy depends on the initial datum, answering also
our fourth question.

It is interesting to observe that the winning strategy that switches
abruptly from a small to a large value could be considered, in the
optimal control terminology, as a “bang-bang” strategy. Even in a target
reachability problem, the structure predicted by Pontryagin’s Maximum
Principle is brought in light: the bounds of the set @xmath , as given
in Theorem 1.7 , depend on the bounds that we impose on the strategy,
that are, @xmath .

It is natural to consider also the case in which the level of
aggressiveness is constrained between a minimal and maximal threshold,
which corresponds to the setting @xmath for suitable @xmath , with the
hypothesis that @xmath . In this setting, we denote by @xmath the class
of piecewise continuous strategies @xmath in @xmath such that @xmath for
all @xmath and we let

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

Then we have the following:

###### Theorem 1.10.

Let @xmath and @xmath be two real numbers such that @xmath and @xmath .
Then, for @xmath we have the strict inclusion @xmath .

Notice that for @xmath , Theorem 1.8 gives instead that @xmath and we
think that this is a nice feature, outlining a special role played by
the parameter @xmath (roughly speaking, when @xmath constant strategies
suffice to detect all possible winning configurations, thanks to Theorem
1.8 , while when @xmath non-constant strategies are necessary to detect
all winning configurations).

###### Time minimizing strategy.

Once established that it is possible to win starting in a certain
initial condition, we are interested in knowing which of the possible
strategies is best to choose. One condition that may be taken into
account is the duration of the war. Now, this question can be written as
a minimization problem with a proper functional to minimize and
therefore the classical Pontryagin theory applies.

To state our next result, we recall the setting in ( 1.41 ) and define

  -- -------- --
     @xmath   
  -- -------- --

that is the set of all bounded strategies for which the trajectory
starting at @xmath leads to the victory of the first population. To each
@xmath we associate the stopping time defined in ( 1.30 ), and we
express its dependence on @xmath by writing @xmath . In this setting, we
provide the following statement concerning the strategy leading to the
quickest possible victory for the first population:

###### Theorem 1.11.

Given a point @xmath , there exists a winning strategy @xmath , and a
trajectory @xmath associated with @xmath , for @xmath , with @xmath ,
where @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- --------
     @xmath      (1.42)
  -- -------- -- --------

The surprising fact given by Theorem 1.11 is that the minimizing
strategy is not only of bang-bang type, but it may assume some values
along a singular arc , given by @xmath . This possibility is realized in
some concrete cases, as we verified by running some numerical
simulations, whose results can be visualized in Figure 1.2 .

##### Perspectives

The system of ODEs is the cornerstone for the study of the
reaction-diffusion system

  -- -------- -- --------
     @xmath      (1.43)
  -- -------- -- --------

for some @xmath . We expect solutions to this system to have very
interesting behaviours. It is possible that the second population
reaches the value @xmath in only some points of the domain, giving an
example of the interesting phenomenon known as dead-core, see e.g. [ 61
] .

### 1.4 Evolution equations with classical and fractional derivatives

#### 1.4.1 Fractional derivatives in evolution equations

The idea of fractional calculus first appears in the discussions between
Leibniz and De l’Hospital (see [ 104 ] ); namely, given the classical
derivative @xmath for @xmath , it is quite natural to ask if it is
possible to define a generalisation of this operator but with non entire
order, thus @xmath with @xmath .

However, it is only in the last few decades that a good number of
mathematicians started to work on fractional calculus. One of the
reasons of this interest is the fact that fractional derivative can help
in the modelization of processes with memory or of diffusion phenomena
with spreading behaviour different from the one prescribed by Brownian
motion. This has applications in charge carrier transport in
semicondutors, nuclear magnetic resonance diffusometry, porous systems,
dynamics in polymeric systems (see [ 84 ] and the references therein).

Here, we introduce some fractional derivatives and operators and justify
their meaning and relations with the previous material. Providing an
overview on the state of art over existence, regularity and behaviour of
evolution equations dealing with fractional operators is far from our
purposes, due to the complexity of the topic. For that, we refer to [ 6
, 33 , 34 , 98 , 106 , 124 ] and the reference therein.

##### The Caputo derivative

There are several way of defining a fractional derivative. We choose to
work with Caputo derivative , that was first proposed in a geology model
by Caputo in [ 30 ] . The Caputo derivative of order @xmath is defined
by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is Euler’s Gamma-function and @xmath is the classical
derivative of @xmath . For simplicity, we will omit the constant and
work with

  -- -------- --
     @xmath   
  -- -------- --

Notice that @xmath is defined for all @xmath such that @xmath . It is
also possible to define Caputo derivatives of higher order, thus with
@xmath for @xmath , by the following:

  -- -------- --
     @xmath   
  -- -------- --

The Caputo derivative describes a process “with memory”, in the sense
that the history of the process is encoded in the derivative, though old
events “count less” than recent ones, since their value is counted with
a smaller weight. Due to this memory property, this operator has found
several applications in models of hydrogeology, heat transmission,
percolation.

The Caputo derivative is considered to be an operator of “fractional”
order, as opposed to the entire order, that is proper to the classical
derivatives. The value @xmath corresponds to the order of the
derivative: indeed, for a power of order @xmath , it holds @xmath for
some constant @xmath .

Among the other types of fractional derivatives, it is worth mentioning
the Riemann-Liouville derivative because of its large diffusion. The
Riemann-Liouville derivative is defined by

  -- -------- -- --------
     @xmath      (1.44)
  -- -------- -- --------

and making the calculations one can show that it differs from the Caputo
derivative by the term @xmath . One of the reasons of the popularity of
the Riemann-Liouville derivative is that its limit for @xmath coincides
with the classical derivative.

###### Evolution equations with Caputo time derivative.

Classical partial differential equations are often divided in three
groups depending on the order of the time derivative: elliptic,
parabolic, hyperbolic. Nevertheless, even in the Preface of Partial
Differential Equations by Evans [ 45 ] , the author states that this
subdivision is fictive and “creates the false impression that there is
some kind of general and useful classification scheme available”. This
subdivision is supposed to put together object with similar behaviours
and classic theory results are usually meant for one of these clusters.

An evolution equation with the Caputo time derivative, for example

  -- -------- -- --------
     @xmath      (1.45)
  -- -------- -- --------

is not part of any of this groups. Thus, many results that one may want
to use are not available and must be recovered.

However, relations with the classical objects are present. Because of
some behaviour similarities, evolution equations with Caputo time
derivative have often been compared to parabolic ones [ 84 ] . Recently,
in [ 42 ] , Dipierro and Valdinoci inspected a model of transmission in
neural structures and derive equation ( 1.45 ) from basic principles.
Doing so, they realized that it can be seen as a superposition of
several hyperbolic equations acting with delay. Despite this, the
behaviour of solutions of ( 1.45 ) is not similar to the one of wave
equations: in fact, in opposition to hyperbolic equations, ( 1.45 ) has
a regularising effect on initial data.

##### The fractional Laplacian

An operator that has been very popular in recent years is the fractional
Laplacian, which is considered in some sense the fractional counterpart
of the classic homonym operator. Given @xmath , we define the fractional
Laplacian as

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

where “P.V.” stands for Principal Value. Curiously, many equivalent
definitions of the fractional Laplacian are possible: a part the one in
( 1.46 ), in [ 1 , 73 ] one can find a very exhaustive list together
with the most important properties of the operator known so far.

One of the reason for the popularity of the fractional Laplacian is its
connection with Lévy processes. We now give the idea behind the
derivation of an evolution equation containing the fractional Laplacian
from a discrete Lévy process, which is similar to the derivation of the
heat equation from a Brownian movement. Consider an infinite grid @xmath
, for some step @xmath , and a discrete evolution of time step @xmath .
Imagine to put a particle at the origin. At each time step @xmath , the
particle can jump to any vertex of the grill different from its actual
position, with a probability that depends on the length of the jump;
namely, if the particle is at the position @xmath , with @xmath , the
probability to jump into the position @xmath , if @xmath , is

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a normalisation constant. Then, we call @xmath the
probability of finding the particle in @xmath at the time @xmath . The
function @xmath evolves according to the probability of the jumps; for
example, the probability of finding the particle in the origin at some
time @xmath is

  -- -------- --
     @xmath   
  -- -------- --

By taking the limit as @xmath tends to @xmath , and by performing
suitable manipulations, the last equality becomes the evolution equation

  -- -------- --
     @xmath   
  -- -------- --

For all the details of the proof, we refer to [ 68 ] .

Satellite-based measures of animal movement performed in the last years
have shown that Lévy process are a better approximation of animal
movement than Brownian motion. Some examples are provided by honey bees
displacements and by movement of marine predators when prey is scarce [
10 , 66 , 101 ] . In general, it appears that Lévy-flights are more
fitting hunt strategies than Brownian walks [ 77 ] . For this reason,
the fractional Laplacian has been introduced in population dynamics
model, see [ 11 , 36 , 55 ] and the reference therein. However, the
technical difficulties of dealing with such delicate operators have not
been totally overcome.

#### 1.4.2 Decay estimates for evolution equations with classical and
fractional derivatives

Among the many open questions for fractional operators, we choose to
study decay estimates of a class of evolution equations with possibly
nonlocal or nonlinear diffusion operators. In particular, we are going
to study the decay in time of the Lebesgue norm of solutions to a Cauchy
problem in a bounded domain. We present some general results that apply
to a wide class of evolution equations, namely all the ones involving a
diffusion operator that is satisfying a certain ellipticity property,
involving an “energy functional” that suits for both local and non local
operators, possibly complex. The time derivative may be of two types:
purely classical or a linear combination of a classical derivative and a
Caputo derivative.

##### The problem

We now set the problem. Let @xmath be fixed positive numbers. We
suppose, for concreteness, that

  -- -------- --
     @xmath   
  -- -------- --

but up to a rescaling of the operator we can take @xmath any nonnegative
numbers with positive sum. Let @xmath be a bounded open set and let
@xmath such that @xmath . Consider the Cauchy problem

  -- -------- -- --------
     @xmath      (1.47)
  -- -------- -- --------

where @xmath is an operator, possibly involving fractional derivatives.

We underline that we consider smooth ( @xmath often, @xmath if also the
second derivative appears) and bounded solutions of the problem ( 1.47
). In fact, we want to avoid convergence problems with the integrals
that appear in the statements and in the proofs. However, for certain
operators, weaker hypothesis may be taken.

Let us recall that for a complex valued function @xmath the Lebesgue
norm is

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath . Also, we call @xmath the real part of @xmath . The main
assumption we take is the following: there exist @xmath and @xmath such
that

  -- -------- -- --------
     @xmath      (1.48)
  -- -------- -- --------

The constants @xmath and @xmath and their dependence from the parameters
of the problem may vary from case to case. The righthandside of the
equation may be seen as an energy functional linked to the diffusion
operator. This inequality implies, essentially, that the operator @xmath
is not too degenerate and the energy of the solution should control a
certain power of the solution itself; here @xmath plays the role of the
degree of ellipticity. The inequality ( 1.48 ) strongly depends on the
validity of a Sobolev inequality for the solutions of the evolution
equation. To get an intuition of the roles of the factors, take the case
of the Laplacian with @xmath ; integrating by parts on the righthandside
one obtains @xmath , thus the energy, which controls the @xmath norm of
the solution by the Gagliardo-Nirenberg-Sobolev inequality. In our
setting, the structural inequality in ( 1.48 ) will be the cornerstone
to obtain general energy estimates, which, combined with appropriate
barriers, in turn produce time-decay estimates.

#### 1.4.3 Our Results

Extending the method of [ 43 ] , we obtain a power-law decay in time of
the @xmath norm with @xmath . Also, for the case of classical
time-derivatives, we obtain exponential decays in time. The difference
between polynomial and exponential decays in time is thus related to the
possible presence of a fractional derivative in the operator involving
the time variable.

##### Decay estimate theorems

First, we present this result for the more general setting, hence for a
linear combination of classical and Caputo time derivative. We have the
following:

###### Theorem 1.12.

Let @xmath be a solution of the Cauchy problem ( 1.47 ), with @xmath
possibly complex valued. Suppose that there exist @xmath , @xmath and
@xmath such that @xmath satisfies ( 1.48 ). Then

  -- -------- -- --------
     @xmath      (1.49)
  -- -------- -- --------

where @xmath and @xmath are the constants appearing in ( 1.48 ).
Furthermore,

  -- -------- -- --------
     @xmath      (1.50)
  -- -------- -- --------

for some @xmath , depending only on @xmath , @xmath , @xmath and @xmath
.

A polynomial decay is a nice piece of information on the solution and we
can expect this to be the best decay we can get for some fractional
evolution equations [ 56 , 25 ] . However, there is also evidence that
for classical settings better decays can be achieved. In fact, the
following theorem holds:

###### Theorem 1.13.

Let @xmath be a solution of the Cauchy problem ( 1.47 ) with only
classical derivative (that is, @xmath ) and @xmath possibly complex
valued. Suppose that there exist @xmath , @xmath and @xmath such that
@xmath satisfies ( 1.48 ). Then, for some @xmath , depending only on the
constants @xmath and @xmath in ( 1.48 ), and on @xmath , we have that:

-    if @xmath the solution @xmath satisfies

      -- -------- -- --------
         @xmath      (1.51)
      -- -------- -- --------

-    if @xmath , the solution @xmath satisfies

      -- -------- -- --------
         @xmath      (1.52)
      -- -------- -- --------

As we will see in the proofs of these two theorems, the idea is to find
a supersolution of ( 1.49 ) and use a comparison principle in order to
estimate the decay of the solution @xmath . For the case of mixed
derivatives, Vergara and Zacher [ 119 ] find both a supersolution and a
subsolution decaying as @xmath . But, when @xmath , the subsolution
tends to 0. On the other hand, the classical equation @xmath has some
exponential supersolutions. This allows possibly better decays, which
are in fact proven.

We point out that the case of an evolution equation with only Caputo
time derivative, i.e. of @xmath , was treated in [ 43 ] . The authors
find in this case that the supersolution is still asymptotic to @xmath
and the decay is of polynomial type.

It is interesting to notice the presence of a “decoupling” effect: for
evolution equations with classical time derivative and fractional space
derivative (take for example the fractional Laplacian, @xmath , @xmath ,
see [ 43 ] ), the space derivative does not asymptotically interfere
with the time derivative; thus the polynomial decay, typical of
fractional derivatives, does not appear, leaving place for the
exponential decay given by the classical time derivative. An example of
this behaviour is found in [ 93 ] , where a model inspired to atoms
dislocation was studied.

##### Applications

What makes Theorems 1.12 and 1.13 interesting is the fact that they may
be applied to a wide range of equations. Indeed, the only hypothesis
required in order to apply the theorems is the validity of the
inequality ( 1.48 ) for suitable parameters @xmath and @xmath . In [ 43
] and in our work, ( 1.48 ) was verified for many operators, that we are
listing here together with some references on the origins of these
operators:

-   [label= @xmath ]

-   the classic and fractional Laplacian, [ 27 ] ,

-   the classic and fractional @xmath -Laplacian, [ 32 ] ,

-   the doubly nonlinear equation, [ 100 ]

-   the classic and fractional porous medium equations, [ 118 , 29 ] and
    [ 39 ] ,

-   the classic and fractional mean curvature equation, [ 28 ]

-   the classic and fractional Kirchhoff equation, [ 23 ] and [ 49 ] ,

-   the classic and fractional magnetic operator, [ 67 ] and [ 38 ] .

The list is not supposed to be exhaustive; in fact, the aim is only to
provide some example of operators satisfying ( 1.48 ) and to encourage
other mathematicians looking for some decay estimates to attempt with
operators they are struggling with.

## Chapter 2 A Fisher-KPP model with a fast diffusion line in periodic
media

In this chapter, we treat a model of population dynamics in a periodic
environment presenting a fast diffusion line. The “road-field” model,
introduced in [ 20 ] , is a system of coupled reaction-diffusion
equations set in domains of different dimensions. Here, we consider for
the first time the case of a reaction term depending on a spatial
variable in a periodic fashion, which is of great interest for both its
mathematical difficult and for its applications. We derive necessary and
sufficient conditions for the survival of the species in terms of the
sign of a suitable generalised principal eigenvalue, defined recently in
[ 16 ] . Moreover, we compare the long time behaviour of a population in
the same environment without the fast diffusion line, finding that this
element has no impact on the survival chances. This chapter corresponds
to the paper [ 2 ] .

### 2.1 Setting and main results

This chapter investigates some effects of a fast diffusion line in an
ecological dynamics problem. Various examples in the literature showed
that, in the presence of roads or trade lines, some species or
infections spread faster along these lines, and then diffuse in the
surroundings. This was observed in the case of the Processionary
caterpillar, whose spreading in France and Europe has been accelerated
by accidental human transport [ 103 ] . Another striking proof was given
in [ 52 ] , where the authors point out that the COVID-19 epidemics in
Northern Italy at the beginning of 2020 diffused faster along the
highways.

A model for biological diffusion in a homogeneous medium presenting a
fast diffusion line was proposed by Berestycki, Roquejoffre and Rossi in
[ 20 ] , and since then is called the road-field model . The authors
proved an acceleration effect due to the road on the spreading speed of
an invading species. Since then, a growing number of articles treated
variations of the same system, investigating in particular the effect of
different type of diffusion or different geometries [ 13 , 14 , 105 ] .

However, natural environments are usually far from being homogeneous
and, more often than not, territories are a composition of different
habitats. Living conditions and heterogeneity play a strong impact on
the survival chances of a species and on the equilibria at which the
population can settle.

Road-field models on heterogeneous environments have been little studied
so far, being more complex to treat. One of the few example is the paper
[ 58 ] for periodic exchange terms between the population on the road
and the one in the field. Recently, Berestycki, Ducasse and Rossi
introduced a notion of generalised principal eigenvalue for the
road-field system in [ 16 ] and, thanks to it, they were able to treat
the case of an ecological niche facing climate change in [ 17 ] .

Here, we propose an analysis of the asymptotic behaviour of an invasive
population under the assumption of spatial periodicity of the reaction
term. Of course, under this hypothesis we can investigate deeper the
dependence of the population on a natural-like environment and the
effects of the road in this balance. Under which conditions does the
population survive in a periodic medium? And does the road play some
role on the survival chances of a species, perturbing the environment
and scattering the individuals, or rather permitting them to reach
advantageous zones more easily? These are the questions we are going to
tackle.

#### 2.1.1 The model

In this chapter, we study the reaction-diffusion model regulating the
dynamics of a population living in a periodic environment with a fast
diffusion channel. The equivalent of this model for homogeneous media
was first introduced by Berestycki, Roquejoffre and Rossi in [ 20 ] .
Consider the half plane @xmath , where we mean @xmath . The proposed
model imposes the diffusion of a species in @xmath and prescribes that
on @xmath the population diffuses at a different speed. We call @xmath
the density of population for @xmath , hence on the “field”, and @xmath
the density of population for @xmath , i.e. on the “road”; moreover, we
take @xmath , @xmath , @xmath , @xmath positive constants and @xmath .
Then, the system we analyse reads

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

In @xmath , the population evolves with a net birth-death rate
represented by @xmath , that depends on the variable @xmath . This
embodies the heterogeneity of the media: in fact, environments are
typically not uniform and some zone are more favourable than others.
There is no dependence in the variable @xmath , since the presence of
the road itself creates enough heterogeneity in that direction. The
function @xmath is always supposed to be @xmath in @xmath , locally in
@xmath , and Lipschitz in @xmath , uniformly in @xmath ; moreover, we
suppose that the value @xmath is an equilibrium, that is

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

and that

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

We will derive some inequalities on the generalised principal eigenvalue
of ( 2.1 ) for the general case of @xmath respecting these hypothesis
and @xmath possibly nonzero.

The characterisation of extinction or persistence of the species is
performed for the case of @xmath and @xmath a periodic function,
reflecting the periodicity of the environment in which the population
diffuses. We will analyse the case of a KPP nonlinearity, that is, we
require that

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

Then, we suppose that there exists @xmath such that

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

To study the effect of the line of fast diffusion, we will compare the
behaviour of ( 2.1 ) to the one of the system

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

whose solution is a function @xmath that can be extended by symmetry to
the whole plane, thanks to the Neumann border condition. It is natural
to consider system ( 2.6 ) as the counterpart of system ( 2.1 ) in the
case without the road, since it presents the same geometry, including
the same boundary condition exception made for the exchange terms that
are in place for the case of a fast diffusion channel.

#### 2.1.2 State of the art

We present here the background that led us consider system ( 2.1 ) and
some useful results that are known in the community.

The study of reaction-diffusion equations started with the works by
Fisher [ 50 ] and by Kolmogorov, Petrowskii and Piskunov [ 72 ] , who
modelled the spacial diffusion of an advantageous gene in a population
living in a one-dimensional environment through the equation

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

for @xmath and @xmath . For ( 2.7 ), it is supposed that @xmath and
@xmath is a @xmath function satisfying @xmath and the KPP hypothesis
@xmath for @xmath . The first example was a nonlinearity of logistic
type, so @xmath for some @xmath . It was shown any solution @xmath
issued from a nonnegative initial datum @xmath converges to 1 as @xmath
goes to infinity, locally uniformly in space; this long time behaviour
is called invasion . The generalisation in higher dimension of equation
( 2.7 ) was then used to study the spatial diffusion of animals, plants,
bacteria and epidemics [ 109 , 89 ] .

A vast literature has been originated from the pioneer works, studying
various aspects of the homogeneous equation ( 2.7 ), in particular
concerning the travelling fronts . These are solutions of the form
@xmath with @xmath , for @xmath a direction, the direction of
propagation , and @xmath the speed of propagation of the travelling
front . Other than this, researchers have investigated the asymptotic
speed of propagation at which level sets of a solution starting from
@xmath expands. These topics arose already in [ 50 ] and [ 72 ] , and
their investigation was continued in many interesting articles, among
which [ 48 ] and [ 7 ] .

The correspondence of the theoretical results with actual data as seen
in [ 109 ] was encouraging, however it was clear that natural
environments, even at macroscopic levels, were not well represented by a
homogeneous medium, due to the alternation of forests, cultivated
fields, plains, scrubs and many other habitats, as well as roads, rivers
and other barriers [ 70 ] . It was necessary to look at more
sophisticated features, as the effects of inhomogeneity, fragmentation,
barriers and fast diffusion channels, and on the top of that, climate
change.

A first analysis was carried out in [ 108 , 107 ] and in [ 70 ] for the
so-called the patch model . The authors considered a periodic mosaic of
two different homogeneous habitats, one favorable and one unfavorable
for the invading species. In [ 70 ] , the authors studied the long time
behaviour of the population starting from any nonnegative initial datum.
For further convenience, let us give the following definition:

###### Definition 2.1.

For the equation of ( 2.7 ) or the system ( 2.1 ), we say that

1.  extinction occurs if any solution starting from a non negative
    bounded initial datum converges to @xmath or to @xmath uniformly as
    @xmath goes to infinity.

2.  persistence occurs if any solution starting from a non negative, non
    zero, bounded initial datum converges to a positive stationary
    solution locally uniformly as @xmath goes to infinity.

In [ 70 ] , it was empirically shown that the stability of the trivial
solution @xmath determines the long time behaviour of the solutions. A
solid mathematical framework for a general periodic environment was
given in [ 18 ] . There, the authors considered the equation

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

for @xmath and @xmath . The diffusion matrix @xmath is supposed to be
@xmath , uniformly elliptic and periodic; however, for our interest we
can suppose @xmath , where @xmath is the identity matrix. The
nonlinearity @xmath is supposed to be @xmath in @xmath , locally in
@xmath , and Lipshitz in @xmath , uniformly in @xmath , respecting
hypothesis ( 2.2 )-( 2.4 ) and such that for some @xmath , with @xmath ,
it holds

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

The criterion for persistence or extinction is given via a notion of
periodic eigenvalue, that is the unique number @xmath such that there
exists a solution @xmath to the system

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

where @xmath is given by

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

We point out that the existence and uniqueness of @xmath is guaranteed
by Krein-Rutman theory. The long time behaviour result in [ 18 ] is the
following:

###### Theorem 2.2 (Theorem 2.6 in [18]).

Assume @xmath satisfies ( 2.2 )-( 2.4 ) and ( 2.9 ). Then:

1.   If @xmath , persistence occurs for ( 2.8 ).

2.   If @xmath , extinction occurs for ( 2.8 ).

To prove Theorem 2.2 , the authors performed an analysis of @xmath ,
proving that it coincide with the limit of eigenvalues for a sequence of
domains invading @xmath , so that it coincides with the generalised
principal eigenvalue of the system “without the road” ( 2.6 ). Nowadays,
that and many other properties of this eigenvalue can be found as part
of a broader framework in [ 22 ] . In Section 2.2 , we will provide
further comments on it.

Another important fact highlighted both in the series in [ 108 , 107 ,
70 ] and in [ 18 ] is that the presence of multiple small unfavourable
zones gives less chances of survival than one large one, the surface
being equal.

A new difficulty that one may consider while studying ecological
problems is, sadly, the issue of a changing climate. A 1-dimensional
model in this sense was first proposed in [ 15 ] and [ 97 ] , and was
later treated in higher dimension in [ 21 ] . The authors first imagined
that a population lives in a favourable region enclosed into a
disadvantageous environment; due to the climate change, the favourable
zone starts to move in one direction, but keeps the same surface. The
resulting equation is

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

with @xmath a direction in @xmath and @xmath . It was observed that a
solution to ( 2.12 ) in the form of a travelling wave @xmath solves the
equation

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

which is more treatable. The main question is if the population keeps
pace with the shifting climate, that is, if the species is able to
migrate with the same speed of the climate. The answer to this question
is positive if a solution to ( 2.13 ) exists; this depends on the value
of @xmath . We point out that already in [ 21 ] the authors considered
the general case of a possible periodic @xmath .

As mentioned before, another feature worth investigation is the effect
of fast diffusion channels on the survival and the spreading of species.
In fact, the propagation of invasive species as well as epidemics is
influenced by the presence of roads [ 103 , 52 ] . This observations led
Berestycki, Roquejoffre and Rossi to propose a model for ecological
diffusion in the presence of a fast diffusion channel in [ 20 ] , the
so-called road-field model . The field is modelled with the halfplane
@xmath and the line with the @xmath axis; the main idea is to use two
different variables for modelling the density of population along the
line, @xmath , and on the half plane, @xmath . The system reads

  -- -- --
        
  -- -- --

for @xmath , @xmath , @xmath , @xmath positive constants; moreover,
@xmath was supposed to satisfy

  -- -------- --
     @xmath   
  -- -------- --

The three equations describe, respectively, the dynamic on the line, the
dynamic on the half plane and the exchanges of population between the
line and the half plane. On the line, the diffusion is faster than in
@xmath if @xmath . In [ 20 ] , the authors identify the unique positive
stationary solution @xmath and prove persistence of the population.
Moreover, they show that the presence of the line increases the
spreading speed. Another version of the model with a reaction term for
the line was presented by the same authors in [ 19 ] , while many
variation of the models were proposed by other authors: with nonlocal
exchanges in the direction of the road [ 94 , 95 ] , with nonlocal
diffusion [ 14 , 13 ] , and with different geometric settings [ 105 ] .
For a complete list, we refer to [ 112 ] .

The case of heterogeneous media for systems of road-field type has been
so far not much treated, due to its difficulties. A first road-field
model with exchange terms that are periodic in the direction of the road
was proposed in [ 58 ] . There, the authors recovered the results of
persistence and of acceleration on the propagation speed due to the road
known in the homogeneous case; they also studied the spreading of
solution with exponentially decaying initial data and calculated their
speeds.

Recently, Berestycki, Ducasse and Rossi introduced in [ 16 ] a new
generalised principal eigenvalue fitting road-field system for possibly
heterogeneous reaction term; here, we give its definition directly for
the system ( 2.1 ). Calling

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

this eigenvalue is defined as

  -- -- -- --------
           (2.15)
  -- -- -- --------

with @xmath belonging to @xmath . Together with the definition, many
interesting properties and bounds were studied; we will recall some of
them later.

Thanks to that, the same authors were able to investigate the case of a
favourable ecological niche, possibly facing climate change, in [ 17 ] .
It was proven that the sign of @xmath characterises the extinction or
the persistence of the population; moreover, comparing the results with
the ones found for the model without the road, a deleterious effect of
the road on the survival chances is always found when there is no
climate change. On the other hand, if the ecological niche shifts, the
road has in some cases a positive effect on the persistence.

#### 2.1.3 Main results

We are now ready to present the main results of this chapter.

##### The case of a periodic @xmath

Here, we consider the case of a nonlinearity that respects the KPP
hypothesis and is periodic in the direction of the road. Moreover, here
we always consider @xmath .

We begin by the following result on long time behaviour for solutions of
system ( 2.1 ):

###### Theorem 2.3.

Assume @xmath satisfy ( 2.2 )-( 2.5 ), @xmath and let @xmath be as in (
2.15 ). Then the following holds:

1.   if @xmath , then extinction occurs.

2.   if @xmath , then persistence occurs and the positive stationary
    solution @xmath is unique and periodic in @xmath .

Now, we compare the behaviour of solutions to the system ( 2.1 ) with
the ones of system ( 2.6 ). This allows us to highlight the effects of
the fast diffusion channel on the survival chances of the population.
Actually, since solutions of ( 2.6 ) can be extended by refection to the
whole plane, we can make the comparison with equation ( 2.8 ) for @xmath
and @xmath . The comparison is performed thanks to the generalised
principal eigenvalue @xmath for system ( 2.1 ) and the periodic
eigenvalue @xmath , as defined in ( 2.10 ), for the operator @xmath in
dimension 2. We obtain the following:

###### Theorem 2.4.

Assume @xmath respects hypothesis ( 2.2 )-( 2.5 ), @xmath . Then:

1.   if @xmath , then @xmath , that is, if persistence occurs for the
    system “without the road” ( 2.8 ), then it occurs also for system
    “with the road” ( 2.1 ).

2.   if @xmath , then @xmath , that is, if extinction occurs for the
    system “without the road” ( 2.8 ), then it occurs also for system
    “with the road” ( 2.1 ).

Theorem 2.4 says that the road has no negative impact on the survival
chances of the population in the case of a periodic medium depending
only on the variable in the direction of the road. This is surprising if
compared to the results obtained in [ 17 ] (precisely Theorem 1.5, part
(ii) ), where the authors find that the existence of the road is
deleterious in presence of an ecological niche, and even more
counter-intuitive owing the fact that fragmentation of the environment
lessens the survival chances of a population, as shown in [ 18 ] . This
means that, in the case of periodic media, the presence of the fast
diffusion channel does not interfere with the persistence of the
population, which depends only on the environment of a periodicity cell.
As seen in [ 18 ] , where the dependence of persistence on the amplitude
of fragmentation was studied, if the favourable zones are sufficiently
large, the population will eventually spread in all of them; the
presence of the road does not cause loss of favourable environment and
consequently of persistence chances. However, we expect the spreading
speed to be influenced by the presence of the road, as it has been
already proven in the case of homogeneous environment.

We point out that Theorem ( 2.3 ) completes and is in accordance with
the results on long time behaviour found in [ 20 ] for a homogeneous
reaction term, which we can see as a particular case of periodicity,
which respects positive KPP hypothesis (where the positivity is
requested through @xmath ). In [ 20 ] , Theorem 4.1 states the
convergence of any positive solution to the unique positive stationary
solution of the system. Since it is well known that for the homogeneous
case it holds @xmath , the positivity hypothesis gives that @xmath and,
as a consequence of Theorem 2.6 , that the second case in our Theorem
2.3 occurs. If instead we asked for @xmath , then we would be in the
first case of Theorem 2.3 , yielding extinction of the population.

###### Effects of amplitude of heterogeneity.

One may expect that the presence of a road may alter the complex
interaction between more favourable and less favourable zones, in
particular penalising the persistence, since it was shown that
populations prefer a less fragmented environment. However, the road does
not interfere with that; as a consequence, also for environments
presenting fast diffusion channels, some results of the analysis on the
effect of fragmentation performed in [ 18 ] holds.

Take a parameter @xmath and consider system ( 2.1 ) with nonlinearity

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

To highlight the dependence on @xmath , we will call @xmath the
generalised principal eigenvalue defined in ( 2.15 ) with nonlinearity
@xmath . As a direct consequence of Theorem ( 2.4 ) and Theorem 2.12 in
[ 18 ] , we have the following result on the amplitude of heterogeneity:

###### Corollary 2.5.

Assume @xmath is defined as in ( 2.16 ), @xmath satisfies ( 2.2 )-( 2.5
), and @xmath . Then:

1.   if @xmath , or if @xmath and @xmath , then for all @xmath we have
    @xmath .

2.   if @xmath , then @xmath for @xmath small enough; if moreover there
    exists @xmath such that @xmath , then for all @xmath large enough
    @xmath .

This result describes with precision the fact that, to persist, a
species must have a sufficiently large favourable zone available. If the
territory is more advantageous than not, then the population persist. If
however there environment is generally unfavourable, the population
persists only if there are some contiguous advantageous zones large
enough; if instead the advantageous zones are fragmented, even if there
is unlimited favourable territory, the population will encounter
extinction.

##### A climate change setting for a general @xmath

We consider now a general nonlinearity that depends on the spatial
variable in the direction of the road. We stress the fact that we do not
suppose any periodicity, but the case of a periodic @xmath is a
particular case of this setting. Moreover, the following result is done
in the general framework of a possible climate change, so the parameter
@xmath may be different from @xmath .

Comparison between the systems with and without the road, in the general
case, are done through comparison between @xmath and the generalised
principal eigenvalue of system ( 2.6 ), given by

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

for @xmath . With this notation, we have the following:

###### Theorem 2.6.

Assume @xmath as in ( 2.17 ) and @xmath as in ( 2.15 ); then @xmath .

In the special case @xmath , some information on the relations between
@xmath and @xmath was already available in [ 17 ] : Proposition 3.1
yields that @xmath implies @xmath . Thanks to that and Theorem 2.6 , the
following result holds:

###### Corollary 2.7.

If @xmath , we have @xmath if and only if @xmath .

As already pointed out in [ 16 ] , even for @xmath it is not true that
@xmath . In fact, it has been found that @xmath , while playing with
@xmath one can have @xmath as large as desired. However, the fact that
the two eigenvalues have the same sign reveals that they are profoundly
linked.

#### 2.1.4 Organisation of the chapter

In Section 2.2 , we recall and discuss the properties of the eigenvalues
@xmath , @xmath and @xmath already known in the literature. Furthermore,
a periodic eigenvalue for the system ( 2.1 ) will be defined; because of
the presence of the road, the periodicity is present only in the @xmath
direction. As a consequence, it is useful to define an analogous
generalised eigenvalue for the system without the road ( 2.6 ) with
periodicity only in the direction of the road.

In Section 2.3 , one finds the proof of Theorem 2.6 and Theorem 2.4 .
Moreover, the relations between the newly defined generalised periodic
eigenvalues and the known ones are shown.

The last Section 2.4 treats large time behaviour for solutions to ( 2.1
) with @xmath and periodic @xmath ; this includes the proof of Theorem
2.3 .

### 2.2 Generalised principal eigenvalues and their properties

Both road-field models and reaction-diffusion equations in periodic
media have been treated in several papers. In this section, we introduce
some useful objects and recall their properties. All along this section
we will make repeated use of the operators @xmath , @xmath and @xmath ,
that were defined in ( 2.14 ).

#### 2.2.1 Eigenvalues in periodic media

Since @xmath has periodic terms, it is natural to look for
eigenfunctions that have the same property. However, to begin the
discussion on the periodic eigenvalue for the operator @xmath in @xmath
, we consider its counterpart in @xmath . We look for the unique number
@xmath such that there exists a function @xmath solution to the problem

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

In ( 2.18 ), the operator @xmath has been replaced by an operator
working on @xmath , namely the Laplacian has been substituted by a
double derivative. Notice that existence and uniqueness of the solution
to ( 2.18 ), that we call @xmath , is guaranteed by Krein-Rutman theory.

For the operator @xmath , since it has no dependence on the @xmath
variable, we have to introduce a fictive periodicity in order to be able
to use the Krein-Rutman theory. Thus, fix @xmath and consider the
problem in @xmath of finding the value @xmath such that there exists a
solution @xmath to the system

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

Again we can use the Krein-Rutman Theorem to see that there exists a
unique pair @xmath solving ( 2.19 ). Now, with a slight abuse of
notation, we consider the function @xmath as the extension in @xmath of
@xmath solution to ( 2.18 ). We observe that the pair @xmath gives a
solution to ( 2.19 ). Hence, by the uniqueness of the positive
eigenfunction, we get

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

This also implies that neither @xmath nor @xmath depend on the parameter
@xmath that was artificially introduced. From now on, we will use only
@xmath .

The properties of the eigenvalue @xmath were also studied in [ 22 ] ,
where it is called @xmath and defined as

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

In particular, in Proposition 2.3 of [ 22 ] it is stated that the value
found with ( 2.19 ) coincides with the one defined in ( 2.21 ).

#### 2.2.2 Generalised principal eigenvalues for the system with and
without the road and some properties

In this section, we are going to treat eigenvalues that are well defined
also for non periodic reaction functions.

The generalised eigenvalue @xmath for the system ( 2.1 ), that we
defined in ( 2.15 ), was first introduced in [ 16 ] . Together with
this, the authors also proved the interesting property that @xmath
coincides with the limit of principal eigenvalues of the same system
restricted to a sequence of invading domains. They use some half ball
domains defined as follow for @xmath :

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

Then we have the following characterisation for @xmath :

###### Proposition 2.8 (Theorem 1.1 of [16]).

For @xmath , there is a unique @xmath and a unique (up to multiplication
by a positive scalar) positive @xmath that satisfy the eigenvalue
problem

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

We also consider the principal eigenvalue on the truncated domains for
the linear operator @xmath . To do that, for any @xmath we call @xmath
the ball of centre @xmath and radius @xmath . We define @xmath as the
unique real number such that the problem

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

admits a solution @xmath . The existence and uniqueness of such quantity
and its eigenfunction is a well-known result derived via the
Krein-Rutman theory. We also notice that, calling @xmath the ball with
radius @xmath and center @xmath , the pair @xmath is also a solution to
the problem

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

The proof of that is very simple. If @xmath is the unique solution to (
2.25 ), extending @xmath by symmetry in @xmath we get a solution to (
2.24 ). By the uniqueness of the solution to ( 2.24 ), we get @xmath .

Similarly to what happens with @xmath , thanks to the fact @xmath solves
( 2.25 ), we have that the sequence @xmath converges to the value @xmath
, that was defined in ( 2.17 ). This was precisely stated in [ 17 ] as:

###### Proposition 2.9 (Proposition 2.4 of [17]).

We have that

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

Another notion of generalised eigenvalue analysed in [ 22 ] is the
quantity

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

for test functions @xmath . As stated in Proposition 2.2 of [ 22 ] , we
have

  -- -------- --
     @xmath   
  -- -------- --

By that and ( 2.9 ), we have

  -- -------- --
     @xmath   
  -- -------- --

With this notation, we can report the following affirmations deriving
from Theorem 1.7 in [ 22 ] for the case of a periodic reaction function:

###### Theorem 2.10 (Theorem 1.7 in [22]).

Suppose @xmath satisfies ( 2.5 ). The following holds:

1.   It holds that @xmath .

2.   If @xmath is self-adjoint (i.e, if @xmath ), then @xmath .

At last, we recall the following result on the signs of the eigenvalues
for the systems with and without the road:

###### Proposition 2.11 (Proposition 3.1 in [17]).

It holds that

  -- -------- --
     @xmath   
  -- -------- --

This is the result that, in combination with Theorem 2.6 , gives
Corollary 2.7 .

#### 2.2.3 The periodic generalised principal eigenvalue for the
road-field system

We introduce here two new eigenvalues that will be useful in the
following proofs. They are somehow of mixed type, in the sense that they
are periodic in @xmath but not in @xmath ; this derives from the fact
that the domains in which they are defined are periodic in the variable
@xmath and truncated in the variable @xmath . Here, we require @xmath to
be periodic as in hypothesis ( 2.5 ).

Given @xmath , let @xmath be the unique pair solving the eigenvalue
problem

  -- -------- -- --------
     @xmath      (2.28)
  -- -------- -- --------

The existence and uniqueness of the solution to ( 2.28 ) derives once
again from Krein-Rutman theory.

We point out that @xmath is decreasing in @xmath by inclusion of
domains. So, there exists a well defined value, that with a slight abuse
of notation we call @xmath , such that

  -- -------- -- --------
     @xmath      (2.29)
  -- -------- -- --------

Given @xmath , there exists a unique value @xmath such that the problem

  -- -------- -- --------
     @xmath      (2.30)
  -- -------- -- --------

has a solution. The proof of the existence can be derived by modifying
for periodic functions the proof of the existence of @xmath that is
found in the Appendix of [ 16 ] .

Moreover, we define

  -- -------- --
     @xmath   
  -- -------- --

with test functions @xmath .

Then, we have:

###### Proposition 2.12.

Suppose @xmath satisfies ( 2.5 ). We have that

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

Moreover, there exists a couple @xmath of positive functions periodic in
@xmath such that satisfy

  -- -------- -- --------
     @xmath      (2.32)
  -- -------- -- --------

###### Proof.

By inclusion of domains, one has that @xmath is decreasing in @xmath .
Let us call

  -- -------- --
     @xmath   
  -- -------- --

Step 1 . We now want to show that there exists a couple @xmath , with
@xmath and @xmath , periodic in @xmath , that satisfy

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

Fix @xmath . First, for all @xmath consider the periodic eigenfunctions
@xmath related to @xmath . We normalize @xmath so that

  -- -------- --
     @xmath   
  -- -------- --

Then, from the Harnack estimate in Theorem 2.3 of [ 16 ] , there exists
@xmath such that

  -- -------- -- --------
     @xmath      (2.34)
  -- -------- -- --------

where the last inequality comes from the normalization. We can use the
interior estimate for @xmath and get

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath depending on @xmath , @xmath , @xmath , and @xmath . By
that and ( 2.34 ), we get

  -- -------- -- --------
     @xmath      (2.35)
  -- -------- -- --------

for a possibly different @xmath .

For @xmath , in order to have estimates up to the border @xmath of
@xmath , we need to make a construction. Recall that, calling @xmath ,
@xmath solves

  -- -------- --
     @xmath   
  -- -------- --

We call

  -- -------- --
     @xmath   
  -- -------- --

and the conjugate operator

  -- -------- --
     @xmath   
  -- -------- --

Now, we have

  -- -------- --
     @xmath   
  -- -------- --

Next, calling

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

we have that

  -- -------- -- --------
     @xmath      (2.37)
  -- -------- -- --------

Now we define in the open ball @xmath the function

  -- -------- -- --------
     @xmath      (2.38)
  -- -------- -- --------

that is the extension of @xmath by reflection; thanks to the Neumann
condition in ( 2.37 ) and the fact that @xmath , we get that @xmath .
Also, we define the function

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

We also take the operator

  -- -------- -- --------
     @xmath      (2.40)
  -- -------- -- --------

where @xmath is the sign function given by

  -- -------- --
     @xmath   
  -- -------- --

Thanks to the definition ( 2.38 ), ( 2.39 ) and ( 2.40 ), we get that
@xmath is a weak solution to the equation

  -- -------- -- --------
     @xmath      (2.41)
  -- -------- -- --------

Finally, we can apply the interior estimates and get

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath depending on @xmath and the coefficients of the equation
( 2.41 ). But using the definition of @xmath and the fact that @xmath is
controlled by the norm of @xmath , we get, for a possible different
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Using ( 2.35 ) and ( 2.34 ), we finally have

  -- -------- --
     @xmath   
  -- -------- --

Thanks to that and ( 2.35 ), we have that @xmath is uniformly bounded in
@xmath for all @xmath . Hence, up to a diagonal extraction, @xmath
converge weakly in @xmath to some @xmath . By Morrey inequality, the
convergence is strong in @xmath for @xmath . Moreover, @xmath are
periodic in @xmath since all of the @xmath are periodic. Then, taking
the limit of the equations in ( 2.30 ), we obtain that @xmath satisfy (
2.33 ), as wished.

Step 2. We now prove that

  -- -------- -- --------
     @xmath      (2.42)
  -- -------- -- --------

Take @xmath and its associated periodic eigenfunctions couple @xmath
obtained in Step 1. By definition, @xmath is the supremum of the set

  -- -------- -- --------
     @xmath      (2.43)
  -- -------- -- --------

Then, using @xmath as test functions, we obtain that @xmath is in the
set @xmath given in ( 2.43 ). By the fact that @xmath is the supremum of
@xmath , we get ( 2.42 ), as wished.

Step 3 . We show

  -- -------- -- --------
     @xmath      (2.44)
  -- -------- -- --------

Now, take any @xmath and one of its associate couple @xmath . Then, by
inclusion of domains, one gets that for all @xmath it holds

  -- -------- --
     @xmath   
  -- -------- --

Hence, by taking the supremum on the left hand side and the infimum on
the right one, we get ( 2.44 ). By this and ( 2.42 ), equality is
proven. Moreover, defining @xmath , by ( 2.33 ), we have the second
statement of the proposition. ∎

### 2.3 Ordering of the eigenvalues

This section is dedicated to show some inequalities and relations
between the aforementioned eigenvalues.

#### 2.3.1 Proof of Theorem 2.6

We start by proving Theorem 2.6 . We stress that this is done for the
general setting of @xmath possibly non zero and @xmath which may not be
periodic.

###### Proof of Theorem 2.6.

Let us start by proving the first part of the theorem. For all @xmath ,
there exists @xmath and a point @xmath such that @xmath : it is
sufficient to take @xmath and @xmath . We want to prove that

  -- -------- -- --------
     @xmath      (2.45)
  -- -------- -- --------

Suppose by the absurd that ( 2.45 ) is not true. Consider @xmath the
eigenfunction related to @xmath and @xmath the eigenfunction in the
couple @xmath related to @xmath . Since @xmath , and both eigenfunctions
are bounded, there exists

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is a supremum, then there exists @xmath such that @xmath .
Then, @xmath because @xmath and @xmath in @xmath . Calling @xmath , in a
neighbourhood of @xmath we have that

  -- -------- -- --------
     @xmath      (2.46)
  -- -------- -- --------

We know that @xmath and that @xmath in @xmath . Then @xmath is a minimum
for @xmath , so @xmath and @xmath . Thus, the lefthandside of ( 2.46 )
is non positive. But by the absurd hypotesis we have @xmath . This gives

  -- -------- --
     @xmath   
  -- -------- --

which is a contradiction. With that we obtain that ( 2.45 ) is true.

Notice that the eigenvalue @xmath , where @xmath is the ball centred in
@xmath , because @xmath does not depend on @xmath , thus system ( 2.24 )
on @xmath and @xmath are the same. As a consequence, also their
eigenfunctions coincide.

Recall that both @xmath and @xmath are limits of eigenvalues on limited
domains, by ( 2.9 ) and Proposition 2.8 . Now, since for all @xmath
there exists @xmath such that ( 2.45 ) is true, then passing to the
limit we find the required inequality.

∎

#### 2.3.2 Further inequalities between the eigenvalues

In this section, we collect some results on the ordering of periodic and
generalised eigenvalues for both system ( 2.1 ) and eqaution ( 2.8 ).
Here we require @xmath to be periodic as in ( 2.5 ).

This first result is the analogue of Theorem ( 2.10 ) for the system (
2.1 ):

###### Theorem 2.13.

Suppose @xmath respects hypothesis ( 2.5 ). Then:

1.   It holds that @xmath .

2.   If moreover @xmath , then we have @xmath .

###### Proof.

1. By definition, @xmath is the supremum of the set @xmath given in (
2.43 ), while @xmath is the supremum of the set

  -- -------- --
     @xmath   
  -- -------- --

By inclusion of sets, we have the desired inequality.

2. We call

  -- -------- --
     @xmath   
  -- -------- --

For @xmath , we define

  -- -------- --
     @xmath   
  -- -------- --

Now we fix @xmath and we consider @xmath ad its periodic eigenfunctions
@xmath . We consider @xmath to be extended to @xmath in @xmath . This
way we have @xmath .

Then for all @xmath we choose a @xmath function @xmath such that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
  -- -------- -------- --

where @xmath is a fixed constant independent of @xmath . To simplify the
notation later, we call @xmath ; we also have that @xmath and @xmath .
We have that

  -- -------- --
     @xmath   
  -- -------- --

Now we want to show that for a suitable diverging sequence @xmath we
have

  -- -------- -- --------
     @xmath      (2.47)
  -- -------- -- --------

First, let us show a few useful rearrangements of the integrals that
define @xmath . We have that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

by having applied integration by parts on the second line and trivial
computation in the others. Since @xmath and @xmath is supported only in
@xmath , we get

  -- -------- -- --------
     @xmath      (2.48)
  -- -------- -- --------

With similar computations we get

  -- -------- -- --------
     @xmath      (2.49)
  -- -------- -- --------

Then, we also have

  -- -------- -- --------
     @xmath      (2.50)
  -- -------- -- --------

We now recall that @xmath is an eigenfunction for the problem ( 2.30 ).
Thanks to the third equation of ( 2.30 ), the second term in ( 2.49 )
cancel out with the second term in ( 2.50 ). Moreover we can sum the
first term of ( 2.48 ) and the first term of ( 2.50 ) and get

  -- -------- --
     @xmath   
  -- -------- --

Moreover we have that

  -- -------- --
     @xmath   
  -- -------- --

So, if we call

  -- -------- --
     @xmath   
  -- -------- --

we have that

  -- -------- --
     @xmath   
  -- -------- --

Proving ( 2.47 ) is equivalent to show that

  -- -------- -- --------
     @xmath      (2.51)
  -- -------- -- --------

for some diverging sequence @xmath . Suppose by the absurd ( 2.51 ) is
not true. First, by the fact that the derivatives of @xmath and @xmath
are bounded, for some positive constant @xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

By the absurd hypothesis, we have that

  -- -------- -- --------
     @xmath      (2.52)
  -- -------- -- --------

Now let us define for all @xmath the quantity

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath and @xmath are bounded from above, we have that for some
constant @xmath depending on @xmath , @xmath , and @xmath , we have

  -- -------- -- --------
     @xmath      (2.53)
  -- -------- -- --------

For @xmath one has

  -- -------- --
     @xmath   
  -- -------- --

By comparison with ( 2.52 ), we have

  -- -------- --
     @xmath   
  -- -------- --

so for @xmath we have

  -- -------- -- --------
     @xmath      (2.54)
  -- -------- -- --------

Thanks to ( 2.54 ) we perform now a chain of inequalities:

  -- -------- --
     @xmath   
  -- -------- --

from with we derive that @xmath diverges as an exponential, in
contradiction with the inequality in ( 2.53 ). Hence we obtain that (
2.51 ) is true, so ( 2.47 ) is also valid.

By Proposition 4.5 in [ 16 ] , we have that

  -- -------- -- --------
     @xmath      (2.55)
  -- -------- -- --------

Hence by ( 2.55 ) we have that

  -- -------- --
     @xmath   
  -- -------- --

Since for all @xmath there exist @xmath so that ( 2.47 ) holds, we have
moreover that

  -- -------- --
     @xmath   
  -- -------- --

Then, recalling Proposition 2.12 , we get that

  -- -------- --
     @xmath   
  -- -------- --

Since the reverse inequality was already stated in the first part of
this theorem, one has the thesis. ∎

At last, we prove this proposition of the bounds for @xmath .

###### Proposition 2.14.

Suppose @xmath satisfies ( 2.5 ). We have that

  -- -------- --
     @xmath   
  -- -------- --

and if @xmath the equality holds.

###### Proof.

Consider any @xmath and take @xmath and its eigenfunction @xmath solving
( 2.28 ), that is periodic in @xmath . Then take @xmath and its periodic
eigenfunction @xmath , that as we have seen in ( 2.20 ) does not depend
on @xmath , therefore it is limited and has positive infimum, and solves
( 2.19 ). Then, @xmath and @xmath are eigenvalues for the same equation
in two domains with one containing the other; hence, one gets that

  -- -------- -- --------
     @xmath      (2.56)
  -- -------- -- --------

By using ( 2.29 ), from ( 2.56 ) we have

  -- -------- -- --------
     @xmath      (2.57)
  -- -------- -- --------

Given @xmath , we can repeat the same argument for @xmath and @xmath and
get

  -- -------- -- --------
     @xmath      (2.58)
  -- -------- -- --------

By ( 2.29 ) and by ( 2.9 ), we get

  -- -------- --
     @xmath   
  -- -------- --

This and ( 2.57 ) give the first statement of the proposition.

If @xmath , by the second part of Theorem 2.10 we get that @xmath ,
hence we have

  -- -------- --
     @xmath   
  -- -------- --

as wished. ∎

#### 2.3.3 Proof of Theorem 2.4

Owing Theorems 2.3 and 2.2 together with the estimates on the
eigenvalues proved in the last subsection, we are ready to prove Theorem
2.4 .

###### Proof of Theorem 2.4.

By Theorem 2.10 , we have that @xmath . Then, by Corollary 2.7 , if
@xmath then @xmath , and if @xmath then @xmath .

Observe that, when @xmath , choosing @xmath and @xmath , the operator
@xmath defined in ( 2.11 ) coincides with @xmath . Then, the
affirmations on the asymptotic behaviour of the solutions of the system
with and without the road comes from the characterisations in Theorem
2.3 and 2.2 .

∎

### 2.4 Large time behaviour for a periodic medium and @xmath

We start considering the long time behaviour of the solutions. As
already stated in Theorem 2.3 , the two possibilities for a population
evolving through ( 2.1 ) are persistence and extinction. We treat these
two case in separate sections.

Before starting our analysis, we recall a comparison principle first
appeared in [ 20 ] that is fundamental for treating system ( 2.1 ). We
recall that a generalised subsolution (respectively, supersolution) is
the supremum (resp. infimum) of two subsolutions (resp. supersolutions).

###### Proposition 2.15 (Proposition 3.2 of [20]).

Let @xmath and @xmath be respectively a generalised subsolution bounded
from above and a generalised supersolution bounded from below of ( 2.1 )
satisfying @xmath and @xmath at @xmath . Then, either @xmath and @xmath
for all @xmath , or there exists @xmath such that @xmath for @xmath .

The original proof is given for the case of @xmath homogeneous in space;
however, it can be adapted with changes so small that we find it useless
to repeat it.

Proposition 2.15 gives us important informations on the behaviour at
microscopic level. In fact, it asserts that if two pairs of population
densities are “ordered” at an initial time, then the order is preserved
during the evolution according to the equations in ( 2.1 ).

#### 2.4.1 Persistence

The aim of this section is to prove the second part of Theorem 2.3 .
First, we are going to show a Liouville type result, that is Theorem
2.19 , and then we will use that to derive the suited convergence.

We start with some technical lemmas.

###### Lemma 2.16.

Let @xmath be a bounded stationary solution to ( 2.1 ) and let @xmath be
a sequence of points such that @xmath modulo @xmath tends to some @xmath
. Then:

1.   if @xmath is bounded, the sequence of function @xmath defined as

      -- -------- -- --------
         @xmath      (2.59)
      -- -------- -- --------

    converges up to a subsequence to @xmath in @xmath and @xmath is a
    bounded stationary solution to ( 2.1 ).

2.   if @xmath is unbounded, the sequence of function @xmath defined as

      -- -------- -- --------
         @xmath      (2.60)
      -- -------- -- --------

    converges up to a subsequence to @xmath and @xmath in @xmath is a
    bounded stationary solution to the second equation in ( 2.1 ) in
    @xmath .

###### Proof.

Let us call @xmath . For all @xmath , there exists @xmath such that
@xmath .

We start with the case of bounded @xmath . By the periodicity of @xmath
, we have that @xmath defined in ( 2.59 ) is a solution to

  -- -------- --
     @xmath   
  -- -------- --

Fix @xmath and three numbers @xmath ; we use the notation in ( 2.22 )
for the sets @xmath and @xmath for @xmath . By Agmon-Douglis-Nirenberg
estimates (see for example Theorem 9.11 in [ 57 ] ), we have

  -- -------- --
     @xmath   
  -- -------- --

To find the same estimate for the norm of @xmath , we have to make the
same construction used in the proof of Proposition 2.12 to find the
bound for @xmath . In the same way, we get

  -- -------- --
     @xmath   
  -- -------- --

where the constant @xmath , possibly varying in each inequality, depends
on @xmath , @xmath , @xmath , @xmath , @xmath and @xmath . Using the
boundedness of @xmath and @xmath , for a possible different @xmath
depending on @xmath we get

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Then, we apply the general Sobolev inequalities (see [ 45 ] , Theorem 6
in 5.6) and get for some @xmath depending on @xmath , that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Now we can apply Schauder interior estimates for the oblique boundary
condition (see for example Theorem 6.30 in [ 57 ] ) and find that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

So the sequences @xmath and @xmath are bounded locally in space in
@xmath . By compactness we can extract converging subsequences with
limits @xmath and @xmath . Moreover, since by hypothesis @xmath as
@xmath , we have that @xmath is a solution

  -- -------- --
     @xmath   
  -- -------- --

This concludes the proof of the first statement.

Now suppose that @xmath is unbounded and, up to a subsequence, we can
suppose that

  -- -------- -- --------
     @xmath      (2.61)
  -- -------- -- --------

Then, the function defined in ( 2.60 ) solves the equation

  -- -------- --
     @xmath   
  -- -------- --

with the boundary condition @xmath . Fix @xmath and three numbers @xmath
; we denote by @xmath the open ball of @xmath centred in @xmath and with
radius @xmath , and we will consider @xmath . Notice that by ( 2.61 )
there exists @xmath we have that @xmath for all @xmath . Hence, applying
the previous estimates to @xmath for all @xmath , we find that

  -- -------- --
     @xmath   
  -- -------- --

and then that

  -- -------- --
     @xmath   
  -- -------- --

So the sequence @xmath is bounded locally in space in @xmath and by
compactness we can extract converging subsequence with limit @xmath ,
that satisfy

  -- -------- --
     @xmath   
  -- -------- --

which gives the claim.

∎

The second lemma is similar to the first one, but treats a shifting in
time.

###### Lemma 2.17.

Let @xmath be a bounded solution to ( 2.1 ) which is monotone in time
and let @xmath be a diverging sequence. Then, the sequence @xmath
defined by

  -- -------- -- --------
     @xmath      (2.62)
  -- -------- -- --------

converges in @xmath to a couple of functions @xmath which is a
stationary solution to ( 2.1 ).

###### Proof.

We call @xmath . For every fixed @xmath we have that @xmath is an
monotone bounded sequence. Then, we can define a function @xmath as

  -- -------- -- --------
     @xmath      (2.63)
  -- -------- -- --------

and @xmath . Analogously, for all @xmath we can define

  -- -------- -- --------
     @xmath      (2.64)
  -- -------- -- --------

and @xmath .

Fix @xmath , @xmath and three numbers @xmath ; we use the notation in (
2.22 ) for the sets @xmath and @xmath for @xmath . For @xmath an open
subset in @xmath , in this proof we denote the space of function with
one weak derivative in time and two weak derivatives in space by @xmath
. By Agmon-Douglis-Nirenberg estimates we have

  -- -------- --
     @xmath   
  -- -------- --

To find the same estimate for the norm of @xmath , we have to make the
same construction used in the proof of Proposition 2.12 to find the
bound for @xmath . In the same way, we get

  -- -------- --
     @xmath   
  -- -------- --

where the constant @xmath , possibly varying in each inequality, depends
on @xmath , @xmath , @xmath , @xmath , @xmath , @xmath and @xmath .
Then, we apply the general Sobolev inequalities (see [ 45 ] , Theorem 6
in 5.6) and get for some @xmath depending on @xmath , that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Moreover, since for @xmath the functions @xmath and @xmath are just time
translation of the same functions @xmath and @xmath , we also have that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Now we can apply Schauder interior estimates (see for example Theorem
10.1 in Chapter IV of [ 74 ] ) and find that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

So the sequences @xmath and @xmath are bounded locally in space in
@xmath . By compactness we can extract converging subsequences with
limits @xmath and @xmath that satisfy system ( 2.1 ). But as said in (
2.63 ) and ( 2.64 ) the sequences @xmath and @xmath also converge
punctually to @xmath and @xmath , that are stationary functions. Then,
the couple @xmath is a positive bounded stationary solution of system (
2.1 ). ∎

The following lemma gives essentials information on the stationary
solutions, on which the uniqueness result of Theorem 2.19 will rely on.

###### Lemma 2.18.

Suppose that @xmath , @xmath satisfies ( 2.2 )-( 2.5 ) and that @xmath .
Then, every stationary bounded solution @xmath of system ( 2.1 )
respects

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Step 1: sliding in @xmath . If @xmath , thanks to Proposition 2.8 there
exists @xmath such that @xmath . Since @xmath is monotonically
decreasing in @xmath , we can suppose that @xmath . By a slight abuse of
notation, let us call @xmath the eigenfunctions associated with @xmath
extended to 0 in @xmath .

We claim that there exists @xmath such that @xmath is a subsolution for
system ( 2.1 ). In fact, we have that

  -- -------- --
     @xmath   
  -- -------- --

so for @xmath small enough we have that

  -- -------- -- --------
     @xmath      (2.65)
  -- -------- -- --------

Then,

  -- -------- -- --------
     @xmath      (2.66)
  -- -------- -- --------

so @xmath is a subsolution.

Decreasing @xmath if necessary, we have that @xmath because @xmath and
@xmath are strictly positive in all points of the domain while @xmath
has compact support. Now we translate @xmath in the variable @xmath by
multiples of @xmath ; given @xmath , we call

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The couple @xmath is still a subsolution to system ( 2.1 ) because is a
translation of a subsolution by multiple of the periodicity of the
coefficients in the equations. Suppose by the absurd that there exists
@xmath such that @xmath . Since @xmath and @xmath are strictly positive
in all points of respectively @xmath and @xmath , while @xmath and
@xmath have compact support, by decreasing @xmath if necessary, we have
that @xmath and either there exists @xmath such that @xmath or there
exists @xmath such that @xmath . Then, by the Comparison Principle, we
have that @xmath , which is absurd because @xmath and @xmath are
compactly supported. Therefore, we have

  -- -------- -- --------
     @xmath      (2.67)
  -- -------- -- --------

Fix @xmath . Then, let us call

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath and @xmath , we have that @xmath . Then, ( 2.67 ) implies
that

  -- -------- -- --------
     @xmath      (2.68)
  -- -------- -- --------

Step 2: sliding in @xmath . Recall that by Corollary 2.7 we have @xmath
implies @xmath and by Proposition ( 2.12 ) it holds @xmath . By
Proposition 2.14 and by ( 2.29 ) we have that for some @xmath we have
@xmath . Then, let us call @xmath the eigenfunction related to @xmath
extended to 0 outside its support; repeating the classic argument, one
has that for some @xmath we have @xmath extended to 0 outside @xmath is
a subsolution for the second equation in system ( 2.1 ). For all @xmath
, let us now call @xmath . Since @xmath is periodic in the variable
@xmath , we have that @xmath is uniformly bounded. Now take @xmath and
@xmath such that @xmath ; by decreasing @xmath if necessary, we get that
@xmath . Hence, we get

  -- -------- -- --------
     @xmath      (2.69)
  -- -------- -- --------

Now define

  -- -------- --
     @xmath   
  -- -------- --

By ( 2.69 ), we get that @xmath .

We now take @xmath and define

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath : if @xmath it is trivial, otherwise one observe that
@xmath . Also, @xmath ; in fact, that is obvious if @xmath , otherwise
we have that @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Then, since @xmath and therefore @xmath are periodic in @xmath , we have
that

  -- -------- -- --------
     @xmath      (2.70)
  -- -------- -- --------

so @xmath for all @xmath , @xmath and moreover

  -- -------- -- --------
     @xmath      (2.71)
  -- -------- -- --------

Suppose by absurd that @xmath . Then there exists a sequence @xmath and
a sequence @xmath with @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

Up to a subsequence, @xmath converges to some @xmath while @xmath either
converges to some @xmath or goes to infinity.

For all @xmath there exists @xmath and @xmath such that

  -- -------- -- --------
     @xmath      (2.72)
  -- -------- -- --------

Up to a subsequence,

  -- -------- -- --------
     @xmath      (2.73)
  -- -------- -- --------

Define

  -- -------- --
     @xmath   
  -- -------- --

Then, by Lemma 2.16 we have that @xmath converges to some @xmath such
that

  -- -- -- --------
           (2.74)
  -- -- -- --------

By ( 2.70 ), we have

  -- -------- -- --------
     @xmath      (2.75)
  -- -------- -- --------

We notice that if @xmath , since @xmath and ( 2.74 ) holds, by the
maximum principle we get @xmath in @xmath . But since ( 2.75 ) holds,
this is not possible and instead @xmath . Hence, @xmath , so

  -- -------- -- --------
     @xmath      (2.76)
  -- -------- -- --------

We have that @xmath is a subsolution for @xmath in @xmath , since it is
a translation of a subsolution. Moreover, thanks to the periodicity of
@xmath and the definition of @xmath in ( 2.72 ), we have

  -- -------- --
     @xmath   
  -- -------- --

It follows that the sequence @xmath converges to @xmath . Then, @xmath
is a subsolution for the second equation in ( 2.1 ) in @xmath and by (
2.76 ) it holds @xmath . Hence, we can apply the comparison principle to
@xmath and @xmath : since @xmath , then @xmath in all the points of
@xmath . But then by continuity @xmath , which is absurd for ( 2.75 ).
Hence @xmath . From that and ( 2.68 ) we have statement of the lemma. ∎

Finally, we are ready to prove existence and uniqueness of a positive
bounded stationary solution to ( 2.1 ). The existence of such couple of
function is crucial to get the persistence result of Theorem 2.3 .

###### Theorem 2.19.

Suppose that @xmath , @xmath satisfies ( 2.2 )-( 2.5 ) and that @xmath .
Then, the following holds:

1.   There exists a unique positive bounded stationary solution @xmath
    to system ( 2.1 ).

2.   The functions @xmath and @xmath are periodic in the variable @xmath
    of period @xmath .

###### Proof.

Step 1: construction of a subsolution.

Since @xmath , by Theorem 2.13 it holds that @xmath and moreover by
Proposition 2.31 there exists @xmath such that @xmath . Let us call
@xmath the eigenfunction related to @xmath .

We have that

  -- -------- --
     @xmath   
  -- -------- --

so there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Then,

  -- -------- -- --------
     @xmath      (2.77)
  -- -------- -- --------

so @xmath is a subsolution to system ( 2.1 ).

Thanks to Corollary 2.7 , @xmath implies @xmath ; then Proposition 2.12
implies that @xmath . By ( 2.20 ), also @xmath .

Consider the periodic positive eigenfunction @xmath related to @xmath .
With a slight abuse of notation, we can extend @xmath in all @xmath by
considering constant with respect to the variable @xmath . Repeating the
same arguments as before, we can prove that for some @xmath the function
@xmath is a subsolution for the second equation of system ( 2.1 ) in
@xmath .

Consider @xmath . We have that @xmath is limited, therefore there exists
@xmath such that

  -- -------- -- --------
     @xmath      (2.78)
  -- -------- -- --------

Then, let us define the functions

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

By ( 2.78 ), for @xmath it holds that @xmath . Hence, we get that @xmath
is a subsolution for the first and third equation of ( 2.1 ). Moreover,
since @xmath and @xmath are both subsolution to the second equation to (
2.1 ), so the maximum between them is a generalised subsolution. Thanks
to that, we can conclude that @xmath is a generalised subsolution for
the system ( 2.1 ).

Since @xmath and @xmath are periodic in @xmath and independent of @xmath
, we get

  -- -------- --
     @xmath   
  -- -------- --

So, @xmath is a generalised subsolution for the system ( 2.1 ), with
positive infimum, and by the periodicity of @xmath , @xmath and @xmath ,
it is periodic in @xmath with period @xmath .

Step 2: construction of a stationary solution.

Take the generalised subsolution @xmath . We want to show that the
solution @xmath having @xmath as initial datum is increasing in time and
converge to a stationary solution.

By the fact that @xmath is a subsolution, at we have @xmath for all
@xmath . Hence, for all @xmath , let us consider the solution @xmath
stating at @xmath from the initial datum @xmath . Then, at @xmath we
have that @xmath . By the comparison principle 2.15 , we have that for
all @xmath it holds that @xmath . By the arbitrariness of @xmath , we
get that @xmath is increasing in time.

Moreover, consider

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the threshold value defined in ( 2.3 ). One immediatly
checks that @xmath is a supersolution for the system ( 2.1 ). Also, we
have that @xmath , so by the comparison principle 2.15 it holds that

  -- -------- --
     @xmath   
  -- -------- --

Hence, @xmath is limited.

Now consider an increasing diverging sequence @xmath . Then, define

  -- -------- --
     @xmath   
  -- -------- --

that is a sequence of functions. By Lemma 2.17 , @xmath converge in
@xmath to a stationary bounded solution to ( 2.1 ), that we call @xmath
. We point out that @xmath since

  -- -------- --
     @xmath   
  -- -------- --

Moreover, both functions are periodic of period @xmath in the variable
@xmath since the initial datum is.

Step 3: uniqueness.

Suppose that there exists another positive bounded stationary solution
@xmath to ( 2.1 ). Then, define

  -- -------- --
     @xmath   
  -- -------- --

Since by Lemma 2.18 the functions @xmath and @xmath have positive
infimum and since @xmath and @xmath are bounded, we have that @xmath .

We claim that

  -- -------- -- --------
     @xmath      (2.79)
  -- -------- -- --------

By the definition of @xmath , one of the following must hold: there
exists

  -- -------- -- --------
     @xmath      (2.80)
  -- -------- -- --------

  -- -- -- --------
           (2.81)
  -- -- -- --------

There exists a sequence @xmath such that

  -- -------- -- --------
     @xmath      (2.82)
  -- -------- -- --------

Then, up to extraction of a converging subsequence, we have that there
exists @xmath such that @xmath . One can see that the sequence of
couples

  -- -------- --
     @xmath   
  -- -------- --

is a stationary solution for ( 2.1 ) with reaction function @xmath . By
Lemma 2.16 , up to a subsequence, @xmath converges in @xmath to some
@xmath , which is a stationary solution of ( 2.1 ) with reaction
function @xmath . We also notice that, thanks to the periodicity of
@xmath and @xmath , @xmath is also a stationary solution of ( 2.1 ) with
reaction function @xmath . Define the function

  -- -------- -- --------
     @xmath      (2.83)
  -- -------- -- --------

and notice that @xmath , @xmath .

Now suppose that ( 2.80 ) holds. We have that

  -- -------- --
     @xmath   
  -- -------- --

Moreover, @xmath is a solution to the equation

  -- -------- --
     @xmath   
  -- -------- --

By the maximum principle, we have that since @xmath attains its minimum
in the interior of the domain then @xmath . Then, one would have @xmath
and by the comparison principle 2.15 we have @xmath . Subtracting the
second equation of system ( 2.1 ) for @xmath from the one for @xmath we
get

  -- -------- -- --------
     @xmath      (2.84)
  -- -------- -- --------

If by the absurd @xmath , by the KPP hypothesis ( 2.4 ) we have @xmath
and the right hand side of ( 2.84 ) has a sign, that is absurd since the
left hand side is 0. We can conclude that if we are in the case of (
2.80 ), then ( 2.79 ) holds.

Suppose instead that ( 2.81 ) is true. If @xmath is bounded, we define
@xmath . Then,

  -- -------- -- --------
     @xmath      (2.85)
  -- -------- -- --------

If by the absurd @xmath , then by the Fisher-KPP hypothesis ( 2.4 ) we
have

  -- -------- -- --------
     @xmath      (2.86)
  -- -------- -- --------

Since @xmath is locally Lipschitz continuous in the second variable, one
infers from ( 2.86 ) that there exists a bounded function @xmath such
that

  -- -------- -- --------
     @xmath      (2.87)
  -- -------- -- --------

Since that, @xmath and by ( 2.85 ) @xmath , if @xmath we apply the
strong maximum principle and we have @xmath . If @xmath , we point out
that by the fact that @xmath and @xmath are solution to ( 2.1 ) it holds

  -- -------- --
     @xmath   
  -- -------- --

By that, the inequality in ( 2.87 ), @xmath , @xmath , we can apply
Hopf’s lemma and get again @xmath . Then for both @xmath and @xmath ,
@xmath and ( 2.84 ) holds, but we have already saw that this is absurd.
So, in the case of ( 2.81 ), if @xmath is bounded, ( 2.79 ) is true.

At last, if @xmath is unbounded, we define

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

By Lemma 2.17 , up to subsequences, @xmath and @xmath converge in @xmath
to some functions @xmath and @xmath solving

  -- -------- --
     @xmath   
  -- -------- --

Moreover, if we suppose @xmath , by the Fisher-KPP hypothesis ( 2.4 ) we
have that

  -- -------- --
     @xmath   
  -- -------- --

and consequently, calling @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

Once again using the local Lipschitz boundedness of @xmath in the second
variable, for some bounded function @xmath we have that

  -- -------- -- --------
     @xmath      (2.88)
  -- -------- -- --------

Also, we have that

  -- -------- --
     @xmath   
  -- -------- --

Since that, @xmath and ( 2.88 ), we can apply the strong maximum
principle and we have @xmath in @xmath . Then, @xmath and

  -- -------- -- --------
     @xmath      (2.89)
  -- -------- -- --------

which is absurd. Since this was the last case to rule out, we can
conclude that ( 2.79 ) holds.

From ( 2.79 ), we have that

  -- -------- -- --------
     @xmath      (2.90)
  -- -------- -- --------

Now, we can repeat all the argument exchanging the role of @xmath and
@xmath . We find

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

By that and ( 2.90 ), we have that @xmath . Hence, the uniqueness is
proven. ∎

Now we are ready to give a result on the persistence of the population.

###### Proof of Theorem 2.3, part 1.

Since @xmath , by Proposition ( 2.8 ), we have that there exists @xmath
such that @xmath . Let us consider @xmath the eigenfunctions related to
@xmath ; then, with the argument already used in the proof of Lemma 2.18
(precisely, in ( 2.65 ) and ( 2.66 )), there exists a value @xmath such
that @xmath is a subsolution to ( 2.1 ) in @xmath . Observe also that
@xmath for @xmath and @xmath for @xmath . Then, we can extend @xmath and
@xmath outside respectively @xmath and @xmath , obtaining the
generalised subsolution @xmath .

Let us consider the solution @xmath issued from @xmath . Then, by the
strong parabolic principle we have that

  -- -------- -- --------
     @xmath      (2.91)
  -- -------- -- --------

Recall that @xmath is the unique stationary solution of ( 2.1 ), and
that by Lemma ( 2.18 ) we have

  -- -------- -- --------
     @xmath      (2.92)
  -- -------- -- --------

By that and ( 2.91 ), we have that

  -- -------- --
     @xmath   
  -- -------- --

Without loss of generality, we can suppose

  -- -------- -- --------
     @xmath      (2.93)
  -- -------- -- --------

and thus by ( 2.91 ), ( 2.92 ), and ( 2.93 ), we have

  -- -------- -- --------
     @xmath      (2.94)
  -- -------- -- --------

Now, consider the solution @xmath issued from @xmath . We point out
that, by the comparison principle, for all @xmath we have

  -- -------- -- --------
     @xmath      (2.95)
  -- -------- -- --------

By the standard argument already used in the proof of Theorem 2.19 , we
have that @xmath is increasing in time and by Lemma 2.17 it converges in
@xmath to a stationary function @xmath as @xmath tends to infinity.
Since @xmath is increasing in time and @xmath , by the strong maximum
principle we have @xmath . By ( 2.94 ), we also have

  -- -------- --
     @xmath   
  -- -------- --

Then, by the uniqueness of the bounded positive stationary solution
proved in Theorem 2.19 , we have @xmath .

Next, take

  -- -------- -- --------
     @xmath      (2.96)
  -- -------- -- --------

where @xmath is the threshold value defined in ( 2.3 ). Making use of
the hypothesis ( 2.3 ) on @xmath , one easily check that @xmath is a
supersolution for ( 2.1 ). Let us call @xmath the solution to ( 2.1 )
issued from @xmath . By definition, @xmath , hence by the comparison
principle for all @xmath we have

  -- -------- -- --------
     @xmath      (2.97)
  -- -------- -- --------

Repeating the argument used in the proof of Theorem 2.19 , we observe
that @xmath is decreasing in time and by Lemma 2.17 it converges in
@xmath to a stationary function @xmath as @xmath tends to infinity. We
have @xmath , so the stationary solution is bounded. Moreover, since by
the definition of @xmath in ( 2.96 ) we have @xmath , by the comparison
principle 2.15 we get

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is a bounded positive stationary solution of ( 2.1 ), by
Theorem 2.19 we have that @xmath .

By the comparison principle 2.15 and by ( 2.95 ) and ( 2.97 ), for all
@xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Since both @xmath and @xmath converge to @xmath locally as @xmath tends
to infinity, by the sandwich theorem we have that @xmath also does. This
is precisely the statement that we wanted to prove. ∎

#### 2.4.2 Extinction

The first step to prove extinction is to show that there is no positive
bounded stationary solution to system ( 2.1 ), that is, the only bounded
stationary solution is @xmath .

###### Lemma 2.20.

Suppose @xmath and @xmath satisfy ( 2.2 )-( 2.5 ). If @xmath , then
there is no positive bounded stationary solution to system ( 2.1 ).

###### Proof.

Step 1: construction of a supersolution. Observe that in this case,
since @xmath , by Theorem 2.13 it holds @xmath . We take the couple of
eigenfunctions @xmath related to @xmath as prescribed by Proposition
2.12 ; recall that @xmath are periodic in @xmath . Suppose @xmath is a
positive bounded stationary solution to ( 2.1 ). Then, there exists
@xmath such that

  -- -------- -- --------
     @xmath      (2.98)
  -- -------- -- --------

We now choose a smooth function @xmath such that @xmath for @xmath ,
@xmath for @xmath .

By ( 2.20 ) and Theorem 2.10 , we have @xmath . By that, Theorem 2.7 and
the fact that @xmath , we get @xmath . We call @xmath the eigenfunction
related to @xmath and, with a slight abuse of notation, we extend it to
@xmath by considering it constant with respect to the variable @xmath .
Take @xmath to be fixed after, and define

  -- -------- --
     @xmath   
  -- -------- --

Then, it holds that

  -- -------- -- --------
     @xmath      (2.99)
  -- -------- -- --------

Using the KPP hypothesis ( 2.4 ) and the boundedness of @xmath , for
@xmath small enough we have

  -- -------- --
     @xmath   
  -- -------- --

By that, ( 2.99 ) and the non negativity of @xmath and @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

This means that @xmath is a supersolution for the second equation of (
2.1 ).

Since by definition for @xmath we have @xmath , it holds that

  -- -------- -- ---------
     @xmath      (2.100)
  -- -------- -- ---------

By the fact that @xmath , it is easy to check that @xmath is a
supersolution for the first and third equation in ( 2.1 ). By ( 2.100 ),
the same holds for @xmath . This, together with ( 2.99 ), gives that
@xmath is a supersolution to ( 2.1 ).

Step 2: construction of a bounded supersolution Now we distinguish two
cases. If @xmath is bounded, then we take

  -- -------- -- ---------
     @xmath      (2.101)
  -- -------- -- ---------

Otherwise, we proceed as follows. Since in this other case @xmath is
unbounded, and since it is periodic in @xmath , this means there exists
a sequence @xmath such that

  -- -------- -- ---------
     @xmath      (2.102)
  -- -------- -- ---------

Now, consider

  -- -------- -- ---------
     @xmath      (2.103)
  -- -------- -- ---------

where @xmath is the quantity defined in ( 2.3 ). Take the set @xmath and
the constant @xmath of the Harnack inequality (see Theorem 5 in Chapter
6.4 of [ 45 ] ) on the set @xmath for the operator @xmath . Then, by (
2.102 ), for some @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Then by using that and Harnack inequality on @xmath in the set @xmath ,
we get

  -- -------- --
     @xmath   
  -- -------- --

Then, using the periodicity of @xmath , we get

  -- -------- -- ---------
     @xmath      (2.104)
  -- -------- -- ---------

Now, define

  -- -------- -- ---------
     @xmath      (2.105)
  -- -------- -- ---------

Also, we define

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ---------
     @xmath      (2.106)
  -- -------- -- ---------

By the definition of @xmath in ( 2.103 ), one readily checks that @xmath
is a supersolution for system ( 2.1 ) and that

  -- -------- -- ---------
     @xmath      (2.107)
  -- -------- -- ---------

We point out that by the definition of @xmath , ( 2.104 ) and ( 2.107 ),
for any @xmath subsolution to system ( 2.1 ), we will be able to apply
the generalised comparison principle, Proposition 3.3 appeared in [ 20 ]
. Moreover, @xmath is bounded from above by @xmath .

By the fact that @xmath is a couple of generalised periodic
eigenfunctions to ( 2.32 ), by the strong maximum principle we have that

  -- -------- -- ---------
     @xmath      (2.108)
  -- -------- -- ---------

Step 3: comparison with the stationary solution. Next, define

  -- -------- --
     @xmath   
  -- -------- --

Since by ( 2.108 ) we have that @xmath and @xmath are bounded away from
@xmath , and since @xmath is bounded by hypothesis, we get that @xmath .
By ( 2.98 ), we have that

  -- -------- -- ---------
     @xmath      (2.109)
  -- -------- -- ---------

Then, either

  -- -- -- ---------
           (2.110)
  -- -- -- ---------

or

  -- -- -- ---------
           (2.111)
  -- -- -- ---------

As usual, for all @xmath we take @xmath such that @xmath . Up to a
subsequence, @xmath is convergent and we call

  -- -------- --
     @xmath   
  -- -------- --

Step 4: @xmath is bounded . If @xmath is bounded, consider a converging
subsequence and call @xmath .

We define

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 2.16 , @xmath converges in @xmath to some @xmath such that
@xmath solves ( 2.1 ). Define the functions

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

If we are in the case of ( 2.110 ), then by the periodicity of @xmath we
get

  -- -------- --
     @xmath   
  -- -------- --

Moreover, by the definition of @xmath , we have that @xmath . Also,
@xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

Then, the strong maximum principle yields that, since @xmath attains its
minimum at @xmath , then @xmath . Then, by the comparison principle 3.3
in [ 20 ] we have that @xmath , hence

  -- -------- -- ---------
     @xmath      (2.112)
  -- -------- -- ---------

By ( 2.109 ), we have that @xmath . Hence, by the Fischer-KPP hypothesis
( 2.4 ), we have that

  -- -------- -- ---------
     @xmath      (2.113)
  -- -------- -- ---------

Hence, again by the fact that @xmath , we have @xmath ; by that and by (
2.113 ), it holds

  -- -------- -- ---------
     @xmath      (2.114)
  -- -------- -- ---------

But this is in contradiction with ( 2.112 ), hence this case cannot be
possible.

If instead ( 2.111 ) holds, we get that

  -- -------- -- ---------
     @xmath      (2.115)
  -- -------- -- ---------

By the definition of @xmath we also have that @xmath . Moreover, we get
that

  -- -------- --
     @xmath   
  -- -------- --

using the fact that @xmath is a supersolution, @xmath is a solution, and
( 2.113 ). Since @xmath is Lipschitz in the second variable, uniformly
with respect to the first one, there exists some function @xmath such
that

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , using the strong maximum principle and owing ( 2.115 ), we
have that @xmath . If instead @xmath , recall that it also holds

  -- -------- --
     @xmath   
  -- -------- --

Hence, in @xmath , we get that @xmath . By Hopf’s lemma, we get again
that @xmath .

But @xmath leads again to ( 2.112 ) and ( 2.114 ), giving an absurd,
hence also this case is not possible.

Step 5: @xmath is unbounded . We are left with the case of @xmath
unbounded. Up to a subsequence, we can suppose that @xmath is
increasing. We define

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 2.16 we have that, up to a subsequence, @xmath converges in
@xmath to some function @xmath such that @xmath is a solution to the
second equation in ( 2.1 ) in @xmath .

Now we have two cases depending on how @xmath was constructed. If @xmath
is bounded, we have defined the supersolution as in ( 2.101 ). Then, by
defining

  -- -------- --
     @xmath   
  -- -------- --

and applying Lemma 2.16 , we have that @xmath converges locally
uniformly to a bounded function @xmath such that @xmath satisfies

  -- -------- -- ---------
     @xmath      (2.116)
  -- -------- -- ---------

In this case, we define

  -- -------- --
     @xmath   
  -- -------- --

We point out that @xmath is a periodic supersolution of the second
equation in ( 2.1 ) by ( 2.116 ) and ( 2.99 ).

If instead @xmath is unbounded, by ( 2.106 ) for @xmath we have @xmath .
In this case, we choose

  -- -------- --
     @xmath   
  -- -------- --

By the definition of @xmath in ( 2.103 ), we have that @xmath is also a
supersolution to ( 2.1 ).

We call @xmath . Hence, @xmath and

  -- -------- -- ---------
     @xmath      (2.117)
  -- -------- -- ---------

Notice than that, since ( 2.109 ) holds, from the Fisher-KPP hypothesis
on @xmath ( 2.4 ), we get

  -- -------- --
     @xmath   
  -- -------- --

Using that, the fact that @xmath is a supersolution, and the fact that
@xmath is a solution, we obtain

  -- -------- -- ---------
     @xmath      (2.118)
  -- -------- -- ---------

Since @xmath is Lipschitz in the second variable, uniformly with respect
to the first one, there exists some function @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Using the strong maximum principle for the case of positive functions,
since ( 2.117 ) holds, we have that @xmath . As a consequence, from (
2.118 ) we have

  -- -------- --
     @xmath   
  -- -------- --

but it also holds that @xmath , hence we have an absurd.

Having ruled out all the possible cases, we can conclude that there
exists no bounded positive stationary solution @xmath to ( 2.1 ). ∎

At last, we are ready to prove the first part of Theorem 2.3 .

###### Proof of Theorem 2.3, part 1.

Define

  -- -------- --
     @xmath   
  -- -------- --

It is easy to check that @xmath is a supersolution for ( 2.1 ). Then
take @xmath to be the solution to ( 2.1 ) with initial datum @xmath .
Notice that by the comparison principle

  -- -------- -- ---------
     @xmath      (2.119)
  -- -------- -- ---------

Since @xmath is a supersolution, we have that

  -- -------- -- ---------
     @xmath      (2.120)
  -- -------- -- ---------

Consider @xmath and call @xmath the solution staring with initial datum
@xmath at @xmath . By ( 2.120 ) we have that @xmath , hence by the
comparison principle ( 2.15 ) we have @xmath . By the arbitrariness of
@xmath , we get that @xmath is decreasing in @xmath .

By Lemma 2.17 , @xmath converges locally uniformly to a stationary
solution @xmath . But by Lemma 2.20 , the only stationary solution is
@xmath . By that and ( 2.119 ), we have that @xmath converges locally
uniformly to @xmath as @xmath goes to infinity.

Moreover, since @xmath is constant in @xmath , and ( 2.1 ) is periodic
in x, @xmath is periodic in @xmath . Hence, the convergence is uniform
in @xmath .

Now suppose by the absurd that the convergence is not uniform in @xmath
; hence there exists some @xmath such that for infinitely many @xmath ,
with @xmath an increasing sequence, and @xmath , it holds

  -- -------- -- ---------
     @xmath      (2.121)
  -- -------- -- ---------

Since @xmath is periodic in @xmath , without loss of generality we can
suppose @xmath and that up to a subsequence @xmath converges to some
@xmath . If @xmath were bounded, by ( 2.121 ) the local convergence to
@xmath would be contradicted; hence @xmath is unbounded.

Then, define the sequence of functions

  -- -------- --
     @xmath   
  -- -------- --

By ( 2.121 ), we have that

  -- -------- -- ---------
     @xmath      (2.122)
  -- -------- -- ---------

Also, since @xmath is bounded, by arguments similar to the ones used in
Lemma 2.16 and Lemma 2.17 one can prove that, up to a subsequence,
@xmath converges in @xmath to a function @xmath that solves

  -- -------- -- ---------
     @xmath      (2.123)
  -- -------- -- ---------

Also by ( 2.122 ), we have that

  -- -------- -- ---------
     @xmath      (2.124)
  -- -------- -- ---------

Recall that by the fact that @xmath , Corollary 2.7 and Theorem 2.10 ,
@xmath . Then by Theorem 2.2 we have that every solution to ( 2.123 )
converges uniformly to @xmath . But this is in contradiction with (
2.124 ), hence we have an absurd and we must refuse the existence such
positive @xmath . So, the convergence of @xmath to @xmath is uniform in
space. As a consequence, the convergence of @xmath to @xmath is uniform
in space. ∎

## Chapter 3 Civil Wars: A New Lotka-Volterra Competitive System and
Analysis of Winning Strategies

We introduce a new model in population dynamics that describes two
species sharing the same environmental resources in a situation of open
hostility. Our basic assumption is that one of the populations
deliberately seek for hostility through ”targeted attacks”. Hence, the
interaction among these populations is described not in terms of random
encounters but via the strategic decisions of one population that can
attack the other according to different levels of aggressiveness.

One of the features that distinguishes this model from usual competitive
systems is that it allows one of the population to go extinct in finite
time . This leads to a non-variational model for the two populations at
war, taking into account structural parameters such as the relative fit
of the two populations with respect to the available resources and the
effectiveness of the attack strikes of the aggressive population.

The analysis that we perform is rigorous and focuses on the dynamical
properties of the system, by detecting and describing all the possible
equilibria and their basins of attraction.

Moreover, we will analyze the strategies that may lead to the victory of
the aggressive population, i.e. the choices of the aggressiveness
parameter, in dependence of the structural constants of the system and
possibly varying in time in order to optimize the efficacy of the
attacks, which take to the extinction in finite time of the defensive
population.

The model that we present is flexible enough to also include commercial
competition models of companies using aggressive policies against the
competitors (such as misleading advertising, or releasing computer
viruses to set rival companies out of the market).

This chapter corresponds to the paper [ 3 ] in collaboration with Serena
Dipierro, Luca Rossi and Enrico Valdinoci.

### 3.1 Introduction

Among the several models dealing with the dynamics of biological
systems, the case of populations engaging into a mutual conflict seems
to be unexplored. This chapter aims at laying the foundations of a new
model describing two populations competing for the same resource with
one aggressive population which may attack the other: concretely, one
may think of a situation in which two populations live together in the
same territory and share the same environmental resources, till one
population wants to prevail and try to kill the other. We consider this
situation as a “civil war”, since the two populations share land and
resources; the two populations may be equally fit to the environment
(and, in this sense, they are “indistinguishable”, up to the aggressive
attitude of one of the populations), or they can have a different
compatibility to the resources (in which case one may think that the
conflict could be motivated by the different accessibility to
environmental resources).

Given the lack of reliable data related to civil wars, a foundation of a
solid mathematical theory for this type of conflicts may only leverage
on the deduction of the model from first principles: we follow this
approach to obtain the description of the problem in terms of a system
of two ordinary differential equations, each describing the evolution in
time of the density of one of the two populations.

The method of analysis that we adopt is a combination of techniques from
different fields, including ordinary differential equations, dynamical
systems and optimal control.

This viewpoint will allow us to rigorously investigate the model, with a
special focus on a number of mathematical features of concrete interest,
such as the possible extinction of one of the two populations and the
analysis of the strategies that lead to the victory of the aggressive
population.

In particular, we will analyze the dynamics of the system ,
characterizing the equilibria and their features (including possible
basins of attraction) in terms of the different parameters of the model
(such as relative fitness to the environment, aggressiveness and
effectiveness of strikes). Also, we will study the initial
configurations which may lead to the victory of the aggressive
population, also taking into account different possible strategies to
achieve the victory: roughly speaking, we suppose that the aggressive
population may adjust the parameter describing the aggressiveness in
order to either dim or exacerbate the conflict with the aim of
destroying the second population (of course, the war has a cost in terms
of life for both the populations, hence the aggressive population must
select the appropriate strategy in terms of the structural parameters of
the system). We will show that the initial data allowing the victory of
the aggressive population does not exhaust the all space, namely there
exists initial configurations for which the aggressive population cannot
make the other extinct , regardless the strategy adopted during the
conflict.

Furthermore, for identical populations with the same fit to the
environment the constant strategies suffices for the aggressive
population to possibly achieve the victory: namely, if an initial
configuration admits a piecewise continuous in time strategy that leads
to the victory of the aggressive population, then it also admits a
constant in time strategy that reaches the same objective (and of
course, for the aggressive population, the possibility of focusing only
on constant strategies would entail concrete practical advantages).

Conversely, for populations with different fit to the environment, the
constant strategies do not exhaust all the winning strategies : that is,
in this case, there are initial conditions which allow the victory of
the aggressive population only under the exploitation of a strategy that
is not constant in time.

In any case, we will also prove that strategies with at most one jump
discontinuity are sufficient for the aggressive population: namely,
independently from the relative fit to the environment, if an initial
condition allows the aggressive population to reach the victory through
a piecewise continuous in time strategy, then the same goal can be
reached using a “bang-bang” strategy with at most one jump.

We will also discuss the winning strategies that minimize the duration
of the war : in this case, we will show that jump discontinuous
strategies may be not sufficient and interpolating arcs have to be taken
into account.

We now describe in further detail our model of conflict between the two
populations and the attack strategies pursued by the aggressive
population. Our idea is to modify the Lotka-Volterra competitive system
for two populations with density @xmath and @xmath , adding to the usual
competition for resources the fact that both populations suffer some
losses as an outcome of the attacks. The key point in our analysis is
that the clashes do not depend on the chance of meeting of the two
populations, given by the quantity @xmath , as it happens in many other
works in the literature (starting from the publications of Lotka and
Volterra, [ 78 ] and [ 121 ] ), but they are sought by the first
population and depend only on the size @xmath of the first population
and on its level of aggressiveness @xmath . The resulting model is

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath , @xmath and @xmath are nonnegative real numbers. Here, the
coefficient @xmath models the fitness of the second population with
respect of the first one when resources are abundant for both; it is
linked with the exponential growth rate of the two species. The
parameter @xmath here stands for the quotient of endured per inflicted
damages for the first population. Deeper justifications to the model (
3.1 ) will be given in Subsection 3.1.1 .

Notice that the size of the second population @xmath may become negative
in finite time while the first population is still alive. The situation
where @xmath and @xmath represents the extinction of the second
population and the victory of the first one.

To describe our results, for communication convenience (and in spite of
our personal fully pacifist believes) we take the perspective of the
first population, that is, the aggressive one; the objective of this
population is to win the war, and, to achieve that, it can influence the
system by tuning the parameter @xmath .

From now on, we may refer to the parameter @xmath as the strategy , that
may also depend on time, and we will say that it is winning if it leads
to victory of the first population.

The main problems that we deal with in this chapter are:

1.  The characterization of the initial conditions for which there
    exists a winning strategy .

2.  The success of the constant strategies , compared to all possible
    strategies.

3.  The construction of a winning strategy for a given initial datum.

4.  The existence of a single winning strategy independently of the
    initial datum .

We discuss all these topics in Subsection 3.1.4 , presenting concrete
answers to each of these problems.

Also, since to our knowledge this is the first time that system ( 3.1 )
is considered, in Subsections 3.1.2 and 3.1.3 we will discuss the
dynamics and some interesting results about the dependence of the basins
of attraction on the other parameters.

It would also be extremely interesting to add the space component to our
model, by considering a system of reaction-diffusion equations. This
will be the subject of a further work.

#### 3.1.1 Motivations and derivation of the model

The classic Lotka-Volterra equations were first introduced for modelling
population dynamics between animals [ 121 ] and then used to model other
phenomena involving competition, for example in technology substitution
[ 85 ] . The competitive Lotka-Volterra system concerns the sizes @xmath
and @xmath of two species competing for the same resources. The system
that the couple @xmath solves is

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

where @xmath , @xmath , @xmath , @xmath , @xmath , @xmath and @xmath are
nonnegative real numbers.

Here, the coefficients @xmath and @xmath represent the competition
between individuals of different species, and indeed they appear
multiplied by the term @xmath , which represents a probability of
meeting.

The coefficient @xmath is the exponential growth rate of the @xmath th
population, that is, the reproduction rate that is observed when the
resources are abundant. The parameters @xmath are called carrying
capacity and represent the number of individuals of the @xmath th
population that can be fed with the resources of the territory, that are
quantified by @xmath . It is however usual to rescale the system in
order to reduce the number of parameters. In general, @xmath and @xmath
are rescaled so that they vary in the interval @xmath , thus describing
densities of populations.

The behavior of the system depends substantially on the values of @xmath
and @xmath with respect to the threshold given by the value @xmath , see
e.g. [ 12 ] : if @xmath , then the first species @xmath has an advantage
over the second one @xmath and will eventually prevail; if @xmath and
@xmath are both strictly above or below the threshold, then the first
population that penetrates the environment (that is, the one that has a
greater size at the initial time) will persist while the other will
extinguish.

Some modification of the Lotka-Volterra model were made in stochastic
analysis by adding a noise term of the form @xmath in the @xmath th
equation, finding some interesting phenomena of phase transition, see
e.g. [ 62 ] .

The ODE system in ( 3.2 ) is of course the cornerstone to study the case
of two competitive populations that diffuse in space. Many different
types of diffusion have been compared and one can find a huge literature
on the topic, see [ 87 , 37 , 82 ] for some examples and [ 86 ] for a
more general overview. We point out that other dynamic systems
presenting finite time extinction of one or more species have been
generalised for heterogeneous environments, see for example the model in
[ 53 ] for the predator-prey behaviour of cats and birds, that has been
thereafter widely studied.

In this chapter, we will focus not only on basic competition for
resources , but also on situations of open hostility . In social
sciences, war models are in general little studied; indeed, the
collection of data up to modern times is hard for the lack of reliable
sources. Also, there is still much discussion about what factors are
involved and how to quantify them: in general, the outcome of a war does
not only depend on the availability of resources, but also on more
subtle factors as the commitment of the population and the knowledge of
the battlefield, see e.g. [ 114 ] . Instead, the causes of war were
investigated by the statistician L.F. Richardson, who proposed some
models for predicting the beginning of a conflict, see [ 102 ] .

In addition to the human populations, behavior of hostility between
groups of the same species has been observed in chimpanzee. Other
species with complex social behaviors are able to coordinate attacks
against groups of different species: ants versus termites, agouti versus
snakes, small birds versus hawk and owls, see e.g. [ 116 ] .

The model that we present here is clearly a simplification of reality.
Nevertheless, we tried to capture some important features of conflicts
between rational and strategic populations, introducing in the
mathematical modeling the new idea that a conflict may be sought and the
parameters that influence its development may be conveniently adjusted.

Specifically, in our model, the interactions between populations are not
merely driven by chance and the strategic decisions of the population
play a crucial role in the final outcome of the conflict, and we
consider this perspective as an interesting novelty in the mathematical
description of competitive environments.

At a technical level, our aim is to introduce a model for conflict
between two populations @xmath and @xmath , starting from the model when
the two populations compete for food and modifying it to add the
information about the clashes. We imagine that each individual of the
first population @xmath decides to attack an individual of the second
population with some probability @xmath in a given period of time. We
assume that hostilities take the form of “duels”, that is, one-to-one
fights. In each duel, the individual of the first population has a
probability @xmath of being killed and a probability @xmath of killing
his or her opponent; notice that in some duel the two fighters might be
both killed. Thus, after one time-period, the casualties for the first
and second populations are @xmath and @xmath respectively. The same
conclusions are found if we imagine that the first population forms an
army to attack the second, which tries to resist by recruting an army of
proportional size. At the end of each battle, a ratio of the total
soldiers is dead, and this is again of the form @xmath for the first
population and @xmath for the second one.

Another effect that we take into account is the drop in the fertility of
the population during wars. This seems due to the fact that families
suffer some income loss during war time, because of a lowering of the
average productivity and lacking salaries only partially compensated by
the state; another reason possibly discouraging couples to have children
is the increased chance of death of the parents during war. As pointed
out in [ 117 ] , in some cases the number of lost births during wars are
comparable to the number of casualties. However, it is not reasonable to
think that this information should be included in the exponential growth
rates @xmath and @xmath , because the fertility drop really depends on
the intensity of the war. For this reason, we introduce the parameters
@xmath and @xmath that are to be multiplied by @xmath for both
populations.

Moreover, for simplicity, we also suppose that the clashes take place
apart from inhabited zone, without having influence on the harvesting of
resources.

Now we derive the system of equations from a microlocal analysis. As in
the Lotka-Volterra model, it is assumed that the change of the size of
the population in an interval of time @xmath is proportional to the size
of the population @xmath , that is

  -- -------- --
     @xmath   
  -- -------- --

for some appropriate function @xmath . In particular, @xmath should
depend on resources that are available and reachable for the population.
The maximum number of individuals that can be fed with all the resources
of the environment is @xmath ; taking into account all the individuals
of the two populations, the available resources are

  -- -------- --
     @xmath   
  -- -------- --

Notice that we suppose here that each individual consumes the same
amount of resources, independently of its belonging. In our model, this
assumption is reasonable since all the individuals belong to the same
species. Also, the competition for the resources depends only on the
number of individuals, independently on their identity.

Furthermore, our model is sufficiently general to take into account the
fact that the growth rate of the populations can be possibly different.
In practice, this possible difference could be the outcome of a cultural
distinction, or it may be also due to some slight genetic
differentiation, as it happened for Homo Sapiens and Neanderthal, see [
51 ] .

Let us call @xmath and @xmath the fertility of the first and second
populations respectively. The contribution to the population growth rate
is given by

  -- -------- --
     @xmath   
  -- -------- --

and these effects can be comprised in a typical Lotka-Volterra system.

Instead, in our model, we also take into account the possible death rate
due to casualties. In this way, we obtain a term such as @xmath to be
added to @xmath . The fertility losses give another term @xmath for the
first population. We also perform the same analysis for the second
population, with the appropriate coefficients.

With these considerations, the system of the equations that we obtain is

  -- -- -- -------
           (3.3)
  -- -- -- -------

As usual in these kinds of models, we can rescale the variables and the
coefficients in order to find an equivalent model with fewer parameters.
Hence, we perform the changes of variables

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

and, dropping the tildas for the sake of readability, we finally get the
system in ( 3.1 ). We will also refer to it as the civil war model (CW).

From the change of variables in ( 3.4 ), we notice in particular that
@xmath may now take values in @xmath .

The competitive Lotka-Volterra system is already used to study some
market phenomena as technology substitution, see e.g. [ 85 , 24 , 122 ]
, and our model aims at adding new features to such models.

Concretely, in the technological competition model, one can think that
@xmath and @xmath represent the capitals of two computer companies. In
this setting, to start with, one can suppose that the first company
produces a very successful product, say computers with a certain
operating system, in an infinite market, reinvesting a proportion @xmath
of the profits into the production of additional items, which are
purchased by the market, and so on: in this way, one obtains a linear
equation of the type @xmath , with exponentially growing solutions. The
case in which the market is not infinite, but reaches a saturation
threshold @xmath , would correspond to the equation

  -- -------- --
     @xmath   
  -- -------- --

Then, when a second computer company comes into the business, selling
computers with a different operating system to the same market, one
obtains the competitive system of equations

  -- -------- --
     @xmath   
  -- -------- --

At this stage, the first company may decide to use an “aggressive”
strategy consisting in spreading a virus attacking the other company’s
operating system, with the aim of setting the other company out of the
market (once the competition of the second company is removed, the first
company can then exploit the market in a monopolistic regime). To model
this strategy, one can suppose that the first company invests a
proportion of its capital in the project and diffusion of the virus,
according to a quantifying parameter @xmath , thus producing the
equation

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

This directly impacts the capital of the second company proportionally
to the virus spread, since the second company has to spend money to
project and release antiviruses, as well as to repay unsatisfied
customers, hence resulting in a second equation of the form

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

The case @xmath would correspond to an “even” effect in which the costs
of producing the virus is in balance with the damages that it causes. It
is also realistic to take into account the case @xmath (e.g., the first
company manages to produce and diffuse the virus at low cost, with high
impact on the functionality of the operating system of the second
company) as well as the case @xmath (e.g., the cost of producing and
diffusing the virus is high with respect to the damages caused).

We remark that equations ( 3.5 ) and ( 3.6 ) can be set into the form (
3.3 ), thus showing the interesting versatility of our model also in
financial mathematics.

#### 3.1.2 Some notation and basic results on the dynamics of
system (3.1)

We denote by @xmath a solution of ( 3.1 ) starting from a point @xmath .
We will also refer to the orbit of @xmath as the collection of points
@xmath for @xmath , thus both positive and negative times, while the
trajectory is the collection of points @xmath for @xmath .

As already mentioned in the discussion below formula ( 3.1 ), @xmath can
reach the value @xmath and even negative values in finite time. However,
we will suppose that the dynamics stops when the value @xmath is reached
for the first time. At this point, the conflict ends with the victory of
the first population @xmath , that can continue its evolution with a
classical Lotka-Volterra equation of the form

  -- -------- --
     @xmath   
  -- -------- --

and that would certainly fall into the attractive equilibrium @xmath .
The only other possibility is that the solutions are constrained in the
set @xmath .

In order to state our first result on the dynamics of the system ( 3.1
), we first observe that, in a real-world situation, the value of @xmath
would probably be non-constant and discontinuous, so we allow this
coefficient to take values in the class @xmath defined as follows:

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

A solution related to a strategy @xmath is a pair @xmath , which is
@xmath outside the discontinuous points of @xmath and solves system (
3.1 ). Moreover, once the initial datum is imposed, the solution is
assumed to be continuous at @xmath .

In this setting, we establish the existence of the solutions of
problem ( 3.1 ) and we classify their behavior with respect to the
possible exit from the domain @xmath :

###### Proposition 3.1.

Let @xmath . Given @xmath , there exists a solution @xmath with @xmath
of system ( 3.1 ) starting at @xmath .

Furthermore, one of the two following situations occurs:

1.   The solution @xmath issued from @xmath belongs to @xmath for all
    @xmath .

2.   There exists @xmath such that the solution @xmath issued from
    @xmath exists unique for all @xmath , and @xmath and @xmath .

As a consequence of Proposition 3.1 , we can define the the stopping
time of the solution @xmath as

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

From now on, we will implicitly consider solutions @xmath only for
@xmath .

Now we are going to analyze the dynamics of ( 3.1 ) with a particular
focus on possible strategies. To do this, we now define the basins of
attraction . The first one is the basin of attraction of the point
@xmath , that is

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

namely the set of the initial points for which the first population gets
extinct (in infinite time) and the second one survives. The other one is

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

namely the set of initial points for which we have the victory of the
first population and the extinction of the second one.

Of course, the sets @xmath and @xmath depend on the parameters @xmath ,
@xmath , and @xmath ; we will express this dependence by writing @xmath
and @xmath when it is needed, and omit it otherwise for the sake of
readability. The dependence on parameters will be carefully studied in
Subsection 3.3 .

#### 3.1.3 Dynamics of system (3.1) for constant strategies

The first step towards the understanding of the dynamics of the system
in ( 3.1 ) is is to analyze the behavior of the system for constant
coefficients.

To this end, we introduce some notation. Following the terminology on
pages 9-10 in [ 123 ] , we say that an equilibrium point (or fixed
point) of the dynamics is a (hyperbolic) sink if all the eigenvalues of
the linearized map have strictly negative real parts, a (hyperbolic)
source if all the eigenvalues of the linearized map have strictly
positive real parts, and a (hyperbolic) saddle if some of the
eigenvalues of the linearized map have strictly positive real parts and
some have negative real parts (since in this chapter we work in
dimension @xmath , saddles correspond to linearized maps with one
eigenvalue with strictly positive real part and one eigenvalue with
strictly negative real part). We also recall that sinks are
asymptotically stable (and sources are asymptotically stable for the
reversed-time dynamics), see e.g. Theorem 1.1.1 in [ 123 ] .

With this terminology, we state the following theorem:

###### Theorem 3.2 (Dynamics of system (3.1)).

For @xmath and @xmath the system ( 3.1 ) has the following features:

-    When @xmath , the system has 3 equilibria: @xmath is a source,
    @xmath is a sink, and

      -- -------- -- --------
         @xmath      (3.11)
      -- -------- -- --------

    is a saddle.

-    When @xmath , the system has 2 equilibria: @xmath is a sink and
    @xmath is a saddle.

-    When @xmath , the system has 2 equilibria: @xmath is a sink and
    @xmath corresponds to a strictly positive eigenvalue and a null one.

-    We have

      -- -------- -- --------
         @xmath      (3.12)
      -- -------- -- --------

    where @xmath and @xmath are defined in ( 3.9 ) and ( 3.10 ),
    respectively, and @xmath is a smooth curve.

-    The trajectories starting in @xmath tend to @xmath if @xmath , and
    to @xmath if @xmath as @xmath goes to @xmath .

More precisely, one can say that the curve @xmath in Theorem 3.2 is the
stable manifold of the saddle point @xmath when @xmath , and of the
saddle point @xmath when @xmath . The case @xmath needs a special
treatment, due to the degeneracy of one eigenvalue, and in this case the
curve @xmath corresponds to the center manifold of @xmath , and an
ad-hoc argument will be exploited to show that also in this degenerate
case orbits that start in @xmath are asymptotic in the future to @xmath
.

As a matter of fact, @xmath acts as a dividing wall between the two
basins of attraction, as described in (iv) of Theorem 3.2 and in the
forthcoming Proposition 3.16 .

Moreover, in the forthcoming Propositions 3.8 and 3.14 we will show that
@xmath can be written as the graph of a function. This is particularly
useful because, by studying the properties of this function, we gain
relevant pieces of information on the sets @xmath and @xmath in ( 3.9 )
and ( 3.10 ).

We point out that in Theorem 3.2 we find that the set of initial data
@xmath splits into three part: the set @xmath , given in ( 3.10 ), made
of points going to the extinction of the second population in finite
time; the set @xmath , given in ( 3.9 ), which is the basin of
attraction of the equilibrium @xmath ; the set @xmath , which is a
manifold of dimension @xmath that separates @xmath from @xmath .

In particular, Theorem 3.2 shows that, also for our model, the Gause
principle of exclusion is respected; that is, in general, two competing
populations cannot coexist in the same territory, see e.g. [ 47 ] .

One peculiar feature of our system is that, if the aggressiveness is too
strong, the equilibrium @xmath changes its “stability” properties,
passing from a source (as in (i) of Theorem 3.2 ) to a saddle point (as
in (ii) of Theorem 3.2 ). This shows that the war may have
self-destructive outcomes, therefore it is important for the first
population to analyze the situation in order to choose a proper level of
aggressiveness. Figure 3.1 shows one example of dynamics for each case.

#### 3.1.4 Dynamics of system (3.1) for variable strategies and optimal
strategies for the first population

We now deal with the problem of choosing the strategy @xmath such that
the first population wins, that is a problem of target reachability for
a control-affine system. As we will see, the problem is not controllable
, meaning that, starting from a given initial point, it is not always
possible to reach a given target.

We now introduce some terminology, that we will use throughout the
chapter. Recalling ( 3.7 ), for any @xmath , we set

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

where @xmath denotes the set of initial data @xmath such that @xmath ,
when the coefficient @xmath in ( 3.1 ) is replaced by the function
@xmath .

Namely, @xmath represents the set of initial conditions for which @xmath
is able to win by choosing a suitable strategy in @xmath ; we call
@xmath the victory set with admissible strategies in @xmath . We also
say that @xmath is a winning strategy for the point @xmath if @xmath .

Moreover, we will call

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

Notice that @xmath is the limit point as @xmath tends to @xmath of the
sequence of saddle points @xmath defined in ( 3.11 ).

With this notation, the first question that we address is for which
initial configurations it is possible for the population @xmath to have
a winning strategy, that is, to characterize the victory set. For this,
we allow the strategy to take all the values in @xmath . In this
setting, we have the following result:

###### Theorem 3.3.

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (3.15)
      -- -------- -- --------

    with the convention that the last line in ( 3.15 ) is not present if
    @xmath .

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (3.16)
      -- -------- -- --------

    where

      -- -------- --
         @xmath   
      -- -------- --

    and we use the convention that the last line in ( 3.16 ) is not
    present if @xmath .

-    For @xmath , we have that

      -- -------- -- --------
         @xmath      (3.17)
      -- -------- -- --------

    where

      -- -------- -- --------
         @xmath      (3.18)
      -- -------- -- --------

    and we use the convention that the last line in ( 3.17 ) is not
    present if @xmath .

In practice, constant strategies could be certainly easier to implement
and it is therefore natural to investigate whether or not it suffices to
restrict to constant strategies without altering the possibility of
victory. The next result addresses this problem by showing that when
@xmath constant strategies are as good as all strategies, but instead
when @xmath victory cannot be achieved by only exploiting constant
strategies:

###### Theorem 3.4.

Let @xmath be the set of constant functions. Then the following holds:

-    For @xmath , we have that @xmath for all @xmath ;

-    For @xmath , we have that @xmath .

The result of Theorem 3.4 , part (i), reveals a special rigidity of the
case @xmath in which, no matter which strategy @xmath chooses, the
victory depends only on the initial conditions, but it is independent of
the strategy @xmath . Instead, as stated in Theorem 3.4 , part (ii), for
@xmath the choice of @xmath plays a crucial role in determining which
population is going to win and constant strategies do not exhaust all
the possible winning strategies. We stress that @xmath plays also a
special role in the biological interpretation of the model, since in
this case the two populations have the same fit to the environmental
resource, and hence, in a sense, they are indistinguishable, up to the
possible aggressive behavior of the first population.

Next, we show that the set @xmath can be recovered if we use piecewise
constant functions with at most one discontinuity, that we call
Heaviside functions.

###### Theorem 3.5.

There holds that @xmath , where @xmath is the set of Heaviside
functions.

The proof of Theorem 3.5 solves also the third question mentioned in the
Introduction. As a matter of fact, it proves that for each point we
either have a constant winning strategy or a winning strategy of type

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , and for suitable values @xmath , @xmath such that one
is very small and the other one very large, the order depending on
@xmath . The construction that we give also puts in light the fact that
the choice of the strategy depends on the initial datum, answering also
our fourth question.

It is interesting to observe that the winning strategy that switches
abruptly from a small to a large value could be considered, in the
optimal control terminology, as a “bang-bang” strategy. Even in a target
reachability problem, the structure predicted by Pontryagin’s Maximum
Principle is brought in light: the bounds of the set @xmath , as given
in Theorem 3.3 , depend on the bounds that we impose on the strategy,
that are, @xmath .

It is natural to consider also the case in which the level of
aggressiveness is constrained between a minimal and maximal threshold,
which corresponds to the setting @xmath for suitable @xmath , with the
hypothesis that @xmath . In this setting, we denote by @xmath the class
of piecewise continuous strategies @xmath in @xmath such that @xmath for
all @xmath and we let

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

Then we have the following:

###### Theorem 3.6.

Let @xmath and @xmath be two real numbers such that @xmath . Then, for
@xmath we have the strict inclusion @xmath .

Notice that for @xmath , Theorem 3.4 gives instead that @xmath and we
think that this is a nice feature, outlining a special role played by
the parameter @xmath (roughly speaking, when @xmath constant strategies
suffice to detect all possible winning configurations, thanks to Theorem
3.4 , while when @xmath non-constant strategies are necessary to detect
all winning configurations).

##### Time minimizing strategy

Once established that it is possible to win starting in a certain
initial condition, we are interested in knowing which of the possible
strategies is best to choose. One condition that may be taken into
account is the duration of the war. Now, this question can be written as
a minimization problem with a proper functional to minimize and
therefore the classical Pontryagin theory applies.

To state our next result, we recall the setting in ( 3.19 ) and define

  -- -------- --
     @xmath   
  -- -------- --

that is the set of all bounded strategies for which the trajectory
starting at @xmath leads to the victory of the first population. To each
@xmath we associate the stopping time defined in ( 3.8 ), and we express
its dependence on @xmath by writing @xmath . In this setting, we provide
the following statement concerning the strategy leading to the quickest
possible victory for the first population:

###### Theorem 3.7.

Given a point @xmath , there exists a winning strategy @xmath , and a
trajectory @xmath associated with @xmath , for @xmath , with @xmath ,
where @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

Moreover,

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

The surprising fact given by Theorem 3.7 is that the minimizing strategy
is not only of bang-bang type, but it may assume some values along a
singular arc , given by @xmath . This possibility is realized in some
concrete cases, as we verified by running some numerical simulations,
whose results can be visualized in Figure 3.2 .

#### 3.1.5 Organization of the chapter

In the forthcoming Section 3.2 we will exploit methods from ordinary
differential equations and dynamical systems to describe the equilibria
of the system and their possible basins of attraction. The dependence of
the dynamics on the structural parameters, such as fit to the
environment, aggressiveness and efficacy of attacks, is discussed in
detail in Section 3.3 .

Section 3.4 is devoted to the analysis of the strategies that allow the
first population to eradicate the second one (this part needs an
original combination of methods from dynamical systems and optimal
control theory).

### 3.2 First results on the dynamics and proofs of Proposition 3.1 and
Theorem 3.2

In this section we provide some useful results on the behavior of the
solutions of ( 3.1 ) and on the basin of attraction. In particular, we
provide the proofs of Proposition 3.1 and Theorem 3.2 and we state a
characterization of the sets @xmath and @xmath given in ( 3.9 ) and (
3.10 ), respectively, see Propositions 3.16 .

This material will be extremely useful for the analysis of the strategy
that we operate later.

We start with some preliminary notation. Given a close set @xmath , we
say that a trajectory @xmath originated in @xmath exits the set @xmath
at some time @xmath if

-   @xmath for @xmath ,

-   @xmath ,

-   for any vector @xmath normal to @xmath at the point @xmath , it
    holds that

      -- -------- --
         @xmath   
      -- -------- --

Now, we prove Proposition 3.1 , which is fundamental to the
well-definition of our model:

###### Proof of Proposition 3.1.

We consider the function @xmath , which is continuous except in a finite
number of points @xmath . In all the intervals @xmath , @xmath , for
@xmath , and @xmath , the equations in ( 3.1 ) have smooth coefficients,
and therefore a solution does exist. Now, it is sufficient to consider
@xmath as the initial datum for the dynamics in @xmath to construct a
solution @xmath for all @xmath satisfying system ( 3.1 ). This is a
rather classical result and we refer to [ 96 ] for more details.

Now, we prove that either the possibility in (1) or the possibility
in (2) can occur. For this, by using the equation for @xmath in ( 3.1 ),
we notice that for @xmath the inward pointing normal derivative is

  -- -------- --
     @xmath   
  -- -------- --

This means that no trajectory can exit @xmath on the edge @xmath .
Similarly, using the equation for @xmath in ( 3.1 ), we see that for
@xmath the normal derivative inward pointing is

  -- -------- --
     @xmath   
  -- -------- --

and therefore no trajectory can exit @xmath on the edge @xmath .

Moreover, it is easy to see that all points on the line @xmath go to the
equilibrium @xmath , thus trajectories do not cross the line @xmath .
The only remaining possibilities are that the trajectories stay in
@xmath , that is possibility (1), or they exit the square on the side
@xmath , that is possibility (2). ∎

Now, we give the proof of (i), (ii) and (iii) of Theorem 3.2 .

###### Proof of (i), (ii) and (iii) of Theorem 3.2.

We first consider equilibria with first coordinate @xmath . In this
case, from the second equation in ( 3.1 ), we have that the equilibria
must satisfy @xmath , thus @xmath or @xmath . As a consequence, @xmath
and @xmath are two equilibria of the system.

Now, we consider equilibria with first coordinate @xmath . Equilibria of
this form must satisfy @xmath with @xmath , and therefore, from the
first equation in ( 3.1 ),

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

Moreover from the condition @xmath and the second equation in ( 3.1 ),
we see that

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

Putting together ( 3.21 ) and ( 3.22 ), we obtain that the intersection
point must lie on the line @xmath . Since the equilibrium is at the
intersection between two lines, it must be unique. One can easily verify
that the values given in ( 3.11 ) satisfy ( 3.21 ) and ( 3.22 ).

From now on, we distinguish the three situations in (i), (ii) and (iii)
of Theorem 3.2 .

(i) If @xmath , we have that the point @xmath given in ( 3.11 ) lies in
@xmath . As a result, in this case the system has @xmath equilibria,
given by @xmath , @xmath and @xmath .

Now, we observe that the Jacobian of the system ( 3.1 ) is

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

At the point @xmath , the matrix has eigenvalues @xmath and @xmath ,
thus @xmath is a source. At the point @xmath , the Jacobian ( 3.23 ) has
eigenvalues @xmath and @xmath , thus @xmath is a sink. At the point
@xmath , by exploiting the relations ( 3.21 ) and ( 3.22 ) we have that

  -- -------- --
     @xmath   
  -- -------- --

which, by the change of basis given by the matrix

  -- -------- --
     @xmath   
  -- -------- --

becomes

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

The characteristic polynomial of the matrix in ( 3.24 ) is @xmath , that
has two real roots, as one can see by inspection. Hence, @xmath has two
real eigenvalues. Moreover, the determinant of @xmath is @xmath , which
implies that @xmath has one positive and one negative eigenvalues. These
considerations give that @xmath is a saddle point, as desired. This
completes the proof of (i) in Theorem 3.2 .

(ii) and (iii) We assume that @xmath . We observe that the equilibrium
described by the coordinates @xmath in ( 3.11 ) coincides with @xmath
for @xmath , and lies outside @xmath for @xmath . As a result, when
@xmath the system has @xmath equilibria, given by @xmath and @xmath .

Looking at the Jacobian in ( 3.23 ), one sees that at the point @xmath ,
it has eigenvalues @xmath and @xmath , and therefore @xmath is a sink
when @xmath .

Furthermore, from ( 3.23 ) one finds that if @xmath then @xmath has the
positive eigenvalue @xmath and the negative eigenvalue @xmath , thus
@xmath is a saddle point.

If instead @xmath , then @xmath has one positive eigenvalue and one null
eigenvalue, as desired. ∎

To complete the proof of Theorem 3.2 , we will deal with the cases
@xmath and @xmath separately. This analysis will be performed in the
forthcoming Sections 3.2.1 and 3.2.2 . The completion of the proof of
Theorem 3.2 will then be given in Section 3.2.3 .

#### 3.2.1 Characterization of @xmath when @xmath

We consider here the case @xmath . The case @xmath is degenerate and it
will be treated separately in Section 3.2.2 .

We point out that in the proof of (i) and (ii) in Theorem 3.2 we found a
saddle point in both cases. By the Stable Manifold Theorem (see for
example [ 96 ] ), the point @xmath in ( 3.11 ) in the case @xmath and
the point @xmath in the case @xmath have a stable manifold and an
unstable manifold. These manifolds are unique, they have dimension
@xmath , and they are tangent to the eigenvectors of the linearized
system. We will denote by @xmath the stable manifold associated with
these saddle points. Since we are interested in the dynamics in the
square @xmath , with a slight abuse of notation we will only consider
the restriction of @xmath in @xmath .

In order to complete the proof of Theorem 3.2 , we now analyze some
properties of @xmath :

###### Proposition 3.8.

For @xmath the set @xmath can be written as the graph of a unique
increasing @xmath function @xmath for some @xmath , such that @xmath ,
@xmath and

-    if @xmath , @xmath ;

-    if @xmath , in @xmath the function @xmath is tangent to the line
    @xmath .

As a byproduct of the proof of Proposition 3.8 , we also obtain some
useful information on the structure of the stable manifold and the
basins of attraction, that we summarize here below:

###### Corollary 3.9.

Suppose that @xmath . Then, the curves ( 3.21 ) and ( 3.22 ), loci of
the points such that @xmath and @xmath respectively, divide the square
@xmath into four regions:

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

Furthermore, the sets @xmath and @xmath are separated by the curve
@xmath , given by the graph of the continuous function

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

that satisfies @xmath , @xmath , and @xmath for all @xmath .

In addition,

  -- -- -- --------
           (3.27)
  -- -- -- --------

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

where the notation in ( 3.9 ) and ( 3.10 ) has been utilized.

To visualize the statements in Corollary 3.9 , one can see Figure 3.3 .

###### Corollary 3.10.

Suppose that @xmath . Then , we have that @xmath in @xmath , and the
curve ( 3.22 ) divides the square @xmath into two regions:

  -- -------- -- --------
     @xmath      (3.30)
  -- -------- -- --------

Furthermore, the sets @xmath and @xmath are separated by the curve
@xmath , given by the graph of the continuous function @xmath given in (
3.26 ).

In addition,

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

Proposition 3.8 and Corollaries 3.9 and 3.10 are a bit technical, but
provide fundamental information to obtain a characterization of the sets
@xmath and @xmath , given in the forthcoming Proposition 3.16 .

We now provide the proof of Proposition 3.8 (and, as a byproduct, of
Corollaries 3.9 and 3.10 ).

###### Proof of Proposition 3.8 and Corollaries 3.9 and 3.10.

We treat separately the cases @xmath and @xmath . We start with the case
@xmath , and divide the proof in three steps.

Step 1: localizing @xmath . With the notation introduced in ( 3.25 ), we
prove that

  -- -------- -- --------
     @xmath      (3.32)
  -- -------- -- --------

To this aim, we first observe that

  -- -- -- --------
           (3.33)
  -- -- -- --------

because @xmath and @xmath have a sign. Furthermore,

  -- -- -- --------
           (3.34)
  -- -- -- --------

Indeed, no point in @xmath with positive first coordinate can be mapped
in @xmath without exiting the set, because @xmath in @xmath . Also, for
all @xmath , we have that @xmath . On the other hand, @xmath in @xmath ,
so no trajectory that is entirely contained in @xmath can converge to
@xmath . These observations prove ( 3.34 ).

As a consequence of ( 3.33 ), ( 3.34 ) and the Poincaré-Bendixson
Theorem (see e.g. [ 113 ] ), we have that all the trajectories in the
interior of @xmath must exit the set at some time.

We remark that the side connecting @xmath and @xmath can be written as
the of points belonging to

  -- -------- --
     @xmath   
  -- -------- --

where the function @xmath is defined in ( 3.26 ). In this set, it holds
that @xmath and @xmath , thus the normal derivative pointing outward
@xmath is negative, so the trajectories cannot go outside @xmath passing
through this side.

Furthermore, on the side connecting @xmath with @xmath , that lies on
the straight line @xmath , we have that @xmath and @xmath for @xmath ,
so also here the outer normal derivative is negative. Therefore, the
trajectories cannot go outside @xmath passing through this side either.

These considerations complete the proof of ( 3.32 ). Accordingly,
recalling the definition of @xmath in ( 3.10 ), we see that

  -- -------- -- --------
     @xmath      (3.35)
  -- -------- -- --------

In a similar way one can prove that all trajectories starting in @xmath
must converge to @xmath , which, recalling the definition of @xmath in (
3.9 ), implies that

  -- -------- -- --------
     @xmath      (3.36)
  -- -------- -- --------

Thanks to ( 3.35 ) and ( 3.36 ), we have that the stable manifold @xmath
has no intersection with @xmath and @xmath , and therefore @xmath must
lie in @xmath .

Also, we know that @xmath is tangent to an eigenvector in @xmath , and
we observe that

  -- -- -- --------
           (3.37)
  -- -- -- --------

Indeed, if @xmath were an eigenvector, then

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath . Hence, recalling ( 3.11 ), we obtain that
@xmath , which is impossible. This establishes ( 3.37 ).

In light of ( 3.37 ), we conclude that @xmath must have intersection
with both @xmath and @xmath .

Step 2: defining @xmath . Since @xmath and @xmath in the interior of
@xmath , the portion of @xmath in @xmath can be described globally as
the graph of a monotone increasing smooth function @xmath , for a
suitable interval @xmath with @xmath , and such that @xmath .

We stress that, for @xmath , the points @xmath belong to @xmath .

Similarly, in the interior of @xmath we have that @xmath and @xmath .
Therefore, we find that @xmath can be represented in @xmath as the graph
of a monotone increasing smooth function @xmath , for a suitable
interval @xmath with @xmath , and such that @xmath . Notice that in the
second case the trajectories and the parametrization run in opposite
directions.

Now, we define

  -- -------- --
     @xmath   
  -- -------- --

and we observe that it is an increasing smooth function locally
parametrizing @xmath around @xmath (thanks to the Stable Manifold
Theorem).

We point out that, in light of the Stable Manifold Theorem, the stable
manifold @xmath is globally parametrized by an increasing smooth
function on a set @xmath .

Step 3: @xmath and @xmath for some @xmath . We first prove that

  -- -------- -- --------
     @xmath      (3.38)
  -- -------- -- --------

For this, we claim that

  -- -- -- --------
           (3.39)
  -- -- -- --------

Indeed, it is easy to see that points on the half axis @xmath converge
to @xmath , and therefore a trajectory cannot enter @xmath from this
side.

As for the side connecting @xmath to @xmath , here one has that @xmath
and @xmath , and so the inward pointing normal derivative is negative.
Therefore, no trajectory can enter @xmath on this side.

Moreover, on the side connecting @xmath to @xmath the inward pointing
normal derivative is negative, because @xmath and @xmath , thus we have
that no trajectory can enter @xmath on this side either. These
considerations prove ( 3.39 ).

Furthermore, we have that

  -- -- -- --------
           (3.40)
  -- -- -- --------

because @xmath and @xmath in @xmath .

From ( 3.39 ), ( 3.40 ) and the Poincaré-Bendixson Theorem (see e.g. [
113 ] ), we conclude that, given a point @xmath in the interior of
@xmath , the @xmath -limit set of @xmath , that we denote by @xmath ,
can be

  -- -------- -- --------
     @xmath      (3.41)
  -- -------- -- --------

We stress that, being @xmath in the interior of @xmath , we have that

  -- -------- -- --------
     @xmath      (3.42)
  -- -------- -- --------

Now, we observe that

  -- -- -- --------
           (3.43)
  -- -- -- --------

Indeed, suppose by contradiction that @xmath does contain @xmath . Then,
we denote by @xmath the solution of ( 3.1 ) with @xmath , and we have
that there exists a sequence @xmath such that @xmath converges to @xmath
as @xmath . In particular, in light of ( 3.42 ), there exists @xmath
sufficiently large such that

  -- -------- --
     @xmath   
  -- -------- --

Consequently, there exists @xmath such that @xmath .

As a result, it follows that @xmath . This, together with the fact that
@xmath , is in contradiction with ( 3.39 ), and the proof of ( 3.43 ) is
thereby complete.

Thus, from ( 3.41 ) and ( 3.43 ), we deduce that @xmath . This gives
that @xmath lies on the stable manifold @xmath , and therefore the proof
of ( 3.38 ) is complete.

Now, we show that

  -- -- -- --------
           (3.44)
  -- -- -- --------

To prove it, we first observe that

  -- -- -- --------
           (3.45)
  -- -- -- --------

Indeed, we suppose by contradiction that

  -- -- -- --------
           (3.46)
  -- -- -- --------

We remark that, in this case,

  -- -- -- --------
           (3.47)
  -- -- -- --------

because @xmath and @xmath have a sign in @xmath . Then, by the
Poincaré-Bendixson Theorem (see e.g. [ 113 ] ), we conclude that, given
a point @xmath in the interior of @xmath , the @xmath -limit set of
@xmath , that we denote by @xmath , can be either an equilibrium or a
union of (finitely many) equilibria and non-closed orbits connecting
these equilibria. We notice that the set @xmath cannot contain @xmath ,
since it is a stable equilibrium. We also claim that

  -- -- -- --------
           (3.48)
  -- -- -- --------

Indeed, we suppose by contradiction that @xmath does contain @xmath . We
observe that, since @xmath in @xmath ,

  -- -------- -- --------
     @xmath      (3.49)
  -- -------- -- --------

We denote by @xmath the solution of ( 3.1 ) with @xmath , and we have
that there exists a sequence @xmath such that @xmath converges to @xmath
as @xmath . In particular, in light of ( 3.49 ), there exists @xmath
sufficiently large such that

  -- -------- --
     @xmath   
  -- -------- --

Consequently, there exists @xmath such that @xmath . Accordingly, we
have that @xmath . This and the fact that @xmath give a contradiction
with ( 3.46 ), and therefore this establishes ( 3.48 ).

These considerations complete the proof of ( 3.45 ).

Now, we observe that the inward pointing normal derivative at every
point in @xmath is negative, since @xmath and @xmath . Hence, no
trajectory can enter from this side. Also, the inward pointing normal
derivative at every point in @xmath is negative, since @xmath and @xmath
. Hence, no trajectory can enter from this side either.

These observations and ( 3.45 ) give the desired result in ( 3.44 ), and
thus Proposition 3.8 is established in the case @xmath .

Now we treat the case @xmath , using the same ideas. In this setting,
@xmath is the stable manifold associated with the saddle point @xmath .
We point out that, in this case, for all points in @xmath we have that
@xmath . Hence, the curve of points satisfying @xmath , that was also
given in ( 3.22 ), divides the square @xmath into two regions @xmath and
@xmath , defined in ( 3.30 ).

Now, one can repeat verbatim the arguments in Step 1 with obvious
modifications, to find that @xmath .

Since the derivatives of @xmath and @xmath have a sign in @xmath , and
the set @xmath in this case is the trajectory of a point converging to
@xmath , the set @xmath can be represented globally as the graph of a
smooth increasing function @xmath for a suitable interval @xmath
containing the origin. As a consequence, the condition @xmath is
trivially satisfied in this setting. The existence of a suitable @xmath
can be derived reasoning as in Step 3 with obvious modifications.

Now, we prove that

  -- -- -- --------
           (3.50)
  -- -- -- --------

For this, we recall ( 3.23 ) and we see, by inspection, that the
Jacobian matrix @xmath has two eigenvectors, namely @xmath and @xmath .
The first one is tangent to the line @xmath , that is the unstable
manifold of @xmath , as one can easily verify. Thus, the second
eigenvector is the one tangent to @xmath , as prescribed by the Stable
Manifold Theorem (see e.g. [ 96 ] ). Hence, in @xmath the manifold
@xmath is tangent to the line @xmath and so is the function @xmath in
@xmath . This proves ( 3.50 ), and thus Proposition 3.8 is established
in the case @xmath as well. ∎

#### 3.2.2 Characterization of @xmath when @xmath

Here we will prove the counterpart of Proposition 3.8 in the degenerate
case @xmath .

To this end, looking at the velocity fields, we first observe that

  -- -------- -- --------
     @xmath      (3.51)
  -- -------- -- --------

We also point out that

  -- -------- -- --------
     @xmath      (3.52)
  -- -------- -- --------

since @xmath along @xmath .

Also, by the Center Manifold Theorem (see e.g. Theorem 1 on page 16 of [
31 ] or pages 89-90 in [ 99 ] ), there exists a collection @xmath of
invariant curves, which are all tangent at the origin to the eigenvector
corresponding to the null eigenvalue, that is the straight line @xmath .
Then, we define @xmath and we observe that this intersection is nonvoid,
given the tangency property of @xmath at the origin.

In what follows, for every @xmath , we denote by @xmath the orbit of
@xmath . We start by providing an observation related to negative times:

###### Lemma 3.11.

If @xmath then @xmath cannot approach the origin for negative values of
@xmath .

###### Proof.

We argue by contradiction and denote by @xmath a sequence of such
negative values of @xmath , for which @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Up to a subsequence, we can also suppose that

  -- -------- -- --------
     @xmath      (3.53)
  -- -------- -- --------

In light of ( 3.52 ), we have that, for all @xmath ,

  -- -------- -- --------
     @xmath      (3.54)
  -- -------- -- --------

Indeed, if @xmath , we deduce from ( 3.52 ) that @xmath for all @xmath .
In particular, we can take @xmath and conclude that @xmath , and this is
in contradiction with the assumption that @xmath .

As a byproduct of ( 3.54 ), we obtain that, for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

In particular

  -- -------- --
     @xmath   
  -- -------- --

which is in contradiction with ( 3.53 ), and consequently we have
established the desired result. ∎

Now we show that the @xmath -limit of any point lying on the global
center manifold coincides with the origin, according to the next result:

###### Lemma 3.12.

If @xmath , then its @xmath -limit is @xmath .

###### Proof.

We observe that, for every @xmath ,

  -- -------- -- --------
     @xmath      (3.55)
  -- -------- -- --------

Indeed, by ( 3.51 ), one sees that, for @xmath , @xmath cannot cross
@xmath , @xmath and @xmath , hence the only possible escape side is
given by @xmath . Therefore, to prove ( 3.55 ), we suppose, by
contradiction, that there exists @xmath such that @xmath , that is
@xmath . Since @xmath is an equilibrium, it follows that @xmath . In
particular, @xmath and accordingly @xmath . This means that @xmath for
all @xmath for a suitable @xmath . Looking again at the velocity fields,
this entails that @xmath for all @xmath . Consequently, @xmath cannot
approach the straight line @xmath for @xmath .

This, combined with Lemma 3.11 , says that the trajectory emanating from
@xmath can never approach the straight line @xmath at the origin, in
contradiction with the definition of @xmath , and thus the proof of (
3.55 ) is complete.

From ( 3.55 ) and the Poincaré-Bendixson Theorem (see e.g. [ 113 ] ), we
deduce that the @xmath -limit of @xmath can be either a cycle, or an
equilibrium, or a union of (finitely many) equilibria and non-closed
orbits connecting these equilibria. We observe that the @xmath -limit of
@xmath cannot be a cycle, since @xmath has a sign in @xmath . Moreover,
it cannot contain the sink @xmath , due to Lemma 3.11 . Hence, the only
possibility is that the @xmath -limit of @xmath coincides with @xmath ,
which is the desired result. ∎

As a consequence of Lemma 3.12 and the fact that @xmath in @xmath , we
obtain the following statement:

###### Corollary 3.13.

Every trajectory in @xmath has the form @xmath , with

  -- -------- --
     @xmath   
  -- -------- --

and there exists @xmath such that @xmath .

The result in Corollary 3.13 can be sharpened in view of the following
statement (which can be seen as the counterpart of Proposition 3.8 in
the degenerate case @xmath ): namely, since the center manifold can in
principle contain many different trajectories (see e.g. Figure 5.3 in [
31 ] ), we provide a tailor-made argument that excludes this possibility
in the specific case that we deal with.

###### Proposition 3.14.

For @xmath @xmath contains one, and only one, trajectory, which is
asymptotic to the origin as @xmath , and that can be written as a graph
@xmath , for some @xmath , where @xmath is an increasing @xmath function
such that @xmath , @xmath and the graph of @xmath at the origin is
tangent to the line @xmath .

###### Proof.

First of all, we show that

  -- -- -- --------
           (3.56)
  -- -- -- --------

Suppose, by contradiction, that @xmath contains two different orbits,
that we denote by @xmath and @xmath . Using Corollary 3.13 , we can
suppose that @xmath lies above @xmath and

  -- -------- -- --------
     @xmath      (3.57)
  -- -------- -- --------

Consequently, for every @xmath , it follows that

  -- -------- -- --------
     @xmath      (3.58)
  -- -------- -- --------

In particular, we can take an open ball @xmath in the vicinity of the
origin, denote by @xmath the Lebesgue measure of @xmath , and write that
@xmath and

  -- -------- -- --------
     @xmath      (3.59)
  -- -------- -- --------

We point out that @xmath lies in the vicinity of the origin for all
@xmath , thanks to ( 3.57 ). As a consequence, for all @xmath , @xmath ,
changing variable

  -- -------- --
     @xmath   
  -- -------- --

we find that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath denotes the trace of a @xmath -matrix.

As a consequence,

  -- -------- -- --------
     @xmath      (3.60)
  -- -------- -- --------

Also, using the notation @xmath , we can write ( 3.1 ) when @xmath in
the form

  -- -------- --
     @xmath   
  -- -------- --

Accordingly,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

whence

  -- -------- -- --------
     @xmath      (3.61)
  -- -------- -- --------

for @xmath near the origin.

As a result, recalling ( 3.58 ), we can take @xmath sufficiently large,
such that @xmath lies in a neighborhood of the origin, exploit ( 3.61 )
to write that @xmath and then ( 3.60 ) to conclude that

  -- -------- --
     @xmath   
  -- -------- --

This implies that @xmath diverges (exponentially fast) as @xmath , which
is in contradiction with ( 3.59 ). The proof of ( 3.56 ) is thereby
complete.

Now, we check the other claims in the statement of Proposition 3.14 .
The asymptotic property as @xmath is a consequence of Corollary 3.13 .
Also, the graphical property as well as the monotonicity property of the
graph follow from the fact that @xmath . The smoothness of the graph
follows from the smoothness of the center manifold. The fact that @xmath
and @xmath follow also from Corollary 3.13 . The tangency property at
the origin is a consequence of the tangency property of the center
manifold to the center eigenspace. ∎

As a byproduct of the proof of Proposition 3.14 we also obtain the
following information:

###### Corollary 3.15.

Suppose that @xmath . Then , we have that @xmath in @xmath , and the
curve ( 3.22 ) divides the square @xmath into two regions @xmath and
@xmath , defined in ( 3.30 ).

Furthermore, the sets @xmath and @xmath are separated by the curve
@xmath , given by the graph of the continuous function @xmath given in (
3.26 ).

In addition,

  -- -------- -- --------
     @xmath      (3.62)
  -- -------- -- --------

#### 3.2.3 Completion of the proof of Theorem 3.2

We observe that, by the Stable Manifold Theorem and the Center Manifold
Theorem, the statement in (v) of Theorem 3.2 is obviously fulfilled.

Hence, to complete the proof of Theorem 3.2 , it remains to show that
the statement in (iv) holds true. To this aim, exploiting the useful
pieces of information in Propositions 3.8 and 3.14 , we first give a
characterization of the sets @xmath and @xmath :

###### Proposition 3.16.

The following characterizations of the sets in ( 3.9 ) and ( 3.10 ) are
true:

  -- -------- -- --------
     @xmath      (3.63)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (3.64)
  -- -------- -- --------

for some @xmath .

One can visualize the appearance of the set @xmath in ( 3.63 ) in two
particular cases in Figure 3.4 .

###### Proof of Proposition 3.16.

We let @xmath be the parametrization of @xmath , as given by
Propositions 3.8 (when @xmath ) and 3.14 (when @xmath ), and we consider
the sets

  -- -- -- -------- --
           @xmath   
           @xmath   
  -- -- -- -------- --

The goal is to prove that @xmath and @xmath . We observe that, when
@xmath , then @xmath . When instead @xmath , then @xmath . Accordingly,
if we show that

  -- -- -- -------- -- --------
           @xmath      (3.65)
           @xmath      (3.66)
  -- -- -- -------- -- --------

we are done.

Hence, we now focus on the proof of ( 3.65 ). Namely, recalling ( 3.10
), we show that

  -- -- -- --------
           (3.67)
  -- -- -- --------

For this, we first notice that, gathering together ( 3.28 ), ( 3.29 ), (
3.39 ), ( 3.40 ) and ( 3.47 ), we find that

  -- -- -- --------
           (3.68)
  -- -- -- --------

(in the case @xmath , and the same holds true in the case @xmath since
@xmath has a sign).

In addition,

  -- -- -- --------
           (3.69)
  -- -- -- --------

Indeed, by Propositions 3.8 (when @xmath ) and 3.14 (when @xmath ), we
have that @xmath , and therefore @xmath . Moreover, if @xmath , a
trajectory in @xmath cannot converge to @xmath , since @xmath does not
contain points of the stable manifold @xmath , nor to @xmath , since
this is a repulsive equilibrium and no trajectory converges here. If
instead @xmath , then it cannot converge to @xmath , since @xmath does
not contain points of @xmath . These observations completes the proof
of ( 3.69 ).

From ( 3.68 ), ( 3.69 ) and the Poincaré-Bendixson Theorem (see e.g. [
113 ] ), we have that every trajectory starting in @xmath leaves the set
(possibly in infinite time).

If the trajectory leaves at @xmath , then it converges to some
equilibrium on @xmath , which is in contradiction with ( 3.69 ).

As a consequence a trajectory in @xmath leaves the set in finite time.
Suppose that a trajectory leaves @xmath at a point @xmath ; then either
@xmath or @xmath . The first possibility is impossible, otherwise the
starting point of the trajectory would converge to @xmath . Hence, the
only possibility is that the trajectory leaves @xmath at @xmath . By
Proposition 3.1 this is possible only if @xmath and @xmath , which
proves ( 3.67 ). As a consequence of ( 3.67 ) we obtain that

  -- -------- -- --------
     @xmath      (3.70)
  -- -------- -- --------

We now claim that

  -- -------- -- --------
     @xmath      (3.71)
  -- -------- -- --------

To this end, we observe that there are neither cycles nor equlibria in
@xmath , and therefore we can use the Poincaré-Bendixson Theorem (see
e.g. [ 113 ] ) to conclude that any trajectory starting in @xmath must
exit the set. Also, the inward normal velocity along the sides @xmath
and @xmath is positive, and thus no trajectory can exit from these
sides. Now, if a trajectory exits @xmath from the side @xmath , then it
enters the set @xmath , and therefore ( 3.71 ) is a consequence of (
3.70 ) in this case. If instead a trajectory exits @xmath from the side
@xmath , then we directly obtain ( 3.71 ).

From ( 3.70 ) and ( 3.71 ) we obtain ( 3.65 ), as desired.

We now prove ( 3.66 ), namely we show that

  -- -- -- --------
           (3.72)
  -- -- -- --------

To this end, we observe that @xmath (if @xmath ) and @xmath are not in
@xmath . Moreover, no trajectory starting in @xmath converges to @xmath
(if @xmath ), nor to @xmath , since @xmath does not contain points on
@xmath .

In addition, recalling ( 3.68 ), we have that there are no limit cycles
in @xmath . As a consequence, by the Poincaré-Bendixson Theorem (see
e.g. [ 113 ] ), we have that every trajectory starting in @xmath either
go to @xmath or it exits the set at some point of @xmath .

In the latter case, since no trajectory can cross @xmath , the only
possibility is that the trajectory exits @xmath at some point @xmath .
We notice that, since @xmath is increasing, we have that @xmath for all
@xmath . As a consequence,

  -- -- -- --------
           (3.73)
  -- -- -- --------

Now, thanks to Proposition 3.1 , the only possibility that a trajectory
exits @xmath at some point @xmath is for @xmath and @xmath , which would
contradict ( 3.73 ).

As a result, the only remaining possibility is that a trajectory in
@xmath converges to @xmath , which proves ( 3.72 ). Hence, the proof
of ( 3.66 ) is complete as well. ∎

With this, we are now able to complete the proof of Theorem 3.2 :

###### Proof of (iv) of Theorem 3.2.

The statement in (iv) of Theorem 3.2 is a direct consequence of the
parametrization of the manifold @xmath , as given by Proposition 3.8 for
@xmath and by Proposition 3.14 for @xmath , and the characterization of
the sets @xmath and @xmath , as given by Proposition 3.16 . ∎

### 3.3 Dependence of the dynamics on the parameters

In this section we discuss the dependence on the parameters involved in
the system ( 3.1 ).

The dynamics of the system in ( 3.1 ) depends qualitatively only on
@xmath , but of course the position of the saddle equilibrium and the
size and shape of the basins of attraction depend quantitatively upon
all the parameters. Here we perform a deep analysis on each parameter
separately.

We notice that the system in ( 3.1 ) does not present a variational
structure, due to the presence of the terms @xmath in the first equation
and @xmath in the second one, that are of first order in @xmath . Thus,
the classical methods of the calculus of variations cannot be used and
we have to make use of ad-hoc arguments, of geometrical flavour.

#### 3.3.1 Dependence of the dynamics on the parameter @xmath

We start by studying the dependence on @xmath , that represents the
losses (soldier death and missing births) caused by the war for the
first population with respect to the second one. In the following
proposition, we will express the dependence on @xmath of the basin of
attraction @xmath in ( 3.10 ) by writing explicitly @xmath .

###### Proposition 3.17 (Dependence of the dynamics on @xmath).

With the notation in ( 3.10 ), we have that

-    If @xmath , then @xmath .

-    It holds that

      -- -------- -- --------
         @xmath      (3.74)
      -- -------- -- --------

We remark that the behavior for @xmath sufficiently small is given
by (i) of Theorem 3.2 : in this case, there is a saddle point inside the
domain @xmath , thus @xmath . On the other hand, as @xmath , the set
@xmath gets smaller and smaller until the first population has no
chances of victory if the second population has a positive size.

The parameter @xmath appears only in the first equation and it is
multiplied by @xmath , that is always negative in the domain we are
interested in. Thus, the dependence on @xmath is independent of the
other parameters. As one would expect, Proposition 3.17 tells us that
the greater the cost of the war for the first population, the fewer
possibilities of victory there are for it.

###### Proof of Proposition 3.17.

(i) We take @xmath . According to Theorem 3.2 , we denote by @xmath the
coexistence equilibrium for the parameter @xmath if @xmath , otherwise
we set @xmath ; similarly, we call @xmath the coexistence equilibrium
for the parameter @xmath if @xmath , and in the other cases we set
@xmath .

We observe that

  -- -------- -- --------
     @xmath      (3.75)
  -- -------- -- --------

Indeed, if @xmath then also @xmath , and therefore, using the
characterization in ( 3.11 ),

  -- -------- --
     @xmath   
  -- -------- --

which implies ( 3.75 ) in this case. If instead @xmath then the
inequality in ( 3.75 ) is trivially satisfied, thanks to (i), (ii)
and (iii) of Theorem 3.2 .

Now, in the notation of Propositions 3.8 (if @xmath ) and 3.14 (if
@xmath ), thanks to the characterization in ( 3.63 ), if we prove that

  -- -------- -- --------
     @xmath      (3.76)
  -- -------- -- --------

then the inclusion in (i) is shown. Hence, we now focus on the proof
of ( 3.76 ).

To this end, we observe that, since @xmath is an increasing function,
its inverse function @xmath is well defined and is increasing as well.
In an analogue fashion, we define @xmath as the inverse of @xmath . We
point out that the inequality in ( 3.76 ) holds true if

  -- -------- -- --------
     @xmath      (3.77)
  -- -------- -- --------

Accordingly, we will show ( 3.77 ) in three steps.

First, in light of ( 3.75 ), we show that

  -- -- -- --------
           (3.78)
  -- -- -- --------

For this, if @xmath , then also @xmath , and therefore @xmath , thanks
to (ii) and (iii) in Theorem 3.2 . Accordingly, in this case the
interval @xmath coincides with the singleton @xmath , and so there is
nothing to prove.

Otherwise, we recall that the curve @xmath , given in ( 3.26 ) and
representing the points where @xmath , is independent of @xmath .
Moreover, thanks to formula ( 3.27 ) in Corollary 3.9 if @xmath ,
formula ( 3.31 ) in Corollary 3.10 if @xmath , and formula ( 3.62 ) in
Corollary 3.15 if @xmath (see also Figure 3.3 ), we have that @xmath for
@xmath and @xmath for @xmath , which proves ( 3.78 ) in the open
interval @xmath .

Moreover, it holds that

  -- -------- -- --------
     @xmath      (3.79)
  -- -------- -- --------

and (if @xmath , otherwise @xmath and there is no need to perform this
computation)

  -- -------- -- --------
     @xmath      (3.80)
  -- -------- -- --------

This completes the proof of ( 3.78 ).

Next we show that

  -- -- -- --------
           (3.81)
  -- -- -- --------

If @xmath , then @xmath , and so the claim in ( 3.81 ) is trivial.
Hence, we suppose that @xmath and we argue by contradiction, assuming
that for some @xmath it holds that @xmath . As a consequence, we can
define

  -- -------- --
     @xmath   
  -- -------- --

We observe that, by continuity, we have that @xmath , and therefore,
by ( 3.78 ), we see that @xmath . As a result, since @xmath for every
@xmath , then it holds that

  -- -------- -- --------
     @xmath      (3.82)
  -- -------- -- --------

On the other hand, we can compute the derivatives by exploiting the fact
that @xmath and @xmath follow the flux for the system ( 3.1 ). Namely,
setting @xmath , we have that

  -- -- -- -------- --
           @xmath   
           @xmath   
  -- -- -- -------- --

Now, since @xmath , we have that @xmath (recall ( 3.27 ) and notice that
@xmath ). This and the fact that @xmath give that

  -- -------- --
     @xmath   
  -- -------- --

which is in contradiction with ( 3.82 ), thus establishing ( 3.81 ).

Now we prove that

  -- -- -- --------
           (3.83)
  -- -- -- --------

Indeed, if @xmath , we argue towards a contradiction, supposing that
there exists @xmath such that @xmath . Hence, we can define

  -- -------- --
     @xmath   
  -- -------- --

and we deduce from ( 3.79 ) that @xmath . By continuity, we see that
@xmath . Therefore, since @xmath for any @xmath , we conclude that

  -- -------- -- --------
     @xmath      (3.84)
  -- -------- -- --------

On the other hand, setting @xmath and exploiting ( 3.1 ), we get that

  -- -- -------- --
        @xmath   
        @xmath   
  -- -- -------- --

Moreover, recalling ( 3.25 ) and ( 3.27 ), we have that @xmath and
@xmath belong to the interior of @xmath , and therefore @xmath . This ad
the fact that @xmath give that

  -- -------- --
     @xmath   
  -- -------- --

which is in contradiction with ( 3.84 ). This establishes ( 3.83 ) in
this case.

If instead @xmath , then also @xmath , and therefore we have that @xmath
. In this setting, we use Propositions 3.8 and 3.14 to say that at
@xmath the function @xmath is tangent to the line @xmath , while @xmath
is tangent to @xmath . Now, since

  -- -------- --
     @xmath   
  -- -------- --

we have that for positive @xmath the second line is above the first one.
Also, thanks to the fact that @xmath and @xmath are tangent to these
lines, we conclude that there exists @xmath such that

  -- -------- -- --------
     @xmath      (3.85)
  -- -------- -- --------

Now, we suppose by contradiction that there exists some @xmath such that
@xmath . Hence, we can define

  -- -- --
        
  -- -- --

In light of ( 3.85 ), we have that @xmath . Moreover, by continuity, we
see that @xmath . Accordingly, since @xmath for any @xmath , then it
must be

  -- -------- -- --------
     @xmath      (3.86)
  -- -------- -- --------

On the other hand, setting @xmath and exploiting ( 3.1 ), we see that

  -- -- -------- --
        @xmath   
        @xmath   
  -- -- -------- --

Now, thanks to ( 3.30 ) and ( 3.31 ), we have that @xmath and @xmath
belong to the interior of @xmath , and therefore @xmath . This ad the
fact that @xmath give that

  -- -------- --
     @xmath   
  -- -------- --

which is in contradiction with ( 3.86 ). This completes the proof of (
3.83 ).

Gathering together ( 3.78 ), ( 3.81 ) and ( 3.83 ), we obtain ( 3.77 ),
as desired.

(ii) We first show that for all @xmath there exists @xmath such that for
all @xmath it holds that

  -- -------- -- --------
     @xmath      (3.87)
  -- -------- -- --------

The inclusion in ( 3.87 ) is also equivalent to

  -- -------- -- --------
     @xmath      (3.88)
  -- -------- -- --------

and the strict inequality is justified by the fact that @xmath and
@xmath are separated by @xmath , according to Proposition 3.16 . We now
establish the inclusion in ( 3.88 ). For this, let

  -- -------- -- --------
     @xmath      (3.89)
  -- -------- -- --------

Now, we can choose @xmath large enough such that the condition @xmath is
fulfilled. In this way, thanks to (ii) and (iii) of Theorem 3.2 , the
only equilibria are the points @xmath and @xmath .

Now, the component of the velocity in the inward normal direction to
@xmath on the side @xmath is given by

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

that is positive for

  -- -------- -- --------
     @xmath      (3.90)
  -- -------- -- --------

This says that no trajectory in @xmath can exit @xmath from the side
@xmath .

The other parts of @xmath belong to @xmath but not to @xmath . As a
consequence, by Proposition 3.1 ,

  -- -- -- --------
           (3.91)
  -- -- -- --------

From this, ( 3.68 ) and the Poincaré-Bendixson Theorem (see e.g. [ 113 ]
), we conclude that the @xmath -limit of any trajectory starting in
@xmath can be either an equilibrium or a union of (finitely many)
equilibria and non-closed orbits connecting these equilibria.

Now, we claim that, possibly taking @xmath larger in ( 3.90 ),

  -- -------- -- --------
     @xmath      (3.92)
  -- -------- -- --------

Indeed, suppose by contradiction that there exists @xmath . Then, in
light of ( 3.91 ), a trajectory passing through @xmath and converging to
@xmath has to be entirely contained in @xmath .

On the other hand, by Propositions 3.8 and 3.14 , we know that at @xmath
the manifold @xmath is tangent to the line @xmath . Hence, if we choose
@xmath large enough such that

  -- -------- --
     @xmath   
  -- -------- --

we obtain that this line is below the line @xmath , thus reaching a
contradiction. This establishes ( 3.92 ).

From ( 3.92 ), we deduce that, given @xmath , and denoting @xmath the
@xmath -limit of @xmath ,

  -- -------- -- --------
     @xmath      (3.93)
  -- -------- -- --------

provided that @xmath is taken large enough.

Furthermore, @xmath cannot consist of the two equilibria @xmath and
@xmath and non-closed orbits connecting these equilibria, since @xmath
is a sink. As a consequence of this and ( 3.93 ), we obtain that @xmath
for any @xmath , provided that @xmath is large enough.

Thus, recalling ( 3.9 ) and ( 3.89 ), this proves ( 3.88 ), and
therefore ( 3.87 ).

Now, using ( 3.87 ), we see that for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Accordingly,

  -- -------- --
     @xmath   
  -- -------- --

which implies ( 3.74 ), as desired. ∎

#### 3.3.2 Dependence of the dynamics on the parameter @xmath

Now we analyze the dependence of the dynamics on the parameter @xmath ,
that is the fitness of the second population @xmath with respect to the
fitness of the first one @xmath .

In the following proposition, we will make it explicit the dependence on
@xmath by writing @xmath and @xmath .

###### Proposition 3.18 (Dependence of the dynamics on @xmath).

With the notation in ( 3.9 ) and ( 3.10 ), we have that

-    When @xmath , for any @xmath the point @xmath is an equilibrium. If
    @xmath , then it corresponds to a strictly negative eigenvalue and a
    null one. If instead @xmath , then it corresponds to a strictly
    positive eigenvalue and a null one

    Moreover,

      -- -------- -- --------
         @xmath      (3.94)
      -- -------- -- --------

    and for any @xmath and any @xmath we have that

      -- -------- -- --------
         @xmath      (3.95)
      -- -------- -- --------

    where

      -- -------- -- --------
         @xmath      (3.96)
      -- -------- -- --------

-    For any @xmath and any @xmath it holds that

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath is defined in ( 3.96 ).

-    It holds that

      -- -------- -- --------
         @xmath      (3.97)
      -- -------- -- --------

We point out that the case @xmath is not comprehended in Theorem 3.2 .
As a matter of fact, the dynamics of this case is qualitatively very
different from all the other cases. Indeed, for @xmath the domain @xmath
is not divided into @xmath and @xmath , since more attractive equilibria
appear on the line @xmath . Thus, even if the second population cannot
grow, it still has some chance of victory.

As soon as @xmath is positive, on the line @xmath only the equilibrium
@xmath survives, and it attracts all the points that were going to the
line @xmath for @xmath .

When @xmath , the basin of attraction of @xmath tends to invade the
domain, thus the first population tends to have almost no chance of
victory and the second population tends to win. However, the dependence
on the parameter @xmath is not monotone as one could think, at least not
in @xmath .

Indeed, by performing some simulation, one could find some values @xmath
and @xmath , with @xmath , and a point @xmath such that @xmath and
@xmath , see Figure 3.5 .

This means that, sometimes, a big value of fitness for the second
population may lead to extinction while a small value brings to victory.
This is counterintuitive, but can be easily explained: the parameter
@xmath is multiplied by the term @xmath , that is negative past the
counterdiagonal of the square @xmath . So in the model ( 3.1 ), as well
as in any model of Lotka-Volterra type, the population that grows faster
is also the one that suffers more the consequences of overpopulation.
Moreover, the usual dynamics of Lotka-Volterra models is altered by the
presence of the term @xmath , and this leads to the lack of monotonicity
that we observe.

We now give the proof of Proposition 3.18 :

###### Proof of Proposition 3.18.

(i) For @xmath , the equation @xmath collapses to @xmath . Since for
@xmath also the equation @xmath is satisfied, each point on the line
@xmath is an equilibrium.

Calculating the eigenvalues for the points @xmath , with @xmath , using
the Jacobian matrix in ( 3.23 ), one gets the values @xmath and @xmath .
Accordingly, this entail that, if @xmath , the point @xmath corresponds
to a strictly negative eigenvalue and a null one, while if @xmath then
@xmath corresponds to a strictly negative eigenvalue and a null one.
These considerations proves the first statement in (i).

We notice also that in the whole square @xmath we have @xmath , hence
there is no trajectory that can go to @xmath , and there is no cycle. In
particular this implies ( 3.94 ).

Now, we observe that on the side @xmath the inward normal derivative is
given by @xmath , which is nonnegative, and therefore a trajectory
cannot exit the square on this side. Similarly, along the side @xmath
the inward normal derivative is given by @xmath , which is positive,
hence a trajectory cannot exit the square on this side either.

The side @xmath is made of equilibrium points at which the first
population @xmath is extinct, while on the side @xmath we have
extinction of the population @xmath . Thus a trajectory either converges
to one of the equilibria on the side @xmath , or exits @xmath through
the side @xmath .

In particular, since @xmath consists of repulsive equilibria, we have
that

  -- -------- --
     @xmath   
  -- -------- --

that is, trajectories starting in @xmath go to the extinction of @xmath
. This proves the first inclusion in ( 3.95 ).

To prove the second inclusion in ( 3.95 ), we first show that

  -- -- -- --------
           (3.98)
  -- -- -- --------

Indeed, on the line @xmath we have that the inward-pointing normal
derivative is given by

  -- -------- -- --------
     @xmath      (3.99)
  -- -------- -- --------

The first term is always positive; the second one is positive for the
choice

  -- -------- --
     @xmath   
  -- -------- --

Hence, under the assumption in (i), on the line @xmath the
inward-pointing normal derivative is positive, which implies that no
trajectories in @xmath can exit from @xmath . This establishes ( 3.98 ).

As a consequence of ( 3.98 ), we obtain also the second inclusion ( 3.95
), as desired.

(ii) We claim that

  -- -------- -- ---------
     @xmath      (3.100)
  -- -------- -- ---------

for all @xmath . To this end, we observe that, in order to determine the
sign of the inward pointing normal derivative on the side @xmath , by (
3.99 ) we have to check that @xmath . In order to simplify the
calculation, we use the change of coordinates @xmath and @xmath . In
this way, one needs to verify that @xmath on the line @xmath . For this,
we compute

  -- -------- -- ---------
     @xmath      (3.101)
  -- -------- -- ---------

Now we choose @xmath and we recall that @xmath . Moreover, we notice
that

  -- -------- --
     @xmath   
  -- -------- --

and therefore @xmath . Thus, we have that

  -- -------- --
     @xmath   
  -- -------- --

that is negative for @xmath . Plugging this information into ( 3.101 ),
we obtain that @xmath , as desired.

This proves that trajectories in @xmath cannot exit @xmath . This, the
fact that there are no cycles in @xmath and the Poincaré-Bendixson
Theorem (see e.g. [ 113 ] ) give that trajectories in @xmath converge to
@xmath , that is the only equilibrium in @xmath . Hence, ( 3.100 ) is
established.

From ( 3.100 ) we deduce that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , which implies the desired result in (ii).

(iii) We consider @xmath to be taken sufficiently small in what follows,
and we show that there exists @xmath , depending on @xmath and @xmath ,
such that for all @xmath it holds that

  -- -------- -- ---------
     @xmath      (3.102)
  -- -------- -- ---------

For this, we first observe that

  -- -- -- ---------
           (3.103)
  -- -- -- ---------

Indeed, looking at the velocity fields on the sides @xmath and @xmath ,
one sees that no trajectory in @xmath can exit from these sides.

Moreover, on the side @xmath , the normal inward derivative is

  -- -------- --
     @xmath   
  -- -------- --

and this is positive for @xmath (which is fixed from now on). In
addition, on the side @xmath , the inward normal derivative is

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

and this is positive for

  -- -------- -- ---------
     @xmath      (3.104)
  -- -------- -- ---------

These observations complete the proof of ( 3.103 ).

From ( 3.68 ), ( 3.103 ) and the Poincaré-Bendixson Theorem (see e.g. [
113 ] ), we have that all the trajectories in the interior of @xmath
must converge to either an equilibrium or a union of (finitely many)
equilibria and non-closed orbits connecting these equilibria.

In addition, we claim that, if @xmath , recalling ( 3.11 ) and possibly
enlarging @xmath in ( 3.104 ),

  -- -------- -- ---------
     @xmath      (3.105)
  -- -------- -- ---------

Indeed, we have that @xmath and @xmath , as @xmath . Hence, we can
choose @xmath large enough such that the statement in ( 3.105 ) is
satisfied.

As a consequence of ( 3.105 ), we get that all the trajectories in the
interior of @xmath must converge to the equilibrium @xmath , and this
establishes ( 3.102 ).

Accordingly, ( 3.102 ) entails that, for @xmath sufficiently small,
there exists @xmath , depending on @xmath and @xmath , such that for all
@xmath

  -- -- --
        
  -- -- --

This implies ( 3.97 ), as desired. ∎

#### 3.3.3 Dependence of the dynamics on the parameter @xmath

The consequences of the lack of variational structure become even more
extreme when we observe the dependence of the dynamics on the parameter
@xmath , that is the aggressiveness of the first population towards the
other. Throughout this section, we take @xmath and @xmath , and we
perform our analysis taking into account the limit cases @xmath and
@xmath . We start analyzing the dynamics of ( 3.1 ) in the case @xmath .

###### Proposition 3.19 (Dynamics of (3.1) when @xmath).

For @xmath the system ( 3.1 ) has the following features:

-    The system has the equilibrium @xmath , which is a source, and a
    straight line of equilibria @xmath , for all @xmath , which
    correspond to a strictly negative eigenvalue and a null one.

-    Given any @xmath we have that

      -- -------- -- ---------
         @xmath      (3.106)
      -- -------- -- ---------

    where @xmath satisfies

      -- -------- -- ---------
         @xmath      (3.107)
      -- -------- -- ---------

-    The equilibrium @xmath given in ( 3.14 ) has a stable manifold,
    which can be written as the graph of an increasing smooth function
    @xmath , for some @xmath , such that @xmath , @xmath .

    More precisely,

      -- -------- -- ---------
         @xmath      (3.108)
      -- -------- -- ---------

    being @xmath defined in ( 3.14 ).

We point out that formula ( 3.106 ) says that for @xmath every point in
the interior of @xmath tends to a coexistence equilibrium. The shape of
the trajectories depends on @xmath , being convex in the case @xmath , a
straight line in the case @xmath , and concave in the case @xmath . This
means that if the second population @xmath is alive at the beginning,
then it does not get extinct in finite time.

###### Proof of Proposition 3.19.

(i) For @xmath , we look for the equilibria of the system ( 3.1 ) by
studying when @xmath and @xmath . It is easy to see that the point
@xmath and all the points on the line @xmath are the only equilibria.

The Jacobian of the system (see ( 3.23 ), with @xmath ) at the point
@xmath has two positive eigenvalues, @xmath and @xmath , and thereofore
@xmath is a source.

Furthermore, the characteristic polynomial at a point @xmath on the line
@xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

and therefore, the eigenvalues are @xmath and @xmath .

(ii) We point out that when @xmath

  -- -- -- ---------
           (3.109)
  -- -- -- ---------

Indeed,

  -- -------- --
     @xmath   
  -- -------- --

As a result, the trajectory starting at a point @xmath lies on the curve

  -- -------- -- ---------
     @xmath      (3.110)
  -- -------- -- ---------

Moreover, the trajectory starting at @xmath is asymptotic as @xmath to
an equilibrium on this curve. Since @xmath is a source, the only
possibility is that the trajectory starting at @xmath converges to an
equlibrium @xmath such that @xmath . This entails that

  -- -------- --
     @xmath   
  -- -------- --

which is exactly equation ( 3.107 ).

(iii) We observe that the point @xmath given in ( 3.14 ) lies on the
straight line @xmath , and therefore, thanks to (i) here, it is an
equilibrium of the system ( 3.1 ), which corresponds to a strictly
negative eigenvalue @xmath and a null one.

Hence, by the Center Manifold Theorem (see e.g. Theorem 1 on page 16 of
[ 31 ] ), the point @xmath has a stable manifold, which has dimension
@xmath and is tangent to the eigenvector of the linearized system
associated to the strictly negative eigenvalue @xmath .

Also, the graphicality and the monotonicity properties follow from the
strict sign of @xmath and @xmath . The smoothnes of the graphs follows
from the smoothness of the center manifold. The fact that @xmath is a
consequence of the monotonicity property of @xmath and @xmath , which
ensures that the limit at @xmath exists, and the fact that this limit
has to lie on the prime integral in ( 3.110 ). The fact that @xmath
follows from formula ( 3.106 ) and the monotonicity property. Formula (
3.108 ) follows from the fact that any trajectory has to lie on the
prime integral in ( 3.110 ). ∎

To state our next result concerning the dependence of the basin of
attraction @xmath defined in ( 3.10 ) on the parameter @xmath , we give
some notation. We will make it explicit the dependence of the sets
@xmath and @xmath on the parameter @xmath , by writing explicitly @xmath
and @xmath , and we will call

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- ---------
     @xmath      (3.111)
  -- -------- -- ---------

In this setting, we have the following statements:

###### Proposition 3.20 (Dependence of the dynamics on @xmath).

-    We have that

      -- -------- -- ---------
         @xmath      (3.112)
      -- -------- -- ---------

    where @xmath and @xmath are given in ( 3.108 ).

-    It holds that

      -- -------- -- ---------
         @xmath      (3.113)
      -- -------- -- ---------

    where

      -- -------- -- ---------
         @xmath      (3.114)
      -- -------- -- ---------

We point out that the set @xmath in ( 3.112 ) does not coincide with the
basin of attraction for the system ( 3.1 ) when @xmath . Indeed, as
already mentioned, formula ( 3.106 ) in Proposition 3.19 says that for
@xmath every point in the interior of @xmath tends to a coexistence
equilibrium and thus if @xmath then @xmath does not get extinct in
finite time.

Also, as @xmath , we have that the set @xmath is determined by @xmath ,
defined in ( 3.114 ), that depends only on the parameter @xmath .

The statement in (i) of Proposition 3.20 will be a direct consequence of
the following result. Recalling the function @xmath introduced in
Propositions 3.8 and 3.14 , we express here the dependence on the
parameter @xmath by writing @xmath , @xmath , @xmath , @xmath , @xmath .
We will also denote by @xmath the stable manifold of the point @xmath
in ( 3.11 ), and by @xmath the stable manifold of the point @xmath in (
3.14 ). The key lemma is the following:

###### Lemma 3.21.

For all @xmath , we have that @xmath uniformly as @xmath , where @xmath
is the function defined in ( 3.108 ).

###### Proof.

Since we are dealing with the limit as @xmath goes to zero, throughout
this proof we will always assume that we are in the case @xmath .

Also, we denote by @xmath the flow at time @xmath of the point @xmath
associated with ( 3.1 ), and similarly by @xmath the flow at time @xmath
of the point @xmath associated with ( 3.1 ) when @xmath . With a slight
abuse of notation, we will also write @xmath , with @xmath .

Let us start by proving that

  -- -------- -- ---------
     @xmath      (3.115)
  -- -------- -- ---------

For this, we claim that, for every @xmath , if

  -- -------- -- ---------
     @xmath      (3.116)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (3.117)
  -- -------- -- ---------

then

  -- -------- -- ---------
     @xmath      (3.118)
  -- -------- -- ---------

for some @xmath , depending only on @xmath and @xmath .

Indeed, by (v) of Theorem 3.2 and ( 3.117 ), the trajectory @xmath
belongs to the set @xmath .

Moreover, we claim that

  -- -------- -- ---------
     @xmath      (3.119)
  -- -------- -- ---------

for any @xmath such that ( 3.117 ) is satisfied. To prove this, we
recall that @xmath lies on the straight line @xmath given by @xmath when
@xmath (see ( 3.21 )). Clearly, there is no point of the set @xmath
lying on @xmath , and we notice that the points in the set @xmath with
minimal distance from @xmath are given by @xmath and @xmath . Also, the
distance of the point @xmath from the straight line @xmath is given by
@xmath . Thus, the distance between @xmath and the line @xmath is
greater than @xmath , and this implies ( 3.119 ).

As a consequence of ( 3.119 ), we obtain that

  -- -------- -- ---------
     @xmath      (3.120)
  -- -------- -- ---------

and that

  -- -------- -- ---------
     @xmath      (3.121)
  -- -------- -- ---------

Now, if @xmath , then from ( 3.120 ) and ( 3.116 ) we obtain that

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

which proves ( 3.118 ) in this case.

If instead @xmath , we use ( 3.121 ) to see that

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

which completes the proof of ( 3.118 ).

Now, for any @xmath , we define

  -- -------- --
     @xmath   
  -- -------- --

Given @xmath , we define

  -- -- -- ---------
           (3.122)
  -- -- -- ---------

We remark that

  -- -------- -- ---------
     @xmath      (3.123)
  -- -------- -- ---------

Also, given @xmath , we define a tubular neighborhood @xmath of @xmath
as

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, we define

  -- -- -- ---------
           (3.124)
  -- -- -- ---------

Recalling ( 3.123 ), we have that

  -- -------- -- ---------
     @xmath      (3.125)
  -- -------- -- ---------

We remark that, as @xmath , the point @xmath in ( 3.11 ), which is a
saddle point for the dynamics of ( 3.1 ) when @xmath (recall Theorem 3.2
), tends to the point @xmath in ( 3.14 ), that belongs to the line
@xmath , which is an equilibrium point for the dynamics of ( 3.1 ) when
@xmath , according to Proposition 3.19 .

As a consequence, for every @xmath , there exists @xmath such that if
@xmath ,

  -- -------- -- ---------
     @xmath      (3.126)
  -- -------- -- ---------

This gives that the intersection of @xmath with @xmath is nonempty.

Furthermore, since @xmath , in light of Proposition 3.8 , we have that
the intersection of @xmath with @xmath is nonempty. Hence, there exists
@xmath .

We also notice that

  -- -------- -- ---------
     @xmath      (3.127)
  -- -------- -- ---------

In addition,

  -- -------- -- ---------
     @xmath      (3.128)
  -- -------- -- ---------

Also, since the origin belongs to @xmath , we have that @xmath . From
this and ( 3.128 ), we deduce that

  -- -------- -- ---------
     @xmath      (3.129)
  -- -------- -- ---------

Now, we let @xmath be as in ( 3.118 ) and we claim that there exists
@xmath such that

  -- -------- -- ---------
     @xmath      (3.130)
  -- -------- -- ---------

To check this, we argue by contradiction and we suppose that

  -- -------- --
     @xmath   
  -- -------- --

Then, for every @xmath , recalling also ( 3.126 ),

  -- -------- --
     @xmath   
  -- -------- --

and consequently ( 3.117 ) is satisfied for every @xmath .

Moreover, we observe that @xmath satisfies ( 3.116 ), and therefore,
by ( 3.118 ),

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , where we used the notation @xmath , being @xmath . As a
result,

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- --
     @xmath   
  -- -------- --

This leads to

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

which forces the trajectory to exit the region @xmath . This is against
the assumption that @xmath , and therefore the proof of ( 3.130 ) is
complete.

In light of ( 3.130 ), we can set @xmath , and we deduce from ( 3.122 )
that @xmath . We also observe that the set @xmath is invariant for the
flow with @xmath , thanks to ( 3.109 ). These observations give that
@xmath for all @xmath .

As a result, using ( 3.124 ), we conclude that

  -- -------- -- ---------
     @xmath      (3.131)
  -- -------- -- ---------

In addition, by the continuous dependence of the flow on the parameter
@xmath (see e.g. Section 2.4 in [ 60 ] , or Theorem 2.4.2 in [ 63 ] ),

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , provided that @xmath is sufficiently small, possibly in
dependence of @xmath . This fact and ( 3.131 ) entail that

  -- -------- --
     @xmath   
  -- -------- --

In particular, for all @xmath ,

  -- -------- -- ---------
     @xmath      (3.132)
  -- -------- -- ---------

We now claim that for all @xmath ,

  -- -------- -- ---------
     @xmath      (3.133)
  -- -------- -- ---------

Indeed, this is true when @xmath thanks to ( 3.126 ) and ( 3.130 ).
Hence, since the trajectory @xmath is contained in the domain where
@xmath and @xmath , thanks to ( 3.27 ), we deduce that ( 3.133 ) holds
true.

From ( 3.126 ) and ( 3.133 ), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

Using this, ( 3.129 ) and ( 3.132 ), we obtain that

  -- -------- --
     @xmath   
  -- -------- --

This and ( 3.125 ) give that ( 3.115 ) is satisfied, as desired.

One can also show that

  -- -------- -- ---------
     @xmath      (3.134)
  -- -------- -- ---------

The proof of ( 3.134 ) is similar to that of ( 3.115 ), just replacing
@xmath with @xmath (in this case the analysis near the origin is simply
omitted since the trajectory has only one limit point).

With ( 3.115 ) and ( 3.134 ) the proof of Lemma 3.21 is thereby
complete. ∎

Now we are ready to give the proof of Proposition 3.20 :

###### Proof of Proposition 3.20.

(i) We call @xmath the right-hand-side of ( 3.112 ), that is

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

and we aim at proving that @xmath .

For this, we observe that, by Lemma 3.21 , @xmath converges to @xmath
pointwise as @xmath . In particular, @xmath as @xmath .

Also, recalling ( 3.108 ), we notice that if @xmath , then @xmath ,
otherwise if @xmath then @xmath , being @xmath strictly monotone
increasing.

Furthermore, thanks to Proposition 3.16 , we know that he set @xmath is
bounded from above by the graph of the function @xmath for @xmath and
from the straight line @xmath for @xmath (that is non empty for @xmath
).

Now we claim that, for all @xmath ,

  -- -------- -- ---------
     @xmath      (3.135)
  -- -------- -- ---------

To show this, we take a point @xmath . Hence, in light of the
considerations above, we have that @xmath for any @xmath sufficiently
small, which proves ( 3.135 ).

From ( 3.135 ), we deduce that

  -- -------- -- ---------
     @xmath      (3.136)
  -- -------- -- ---------

Now we show that

  -- -------- -- ---------
     @xmath      (3.137)
  -- -------- -- ---------

For this, we take

  -- -------- --
     @xmath   
  -- -------- --

then it must hold that for every @xmath there exists @xmath such that
@xmath , namely @xmath if @xmath and @xmath if @xmath . Thus, by the
pointwise convergence, we have that @xmath if @xmath and @xmath if
@xmath , which proves ( 3.137 ).

From ( 3.136 ) and ( 3.137 ), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

as desired.

(ii) Since we deal with the limit case as @xmath , from now on we
suppose from now on that @xmath . We fix @xmath and we consider the set

  -- -------- --
     @xmath   
  -- -------- --

We claim that

  -- -------- -- ---------
     @xmath      (3.138)
  -- -------- -- ---------

for @xmath big enough, possibly in dependence of @xmath . For this, we
first analyze the component of the velocity in the inward normal
directions along the boundary of @xmath . On the side @xmath , the
trajectories cannot cross the boundary thanks to Proposition 3.1 , and
the same happens for the sides @xmath and @xmath .

Hence, it remains to check the sign of the normal derivative along the
side given by the straight line @xmath . We compute

  -- -------- --
     @xmath   
     @xmath   
              
  -- -------- --

Thus, by using that @xmath , we obtain that

  -- -------- --
     @xmath   
  -- -------- --

Notice that @xmath and @xmath , and therefore

  -- -------- --
     @xmath   
  -- -------- --

Accordingly, the normal velocity is positive for @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

These considerations, together with the fact that there are no cycles in
@xmath and the Poincaré-Bendixson Theorem (see e.g. [ 113 ] ) give that
the @xmath -limit set of any trajectory starting in the interior of
@xmath can be either an equilibrium or a union of (finitely many)
equilibria and non-closed orbits connecting these equilibria.

We remark that

  -- -- -- ---------
           (3.139)
  -- -- -- ---------

Indeed, if the @xmath -limit of a trajectory were @xmath , then this
trajectory must lie on the stable manifold of @xmath , and moreover it
must be contained in @xmath , since no trajectory can exit @xmath . On
the other hand, by Proposition 3.8 , we have that at @xmath the stable
manifold is tangent to the line

  -- -------- --
     @xmath   
  -- -------- --

Now, if we take @xmath sufficiently large, this line lies below the line
@xmath , thus providing a contradiction. Hence, the proof of ( 3.139 )
is complete.

Accordingly, since @xmath is a sink, the only possibility is that the
@xmath -limit set of any trajectory starting in the interior of @xmath
is the equilibrium @xmath . Namely, we have established ( 3.138 ).

As a consequence of ( 3.138 ), we deduce that for every @xmath there
exists @xmath such that

  -- -------- -- ---------
     @xmath      (3.140)
  -- -------- -- ---------

In addition,

  -- -------- --
     @xmath   
  -- -------- --

This and ( 3.140 ) entail that

  -- -------- --
     @xmath   
  -- -------- --

which implies the second inclusion in ( 3.113 ).

Now, to show the first inclusion in ( 3.113 ), for every @xmath we
consider the set

  -- -------- --
     @xmath   
  -- -------- --

We claim that, for all @xmath ,

  -- -------- -- ---------
     @xmath      (3.141)
  -- -------- -- ---------

For this, we first show that if @xmath is sufficiently large, possibly
in dependence of @xmath ,

  -- -------- -- ---------
     @xmath      (3.142)
  -- -------- -- ---------

Indeed, on the side @xmath the trajectory cannot exit the set, thanks to
Proposition 3.1 . On the side given by @xmath , the component of the
velocity in the direction of the outward normal is

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

which is negative if @xmath , with

  -- -------- --
     @xmath   
  -- -------- --

Hence, if @xmath , then either @xmath or @xmath for all @xmath , where
the notation in ( 3.8 ) has been used. We also notice that, for @xmath ,
the points @xmath and @xmath are the only equilibria of the system, and
there are no cycles. We have that @xmath and @xmath , thus if

  -- -- -- ---------
           (3.143)
  -- -- -- ---------

then

  -- -------- -- ---------
     @xmath      (3.144)
  -- -------- -- ---------

On the other hand, by Proposition 3.8 , we have that at @xmath the
stable manifold is tangent to the line

  -- -------- --
     @xmath   
  -- -------- --

and, if we take @xmath large enough, this line lies above the line
@xmath . This says that, for sufficiently large @xmath , the trajectory
must lie outside @xmath , and this is in contradiction with ( 3.143 ).

As a result of these considerations, we conclude that if @xmath then
@xmath , which implies ( 3.142 ).

As a consequence of ( 3.142 ), we obtain that for every @xmath there
exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

In particular for all @xmath it holds that

  -- -------- --
     @xmath   
  -- -------- --

which proves ( 3.141 ), as desired.

Then, the first inclusion in ( 3.113 ) plainly follows from ( 3.141 ). ∎

### 3.4 Analysis of the strategies for the first population

The main theorems on the winning strategy have been stated in Subsection
3.1.4 . In particular, Theorem 3.3 gives the characterization of the set
of points that have a winning strategy @xmath in ( 3.13 ), and Theorem
3.4 establishes the non equivalence of constant and non-constant
strategies when @xmath (and their equivalence when @xmath ).
Nonetheless, in Theorem 3.5 we state that Heaviside functions are enough
to construct a winning strategy for every point in @xmath .

In the following subsections we will give the proofs of these results.

#### 3.4.1 Construction of winning non-constant strategies

We want to put in light the construction of non-constant winning
strategies for the points for which constant strategies fail.

For this, we recall the notation introduced in ( 3.14 ), ( 3.18 ) and (
3.108 ), and we have the following statement:

###### Proposition 3.22.

Let @xmath . Then we have:

-    For @xmath , let @xmath be a point of the set

      -- -------- -- ---------
         @xmath      (3.145)
      -- -------- -- ---------

    Then there exist @xmath , @xmath , and @xmath , depending on @xmath
    , @xmath , and @xmath , such that the Heaviside strategy defined by

      -- -------- -- ---------
         @xmath      (3.146)
      -- -------- -- ---------

    belongs to @xmath .

-    For @xmath , let @xmath be a point of the set

      -- -------- -- ---------
         @xmath      (3.147)
      -- -------- -- ---------

    Then there exist @xmath , @xmath , and @xmath , depending on @xmath
    , @xmath , and @xmath , such that the Heaviside strategy defined by

      -- -------- --
         @xmath   
      -- -------- --

    belongs to @xmath .

###### Proof.

We start by proving the first claim in Proposition 3.22 . To this aim,
we take @xmath , and we observe that

  -- -------- --
     @xmath   
  -- -------- --

Therefore, there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Hence, setting

  -- -------- -- ---------
     @xmath      (3.148)
  -- -------- -- ---------

we see that

  -- -------- -- ---------
     @xmath      (3.149)
  -- -------- -- ---------

Now, we want to show that there exists @xmath such that, for any @xmath
and @xmath , we have that

  -- -------- -- ---------
     @xmath      (3.150)
  -- -------- -- ---------

To prove this, we first notice that

  -- -- -- ---------
           (3.151)
  -- -- -- ---------

Moreover, we set

  -- -------- --
     @xmath   
  -- -------- --

and we claim that,

  -- -- -- ---------
           (3.152)
  -- -- -- ---------

Indeed, we recall that the function @xmath defined in ( 3.26 )
represents the points in @xmath where @xmath and separates the points
where @xmath , which lie on the left of the curve described by @xmath ,
from the points where @xmath , which lie on the right of the curve
described by @xmath .

Therefore, in order to show ( 3.152 ), it is sufficient to prove that
the curve described by @xmath is contained in @xmath whenever @xmath .
For this, one computes that, if @xmath and @xmath , then

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

This completes the proof of ( 3.152 ).

Now we define

  -- -------- --
     @xmath   
  -- -------- --

and we claim that

  -- -------- -- ---------
     @xmath      (3.153)
  -- -------- -- ---------

Indeed, under the assumptions of ( 3.153 ), we deduce that

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

and this establishes the claim in ( 3.153 ).

Then, choosing

  -- -------- --
     @xmath   
  -- -------- --

we can exploit ( 3.151 ), ( 3.152 ) and ( 3.153 ) to deduce ( 3.150 ),
as desired.

Now we claim that, for any @xmath , there exists @xmath such that the
trajectory @xmath starting from @xmath satisfies

  -- -- -- ---------
           (3.154)
  -- -- -- ---------

Indeed, we define @xmath to be the first time for which @xmath . This is
a fair definition, since @xmath and @xmath is negative, and bounded away
from zero till @xmath , thanks to ( 3.151 ). Then, we see that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

thanks to ( 3.148 ) and ( 3.150 ), and this establishes ( 3.154 ).

Now we observe that

  -- -------- --
     @xmath   
  -- -------- --

due to ( 3.149 ) and ( 3.154 )

As a result, recalling Lemma 3.21 , we can choose @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Accordingly, by Proposition 3.16 , we obtain that @xmath . Hence,
applying the strategy in ( 3.146 ), we accomplish the desired result and
complete the proof of the first claim in Proposition 3.22 .

Now we focus on the proof of the second claim in Proposition 3.22 . For
this, let

  -- -------- -- ---------
     @xmath      (3.155)
  -- -------- -- ---------

and consider the trajectory @xmath starting from @xmath for the strategy
@xmath . In light of formula ( 3.106 ) of Proposition 3.19 , we have
that

  -- -------- -- ---------
     @xmath      (3.156)
  -- -------- -- ---------

We define

  -- -------- -- ---------
     @xmath      (3.157)
  -- -------- -- ---------

where the last equality can be checked starting from the value of @xmath
given in ( 3.18 ). Using the definition of @xmath in ( 3.18 ) and the
information in ( 3.109 ), we also notice that the curve given by @xmath
is a trajectory for @xmath . Moreover

  -- -------- --
     @xmath   
  -- -------- --

and, recalling ( 3.157 ) and formula ( 3.106 ) of Proposition 3.19 , we
get that the graph of @xmath is a trajectory for @xmath that converges
to @xmath as @xmath .

Also, by ( 3.155 ), we have that @xmath . Thus, since by Cauchy’s
uniqueness result for ODEs, two orbits never intersect, we have that

  -- -- -- ---------
           (3.158)
  -- -- -- ---------

Since both @xmath and @xmath belong to the line given by @xmath , from (
3.158 ) we get that

  -- -------- -- ---------
     @xmath      (3.159)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (3.160)
  -- -------- -- ---------

Thanks to ( 3.159 ) and ( 3.160 ) and recalling the values of @xmath
from ( 3.18 ) and of @xmath from ( 3.157 ), we get that

  -- -------- -- ---------
     @xmath      (3.161)
  -- -------- -- ---------

As a consequence, since the inequality in ( 3.161 ) is strict, we find
that there exists @xmath such that

  -- -------- -- ---------
     @xmath      (3.162)
  -- -------- -- ---------

Moreover, since @xmath for @xmath and @xmath , we get that @xmath is
decreasing in @xmath , and therefore @xmath .

By the strict inequality in ( 3.162 ), and claim (ii) in Proposition
3.20 , we have that @xmath , where @xmath is defined in ( 3.111 ). In
particular, we have that @xmath , for every @xmath . Consequently, there
exists @xmath such that @xmath . Therefore, applying the strategy

  -- -------- --
     @xmath   
  -- -------- --

we reach the victory. ∎

#### 3.4.2 Proof of Theorem 3.3

To avoid repeating passages in the proofs of Theorems 3.3 and 3.4 , we
first state and prove the following lemma:

###### Lemma 3.23.

If @xmath , then for all @xmath we have @xmath , where @xmath was
defined in ( 3.114 ).

###### Proof.

Let @xmath be a trajectory starting at a point in @xmath . For any
@xmath , we consider the function

  -- -------- --
     @xmath   
  -- -------- --

Notice that

  -- -------- -- ---------
     @xmath      (3.163)
  -- -------- -- ---------

In addition, we observe that

  -- -------- -- ---------
     @xmath      (3.164)
  -- -------- -- ---------

The equation in ( 3.164 ) is integrable and leads to

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.163 ), we deduce that

  -- -------- --
     @xmath   
  -- -------- --

This leads to

  -- -------- --
     @xmath   
  -- -------- --

which, recalling the definition of @xmath in ( 3.114 ), ends the proof.
∎

Now we provide the proof of Theorem 3.3 , exploiting the result obtained
in Section 3.4.1 .

###### Proof of Theorem 3.3.

(i) Let @xmath . For the sake of simplicity, we suppose that @xmath ,
and therefore the second line in ( 3.15 ) is not present (the proof of (
3.15 ) when @xmath is similar, but one has to take into account also the
set @xmath and show that it is contained in @xmath by checking the sign
of the component of the velocity field in the normal direction).

We claim that

  -- -- -- ---------
           (3.165)
  -- -- -- ---------

where @xmath was defined in ( 3.114 ) (incidentally, @xmath is precisely
the right-hand-side of equation ( 3.15 )).

From Lemma 3.23 we have that for @xmath and @xmath it holds @xmath .
Thus, to show ( 3.165 ) we just need to check that

  -- -------- -- ---------
     @xmath      (3.166)
  -- -------- -- ---------

which is equivalent to

  -- -------- -- ---------
     @xmath      (3.167)
  -- -------- -- ---------

where the superscript @xmath denotes the complement of the set in the
topology of @xmath .

First, by definition we have that

  -- -------- -- ---------
     @xmath      (3.168)
  -- -------- -- ---------

Now, we analyze the behavior of the trajectories at @xmath . By
Proposition 3.1 , no trajectory can exit @xmath from a point on @xmath .
Moreover, @xmath thanks to ( 3.168 ) and the fact that @xmath is closed
in the topology of @xmath . Hence,

  -- -- -- ---------
           (3.169)
  -- -- -- ---------

Furthermore, it holds that

  -- -------- --
     @xmath   
  -- -------- --

The velocity of a trajectory starting on the line @xmath in the
orthogonal direction pointing inward @xmath is

  -- -------- --
     @xmath   
  -- -------- --

the last equality coming from the fact that @xmath on @xmath . This
means that

  -- -- -- ---------
           (3.170)
  -- -- -- ---------

From ( 3.169 ) and ( 3.170 ), we get that no trajectory exits @xmath .
Then, by ( 3.168 ), no trajectory starting in @xmath can reach the set
@xmath , therefore @xmath and this implies that ( 3.167 ) is true. As a
result, the proof of ( 3.166 ) is established and the proof is completed
for @xmath .

(ii) Let @xmath . For the sake of simplicity, we suppose that @xmath .
Let @xmath be the set in the right-hand-side of ( 3.16 ), and

  -- -------- -- ---------
     @xmath      (3.171)
  -- -------- -- ---------

Notice that

  -- -------- -- ---------
     @xmath      (3.172)
  -- -------- -- ---------

being @xmath the set defined in ( 3.145 ).

Moreover,

  -- -------- -- ---------
     @xmath      (3.173)
  -- -------- -- ---------

thanks to Proposition 3.22 .

We also claim that

  -- -------- -- ---------
     @xmath      (3.174)
  -- -------- -- ---------

where @xmath is the set of constant functions. Indeed, if @xmath , we
have that @xmath and consequently @xmath , as long as @xmath is small
enough, due to Lemma 3.21 .

From this and Proposition 3.16 , we deduce that @xmath belongs to @xmath
, as long as @xmath is small enough, and this proves ( 3.174 ).

From ( 3.174 ) and the fact that @xmath , we obtain that

  -- -------- -- ---------
     @xmath      (3.175)
  -- -------- -- ---------

Then, as a consequence of ( 3.172 ), ( 3.173 ) and ( 3.175 ), we get
that @xmath .

Hence, we are left with proving that

  -- -------- -- ---------
     @xmath      (3.176)
  -- -------- -- ---------

For this, we show that

  -- -- -- ---------
           (3.177)
  -- -- -- ---------

To prove this, we calculate the outward normal derivative on the part of
@xmath lying on the graph of @xmath , that is

  -- -------- --
     @xmath   
  -- -------- --

By substituting @xmath we get

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

As a result, since @xmath , we have

  -- -------- -- ---------
     @xmath      (3.178)
  -- -------- -- ---------

On the part of @xmath contained on the line @xmath , the outward normal
derivative is

  -- -------- -- ---------
     @xmath      (3.179)
  -- -------- -- ---------

We also observe that, when @xmath , the condition @xmath gives that

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Therefore, when @xmath , we deduce from ( 3.179 ) that

  -- -------- --
     @xmath   
  -- -------- --

Combining this and ( 3.178 ), we obtain ( 3.177 ), as desired.

Now, by ( 3.177 ), we have that, for any value of @xmath , no trajectory
starting in @xmath can enter in @xmath , and in particular no trajectory
starting in @xmath can hit @xmath , which ends the proof of ( 3.176 ).

(iii) Let @xmath . For the sake of simplicity, we suppose that @xmath .
Let @xmath be the right-hand-side of ( 3.17 ). We observe that

  -- -------- -- ---------
     @xmath      (3.180)
  -- -------- -- ---------

where @xmath was defined in ( 3.114 ) and @xmath in ( 3.147 ). Thanks to
Proposition 3.20 , one has that @xmath , for every @xmath , and
therefore @xmath . Moreover, by the second claim in Proposition 3.22 ,
one also has that @xmath . Hence,

  -- -------- -- ---------
     @xmath      (3.181)
  -- -------- -- ---------

Accordingly, to prove equality in ( 3.181 ) and thus complete the proof
of ( 3.17 ), we need to show that @xmath . First, we prove that

  -- -------- -- ---------
     @xmath      (3.182)
  -- -------- -- ---------

Indeed, for @xmath we have @xmath , therefore @xmath for @xmath . Then,
@xmath is increasing in @xmath since it is a positive power function,
therefore @xmath for @xmath , hence @xmath for @xmath . These
observations prove ( 3.182 ).

We now prove that the component of the velocity field in the outward
normal direction with respect to @xmath is nonnegative on

  -- -- --
        
  -- -- --

To this end. we observe that on the line @xmath , the outward normal
derivative is

  -- -------- -- ---------
     @xmath      (3.183)
  -- -------- -- ---------

The first term is positive because for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for @xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

thanks to ( 3.18 ). Thus, the left hand side of ( 3.183 ) is
nonnegative, which proves that the component of the velocity field in
the outward normal direction is nonnegative on @xmath .

On the part of @xmath lying in the graph of @xmath , the component of
the velocity field in the outward normal direction is given by

  -- -------- -- ---------
     @xmath      (3.184)
  -- -------- -- ---------

Now we substitute @xmath in ( 3.184 ) and we get

  -- -------- --
     @xmath   
  -- -------- --

which leads to

  -- -------- --
     @xmath   
  -- -------- --

as desired.

As a consequence of these considerations, we find that no trajectory
starting in @xmath can enter in @xmath and therefore hit @xmath , by (
3.182 ). Hence, we conclude that @xmath , which, together with ( 3.181
), establishes ( 3.17 ). ∎

#### 3.4.3 Proof of Theorem 3.4

In order to prove Theorem 3.4 , we will establish a geometrical lemma in
order to understand the reciprocal position of the function @xmath , as
given by Propositions 3.8 and 3.14 , and the straight line where the
saddle equilibria lie. To emphasize the dependence of @xmath on the
parameter @xmath we will often use the notation @xmath . Moreover, we
recall the notation of the saddle points @xmath defined in ( 3.11 ) and
of the points @xmath given by Propositions 3.8 and 3.14 , with the
convention that

  -- -- -- ---------
           (3.185)
  -- -- -- ---------

and we state the following result:

###### Lemma 3.24.

If @xmath , then

  -- -------- -- ---------
     @xmath      (3.186)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (3.187)
  -- -------- -- ---------

If instead @xmath , then

  -- -------- -- ---------
     @xmath      (3.188)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (3.189)
  -- -------- -- ---------

Moreover equality holds in ( 3.186 ) and ( 3.188 ) if and only if either
@xmath or @xmath . Also, strict inequality holds in ( 3.187 ) and (
3.189 ) for @xmath .

###### Proof.

We focus here on the proof of ( 3.187 ), since the other inequalities
are proven in a similar way. Moreover, we deal with the case @xmath ,
being the case @xmath analogous with obvious modifications.

We suppose by contradiction that ( 3.187 ) does not hold true. Namely,
we assume that there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is continuous thanks to Propositions 3.8 , we have that

  -- -------- --
     @xmath   
  -- -------- --

Hence, we consider the largest open interval @xmath containing @xmath
and such that

  -- -------- -- ---------
     @xmath      (3.190)
  -- -------- -- ---------

Moreover, in light of ( 3.11 ), we see that

  -- -------- -- ---------
     @xmath      (3.191)
  -- -------- -- ---------

Hence, by the continuity of @xmath , we have that @xmath and

  -- -- -- ---------
           (3.192)
  -- -- -- ---------

Now, we consider the set

  -- -------- --
     @xmath   
  -- -------- --

that is non empty, thanks to ( 3.190 ). We claim that

  -- -- -- ---------
           (3.193)
  -- -- -- ---------

To prove this, we analyze the normal derivative on

  -- -------- --
     @xmath   
  -- -------- --

with the convention that @xmath does contain @xmath only if the second
possibility in ( 3.192 ) occurs.

We notice that the set @xmath is an orbit for the system, and thus the
component of the velocity in the normal direction is null. On @xmath ,
we have that the sign of the component of the velocity in the inward
normal direction is given by

  -- -------- -- ---------
     @xmath      (3.194)
  -- -------- -- ---------

Notice that for @xmath we have that

  -- -------- -- ---------
     @xmath      (3.195)
  -- -------- -- ---------

thus the sign of last term in ( 3.194 ) depends only on the quantity
@xmath . Consequently, since @xmath the sign of the component of the
velocity in the inward normal direction is positive.

Furthermore, in the case in which the second possibility in ( 3.192 )
occurs, we also check the sign of the component of the velocity in the
inward normal direction along @xmath . In this case, if @xmath then
@xmath , and therefore we find that

  -- -------- --
     @xmath   
  -- -------- --

which is positive. If instead @xmath

  -- -------- --
     @xmath   
  -- -------- --

which is positive, thanks to ( 3.195 ).

We also point out that there are no cycle in @xmath , since @xmath has a
sign. These considerations and the Poincaré-Bendixson Theorem (see e.g.
[ 113 ] ) give that the @xmath -limit set of @xmath can be either an
equilibrium or a union of (finitely many) equilibria and non-closed
orbits connecting these equilibria. Since @xmath and @xmath do not
belong to the closure of @xmath , in this case the only possibility is
that the @xmath -limit is the equilibrium @xmath . Consequently, we have
that @xmath , and that ( 3.193 ) is satisfied.

Accordingly, in light of ( 3.193 ), we have that the set @xmath is
contained in the stable manifold of @xmath , which is in contradiction
with the definition of @xmath . Hence, ( 3.187 ) is established, as
desired.

Now we show that strict inequality holds true in ( 3.187 ) if @xmath .
To this end, we suppose by contradiction that there exists @xmath such
that

  -- -------- -- ---------
     @xmath      (3.196)
  -- -------- -- ---------

Now, since ( 3.187 ) holds true, we have that the line @xmath is tangent
to the curve @xmath at @xmath , and therefore at this point the
components of the velocity along the normal directions to the curve and
to the line coincide. On the other hand, the normal derivative at a
point on the line has a sign, as computed in ( 3.194 ), while the normal
derivative to @xmath is @xmath because the curve is an orbit.

This, together with ( 3.191 ), proves that equality in ( 3.187 ) holds
true if @xmath , but strict inequality holds true for all @xmath , and
thus the proof of Lemma 3.24 is complete. ∎

For each @xmath , we define @xmath as the unique intersection of the
graph of @xmath with the line @xmath , that is the solution of the
system

  -- -------- -- ---------
     @xmath      (3.197)
  -- -------- -- ---------

We recall that the above intersection is unique since the function
@xmath is increasing. Also, by construction,

  -- -------- -- ---------
     @xmath      (3.198)
  -- -------- -- ---------

Now, recalling ( 3.11 ) and making explicit the dependence on @xmath by
writing @xmath (with the convention in ( 3.185 )), we give the following
result:

###### Lemma 3.25.

We have that:

1.   For @xmath , for all @xmath it holds that

      -- -------- -- ---------
         @xmath      (3.199)
      -- -------- -- ---------

2.   For @xmath , for all @xmath it holds that

      -- -------- -- ---------
         @xmath      (3.200)
      -- -------- -- ---------

###### Proof.

We claim that

  -- -------- -- ---------
     @xmath      (3.201)
  -- -------- -- ---------

Indeed, when @xmath , we have that @xmath and thus ( 3.201 ) holds true.
If instead @xmath , by ( 3.11 ) and ( 3.197 ) we have that

  -- -------- -- ---------
     @xmath      (3.202)
  -- -------- -- ---------

Also, since @xmath is increasing, we have that the map @xmath is
strictly increasing. Consequently, we deduce from ( 3.202 ) that ( 3.201
) holds true in this case as well.

Now we suppose that @xmath and we prove ( 3.199 ). For this, we claim
that, for every @xmath and every @xmath ,

  -- -------- -- ---------
     @xmath      (3.203)
  -- -------- -- ---------

To check this, we distinguish two cases. If @xmath , then for all @xmath

  -- -------- -- ---------
     @xmath      (3.204)
  -- -------- -- ---------

By ( 3.204 ) and formula ( 3.187 ) in Lemma 3.24 , we have that

  -- -------- -- ---------
     @xmath      (3.205)
  -- -------- -- ---------

If instead @xmath , then @xmath and for all @xmath we have @xmath . As a
consequence,

  -- -------- -- ---------
     @xmath      (3.206)
  -- -------- -- ---------

The claim in ( 3.203 ) thus follows from ( 3.205 ) and ( 3.206 ).

Furthermore, by Propositions 3.8 and 3.14 ,

  -- -------- -- ---------
     @xmath      (3.207)
  -- -------- -- ---------

Moreover, for all @xmath and @xmath it holds that, when @xmath ,

  -- -------- -- ---------
     @xmath      (3.208)
  -- -------- -- ---------

Now, we establish that

  -- -------- -- ---------
     @xmath      (3.209)
  -- -------- -- ---------

Indeed, for the values of @xmath , @xmath and @xmath as in ( 3.209 ) we
have that @xmath and hence

  -- -------- -- ---------
     @xmath      (3.210)
  -- -------- -- ---------

Moreover, by formula ( 3.187 ) in Lemma 3.24 , for @xmath and @xmath and
we have that

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.210 ), we see that ( 3.209 ) plainly follows, as
desired.

As a consequence of ( 3.208 ) and ( 3.209 ), one deduces that, for all
@xmath , @xmath and @xmath ,

  -- -------- -- ---------
     @xmath      (3.211)
  -- -------- -- ---------

Now, we define

  -- -------- -- ---------
     @xmath      (3.212)
  -- -------- -- ---------

and we claim that

  -- -- -- ---------
           (3.213)
  -- -- -- ---------

Indeed, since @xmath is a trajectory for ( 3.1 ), if @xmath is a
solution of ( 3.1 ), we have that @xmath , whence

  -- -------- -- ---------
     @xmath      (3.214)
  -- -------- -- ---------

Then, we let @xmath and we notice that @xmath coincides also with @xmath
. Hence, we take trajectories of the system with parameter @xmath and
@xmath starting at @xmath , and by ( 3.211 ) we obtain that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which establishes ( 3.213 ).

Now we claim that

  -- -------- -- ---------
     @xmath      (3.215)
  -- -------- -- ---------

Indeed, if @xmath , we deduce from ( 3.203 ) that @xmath and therefore (
3.215 ) holds true with @xmath . If instead @xmath , we have that @xmath
and we deduce from ( 3.203 ) and ( 3.207 ) that @xmath and @xmath , from
which ( 3.215 ) follows by choosing @xmath with @xmath sufficiently
small.

Now we claim that

  -- -------- -- ---------
     @xmath      (3.216)
  -- -------- -- ---------

To prove this, in light of ( 3.215 ), it suffices to check that @xmath
for every @xmath . Suppose not. Then there exists @xmath such that
@xmath for all @xmath and @xmath . This gives that @xmath . But this
inequality is in contradiction with ( 3.213 ) and therefore the proof
of ( 3.216 ) is complete.

The desired claim in ( 3.199 ) follows easily from ( 3.216 ), hence we
focus now on the proof of ( 3.200 ).

To this end, we take @xmath and we claim that, for every @xmath and
every @xmath ,

  -- -------- -- ---------
     @xmath      (3.217)
  -- -------- -- ---------

To prove this, we first notice that, if @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

Hence by ( 3.188 ) in Lemma 3.24 we have

  -- -------- --
     @xmath   
  -- -------- --

and this establishes ( 3.217 ) when @xmath . Thus, we now focus on the
case @xmath . In this situation, we have that @xmath and accordingly
@xmath , that completes the proof of ( 3.217 ).

In addition, by Propositions 3.8 and 3.14 we have that

  -- -------- -- ---------
     @xmath      (3.218)
  -- -------- -- ---------

Moreover, for @xmath , if @xmath we have that @xmath , thanks to the
monotonicity of @xmath , and, as a result,

  -- -------- -- ---------
     @xmath      (3.219)
  -- -------- -- ---------

Now we claim that, for all @xmath , @xmath and @xmath , we have

  -- -------- -- ---------
     @xmath      (3.220)
  -- -------- -- ---------

Indeed, by the monotonicity of @xmath , in this situation we have that
@xmath , and therefore, by ( 3.197 ),

  -- -------- -- ---------
     @xmath      (3.221)
  -- -------- -- ---------

Moreover, by ( 3.189 ) in Lemma ( 3.24 ), we have that @xmath , and
hence @xmath . Combining this inequality with ( 3.221 ), we obtain (
3.220 ), as desired.

Now, by ( 3.219 ), for all @xmath , @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and then, by ( 3.220 ),

  -- -------- -- ---------
     @xmath      (3.222)
  -- -------- -- ---------

Now we recall the definition of @xmath in ( 3.212 ) and we claim that

  -- -- -- ---------
           (3.223)
  -- -- -- ---------

To prove this, we let @xmath , we notice that @xmath , we recall ( 3.214
) and apply it to a trajectory starting at @xmath , thus finding that

  -- -------- --
     @xmath   
  -- -------- --

This and ( 3.222 ) yield that

  -- -------- --
     @xmath   
  -- -------- --

which proves the desired claim in ( 3.223 ).

We now point out that

  -- -------- -- ---------
     @xmath      (3.224)
  -- -------- -- ---------

Indeed, if @xmath , this claim follows directly from ( 3.203 ) by
choosing @xmath , while if @xmath , the claim follows from ( 3.203 )
and ( 3.213 ) by choosing @xmath with @xmath sufficiently small.

Now we claim that

  -- -------- -- ---------
     @xmath      (3.225)
  -- -------- -- ---------

Indeed, by ( 3.224 ), we know that the claim is true for all @xmath .
Then, the claim for @xmath can be proved by contradiction, supposing
that there exists @xmath such that @xmath for all @xmath and @xmath .
This gives that @xmath , which is in contradiction with ( 3.213 ).

Having completed the proof of ( 3.225 ), one can use it to obtain the
desired claim in ( 3.200 ). ∎

Now we perform the proof of Theorem 3.4 , analyzing separately the cases
@xmath , @xmath and @xmath .

###### Proof of Theorem 3.4, case @xmath.

We notice that

  -- -------- -- ---------
     @xmath      (3.226)
  -- -------- -- ---------

since @xmath .

Also, from Theorem 3.3 , part (i), we get that @xmath , where @xmath was
defined in ( 3.114 ). On the other hand, by Lemma 3.23 , we know that
for @xmath and for all @xmath we have @xmath . But since every constant
@xmath belongs to the set @xmath , we have @xmath . This shows that
@xmath , and together with ( 3.226 ) concludes the proof. ∎

###### Proof of Theorem 3.4, case @xmath.

We notice that

  -- -------- -- ---------
     @xmath      (3.227)
  -- -------- -- ---------

since @xmath . To prove that the inclusion is strict, we aim to find a
point @xmath . Namely, we have to prove that there exists @xmath such
that, for all constant strategies @xmath , we have that @xmath , that
is, by the characterization in Proposition 3.16 , it must hold true that
@xmath and @xmath .

To do this, we define

  -- -- -- ---------
           (3.228)
  -- -- -- ---------

By inspection, one can see that @xmath if and only if @xmath . We point
out that, by (ii) of Theorem 3.3 , for @xmath and @xmath , a point
@xmath belongs to @xmath if and only if @xmath . Here @xmath is defined
in ( 3.14 ). We underline that the interval @xmath is non empty since

  -- -------- -- ---------
     @xmath      (3.229)
  -- -------- -- ---------

Now we point out that

  -- -------- -- ---------
     @xmath      (3.230)
  -- -------- -- ---------

Indeed, by ( 3.228 ) we already know that @xmath , thus if @xmath the
inequality in ( 3.230 ) is true. On the other hand, when @xmath we have
that @xmath . This and ( 3.227 ) give that @xmath . Hence, in view of (
3.16 ), we deduce that @xmath . In particular, we find that @xmath , and
therefore ( 3.230 ) is true also in this case.

With this notation, we claim the existence of a value @xmath such that
for all @xmath we have @xmath . That is, we prove now that there exists
@xmath such that

  -- -------- -- ---------
     @xmath      (3.231)
  -- -------- -- ---------

The strategy is to study two cases separately, namely we prove ( 3.231 )
for sufficiently small values of @xmath and then for the other values of
@xmath .

To prove ( 3.231 ) for small values of @xmath , we start by looking at
the limit function @xmath defined in ( 3.108 ). One observes that

  -- -------- -- ---------
     @xmath      (3.232)
  -- -------- -- ---------

Moreover, for all @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

Hence, using the fundamental theorem of calculus on the continuous
functions @xmath and @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

Then, the quantity

  -- -------- --
     @xmath   
  -- -------- --

is positive and we have

  -- -------- -- ---------
     @xmath      (3.233)
  -- -------- -- ---------

Now, by the uniform convergence of @xmath to @xmath given by Lemma 3.21
, we know that there exists @xmath such that, if @xmath ,

  -- -------- -- ---------
     @xmath      (3.234)
  -- -------- -- ---------

By this and ( 3.233 ), we obtain that

  -- -------- -- ---------
     @xmath      (3.235)
  -- -------- -- ---------

We remark that formula ( 3.235 ) will give the desired claim in ( 3.231
) for conveniently small values of @xmath .

We are now left with considering the case @xmath . To this end,
recalling ( 3.11 ), ( 3.197 ), by the first statement in Lemma 3.25 ,
used here with @xmath , we get

  -- -------- -- ---------
     @xmath      (3.236)
  -- -------- -- ---------

Now we observe that

  -- -------- -- ---------
     @xmath      (3.237)
  -- -------- -- ---------

Indeed, suppose not, namely

  -- -------- -- ---------
     @xmath      (3.238)
  -- -------- -- ---------

Then, by the monotonicity of @xmath , we have that @xmath . This and (
3.236 ) yield that @xmath . Hence, the monotonicity of @xmath gives that
@xmath . This and ( 3.197 ) lead to @xmath , that is @xmath . From this
inequality, using again ( 3.238 ), we deduce that @xmath . This is in
contradiction with ( 3.201 ) and thus the proof of ( 3.237 ) is
complete.

We also notice that

  -- -------- -- ---------
     @xmath      (3.239)
  -- -------- -- ---------

Indeed, suppose not, say

  -- -------- -- ---------
     @xmath      (3.240)
  -- -------- -- ---------

Then, by ( 3.237 ), we have that @xmath and therefore we can apply (
3.236 ) to say that @xmath . Also, by the monotonicity of @xmath , we
have that @xmath .

With these items of information and ( 3.197 ), we find that

  -- -------- --
     @xmath   
  -- -------- --

and accordingly @xmath . This is in contradiction with ( 3.240 ) and
establishes ( 3.239 ).

Moreover, by ( 3.11 ) and ( 3.14 ), we know that @xmath , for every
@xmath . Therefore, setting @xmath , we have that @xmath . Thus, we are
in the position of using the first statement in Lemma 3.25 with @xmath
and deduce that

  -- -------- -- ---------
     @xmath      (3.241)
  -- -------- -- ---------

We also remark that

  -- -------- -- ---------
     @xmath      (3.242)
  -- -------- -- ---------

Indeed, up to a subsequence we can assume that @xmath as @xmath , for
some @xmath . Also, by ( 3.197 ),

  -- -------- --
     @xmath   
  -- -------- --

and then the uniform convergence of @xmath in Lemma 3.21 yields that

  -- -------- --
     @xmath   
  -- -------- --

This and ( 3.197 ) lead to @xmath . Since

  -- -------- -- ---------
     @xmath      (3.243)
  -- -------- -- ---------

in virtue of ( 3.14 ), we thus conclude that @xmath and the proof of (
3.242 ) is thereby complete.

As a consequence of ( 3.242 ), we have that @xmath as @xmath . Hence,
using again the uniform convergence of @xmath in Lemma 3.21 , we obtain
that @xmath . From this and ( 3.241 ), we conclude that

  -- -------- -- ---------
     @xmath      (3.244)
  -- -------- -- ---------

Now we claim that

  -- -------- -- ---------
     @xmath      (3.245)
  -- -------- -- ---------

Indeed, suppose, by contradiction, that

  -- -------- -- ---------
     @xmath      (3.246)
  -- -------- -- ---------

Then, the monotonicity of @xmath , together with ( 3.243 ) and ( 3.244
), gives that

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.246 ) we deduce that @xmath . In particular, we have
that @xmath . Accordingly, by ( 3.187 ),

  -- -------- --
     @xmath   
  -- -------- --

As a consequence,

  -- -------- --
     @xmath   
  -- -------- --

and this is in contradiction with ( 3.14 ). The proof of ( 3.245 ) is
thereby complete.

As a byproduct of ( 3.243 ) and ( 3.245 ), we have that

  -- -------- -- ---------
     @xmath      (3.247)
  -- -------- -- ---------

Similarly, by means of ( 3.239 ),

  -- -------- -- ---------
     @xmath      (3.248)
  -- -------- -- ---------

In light of ( 3.239 ), ( 3.245 ), ( 3.247 ) and ( 3.248 ), we can write
that

  -- -------- -- ---------
     @xmath      (3.249)
  -- -------- -- ---------

Now, to complete the proof of ( 3.231 ) when @xmath , we consider two
cases depending on the order of @xmath and @xmath . If @xmath , by (
3.249 ) we have that @xmath and @xmath . Then,

  -- -------- -- ---------
     @xmath      (3.250)
  -- -------- -- ---------

thanks to the monotonicity of @xmath , ( 3.236 ) and ( 3.249 ). We
define

  -- -------- --
     @xmath   
  -- -------- --

which is positive thanks to ( 3.249 ). From ( 3.250 ), we get that

  -- -------- -- ---------
     @xmath      (3.251)
  -- -------- -- ---------

This formula proves the claim in ( 3.231 ) for @xmath and @xmath .

If instead @xmath , then we proceed as follows. By ( 3.249 ) we have

  -- -------- -- ---------
     @xmath      (3.252)
  -- -------- -- ---------

Now we set

  -- -------- --
     @xmath   
  -- -------- --

Using the definition of @xmath in ( 3.228 ), we see that

  -- -------- --
     @xmath   
  -- -------- --

and accordingly @xmath is positive, due to ( 3.249 ).

From ( 3.252 ) we have

  -- -------- -- ---------
     @xmath      (3.253)
  -- -------- -- ---------

Now we show that, on any trajectory @xmath lying on the graph of @xmath
, it holds that

  -- -------- -- ---------
     @xmath      (3.254)
  -- -------- -- ---------

To prove this, we first observe that @xmath , thanks to ( 3.201 ).
Hence, we can exploit formula ( 3.187 ) of Lemma 3.24 and get that

  -- -------- -- ---------
     @xmath      (3.255)
  -- -------- -- ---------

Also, by the monotonicity of @xmath and ( 3.197 ),

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.255 ) it follows that

  -- -------- --
     @xmath   
  -- -------- --

provided that @xmath , and this proves ( 3.254 ).

In addition, for such a trajectory @xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

provided that @xmath .

From this and ( 3.254 ), we get

  -- -------- --
     @xmath   
  -- -------- --

provided that @xmath .

Consequently, taking as initial datum of the trajectory an arbitrary
point @xmath with @xmath , we can write that, for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

As a result, integrating and using ( 3.236 ), for all @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Then, making use ( 3.253 ), for @xmath ,

  -- -------- -- ---------
     @xmath      (3.256)
  -- -------- -- ---------

Also, recalling ( 3.249 ) and the monotonicity of @xmath , we see that
@xmath . Combining this and ( 3.256 ), we deduce that

  -- -------- -- ---------
     @xmath      (3.257)
  -- -------- -- ---------

We also observe that if @xmath , then the monotonicity of @xmath yields
that @xmath . It follows from this and ( 3.253 ) that @xmath . This and
the monotonicity of @xmath give that

  -- -------- --
     @xmath   
  -- -------- --

Comparing this with ( 3.257 ), we obtain

  -- -------- --
     @xmath   
  -- -------- --

and therefore

  -- -------- -- ---------
     @xmath      (3.258)
  -- -------- -- ---------

Now, in view of ( 3.230 ), we have that @xmath . Consequently, we can
utilize ( 3.258 ) with @xmath and find that

  -- -------- -- ---------
     @xmath      (3.259)
  -- -------- -- ---------

which gives ( 3.231 ) in the case @xmath and @xmath (say, in this case
with @xmath ).

That is, by ( 3.235 ), ( 3.251 ) and ( 3.259 ) we obtain that ( 3.231 )
holds true for

  -- -------- --
     @xmath   
  -- -------- --

If we choose @xmath we have that

  -- -------- -- ---------
     @xmath      (3.260)
  -- -------- -- ---------

This completes the proof of Theorem 3.4 when @xmath , in light of the
characterizations of @xmath and @xmath from Proposition 3.16 and Theorem
3.3 , respectively. ∎

Now we focus on the case @xmath .

###### Proof of Theorem 3.4, case @xmath.

As before, the inclusion @xmath is trivial since @xmath . To prove that
it is strict, we aim to find a point @xmath such that @xmath . Thus, we
have to prove that there exists @xmath such that, for all constant
strategies @xmath , we have that @xmath .

To this end, using the characterizations given in Proposition 3.16 and
Theorem 3.3 , we claim that

  -- -------- -- ---------
     @xmath      (3.261)
  -- -------- -- ---------

For this, we let

  -- -------- --
     @xmath   
  -- -------- --

By ( 3.18 ) one sees that

  -- -------- -- ---------
     @xmath      (3.262)
  -- -------- -- ---------

In addition, we point out that

  -- -------- -- ---------
     @xmath      (3.263)
  -- -------- -- ---------

Indeed, since @xmath , if @xmath the desired inequality is obvious. If
instead @xmath we have that @xmath . Hence, by ( 3.17 ), it follows that
@xmath , which leads to ( 3.263 ), as desired.

Now we claim that there exists @xmath such that

  -- -------- -- ---------
     @xmath      (3.264)
  -- -------- -- ---------

We first show some preliminary facts for @xmath . For all @xmath , we
have that @xmath . Owing to the characterization of @xmath from
Proposition 3.16 and of @xmath from Theorem 3.3 (which can be used here,
thanks to ( 3.262 ) and ( 3.263 )), we get that

  -- -------- -- ---------
     @xmath      (3.265)
  -- -------- -- ---------

This is true in particular for @xmath .

We choose

  -- -- -- ---------
           (3.266)
  -- -- -- ---------

and we prove ( 3.264 ) by treating separately the cases @xmath and
@xmath .

We first consider the case @xmath . We let @xmath be a trajectory for (
3.1 ) lying on @xmath and we show that

  -- -------- -- ---------
     @xmath      (3.267)
  -- -------- -- ---------

To check this, we observe that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where the last inequality is true thanks to the hypothesis @xmath and
the definition of @xmath in ( 3.266 ). This proves ( 3.267 ).

Moreover, for @xmath we have @xmath . From this, ( 3.267 ) and the
invariance of @xmath for the flow, we get

  -- -------- -- ---------
     @xmath      (3.268)
  -- -------- -- ---------

provided that @xmath and @xmath .

For this reason and ( 3.265 ), we get

  -- -------- -- ---------
     @xmath      (3.269)
  -- -------- -- ---------

provided that @xmath and @xmath .

Furthermore, thanks to the choice of @xmath in ( 3.266 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Since also @xmath , by ( 3.269 ) we deduce that

  -- -------- -- ---------
     @xmath      (3.270)
  -- -------- -- ---------

provided that @xmath and @xmath .

In particular, given any @xmath , we can take a trajectory starting at
@xmath and deduce from ( 3.270 ) that

  -- -------- --
     @xmath   
  -- -------- --

whenever @xmath . We stress that, in light of ( 3.262 ), we can take
@xmath in the above chain of inequalities, concluding that

  -- -------- --
     @xmath   
  -- -------- --

We rewrite this in the form

  -- -------- -- ---------
     @xmath      (3.271)
  -- -------- -- ---------

We define

  -- -------- -- ---------
     @xmath      (3.272)
  -- -------- -- ---------

that is positive thanks to the last inequality in ( 3.271 ). Then by the
first inequality in ( 3.271 ) we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, using again the last inequality in ( 3.271 ), we obtain that

  -- -------- -- ---------
     @xmath      (3.273)
  -- -------- -- ---------

which gives the claim in ( 3.264 ) for the case @xmath .

Now we treat the case @xmath . We claim that

  -- -------- -- ---------
     @xmath      (3.274)
  -- -------- -- ---------

Here, we are using the notation @xmath to denote the point @xmath when
@xmath . To prove ( 3.274 ) we argue as follows. Since @xmath , by
Propositions 3.8 and 3.14 we have

  -- -------- -- ---------
     @xmath      (3.275)
  -- -------- -- ---------

Moreover, since the graph of @xmath is a parametrization of a trajectory
for ( 3.1 ) with @xmath , we have that @xmath . Hence, at all points
@xmath with @xmath and @xmath we have

  -- -------- -- ---------
     @xmath      (3.276)
  -- -------- -- ---------

We stress that the denominator in the right hand side of ( 3.276 ) is
strictly positive, since @xmath and @xmath .

In addition, we have that

  -- -------- -- ---------
     @xmath      (3.277)
  -- -------- -- ---------

Also,

  -- -------- --
     @xmath   
  -- -------- --

thanks to ( 3.262 ) and ( 3.263 ). Hence, we can exploit formula ( 3.189
) in Lemma 3.24 with the strict inequality, thus obtaining that

  -- -------- -- ---------
     @xmath      (3.278)
  -- -------- -- ---------

Moreover, by ( 3.265 ),

  -- -------- --
     @xmath   
  -- -------- --

Therefore, using the latter estimate and ( 3.278 ) into ( 3.277 ), we
get that

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.276 ), we have that

  -- -------- --
     @xmath   
  -- -------- --

This, together with ( 3.275 ) and the fact that @xmath , gives

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . This inequality yields that

  -- -------- -- ---------
     @xmath      (3.279)
  -- -------- -- ---------

Now, to complete the proof of ( 3.274 ) we argue by contradiction and
suppose that the claim in ( 3.274 ) is false, hence

  -- -------- -- ---------
     @xmath      (3.280)
  -- -------- -- ---------

Thus, by ( 3.279 ), the monotonicity of @xmath and the definition of
@xmath given in ( 3.197 ), we get

  -- -------- --
     @xmath   
  -- -------- --

which is in contraddiction with ( 3.280 ). Hence, ( 3.274 ) holds true,
as desired.

Also, by the second statement in Lemma 3.25 , used here with @xmath ,

  -- -------- -- ---------
     @xmath      (3.281)
  -- -------- -- ---------

We claim that

  -- -------- -- ---------
     @xmath      (3.282)
  -- -------- -- ---------

Indeed, suppose, by contradiction, that

  -- -------- -- ---------
     @xmath      (3.283)
  -- -------- -- ---------

Then, by the monotonicity of @xmath and ( 3.281 ), used here with @xmath
, we find that

  -- -------- --
     @xmath   
  -- -------- --

This entails that @xmath , which is in contradiction with ( 3.283 ), and
thus establishes ( 3.282 ).

We note in addition that

  -- -------- -- ---------
     @xmath      (3.284)
  -- -------- -- ---------

thanks to the definition of @xmath and ( 3.274 ).

Similarly, by ( 3.282 ),

  -- -------- -- ---------
     @xmath      (3.285)
  -- -------- -- ---------

Collecting the pieces of information in ( 3.274 ), ( 3.282 ), ( 3.284 )
and ( 3.285 ), we thereby conclude that, for all @xmath ,

  -- -------- -- ---------
     @xmath      (3.286)
  -- -------- -- ---------

Now we consider two cases depending on the order of @xmath and @xmath .
If @xmath , by ( 3.286 ) we have @xmath and @xmath . Accordingly, for
@xmath , by ( 3.286 ) and ( 3.281 ) we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, we can define

  -- -------- --
     @xmath   
  -- -------- --

and observe that @xmath is positive by ( 3.286 ), thus obtaining that

  -- -------- -- ---------
     @xmath      (3.287)
  -- -------- -- ---------

This is the desired claim in ( 3.264 ) for @xmath and @xmath .

If instead @xmath , we consider the function

  -- -------- --
     @xmath   
  -- -------- --

and we claim that

  -- -------- -- ---------
     @xmath      (3.288)
  -- -------- -- ---------

To prove this, we recall ( 3.286 ) and the fact that @xmath is an
increasing function to see that

  -- -------- -- ---------
     @xmath      (3.289)
  -- -------- -- ---------

Now we remark that

  -- -------- --
     @xmath   
  -- -------- --

and therefore @xmath . Notice also that @xmath , thanks to ( 3.263 ). As
a result, we find that @xmath by inequality ( 3.189 ) in Lemma 3.24 .
Therefore, if @xmath and @xmath , then

  -- -- --
        
  -- -- --

Using this and ( 3.219 ), we deduce that, if @xmath , @xmath and @xmath
,

  -- -------- -- ---------
     @xmath      (3.290)
  -- -------- -- ---------

Now we take @xmath , @xmath and suppose that @xmath , we consider an
orbit @xmath lying on @xmath with @xmath , and we notice that, by (
3.219 ) and ( 3.290 ),

  -- -------- -- ---------
     @xmath      (3.291)
  -- -------- -- ---------

To complete the proof of ( 3.288 ), we define

  -- -------- --
     @xmath   
  -- -------- --

and we claim that for every @xmath there exists @xmath such that

  -- -- -- ---------
           (3.292)
  -- -- -- ---------

Indeed, by ( 3.289 ), we know that @xmath . Thus, if @xmath then we can
choose @xmath and obtain ( 3.292 ). If instead @xmath , we have that
@xmath and thus we can exploit ( 3.291 ) and find that @xmath , from
which we obtain ( 3.292 ).

Now we claim that, for every @xmath and @xmath ,

  -- -------- -- ---------
     @xmath      (3.293)
  -- -------- -- ---------

For this, given @xmath , we define

  -- -------- --
     @xmath   
  -- -------- --

We remark that @xmath , thanks to ( 3.292 ) and therefore @xmath is well
defined. We have that

  -- -------- -- ---------
     @xmath      (3.294)
  -- -------- -- ---------

otherwise we would have that @xmath and thus @xmath , thanks to ( 3.291
), which would contradict the maximality of @xmath . Now, the claim in (
3.293 ) plainly follows from ( 3.294 ).

We notice that by the inequalities in ( 3.286 ) we have

  -- -------- -- ---------
     @xmath      (3.295)
  -- -------- -- ---------

Then, we define

  -- -------- -- ---------
     @xmath      (3.296)
  -- -------- -- ---------

that is positive thanks to ( 3.295 ). We get that

  -- -------- -- ---------
     @xmath      (3.297)
  -- -------- -- ---------

From this and ( 3.288 ), we conclude that

  -- -------- -- ---------
     @xmath      (3.298)
  -- -------- -- ---------

By ( 3.273 ), ( 3.287 ) and ( 3.298 ) we have that ( 3.264 ) is true for
@xmath .

This also establishes the claim in ( 3.261 ), and the proof is
completed. ∎

#### 3.4.4 Proof of Theorem 3.5

Now, we can complete the proof of Theorem 3.5 by building on the
previous work.

###### Proof of Theorem 3.5.

Since the class of Heaviside functions @xmath is contained in the class
of piecewise continuous functions @xmath , we have that

  -- -------- -- ---------
     @xmath      (3.299)
  -- -------- -- ---------

hence we are left with proving the converse inclusion. We treat
separately the cases @xmath , @xmath and @xmath .

If @xmath , the desired claim follows from Theorem 3.4 , part (i).

If @xmath , we deduce from ( 3.16 ) and ( 3.172 ) that

  -- -------- -- ---------
     @xmath      (3.300)
  -- -------- -- ---------

where @xmath has been defined in ( 3.145 ) and @xmath in ( 3.171 ).

Moreover, by ( 3.174 ), we have that

  -- -------- -- ---------
     @xmath      (3.301)
  -- -------- -- ---------

Also, in Proposition 3.22 we construct a Heaviside winning strategy for
every point in @xmath . Accordingly, it follows that @xmath . This, (
3.300 ) and ( 3.301 ) entail that @xmath , which completes the proof of
Theorem 3.5 when @xmath .

Hence, we now focus on the case @xmath . By ( 3.17 ) and ( 3.180 ),

  -- -------- -- ---------
     @xmath      (3.302)
  -- -------- -- ---------

where @xmath was defined in ( 3.114 ) and @xmath in ( 3.147 ).

For every point @xmath there exists @xmath that is a constant winning
strategy for @xmath , thanks to Proposition 3.20 , therefore @xmath .
Moreover, in Proposition 3.22 for every point @xmath we constructed a
Heaviside winning strategy, whence @xmath . In light of these
observations and ( 3.302 ), we see that also in this case @xmath and the
proof is complete. ∎

#### 3.4.5 Bounds on winning initial positions under pointwise
constraints for the possible strategies

This subsection is dedicated to the analysis of @xmath when we put some
constraints on @xmath . In particular, we consider @xmath with @xmath
and the set @xmath of the functions @xmath with @xmath for all @xmath .
We will prove Theorem 3.6 via a technical proposition giving informative
bounds on @xmath .

For this, we denote by @xmath the point @xmath introduced in ( 3.11 )
when @xmath for all @xmath (this when @xmath , and we use the convention
that @xmath when @xmath ). In this setting, we have the following result
obtaining explicit bounds on the favorable set @xmath :

###### Proposition 3.26.

Let @xmath with @xmath and

  -- -------- -- ---------
     @xmath      (3.303)
  -- -------- -- ---------

Then

-    If @xmath , we have

      -- -------- -- ---------
         @xmath      (3.304)
      -- -------- -- ---------

    where @xmath is the continuous function given by

      -- -------- --
         @xmath   
      -- -------- --

    with the convention that the first interval is empty if @xmath , the
    second interval is empty if @xmath , and @xmath , @xmath and @xmath
    take the following values:

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

-    If @xmath , we have

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath is the continuous function given by

      -- -- --
            
      -- -- --

    for the following values:

      -- -------- --
         @xmath   
         @xmath   
      -- -------- --

We observe that it might be that for some @xmath we have @xmath or
@xmath . In this case, the above proposition would produce the trivial
result that @xmath . On the other hand, a suitable choice of @xmath
would lead to nontrivial consequences entailing, in particular, the
proof of Theorem 3.6 .

###### Proof of Proposition 3.26.

We start by proving the claim in (i). For this, we will show that

  -- -------- -- ---------
     @xmath      (3.305)
  -- -------- -- ---------

where @xmath is the complement of @xmath in the topology of @xmath . We
remark that once ( 3.305 ) is established, then the desired claim in (
3.304 ) plainly follows by taking the complement sets.

To prove ( 3.305 ) we first show that

  -- -------- -- ---------
     @xmath      (3.306)
  -- -------- -- ---------

Notice, as a byproduct, that the above inequalities also give that
@xmath is well defined. To prove ( 3.306 ) we notice that, by ( 3.11 ),
( 3.14 ) and ( 3.185 ),

  -- -------- --
     @xmath   
  -- -------- --

(and actually the first inequality is strict if @xmath ). Next, one can
check that, since @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, since @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

These observations prove ( 3.306 ), as desired.

Now we point out that

  -- -- -- ---------
           (3.307)
  -- -- -- ---------

Indeed,

  -- -------- -- ---------
     @xmath      (3.308)
  -- -------- -- ---------

Furthermore, by the definitions of @xmath and @xmath we see that

  -- -------- -- ---------
     @xmath      (3.309)
  -- -------- -- ---------

Moreover, from the definition of @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Combining this and ( 3.309 ), we deduce that

  -- -------- -- ---------
     @xmath      (3.310)
  -- -------- -- ---------

This observation and ( 3.308 ) entail the desired claim in ( 3.307 ).

Next, we show that

  -- -------- -- ---------
     @xmath      (3.311)
  -- -------- -- ---------

To prove this, we note that for @xmath the function is an exponential
times the positive constant @xmath , hence is positive. If @xmath then
@xmath is a linear function and it is positive since @xmath . On @xmath
, @xmath coincide with a linear function with positive angular
coefficient, hence we have

  -- -------- --
     @xmath   
  -- -------- --

By inspection one can check that @xmath . Hence, in the interval @xmath
we have

  -- -------- --
     @xmath   
  -- -------- --

This completes the proof of ( 3.311 ).

Let us notice that, as a consequence of ( 3.311 ),

  -- -------- -- ---------
     @xmath      (3.312)
  -- -------- -- ---------

Now we show that

  -- -- -- ---------
           (3.313)
  -- -- -- ---------

To this end, we notice that, since @xmath , and the origin is an
equilibrium, we already have that no trajectory can exit @xmath by
passing through the points in @xmath . Hence, we are left with
considering the possibility of leaving @xmath through @xmath . To
exclude this possibility, we compute the velocity of a trajectory in the
inward normal direction at @xmath .

For every @xmath we have that this normal velocity is

  -- -------- -- ---------
     @xmath      (3.314)
  -- -------- -- ---------

Notice that the term @xmath vanishes on @xmath when @xmath . Also, for
all @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

thus the left hand side in ( 3.314 ) is positive. This observation rules
out the possibility of leaving @xmath through @xmath at points where
@xmath .

It remains to exclude egresses at points of @xmath with @xmath . We
first consider this type of points when @xmath . At these points, we
have that the velocity in the inward normal direction on @xmath is

  -- -------- --
     @xmath   
  -- -------- --

Expressing @xmath with respect to @xmath on @xmath with @xmath , we have

  -- -------- -- ---------
     @xmath      (3.315)
  -- -------- -- ---------

We also remark that, for these points,

  -- -------- --
     @xmath   
  -- -------- --

thanks to ( 3.11 ). This gives that the quantity in ( 3.315 ) is
strictly positive and, as a consequence, we have excluded the
possibility of exiting @xmath at points of @xmath with @xmath .

It remains to consider the case @xmath . We first focus on the range
@xmath . In this interval, the velocity of a trajectory starting at a
point @xmath lying on the line @xmath in the inward normal direction
with respect to @xmath is given by

  -- -------- -- ---------
     @xmath      (3.316)
  -- -------- -- ---------

We also observe that, in light of ( 3.14 ),

  -- -------- --
     @xmath   
  -- -------- --

and therefore, for any @xmath lying on the above line,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Using these pieces of information in ( 3.316 ), we conclude that the
inward normal velocity of a trajectory starting at a point @xmath with
@xmath is strictly positive. This gives that no trajectory can exit
@xmath at this type of points, and we need to exclude the case @xmath .

We consider now the interval @xmath . In this interval, the component of
the velocity of a trajectory at a point on the straight line given by
@xmath in the orthogonal inward pointing direction is

  -- -------- -- ---------
     @xmath      (3.317)
  -- -------- -- ---------

We observe that, if @xmath ,

  -- -- -- ---------
           (3.318)
  -- -- -- ---------

thanks to ( 3.310 ).

We also remark that

  -- -------- --
     @xmath   
  -- -------- --

Accordingly,

  -- -------- --
     @xmath   
     @xmath   
              
     @xmath   
     @xmath   
  -- -------- --

From this and ( 3.318 ), we gather that

  -- -------- -- ---------
     @xmath      (3.319)
  -- -------- -- ---------

Furthermore, we point out that, when @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

thanks to ( 3.310 ).

Combining this inequality and ( 3.319 ), we deduce that

  -- -------- --
     @xmath   
  -- -------- --

Therefore, noticing that @xmath ,

  -- -- -------- -------- --
                 @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

which is strictly positive.

Using this information in ( 3.317 ), we can thereby exclude the
possibility of leaving @xmath through @xmath with @xmath . As a result,
it only remains to exclude the possibility of an egress from @xmath
through @xmath with @xmath .

For this, we perform a general argument of dynamics, as follows. We
denote by @xmath and @xmath the points on @xmath with @xmath and @xmath
, respectively (these points may also coincide, as it happens when
@xmath ). We stress that we already know by the previous arguments that

  -- -- -- ---------
           (3.320)
  -- -- -- ---------

Our goal is to show that no trajectory leaves @xmath and for this we
argue by contradiction, supposing that there exist @xmath and @xmath
such that @xmath lies in the complement of @xmath in @xmath . Here, we
have denoted by @xmath the flow associated to ( 3.1 ). We let @xmath
and, since the complement of @xmath is open in @xmath , we can find
@xmath such that @xmath is contained in the complement of @xmath .

Also, from ( 3.320 ), there exists @xmath such that @xmath . We suppose
that @xmath (the case @xmath being completely analogous). We let @xmath
and we notice that @xmath . Hence, by continuity with respect to the
data, we can find @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

We define @xmath . We observe that

  -- -- -- ---------
           (3.321)
  -- -- -- ---------

since @xmath and @xmath has boundary of Hölder class. In addition,

  -- -------- --
     @xmath   
  -- -------- --

This and ( 3.320 ) give that for every @xmath there exists @xmath such
that @xmath . In particular,

  -- -------- --
     @xmath   
  -- -------- --

Since this is valid for every @xmath , we conclude that

  -- -------- -- ---------
     @xmath      (3.322)
  -- -------- -- ---------

Now we remark that @xmath is an arc of a smooth curve, whence it has
null Lebesgue measure, and a similar statement holds true for @xmath .
Consequently, we deduce from ( 3.322 ) that @xmath has null Lebesgue
measure, in contradiction with ( 3.321 ).

In this way, we have shown that no trajectory can leave @xmath and the
proof of ( 3.313 ) is complete.

By ( 3.312 ) and ( 3.313 ), no trajectory starting in @xmath can arrive
in @xmath when the bound @xmath holds, hence ( 3.305 ) is true.
Therefore the statement (i) in Proposition 3.26 is true.

Now we establish the claim in (ii). To this end, we point out that claim
(ii) is equivalent to

  -- -------- -- ---------
     @xmath      (3.323)
  -- -------- -- ---------

for all @xmath , where @xmath is the complement of @xmath in the
topology of @xmath .

First, we point out that

  -- -- -- ---------
           (3.324)
  -- -- -- ---------

Indeed, one can easily check for @xmath that

  -- -------- -- ---------
     @xmath      (3.325)
  -- -------- -- ---------

Then, one checks that

  -- -------- --
     @xmath   
  -- -------- --

hence @xmath is continuous at the point @xmath . In addition, one can
check that @xmath is continuous at the point @xmath by observing that

  -- -------- -- ---------
     @xmath      (3.326)
  -- -------- -- ---------

This completes the proof of ( 3.324 ).

Now we show that

  -- -------- -- ---------
     @xmath      (3.327)
  -- -------- -- ---------

We have that @xmath for every @xmath , and therefore @xmath for all
@xmath . Also, since @xmath and @xmath is linear in @xmath , we have
that @xmath for all @xmath . Moreover, in the interval @xmath we have
that @xmath is an exponential function multiplied by a positive
constant, thanks to ( 3.325 ), hence it is positive. These
considerations prove ( 3.327 ).

As a consequence of ( 3.327 ), we have that

  -- -------- -- ---------
     @xmath      (3.328)
  -- -------- -- ---------

Now we claim that

  -- -- -- ---------
           (3.329)
  -- -- -- ---------

For this, we observe that, in light of ( 3.328 ), all the points on

  -- -------- --
     @xmath   
  -- -------- --

belong to @xmath , and these three sides of the square do not allow the
flow to exit. Hence, to prove ( 3.329 ) it suffices to check that the
trajectories starting on @xmath enter @xmath . We do this by showing
that the inner pointing derivative of the trajectory is nonnegative,
according to the computation below.

At a point on the line @xmath , the velocity of a trajectory in the
direction that is orthogonal to @xmath for @xmath and pointing inward
is:

  -- -------- -- ---------
     @xmath      (3.330)
  -- -------- -- ---------

We also note that

  -- -------- -- ---------
     @xmath      (3.331)
  -- -------- -- ---------

and therefore, at a point on @xmath with @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This inequality entails that

  -- -------- --
     @xmath   
  -- -------- --

Consequently,

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.330 ), one deduces that, for all @xmath , @xmath , and
@xmath ,

  -- -- --
        
  -- -- --

This (and the fact that the origin is an equilibrium) rules out the
possibility of exiting @xmath from @xmath .

It remains to consider the portions of @xmath given by

  -- -------- -- ---------
     @xmath      (3.332)
  -- -------- -- ---------

and by

  -- -------- -- ---------
     @xmath      (3.333)
  -- -------- -- ---------

Let us deal with the case in ( 3.332 ). In this case, the velocity of a
trajectory in the direction orthogonal to @xmath for @xmath and pointing
inward is

  -- -------- -- ---------
     @xmath      (3.334)
  -- -------- -- ---------

Recalling ( 3.303 ), we also observe that

  -- -- -- ---------
           (3.335)
  -- -- -- ---------

Thus, on the line given by @xmath we have that

  -- -------- -- ---------
     @xmath      (3.336)
  -- -------- -- ---------

where ( 3.335 ) has been used in the latter inequality.

In addition, recalling ( 3.326 ),

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 3.336 ), we gather that the velocity calculated in (
3.334 ) is positive in @xmath and this excludes the possibility of
exiting @xmath from the boundary given in ( 3.332 ).

Next, we focus on the portion of the boundary described in ( 3.333 ) by
considering @xmath . That is, we now compute the component of the
velocity at a point on @xmath for @xmath in the direction that is
orthogonal to @xmath and pointing inward, that is

  -- -------- -- ---------
     @xmath      (3.337)
  -- -------- -- ---------

Now we notice that

  -- -------- --
     @xmath   
  -- -------- --

thanks to ( 3.326 ).

As a result, using ( 3.335 ),

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

This gives that the quantity in ( 3.337 ) is positive. Hence, we have
ruled out also the possibility of exiting @xmath from the boundary given
in ( 3.333 ), and this ends the proof of ( 3.329 ).

Since no trajectory can exit @xmath for any @xmath with @xmath , we get
that no point @xmath is mapped into @xmath because of ( 3.328 ), thus (
3.323 ) is true and the proof is complete. ∎

We end this section with the proof of Theorem 3.6 .

###### Proof of Theorem 3.6.

Since by definition @xmath , we have that @xmath . Hence, we are left
with proving that the latter inclusion is strict.

We start with the case @xmath . We choose

  -- -------- -- ---------
     @xmath      (3.338)
  -- -------- -- ---------

We observe that this choice is compatible with the assumption on @xmath
in ( 3.303 ). We note that

  -- -------- -- ---------
     @xmath      (3.339)
  -- -------- -- ---------

thanks to ( 3.338 ). Moreover, by ( 3.310 ) and the fact that @xmath ,
it holds that

  -- -------- -- ---------
     @xmath      (3.340)
  -- -------- -- ---------

for all @xmath .

Now we choose

  -- -------- --
     @xmath   
  -- -------- --

which is possible thanks to ( 3.339 ), and

  -- -------- -- ---------
     @xmath      (3.341)
  -- -------- -- ---------

By ( 3.340 ) we get that

  -- -------- -- ---------
     @xmath      (3.342)
  -- -------- -- ---------

Using Proposition 3.26 and ( 3.342 ), we deduce that @xmath . By Theorem
3.3 and ( 3.342 ) we obtain instead that @xmath . Hence, the set @xmath
is strictly included in @xmath when @xmath .

Now we consider the case @xmath , using again the notation of
Proposition 3.26 . We recall that @xmath and @xmath , due to ( 3.18 )
and ( 3.325 ), hence we can choose

  -- -------- --
     @xmath   
  -- -------- --

We also define

  -- -------- --
     @xmath   
  -- -------- --

By ( 3.331 ), we get that

  -- -------- -- ---------
     @xmath      (3.343)
  -- -------- -- ---------

Exploiting this and the characterization in Proposition 3.26 , it holds
that @xmath . On the other hand, by Theorem ( 3.3 ) and ( 3.343 ) we
have instead that @xmath . As a consequence, the set @xmath is strictly
contained in @xmath for @xmath . This concludes the proof of Theorem 3.6
. ∎

#### 3.4.6 Minimization of war duration: proof of Theorem 3.7

We now deal with the strategies leading to the quickest possible victory
of the first population.

###### Proof of Theorem 3.7.

Our aim is to establish the existence of the strategy leading to the
quickest possible victory and to determine its range. For this, we
consider the following minimization problem under constraints for @xmath
:

  -- -------- -- ---------
     @xmath      (3.344)
  -- -------- -- ---------

where

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath corresponds to the exit time introduced in ( 3.8 ), in
dependence of the strategy @xmath .

Theorem 6.15 in [ 115 ] assures the existence of a minimizing solution
@xmath with @xmath for all @xmath , and @xmath absolutely continuous,
such that @xmath with @xmath , where @xmath is the exit time for @xmath
.

We now prove that

  -- -------- -- ---------
     @xmath      (3.345)
  -- -------- -- ---------

Indeed, if this were false, then @xmath . Let us call @xmath . Then, we
observe that the function @xmath satisfies the following differential
inequality:

  -- -------- -- ---------
     @xmath      (3.346)
  -- -------- -- ---------

To check this, we compute that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which proves ( 3.346 ).

From ( 3.346 ), one has that

  -- -------- --
     @xmath   
  -- -------- --

and this leads to ( 3.345 ), as desired. We remark that, in this way, we
have found a trajectory @xmath which leads to the victory of the first
population in the shortest possible time.

Theorem 6.15 in [ 115 ] assures that @xmath , so @xmath is measurable.
We have that the two vectorial functions @xmath and @xmath , defined by

  -- -- --
        
  -- -- --

and satisfying @xmath , are analytic. Moreover the set @xmath is a
subset of @xmath , therefore it can be seen as an analytic manifold with
border which is also a compact set. For all @xmath and @xmath we have
that the trajectory starting from @xmath satisfies @xmath for all @xmath
. Then, by Theorem 3.1 in [ 111 ] , there exists a couple @xmath
analytic a part from a finite number of points, such that @xmath solves
( 3.344 ).

Now, to study the range of @xmath , we apply the Pontryagin Maximum
Principle (see for example [ 115 ] ). The Hamiltonian associated with
system ( 3.344 ) is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the adjoint to @xmath and @xmath is the adjoint to the
cost function identically equal to @xmath . The Pontryagin Maximum
Principle tells us that, since @xmath and @xmath give the optimal
solution, there exist a vectorial function @xmath and a scalar @xmath
such that

  -- -------- -- ---------
     @xmath      (3.347)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (3.348)
  -- -------- -- ---------

Moreover, since the final time is free, we have

  -- -------- -- ---------
     @xmath      (3.349)
  -- -------- -- ---------

Also, since @xmath does not depend on @xmath , we get

  -- -------- -- ---------
     @xmath      (3.350)
  -- -------- -- ---------

where the value of the constant is given by ( 3.349 ). By substituting
the values of @xmath in @xmath and using ( 3.350 ), we get, for a.a.
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

Also, by ( 3.348 ) we get that

  -- -------- -- ---------
     @xmath      (3.351)
  -- -------- -- ---------

Thus, to maximize the term in the square brackets we must choose
appropriately the value of @xmath depending on the sign of @xmath , that
is we choose

  -- -------- -- ---------
     @xmath      (3.352)
  -- -------- -- ---------

When @xmath , we are for the moment free to choose @xmath for every
@xmath with range in @xmath , without affecting the maximization problem
in ( 3.351 ).

Our next goal is to determine that @xmath has the expression stated in (
3.20 ) for a.a. @xmath .

To this end, we claim that

  -- -- -- ---------
           (3.353)
  -- -- -- ---------

Indeed, by ( 3.347 ), we know that @xmath is Lipschitz continuous in
@xmath , hence almost everywhere differentiable, and thus the same holds
for @xmath . Hence, up to a set of null measure, given @xmath , we can
suppose that @xmath is not an isolated point in such a set, and that
@xmath is differentiable at @xmath . That is, there exists an
infinitesimal sequence @xmath for which @xmath and

  -- -------- --
     @xmath   
  -- -------- --

and this establishes ( 3.353 ).

Consequently, in light of ( 3.353 ), a.a. @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

Now, since @xmath , we have that @xmath ; inserting this information in
the last equation, we get

  -- -------- -- ---------
     @xmath      (3.354)
  -- -------- -- ---------

Notice that if @xmath , then @xmath ; moreover, by ( 3.350 ), one gets
@xmath . But by the Pontryagin Maximum Principle one cannot have @xmath
, therefore one obtains @xmath in @xmath . Hence, dividing ( 3.354 ) by
@xmath and rearranging the terms, one gets

  -- -------- -- ---------
     @xmath      (3.355)
  -- -------- -- ---------

Differentiating the expression in ( 3.355 ) with respect to time, we get

  -- -------- --
     @xmath   
  -- -------- --

that yields

  -- -------- -- ---------
     @xmath      (3.356)
  -- -------- -- ---------

which is the desired expression. By a slight abuse of notation, we
define the function @xmath for @xmath . Notice that since @xmath for
@xmath , @xmath is continuous for @xmath . ∎

## Chapter 4 Decay estimates for evolution equations with classical and
fractional time-derivatives

Using energy methods, we prove some power-law and exponential decay
estimates for classical and nonlocal evolutionary equations. The results
obtained are framed into a general setting, which comprise, among the
others, equations involving both standard and Caputo time-derivative,
complex valued magnetic operators, fractional porous media equations and
nonlocal Kirchhoff operators.

Both local and fractional space diffusion are taken into account,
possibly in a nonlinear setting. The different quantitative behaviors,
which distinguish polynomial decays from exponential ones, depend
heavily on the structure of the time-derivative involved in the
equation.

The content of this chapter comes from the paper [ 5 ] in collaboration
with Enrico Valdinoci and the paper [ 4 ] in collaboration with Serena
Dipierro and Enrico Valdinoci.

### 4.1 Introduction and main results

#### 4.1.1 Setting of the problem

Fractional calculus is becoming popular thanks to both the deep
mathematics that it involves and its adaptability to the modelization of
several real-world phenomena. As a matter of fact, integro-differential
operators can describe nonlocal interactions of various type and
anomalous diffusion by using suitable kernels or fractional
time-derivatives, see e.g. [ 71 ] . Integro-differential equations and
fractional derivatives have been involved in designing, for example,
wave equations, magneto-thermoelastic heat conduction, hydrodynamics,
quantum physics, porous medium equations.

A wide literature is devoted to the study of existence, uniqueness,
regularity and asymptotic theorems. Here we study the behaviour of the
Lebesgue norm of solutions of integro-differential equations on bounded
domains, extending the method of [ 43 ] to a very broad class of
nonlocal equations and obtaining a power-law decay in time of the @xmath
norm with @xmath . Also, for the case of classical time-derivatives, we
obtain exponential decays in time. The difference between polynomial and
exponential decays in time is thus related to the possible presence of a
fractional derivative in the operator involving the time variable.

The setting in which we work takes into account a parabolic evolution of
a function under the action of a spatial diffusive operator, which
possesses suitable “ellipticity” properties, can be either classical or
fractional, and can also be of nonlinear type. We work in a very general
framework that adapts to both local and nonlocal operators. We comprise
in this analysis also the case of complex valued operators and of a
combination of fractional and classical time-derivatives.

The main assumptions that we take is an “abstract” hypothesis which
extends a construction made in [ 43 ] , and which, roughly speaking, can
be seen as a quantitative counterpart of the uniform ellipticity of the
spatial diffusive operators. In [ 43 ] , several time-decay estimates
have been given covering the cases in which the time-derivative is of
fractional type and the spatial operator is either the Laplacian, the
fractional Laplacian, the @xmath Laplacian and the mean curvature
equation. In this chapter, we deal with the cases in which the
time-derivative can be either classical or fractional, or a convex
combination of the two , and we deal with new examples of spatial
diffusive operators, which include the case of a complex valued
operators. In particular, we present applications to the fractional
porous medium equation , to the classical and fractional Kirchhoff
equations , to the classical and fractional magnetic operators .
Referring to [ 43 ] for the corresponding results, we also present in
Table 4.1 the decay results for the @xmath Laplacian , the nonlinear
diffusion operator , the graphical mean curvature operator , the
fractional @xmath Laplacian , the anisotropic fractional @xmath
Laplacian , a second version of fractional porous medium (unfortunately,
two different operators are known under the same name), and the
fractional graphical mean curvature .

We recall that the Caputo derivative of order @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

up to a normalizing constant (that we omit here for the sake of
simplicity).

Let also @xmath be fixed. We suppose, for concreteness, that

  -- -------- --
     @xmath   
  -- -------- --

but up to a rescaling of the operator we can take @xmath any nonnegative
number with positive sum. Let @xmath be a bounded open set and let
@xmath such that @xmath . Consider the Cauchy problem

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where @xmath is a possibly nonlocal operator. Given @xmath we want to
find some estimates on the @xmath norm of @xmath . To this end, we
exploit analytical techniques relying on energy methods, exploiting also
some tools that have been recently developed in [ 69 , 119 , 43 ] .
Namely, as in [ 43 ] , we want to compare the @xmath norm of the
solution @xmath with an explicit function that has a power law decay,
and to do this we take advantadge of a suitable comparison result and of
the study of auxiliary fractional parabolic equations as in [ 69 , 119 ]
.

#### 4.1.2 Notation and structural assumptions

Let us recall that for a complex valued function @xmath the Lebesgue
norm is

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath . Also, we will call @xmath the real part of @xmath . The
main assumption we take is the following: there exist @xmath and @xmath
such that

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

The constants @xmath and @xmath and their dependence from the parameters
of the problem may vary from case to case. This structural assumption
says, essentially, that @xmath has an elliptic structure and it is also
related (via an integration by parts) to a general form of the Sobolev
inequality (as it is apparent in the basic case in which @xmath is real
valued, @xmath and @xmath ).

In our setting, the structural inequality in ( 4.2 ) will be the
cornerstone to obtain general energy estimates, which, combined with
appropriate barriers, in turn produce time-decay estimates. The results
obtained in this way are set in a general framework, and then we make
concrete examples of operators that satisfy the structural assumptions,
which is sufficient to establish asymptotic bounds that fit to the
different cases of interest and take into account the peculiarities of
each example in a quantitative way.

Our general result also includes Theorem 1 of [ 43 ] as a particular
case, since, if @xmath and @xmath are real valued, the ( 4.2 ) boils
down to hypothesis (1.3) of [ 43 ] (in any case, the applications and
examples covered here go beyond the ones presented in [ 43 ] both for
complex and for real valued operators).

#### 4.1.3 Main results

The “abstract” result that we establish here is the following:

###### Theorem 4.1.

Let @xmath be a solution of the Cauchy problem ( 4.1 ), with @xmath
possibly complex valued. Suppose that there exist @xmath , @xmath and
@xmath such that @xmath satisfies ( 4.2 ). Then

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

where @xmath and @xmath are the constants appearing in ( 4.2 ).
Furthermore,

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

for some @xmath , depending only on @xmath , @xmath , @xmath and @xmath
.

Theorem 4.1 here comprises previous results in [ 43 ] , extending their
applicability to a wider class of equations, which include the cases of
both standard and fractional time-derivatives and complex valued
operators.

We also recall that the power-law decay in ( 4.4 ) is due to the
behaviour of the solution of the equation

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

for @xmath . Indeed, the solution of ( 4.5 ) is explicit in terms of the
Mittag-Leffler function and it is asymptotic to @xmath as @xmath (see [
80 ] , [ 92 ] ); notice that the latter decay corresponds to the one
in ( 4.5 ) when @xmath .

As pointed out in [ 69 ] , the power law decay for solutions of
time-fractional equations is, in general, unavoidable. On the other
hand, solutions of equations driven by the standard time-derivative of
the type

  -- -------- --
     @xmath   
  -- -------- --

often have a faster decay in many concrete examples, for instance for
@xmath where exponential decay is attained. This particular feature of
the classical heat equation is in fact a special case of a general
phenomenon, described in details in the following result:

###### Theorem 4.2.

Let @xmath be a solution of the Cauchy problem ( 4.1 ) with only
classical derivative ( @xmath ) and @xmath possibly complex valued.
Suppose that there exist @xmath , @xmath and @xmath such that @xmath
satisfies ( 4.2 ). Then, for some @xmath , depending only on the
constants @xmath and @xmath in ( 4.2 ), and on @xmath , we have that:

-    if @xmath the solution @xmath satisfies

      -- -------- -- -------
         @xmath      (4.6)
      -- -------- -- -------

-    if @xmath , the solution @xmath satisfies

      -- -------- -- -------
         @xmath      (4.7)
      -- -------- -- -------

We stress that Theorem 4.2 is valid for a very general class of
diffusive operators @xmath , including also the ones which take into
account fractional derivatives in the space-variables. In this sense,
the phenomenon described in Theorem 4.2 is that:

-   on the one hand, the fractional behaviour induces power-law decay,

-   on the other hand, for long times, the interactions between
    different derivatives “decouple”: for instance, a space-fractional
    derivative, which would naturally induce a polynomial decay, does
    not asymptotically “interfere” with a classical time-derivative in
    the setting of Theorem 4.2 , and the final result is that the decay
    in time is of exponential, rather than polynomial, type.

The fact that long-time asymptotics of mixed type (i.e. classical
time-derivatives versus fractional-space diffusion) reflect the
exponential decay of linear ordinary differential equations was also
observed in [ 93 ] for equations inspired by the Peierls-Nabarro model
for atom dislocations in crystal.

As we will see in the proof of Theorem 4.2 , the idea is to find a
supersolution of ( 4.3 ) and use a comparison principle in order to
estimate the decay of the solution @xmath . For the case of mixed
derivatives, Vergara and Zacher [ 119 ] find both a supersolution and a
subsolution decaying as @xmath . When @xmath , thus when the mixed
derivative is approaching the classical one, the subsolution tends to 0.
This allows possibly better decays, which are in fact proven. On the
other side, the supersolution gains some extra decay, possibly reaching
an exponential decay.

The optimality of the decay estimates obtained in our results and some
further comparisons with the existing literature are discussed in
Subsection 4.1.4 .

#### 4.1.4 Applications

We now present several applications of Theorem 4.1 to some concrete
examples.

###### The case of the fractional porous medium equation.

Let @xmath and

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

be the positive function

  -- -------- --
     @xmath   
  -- -------- --

being @xmath a constant. The fractional ¹ ¹ 1 As a matter of fact, as
clearly explained in
https://www.ma.utexas.edu/mediawiki/index.php/Nonlocal_porous_medium_equation
, the fractional porous medium equation is “the name currently given to
two very different equations”. The one introduced in [ 39 ] has been
studied in details in [ 43 ] in terms of decay estimates. We focus here
on the equation introduced in [ 29 ] . As discussed in the above
mentioned mediawiki page, the two equations have very different
structures and typically exhibit different behaviors, so we think that
it is a nice feature that, combining the results here with those in [ 43
] , it follows that a complete set of decay estimates is valid for both
the fractional porous medium equations at the same time. porous medium
operator (as defined in [ 29 ] ) is

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

where @xmath denotes the convolution. This operator is used to describe
the diffusion of a liquid under pressure in a porous environment in
presence of memory effects and long-range interactions, and also has
some application in biological models, see [ 29 ] .

In this framework, the following result holds:

###### Theorem 4.3.

Take @xmath and let @xmath be a solution in @xmath to ( 4.1 ) with
@xmath the fractional porous medium operator as in ( 4.9 ). Then for all
@xmath there exists @xmath depending on @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Also, in the case of only classical derivative ( @xmath ), we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , possibly different than before, depends on @xmath .

###### The case of the Kirchhoff operator and the fractional Kirchhoff
operator.

The Kirchhoff equation describes the movement of an elastic string that
is constrained at the extrema, taking into account a possible growth of
the tension of the vibrating string in view of its extension. It was
first introduced by Gustav Robert Kirchhoff in 1876, see
https://archive.org/details/vorlesungenberm02kircgoog , and fully
addressed from the mathematical point of view in the 20th century, see [
23 ] .

Parabolic equations of Kirchhoff type have been widely studied during
the ’90s (see for example [ 56 ] and the reference therein). Recently a
fractional counterpart to the Kirchhoff operator has been introduced by
Fiscella and Valdinoci [ 49 ] .

The setting that we consider here is the following. Let @xmath be an
nondecreasing function. A typical example is

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

where @xmath and @xmath . We consider here both the cases ² ² 2 The case
@xmath for ( 4.10 ) is usually called the degenerate case and it
presents several additional difficulties with respect with the
non-degenerate case. in which @xmath and in which @xmath takes the form
in ( 4.10 ) with @xmath . In this setting, the Kirchhoff operator that
we take into account is

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

Then, we obtain the following decay estimates:

###### Theorem 4.4.

Let @xmath be the solution of problem ( 4.1 ) with @xmath the Kirchhoff
operator in ( 4.11 ). Then there exist @xmath and @xmath depending on
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

in the following cases:

-    for all @xmath when @xmath is non-degenerate; in particular, in
    this case @xmath .

-    for all @xmath when @xmath is degenerate and @xmath ; in
    particular, in this case @xmath .

-    for @xmath when @xmath is degenerate and @xmath ; in particular, in
    this case @xmath .

Moreover, if we take @xmath , then there exists @xmath , @xmath
depending on @xmath , for which the following statements hold true:

-    in case (i) we have

      -- -------- --
         @xmath   
      -- -------- --

-    in cases (ii) and (iii) we have

      -- -------- --
         @xmath   
      -- -------- --

Next, we consider the case of the fractional Kirchhoff operator. We take
a nondecreasing positive function @xmath . As for the classic Kirchhoff
operator, we consider either the case when @xmath or the case @xmath
with @xmath . We fix @xmath . We define the norm

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

Finally, the fractional Kirchhoff operator reads

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

In this setting, our result is the following:

###### Theorem 4.5.

Let @xmath be the solution of problem ( 4.1 ) with @xmath the fractional
Kirchhoff operator in ( 4.13 ). Then there exist @xmath and @xmath ,
depending on @xmath , @xmath , @xmath , @xmath and @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

in the following cases:

-    for all @xmath when @xmath is non-degenerate; in particular, in
    this case @xmath .

-    for all @xmath when @xmath is degenerate and @xmath ; in
    particular, in this case @xmath .

-    for @xmath when @xmath is degenerate and @xmath ; in particular, in
    this case @xmath .

Moreover, if we take @xmath , then there exists @xmath , depending on
@xmath , such that:

-    in case (i) we have

      -- -------- --
         @xmath   
      -- -------- --

    for some @xmath ,

-    in cases (ii) and (iii) we have

      -- -------- --
         @xmath   
      -- -------- --

It is interesting to remark that the cases (i), (ii) and (iii) in
Theorem 4.5 formally reduce to those in Theorem 4.4 when @xmath .

###### The case of the magnetic operator and the fractional magnetic
operator.

We consider here an operator similar to Schrödinger equation with a
magnetic potential (see e.g. [ 67 ] and the references therein), that is

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

where @xmath has the physical meaning of a magnetic field (in this case,
one usually studies the three-dimensional case @xmath , but our approach
is general). The goal of these pages is to apply Theorem 4.1 to the
magnetic operator in ( 4.14 ), thus obtaining decay estimates in time in
this framework.

It is interesting to remark that the operator in ( 4.14 ) is
structurally very different from the linear Schrödinger operator, which
corresponds to the choice

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

Indeed, for the operator in ( 4.15 ) decay estimates in time do not ³ ³
3 Indeed, if @xmath and @xmath is a solution of the Schrödinger
parabolic equation @xmath in @xmath with homogeneous data along @xmath ,
the conjugated equation reads @xmath , and therefore

@xmath @xmath @xmath

where the last identity follows from the Divergence Theorem and the
boundary conditions. This shows that decay estimates in time are in
general not possible in this setting, thus highlighting an interesting
difference between the Schrödinger operator in ( 4.15 ) and the magnetic
operator in ( 4.14 ). This difference, as well as the computation above,
has a natural physical meaning, since in the Schrödinger equation the
squared modulus of the solution represents the probability density of a
wave function, whose total amount remains constant if no dissipative
forces appear in the equation. hold in general, not even in the case of
classical time-derivatives.

The decay estimate for the classical magnetic operator is the following:

###### Theorem 4.6.

Let @xmath be the solution of problem ( 4.1 ) with @xmath the magnetic
operator in ( 4.14 ). Then for all @xmath there exist @xmath depending
on @xmath , @xmath , @xmath and @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Moreover, in the case of classical derivatives ( @xmath ), we have

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , @xmath , depending on @xmath , @xmath , @xmath and
@xmath .

In [ 38 ] D’Avenia and Squassina introduced a fractional operator where
a magnetic field @xmath appears. Their aim was to study the behaviour of
free particles interacting with a magnetic field. For a fixed @xmath ,
such an operator in dimension @xmath reads

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

In the appropriate framework, the fractional magnetic operator in ( 4.16
) recovers the classical magnetic operator in ( 4.14 ) as @xmath , see [
110 ] (see also [ 88 ] for a general approach involving also nonlinear
operators).

In the setting of the fractional magnetic operator, we present the
following result:

###### Theorem 4.7.

Let @xmath be the solution of problem ( 4.1 ) with @xmath the fractional
magnetic operator in ( 4.16 ). Then for all @xmath there exist @xmath
depending on @xmath , @xmath and @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Moreover, in the case of classical derivatives ( @xmath ), we have

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , @xmath depending on @xmath , @xmath and @xmath .

The magnetic operators present a crucial difference with respect to the
other operators considered in the previous applications, since they are
complex valued operators.

###### Other operators.

We point out that condition ( 4.2 ) has already been checked in many
cases in [ 43 ] . We present here very briefly the operators treated
there that may need an introduction. The list includes the cases of the
classical @xmath -Laplacian and porous media diffusion (see [ 41 , 118 ]
)

  -- -------- --
     @xmath   
  -- -------- --

the case of graphical mean curvature, given in formula (13.1) of [ 59 ]
,

  -- -------- --
     @xmath   
  -- -------- --

the case of the fractional @xmath -Laplacian (see e.g. [ 26 ] )

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

and possibly even the sum of different nonlinear operator of this type,
with coefficients @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

the case of the anisotropic fractional Laplacian, that is the sum of
fractional directional derivatives in the directions of the space @xmath
, given by

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , @xmath and @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

considered for example in [ 46 ] . The list of possible diffusion
operators continues with a fractional porous media operators (see [ 39 ]
)

  -- -------- --
     @xmath   
  -- -------- --

and the graphical fractional mean curvature operator (see [ 9 ] )

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

For the sake of brevity, we recall the corresponding results in Table
4.1 .

The examples provided here show that the “abstract” structural
hypothesis ( 4.2 ) is reasonable and can be explicitly checked in
several cases of interest. We are also confident that other interesting
examples fulfilling such an assumption can be found, therefore Theorem
4.1 turns out to play a pivotal role in the asymptotics of real and
complex valued, possibly nonlinear, and possibly fractional, operators.

##### Comparison with the existing literature

In general, in problems of the type ( 4.1 ) it is very difficult to
provide explicit solutions and often the system has no unique solution,
see e.g. [ 25 ] . Therefore, even partial information on the solutions
is important.

In the case of a Kirchhoff parabolic equation with purely classical
time-derivative in the degenerate case @xmath , Ghisi and Gobbino [ 56 ]
found the time-decay estimate

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

for some costants @xmath depending on initial data. From this,
performing an integration of the gradient along paths ⁴ ⁴ 4 More
precisely, the fact that ( 4.17 ) implies ( 4.19 ) can be seen as a
consequence of the following observation: for every @xmath ,

@xmath (4.18)

where @xmath depends on @xmath and @xmath . Indeed, fix @xmath such that
@xmath and @xmath , for some @xmath . Then, for every @xmath we have
that @xmath and thus

@xmath @xmath

On the other hand, if @xmath we have that

@xmath

and so @xmath , which in turn implies that @xmath . This gives that

@xmath

Hence, using the substitution @xmath , we conclude that

@xmath @xmath

which proves ( 4.18 ). , one can find the estimate

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

The latter is exactly the estimate we found in Theorem 4.4 as a
particular case of our analysis.

The fractional porous medium equation with classical derivative has been
studied by Biler, Karch and Imbert in [ 25 ] , establishing some decay
estimates of the @xmath norm, such as

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

As a matter of fact, this decay is slower than what we find in Theorem
4.3 , which is asymptotic to @xmath (in this sense, Theorem 4.3 here can
be seen as an improvement of the estimates in [ 25 ] ).

On the other hand, in [ 25 ] the Authors also provide a weak solution
that has exactly the decay in ( 4.20 ), thus showing the optimality of (
4.20 ) in this generality, while our result holds for strong solutions.
Then, comparing Theorem 4.3 here with the results in ( 4.20 ) we obtain
that a better decay is valid for regular solutions with respect to the
one which is valid also for irregular ones.

### 4.2 Proofs

This section contains the proofs of our main results. We start with the
proof of Theorem 4.1 .

In order to prove Theorem 4.1 , we need a comparison result for the
equation involving the mixed time-derivative. As a matter of fact,
comparison results for the case of the Caputo derivative are available
in the literature, see e.g. Lemma 2.6 of [ 119 ] . In our arguments we
employ the differentiability of @xmath and the fact that @xmath is a
strong solution, and we obtain:

###### Lemma 4.8.

Let @xmath and @xmath be two Lipschitz continuous functions. Assume that
@xmath is a supersolution and @xmath is a subsolution at each
differentiability point for the equation

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

with @xmath , @xmath , @xmath , @xmath .

Then: if

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

we have that

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

###### Proof.

By contradiction, let us suppose that for some time @xmath we have
@xmath , and let us call @xmath the first time for which the equality is
reached. Then, since @xmath is a supersolution and @xmath is a
subsolution of ( 4.21 ), we obtain that

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Now we distinguish two cases, depending on whether or not @xmath is
differentiable at @xmath . To start with, suppose that @xmath is
differentiable at @xmath . Since @xmath in @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 4.24 ), we obtain that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

This is in contradiction with ( 4.22 ) and so it proves ( 4.23 ) in this
case.

Now we focus on the case in which @xmath is not differentiable at @xmath
. Then, there exists a sequence @xmath such that @xmath is
differentiable at @xmath , with @xmath and @xmath as @xmath .
Consequently, since @xmath is a supersolution and @xmath is a
subsolution of ( 4.21 ), we obtain that

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

Now we observe that if @xmath is a Lipschitz function and @xmath as
@xmath , then

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

To check this, let

  -- -------- --
     @xmath   
  -- -------- --

and let @xmath be a measurable set, with measure @xmath less than a
given @xmath . Let also @xmath and denote by @xmath its conjugated
exponent. Then, by Hölder inequality, for large @xmath we have that

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath is the Lipschitz constant of @xmath . Consequently, by the
Vitali Convergence Theorem, we obtain that

  -- -------- --
     @xmath   
  -- -------- --

which gives ( 4.26 ), as desired.

Now, we take the limit as @xmath in ( 4.25 ), exploiting ( 4.26 ) and
the fact that @xmath . In this way, we have that

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath in @xmath , the latter inequality implies that

  -- -------- --
     @xmath   
  -- -------- --

This is in contradiction with ( 4.22 ) and so it completes the proof
of ( 4.23 ). ∎

It is also useful to observe that Lemma 4.8 holds true also for the
classical derivative (i.e. when @xmath ). We give its statement and
proof for the sake of completeness:

###### Lemma 4.9.

Let @xmath , @xmath be two Lipschitz continuous functions. Assume that
@xmath is a supersolution and @xmath is a subsolution at each
differentiability point for the equation

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

with @xmath , @xmath .

Then: if

  -- -------- -- --------
     @xmath      (4.28)
  -- -------- -- --------

we have that

  -- -------- -- --------
     @xmath      (4.29)
  -- -------- -- --------

###### Proof.

Suppose that ( 4.29 ) is false. Then there exists @xmath such that
@xmath in @xmath and

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

We fix @xmath , to be taken as small as we wish in the sequel, and
define

  -- -------- -- --------
     @xmath      (4.31)
  -- -------- -- --------

We observe that

  -- -------- --
     @xmath   
  -- -------- --

as long as @xmath is sufficiently small, and @xmath . Therefore there
exists @xmath such that

  -- -- -- --------
           (4.32)
  -- -- -- --------

We claim that

  -- -------- -- --------
     @xmath      (4.33)
  -- -------- -- --------

Indeed, suppose, by contradiction, that, up to a subsequence, @xmath
converges to some @xmath as @xmath . Then we have that

  -- -------- --
     @xmath   
  -- -------- --

This is in contradiction with the definition of @xmath and so ( 4.33 )
is proved.

Now, from ( 4.32 ), we know that there exists a sequence @xmath such
that @xmath is differentiable at @xmath , @xmath and @xmath as @xmath .

Accordingly, we deduce from ( 4.27 ) and ( 4.31 ) that

  -- -------- --
     @xmath   
  -- -------- --

Hence, taking the limit as @xmath ,

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

We claim that

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

Indeed, if not, by ( 4.30 ) and ( 4.33 ),

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

We observe that this implies that

  -- -------- -- --------
     @xmath      (4.37)
  -- -------- -- --------

Indeed, since @xmath is a supersolution of ( 4.27 ), we have that

  -- -- -- -------- --
           @xmath   
           @xmath   
  -- -- -- -------- --

as long as @xmath , and so for all @xmath . In particular, we have that
@xmath , in contradiction with ( 4.36 ), and this proves ( 4.37 ).

Then, we use that @xmath is a subsolution of ( 4.27 ) and ( 4.36 ) to
write that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Therefore, recalling ( 4.37 ),

  -- -------- --
     @xmath   
  -- -------- --

and thus

  -- -------- -- --------
     @xmath      (4.38)
  -- -------- -- --------

Similarly, using that @xmath is a supersolution of ( 4.27 ) and ( 4.36 )
we obtain that, for any @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Comparing this and ( 4.38 ), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

which is in contradiction with ( 4.28 ), and so the proof of ( 4.35 ) is
complete.

Then, using ( 4.34 ) and ( 4.35 ), a Taylor expansion gives that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Then, sending @xmath and recalling ( 4.33 ) and ( 4.35 ), we conclude
that @xmath . This is a contradiction and the proof of ( 4.29 ) is
thereby complete. ∎

With this preliminary work, we are in the position of proving the
general claim stated in Theorem 4.1 .

###### Proof of Theorem 4.1.

First, notice that

  -- -------- -- --------
     @xmath      (4.39)
  -- -------- -- --------

Using ( 4.39 ) and exchanging the order of the integral and the
derivative, we have

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

Now we claim that

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

This formula is similar to one given in Corollary 3.1 of [ 119 ] for
general kernels. In our setting, we provide an easier proof for the case
of the Caputo derivative, comprising also the case of complex valued
operators. To prove ( 4.41 ), using the definition of Caputo derivative
we see that

  -- -------- --
     @xmath   
  -- -------- --

Hence, by using the Hölder inequality, we get

  -- -- --
        
  -- -- --

This completes the proof of ( 4.41 ).

Now, to make the notation simpler, we set @xmath . By combining ( 4.40 )
and ( 4.41 ), we find that

  -- -------- --
     @xmath   
  -- -------- --

and so, using the fact that @xmath is a solution of ( 4.1 ), we conclude
that

  -- -------- --
     @xmath   
  -- -------- --

From this, we use the structural hypothesis ( 4.2 ) and we obtain that

  -- -------- --
     @xmath   
  -- -------- --

Hence, we have established the claim in ( 4.3 ) for all @xmath such that
@xmath . Then, suppose that for some @xmath we have @xmath . Since
@xmath is nonnegative, it follows that

  -- -------- -- --------
     @xmath      (4.42)
  -- -------- -- --------

On the other hand, if @xmath , then

  -- -------- -- --------
     @xmath      (4.43)
  -- -------- -- --------

because

  -- -------- --
     @xmath   
  -- -------- --

So, by ( 4.42 ) and ( 4.43 ), @xmath , which gives ( 4.3 ) also in this
case, as desired.

Now we exhibit a supersolution @xmath of the equation @xmath , where
@xmath . For this, we recall Section 7 of [ 119 ] , and we have that the
function

  -- -------- --
     @xmath   
  -- -------- --

with @xmath is a supersolution of @xmath as long as

  -- -------- --
     @xmath   
  -- -------- --

We claim that @xmath . To prove this, it is equivalent to check that

  -- -------- --
     @xmath   
  -- -------- --

which is in turn equivalent to

  -- -------- --
     @xmath   
  -- -------- --

and the latter equation holds if

  -- -------- --
     @xmath   
  -- -------- --

Therefore for @xmath big enough we have that @xmath is a supersolution
of the equation @xmath . Also, @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath depending only on @xmath and @xmath . Hence by the
comparison principle in Lemma 4.8 , we infer that @xmath , which
completes the proof of the desired result in ( 4.4 ). ∎

###### Proof of Theorem 4.2.

The proof is identical to the one of Theorem 4.1 a part from the
construction of the supersolution (and from the use of the comparison
principle in Lemma 4.9 rather than in Lemma 4.8 ). Our aim is now to
find a supersolution to the equation ( 4.3 ) in the case @xmath , that
we can write as

  -- -------- -- --------
     @xmath      (4.44)
  -- -------- -- --------

where @xmath is the constant given in the hypothesis. To construct this
supersolution, we distinguish the cases @xmath and @xmath .

We define

  -- -------- -- --------
     @xmath      (4.45)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (4.46)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (4.47)
  -- -------- -- --------

Notice that, for @xmath

  -- -------- -- --------
     @xmath      (4.48)
  -- -------- -- --------

In fact,

  -- -------- --
     @xmath   
  -- -------- --

implies

  -- -------- --
     @xmath   
  -- -------- --

and that proves ( 4.48 ). Then, we see that the function

  -- -------- -- --------
     @xmath      (4.49)
  -- -------- -- --------

is a continuous and Lipschitz function, moreover it is a solution of (
4.44 ) in the case @xmath and a supersolution of ( 4.44 ) in the case
@xmath . Indeed, to check this, we observe that, for @xmath ,

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

while for all @xmath ,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where the inequality holds thanks to ( 4.48 ). Notice also that the
function @xmath is Lipschitz since it is piecewise continuous and
derivable and it is continuous in the point @xmath because of the
definition of @xmath given in ( 4.47 ). These observations establish the
desired supersolution properties for the function in ( 4.49 ) for @xmath
. From this and the comparison result in Lemma 4.9 , used here with
@xmath and @xmath , we obtain that @xmath for any @xmath , and in
particular,

  -- -------- -- --------
     @xmath      (4.50)
  -- -------- -- --------

for @xmath . This proves ( 4.6 ).

Now we deal with the case @xmath . In this case, we set

  -- -------- --
     @xmath   
  -- -------- --

Then the function

  -- -------- -- --------
     @xmath      (4.51)
  -- -------- -- --------

is a supersolution of ( 4.44 ). Indeed, if @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

while, if @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This gives that the function in ( 4.51 ) has the desired supersolution
property and consequently we can apply the comparison result in Lemma
4.9 with @xmath and @xmath . In this way, we obtain that for all @xmath

  -- -------- --
     @xmath   
  -- -------- --

and so the proof of ( 4.7 ) is complete. ∎

Now, we present the applications of the abstract results to the
operators introduced in Section 4.1.4 .

We start with the case of the fractional porous medium equation.

###### Proof of Theorem 4.3.

In order to prove Theorem 4.3 , our strategy is to verify the validity
of inequality ( 4.2 ) with @xmath for the porous medium operator, which
would put us in the position of exploiting Theorems 4.1 and 4.2 .

To this end, by elementary computations, up to changes of the positive
constant @xmath depending on @xmath and @xmath , we see that

  -- -------- -- --------
     @xmath      (4.52)
  -- -------- -- --------

Now, define for @xmath , the regularized operator

  -- -------- -- --------
     @xmath      (4.53)
  -- -------- -- --------

where @xmath is the same constant that appears in the definition of
@xmath in ( 4.8 ). Notice that, since @xmath is regular, we have

  -- -------- -- --------
     @xmath      (4.54)
  -- -------- -- --------

where @xmath is the characteristic function. Thus, thanks to ( 4.54 ) we
can apply the Dominated Convergence Theorem and obtain

  -- -------- -- --------
     @xmath      (4.55)
  -- -------- -- --------

So, using ( 4.52 ) and ( 4.55 ), we have

  -- -------- -- --------
     @xmath      (4.56)
  -- -------- -- --------

up to changes of the positive constant @xmath . Now we adapt a method
that was introduced in [ 29 ] to obtain @xmath estimates. We exchange
the order of integration and have that

  -- -------- --
     @xmath   
  -- -------- --

We observe now that, since @xmath is always positive,

  -- -------- --
     @xmath   
  -- -------- --

Thus, again by the Dominated Convergence Theorem, we can pass to the
limit in ( 4.56 ) and obtain

  -- -------- -- --------
     @xmath      (4.57)
  -- -------- -- --------

Now, we define @xmath . Then, by inequality (2.15) of [ 43 ] we have,
for some @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

From this, ( 4.52 ) and ( 4.57 ) we obtain that

  -- -------- -- --------
     @xmath      (4.58)
  -- -------- -- --------

Now we set @xmath ; then @xmath and @xmath . Let also

  -- -------- --
     @xmath   
  -- -------- --

Then for any @xmath we can apply the
Gagliardo-Sobolev-Slobodetskiĭ fractionary inequality (compare [ 40 ] ,
Theorem 6.5) and obtain

  -- -------- -- --------
     @xmath      (4.59)
  -- -------- -- --------

with @xmath depending only on @xmath and @xmath . In particular,
choosing @xmath , we deduce from ( 4.59 ) that

  -- -------- -- --------
     @xmath      (4.60)
  -- -------- -- --------

On the other hand, using the Hölder inequality, one has that

  -- -------- --
     @xmath   
  -- -------- --

Combining this and ( 4.60 ), we obtain

  -- -------- --
     @xmath   
  -- -------- --

up to renaming @xmath . This and ( 4.58 ) establish the validity of (
4.2 ) for @xmath , as desired. ∎

Now we focus on the Kirchhoff equation, first dealing with the case of
classical derivatives.

###### Proof of Theorem 4.4.

Our objective here is to verify the validity of inequality ( 4.2 ) for
suitable values of @xmath , and then make use of Theorems 4.1 and 4.2 .

First we present the proof for the non-degenerate case, that takes place
when @xmath has a positive minimum. Let us call @xmath , then

  -- -------- -- --------
     @xmath      (4.61)
  -- -------- -- --------

In Theorem 1.2 of [ 43 ] , the case of the Laplacian was considered:
there it was found that, for some @xmath depending on @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Combining this with ( 4.61 ) we see that ( 4.2 ) holds true for @xmath
and @xmath depending on @xmath .

Now we deal with the degenerate case, which requires the use of finer
estimates. In this case, we have that

  -- -------- -- --------
     @xmath      (4.62)
  -- -------- -- --------

where the first passage is an integration by parts and the last
inequality holds in view of the Cauchy-Schwarz inequality.

Now define

  -- -------- -- --------
     @xmath      (4.63)
  -- -------- -- --------

We have that

  -- -------- --
     @xmath   
  -- -------- --

This and ( 4.62 ) give that

  -- -- -- --------
           (4.64)
  -- -- -- --------

We now use Sobolev injections (in the form given, for instance, in
formula (2.9) of [ 43 ] ), remembering that @xmath is zero outside
@xmath . The inequality

  -- -------- -- --------
     @xmath      (4.65)
  -- -------- -- --------

holds

  -- -- -- --------
           (4.66)
  -- -- -- --------

Therefore, we set

  -- -------- -- --------
     @xmath      (4.67)
  -- -------- -- --------

Recalling the ranges of @xmath in claim (iii) of Theorem 4.4 , when
@xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

which shows that the definition in ( 4.67 ) fulfills the conditions in (
4.66 ), and so ( 4.65 ) is valid in this setting.

Hence, making use of ( 4.63 ), ( 4.64 ) and ( 4.65 ), up to renaming
@xmath line after line, we deduce that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

These observations imply that condition ( 4.2 ) is satisfied here with
@xmath and @xmath depending on @xmath and @xmath . ∎

Now we deal with the case of the fractional Kirchhoff equation.

###### Proof of Theorem 4.5.

As in the case of classical space-derivatives dealt with in the proof of
Theorem 4.4 , a quick proof for the non-degenerate case is available.
Indeed,

  -- -------- --
     @xmath   
  -- -------- --

and in [ 43 ] it was shown that

  -- -------- --
     @xmath   
  -- -------- --

Thus, the validity of inequality ( 4.2 ) with @xmath is established in
this case.

We now deal with the degenerate case. We fix

  -- -------- -- --------
     @xmath      (4.68)
  -- -------- -- --------

and we define

  -- -------- -- --------
     @xmath      (4.69)
  -- -------- -- --------

We claim that

  -- -------- -- --------
     @xmath      (4.70)
  -- -------- -- --------

for some @xmath , independent of @xmath . To prove this, we first
observe that the radicand in ( 4.70 ) is well defined, since, for every
@xmath , @xmath we have that

  -- -------- -- --------
     @xmath      (4.71)
  -- -------- -- --------

To check this, up to exchanging @xmath and @xmath , we can suppose that
@xmath . Then, we have three cases to take into account: either @xmath ,
or @xmath , or @xmath . If @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

and so ( 4.71 ) holds true. If instead @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

which gives ( 4.71 ) in this case. Finally, if @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

again since @xmath , thus completing the proof of ( 4.71 ).

Then, by ( 4.71 ), we have that ( 4.70 ) is equivalent to

  -- -------- -- --------
     @xmath      (4.72)
  -- -------- -- --------

We also note that when @xmath the inequality in ( 4.72 ) is trivially
satisfied. Hence, without loss of generality we can suppose that

  -- -- -- --------
           (4.73)
  -- -- -- --------

We define the function

  -- -------- -- --------
     @xmath      (4.74)
  -- -------- -- --------

and we claim that

  -- -------- -- --------
     @xmath      (4.75)
  -- -------- -- --------

To this end, we point out that @xmath is regular for all @xmath , so, to
establish ( 4.75 ), we only have to study the limits of @xmath for
@xmath and @xmath .

When @xmath , this limit is immediate and @xmath . On the other hand,
when @xmath , we see that

  -- -------- --
     @xmath   
  -- -------- --

which is finite, thanks to ( 4.68 ). Then ( 4.75 ) holds true, as
desired.

Then, using ( 4.75 ) with @xmath , we have that

  -- -------- -- --------
     @xmath      (4.76)
  -- -------- -- --------

for some @xmath . Then, in view of ( 4.73 ), we can exploit ( 4.76 )
with @xmath and @xmath , from which we obtain that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

This and ( 4.69 ) imply ( 4.70 ), as desired.

Now, fixed @xmath as in ( 4.68 ), we set

  -- -------- -- --------
     @xmath      (4.77)
  -- -------- -- --------

We apply the Gagliardo-Sobolev-Slobodetskiĭ fractional immersion (for
instance, in the version given in formula (2.18) of [ 43 ] ) to @xmath .
In this way,

  -- -- -- --------
           (4.78)
  -- -- -- --------

we have that

  -- -------- -- --------
     @xmath      (4.79)
  -- -------- -- --------

where the first equality comes from ( 4.69 ) and the latter equality is
a consequence of ( 4.77 ).

Now we choose

  -- -------- -- --------
     @xmath      (4.80)
  -- -------- -- --------

Notice that condition ( 4.68 ) is fulfilled in this setting.
Furthermore, recalling ( 4.77 ) and the assumptions in point (iii) of
Theorem 4.5 , we have that, when @xmath , we have

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

As a consequence, we have that condition ( 4.78 ) is fulfilled the
setting prescribed by ( 4.80 ), hence we can exploit ( 4.79 ) in this
framework.

Then, from ( 4.80 ) we have that

  -- -------- --
     @xmath   
  -- -------- --

and so ( 4.79 ) gives that

  -- -------- --
     @xmath   
  -- -------- --

Hence, recalling ( 4.70 ), up to renaming @xmath , we have that

  -- -------- -- --------
     @xmath      (4.81)
  -- -------- -- --------

Notice also that, in the degenerate case, we deduce from ( 4.12 ) and (
4.13 ) that

  -- -------- -- --------
     @xmath      (4.82)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (4.83)
  -- -------- -- --------

with @xmath .

Then, from ( 4.82 ) and ( 4.83 ),

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Comparing this with ( 4.81 ), we conclude that

  -- -------- --
     @xmath   
  -- -------- --

up to renaming @xmath . This gives that hypothesis ( 4.2 ) is fulfilled
in this case with @xmath . ∎

Now we deal with the case of the magnetic operators. We start with the
case of classical space-derivatives. For this, we exploit an elementary,
but useful, inequality, stated in the following auxiliary result:

###### Lemma 4.10.

Let @xmath , @xmath , and @xmath , @xmath , @xmath . Then

  -- -------- -- --------
     @xmath      (4.84)
  -- -------- -- --------

###### Proof.

For any @xmath , we define

  -- -------- -- --------
     @xmath      (4.85)
  -- -------- -- --------

We observe that

  -- -------- -- --------
     @xmath      (4.86)
  -- -------- -- --------

Moreover

  -- -------- -- --------
     @xmath      (4.87)
  -- -------- -- --------

Now we claim that

  -- -------- -- --------
     @xmath      (4.88)
  -- -------- -- --------

for all @xmath . To prove ( 4.88 ) we argue by contradiction and assume
that

  -- -------- --
     @xmath   
  -- -------- --

Then, in view of ( 4.86 ) and ( 4.87 ), we have that

  -- -------- -- --------
     @xmath      (4.89)
  -- -------- -- --------

for some @xmath . As a consequence,

  -- -------- --
     @xmath   
  -- -------- --

which implies that

  -- -------- --
     @xmath   
  -- -------- --

Thus, we substitute this information into ( 4.85 ) and we obtain that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

This is in contradiction with ( 4.89 ) and so it proves ( 4.88 ), which
in turn implies ( 4.84 ), as desired. ∎

With this, we are now in the position of completing the proof of Theorem
4.6 and obtain the desired decay estimates for the classical magnetic
operator.

###### Proof of Theorem 4.6.

We want to prove inequality ( 4.2 ) for the classical magnetic operator
in order to apply Theorem 4.1 . To this end, we aim at proving that

  -- -------- -- --------
     @xmath      (4.90)
  -- -------- -- --------

To check this, we observe ⁵ ⁵ 5 For an alternative proof based on
fractional arguments, see the forthcoming footnote 6 . that we can make
the computations in the vicinity of a point @xmath for which @xmath .
Indeed, if ( 4.90 ) holds true at @xmath , we can fix @xmath and
consider the function @xmath . In this way, @xmath , hence we can
apply ( 4.90 ) to @xmath and conclude that

  -- -------- -- --------
     @xmath      (4.91)
  -- -------- -- --------

Notice that, for any test function @xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

and so (in the distributional sense)

  -- -------- --
     @xmath   
  -- -------- --

Hence, we can pass to the limit in ( 4.91 ) and obtain ( 4.90 ).

Accordingly, to prove ( 4.90 ), from now on we will focus on the case in
which @xmath . We write @xmath and we observe that

  -- -------- -- --------
     @xmath      (4.92)
  -- -------- -- --------

where we used the fact that @xmath is real valued.

On the other hand, at points where @xmath ,

  -- -- -- -------- --
           @xmath   
           @xmath   
  -- -- -- -------- --

therefore

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

From this and ( 4.92 ), we conclude that

  -- -------- -- --------
     @xmath      (4.93)
  -- -------- -- --------

and the latter term is nonnegative, thanks to ( 4.84 ) (applied here
with @xmath , @xmath and @xmath ). This completes the proof of ( 4.90 ).

Then, from ( 4.90 ) here and [ 43 ] (see in particular the formula
before (2.12) in [ 43 ] , exploited here with @xmath and @xmath ),

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

for some @xmath . This establishes inequality ( 4.2 ) in this case, with
@xmath . Hence, Theorem 4.6 follows from Theorems 4.1 and 4.2 . ∎

Now we deal with the fractional magnetic operator.

###### Proof of Theorem 4.7.

We have to verify the structural hypothesis ( 4.2 ). We already know
that the desired inequality holds for the fractional Laplacian @xmath
for @xmath and @xmath (compare Theorem 1.2 of [ 43 ] ). We notice that

  -- -------- -- --------
     @xmath      (4.94)
  -- -------- -- --------

and therefore ⁶ ⁶ 6 Interestingly, integrating and taking the limit as
@xmath in ( 4.94 ), one obtains an alternative (and conceptually
simpler) proof of ( 4.90 ). This is a nice example of analysis in a
nonlocal setting which carries useful information to the classical case.

  -- -------- -- --------
     @xmath      (4.95)
  -- -------- -- --------

Also, since @xmath is a real and positive function, we can exploit
formula (2.25) in [ 43 ] (used here with @xmath ) and write that

  -- -------- --
     @xmath   
  -- -------- --

From this and ( 4.95 ) we infer that condition ( 4.2 ) is satisfied in
this case with @xmath . Then, the desired conclusion in Theorem 4.7
follows from Theorems 4.1 and 4.2 . ∎