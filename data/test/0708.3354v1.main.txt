# Acknowledgements

This work was done under the supervision of Professor Anthony Iarrobino
of Northeastern University and Professor George McNinch of Tufts
University. The author wishes to express his sincere appreciation.

The author wishes to thank Professor Fabrizio Zanello for reviewing an
early draft of this work and offering numerous insightful comments and
suggestions.

The author wishes to thank Professor Juan Migliore for providing a
preprint of [ GHMS06 ] .

The author wishes to thank Emeritus Professor George Leger and Professor
Montserrat Teixidor for their excellent advice throughout the graduate
student period.

###### Contents

-    1 Introduction
-    2 Algebraic Preliminaries
    -    2.1 Level Algebras
    -    2.2 Polynomials as Differential Operators
    -    2.3 Matlis Duality
-    3 Hilbert Functions
    -    3.1 Definitions and Preliminaries
    -    3.2 Splicing
-    4 L-Matrices
    -    4.1 Definitions and Preliminaries
    -    4.2 PV-Matrices as Parameterized Families
-    5 Combinatorial Preliminaries
    -    5.1 Partially Ordered Sets
    -    5.2 The Partially Ordered Set @xmath
    -    5.3 Block L-Matrices Associated to @xmath
-    6 Coefficient Matrices
    -    6.1 Coefficient Matrices of @xmath
    -    6.2 Coefficient Matrices for Constrained Subspaces of @xmath
    -    6.3 Intersections of Subspaces of @xmath
-    7 Special Cases for Interesting Choices of Q
    -    7.1 Absence of Constraints
    -    7.2 @xmath
    -    7.3 Q = (1)
    -    7.4 Essentially n-fold-constrained
        -    7.4.1 @xmath -fold-constrained
        -    7.4.2 @xmath -fold-constrained
        -    7.4.3 @xmath -fold-constrained
        -    7.4.4 @xmath -fold-constrained
-    8 Construction of New Non-Unimodal Level Algebras
    -    8.1 Overview of the Construction of Level Algebras
    -    8.2 Computations by Computer
    -    8.3 Six Families of Level Algebras, together with
        Computer-Calculated Hilbert Functions
    -    8.4 Formulas for @xmath and @xmath
    -    8.5 Formulas for @xmath and @xmath
    -    8.6 Computing @xmath
    -    8.7 Proof of Non-Unimodality
    -    8.8 Computation of Types
-    9 Further Remarks
    -    9.1 For Which Codimensions and Types are Non-Unimodal Level
        Algebras Possible?
    -    9.2 Minimal Socle Degree

Some New Non-Unimodal Level Algebras

## Chapter 1 Introduction

In this section, which is intended to provide an overview, we use some
technical terms without stopping to provide definitions. The definitions
can all be found in later sections.

For over a century, mathematicians have been investigating Hilbert
functions of (standard) graded quotients of polynomial rings, and the
subject is still a focus of active study. In particular, among the
graded quotients are the Gorenstein Artinian graded algebras, which
arise in various contexts. R. Stanley defined a generalization of this
class, the class of level algebras, that is useful for studying
Gorenstein Artinian graded algebras, but is also interesting in its own
right.

The general question for Hilbert functions of level algebras, that is,
what sequences could be their Hilbert functions, is the subject of the
recent paper [ GHMS06 ] , whose introduction provides an excellent
history of work that has been done in this direction to date. Most of
that work proceeds in different directions from what is done in this
thesis.

Here, we focus on a property called unimodality that Hilbert functions
of level algebras sometimes have. In studying unimodality of level
algebras, it is usual to classify them by codimension and type; and one
can ask whether it is possible for a level algebra of some particular
codimension and type to be non-unimodal. The following is a summary of
the history so far, for which the author is indebted to A. Iarrobino, F.
Zanello, and [ BI92 ] .

In codimensions 1 and 2, level algebras of all types are necessarily
unimodal. The level algebras of codimension 1 are sufficiently simple
that this is easy. The investigations in codimension 2 were performed by
F. S. Macaulay in [ Mac04 ] and [ Mac27 ] , written in the first several
decades of the twentieth century .

The next step was in showing that Gorenstein Artinian graded algebras in
codimension 3 are necessarily unimodal. This was done by R. Stanley in [
Sta77 ] , although it was D. Buchsbaum and D. Eisenbud who first
determined the actual Hilbert functions in [ BE77 ] . In [ Sta78 ] ,
Stanley also demonstrated a level algebra in codimension 13 that was not
unimodal.

The next progress was accomplished in [ BI92 ] by D. Bernstein and A.
Iarrobino, who showed that a non-unimodal Gorenstein Artinian algebra
could be found in codimension 5 and in any higher codimension.

Meanwhile, groundwork was being laid for further progress. In
particular, we note the work of J. Emsalem and A. Iarrobino in [ EI78 ]
, which contained some basic concepts underlying the investigation of
catalecticants by A. Iarrobino in [ I84 ] and differently by R. Froberg
and D. Laksov in [ FL84 ] . Investigations of non-unimodality in
Gorenstein Artinian graded algebras were conducted in [ B94 ] by M.
Boij, and by M. Boij and D. Laksov in [ BL94 ] .

In 2005, F. Zanello published the first non-unimodal level algebra in
codimension 3 in [ Z06 ] . Its type is 28. Later that year, A. Iarrobino
used the same general idea to produce a level algebra in codimension 3
of type 5 that, he conjectured, would prove to be non-unimodal, as well
as showing how to perform a similar construction for any type higher
than 5. Iarrobino also suggested methods for codimension 4 that, he
conjectured, would produce non-unimodal level algebras. It is his
construction in codimension 3, as well as some constructions in
codimensions 3, 4, and 5 that proceed along lines suggested by his work,
that are analyzed in this thesis, and shown to be non-unimodal.

As discussed in a later chapter, with a few additional observations we
will be able to summarize the current state of knowledge as follows.
Necessarily Unimodal: Codimensions 1 and 2 of all types, codimension 3
of type 1. Non-unimodals exist: Codimension 3, of types 5 and greater;
codimension 4, of types 3 and greater; codimension 5 and greater, of all
types. Unknown: Codimension 3, types 2, 3, and 4; codimension 4, types 1
and 2.

Among the classes listed as unknown, some useful progress has been made.
In particular, we note [ IS05 ] .

## Chapter 2 Algebraic Preliminaries

### 2.1. Level Algebras

We fix @xmath , an algebraically closed field of characteristic 0.
Throughout this work, it will be implicitly assumed that all our vector
spaces are over the field @xmath .

Let @xmath be the polynomial ring over @xmath in @xmath variables:
@xmath . @xmath can be written as a direct sum @xmath , where the
subspaces @xmath consist of all homogeneous polynomials (forms) in
@xmath of degree @xmath . For every @xmath , @xmath is a
finite-dimensional vector space, of dimension @xmath . One basis of
@xmath consists of all monomials of degree @xmath . By way of notation,
let @xmath be any @xmath -tuple of non-negative integers such that
@xmath . Then @xmath determines a monomial @xmath of degree @xmath , and
monomials of degree @xmath are indexed by the @xmath -tuples @xmath .
@xmath is sometimes called a multi-index of dimension @xmath and degree
@xmath .

When considering the monomials @xmath of @xmath , we sometimes use
lexicographic ordering , defined as follows. For two different
multi-indexes @xmath and @xmath , we say @xmath comes before @xmath if,
in the leftmost co-ordinate for which @xmath , @xmath . In this case, we
write @xmath . By extension, we place an ordering on the monomials of
@xmath : @xmath . In this definition, there is no requirement that
@xmath and @xmath be monomials of the same degree. When listing all
monomials of a fixed degree @xmath , to say that they are listed
lexicographically means that the listing is according to lexicographical
order. For example, if @xmath , we list the monomials of degree 2
lexicographically as follows: @xmath .

If @xmath and @xmath are two multi-indexes, we define their addition and
subtraction co-ordinatewise. That is, @xmath , and @xmath .

The direct-sum decomposition of @xmath makes it a graded @xmath -module,
graded by total degree, since for non-negative integers @xmath and
@xmath , @xmath .

Let @xmath be a homogeneous ideal of @xmath , where @xmath consists of
all forms in @xmath of degree @xmath . We form the quotient ring @xmath
, which is a @xmath -algebra. The direct-sum decomposition @xmath ,
where @xmath , makes @xmath both a graded @xmath -algebra and a graded
@xmath -module. In each case, the grading is by total degree.

In considering @xmath or its graded quotients by homogeneous ideals, the
only grading we will ever use is the grading by total degree, which is
sometimes called standard . From now on, standard grading will always be
implicitly assumed.

For any graded quotient @xmath , we say @xmath is Artinian if it is
finite-dimensional as a vector space. In this case, we write @xmath ,
where @xmath is the largest integer for which @xmath is nonzero. In
writing such a direct sum decomposition, we will always assume @xmath is
nonzero unless otherwise stated.

For an Artinian quotient @xmath , we define soc( @xmath ), the socle of
@xmath , to be the annihilator of the linear part of @xmath : soc(
@xmath }. Soc(A) is easily seen to be a homogeneous ideal of @xmath . We
remark that @xmath soc( @xmath ) since @xmath , but equality need not
hold.

###### Example 2.1.

@xmath ,

where we adopt the usual notation that for any @xmath denotes the
homomorphic image of @xmath in @xmath . Then @xmath , and soc( @xmath )=
@xmath .

An Artinian quotient @xmath is said to be level if @xmath = soc( @xmath
), and in this case we call @xmath the socle degree of @xmath , and we
call @xmath the type of @xmath . If the type @xmath , we say the level
algebra @xmath is Gorenstein .

The following lemma provides an equivalent condition for a graded
Artinian quotient @xmath to be level.

###### Lemma 2.2.

The graded Artinian quotient @xmath is level if and only if

  ------- -- -------- --
  (2.1)      @xmath   
  ------- -- -------- --

###### Proof.

Assume ( 2.1 ) holds. Let @xmath be nonzero, where @xmath and @xmath .
We must show @xmath soc( @xmath ). Reasoning by contradiction, if @xmath
soc( @xmath ), then @xmath , and @xmath , so @xmath . That is, @xmath ,
contradicting ( 2.1 ).

Conversely, assume that @xmath is level, and let @xmath with @xmath . To
prove ( 2.1 ), it suffices to prove the following statement, and then
iterate @xmath times:

  ------- -- -------- --
  (2.2)      @xmath   
  ------- -- -------- --

To prove ( 2.2 ): Since @xmath soc( @xmath ), there exists some @xmath
with @xmath , that is @xmath . This shows @xmath . ∎

###### Corollary 2.3.

If @xmath is a level algebra of socle degree @xmath , then @xmath is
determined by @xmath . More precisely,

  -- -------- --
     @xmath   
  -- -------- --

@xmath

### 2.2. Polynomials as Differential Operators

A good reference for the material in this section is [ IK99 ] , Appendix
A.

Recalling that @xmath is an algebraically closed field of characteristic
0 and @xmath is a polynomial ring in @xmath variables, we define @xmath
, an isomorphic copy of @xmath , where the variables @xmath are written
in lower case to distinguish them from the variables of @xmath . To
distinguish elements of the two rings, we denote elements of @xmath by
uppercase letters @xmath and elements of @xmath by lowercase letters
@xmath .

We let @xmath operate on @xmath according to the rule that, for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and so on, extended by linearity. We remark that this makes @xmath an
@xmath -module, with scalar multiplication @xmath for @xmath . We say
the elements of @xmath act on @xmath as differential operators . If
@xmath is a homogeneous polynomial of degree @xmath , we call @xmath an
@xmath partial derivative of @xmath .

@xmath can be written as a direct sum @xmath , where the submodules
@xmath consist of all homogeneous polynomials (forms) in @xmath of
degree @xmath . For any @xmath , @xmath is a finite-dimensional vector
space, of dimension @xmath . One basis consists of all monomials of
degree @xmath . Analogously with monomials in @xmath , we adopt the
notation that an @xmath -tuple @xmath of non-negative integers such that
@xmath determines the monomial @xmath .

The direct-sum decomposition of @xmath does not make @xmath a graded
@xmath -module, since it obeys a different grading rule:

  -- -------- --
     @xmath   
  -- -------- --

However, if we fix a value of @xmath and consider what happens when
@xmath operates on @xmath , we can view @xmath as the dual vector space
of @xmath . Specifically, we take as basis of @xmath the set of all
monomials @xmath , where as usual @xmath and @xmath . Then, setting
@xmath , we evaluate @xmath ; and for any other monomial @xmath , we
evaluate @xmath . In other words, @xmath is the dual vector to @xmath .

Since @xmath is dual to @xmath , there is a perfect pairing

  ------- -- -------- --
  (2.3)      @xmath   
  ------- -- -------- --

and in this context it makes sense to talk about perpendicular spaces.
Specifically, if @xmath is a vector subspace, @xmath ; and if @xmath is
a vector subspace, @xmath .

### 2.3. Matlis Duality

The material in this section was first considered by F. S. Macaulay in
his work on inverse systems in [ Mac94 ] . For a more recent treatment,
see [ E95 ] or [ G96 ] .

We use the structure described in the previous section to get an
alternative description of what it means for an Artinian graded algebra
@xmath to be a level algebra. We begin with a definition.

If @xmath is a level algebra of socle degree @xmath , then we define
@xmath , a vector subspace. That is,

  -- -------- --
     @xmath   
  -- -------- --

We give another characterization of the vector space @xmath .

###### Lemma 2.4.

@xmath

###### Proof.

Assume @xmath , where @xmath . We must show that @xmath for all @xmath .
This is surely true when @xmath , and it is true when @xmath by
hypothesis. If @xmath , we argue by contradiction. Suppose, for @xmath ,
@xmath and @xmath . Then, recalling that @xmath is dual to @xmath ,
there is at least one vector @xmath such that @xmath . Then @xmath and
@xmath , a contradiction. ∎

Since @xmath is an @xmath -module and @xmath , it is permissible to
consider @xmath , easily seen to be a homogeneous ideal of @xmath . In
fact, this construction just recovers @xmath .

###### Lemma 2.5.

Let @xmath be a level algebra. Then @xmath .

###### Proof.

Since @xmath , @xmath , so @xmath . For the other direction, we must
show that, for all @xmath , @xmath .

For @xmath , @xmath .

For @xmath , @xmath , the last equality being true because the pairing
in @xmath is perfect.

For @xmath , we argue by contradiction. Assume @xmath and @xmath , so
that @xmath Then @xmath , and @xmath . However, by Lemma 2.2 , @xmath ,
a contradiction. ∎

We have defined @xmath to be @xmath . We now wish to characterize @xmath
for values of @xmath .

###### Lemma 2.6.

For @xmath

###### Proof.

For any @xmath and @xmath , we have @xmath . In particular, letting
@xmath range through @xmath and @xmath range through @xmath , we have

  ------- -- -------- --
  (2.4)      @xmath   
  ------- -- -------- --

We can equate the set of those @xmath for which the left-hand side of (
2.4 ) equals 0 with the set for which the right-hand side equals 0.

For the left-hand side,

  -- -------- --
     @xmath   
  -- -------- --

the last equality being guaranteed by Corollary 2.3 . For the right-hand
side,

  -- -------- --
     @xmath   
  -- -------- --

Thus @xmath , so @xmath . ∎

###### Corollary 2.7.

If @xmath is a level algebra, then

  -- -------- --
     @xmath   
  -- -------- --

@xmath

So far we have shown that, given a level algebra @xmath , we can
characterize @xmath as the annihilator (in @xmath ) of a vector subspace
@xmath . We next turn the question around. Given an arbitrary vector
subspace @xmath , we can define

  ------- -- -------- --
  (2.5)      @xmath   
  ------- -- -------- --

It is easy to see that @xmath is a homogeneous ideal. However, is @xmath
a level algebra?

###### Lemma 2.8.

Let @xmath be a vector subspace. Then @xmath is a level algebra.

###### Proof.

First of all, @xmath is Artinian because, for @xmath . To show @xmath is
level, by Lemma 2.2 it is enough to establish that, given @xmath and
@xmath we have @xmath Consider such an @xmath . Since @xmath , there is
some @xmath such that @xmath . @xmath is a nonzero element of @xmath ,
so there exists at least one @xmath such that @xmath . Thus @xmath , and
@xmath as required. ∎

We are now ready to state another characterization of level algebras.

###### Theorem 2.9.

MATLIS DUALITY. Let @xmath be a field of characteristic 0 and let the
elements of @xmath act on @xmath as differential operators. Then the
level quotients @xmath of socle degree @xmath are in bijection with the
nonzero vector subspaces @xmath . Specifically, given @xmath , take
@xmath ; and given @xmath , take @xmath , which is the unique
homogeneous ideal with @xmath such that @xmath is level.

###### Proof.

We first remark that if @xmath , then @xmath and @xmath is the 0-ring,
which is not of socle degree @xmath . This explains the stipulation that
@xmath be nonzero.

We next remark that @xmath . By Lemma 2.8 , @xmath is level, and by
Corollary 2.3 , @xmath is the only level quotient @xmath such that
@xmath .

We define the maps @xmath and @xmath . We must show that @xmath for any
homogeneous ideal @xmath such that @xmath is level of socle degree
@xmath , and @xmath for any nonzero vector subspace @xmath . We have

  -- -------- --
     @xmath   
  -- -------- --

where the last equality follows from Lemma 2.5 . Also

  -- -------- --
     @xmath   
  -- -------- --

where the last equality follows because we showed that @xmath . ∎

###### Lemma 2.10.

Let @xmath be a vector subspace. Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Set @xmath . Then by Theorem 2.9 , @xmath . We substitute theses values
into the formula of Corollary 2.7 , which is permitted because, by Lemma
2.8 , @xmath is a level algebra. ∎

## Chapter 3 Hilbert Functions

### 3.1. Definitions and Preliminaries

As we have seen, level algebras are graded Artinian quotients of the
form @xmath , where @xmath is a homogeneous ideal of @xmath . In
considering a homogeneous ideal @xmath , we will always assume that
@xmath contains no constant or linear polynomials as elements;
equivalently, @xmath and @xmath = 0. The condition that @xmath ensures
that @xmath is nonzero; the condition that @xmath is equivalent to
saying that @xmath is not isomorphic (as a graded ring with standard
grading) to any quotient of a polynomial ring with fewer than @xmath
variables. With this understanding, we define the codimension of @xmath
to be @xmath , the number of variables.

For a graded Artinian quotient @xmath , we define its Hilbert function
@xmath as follows: For non-negative integers @xmath , @xmath . When we
form the level algebra @xmath , where @xmath is a vector subspace of
@xmath , we may write @xmath instead of @xmath .

Notationally, it is sometimes useful to express the Hilbert function as
an h-vector , which is to say a @xmath - tuple of values taken on. In
Example 2.1 , @xmath . As an h-vector, the Hilbert function is written
(1,2,1).

The Hilbert function turns out to be a useful concept in algebraic
geometry. This has been known for many years, but some recent research
has extended the applicability of the Hilbert function in some new ways.
The details are beyond the scope of this thesis, but we describe the
concept, and refer the reader to [ BZ06 ] , [ Mig05 ] , [ Mig06 ] , and
[ GHMS06 ] for basic definitions and further details.

The concept is this: one uses the Hilbert function of a graded Artinian
quotient @xmath and of related algebras to define certain properties of
@xmath , specifically the Uniform Position Property (UPP), Weak
Lefschetz Property (WLP), Strong Lefschetz Property (SLP), and
Unimodality . If a projective scheme is arthmetically Cohen-Macaulay,
one can discover some of its geometric properties by asking whether all
Artinian reductions of its co-ordinate ring have these properties.

We are interested in the last of these properties, unimodality, as it
applies to level algebras. We say the Hilbert function @xmath of a
graded Artinian quotient @xmath is unimodal if there is some degree
@xmath such that @xmath is nondecreasing for values of @xmath between
@xmath and @xmath (inclusive), and nonincreasing for values of @xmath
between @xmath and @xmath (inclusive). Otherwise, we say @xmath is
non-unimodal . By extension, we say @xmath itself is unimodal or
non-unimodal.

If one works with level algebras for even a small amount of time, either
by hand or using a computer, it becomes immediately evident that, in
some sense, non-unimodal Hilbert functions are difficult to find. One
might never find one at all, unless armed with some particular strategy
of construction. Based on this experience, we pose the following
questions:

1.  For @xmath , is every level algebra of codimension @xmath
    necessarily unimodal?

2.  If not, what is the lowest possible type @xmath of a non-unimodal
    level algebra of codimension @xmath ?

3.  For a given codimension @xmath for which type- @xmath non-unimodals
    exist, what is the lowest possible socle degree @xmath ?

For the first question, the answer is yes for @xmath or @xmath , no for
@xmath .

For the second question, the most difficult cases are @xmath and @xmath
. This thesis describes non-unimodal level algebras in codimension 3 of
type 5 or more, and non-unimodal level algebras in codimensions 4 and 5,
of type 3 or more, and proves that they are in fact non-unimodal. The
strategy used in constructing some of them is due A. Iarrobino, who
conjectured that they would turn out to be non-unimodal; others involve
minor variations on Iarrobino’s strategy of construction. For a more
detailed description of the current state of play, please refer back to
Chapter 1.

For the third question, very little is known, and the state of knowledge
appears to be too rudimentary to attempt a comprehensive theory. We will
make a few observations, but prove no results, on this subject in a
later section.

### 3.2. Splicing

In trying to construct non-unimodal Hilbert functions, one strategy is
to build them up out of smaller pieces. We perform our constructions in
the polynomial rings @xmath and @xmath with @xmath variables, and we
focus on the @xmath graded piece @xmath of @xmath . Always, the level
algebras constructed will turn out to have codimension @xmath and socle
degree @xmath ; so when we choose values for @xmath and @xmath we will
say we are fixing the codimension and fixing the socle degree .

We start by fixing the codimension @xmath and the socle degree @xmath .
We consider two vector subspaces @xmath , and for convenience we require
that @xmath , so that @xmath , an internal direct sum. If we know the
Hilbert functions @xmath and @xmath of the level algebras @xmath and
@xmath , it is reasonable to hope that the Hilbert function @xmath of
@xmath will be related to @xmath and @xmath . A first step is provided
by the following lemma.

###### Lemma 3.1.

Fix codimension @xmath and socle degree @xmath . Let @xmath and @xmath
be two vector subspaces of @xmath such that that @xmath . Then for any
@xmath ,

  ------- -- -------- --
  (3.1)      @xmath   
  ------- -- -------- --

with equality if and only if @xmath .

###### Proof.

From Theorem 2.9 and Corollary 2.7 ,

1.  @xmath .

2.  @xmath .

3.  @xmath .

The lemma then follows from the observation that
@xmath . ∎

###### Example 3.2.

@xmath .

For @xmath , we have @xmath since @xmath divides every element of @xmath
but divides no nonzero element of @xmath .

For @xmath , we have @xmath , since @xmath is in the intersection.

One constraint on the dimension of @xmath is that it cannot exceed the
dimension of @xmath , of which it is a subspace:

  ------- -- -------- --
  (3.2)      @xmath   
  ------- -- -------- --

This places an immediate limitation on the choices of @xmath and @xmath
that give equality.

In [ I84 ] , A. Iarrobino proved a result of which the following is a
special case. To state the result, we use the word general in the sense
of algebraic geometry, that is, to say that a statement is true for
general @xmath means that the statement is true for @xmath lying in some
dense Zariski-open subset of @xmath , regarded as an affine variety .
(See, for example, [ Sha94 ] .) We will be more precise about this
notion later on.

###### Theorem 3.3.

With notation as above, let @xmath be arbitrary and let @xmath , the
one-dimensional subspace generated by the single element @xmath . Then
for general @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

@xmath

In other words, for general @xmath , @xmath is as large as it could
possibly be, subject to ( 3.2 ).

We will not rely on Theorem 3.3 because we will sometimes want to chose
non-general @xmath . Instead, we will prove similar-looking results, in
contexts where @xmath , rather than being arbitrary, is required to
satisfy specified conditions.

In order to use Theorem 3.3 or anything similar, it is of course
desirable to know the Hilbert function @xmath . To this end, we quote
another theorem of Iarrobino from [ I84 ] (and others in [ FL84 ] and [
G78 ] ). For details, see, for example, [ IK99 ] .

###### Theorem 3.4.

With the notation above, let @xmath . Then for general @xmath

  ------- -- -------- --
  (3.3)      @xmath   
  ------- -- -------- --

@xmath

We will be proving this theorem (by different methods) and extending it
in a later chapter. For now, to see better what is involved, we work an
explicit example.

We let @xmath and write @xmath , @xmath .

Any @xmath can be written

  ------- -- -------- --
  (3.4)      @xmath   
  ------- -- -------- --

where @xmath are the co-ordinates of @xmath , a 10-dimensional vector
space of which the monomials form a basis.

Setting @xmath , let us compute @xmath , which is the same as the
dimension of @xmath . (Here we have put @xmath , so @xmath .) We compute
@xmath , and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Note that in writing the three partial derivatives, we have listed the
six monomials of degree 2 lexicographically across the page; and we have
listed the three monomials of degree 1 ( @xmath and @xmath ), which
determine which partial derivative is being taken, lexicographically
down the page.

To determine the dimension of @xmath , one must compute the rank of the
3 @xmath 6 coefficient matrix

  -- -- --
        
  -- -- --

Of course, @xmath , and @xmath ; and Theorem 3.4 is saying that the
coefficient matrix has maximal rank for general @xmath .

To generalize the context of Theorem 3.4 , we consider what might happen
if @xmath were defined to be, not a member of the whole space @xmath ,
but instead a member of some vector subspace @xmath generated by
monomials. For example, let @xmath . Then any member @xmath can be
written

  ------- -- -------- --
  (3.5)      @xmath   
  ------- -- -------- --

where we have retained the same coefficient names for purposes of
comparison. Then

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

The matrix of coefficients is now

  -- -------- --
     @xmath   
  -- -------- --

Alternatively, we could have observed that ( 3.5 ) is obtained from (
3.4 ) by substituting @xmath , so the new matrix of coefficients is
obtained from the old one by making the same set of substitutions (and
then deleting the column that consists entirely of zeroes).

As a third example, we modify the previous example. We retain the
definition of @xmath , but this time we let @xmath be generated by two
vectors of @xmath , denoted

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Then, for @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and the matrix of coefficients is now

  -- -------- --
     @xmath   
  -- -------- --

We remark that adding another generator of @xmath created new rows in
the matrix of coefficients without changing the number of columns.

Searching for a generalization of Theorem 3.4 , it is logical to look
more closely at matrices of coefficients and ask whether they provide a
means for computing values of the Hilbert function of @xmath .

## Chapter 4 L-Matrices

### 4.1. Definitions and Preliminaries

Recall that @xmath is an algebraically closed field of characteristic 0.
Let @xmath be a polynomial ring. Then a matrix @xmath is called
PV-matrix over @xmath if every nonzero entry of @xmath has the form
@xmath , where @xmath is a positive integer and @xmath .

A variable @xmath in a PV-matrix @xmath over @xmath is said to move to
the left in @xmath if, whenever the variable @xmath appears in both
@xmath and @xmath , then @xmath . In more precise language: if @xmath
and @xmath with @xmath and @xmath positive integers, then @xmath .

###### Lemma 4.1.

Let @xmath be a PV-matrix in which the variable @xmath moves to the
left. Then @xmath does not appear twice in the same row of @xmath or
twice in the same column of @xmath . If @xmath appears in two distinct
rows, its column in the lower row will be to the left of its column in
the higher row.

###### Proof.

These results follow directly from the definitions. ∎

A PV-matrix @xmath over @xmath in which all variables move to the left
is called an L-matrix .

For example, the three coefficient matrices worked as examples in the
previous chapter are PV-matrices over @xmath . Since all variables move
to the left, they are also L-matrices.

We will be proving several results about the ranks of PV-matrices. The
following lemma is crucial to their proofs.

###### Lemma 4.2.

Let @xmath be a PV-matrix over a polynomial ring @xmath and let @xmath
be a submatrix of @xmath . Then @xmath is a PV-Matrix over @xmath . Any
variable that moves to the left in @xmath moves to the left in @xmath .
If @xmath is an L-matrix, so is @xmath .

###### Proof.

The definitions of PV-matrix and of variables moving to the left put
conditions on the entries of @xmath , and it is immediate that @xmath
inherits them from @xmath . ∎

We remark that it is unusual for some useful property of a class of
matrices to be inherited by its submatrices.

###### Lemma 4.3.

Let @xmath be a square @xmath PV-matrix over @xmath with block
decomposition

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a square @xmath matrix with nonzero determinant (when
@xmath ), @xmath is a square @xmath matrix whose entries on the main
diagonal are all nonzero and all contain variables that move to the left
in @xmath , and the entries of blocks marked @xmath are not restricted.
(To be precise, we assume @xmath ). Then the determinant @xmath of
@xmath is a nonzero polynomial.

###### Proof.

For any non-negative integer @xmath , we prove the lemma for matrices
@xmath for which @xmath is a @xmath matrix. Let @xmath , an @xmath
matrix. We perform induction on @xmath . If @xmath , we start the
induction with @xmath , in which case @xmath has a single nonzero entry,
and the determinant must necessarily be nonzero. If @xmath , we start
the induction with @xmath = @xmath , in which case @xmath = @xmath ,
whose determinant is nonzero by hypothesis.

For the induction step, we assume the result proved for @xmath a @xmath
matrix and @xmath an @xmath matrix, and we prove it for @xmath a @xmath
matrix and @xmath an @xmath matrix.

Let @xmath denote the symmetric group on @xmath letters, and recall that

  ------- -- -------- --
  (4.1)      @xmath   
  ------- -- -------- --

where as usual sgn( @xmath ) is @xmath if @xmath is an even permutation,
@xmath if @xmath is an odd permutation.

Let @xmath . Since the variable @xmath moves to the left, we claim it
can appear only in the entry @xmath of @xmath : Suppose @xmath appears
in @xmath . If @xmath , then @xmath , which is impossible; if @xmath ,
then @xmath , which is again impossible.

If we wish to compute those terms of @xmath in which @xmath appears, we
must take, in ( 4.1 ), those @xmath for which @xmath . Collecting these
terms together into a polynomial @xmath , and letting @xmath denote the
@xmath submatrix of @xmath formed by the first @xmath rows and the first
@xmath columns, we have

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Det @xmath is nonzero by induction and @xmath by hypothesis. This shows
that that @xmath , and hence @xmath , is nonzero. ∎

###### Corollary 4.4.

Let @xmath be a square PV-matrix over @xmath with block decomposition

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a square @xmath matrix with nonzero determinant (when
@xmath ), @xmath is a square @xmath matrix with nonzero entries on the
main diagonal, and the entries of blocks marked @xmath are not
restricted. We assume @xmath . If @xmath is either (a) an L-matrix or
(b) the result of permuting the first @xmath rows and the first @xmath
columns of an L-matrix, then the determinant @xmath of @xmath is
nonzero.

###### Proof.

For case (a), if @xmath is an L-matrix, the variables on the main
diagonal of @xmath move to the left, and the result follows immediately
from Lemma 4.3 . For case (b), if @xmath is the result of permuting the
first @xmath rows and the first @xmath columns of an L-matrix @xmath ,
@xmath is of the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , which is nonzero by hypothesis. Thus, by part (a), @xmath
is nonzero. But @xmath . ∎

###### Corollary 4.5.

Let @xmath be a square @xmath PV-matrix of block form

  -- -------- --
     @xmath   
  -- -------- --

where 0 denotes a block of zeroes, @xmath is a square @xmath matrix with
nonzero determinant, @xmath is a square @xmath matrix with nonzero
determinant, @xmath is a square matrix with nonzero entries on the main
diagonal, and the entries of blocks marked @xmath are not restricted. If
@xmath is either (a) an L-matrix, or (b) the result of permuting the
first @xmath rows and the first @xmath columns of an L-matrix, then
@xmath has nonzero determinant.

###### Proof.

This follows from Corollary 4.4 , taking @xmath to be the submatrix
formed by joining the blocks @xmath and @xmath . ∎

### 4.2. PV-Matrices as Parameterized Families

Let @xmath be a @xmath PV-matrix over @xmath and let @xmath .
Substituting @xmath for each @xmath in @xmath , we obtain the matrix
@xmath , a matrix with entries in @xmath . It is therefore possible to
view @xmath as a family @xmath of matrices with entries in @xmath . We
wish to translate the notion of @xmath having the maximal possible rank
min( @xmath ) into a statement about the family @xmath . We use the word
general in the sense of algebraic geometry: regarding @xmath as an
affine variety, a statement is true for general @xmath if it is true for
all @xmath contained in a dense Zariski-open subset of @xmath .

###### Lemma 4.6.

Let @xmath be a matrix with entries in @xmath having maximal rank. Then
for general @xmath , @xmath has maximal rank.

###### Proof.

We must show there is a dense Zariski-open subset of @xmath on which
@xmath has maximal rank. In fact, we will show that @xmath has maximal
rank @xmath is itself a dense Zariski-open set.

Since @xmath is algebraically closed, @xmath is an irreducible affine
variety. Since @xmath is irreducible, any non-empty open subset is
dense.

Having maximal rank is equivalent to there being at least one maximal
square submatrix with nonzero determinant. Let @xmath be the finitely
many maximal square submatrices of @xmath . For @xmath , let @xmath be
the determinant of @xmath and let @xmath . Then @xmath , so it is enough
to show that each @xmath is Zariski-open and that at least one of them
is nonempty (hence dense).

@xmath is Zariski-open because it is the complement of the zero-set of
@xmath , a polynomial in @xmath . By hypothesis, at least one of the
@xmath is nonzero, say @xmath . Since @xmath is a nonzero polynomial and
@xmath is infinite, there is some @xmath such that @xmath . That is,
@xmath , and @xmath is nonempty. ∎

Before leaving this section, we remind the reader of the rule for
combining two (and by iteration, finitely many) statements, each of
which is true for general @xmath .

###### Lemma 4.7.

Let @xmath and @xmath be two statements, each of which is true for
general @xmath . Then, for general @xmath , @xmath and @xmath are
simultaneously true.

###### Proof.

@xmath is true on some Zariski-open dense set @xmath ; @xmath is true on
some Zariski-open dense set @xmath . @xmath and @xmath being dense,
@xmath is dense as well. That is, @xmath is a Zariski-open dense set on
which @xmath and @xmath are both true. ∎

## Chapter 5 Combinatorial Preliminaries

### 5.1. Partially Ordered Sets

A partially ordered set or poset is a set @xmath together with a binary
relation @xmath satisfying the following three properties (See [ vLW92 ]
.):

-   (Reflexivity) For any @xmath .

-   (Transitivity) For any @xmath , if @xmath and @xmath , then @xmath .

-   (Antisymmetry) For any @xmath , if @xmath and @xmath , then @xmath .

If, for @xmath , @xmath but @xmath , we write @xmath .

In this work, the only partially ordered sets we will be considering are
finite and nonempty. Whenever we use the phrase partially ordered set ,
we will mean a finite, nonempty partially ordered set.

We say two partially ordered sets @xmath and @xmath are isomorphic if
there exists a bijection @xmath such that, for all @xmath , @xmath .

Let @xmath be a partially ordered set and let @xmath . We say @xmath is
a co-ideal or filter or topset if the following condition is satisfied:

  ------- -- -------- --
  (5.1)      @xmath   
  ------- -- -------- --

Similarly, let @xmath be a partially ordered set and let @xmath .We say
@xmath is an ideal or bottomset if the following condition is satisfied:

  ------- -- -------- --
  (5.2)      @xmath   
  ------- -- -------- --

We collect some properties of topsets and bottomsets into a lemma for
future use.

###### Lemma 5.1.

Let @xmath be a partially ordered set.

1.  @xmath is a topset of @xmath if and only if @xmath is a bottomset of
    @xmath .

2.   If @xmath and @xmath are topsets of @xmath , then @xmath and @xmath
    are topsets of @xmath , and @xmath is a topset of @xmath .

3.   Let @xmath be any subset. Then @xmath for some @xmath is a topset
    of @xmath and @xmath for some @xmath is a bottomset of @xmath .

4.   Let @xmath be a topset of @xmath and let @xmath .

    1.   Let @xmath be a topset of @xmath . Then @xmath is a topset of
        @xmath .

    2.   Let @xmath be a topset of @xmath . Then

        1.  @xmath .

        2.  @xmath topsets of @xmath = @xmath is a topset of @xmath .

        3.  @xmath is a topset of @xmath .

        4.   Let @xmath be a bottomset of @xmath . Then @xmath is a
            bottomset of @xmath , and @xmath is a topset of @xmath .

    3.   Let @xmath be a bottomset of @xmath . Then @xmath is a
        bottomset of @xmath .

    4.   Let @xmath be a bottomset of @xmath . Then

        1.  @xmath

        2.  @xmath bottomsets of @xmath = @xmath is a bottomset of
            @xmath .

5.   Recalling that @xmath is finite by definition, let @xmath be the
    finite set of all minimal elements of @xmath . For each @xmath , let
    @xmath be a topset of @xmath containing @xmath . Then @xmath .

###### Proof.

(1) Assume @xmath is a topset. Let @xmath . We must show @xmath . Since
@xmath is a topset, @xmath . That is, @xmath .

Assume @xmath is a bottomset. Let @xmath . We must show @xmath . Since
@xmath is a bottomset, @xmath . That is, @xmath .

(2) Assume @xmath . For @xmath , @xmath is a topset, so if @xmath then
@xmath . That is, if @xmath is a member of both @xmath and @xmath , so
is @xmath ; and if @xmath is a member of @xmath or @xmath , so is @xmath
.

Let @xmath . Then @xmath since @xmath is a topset of @xmath .

(3) Assume @xmath and @xmath . We must show @xmath . Since @xmath ,
@xmath for some @xmath . That is, @xmath , and by transitivity @xmath ,
thus @xmath .

Assume @xmath and @xmath . We must show @xmath . Since @xmath , @xmath
for some @xmath . That is, @xmath , and by transitivity @xmath , thus
@xmath .

(4)(a) Assume @xmath . We must show @xmath . But @xmath because @xmath
is a topset, and @xmath by hypothesis.

(4)(b)(i) We first show @xmath . @xmath since, by reflexivity, @xmath
for all @xmath ; and @xmath by hypothesis.

For the other direction, let @xmath . Since @xmath , there is some
@xmath for which @xmath . Since @xmath and @xmath is a topset of @xmath
, this gives @xmath .

(4)(b)(ii) This follows from the previous results. If @xmath is a topset
of @xmath , then @xmath and @xmath is a topset of @xmath . If @xmath is
a topset of @xmath , then @xmath is a topset of @xmath .

(4)(b)(iii) Let @xmath and @xmath . We must show @xmath or @xmath . If
@xmath , then since @xmath is a topset of @xmath , @xmath . If @xmath ,
then either @xmath , in which case @xmath , since @xmath is a topset of
@xmath ; or else @xmath , in which case @xmath .

(4)(b)(iv) For the first assertion, let @xmath . We must show @xmath ,
so it is enough to show @xmath . This follows from @xmath being a
bottomset of @xmath : @xmath , and @xmath .

For the second assertion, let @xmath . We must show @xmath . That @xmath
follows from @xmath being a topset of @xmath : @xmath . That @xmath
follows from @xmath being a bottomset of @xmath : @xmath ; if @xmath
were an element of @xmath , @xmath would also have to be an element of
@xmath , which it is not.

(4)(c) Assume @xmath . We must show @xmath . But @xmath because @xmath
is a bottomset, and @xmath by hypothesis.

(4)(d)(i) We first show @xmath . @xmath since, by reflexivity, @xmath
for all @xmath ; and @xmath by hypothesis.

For the other direction, let @xmath . Since @xmath , there is some
@xmath for which @xmath . Since @xmath and @xmath is a bottomset of
@xmath , this gives @xmath .

(4)(d)(ii) This follows from the previous results. If @xmath is a
bottomset of @xmath , then @xmath and @xmath is a bottomset of @xmath .
If @xmath is a bottomset of @xmath , then @xmath is a bottomset of
@xmath .

(5) Let @xmath , which is a finite set. We claim that there is a minimal
@xmath such that @xmath . Assuming the claim, @xmath because @xmath is a
topset, and we are done.

To prove the claim: If @xmath is not minimal, there is some @xmath such
that @xmath ; if @xmath is not minimal, there is some @xmath such that
@xmath . Continuing in this manner, we get a chain @xmath , which must
stop because @xmath is finite and (being a partially ordered set)
antisymmetric. ∎

Let @xmath be a partially ordered set. A real-valued function @xmath is
called order-preserving if, for @xmath , @xmath whenever @xmath .

We investigate the connection between order-preserving functions and
topsets. We start by defining two properties that a partially ordered
set might or might not have.

We say that a partially ordered set @xmath has the Topset Positivity
Property (TPP) if @xmath for any order-preserving function @xmath
defined on @xmath such that @xmath and any topset @xmath . We say that
@xmath has the Topset Average Property (TAP) if for any order-preserving
function @xmath defined on @xmath and any nonempty topset @xmath , the
average of the values of @xmath on @xmath is at least as large as the
average of the values of @xmath on @xmath . In symbols, @xmath .

###### Example 5.2.

@xmath , with neither @xmath nor @xmath .

@xmath has neither TPP nor TAP, as can be verified by considering the
order-preserving function @xmath with @xmath , and the topset @xmath .

###### Proposition 5.3.

A partially ordered set @xmath has TAP if and only if it has TPP.

###### Proof.

Assume @xmath has TAP and let @xmath be an order-preserving function on
@xmath such that @xmath . Let @xmath be a nonempty topset. By TAP,
@xmath . And if @xmath is empty, @xmath

For the other direction, assume @xmath has TPP and let @xmath be an
order-preserving function on @xmath . Let @xmath and define a new
order-preserving function @xmath on @xmath by setting @xmath for all
@xmath . We observe that @xmath . For any topset @xmath , TPP gives
@xmath . So

  -- -------- -------- --
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

∎

### 5.2. The Partially Ordered Set @xmath

Let @xmath be an @xmath -tuple of non-negative integers. We define the
set @xmath as follows:

  ------- -- -------- --
  (5.3)      @xmath   
  ------- -- -------- --

We call @xmath the dimension of @xmath or of @xmath .

An element of @xmath will often be called a multi-index . The
multi-index @xmath consisting of all zeroes comes up frequently, and we
sometimes refer to it as @xmath . We give @xmath a partial ordering as
follows:

  ------- -- -------- --
  (5.4)      @xmath   
  ------- -- -------- --

For example, for any @xmath . We note that the partial ordering defined
here is not at all the same as lexicographic ordering, which is also
defined on sets of @xmath -tuples.

As a first step, we consider some linearly ordered subsets of @xmath .
Specifically, for some co-ordinate @xmath , we fix the values of all
co-ordinates of @xmath except the @xmath to be @xmath . We say that the
@xmath -element set

  ------- -- -------- --
  (5.5)      @xmath   
  ------- -- -------- --

is a one-parameter subset of @xmath .

###### Lemma 5.4.

Let @xmath be an order-preserving function on @xmath , let @xmath be a
one-parameter subset of @xmath , and let @xmath be a nonempty topset of
@xmath (under the partial order inherited from @xmath ). Then the
average value of @xmath on @xmath is at least as great as the average
value of @xmath on @xmath . In symbols, @xmath .

###### Proof.

This is an immediate consequence of the definition of order-preserving:
restricting from @xmath to @xmath removes the smallest values of @xmath
. ∎

We next prove a computational lemma.

###### Lemma 5.5.

Let @xmath be an order-preserving function defined on @xmath , let
@xmath , and let @xmath . Consider the two sums:

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Then there is a positive constant @xmath such that @xmath In particular,
if @xmath , then @xmath

###### Proof.

We note that the two sums are taken over the same set of values of
@xmath , and @xmath . Only the values of @xmath are different in the two
sums. The set of multi-indexes @xmath over which the first sum is taken
can be subdivided into one-parameter subsets @xmath , one for each
choice of @xmath ; and then the second sum can be subdivided into
subsets @xmath , where @xmath . For each @xmath , we note that @xmath is
a topset of @xmath (under the partial order inherited from @xmath ),
that there are @xmath elements in @xmath , and that there are @xmath
elements in @xmath . By Lemma 5.4 , for each @xmath we have

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

and summing over all values of @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

or

  -- -------- --
     @xmath   
  -- -------- --

The proof is completed by setting @xmath . ∎

Next we state a result about topsets of @xmath that have the form @xmath
, for some element @xmath .

###### Proposition 5.6.

Let @xmath and let @xmath be an order-preserving function on @xmath such
that

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The first inequality can be rewritten

  -- -------- --
     @xmath   
  -- -------- --

and the second inequality can be written

  -- -------- --
     @xmath   
  -- -------- --

The first is transformed into the second by @xmath iterations of Lemma
5.5 . ∎

We next prove an extension of the previous proposition.

###### Proposition 5.7.

The partially ordered set @xmath has TPP. Equivalently, for any topset
@xmath and any order-preserving function @xmath on @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We proceed by induction on @xmath , the dimension of @xmath . To start
the induction, we must show that TPP holds for @xmath of dimension 1, so
we assume @xmath . Any nonempty topset @xmath has the form @xmath for
some 1-tuple @xmath . So the dimension-1 case follows from Proposition
5.6 .

For the induction step, we assume the proposition proved for @xmath of
dimension @xmath , and prove it for dimension @xmath . We first deal
with the special case that @xmath . In this case, @xmath = @xmath is
isomorphic to @xmath by the bijection @xmath . Since @xmath has
dimension @xmath , the result follows by the induction hypothesis.

To prove the result for arbitrary @xmath of dimension @xmath , assuming
it to be true for lower dimensions, we perform another induction. As the
induction step, we assume that the proposition is true for all @xmath
for which @xmath , …, @xmath , and at least one inequality is strict;
and we prove the proposition for @xmath . To start the induction, we
note that the result is immediate for @xmath . Also, we have already
dealt with the special case that @xmath , so in proving the induction
step we are entitled to assume that @xmath .

To prove the induction step, we assume that @xmath is an
order-preserving function on @xmath such that @xmath , and that @xmath
is a topset. Our goal is to show that @xmath .

We make several definitions. Let @xmath . Let @xmath . We observe that
@xmath . We observe that @xmath since if @xmath is a member of the
topset @xmath then @xmath is also a member.

Let @xmath . We observe that @xmath is isomorphic to @xmath by the
bijection @xmath . We let @xmath and observe that @xmath is a topset of
@xmath by Lemma 5.1 (4)(a).

We let @xmath , and observe that @xmath by Proposition 5.6 . We define a
new order-preserving function @xmath on @xmath according to the rule: if
@xmath ; otherwise, @xmath . To verify that @xmath is order-preserving,
let @xmath and let @xmath . If @xmath , then @xmath . If @xmath , then
@xmath (since @xmath and @xmath ) so @xmath . We observe that

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

the last inequality being true by hypothesis.

We now use the induction hypothesis, applied to @xmath , and @xmath ,
which is applicable because of the previous computation. We deduce that
@xmath . We observe, for use in the next paragraph:

  ------- -- -------- --
  (5.6)      @xmath   
  ------- -- -------- --

Recall that our goal is to show that @xmath . We have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

the last inequality being demonstrated as follows:

1.  By the special case, @xmath has TPP.

2.  @xmath is a topset of @xmath by Lemma 5.1 (2).

3.  TPP @xmath TAP by Proposition 5.3 .

Continuing the computation,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
                       
  -- -------- -------- --

the last inequality having been established as ( 5.6 ). ∎

### 5.3. Block L-Matrices Associated to @xmath

Recall that the elements of @xmath have two different orderings on them.
There is lexicographic order, denoted @xmath , and the partial order,
denoted @xmath .

We say that an L-Matrix @xmath has @xmath pattern if

1.  For each @xmath , there exist non-negative integers @xmath and
    @xmath such that @xmath has block form, with one @xmath block @xmath
    corresponding to each ordered pair @xmath of elements of @xmath .

2.  The block-row indices @xmath occur in lexicographic order.

3.  The block-column indices @xmath occur in reverse lexicographic
    order.

4.  All entries in the block @xmath are nonzero if @xmath and all
    entries are zero if @xmath .

Recalling that in lexicographic order @xmath comes first and @xmath
comes last, an L-matrix with @xmath pattern decomposes into blocks as
follows:

  -- -------- --
     @xmath   
  -- -------- --

Recall that the size of @xmath is @xmath . If we wish to include this
information along with the matrix, we will do it as follows, with the
understanding that the @xmath ’s and @xmath ’s are not matrix entries:

  -- -------- --
     @xmath   
  -- -------- --

We will be interested in determining necessary and sufficient conditions
that that an L-Matrix with @xmath pattern have nonzero determinant.

Let @xmath be an L-Matrix with @xmath pattern. We wish to define the
notion of a superblock of @xmath . Let @xmath be subsets. Then the
@xmath superblock of @xmath is the submatrix composed of all blocks
@xmath such that @xmath and @xmath . A superblock of zeroes is a
superblock of @xmath composed entirely of blocks of zeroes. A maximal
superblock of zeroes is a superblock of zeroes that is not properly
contained in any larger superblock of zeroes.

###### Example 5.8.

Let @xmath , @xmath . @xmath . Abusing notation, @xmath .

Let us analyze an L-Matrix @xmath with @xmath pattern, for the choice of
@xmath in Example 5.8 . According to the definition of @xmath pattern,
the blocks @xmath are composed entirely of zeroes if @xmath and contain
no zeroes if @xmath . The pairs @xmath for which @xmath are:

  -- -------- --
     @xmath   
  -- -------- --

Therefore @xmath has the following block form, where an asterisk denotes
a block that contains only nonzero entries:

  -- -------- --
     @xmath   
  -- -------- --

The four maximal superblocks of zeroes can be demonstrated by placing
spaces into the diagram, as follows, and perhaps permuting the rows and
columns of @xmath (as was done to demonstrate the third maximal
superblock).

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 5.9.

Let @xmath be an L-Matrix with @xmath pattern. Then its maximal
superblocks @xmath of zeroes are determined by the proper nonempty
topsets @xmath : the block @xmath contains precisely those blocks @xmath
such that @xmath and @xmath .

###### Proof.

We first show that any such superblock contains only zeroes. By the
definition of @xmath pattern, it is enough to show that, for any block
@xmath in the superblock, @xmath . But @xmath is an element of the
topset @xmath and @xmath is not, so @xmath .

We next show that, given a superblock @xmath of zeroes, it is a
subsuperblock of one of the @xmath ’s. Since all its constituent blocks
@xmath are 0, we always have @xmath . So if we consider the set @xmath
where some @xmath is in @xmath , then @xmath is a topset by Lemma 5.1
(3), and @xmath is a subsuperblock of @xmath . ∎

In the matrix @xmath with @xmath pattern discussed in connection with
Example 5.8 , we see that the four maximal superblocks of zeroes
correspond, respectively, to the four nonempty proper subsets of @xmath
: @xmath .

For an L-matrix @xmath with @xmath pattern, with block dimensions @xmath
and @xmath as above, we define, for each @xmath , the excess @xmath .
Despite the name, there is no requirement that @xmath , and @xmath can
certainly be a negative number.

###### Lemma 5.10.

Let @xmath be an L-matrix with @xmath pattern and excesses @xmath . Then
@xmath is a square matrix if and only if @xmath .

###### Proof.

The condition is equivalent to @xmath ∎

###### Theorem 5.11.

Let @xmath be a square L-matrix with @xmath pattern and excesses @xmath
. Then the following are equivalent:

1.  @xmath

2.   For any nonempty proper topset @xmath .

3.   For any nonempty topset @xmath .

4.   For any nonempty proper bottomset @xmath .

5.   For any nonempty bottomset @xmath .

###### Proof.

To see that (2) and (3) are equivalent, we observe that a proper topset
of @xmath is the same thing as a topset of @xmath , since the only
topset of @xmath containing @xmath is @xmath itself. Similarly, to see
that (4) and (5) are equivalent, we observe that a proper bottomset of
@xmath is the same thing as a bottomset of @xmath , since the only
bottomset of @xmath containing @xmath is @xmath itself.

To see that (2) and (4) are equivalent, we first observe that
@xmath is a bottomset @xmath = @xmath is a topset @xmath . (See Lemma
5.1 (1).) By Lemma 5.10 , @xmath .

To see that (1) @xmath (2), let @xmath be a nonempty proper topset and
let @xmath be the corresponding maximal superblock of zeroes. Recall
that @xmath consists of blocks @xmath such that @xmath and @xmath . Then
some matrix @xmath , formed by (perhaps) permuting some of the rows and
columns of @xmath , has a decomposition into four superblocks as
follows:

  -- -- --
        
  -- -- --

where 0 represents @xmath . Assume @xmath . Then @xmath , since @xmath
was formed by permuting rows of columns of @xmath . So the first @xmath
columns must be linearly independent, which means the rank of the
superblock @xmath must be at least @xmath . This implies @xmath , that
is, @xmath .

To prove that (2) @xmath (1) takes several pages and constitutes the
remainder of this chapter. We proceed by induction on the size @xmath of
@xmath . We fix a value of @xmath , which remains unchanged throughout
the induction.

We start the induction with @xmath , which is to say @xmath has a single
entry @xmath . For @xmath to have a nonzero determinant, @xmath must be
nonzero. We observe that, for some choice of multi-indexes @xmath and
@xmath , @xmath constitutes the @xmath block of @xmath . That is, @xmath
, and these are the only nonzero @xmath and @xmath . In particular, if
@xmath , the only nonzero values of @xmath are @xmath and @xmath .

To prove the case @xmath : we assume, for every nonempty proper topset
@xmath , that @xmath ; and our goal is to show that the @xmath block has
a nonzero entry. Equivalently, since @xmath has @xmath pattern, we must
show that @xmath .

If @xmath or @xmath , this is immediate. Otherwise, we form the nonempty
proper topset @xmath (See Lemma 5.1 (3).) Since @xmath and @xmath , it
must be that @xmath . That is, @xmath .
For the induction step, we assume that the theorem has been proved for
@xmath , and we let @xmath be an @xmath matrix such that (2) holds. We
must show that the determinant of @xmath is nonzero. To do this, having
Corollary 4.5 in mind, we choose an arbitrary nonempty proper topset
@xmath (switching to @xmath in order to reserve the letter @xmath for
future use) and we set @xmath . Then we permute the rows and columns of
@xmath , if necessary, so that @xmath , the maximal superblock of zeroes
associated to @xmath , is in the upper left. We call this permuted
matrix @xmath , and look at its decomposition into four superblocks.

  -- -------- --
     @xmath   
  -- -------- --

We observe that it was not necessary to permute the last @xmath rows or
the last @xmath columns, since automatically @xmath , which forces the
@xmath block (which is contained in @xmath ) to consist of nonzero
entries. Since we are assuming that (2) holds, we know that @xmath has
at least as many columns as rows, and @xmath has at least as many rows
as columns. We let @xmath denote the leftmost maximal square submatrix
of @xmath , and let @xmath denote the uppermost maximal square submatrix
of @xmath . With this notation, the decomposition of @xmath can be
rewritten

  -- -------- --
     @xmath   
  -- -------- --

This rewriting did not involve any further permuting of the rows and
columns, so we may be sure that the last @xmath rows and the last @xmath
columns have never been permuted from the original @xmath .

In order to show that @xmath has nonzero determinant, it is enough to
show that, for some choice of @xmath , @xmath has nonzero determinant.
According to Corollary 4.5 , we can show that @xmath has nonzero
determinant by showing that (a1) @xmath has nonzero determinant, (b1)
@xmath has nonzero determinant, and (c) the block @xmath lies entirely
within the @xmath block, which guarantees that its rows and columns have
not been permuted and that its entries (and hence its main diagonal
entries) are all nonzero.

In order to show this, we fix some notations. We recall that both @xmath
and @xmath were formed by first permuting some of the rows and columns
of @xmath , and then deleting some of the rows and columns of the
permuted matrix. We observe that the result would have been the same if
we had first deleted the appropriate rows and columns of @xmath and then
suitably permuted the rows and columns of what remained. With regard to
this equivalent alternative construction of @xmath and @xmath , we
define @xmath and @xmath to be the submatrices of @xmath that were
formed by deletion of rows and columns, and were subsequently altered by
permutations of rows and columns to form, respectively, @xmath and
@xmath . We remark that @xmath and @xmath , being submatrices of the
L-matrix @xmath , are themselves L-matrices; and that, in order to show
that @xmath and @xmath have nonzero determinant, it is enough to show
that @xmath and @xmath have nonzero determinant.

In order to use induction, we need to view @xmath and @xmath as
L-matrices with @xmath pattern. To do this, we say that an entry is in
the @xmath block of @xmath or @xmath if it was in the @xmath block of
@xmath . Thus, if we use primes to denote block dimensions and excessess
in @xmath (viz. @xmath ) and double primes to denote block dimensions
and excesses in @xmath (viz. @xmath ),

1.  For all @xmath , @xmath , @xmath , @xmath , @xmath

2.  For all @xmath , and @xmath

3.  For all @xmath , and @xmath

With these notations, we repeat the previous decomposition of @xmath ,
this time including some of the block dimensions.

  -- -- --
        
  -- -- --

With these notations, we can break statement (c) above into two parts:
Statement (a2):

  -- -------- --
     @xmath   
  -- -------- --

and Statement (b2):

  -- -------- --
     @xmath   
  -- -------- --

To state (a1) with the new notations, we use the induction hypothesis to
obtain a set of conditions that @xmath have nonzero determinant:

  -- -------- --
     @xmath   
  -- -------- --

By (ii), this is equivalent to:

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 5.1 (4)(b)(ii), this is equivalent to:

  ------- -- -------- --
  (5.7)      @xmath   
  ------- -- -------- --

Also, we recall (a2):

  -- -------- --
     @xmath   
  -- -------- --

which, since @xmath is square, is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

or

  ------- -- -------- --
  (5.8)      @xmath   
  ------- -- -------- --

We now introduce a condition on @xmath that, we claim, implies both (
5.7 ) and ( 5.8 ):

  ------- -- -------- --
  (5.9)      @xmath   
  ------- -- -------- --

To see that ( 5.9 ) implies ( 5.7 ), let @xmath be a nonempty topset of
@xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

To see that ( 5.9 ) implies ( 5.8 ), apply ( 5.9 ) to @xmath (which is a
topset of itself):

  -- -------- --
     @xmath   
  -- -------- --

Summarizing the progress so far, we have shown that the induction step
will follow if we can demonstrate a maximal superblock @xmath for which
(a1), (a2), (b1), and (b2) hold. We have shown that (a1) and (a2) hold
if @xmath satisfies ( 5.9 ). We now proceed in a completely analogous
fashion to establish another condition on @xmath that will ensure (b1)
and (b2) hold.

To state (b1) with the new notations, we argue similarly, using the
induction hypothesis to obtain a set of sufficient conditions that
@xmath have nonzero determinant:

  -- -------- --
     @xmath   
  -- -------- --

By (iii), this is equivalent to:

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 5.1 (4)(d)(ii), this is equivalent to:

  -------- -- -------- --
  (5.10)      @xmath   
  -------- -- -------- --

Also, we recall (b2):

  -- -------- --
     @xmath   
  -- -------- --

which, since @xmath is square, is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

or

  -------- -- -------- --
  (5.11)      @xmath   
  -------- -- -------- --

We now introduce a condition on @xmath that, we claim, implies both (
5.10 ) and ( 5.11 ):

  -------- -- -------- --
  (5.12)      @xmath   
  -------- -- -------- --

To see that ( 5.12 ) implies ( 5.10 ), let @xmath be a bottomset of
@xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

To see that ( 5.12 ) implies ( 5.11 ), apply ( 5.12 ) to @xmath (which
is a bottomset of itself):

  -- -------- --
     @xmath   
  -- -------- --

Again summarizing the progress so far, we have shown that the induction
step will hold if we can guarantee the existence of a nonempty topset
@xmath of @xmath for which ( 5.9 ) and ( 5.12 ) are true.

Our method of proof is algorithmic. We start with a candidate for @xmath
, namely @xmath , for which ( 5.12 ) is (vacuously) true, but for which
( 5.9 ) may not be true. We describe a procedure for replacing the
current candidate for @xmath by another candidate topset that properly
contains it, a process that must stop because it can be carried out only
a finite number of times. We then show that (i) the procedure results in
a new candidate that also satisfies ( 5.12 ), and (ii) if the process
cannot be continued, the current candidate satisfies ( 5.9 ) as well.
Establishing (i) and (ii) suffices to prove the induction step, and the
theorem.

By way of notation, let @xmath represent the current candidate topset,
which is known to satisfy ( 5.12 ), and let @xmath represent the next
candidate. That is, we start with @xmath = @xmath . If we have a current
@xmath , the procedure to find @xmath is as follows: Among all nonempty
topsets of @xmath , pick a smallest one @xmath (smallest by inclusion)
such that @xmath . We set @xmath .

We note that if no such @xmath exists, @xmath satisfies ( 5.9 ), since
for all nonempty topsets @xmath , we have @xmath , and @xmath . This
establishes (ii).

If @xmath can be found, we note that @xmath is a topset of @xmath by
Lemma 5.1 (4)(b)(iii). We note that @xmath is nonempty because @xmath
and proper because @xmath and @xmath . We note that, by construction,
@xmath and @xmath are disjoint.

We must show that @xmath satisfies ( 5.12 ). That is, for any bottomset
@xmath , we must show that @xmath . For this, it is enough establish the
following two inequalities:

  -------- -- -------- --
  (5.13)      @xmath   
  -------- -- -------- --

and

  -------- -- -------- --
  (5.14)      @xmath   
  -------- -- -------- --

Statement ( 5.13 ) follows immediately from the fact that ( 5.12 ) holds
for @xmath , once one has verified that @xmath is a bottomset of @xmath
, which follows from Lemma 5.1 (4)(b)(iv).

Statement ( 5.14 ) follows from the following two inequalities:

  -------- -- -------- --
  (5.15)      @xmath   
  -------- -- -------- --

and

  -------- -- -------- --
  (5.16)      @xmath   
  -------- -- -------- --

since

  -- -------- --
     @xmath   
  -- -------- --

Statement ( 5.15 ) is true by construction. Statement ( 5.16 ) is
certainly true if @xmath is empty. If @xmath is nonempty it is a topset
of @xmath by Lemma 5.1 (4)(b)(iv), and then ( 5.16 ) follows by
construction, because @xmath is topset of @xmath that is smaller (by
inclusion) than @xmath . ∎

## Chapter 6 Coefficient Matrices

### 6.1. Coefficient Matrices of @xmath

We fix a codimension @xmath and a socle degree @xmath . We consider a
vector subspace @xmath . We fix a degree @xmath and we wish to consider
@xmath . By way of notation, we make the convention that @xmath , @xmath
. Also, whenever we wish to specify that generators @xmath of @xmath are
to be taken from a particular vector subspace @xmath , we will simply
write @xmath .

Let @xmath be a set of multi-indexes of degree @xmath , and define
@xmath . That is, @xmath is a vector subspace of @xmath generated by
monomials. We let @xmath . For each generator @xmath , we write @xmath ,
where each @xmath .

We will always adopt the point of view that the @xmath ’s are allowed to
vary. Specifying a value @xmath for each of them, or equivalently
specifying an element @xmath , determines a particular subspace
@xmath . When we later define the matrices @xmath and @xmath with
coefficients in @xmath , @xmath and @xmath will similarly be specific
matrices with coefficients in @xmath . In other words, from now on we
will view the @xmath ’s, @xmath , @xmath , and @xmath (written without
the @xmath ) as functions whose domain is the irreducible affine variety
@xmath . We will consider the images of these functions as families of
vectors, vector subspaces, or matrices, parameterized by elements @xmath
. Whenever we wish to indicate a specific element of a family, we will
use the notation with the @xmath , sometimes without explicitly
mentioning the @xmath ’s or the @xmath ’s.

###### Lemma 6.1.

For all @xmath , @xmath is generated as a vector space by
@xmath is a monomial of degree @xmath and @xmath .

###### Proof.

Any element of @xmath can be written
@xmath ∎

###### Lemma 6.2.

Let @xmath be a monomial of degree @xmath and @xmath as above. Then

  -- -------- --
     @xmath   
  -- -------- --

where the @xmath ’s are positive integers.

###### Proof.

This follows immediately from the definition of the operation * as
partial differentiation. ∎

We wish to translate the problem of determining @xmath into the language
of matrices. To this end, we define a matrix @xmath , the uncropped
coefficient matrix of @xmath partial derivatives of @xmath , or simply
the @xmath uncropped matrix of @xmath , as follows. (We use the prime to
distinguish it from the @xmath cropped matrix @xmath , to be defined
later.)

The matrix @xmath has rows indexed by ordered pairs @xmath where @xmath
is a multi-index of degree @xmath and @xmath . The rows are ordered
according to the rule that @xmath comes before @xmath if @xmath (in
lexicographic order) or if @xmath and @xmath . The columns of @xmath are
indexed by multi-indexes @xmath of degree @xmath , where @xmath comes
before @xmath if @xmath (in lexicographic order). The entry of @xmath in
the @xmath position is @xmath if @xmath and 0 otherwise.

###### Lemma 6.3.

Let the vector subspace @xmath be defined as above and let @xmath be its
@xmath uncropped matrix. Then @xmath is an L-matrix over
@xmath and @xmath .

###### Proof.

By construction, the entries of @xmath are either 0 or positive integer
multiples of some @xmath . So it remains to show that every @xmath moves
to the left.

Assume @xmath is the variable in two different locations @xmath and
@xmath . We first note that @xmath , since that is the only way (by the
definition of @xmath ) that the variable @xmath can appear at all. Since
the order of the rows @xmath and @xmath in @xmath is determined by
lexicographical order of @xmath and @xmath , and the order of the
columns is determined by lexicographical order of @xmath and @xmath , we
must show @xmath if and only if @xmath .

By way of notation, let @xmath . From the definition of @xmath , @xmath
. So for each co-ordinate @xmath , @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

∎

###### Lemma 6.4.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be its @xmath uncropped matrix. Then for all @xmath , @xmath .

###### Proof.

We combine previous results concerning the vector space @xmath , of
which @xmath is a basis and @xmath is a vector subspace. @xmath is
generated by the vectors @xmath , so to find its dimension we express
each generator as a linear combination of basis vectors and determine
the rank of the matrix of coefficients. Since @xmath , its matrix of
coefficients is @xmath . ∎

### 6.2. Coefficient Matrices for Constrained Subspaces of @xmath

As before, we assume that the codimension @xmath and socle degree @xmath
have been fixed. We now fix a nonegative number @xmath and a multi-index
@xmath , where @xmath for @xmath . We say an @xmath -tuple @xmath of
non-negative integers, of any degree @xmath , is constrained by @xmath
if @xmath for @xmath . We say that a monomial @xmath or @xmath is
constrained by @xmath if I is constrained by @xmath . We define @xmath
to be the set of all multi-indexes of degree @xmath that are constrained
by @xmath . In particular, @xmath is a set of multi-indexes of degree
@xmath , so we can consider @xmath . By way of notation, we will always
write @xmath for @xmath . As in the previous section, we fix degree
@xmath and write @xmath .

###### Lemma 6.5.

Let @xmath be a family of vector subspaces and let @xmath be its @xmath
uncropped matrix. If @xmath is a multi-index of degree @xmath and @xmath
, the @xmath row of @xmath consists entirely of zeroes. If @xmath is a
multi-index of degree @xmath , the @xmath column of @xmath consists
entirely of zeroes.

###### Proof.

For the @xmath entry to be nonzero, we need @xmath . That is, writing
@xmath and @xmath , we must have @xmath for @xmath . This implies @xmath
and @xmath for @xmath . Equivalently, @xmath and @xmath . ∎

Since our interest in @xmath stems from our desire to compute its rank,
we lose nothing by deleting rows and columns that consist entirely of
zeroes. We define @xmath , the cropped coefficient matrix of @xmath
partial derivatives of @xmath , or simply the @xmath cropped matrix of
@xmath , to be the submatrix of @xmath obtained by taking only those
@xmath entries for which @xmath and @xmath . More precisely,

###### Definition 6.6.

For a fixed choice of @xmath , and @xmath , the @xmath cropped matrix of
@xmath is defined as follows:

The rows are indexed by pairs @xmath where @xmath and @xmath , ordered
by the rule that @xmath comes before @xmath if @xmath (in lexicographic
order) or if @xmath and @xmath . The columns are indexed by elements
@xmath , ordered by the rule that @xmath comes before @xmath if @xmath
(in lexicographic order). Writing

  -- -------- --
     @xmath   
  -- -------- --

the entry of @xmath in the @xmath position is @xmath if @xmath and 0
otherwise.

###### Corollary 6.7.

Let the family of vector subspaces @xmath be defined as above, let
@xmath be its @xmath uncropped matrix, and let @xmath be its @xmath
cropped matrix. Then @xmath .

###### Proof.

Removing rows and columns of zeroes does not affect the rank of a
matrix. ∎

###### Corollary 6.8.

For @xmath , let @xmath , let @xmath be its @xmath uncropped matrix, and
let @xmath be its @xmath cropped matrix. Then @xmath .

###### Proof.

Again, removing rows and columns of zeroes does not affect the rank of a
matrix. The second equality simply repeats the statement of Lemma 6.4 .
∎

###### Lemma 6.9.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath cropped matrix of @xmath . Then @xmath is an
L-matrix over @xmath and @xmath .

###### Proof.

By Lemma 6.3 , the uncropped matrix is an L-matrix over
@xmath and @xmath . By Lemma 4.2 , @xmath is as well, since it is
defined to be a submatrix of the uncropped matrix. ∎

The matrix @xmath is an L-Matrix, and we describe a scheme for
subdividing it into blocks @xmath , where @xmath , that makes @xmath an
L-Matrix with @xmath pattern.

Given a multi-index @xmath , we must designate @xmath row indices @xmath
and @xmath column indices @xmath to associate with @xmath . Writing
@xmath , @xmath and @xmath , we associate with @xmath those row indices
@xmath for which @xmath , and we associate with @xmath those column
indices @xmath for which @xmath . We call this assignment of rows and
columns the standard assignment .

###### Lemma 6.10.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath cropped matrix of @xmath . Then the standard
assignment makes @xmath an L-matrix with @xmath pattern.

###### Proof.

We must verify the following statements.

1.  Every row and every column of @xmath is associated to a unique
    @xmath .

2.  The standard assignment subdivides @xmath into blocks. That is, for
    any multi-index @xmath , all rows associated to @xmath are
    consecutive in @xmath , and all columns associated to @xmath are
    consecutive in @xmath .

3.  The block-row indices @xmath occur in lexicographic order, and the
    block-column indices @xmath occur in reverse lexicographic order.

4.  The entries in the block @xmath are nonzero if @xmath and 0
    otherwise.

For (i), consider a row @xmath of @xmath and write @xmath . Then the
only possible candidate for @xmath is @xmath , and we must verify that
it is an element of @xmath . Since @xmath is the cropped matrix, @xmath
, which implies @xmath for each @xmath ; hence @xmath .

Similarly, let @xmath be a column of @xmath and write @xmath . Then the
only possible candidate for @xmath is @xmath , and we must verify that
it is an element of @xmath . This is true because @xmath , so @xmath ,
which is to say @xmath .

For (ii), recall that the ordering of the rows and columns of @xmath is
given in Defintion 6.6 . Assume that @xmath and @xmath are two row
indices associated to @xmath , and that @xmath comes between them. Write
@xmath . We must show that @xmath for @xmath , and we argue by
contradiction. If not, let @xmath be the first co-ordinate in which this
is not so. By the rule for ordering the rows of @xmath , @xmath , so
@xmath , which is impossible if @xmath .

The argument for columns is similar. Assume that @xmath and @xmath are
two column indices associated to @xmath , and that @xmath comes between
them. Write @xmath . We must show that @xmath for @xmath , and we argue
by contradiction. If not, let @xmath be the first co-ordinate in which
this is not so. By the rule for ordering the columns of @xmath , @xmath
, so @xmath , which is impossible if @xmath .

For (iii), let row index @xmath associated to @xmath come before row
index @xmath associated to @xmath . Then @xmath , or as expanded by
co-ordinates, @xmath . That is, either @xmath for @xmath , or else, for
some @xmath , @xmath for @xmath and @xmath ; equivalently, @xmath .

The argument for columns is similar. Let column index @xmath associated
to @xmath come before column index @xmath associated to @xmath . Then
@xmath , or as expanded by co-ordinates, @xmath . That is, either @xmath
for @xmath , or else, for some @xmath , @xmath for @xmath and @xmath .
So either @xmath for @xmath or @xmath for @xmath and @xmath ;
equivalently, @xmath .

For (iv), we recall from the definition of @xmath that the @xmath entry
is nonzero if and only if @xmath . So if @xmath is associated to @xmath
and @xmath is associated to @xmath , the condition for being nonzero
becomes @xmath for @xmath , or equivalently, @xmath for @xmath . But
that is the definition of @xmath . ∎

###### Proposition 6.11.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath cropped matrix of @xmath . Then, with the standard
assignment, the block dimensions @xmath and @xmath of @xmath are given
as follows. Setting @xmath and @xmath , we have:

  ------- -- -------- --
  (6.1)      @xmath   
  ------- -- -------- --

  ------- -- -------- --
  (6.2)      @xmath   
  ------- -- -------- --

###### Proof.

To find @xmath , we count the number of ways of forming multi-indexes
@xmath associated to @xmath . Writing @xmath , and recalling that @xmath
must be of degree @xmath , we see immediately that this is impossible
unless @xmath . In this case, we must assign non-negative integer values
of @xmath that bring the total degree up to @xmath . Equivalently, we
must count the number of monomials of degree @xmath in @xmath variables
(and then multiply by @xmath to account for all possible choices of
@xmath ). As is well-known, there are @xmath monomials of degree @xmath
in @xmath variables, so @xmath when @xmath .

Similarly, to find @xmath we count the number of ways of forming
multi-indexes @xmath associated to @xmath . Writing @xmath , and
recalling that @xmath must be of degree @xmath , we see immediately that
this is impossible unless @xmath . In this case, we must assign
non-negative integer values of @xmath that bring the total degree up to
@xmath . That is, we must count the number of monomials of degree @xmath
in @xmath variables. This gives @xmath when @xmath . ∎

###### Corollary 6.12.

Let the family of vector subspaces
@xmath be defined as above and let @xmath be the @xmath cropped matrix
of @xmath . Under the standard assignment, denote the block dimensions
@xmath and @xmath . If @xmath and @xmath , then @xmath and @xmath . In
particular, both @xmath and the excess @xmath are order-preserving
functions on @xmath .

###### Proof.

This is a consequence of the formulas in Proposition 6.11 . Write @xmath
, @xmath , @xmath , @xmath . We remark that if @xmath , then the
definition of partial order gives @xmath and @xmath .

To see that @xmath is order-preserving, assume that @xmath . If @xmath ,
then @xmath and @xmath as required. If @xmath , then @xmath and @xmath ,
and again @xmath . Finally, if @xmath , then @xmath and @xmath . Since
@xmath , this gives @xmath .

The argument for @xmath is similar. If @xmath , then @xmath and @xmath
as required. If @xmath , then @xmath and @xmath , and again @xmath .
Finally, if @xmath , then @xmath and @xmath . Since @xmath , this gives
@xmath . ∎

###### Theorem 6.13.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath cropped matrix of @xmath . If @xmath has at least
as many rows as columns, then it has maximal rank.

###### Proof.

We use the standard assignment to regard @xmath as an L-matrix with
@xmath pattern. Since it has at least as many rows as columns,

  -- -------- --
     @xmath   
  -- -------- --

By Corollary 6.12 , @xmath is an order-preserving function on @xmath ,
so according to Proposition 5.7 :

  ------- -- -------- --
  (6.3)      @xmath   
  ------- -- -------- --

By Theorem 5.11 , this would settle the matter, if only @xmath were
square. So our goal is to show that we can delete rows, one at a time,
in such a way that, at every stage, ( 6.3 ) remains true for the new
values of @xmath corresponding to the submatrix (still with @xmath
pattern) formed by deleting the row.

At each stage, we consider the subset @xmath , consisting of all
multi-indexes @xmath for which @xmath remains nonzero. When we start
out, @xmath is a topset, because, by Corollary 6.12 , @xmath is
order-preserving: given @xmath such that @xmath and @xmath , we have
@xmath and @xmath . When we delete a row, we always choose a row
associated with an @xmath that is minimal in @xmath , and claim that
@xmath remains a topset: If before the deletion, @xmath , @xmath is
unchanged. If before the deletion, @xmath , the deletion will remove
@xmath from @xmath , and the result will remain a topset. (See Lemma 5.1
(3), setting @xmath ).

So assume at some stage that we have deleted some number of rows from
@xmath , each time diminishing @xmath by 1 for some minimal @xmath , and
that ( 6.3 ) remains true. If we are not yet done, by Lemma 5.10 it must
be that @xmath , that is, the inequality is strict. We seek to find a
minimal multi-index @xmath with the property that any topset @xmath that
contains @xmath has @xmath . If such an @xmath exists, we can delete a
row associated to @xmath (thus diminishing @xmath , and therefore also
@xmath , by 1) and ( 6.3 ) will remain true. The assertion is that such
a minimal multi-index @xmath can always be found.

To prove the assertion, we argue by contradiction. Assume there are
@xmath minimal elements @xmath of @xmath and that each @xmath lies in a
topset @xmath for which @xmath . We claim @xmath . But by Lemma 5.1 (5),
@xmath , and we are assuming @xmath . This contradiction proves the
theorem, once the claim is established.

To establish the claim, we prove by induction on @xmath the statement
that
@xmath . For @xmath , this is true because we have assumed @xmath . For
the induction step, assume @xmath . Write @xmath , and observe that
@xmath is a topset by Lemma 5.1 (2). Then @xmath and @xmath are also
topsets, again by Lemma 5.1 (2), and

  -- -------- --
     @xmath   
  -- -------- --

This forces @xmath , since both terms on the left are non-negative. But
of course @xmath . ∎

We collect several results together into one theorem.

###### Theorem 6.14.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath cropped matrix of @xmath . If @xmath has at least
as many rows as columns, or more generally if @xmath has maximal rank,
then for general @xmath , @xmath .

###### Proof.

By Theorem 6.13 , @xmath having at least as many rows as columns
guarantees that @xmath has maximal rank.

In any event, @xmath is an L-matrix by Lemma 6.9 . By Lemma 4.6 , @xmath
has maximal rank = @xmath for general @xmath , which is the same as
@xmath by Corollary 6.8 . Finally, by Lemma 2.10 , this is the same as
@xmath . ∎

###### Corollary 6.15.

Let the family of vector subspaces
@xmath be defined as above, where @xmath . Then for general @xmath .

###### Proof.

Let @xmath and let @xmath . Then setting @xmath , the @xmath cropped
matrix @xmath of @xmath is @xmath , and we apply Theorem 6.14 . We find
that, for general @xmath , @xmath ; thus @xmath are linearly
independent, and perforce @xmath are also linearly independent. Let
@xmath be the Zariski-open dense set on which @xmath are linearly
independent. Then, as a subset of @xmath , @xmath is Zariski-open; and
it is nonempty, thus dense. Equivalently, for general @xmath , @xmath
are linearly independent, and @xmath . ∎

### 6.3. Intersections of Subspaces of @xmath

For the theorem proved in this section, we select a notation that will
be convenient later. We define, as above, a family of vector subspaces
@xmath . We let @xmath be the @xmath cropped matrix of @xmath and let
@xmath be a submatrix of @xmath . Recalling that the columns of @xmath
are indexed by @xmath , let @xmath be the set of all column indices in
@xmath , and let @xmath be the set of all column indices not in @xmath .
We define, for use in this section and in later sections,

  ------- -- -------- --
  (6.4)      @xmath   
  ------- -- -------- --

We remark a peculiarity of the notation, namely, that @xmath is the same
as @xmath . The difference in notation highlights the distinction that
@xmath is a vector subspace of @xmath , whereas @xmath is a vector
subspace of @xmath . We also define

  -- -------- --
     @xmath   
  -- -------- --

and

  ------- -- -------- --
  (6.5)      @xmath   
  ------- -- -------- --

###### Theorem 6.16.

Let the family of vector subspaces @xmath be defined as above and let
@xmath be the @xmath coefficient matrix of @xmath . Assume that @xmath
is of dimension @xmath and that @xmath is a @xmath square submatrix of
@xmath whose determinant is nonzero. Let @xmath be the set of all row
indices @xmath of @xmath . Let @xmath be a vector subspace such that
@xmath for all @xmath . Then

1.   For general @xmath

2.   If @xmath , then for general @xmath , @xmath and @xmath

###### Proof.

We can express @xmath as an internal direct sum:

  -- -------- --
     @xmath   
  -- -------- --

If we now focus on a particular @xmath , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and we observe from Definition 6.6 that @xmath is the entry of @xmath
appearing in the @xmath position. For a linear combination @xmath , we
have

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The non-vanishing of @xmath (as a polynomial in the coefficients @xmath
of the @xmath ’s), being a Zariski-open condition, guarantees that the
row vectors
@xmath of @xmath are linearly independent for general @xmath . For such
a choice of @xmath , the linear combination
@xmath is never 0 unless all of the @xmath ’s are 0, in which case
@xmath . This gives @xmath , which proves (i).

For (ii), we are considering the special case that @xmath , which is to
say that @xmath has at least as many columns as rows, and that @xmath is
a maximal square submatrix. In this case, @xmath comprises all the rows
of @xmath , which by construction are indexed by @xmath . By Lemma 6.1 ,
@xmath is of degree @xmath , and we have seen in Lemma 6.5 that nothing
is lost by considering only those @xmath that lie in @xmath . Thus
@xmath , and the first statement of (ii) follows from (i).

Finally, for general @xmath , we have assumed @xmath , and of course
@xmath . Thus
@xmath . ∎

## Chapter 7 Special Cases for Interesting Choices of Q

In this chapter we examine some special cases that result from
particular choices of constraints @xmath , some of which will be used
later to construct non-unimodal level algebras. In the first three
sections of this chapter, the following outline will be followed. We
assume that a choice of codimension @xmath and socle degree @xmath has
been made, and we state the constraint @xmath that is to be studied in
the section. We assume that a degree @xmath has been chosen and we set
@xmath . We study the situation that some number @xmath of polynomials
@xmath have been selected from @xmath to generate a vector subspace
@xmath , subject to the condition that all monomials appearing in these
generators are to be constrained by @xmath . That is, we consider the
family of subspaces @xmath , parameterized by elements @xmath . We
remark that the choice of notation has been influenced by context: we
will be applying these results in a context where we have already
defined, for some other constraint @xmath , a family @xmath ,
parameterized by elements @xmath . We let @xmath denote the @xmath
cropped matrix of @xmath .

### 7.1. Absence of Constraints

If we set @xmath and @xmath , there are no actual constraints imposed.
For any degree @xmath , we have @xmath (recalling the definition in
@xmath ; and in particular @xmath . We can easily count @xmath as the
number of monomials of degree @xmath in @xmath variables, namely, @xmath
.

With the results obtained so far, we are in a position to prove one of
the two theorems of A. Iarrobino quoted earlier, although we now restate
it slightly different language.

###### Theorem 7.1.

Consider the family of vector subspaces @xmath . Then for general @xmath

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Given @xmath , we set @xmath and we construct @xmath , the @xmath
cropped matrix of @xmath , which by Lemma 6.9 is an L-matrix. We remark
that all entries of @xmath are nonzero, since for any two multi-indexes
@xmath of degree @xmath and @xmath of degree @xmath , @xmath . Thus, by
Lemma 4.3 every square submatrix of @xmath has nonzero determinant, and
@xmath has maximal rank. That is, its rank is either @xmath , the number
of rows, or @xmath , the number of columns, whichever is smaller;
equivalently, the rank is @xmath . By Theorem 6.14 , for general @xmath
, this is the same as @xmath .
∎

### 7.2. @xmath

In this section we choose @xmath such that @xmath , and consider the
constraint @xmath of dimension @xmath , in which the first @xmath
constraints are @xmath and the remaining @xmath constraints are 0. We do
not exclude the possibility that @xmath .

###### Proposition 7.2.

Let @xmath , fix a socle degree @xmath , and consider the constraint
@xmath in which the first @xmath constraints are @xmath and the
remaining @xmath constraints are @xmath . Let @xmath . Fix a degree
@xmath , and let @xmath . Let @xmath be the @xmath cropped matrix of the
family of vector subspaces @xmath , where @xmath is chosen such that
@xmath . Then

1.  @xmath is a @xmath matrix with at least as many columns as rows, all
    of whose entries are nonzero.

2.  @xmath is of maximal rank @xmath . For general @xmath .

If also @xmath is a vector subspace for which @xmath , where @xmath is a
vector subspace, generated by monomials, such that
@xmath , then

1.   For general @xmath , @xmath .

###### Proof.

Since @xmath , no effective constraint is placed on the first @xmath
variables @xmath . Since @xmath , no other variables are allowed to
appear at all. So for any degree @xmath (defined in @xmath is spanned by
all monomials (of degree d) in which no variables other than @xmath
appear, of which there are @xmath . If we regard @xmath as a vector
subspace of @xmath , we have @xmath .

To show (i): By definition, @xmath has @xmath rows and @xmath columns.
Since @xmath , @xmath has at least as many columns as rows. By
construction, the @xmath row has a nonzero entry whenever @xmath ; this
always happens because if the only nonzero co-ordinates of @xmath and
@xmath occur among the first @xmath , the same is true for @xmath .

For (ii), we apply Lemma 6.9 to show @xmath is an L-matrix, and then
Lemma 4.3 to show @xmath has maximal rank. In fact, since all entries of
@xmath are nonzero, any maximal square submatrix of @xmath has nonzero
determinant, and @xmath has maximal rank. This rank is of course @xmath
, the number of rows.

For (iii), we recall the definition of @xmath from @xmath and we seek to
apply Theorem 6.16 (ii). In order to do so, we must find a maximal
square submatrix @xmath of @xmath whose determinant is nonzero and whose
columns are indexed by multi-indexes @xmath for which the monomial
@xmath is not among the monomial generators of @xmath . This would
ensure that @xmath . Also, the hypothesis that @xmath ensures that, for
all @xmath , @xmath . Thus, provided a suitable @xmath can be found, the
conditions of Theorem 6.16 are met, and we conclude that @xmath for
general @xmath .

Finding @xmath is easy: create @xmath from any @xmath columns
corresponding to indices @xmath for which @xmath is not among the
generators of @xmath . This can be done because we have assumed @xmath .
As remarked above, any maximal square submatrix of @xmath has nonzero
determinant, so in particular @xmath is nonzero.

∎

### 7.3. Q = (1)

In this section, we consider the case that a single variable @xmath is
constrained so that if it appears in any term, it does so with exponent
1.

###### Proposition 7.3.

Let @xmath and let @xmath for some socle degree @xmath . Fix a degree
@xmath , let @xmath , and assume @xmath . Let @xmath be the @xmath
cropped matrix of @xmath . Then

1.  @xmath is a block matrix of the form

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath denotes a block of zeroes and blocks @xmath , and
    @xmath consist entirely of nonzero entries. The dimensions of the
    blocks are

      -- -------- --
         @xmath   
         @xmath   
         @xmath   
         @xmath   
      -- -------- --

2.  @xmath has maximal rank.

If also @xmath is a vector subspace for which @xmath , where @xmath is a
vector subspace generated by @xmath monomials, in @xmath of which @xmath
appears (with exponent 1) and in @xmath of which @xmath does not appear,
then

1.  @xmath for general @xmath if both

      ------- -- -------- --
      (7.1)      @xmath   
      ------- -- -------- --

    and

      ------- -- -------- --
      (7.2)      @xmath   
      ------- -- -------- --

###### Proof.

For (i), we apply Lemma 6.10 to establish that @xmath is an L-matrix
with @xmath pattern. Since @xmath , which for simplicity we will write
as @xmath , the order of rows, which must be lexicographic, is 1 then 0,
and the order of columns, which must be reverse lexicographic, is 0 then
1. The entries of block @xmath are zero if and only if @xmath , that is,
only when @xmath and @xmath .

To establish the dimensions of the blocks, we use the formulas in
Proposition 6.11 , with @xmath , and @xmath .

For (ii): From the formulas in (i) and the hypothesis that @xmath , we
see that @xmath has at least as many columns as rows, so it suffices to
show that the rightmost square submatrix @xmath has nonzero determinant.
If @xmath contains no entries from the 0 block, its entries are all
nonzero, and @xmath is nonzero by Lemma 4.3 . Otherwise, @xmath contains
blocks @xmath and @xmath in their entirety, and has the form

  -- -------- --
     @xmath   
  -- -------- --

By Theorem 5.11 , @xmath will be nonsingular if, for every nonempty
proper bottomset @xmath , @xmath , where @xmath is the excess @xmath .
Since @xmath , its only nonempty proper bottomset is @xmath , so the
condition reduces to @xmath , that is, @xmath . This last condition
follows from the formulas in (i) because we have assumed @xmath .

For (iii), we apply Theorem 6.16 (ii). To do so, we must construct a
square submatrix @xmath of @xmath with nonzero determinant, such that
the @xmath monomial generators of @xmath lie in @xmath . Assuming this,
the hypothesis that @xmath ensures that @xmath for all @xmath . Thus,
provided a suitable @xmath can be found, the conditions of Theorem 6.16
are met, and we conclude that @xmath for general @xmath .

So we ask under what circumstances a suitable submatrix @xmath of @xmath
can be found. One requirement is that @xmath have enough columns so
that, when @xmath of them are not used, there are still enough columns
left to form a square @xmath submatrix @xmath . That is, we require
@xmath . Assuming this, we must still ask whether we can find a suitable
submatrix @xmath whose determinant is nonzero. To this end, we delete
from @xmath the @xmath columns corresponding to the generators of @xmath
, to obtain a submatrix @xmath of the form

  -- -------- --
     @xmath   
  -- -------- --

and we argue as in part (ii): If the rightmost square submatrix @xmath
of @xmath has no entries from the @xmath block, @xmath is nonzero by
Lemma 4.3 . Otherwise, the condition from Theorem 5.11 is that @xmath ,
or equivalently
@xmath . ∎

The following special case will be of interest later.

###### Corollary 7.4.

Let @xmath , @xmath and @xmath for some socle degree @xmath . Fix a
degree @xmath , let @xmath , and assume @xmath . Let @xmath be the
@xmath cropped matrix of the family of vector subspaces @xmath . Then

1.  @xmath has maximal rank @xmath .

2.   For general @xmath .

###### Proof.

We use Proposition 7.3 for the case that @xmath .

For (i): @xmath is of maximal rank, which is the number of rows.
Substituting @xmath into the formulas for the number of rows in each
block gives

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), @xmath has maximal rank for general @xmath by Lemma 4.6 , and
this rank is @xmath by Corollary 6.8 .

∎

### 7.4. Essentially n-fold-constrained

In this section, we find it convenient to assume that exactly @xmath of
the variables are constrained to have less than the full range of
exponents. In this case, we will say that, for any degree @xmath , the
multi-indexes in @xmath and their corresponding monomials are
essentially n-fold-constrained , or simply n-fold-constrained .

We wish to compute @xmath , or equivalently the dimension of the vector
space generated by monomials of degree @xmath constrained by @xmath .
For the purposes of this computation, we may as well assume that the
constrained variables are listed first; that is, we assume @xmath is a
constraint of dimension @xmath where @xmath for @xmath . The following
lemma makes this precise.

###### Lemma 7.5.

Fix codimension @xmath and socle degree @xmath , and let @xmath be a
constraint of dimension @xmath , such that @xmath are all strictly less
than @xmath and the rest of the @xmath ’s are equal to @xmath . Let
@xmath be another constraint of dimension @xmath whose entries are
related to those of @xmath via some permutation @xmath of @xmath , such
that the entries equal to @xmath all come last. Then for any degree
@xmath , @xmath .

###### Proof.

We define a function @xmath , evidently a bijection, from the set of all
@xmath -tuples of degree @xmath to itself, induced by @xmath , as
follows. If @xmath , then
@xmath @xmath .

We now claim that a multi-index @xmath of degree @xmath lies in @xmath
if and only if the multi-index @xmath lies in @xmath : the first
condition is that, for each @xmath , @xmath ; the second is that, for
each @xmath , @xmath , which is the same as the first condition because
@xmath .

Since @xmath is a bijection, its restriction to @xmath is a bijection
from @xmath to its image @xmath . ∎

###### Lemma 7.6.

Fix codimension @xmath and socle degree @xmath , and let @xmath be a
constraint on @xmath -tuples that fails to constrain the value of at
least one co-ordinate. Then the function @xmath is a non-decreasing
function of @xmath for @xmath .

###### Proof.

We must show that if @xmath , then @xmath . Let the value of the @xmath
coordinate not be constrained. Then for any element @xmath , there is a
corresponding element @xmath . ∎

Getting closed formulas of a simple form will sometimes not be possible
for some values of @xmath , but we will typically find that patterns
emerge when @xmath is large enough. We classify the results by @xmath ,
the number of constraints. In order to state the results more concisely,
we define @xmath and @xmath for @xmath . We denote a multi-index of
degree @xmath constrained by @xmath as @xmath .

#### 7.4.1. @xmath-fold-constrained

###### Proposition 7.7.

When multi-indexes are @xmath -fold constrained by @xmath , @xmath for
@xmath .

###### Proof.

The largest possible degree of any multi-index is @xmath . So for @xmath
, no multi-indexes are possible. ∎

#### 7.4.2. @xmath-fold-constrained

###### Proposition 7.8.

When multi-indexes are @xmath -fold constrained by @xmath ,
@xmath for @xmath .

###### Proof.

All but one of the variables are constrained, and the last is allowed to
vary. Thus, for any degree @xmath , any choice of @xmath can be
augmented by @xmath in a unique way to create a monomial of degree
@xmath . Since each @xmath can be chosen in @xmath ways, we have @xmath
. ∎

#### 7.4.3. @xmath-fold-constrained

###### Proposition 7.9.

Let @xmath and let multi-indexes be @xmath -fold constrained by @xmath .
Let @xmath and @xmath . Then for @xmath , @xmath

###### Proof.

We proceed by induction on @xmath , starting with @xmath . For the
initial case, we are counting multi-indexes @xmath such that @xmath .
For any choice of @xmath , we can complete @xmath by choosing values of
@xmath and @xmath whose sum is @xmath , and there are @xmath ways to do
it. So for @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

In the induction step, we assume the proposition has been proved for
@xmath and we prove it for @xmath . For a fixed choice of @xmath , we
ask how many choices of
@xmath are permissible. This amounts to asking the value of
@xmath , for dimension @xmath and constraint @xmath , which we claim
satisfies the hypothesis of the proposition: @xmath -tuples are @xmath
-fold constrained by @xmath ; and we have @xmath since @xmath and @xmath
. Applying the induction hypothesis,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

For the cases @xmath and @xmath , we will need to know @xmath for
smaller values of @xmath than those covered by Proposition 7.9 .

###### Proposition 7.10.

Let @xmath and let multi-indexes be once-constrained by
@xmath Then

1.  @xmath for @xmath @xmath @xmath

2.  @xmath for @xmath

3.  @xmath for @xmath

###### Proof.

We start with the formulas from Proposition 7.9 ,

  -- -------- --
     @xmath   
  -- -------- --

Viewing the left- and right-hand sides of this equation as polynomials
in @xmath , we see they agree for the infinitely many integer values of
@xmath such that @xmath , and hence must agree for all @xmath .

We remark that, for values of @xmath , a valid expression for @xmath can
be obtained as before, by summing terms of the form @xmath , for a
suitable range of values of @xmath . We now investigate how to do this
for @xmath and @xmath .

For @xmath , the summation ends with @xmath . Equivalently, one can take
the previous summation and subtract the term for @xmath . That is,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath , the terms with @xmath having the values @xmath and @xmath
must be omitted. That is,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

When @xmath , we have @xmath . So all of the @xmath multi-indexes of
degree @xmath satisfy the condition of being constrained by @xmath .
Equivalently, @xmath . ∎

###### Proposition 7.11.

Let @xmath and let multi-indexes be twice-constrained by @xmath Then

1.  @xmath for @xmath @xmath @xmath

2.  @xmath for @xmath

3.  @xmath for @xmath

###### Proof.

The formula for @xmath is given by Proposition 7.9 . An alternative
formula is derived as follows, in a manner similar to the codimension
@xmath case. We are counting multi-indexes @xmath such that @xmath and
@xmath . For any choice of values of @xmath and @xmath , we can complete
@xmath by choosing values of @xmath and @xmath whose sum is @xmath , and
there are @xmath ways to do it. So for @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

As in the previous theorem, we can regard the left- and right-hand sides
of

  -- -------- --
     @xmath   
  -- -------- --

as an identity in @xmath . And again, the same argument justifies the
right-hand side as an expression for @xmath when @xmath or @xmath ,
except that the range of summation must change.

For @xmath , the term with @xmath and @xmath must be omitted. That is,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath , there are three terms that must be omitted: those with
@xmath and @xmath ; with @xmath and @xmath ; and with @xmath and @xmath
; that is,

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

When @xmath , we have @xmath and @xmath . So all of the @xmath
multi-indexes of degree @xmath satisfy the condition of being
constrained by @xmath . Equivalently, @xmath . ∎

#### 7.4.4. @xmath-fold-constrained

For @xmath -fold-constrained monomials, a
closed-form expression would be complicated. We give a formula involving
summations, and then obtain closed-form expressions for the cases that
@xmath is 4 or 5.

###### Proposition 7.12.

Let @xmath and let multi-indexes be @xmath -fold constrained by @xmath .
Then for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Once again, the approach is similar to the previous cases. We are
counting multi-indexes @xmath such that @xmath . For any choice of
values of @xmath , we can complete @xmath by choosing values of @xmath
and @xmath whose sum is @xmath , and there are
@xmath ways to do it. ∎

###### Corollary 7.13.

Let @xmath and let multi-indexes be once constrained by @xmath . Then
for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We apply the formula from Proposition 7.12 .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
                       
                       
              @xmath   
              @xmath   
  -- -------- -------- --

∎

We remark that substituting @xmath gives a confirmation of the formula
in Corollary 7.4 .

###### Corollary 7.14.

Let @xmath and let multi-indexes be twice constrained by @xmath . Then
for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We apply the formula from Proposition 7.12 . The computation is similar
in nature to that of the previous corollary. We omit the details. ∎

## Chapter 8 Construction of New Non-Unimodal Level Algebras

In this chapter we construct several families of non-unimodal level
algebras. As was mentioned in an earlier chapter, some of the algebras
described here were described and conjectured to be non-unimodal by A.
Iarrobino in 2005 following lines suggested by F. Zanello in [ Z06 ] ,
and all of them use the same general framework of Iarrobino and Zanello.
What is new here is that we prove these algebras to be non-unimodal.

### 8.1. Overview of the Construction of Level Algebras

In this section we co-ordinate earlier results and describe our
framework for constructing new non-unimodal level algebras. We review
some notation from previous sections, establish some new notation, and
give an overall description of the process. This section is meant to be
a qualitative overview. The quantitative statements that ensure
non-unimodality are proved in later sections.

We let @xmath be an algebraically closed field of characteristic @xmath
and define @xmath and @xmath . As previously described, the elements of
@xmath act as differential operators on @xmath . Specifically, we will
let @xmath take the value @xmath , or @xmath , and it will be convenient
to reduce the number of subscripts by defining @xmath , and @xmath ;
also @xmath , and @xmath .

We fix a positive integer @xmath that will become the socle degree of
the level algebra of codimension @xmath being constructed. For any
constraint @xmath of dimension @xmath such that @xmath for @xmath , we
let @xmath denote the set of multi-indexes of dimension @xmath and
degree @xmath constrained by @xmath . We define @xmath . We define
@xmath to be the vector subspace of @xmath spanned by all monomials
@xmath such that @xmath . For a degree @xmath , we define @xmath to be
the vector subspace of @xmath spanned by all monomials @xmath such that
@xmath .

We consider two constraints @xmath of dimension @xmath and
@xmath of dimension @xmath , and use them as follows.

We choose a positive integer @xmath and specify a family of vector
subspaces @xmath parameterized by elements of the irreducible affine
variety @xmath , where such an element represents a choice @xmath of
coefficients for the polynomials @xmath . We construct, for general
@xmath , the graded level algebra @xmath . We remark that our previous
discussion of Matlis Duality (in Chapter 2, section 3) motivates this
construction, and in particular that Theorem guarantees @xmath is level.

If @xmath is sufficiently large, then for general @xmath the Hilbert
function @xmath of @xmath is computed, according to Theorem 6.14 , by
the rule @xmath , where @xmath and @xmath is the @xmath cropped matrix
of @xmath .

We will always choose @xmath so that the monomials are @xmath -fold
constrained. That is, for @xmath , @xmath , where for technical reasons
we require that @xmath . For @xmath , @xmath or @xmath , where we
require respectively that @xmath or @xmath . For @xmath , @xmath , where
we require that @xmath . To compute values of @xmath , we rely on
Propositions 7.9 , 7.10 , and 7.11 , which deal with monomials that are
@xmath -fold constrained. In these propositions, the definition is made
that @xmath . However, again to reduce the number of subscripts, we
define @xmath . Also, we define @xmath to be either @xmath , or @xmath ,
according to whether @xmath , or @xmath .

We next perform a similar construction to specify another family of
vector subspaces of @xmath . This time we choose a positive integer
@xmath , which for the examples here will always be either @xmath or
@xmath , and specify a family of vector subspaces @xmath parameterized
by elements of the irreducible affine variety @xmath , where such an
element represents a choice @xmath of coefficients for the polynomials
@xmath . Then we construct, for general @xmath , the graded level algbra
@xmath .

The specific constraint @xmath varies according to the family of
non-unimodals being constructed, as follows. For @xmath , @xmath . For
@xmath , @xmath , or @xmath . For @xmath , @xmath .

For these choices of constraints, the Hilbert function @xmath of @xmath
is computed according to Proposition 7.2 or Corollary 7.4 .

Having constructed families of vector subspaces @xmath and @xmath , we
can construct the family @xmath and consider the family of level
algebras @xmath with corresponding Hilbert functions @xmath . For
general @xmath and @xmath , we will prove that @xmath and that @xmath is
non-unimodal.

We establish some terminology for discussing non-unimodality of a
Hilbert function @xmath .

###### Definition 8.1.

The terms single drop, double drop, initial degree, final degree , and
critical range are defined as follows.

If for some degree @xmath , @xmath , we say that @xmath has a single
drop with initial degree @xmath and final degree @xmath . If for some
degree @xmath , @xmath we say that @xmath has a double drop with initial
degree @xmath and final degree @xmath . In this chapter, we will use the
variables @xmath and @xmath to represent the candidates for the initial
and final degrees of a single or double drop. We say that a degree
@xmath is in the critical range if @xmath .

To establish, for general @xmath and @xmath , that @xmath exhibits a
single drop with initial degree @xmath , our method will be to show that

  -- -------- --
     @xmath   
  -- -------- --

and then to establish that @xmath for @xmath ; similarly for a double
drop. To this end, we define differences
@xmath and @xmath .

###### Lemma 8.2.

Assume, for some degree @xmath , that

  -- -------- --
     @xmath   
  -- -------- --

and that

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

This follows immediately from the definitions. ∎

Finally, we will need to establish, for appropriate values of @xmath ,
that the Hilbert functions @xmath and @xmath do indeed add as desired.
To this end, we will be using Lemma 3.1 together with Propositions 7.2
and 7.3 .

### 8.2. Computations by Computer

Direct computation is difficult with polynomials of high degree having
many terms; instead, we use the [ Macaulay2 ] computer program. We set
the field @xmath equal to @xmath , a large finite field (as suggested in
[ E01 ] ); the finiteness permits rapid calculations and gives access to
some special applications that are implemented only for finite fields.
Following suggestions of A. Iarrobino, to simulate the selection of
general members of a vector space we first generate pseudorandom scalars
on the computer; for a fixed basis, we then use these scalars as
coefficients to produce members of the vector space; and we hope that
this procedure does in fact approximate the selection of general
members. We use the command “fromDual( @xmath )” to compute @xmath for a
vector subspace @xmath .

Computers are useful for comprehension and they sometimes provide
persuasive plausibility arguments. But the proofs of non-unimodality
given here are entirely independent of computer results.

### 8.3. Six Families of Level Algebras, together with
Computer-Calculated Hilbert Functions

In this section we define six parameterized families @xmath of level
algebras according to the program of the previous section. That is, for
each choice of parameters we obtain a family of algebras. We will show,
in a later section, that each choice of parameters yields a family of
algebras that are non-unimodal for general @xmath and @xmath . In this
section, we confine ourselves to definitions, examples, and display of
computer results.

For each parameterized family, one of the parameters is @xmath , which
denotes the initial degree of the single or double drop that (we will
subsequently prove) occurs in the Hilbert function. It is not necessary
to specify the final degree @xmath as another parameter, because its
value can be calculated from @xmath , once we make the claim that all
algebras in families @xmath , and @xmath have a single drop (so that
@xmath ) and all algebras in families @xmath , and @xmath have a double
drop (so that @xmath ).

For each family we specify that the parameter @xmath , the number of
vectors generating @xmath , be @xmath -sufficient , by which we mean
that the @xmath cropped matrix of @xmath should have at least as many
rows as columns, a condition motivated by Theorem 6.14 . For now, we do
not state the precise values of @xmath that are @xmath -sufficient,
postponing the discussion until Lemma 8.19 . The number @xmath of
vectors generating @xmath is not a parameter, since it is fixed within
each family. The type of the resulting level algebra is then min @xmath
.

When displaying computer results, we will simplify notation by writing
@xmath instead of @xmath .

###### Definition 8.3.

The family @xmath is obtained by setting @xmath , @xmath , @xmath ,
@xmath , @xmath . We require that @xmath , that @xmath , and that @xmath
be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath , @xmath . We set socle
degree @xmath . We define constraints @xmath with @xmath and @xmath with
@xmath . We define the vector space @xmath as the span of 4 general
members of @xmath ; @xmath as the span of one general member of @xmath .
Then @xmath := @xmath . According to Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 8.4.

The family @xmath is obtained by setting @xmath ,
@xmath , @xmath , @xmath , @xmath . We require that @xmath be odd, that

  ------- -- -------- --
  (8.1)      @xmath   
  ------- -- -------- --

and that @xmath be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath ,
@xmath . We set socle degree @xmath . We define constraints @xmath with
@xmath and @xmath with @xmath . We define the vector space @xmath as the
span of 14 general members of @xmath ; @xmath as the span of two general
members of @xmath . Then @xmath := @xmath . According to Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 8.5.

The family @xmath is obtained by setting @xmath , @xmath , @xmath ,
@xmath , @xmath . We require that @xmath , that @xmath , and that @xmath
be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath ,
@xmath . We set socle degree @xmath . We define constraints @xmath with
@xmath and @xmath with @xmath . We define the vector space @xmath as the
span of two general members of @xmath ; @xmath as the span of one
general member of @xmath . Then @xmath := @xmath . According to
Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 8.6.

The family @xmath is obtained by setting @xmath , @xmath , @xmath ,
@xmath , @xmath . We require that @xmath , that @xmath be even, that
@xmath , and that @xmath be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath ,
@xmath . We set socle degree @xmath . We define constraints @xmath with
@xmath and @xmath with @xmath . We define the vector space @xmath as the
span of two general members of @xmath ; @xmath as the span of one
general member of @xmath . Then @xmath := @xmath . According to
Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 8.7.

The family @xmath is obtained by setting @xmath ; @xmath , where @xmath
is the largest integer such that @xmath ; @xmath ; @xmath ; @xmath . We
require that @xmath , that @xmath not be equal to a binomial coefficient
of the form @xmath , that @xmath ; that

  ------- -- -------- --
  (8.2)      @xmath   
  ------- -- -------- --

and that @xmath be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath ,
@xmath . We set socle degree @xmath . We define constraints @xmath with
@xmath and @xmath with @xmath . We define the vector space @xmath as the
span of 7 general members of @xmath ; @xmath as the span of one general
member of @xmath . Then @xmath := @xmath . According to Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 8.8.

The family @xmath is obtained by setting @xmath , @xmath , @xmath ,
@xmath , @xmath . We require that @xmath , that @xmath , and that @xmath
be @xmath -sufficient.

EXAMPLE @xmath : Let @xmath , @xmath , @xmath ,
@xmath . We set socle degree @xmath . We define constraints @xmath with
@xmath and @xmath with @xmath . We define the vector space @xmath as the
span of two general members of @xmath ; @xmath as the span of one
general member of @xmath . Then @xmath := @xmath . According to
Macaulay2:

  -- -------- --
     @xmath   
  -- -------- --

Before entering a discussion of the six families defined here, we stop
to check that they are all nonempty.

###### Proposition 8.9.

For any of the families @xmath , it is possible to find values of the
parameters that satisfy the requirements set forth in their definitions.

###### Proof.

For each of the families, it is immediate that all parameters except
@xmath can be chosen consistent with the requirements of the definitions
of the families. So it is enough to show that, for any such choice,
@xmath is @xmath -sufficient.

Setting @xmath and @xmath , the size of the @xmath cropped matrix is
@xmath . To verify it has at least as many rows as columns when @xmath ,
we observe

  -- -------- --
     @xmath   
  -- -------- --

the last inequality following from Lemma 7.6 . ∎

### 8.4. Formulas for @xmath and @xmath

Recall that in definition 8.1 we have defined degrees @xmath to lie in
the critical range if @xmath , where @xmath and @xmath are the initial
and final degrees of a proposed single or double drop; and we have
specified that @xmath and @xmath are candidates for having a single drop
with initial degree @xmath , whereas @xmath , and @xmath are candidates
for having a double drop with initial degree @xmath . Also recall that
@xmath was defined to be @xmath or @xmath , depending on whether the
codimension is 3, 4, or 5.

###### Lemma 8.10.

For any of the families @xmath , the values of @xmath are given as
follows for degrees @xmath in the critical range.

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

###### Proof.

Propositions 7.10 , 7.11 , and 7.9 yield the formulas above, provided we
verify that @xmath is large enough.

For @xmath , the condition is that @xmath . This is true for @xmath ,
since @xmath ; and for @xmath , since @xmath .

For @xmath , the condition is that @xmath . Recall that for @xmath ,
@xmath and @xmath ; for @xmath , @xmath and @xmath . In either case, we
use the fact that, for @xmath and @xmath , @xmath . For @xmath , @xmath
. For @xmath , @xmath . For @xmath , @xmath , where the last inequality
was required to hold in the definition of @xmath .

For @xmath , the condition is that @xmath . For @xmath , @xmath and
@xmath , so @xmath . ∎

###### Proposition 8.11.

For any of the families @xmath , let @xmath lie in the critical range.
Then for general @xmath ,

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

###### Proof.

Recall that the hypothesis that @xmath is @xmath -sufficient means that
the @xmath cropped matrix of @xmath has at least as many rows as
columns. This matrix has @xmath rows and @xmath columns. We observe
that, for any @xmath in the critical range, the @xmath cropped matrix of
@xmath also has at least as many rows as columns, since by Lemma 7.6 it
has @xmath rows and @xmath columns. So for all values of @xmath in the
critical range, Theorem 6.14 applies, and for general @xmath we have
@xmath , the rank of the @xmath cropped matrix @xmath of @xmath , or
equivalently the number of columns in @xmath . ∎

###### Corollary 8.12.

For any of the families @xmath , and for @xmath , @xmath for general
@xmath .

###### Proof.

Recalling that @xmath , we obtain values for
@xmath (for general @xmath ) and @xmath (for general @xmath ) from
Proposition 8.11 . Since these formulas both hold for general @xmath ,
Lemma 4.7 guarantees that they hold simultaneously for general @xmath ,
so subtracting them gives a formula for their difference that holds for
general @xmath . ∎

### 8.5. Formulas for @xmath and @xmath

###### Proposition 8.13.

For any of the families @xmath , let @xmath lie in the critical range.
Then for general @xmath , the following formulas for @xmath apply.
(Recall that @xmath .)

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

###### Proof.

For all of the families except @xmath , we apply Proposition 7.2 , which
requires us to verify that @xmath . We consider each family in turn.

For @xmath , @xmath and @xmath .

For @xmath , @xmath and @xmath .

For @xmath , @xmath and @xmath .

For @xmath , @xmath and @xmath , where @xmath follows immediately from (
8.2 ).

For @xmath , @xmath and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath follows immediately from ( 8.1 ).

For @xmath , we apply Proposition 7.3 , which requires that @xmath . We
have
@xmath . ∎

###### Corollary 8.14.

For the families @xmath , for @xmath , and for general @xmath the
formulas for @xmath are as follows.

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

###### Proof.

Recalling that @xmath , we obtain values for
@xmath (for general @xmath ) and @xmath (for general @xmath ) from
Proposition 8.13 . Since these formulas both hold for general @xmath ,
Lemma 4.7 guarantees that they hold simultaneously for general @xmath ,
so subtracting them gives a formula for their difference that holds for
general @xmath . In performing the subtraction, we use the following
well-known formula for binomial coefficients.

  -- -- --
        
  -- -- --

∎

### 8.6. Computing @xmath

###### Theorem 8.15.

For any of the families @xmath , for general @xmath and @xmath , we have

1.  @xmath and

2.  @xmath , simultaneously for all degrees @xmath in the critical
    range.

###### Proof.

Since we must verify (ii) for only finitely many values of @xmath , by
Lemma 4.7 it is enough to verify it separately for each degree @xmath .
If (i) has been established, to verify (ii) it is enough, by Lemma 3.1 ,
to show that

  ------- -- -------- --
  (8.3)      @xmath   
  ------- -- -------- --

We remark that @xmath also implies (i), since the existence of a nonzero
polynomial @xmath would imply the existence of a nonzero @xmath partial
derivative of @xmath , which would lie in @xmath . Thus, to prove the
theorem, it is enough to prove @xmath .

To show @xmath , for all families except @xmath , we apply Proposition
7.2 as follows. Let @xmath (defined in @xmath . We observe that, for
each family other than @xmath , where @xmath has the value 3 or 4. Let
@xmath . To use Proposition 7.2 with these values of @xmath and @xmath ,
we must verify that

  ------- -- -- --
  (8.4)         
  ------- -- -- --

where @xmath . Assuming this verification has been done, we conclude
from part (iii) of Proposition 7.2 that, for general @xmath , @xmath .
Since @xmath , we conclude that @xmath , as required.

Before proceeding to the numerical verifications of @xmath , we consider
the family @xmath , and apply Proposition 7.3 to verify @xmath as
follows. As with the other five families, we again let @xmath and @xmath
. To use Proposition 7.3 with these values of @xmath and @xmath , we
must verify @xmath and @xmath . Assuming these verifications have been
done, we proceed as before, concluding from part (iii) of Proposition
7.3 that, for general @xmath , @xmath . Again, since @xmath , we
conclude that @xmath , as required. We now proceed to the verifications
of @xmath and @xmath .

For @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

From Proposition 8.10 , @xmath , so to use Proposition 7.2 we must
verify that

  -- -- --
        
  -- -- --

or equivalently that

  -- -- --
        
  -- -- --

We are considering values of @xmath and @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

For @xmath , again

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

and again @xmath .

To use Proposition 7.2 we must verify that

  -- -- --
        
  -- -- --

or equivalently that

  -- -- --
        
  -- -- --

We are considering values of @xmath , and @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
  -- -------- -------- --

We must demonstrate that the expression within square brackets is always
non-negative. We recall that, in defining the family @xmath , we have
required that

  -- -------- --
     @xmath   
  -- -------- --

Using the quadratic formula to solve the quadratic inequality

  -- -------- --
     @xmath   
  -- -------- --

and noting that we are only interested in positive values of @xmath as
solutions, we have:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

which has been assumed true for the family @xmath .

For @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

or equivalently the vector subspace of @xmath spanned by monomials
constrained by @xmath . Its dimension is @xmath by Proposition 7.8 since
@xmath . We must verify that

  -- -------- --
     @xmath   
  -- -------- --

or equivalently that

  -- -------- --
     @xmath   
  -- -------- --

We are considering values of @xmath and @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

For @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

By Proposition 8.10 , the dimension of @xmath is @xmath . To use
Proposition 7.2 , we must verify for @xmath that

  -- -------- --
     @xmath   
  -- -------- --

For the case that @xmath , this is just ( 8.2 ). Moving to @xmath , the
first term on the left increases by @xmath , the second term decreases,
and the term on the right increases by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

so the required inequality holds for the case @xmath . A similar
computation establishes the inequality for @xmath .

For @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

or equivalently the vector subspace of @xmath spanned by monomials
constrained by @xmath . Its dimension is @xmath by Proposition 7.7 since
@xmath . We must verify that

  -- -------- --
     @xmath   
  -- -------- --

or equivalently that

  -- -------- --
     @xmath   
  -- -------- --

Since we are considering values of @xmath and @xmath , this is
immediate.

For @xmath , we use Proposition 7.3 , taking @xmath , which is the
vector subspace of @xmath constrained by @xmath . Its dimension is
@xmath by Proposition 7.8 since @xmath . Looking further, we can see
that exactly @xmath of the generators do not contain the variable @xmath
by again applying Proposition 7.8 , this time to the constraint @xmath .
So to apply Proposition 7.3 with this choice of @xmath , we use @xmath
for the parameter @xmath of that proposition.

According to Proposition 7.3 (iii), there are two inequalities to verify
for @xmath in the critical range. The first is that

  -- -------- --
     @xmath   
  -- -------- --

or equivalently that

  -- -------- --
     @xmath   
  -- -------- --

We are considering values of @xmath and @xmath , with @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The second inequality to be verified is that

  -- -------- --
     @xmath   
  -- -------- --

or equivalently that

  -- -------- --
     @xmath   
  -- -------- --

Once again we are considering values of @xmath and @xmath , with @xmath
and @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

∎

### 8.7. Proof of Non-Unimodality

###### Theorem 8.16.

For general @xmath and @xmath , all of the families @xmath , are
non-unimodal. The Hilbert functions of @xmath , and @xmath have single
drops with initial degree @xmath . The Hilbert functions of @xmath , and
@xmath have double drops with initial degree @xmath .

###### Proof.

By Theorem 8.15 , we are entitled to use Lemma 8.2 , in which we use the
values of @xmath and @xmath given in Corollaries 8.12 and 8.14 . We let
@xmath . For each family, our approach is to determine relationships
between consecutive values of @xmath that demonstrate the
non-unimodality of @xmath in the critical range.

For @xmath , we have @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath , we have @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath , we have @xmath , where by definition

  -- -------- --
     @xmath   
  -- -------- --

We have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For @xmath , and @xmath , we have @xmath , so

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

### 8.8. Computation of Types

###### Lemma 8.17.

For any of the families @xmath , let @xmath be chosen such that @xmath .
Then for general @xmath and @xmath , the type of @xmath is @xmath .

###### Proof.

By Corollary 6.15 , for general @xmath and @xmath , the dimension of
@xmath is @xmath and the dimension of @xmath is @xmath . By Theorem 8.15
, @xmath . ∎

Among the defining parameters, we will call @xmath , and @xmath the
P-parameters , since they define the constraint @xmath .

###### Lemma 8.18.

For any of the families @xmath , for any fixed choice of the @xmath
-parameters, the value of @xmath is constant, given by the following
formulas:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

###### Proof.

From the definitions, the value of @xmath is @xmath for @xmath , and
@xmath ; @xmath for @xmath ; @xmath for @xmath ; and the greatest
integer @xmath such that @xmath for @xmath . For @xmath , and @xmath ,
which have double drops, @xmath ; for the others, which have single
drops, @xmath . ∎

We define the ceiling function @xmath as follows. For any non-negative
real number @xmath , @xmath is the the smallest integer @xmath such that
@xmath .

###### Lemma 8.19.

For any of the families @xmath , for general @xmath and @xmath , the
requirement that @xmath is @xmath -sufficient is equivalent to the
condition that @xmath . For any fixed choice of the @xmath -parameters,
this formula attains the smallest possible value when @xmath is as small
as permitted by the definition of the family.

###### Proof.

The definition of @xmath -sufficient is that the @xmath cropped matrix
of @xmath has at least as many rows as columns. It has @xmath rows and
@xmath columns, so the condition is that @xmath , or equivalently that
@xmath . We introduce the ceiling function because @xmath must be an
integer.

For any of the families, once we have fixed a choice of @xmath
-parameters, the lemma follows if we show that @xmath is a
non-decreasing function of @xmath . Since the ceiling function is
nondecreasing, it is enough to show that @xmath is non-decreasing as a
function of @xmath , and by the previous lemma it is enough that @xmath
be non-decreasing as a function of @xmath . By Lemma 7.6 , it is enough
that @xmath be a non-decreasing function of @xmath . But @xmath or
@xmath , depending on whether the family has a single drop or a double
drop. ∎

###### Lemma 8.20.

For any of the families @xmath , for any fixed choice of the @xmath
-parameters and @xmath ,
let @xmath . Then for general @xmath and @xmath , the type of the
algebra so obtained is @xmath .

###### Proof.

By Lemma 8.19 , the specified value of @xmath yields an algebra in the
family. To verify the formula for the type, by Lemma 8.17 we must verify
that @xmath . We have

  -- -------- --
     @xmath   
  -- -------- --

where the last inequality follows from Lemma 7.6 . ∎

Up to this point, we have stated results that emphasized the
similarities between the families. Now, we focus on the particulars of
each family in turn.

###### Theorem 8.21.

In the family @xmath , we have

1.   For a fixed choice of @xmath and @xmath , the smallest possible
    type @xmath is achieved by taking @xmath .

2.   For a fixed choice of @xmath , the smallest possible type @xmath is
    achieved by taking @xmath , @xmath . With these choices, the type is
    greater than 5 for @xmath , and the type is exactly 5 for @xmath .

3.   For any choice of @xmath , @xmath , and @xmath , the type is at
    least 5.

###### Proof.

For (i), we combine the various lemmas in this section with Lemma 7.10 .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), we observe that @xmath is an increasing function of @xmath ,
and we substitute the smallest permissible value @xmath to obtain @xmath
. We observe that the fraction @xmath is a decreasing function of @xmath
that is always strictly greater than 3. Evaluating for @xmath gives
@xmath , and for @xmath , @xmath .

Part (iii) follows immediately from part (ii). ∎

###### Theorem 8.22.

In the family @xmath , we have

1.   For a fixed choice of @xmath and @xmath , the smallest possible
    type @xmath is achieved by taking @xmath .

2.   For a fixed choice of @xmath , the smallest possible type @xmath is
    achieved by taking @xmath , @xmath . With these choices, the type is
    12 for @xmath , @xmath , and @xmath . The corresponding values of
    @xmath are 350, 357, and 364. For any other value of @xmath , the
    type is greater than 12.

3.   For any choice of @xmath , @xmath , and @xmath , the type is at
    least 12.

###### Proof.

For (i), we combine the various lemmas in this section with Lemma 7.10 .
To evaluate @xmath , we observe @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
                       
                       
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), we observe that @xmath is a non-decreasing function of @xmath
, and we substitute the smallest permissible value @xmath to obtain

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Because of the effect of the inner ceiling function, we do not claim
that @xmath is non-increasing as a function of @xmath . In fact, using a
computer, we calculated @xmath for integer values of @xmath up to 220,
and found that @xmath for @xmath = 198, 202, 205, 206, 208, 209, and
210, and for all values of @xmath ; and that @xmath for all other values
of @xmath . However, the formula for @xmath is sandwiched between

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

which are both nonincreasing as functions of @xmath and which both
approach the value @xmath as a limit for large values of @xmath . Since
@xmath , it must be that @xmath for @xmath .

Our construction of @xmath requires @xmath to be odd, so we have type
@xmath for @xmath and 209, and for any odd @xmath . For @xmath , @xmath
. For @xmath , @xmath . For @xmath , @xmath .

Part (iii) follows immediately from part (ii). ∎

###### Theorem 8.23.

In the family @xmath , we have

1.   For a fixed choice of @xmath , @xmath , and @xmath , the smallest
    possible type @xmath is achieved by taking @xmath .

2.   For a fixed choice of @xmath and @xmath , the smallest possible
    type @xmath is achieved by taking @xmath , @xmath . With these
    choices, the type is 3 for @xmath if and only if either @xmath or
    @xmath ; the lowest values of @xmath for which the type is 4 are
    @xmath and @xmath .

3.   For any choice of @xmath , @xmath , @xmath , and @xmath , the type
    is at least 3.

###### Proof.

For (i), we combine the various lemmas in this section with Lemma 7.11 .
To evaluate @xmath , we observe @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), we observe that @xmath is an increasing function of @xmath ,
and we substitute the smallest permissible value @xmath to obtain @xmath
. We observe that the fraction @xmath is a decreasing function,
separately in @xmath and @xmath , that is always strictly greater than
1. Evaluating @xmath for the relevant values of @xmath , we have:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Part (iii) follows immediately from part (ii). ∎

###### Theorem 8.24.

In the family @xmath , we have

1.   For a fixed choice of @xmath , @xmath , and @xmath , the smallest
    possible type @xmath is achieved by taking

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

2.   For a fixed choice of @xmath and @xmath , the smallest possible
    type @xmath is achieved by taking @xmath , in which case

      -- -------- -------- --
         @xmath   @xmath   
         @xmath   @xmath   
      -- -------- -------- --

    With these choices, the type is 3 for @xmath if and only if either
    @xmath or @xmath or @xmath . The smallest values of @xmath for which
    the type is 4 are (2,8), (3,6), and (4,4).

3.   For any choice of @xmath , @xmath , and @xmath , the type is at
    least 3.

###### Proof.

For (i), we combine the various lemmas in this section with Lemma 7.11 .
To evaluate @xmath , we observe that if @xmath , @xmath ; but if @xmath
, @xmath .

If @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

If @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), we observe that @xmath is an increasing function of @xmath ,
and we substitute the smallest permissible value @xmath to obtain, for
@xmath , @xmath ; and for @xmath , @xmath . We let @xmath and @xmath .
We observe that, for all values of @xmath and @xmath , @xmath and @xmath
. In addition, @xmath and @xmath are both decreasing functions,
separately in @xmath and @xmath . Evaluating @xmath and @xmath for the
relevant values of @xmath (recalling that either @xmath or @xmath must
be even), we have:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Part (iii) follows immediately from part (ii). ∎

###### Theorem 8.25.

In the family @xmath

1.   For a fixed choice of @xmath , @xmath , @xmath , and @xmath , the
    smallest possible type @xmath is achieved by taking @xmath

2.   For a fixed choice of @xmath , @xmath , and @xmath , the smallest
    possible type @xmath is achieved by taking @xmath , @xmath . With
    these choices, the type is 3 unless @xmath , in which case the type
    is 4.

3.   For any choice of @xmath , @xmath , @xmath , and @xmath , the type
    is at least 3.

###### Proof.

For (i), we combine the various lemmas in this section with Lemma 7.9 .
To evaluate @xmath , we observe @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

For (ii), we observe that @xmath is an increasing function of @xmath ,
and we substitute the smallest permissible value @xmath to obtain
@xmath . We observe that the fraction
@xmath is a decreasing function, separately in @xmath , @xmath , and
@xmath , that is always strictly greater than 1. Evaluating for the
relevant values of @xmath , we have:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Part (iii) follows immediately from part (ii). ∎

For the family @xmath , we do not attempt to state a theorem with
closed-form solutions, similar to those we have proved for the other
five families. The most serious obstacle is finding a closed-form
solution of ( 8.2 ), which is cubic in the variable @xmath . Instead, we
content ourselves with demonstrating the method that led to choosing the
example @xmath above.

We begin with some suitable choice of @xmath and @xmath , in this case
@xmath , in which case @xmath because

  -- -------- --
     @xmath   
  -- -------- --

Then ( 8.2 ) becomes

  -- -------- --
     @xmath   
  -- -------- --

This is false for @xmath since @xmath , but true for @xmath , since
@xmath , so we must choose @xmath ; and the additional requirement that
@xmath imposes no further condition. If we choose @xmath , with the
intention of obtaining the smallest possible type for this choice of
@xmath and @xmath , the condition on @xmath (using Proposition 7.11 ) is
that

  -- -------- --
     @xmath   
  -- -------- --

so we must take @xmath .

## Chapter 9 Further Remarks

### 9.1. For Which Codimensions and Types are Non-Unimodal Level
Algebras Possible?

We now return to a question raised in Chapter 1, at which time we were
not yet ready to provide justification for the answer given: for a
specified codimension @xmath and type @xmath , must level algebras
necessarily be unimodal?

###### Proposition 9.1.

In codimension @xmath , there exist non-unimodal level algebras for any
type @xmath or greater. In codimensions @xmath and @xmath , there exist
non-unimodal level algebras for any type @xmath or greater.

###### Proof.

For codimension 3, we let @xmath and describe a procedure for finding a
member of @xmath of type @xmath . We choose @xmath such that @xmath ,
that is, @xmath . We apply Theorem 8.16 for @xmath , with @xmath and
@xmath . That is, we let @xmath , where @xmath are general elements of
@xmath , and we let @xmath , where @xmath is a general element of @xmath
. To ensure that @xmath is non-unimodal of type @xmath for general
@xmath and @xmath , we must check that the parameters @xmath are
permissible. It is immediate that @xmath and @xmath , and by Lemma 8.19
we must check that @xmath . But, having assumed that @xmath , we know
from Theorem 8.21 that @xmath , and we have also assumed that @xmath
Thus the values of the parameters @xmath , and @xmath are permissable,
so @xmath is indeed a member of the family @xmath , hence non-unimodal
by Theorem 8.16 .

Analogous constructions are available in codimensions 4 and 5. For
codimension 4, we let @xmath and we find a member of @xmath of given
type @xmath . We choose @xmath such that @xmath , that is, @xmath , and
we again apply Theorem 8.16 , this time for @xmath , with @xmath and
@xmath . That is, we let @xmath , where @xmath are general elements of
@xmath , and we let @xmath , where @xmath is a general element of @xmath
. To ensure that @xmath is non-unimodal of type @xmath for general
@xmath and @xmath , we must check that the parameters @xmath are
permissible. It is immediate that @xmath and @xmath , and by Lemma 8.19
we must check that @xmath . But, having assumed that @xmath , we know
from Theorem 8.23 that @xmath , and we have also assumed that @xmath
Thus the values of the parameters @xmath , and @xmath are permissable,
so @xmath is indeed a member of the family @xmath , hence non-unimodal
by Theorem 8.16 .

For codimension 5, we let @xmath and we find a member of @xmath of given
type @xmath . We choose @xmath such that @xmath , that is,
@xmath , and we again apply Theorem 8.16 , this time for @xmath , with
@xmath and @xmath . That is, we let @xmath , where @xmath are general
elements of @xmath , and we let @xmath , where @xmath is a general
element of @xmath . To ensure that @xmath is non-unimodal of type @xmath
for general @xmath and @xmath , we must check that the parameters @xmath
are permissible. It is immediate that @xmath and @xmath , and by Lemma
8.19 we must check that @xmath . But, having assumed that @xmath , we
know from Theorem 8.25 that @xmath , and we have also assumed that
@xmath Thus the values of the parameters @xmath , and @xmath are
permissable, so @xmath is indeed a member of the family @xmath , hence
non-unimodal by Theorem 8.16 .
∎

###### Proposition 9.2.

Let @xmath be a nonzero vector subspace of dimension @xmath . Define
@xmath . Then @xmath is a level algebra of codimension @xmath , type
@xmath , and socle degree @xmath ; and @xmath is a level algebra of
codimension @xmath , type @xmath , and socle degree @xmath . For @xmath
, @xmath .

###### Proof.

By Theorem 2.9 , @xmath and @xmath are level algebras of the stated
codimension and socle degree, and the types are, by construction, the
dimensions respectively of @xmath and @xmath . We write

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

and observe that @xmath is a vector space of dimension 1 whose
intersection with @xmath is @xmath . By Lemmas 2.10 and 3.1 ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

∎

###### Proposition 9.3.

If there exists a non-unimodal level algebra @xmath of codimension
@xmath , type @xmath , and socle degree @xmath , then there exists a
non-unimodal level algebra @xmath of codimension @xmath , type @xmath ,
and socle degree @xmath .

###### Proof.

This follows immediately from the construction of the previous
proposition. Writing @xmath , take @xmath . ∎

We next cite a result of D. Bernstein from [ BI92 ] , which we restate
in our own notation.

###### Theorem 9.4.

Let @xmath . Consider the family of vector subspaces @xmath , where
@xmath . Then for general @xmath and @xmath , @xmath is a level algebra
of type 1 and socle degree 16, with Hilbert function
(1,5,12,22,35,51,70,91,90,91,70,51,35,22,12,5,1). That is, @xmath is a
non-unimodal Gorenstein algebra..

@xmath

###### Proposition 9.5.

Given integers @xmath and @xmath , there exists a non-unimodal level
algebra of codimension @xmath and type @xmath .

###### Proof.

By Proposition 9.3 , it is enough to demonstrate a non-unimodal level
algebra (a) when @xmath , for any @xmath , and (b) when @xmath , for any
@xmath .

By virtue of the Bernstein example and Proposition 9.1 , to establish
(a) it only remains to consider the case @xmath , @xmath . For this, we
modify the Bernstein example so that @xmath . Then, for @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

for exactly the same reasons as in the proof of Proposition 9.2 . So
@xmath is non-unimodal.

To establish (b) for codimension @xmath , we modify the Bernstein
example in a different way. This time, we let @xmath , and then for
@xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

once again by Lemma 3.1 and Lemma 2.10 . So, again, @xmath is
non-unimodal. ∎

We remark that Propositions 9.1 and 9.5 were used in Chapter 1 to list
the codimensions and types for which non-unimodal level algebras are
known to exist.

### 9.2. Minimal Socle Degree

For non-unimodal level algebras of given codimension @xmath and type
@xmath , we have no actual methods for determining what the lowest
possible socle degree @xmath might be. We make several remarks about
interesting cases.

For @xmath , the only known non-unimodals come from the family @xmath .
For these, we see from Theorem 8.21 that it is possible to achieve type
5 only for @xmath . We have @xmath , so the smallest known socle degree
is 63.

For @xmath , we must consider the families @xmath and @xmath .
(Logically, we ought also to consider @xmath , but this family is not
known to yield algebras of type 3). By arguments analogous to the one in
the previous paragraph, we see from Theorems 8.23 and 8.24 that we must
check @xmath , @xmath , @xmath , @xmath , and @xmath , of respective
socle degrees @xmath . Thus @xmath represents the smallest known socle
degree, arising from family @xmath .

For @xmath , the lowest known socle degree does not result from family
@xmath , which can do no better than @xmath , of socle degree 24.
Instead, we can modify the Bernstein example @xmath , discussed earlier,
of a non-unimodal Gorenstein of codimension 5. We let @xmath . Then, for
@xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

So we can find socle degree @xmath .

For @xmath , there are several possible sources to consider. @xmath
gives @xmath . We could try modifying a type-3 member of family @xmath
by adding a generator, but the socle degree would then be at least 24.
We could try using Proposition 9.2 , applied to a type-3 non-unimodal of
codimension 4, but the socle degree would be at least 25. Finally, we
could consider another modification of the Bernstein example: we let
@xmath . Then, for @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

This is another example of socle degree @xmath . With its single drop,
this is certainly different from @xmath , which has a double drop.