# Table of Contents

\pdfbookmark Table of Contents Table of Contents

######

-    List of Figures
-    Declaration
-    Acknowledgements
-    1 Cosmological introduction
    -    1.1 The FLRW Universe
        -    1.1.1 Geometry
        -    1.1.2 Dynamics
        -    1.1.3 Past
        -    1.1.4 Composition
    -    1.2 Inflation
        -    1.2.1 Classical inflationary dynamics
        -    1.2.2 Sourcing cosmological perturbations
        -    1.2.3 Resumming divergences
    -    1.3 Perturbative reheating
        -    1.3.1 The curvaton mechanism
-    2 Statistical introduction
    -    2.1 Bayesian inference
    -    2.2 The Kullback-Leibler divergence
    -    2.3 Bayesian model selection
    -    2.4 Choice of prior
    -    2.5 Bayesian experimental design
-    3 Curvaton reheating
    -    3.1 Introduction
    -    3.2 Method
        -    3.2.1 Curvaton and reheating
        -    3.2.2 Inverse problem for reheating parameters
        -    3.2.3 Bayesian inference and prior choices
    -    3.3 Results and analysis
        -    3.3.1 Constraints on inflationary energy and reheating
            temperatures
        -    3.3.2 Information gain
    -    3.4 Discussion
        -    3.4.1 Inflationary energy scale in plateau models
        -    3.4.2 Gravitino overproduction bounds
        -    3.4.3 Decay mediation scale
    -    3.5 Conclusion
    -    3.A Kullback-Leibler divergence
    -    3.B Individual reheating scenarios constraints
        -    3.B.1 Energy density at the end of inflation
        -    3.B.2 Reheating Temperature
        -    3.B.3 Early reheating temperature
    -    3.C Information density
        -    3.C.1 Energy density at the end of inflation
        -    3.C.2 Reheating temperature
        -    3.C.3 Early reheating temperature
-    4 Spectator field condensates
    -    4.1 Introduction
        -    4.1.1 Stochastic single spectator
        -    4.1.2 Limitations of the adiabatic approximation
    -    4.2 Quadratic spectator
        -    4.2.1 Plateau inflation
        -    4.2.2 Monomial inflation
        -    4.2.3 Can a spectator field drive a second phase of
            inflation?
    -    4.3 Quartic spectator
        -    4.3.1 Plateau inflation
        -    4.3.2 Monomial inflation
    -    4.4 Axionic spectator
        -    4.4.1 Plateau inflation
        -    4.4.2 Monomial inflation
    -    4.5 Non-minimally coupled spectator
        -    4.5.1 Plateau inflation
        -    4.5.2 Monomial inflation
    -    4.6 Information retention from initial conditions
    -    4.7 Multiple spectator condensates from inflation
    -    4.8 Vanishing probability current with symmetric potentials
    -    4.9 Computation and analytic arguments
        -    4.9.1 The critical coupling
        -    4.9.2 The decoupling limit
        -    4.9.3 Non-vanishing probability currents
    -    4.10 Conclusions
    -    4.A Statistical moments of quadratic spectators
    -    4.B Adiabatic solution for quartic spectators
    -    4.C Numerical implementation
-    5 Probing inflation with extra fields
    -    5.1 ‘A quantum window’
    -    5.2 Freeze-in dark matter
    -    5.3 Freeze-in: extended scenario
        -    5.3.1 Varying the inflationary dynamics
        -    5.3.2 Varying the reheating history
        -    5.3.3 Low-energy dynamics
    -    5.4 The duration of inflation with a curvaton
    -    5.5 Duration of inflation: results
        -    5.5.1 Single-field versus spectator model
        -    5.5.2 Measuring the duration of inflation
    -    5.6 Conclusions
    -    5.A Calculation of the dark matter abundance
    -    5.B Calculation of the portal coupling
    -    5.C Statistical computation
-    6 The probable future
    -    6.1 Introduction
    -    6.2 Formalism
        -    6.2.1 Probability measures primer
        -    6.2.2 Defining the expected utility
        -    6.2.3 The utility functions
        -    6.2.4 The maximum-likelihood average
        -    6.2.5 A novel computational forecasting method
    -    6.3 Results and analysis
        -    6.3.1 General statements
        -    6.3.2 Forecasts using P1 and P2
        -    6.3.3 Forecasts using F1-4
        -    6.3.4 Deciding between reheating scenarios
        -    6.3.5 Measuring the scalar running
    -    6.4 Concluding remarks
    -    6.A The single-field models
    -    6.B Computational methods in foxi
    -    6.C Checking for numerical robustness
    -    6.D Identifying the constraint on @xmath
-    7 Discussion and conclusions
    -    7.1 Outlining the results
        -    7.1.1 Impact on the scientific community
    -    7.2 Future directions
        -    7.2.1 Dark matter initial conditions
        -    7.2.2 Higgs stability
        -    7.2.3 New gravitational wave signals
        -    7.2.4 Survey design

## List of Tables

\pdfbookmark

List of Tables List of Tables

######

-    3.1 Information gain on energy densities and reheating temperatures
-    3.2 Information gain on energy densities and reheating temperatures
-    4.1 Summary of variances
-    6.1 Measurement configurations for each toy CMB experiment
-    6.2 Experiment P1 expected utilities
-    6.3 Experiment P2 expected utilities
-    6.4 Expected utilities for post-Higgs inflation reheating
-    6.5 Probabilties to measure the running of the spectral index
-    6.6 Expected utilities for F1-4 experiments
-    6.7 Percentages of realisation in each category of the numerical
    pipeline
-    6.8 Comparison of approximate method with known codes

## List of Figures

\pdfbookmark

List of Figures List of Figures

######

-    1.1 Energy density scaling illustration
-    1.2 Cosmic history illustration
-    1.3 Cosmic pie chart
-    1.4 Simple decay of the inflaton
-    3.1 Information gain on the reheating temperature
-    3.2 Curvatonic reheating scenarios
-    3.3 Posterior distributions on the energy density at the end of
    inflation
-    3.4 Posteriors on the reheating (and early) temperature
-    3.5 Induced prior on the reheating temperature for the Higgs
    potential
-    3.6 Posteriors on the energy density and reheating temperatures
-    3.7 Posterior distributions of the mass mediation scale
-    3.8 Posterior distributions on the energy density at the end of
    inflation
-    3.9 Posterior distributions on the reheating temperature
-    3.10 Posterior distributions on the early reheating temperature
-    3.11 Information density over the averaged energy density
-    3.12 Information density on the energy density at the end of
    inflation
-    3.13 Information density on the averaged reheating temperature
-    3.14 Information density on the reheating temperature
-    3.15 Information density on the averaged early reheating
    temperature
-    4.1 Quadratic spectator typical field displacement
-    4.2 Probability of second inflationary phase
-    4.3 Quartic spectator typical field displacement
-    4.4 Quartic spectator field displacement at the end of inflation
-    4.5 Axionic spectator typical field displacement
-    4.6 Spectator information retention
-    4.7 Saturation of the multi-field variance
-    4.8 Time evolution of many spectators
-    4.9 Critical coupling for multiple fields
-    4.10 Time evolution of coupled quadratic spectator fields
-    4.11 Initial condition independence of coupled quadratic spectator
    fields
-    4.12 Time evolution of coupled quartic spectator fields
-    4.13 The time evolution of the effective mass for coupled quadratic
    fields
-    4.14 The time evolution of the effective mass for coupled quartic
    fields
-    4.15 Probability density function for coupled quadratic spectators
-    4.16 Probability current for coupled quadratic spectators
-    5.1 Inflationary potential with large field corrections
-    5.2 Number of plateau @xmath -folds in order to erase information
-    5.3 Freeze-in dark matter reheating schematic
-    5.4 Energy scale of inflation
-    5.5 Corrections factor from inflationary dynamics
-    5.6 Energy scale of inflation corrected by the inflationary
    dynamics
-    5.7 Correction from reheating history
-    5.8 Energy scale of inflation corrected by the reheating history
-    5.9 Feynman diagrams of dark matter cannibalism
-    5.10 Correction from low energy dynamics
-    5.11 Energy scale of inflation corrected by the low energy dynamics
-    5.12 Constraint on the tensor-to-scalar ratio from dark matter
-    5.13 Bayesian evidence of single field versus curvaton models
-    5.14 Marginal posterior distributions for the curvaton models
-    5.15 Marginal posterior over the number of @xmath -folds of
    inflation
-    6.1 Decisivity score for a selection of CMB experiments
-    6.2 Spectral index against tensor-to-scalar ratio
-    6.3 Diagram of the Bayesian experimental design setup
-    6.4 Probability density of the Kullback-Leibler divergence in each
    case
-    6.5 Categories of situation in the numerical pipeline
-    6.6 Indicated forecast contours for the LiteCOrE experiment

## Declaration

Whilst registered as a candidate for the above degree, I have not been
registered for any other research award. The results and conclusions
embodied in this thesis are the work of myself and have not been
submitted for any other academic award.

Chapter 1 and Chapter 2 are introductory, written by myself and drawn
from multiple references which are cited accordingly.

Chapter 3 is primarily based on the work in: JCAP 1608 (2016), no.08,
042 . I am the primary author of this publication where the code, upon
which the work relies, was partially written by and entirely run by
myself.

Chapter 4 is primarily based on the works in: JCAP 1710 , (2017)018 ;
and JCAP 1805 , no.05, 054(2018) . I am the primary author and wrote the
majority of text in both publications, where in the latter I was the
sole author. The analytic and numerical calculations in both works were
all performed by myself, where in some cases in the former work there
were replications and additional checks on these by my co-authors. I was
also the sole developer of the code in the latter publication. This
chapter also contains some original calculations for non-minimally
coupled spectator fields written by myself.

Chapter 5 is primarily based on the works in: Int. J. Mod. Phys. D 26
(2017) no.12, 1743025 ; JCAP 1802 , no.02, 006(2018) ; and
arXiv:1712.05364 . I am the primary author of the first publication and
a major co-author in the other two works. I wrote approximately half of
the text in the first two works and a less, but still significant,
component of the latter. All of the analytic and numerical calculations
in these works were performed by myself, either in the first instance or
as checks for my co-authors.

Chapter 6 is primarily based on the work in: JCAP 1805 , no.05,
070(2018) . The entire body of text was written and the code was
developed by myself.

Chapter 7 is an original piece of writing by myself that is intended to
summarise all previous sections. References are used where necessary.

Word count: 49,095 words.

Ethical review code: 4C42-FF17-B7FF-2C76-32CC-FA5B-2ACD-593C

## Acknowledgements

I would like to sincerely thank all of my truly superb supervisors: Prof
David Wands, Dr Vincent Vennin and Dr Hooshyar Assadullahi, for their
expertise, advice and great humour throughout the last 3 years. In
particular, I would like to thank: David for the huge amount of
knowledge that you have imparted to me and the relaxed, encouraging way
in which you imparted it; and Vincent, for both teaching me so much and
for the extraordinary example you set for me in all aspects of research.

To my examiners: Dr Roberto Trotta and Prof Robert Crittenden, I
sincerely thank you both for your careful reading of the manuscript and
insightful commments.

I would also like to acknowledge and thank all of my collaborators, both
past and present, from whom I have learned a huge amount: Christian
Byrnes, Emanuela Dimastrogiovanni, Kari Enqvist, Matteo Fasiello, Kazuya
Koyama, Tommi Markkanen, Sami Nurmi, Diederik Roest, Tommi Tenkanen and
Jesús Torrado.

To all of my fellow PhD colleagues: You are a fantastic bunch of people
and I sincerely wish you to all achieve your dreams! Most notably to the
pub crew — Paul, Ben, Dan, Matt and Mike — whose ridiculous
conversations have always cheered me up (and inspired me). Thank you all
so much for everything.

Lastly, and most importantly. To Camila and my family, who have always
supported me through thick and thin: I love you all very dearly. I feel
that this thesis sums up everything that you have all helped me to
accomplish.

## Dissemination

#### Publications

R. J. Hardwick , V. Vennin and D. Wands, “ The decisive future of
inflation ,” JCAP 1805 , no.05, 070(2018),
doi:10.1088/1475-7516/2018/05/070 , [ arXiv:1803.09491 [astro-ph.CO]].
R. J. Hardwick , “ Multiple spectator condensates from inflation ,” JCAP
1805 , no.05, 054(2018), doi:10.1088/1475-7516/2018/05/054 , [
arXiv:1803.03521 [gr-qc]].
J. Torrado, C. T. Byrnes, R. J. Hardwick , V. Vennin and D. Wands, “
Measuring the duration of inflation with the curvaton ,”
arXiv:1712.05364 [astro-ph.CO].
K. Enqvist, R. J. Hardwick , T. Tenkanen, V. Vennin and D. Wands, “ A
novel way to determine the scale of inflation ,” JCAP 1802 , no.02,
006(2018), doi:10.1088/1475-7516/2018/02/006 , [ arXiv:1711.07344
[astro-ph.CO]].
R. J. Hardwick , V. Vennin and D. Wands, “ A Quantum Window Onto Early
Inflation ,” Int. J. Mod. Phys. D 26 (2017) no.12, 1743025,
doi:10.1142/S0218271817430258 , [ arXiv:1705.05746 [hep-th]].
R. J. Hardwick , V. Vennin, C. T. Byrnes, J. Torrado and D. Wands, “ The
stochastic spectator ,” JCAP 1710 , (2017)018,
doi:10.1088/1475-7516/2017/10/018 , [ arXiv:1701.06473 [astro-ph.CO]].
R. J. Hardwick , V. Vennin, K. Koyama and D. Wands, “ Constraining
Curvatonic Reheating ,” JCAP 1608 (2016), no.08, 042,
doi:10.1088/1475-7516/2016/08/042 , [ arXiv:1606.01223 [astro-ph.CO]].

## Chapter 1 Cosmological introduction

Abstract. In this chapter we will review the
Friedmann-Lemaître-Robertson-Walker (FLRW) Universe, cosmological
inflation and reheating, emphasising the components in understanding
that are necessary to read the main body of the thesis. More
specifically, we shall focus on both the origin of divergences in
inflationary correlation functions and the stochastic framework in which
to calculate their observational effects, as well as the essential
physics of perturbative reheating. For more pedagogical modern reviews,
we suggest Refs. [ 1 , 2 , 3 , 4 , 5 , 6 ] .

### 1.1 The FLRW Universe

#### 1.1.1 Geometry

Through successive observations of the mass, distance and recessional
velocity of astrophysical objects, we know that our Universe is
expanding and cooling [ 7 , 8 , 9 , 10 ] . It is also filled with a vast
array of structures that are distributed on many length scales. Despite
this complexity, on the largest (cosmological) length scales, the
Universe appears to be statistically homogeneous and isotropic to all
observers. Imposing these symmetries, one finds that the spacetime
geometry of the Universe at these scales is well described by a
Friedmann-Lemaître-Robertson-Walker (FLRW) metric, with the following
line element in spherical polar coordinates [ 11 , 12 , 13 , 14 ]

  -- -- -- -------
           (1.1)
  -- -- -- -------

where @xmath is the radial distance from a fundamental observer, @xmath
is a constant scalar curvature, ¹ ¹ 1 This can be a positive number for
spatially closed, 0 for spatially flat and negative for spatially open
universes. @xmath is the 2-dimensional solid angle, @xmath is the FLRW
scale factor and @xmath is cosmic time: the proper time of the
fundamental observer. Eq. ( 1.1 ) is very simple due to the symmetries
of homogeneity and isotropy. If the scale factor were to spatially vary
@xmath then homogeneity would be violated.

A useful parameterisation @xmath factors expansion out of the time
elapsed for the observer, converting Eq. ( 1.1 ) into

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath is known as ‘conformal time’. Note that throughout this
thesis the convention of (Planck) natural units ( @xmath , @xmath ,
@xmath ) will be adopted.

#### 1.1.2 Dynamics

In order to calculate how the Universe dynamically evolves, one must
introduce a theory of gravitation. The Einstein-Hilbert action [ 15 , 16
] of General Relativity is given by

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

in which @xmath (in natural units) is the reduced Planck mass, @xmath is
the Ricci tensor ² ² 2 In General Relativity the Ricci tensor is a
contraction of the Riemann tensor

@xmath

where we are using square brackets to denote antisymmetrising @xmath and
the Christoffel symbols are

@xmath

and its contraction @xmath is the Ricci scalar. Note that in Eq. ( 1.3 )
the integral comes equipped with a spacetime 4-volume element @xmath .
If one varies Eq. ( 1.3 ) with respect to @xmath

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

which is the vacuum solution to the theory. We note here that the
convention of Latin and Greek indices to represent 3 and 4-vectors,
respectively, will be used throughout this section unless otherwise
indicated.

Adding gravitating matter — through its Lagrangian density @xmath — and
a cosmological constant @xmath to the Universe gives a new action

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

from which we can see that @xmath plays the role of a coupling between
matter and the gravitational field @xmath . From Eq. ( 1.5 ) the
energy-momentum tensor @xmath of the matter fields can be obtained

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

Hence, by varying the overall action in Eq. ( 1.5 ) with respect to
@xmath , one arrives at the Einstein field equations

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

which describe how the energy-momentum of matter sources the dynamics of
@xmath .

For a fundamental observer moving with respect to the rest frame in a
perfect fluid with density @xmath , pressure @xmath and four velocity
vector @xmath , one can identify @xmath . When the observer is at rest,
@xmath and @xmath , so we find that @xmath , which is consistent with
the homogeneity and isotropy assumed by FLRW if @xmath and @xmath do not
spatially vary. One may then use Eq. ( 1.1 ) and components of Eq. ( 1.7
) to derive the following equations: The @xmath -component

  --------------------------- -------- -------- -- -------
                              @xmath   @xmath      (1.8)
  and the @xmath -component                        
                              @xmath   @xmath      (1.9)
  --------------------------- -------- -------- -- -------

where we have defined the Hubble parameter @xmath and the equation of
state parameter @xmath . Eqs. ( 1.8 ) and ( 1.9 ) are also consistent
with the continuity equation

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

which may also be derived from the 0-component of the conservation of
energy-momentum, ³ ³ 3 In fact, Eq. ( 1.7 ) satisfies the more general
energy-momentum conservation law @xmath where the geometric side of the
relation follows from the Bianchi identities. i.e., @xmath , where
@xmath denotes a covariant derivative. The general solution of Eq. (
1.10 ) is straightforward

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

Note that, in the limit where @xmath is constant: substituting Eq. ( 1.8
) into Eq. ( 1.11 ) yields

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

where we have now implicitly dropped the time dependencies of each
quantity @xmath such that @xmath and @xmath . Familiar solutions to
Eq. ( 1.12 ) include: a vacuum energy ( @xmath ); a matter-like energy
density ( @xmath ); and a radiation-like (conformal) energy density (
@xmath ). Note also that the cosmological constant coincides with a
vacuum energy-like @xmath and spatial curvature @xmath can be identified
as a fluid with @xmath .

By replacing @xmath in Eq. ( 1.8 ) to account for all distinct
constituents of gravitating matter in the Universe, one may account for
a more complex cosmic history by ‘stitching together’ separate epochs of
@xmath -dominated expansion. Each @xmath -dominated epoch may dilute
with energy density differently according to an equation of state @xmath
and hence one may make a multiplicative chain to track the evolution of
the total energy density using barotopic terms taking the form of Eq. (
1.12 ). Such calculation is illustrated in Fig. 1.1 , which corresponds
to the true scaling in energy density that is expected in the cosmic
past.

#### 1.1.3 Past

Fig. 1.1 reveals an important characteristic of our expanding Universe:
those components of matter which dilute more efficiently with expansion
are, conversely, expected to dominate the total energy density in the
distant past. Tracking the evolution backward in time, one can invert
Eq. ( 1.12 ) to find that the Universe must become both increasingly
dense and thus, because it was radiation dominated, at a higher
temperature. The oldest light detected from this era is known as the
Cosmic Microwave Background (CMB) radiation.

The CMB is a near-perfect blackbody spectrum of radiation — measured to
have a temperature today of @xmath — which formed when the Universe
cooled sufficiently such that free electrons and protons could bind to
form neutral Hydrogen (a process known as recombination) during the
matter era (labeled in Fig. 1.1 ). We have indicated when the CMB forms
relative to the earliest epochs in Fig. 1.2 . In order to better
understand the key processes expected at earlier times, and how the CMB
formed, one needs to understand the properties of a thermal bath of
particles in a cosmological context. In light of this, we shall briefly
review some of the required elements in statistical mechanics.

The central object in describing the state space of many-body systems is
the distribution function @xmath — from which observable quantities,
such as pressure and temperature, may be calculated by integration with
an appropriate function. The ‘state’ of the system is generally a
configuration in a time-dependent phase space, and hence we have @xmath
, where we remind the reader that @xmath and @xmath denote the
corresponding 3-vector components in momentum and space, respectively.
Typically, if the interaction rate of a system is sufficiently high, it
reaches thermodynamic equilibrium and hence equilibrium distribution
functions @xmath may be used. We note that @xmath are often analytic
functions where there is no longer any explicit temporal variation due
to stationarity. For an adiabatically expanding Universe that retains
thermal equilibrium, however, implicit time dependence is still present
since the energy of the system will decrease with increasing volume of
the thermal bath. ⁴ ⁴ 4 One can easily see this by considering the first
law of thermodynamics @xmath , which is valid for a change in total
energy @xmath of a closed system in thermal equilibrium by either a
total change in entropy @xmath or volume @xmath .

The equilibrium distribution function for a species of particle, with
degrees of freedom @xmath , that is relativistic (its rest mass @xmath ,
where @xmath is the temperature of the thermal bath) is a stationary
solution of the relativistic Boltzmann equation. The relativistic
Boltzmann equation takes the form

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

where the relativistic Liouville operator @xmath is

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

and @xmath is the collision operator. In an FLRW Universe, and hence
using Eq. ( 1.1 ) and its Christoffel symbols, this operator reduces to

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

where we have assumed statistical homogeneity and @xmath is the square
magnitude of the 3-momentum vector. ⁵ ⁵ 5 Note that we have made use of
the invariant @xmath and the fact that only @xmath is non-vanishing. In
a semi-classical treatment @xmath must contain the fact that the
scattering species is either Fermionic or Bosonic, whose @xmath
scattering collision operator will take the form [ 17 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.16)
     @xmath   @xmath      (1.17)
  -- -------- -------- -- --------

where @xmath is the @xmath transition rate and in our notation @xmath is
the phase space distribution function over the @xmath -th (denoting the
number of primes @xmath ) particle. If the species is Fermionic, an
initial or final scattering state cannot be occupied at the same time by
both particles and hence @xmath should be chosen in Eq. ( 1.17 ).
Equivalently, if the species were Bosonic, @xmath should be chosen due
to the fact that a Boson can occupy any of the initial or any of the
final states. Finally, to be governed by Maxwell-Boltzmann statistics,
the value of @xmath should be used.

Now consider the system in an FLRW background at equilibrium (stationary
limit) so @xmath such that the first term on the left hand side of Eq. (
1.15 ) vanishes. The second term accounts for the expansion rate which
limits the progress towards equilibrium by increasing the distance
between scattering particles. However, in the high interaction rate
limit this term is negligible to the collision term and so it too can be
treated as vanishing. Hence, because now @xmath , Eq. ( 1.13 ) leaves us
with the requirement that

  -- -------- -- --------
     @xmath      
     @xmath      (1.18)
  -- -------- -- --------

Eq. ( 1.18 ) suggests that the quantity @xmath is invariant under
scattering, and hence is equal to a linear combination of other
invariants

  -- -------- -- --------
     @xmath      (1.19)
  -- -------- -- --------

The constants @xmath and @xmath in Eq. ( 1.19 ) can be determined such
that we may identify the Fermi-Dirac/Bose-Einstein/Maxwell-Boltzmann
distributions by integration over the total number of particles ⁶ ⁶ 6 A
full derivation of Eq. ( 1.20 ) requires a maximum probability analysis
over the state space, such as the Darwin-Fowler method [ 18 ] . Here we
shall simply quote the result.

  -- -------- -- --------
     @xmath      (1.20)
  -- -------- -- --------

where we note that @xmath is the relativistic energy of the particle and
@xmath is its rest mass. An additional factor of @xmath is present in
Eq. ( 1.20 ) to account for the number of degenerate spin states per
unit volume.

Eq. ( 1.20 ) is a distribution from which one can extract number density
@xmath , energy density @xmath and pressure @xmath from the microphysics
of the relevant species. For a Bosonic species

  -- -------- -------- -- --------
     @xmath   @xmath      (1.21)
     @xmath   @xmath      (1.22)
     @xmath   @xmath      (1.23)
  -- -------- -------- -- --------

in the relativistic limit ( @xmath ), where @xmath is a value of the
Riemann zeta function. The corresponding number density, energy density
and pressure for a Fermionic ( @xmath ) species are @xmath , @xmath and
@xmath . Note that Eq. ( 1.23 ) ⁷ ⁷ 7 The factor of @xmath is correct if
one considers 3 spatial directions each with a magnitude in rate of
change in momentum per unit area (or force per unit area) integrated
over the spatial volume used by the motion of particles @xmath . (and
its Fermionic counterpart) correctly reproduce the equation of state for
radiation ( @xmath ) which is used in Eq. ( 1.12 ). Notice also that
Eq. ( 1.10 ) can now be confirmed by integrating Eq. ( 1.13 ) in the
collisionless limit over @xmath and combining with Eqs. ( 1.14 ), ( 1.22
) and ( 1.23 ).

For these relativistic species, as the temperature decreases with
expansion, eventually they will fall out of thermal equilibrium. The
quantities @xmath will then become frozen in at their decoupling value,
which is then diluted through the increase of volume during expansion.
Note that because Eqs. ( 1.21 ), ( 1.22 ) and ( 1.23 ) all depend on
temperature (and equivalently for the Fermions) this subsequent dilution
can be accounted for by considering how the temperature reduces with
expansion. Notice that this scaling can be easily connected to the
equation of state of the thermal bath by comparing Eq. ( 1.22 ) to Eq. (
1.12 ). Hence, we find that @xmath .

#### 1.1.4 Composition

Let us define @xmath as the total energy density of the Universe.
Summing over: relativistic species in the Standard Model (SM), i.e.,
neutrinos @xmath and photons @xmath ; vacuum energy density @xmath ;
Baryonic matter @xmath ; and Dark matter @xmath in Eq. ( 1.8 ) we find

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (1.24)
  -- -------- -------- -- --------

where @xmath and we have defined @xmath . The value of the reduced
energy densities today are denoted with @xmath and their approximate
values are indicated in Fig. 1.3 . The dilution factors, in powers of
@xmath , in Eq. ( 1.24 ) are found using the known equations of state
for each component of matter and Eq. ( 1.12 ). In obtaining Eq. ( 1.24
), we have assumed that baryons are non-relativistic — this is, of
course, different depending on the temperature above which they are
relativistic due to their interactions with the thermal bath (and hence
@xmath ). In the case of neutrinos, we have included the possibility
that some neutrinos could be either non-relativistic @xmath or
relativistic @xmath today.

In addition to its homogeneous matter constitution, today the Universe
on large scales exhibits many inhomogeneities such as filaments,
clusters and voids. Such structures must have been sourced by
fluctuations in the total energy density of the Universe that
subsequently collapsed under their own gravity. High-precision
observations of the CMB radiation [ 20 , 21 , 22 ] have revealed
temperature fluctuations @xmath that seeded these collapsed structures,
but the CMB itself must have been imprinted with perturbations in the
primordial plasma energy density from a much earlier mechanism.

### 1.2 Inflation

Inflation [ 23 , 24 , 25 , 26 , 27 , 28 ] is the leading paradigm to
describe the physical conditions that prevailed in the very early
Universe. During this accelerated expansion epoch, cosmological
perturbations are amplified from the vacuum quantum fluctuations of the
gravitational and matter fields [ 29 , 30 , 31 , 32 , 33 , 34 ] and, as
implied in the previous section, measurements [ 20 , 21 , 22 ] of these
inhomogeneities in the CMB have significantly improved our knowledge of
inflation [ 2 , 35 , 36 , 37 ] .

#### 1.2.1 Classical inflationary dynamics

At its simplest (and perhaps most successful), inflation is driven by
the slow roll of a quantum scalar field down its potential. To discuss
the dynamics further, one must introduce a model by way of example. Let
us consider all other matter fields (and @xmath ) to be negligible ⁸ ⁸ 8
This can also be made reasonable as an assumption in the language of
effective field theory: all other fields may take masses which are too
high to be excited at this energy scale, and thus may be ‘integrated
out’. and introduce the following canonical single scalar field @xmath
Langrangian density into the matter Lagrangian density @xmath of Eq. (
1.5 )

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

The action for this canonical scalar field in a general cosmological
background is thus

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

The energy-momentum tensor of @xmath is

  -- -------- -- --------
     @xmath      (1.27)
  -- -------- -- --------

and its equation of motion is

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

In an FLRW Universe (see the line element in Eq. ( 1.1 )) with the
spatial curvature @xmath (as it is suppressed during inflation) and a
homogeneous scalar field @xmath , Eq. ( 1.28 ) becomes

  -- -------- -- --------
     @xmath      (1.29)
  -- -------- -- --------

where the @xmath is constrained to the energy density of the scalar
field @xmath via Eq. ( 1.8 ). One can always treat the scalar field as a
perfect fluid due to there being no anisotropic stress, ⁹ ⁹ 9 Since
there can only be one degree of freedom. hence we can obtain the energy
density of @xmath

  -- -------- -- --------
     @xmath      (1.30)
  -- -------- -- --------

and the pressure of @xmath

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

Hence the equation of state for @xmath is

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

Inflation requires an accelerated expansion of the Universe, so the
condition on the scale factor for this epoch is

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

In this regime it will also prove convenient to define some new
parameters

  -- -------- -- --------
     @xmath      (1.34)
  -- -------- -- --------

where @xmath , @xmath and @xmath is known as the number of ‘ @xmath
-folds’. In rewriting Eq. ( 1.33 ) in terms of @xmath and Eq. ( 1.34 )
one finds

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

thus inflation corresponds to @xmath . Notice that matching Eq. ( 1.9 )
with Eq. ( 1.33 ) also is equivalent to the condition

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

Hereafter, we shall use the term ‘slow-roll’ for dynamics which satisfy
@xmath . This regime is interesting due to its known attractor
behaviour, limiting the arbitrariness required in setting the initial
conditions to the inflationary epoch.

By comparison with Eq. ( 1.32 ) we see that this condition on the
equation of state requires the field to be dominated by its potential
energy @xmath and so, using Eq. ( 1.32 ), typical models of inflation
have @xmath corresponding to (or close to) a pure de Sitter spacetime
where @xmath and @xmath . ¹⁰ ¹⁰ 10 Note that this is exactly the same as
a spacetime dominated by a cosmological constant @xmath . Slow-roll
inflation achieves exactly this feat by considering the gradual roll of
a scalar field towards its potential minimum (where an initial condition
has to be set by some mechanism) while the slope of the potential is
typically gentle enough that the second derivative in time of Eq. ( 1.29
) is never important. Due to this fact, Eq. ( 1.29 ) reduces to

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

defining what are known as ‘classical’ slow-roll dynamics. ¹¹ ¹¹ 11
Reasons for this distinction from ‘quantum’ dynamics will become clear
in later sections. In this limit, we must also assume that

  -- -------- -- --------
     @xmath      (1.38)
  -- -------- -- --------

such that Eq. ( 1.37 ) can be rewritten as

  -- -------- -- --------
     @xmath      (1.39)
  -- -------- -- --------

The number of @xmath -folds @xmath serves as a useful parameter to
characterise the length of time that inflation takes place. Between
@xmath and @xmath , Eq. ( 1.39 ) can be manipulated to give

  -- -------- -- --------
     @xmath      (1.40)
  -- -------- -- --------

where we have integrated between @xmath and @xmath during some slow-roll
phase of the homogeneous field @xmath . Note that for single field
slow-roll inflation it is simple to show, using Eqs.( 1.38 ), ( 1.39 )
and ( 1.34 ), that

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

#### 1.2.2 Sourcing cosmological perturbations

To begin with, let us break the homogeneity assumption of @xmath by
splitting it up into a homogenous part and a small fluctuation @xmath
like so

  -- -------- -- --------
     @xmath      (1.42)
  -- -------- -- --------

where we are now using conformal time @xmath as our time variable. This
expansion should be considered in conjunction with the line element for
scalar metric perturbations to linear order [ 10 , 38 ]

  -- -------- -- --------
     @xmath      
     @xmath      (1.43)
  -- -------- -- --------

which follows from a flat FLRW background. Using Eq. ( 1.43 ) and Eq. (
1.42 ) it can be shown that the scalar sector of matter and
gravitational fluctuating degrees of freedom can be described entirely
by the following gauge-invariant quantity [ 10 , 38 ]

  -- -------- -- --------
     @xmath      (1.44)
  -- -------- -- --------

where @xmath is known as the Mukhanov-Sasaki variable [ 39 , 40 ] . We
will avoid discussing Eq. ( 1.44 ) in too much detail here, however, let
us simply note that gauge freedom permits the fixing of variables within
@xmath to eliminate unphysical degrees of freedom. ¹² ¹² 12 Choose
@xmath for the spatially flat gauge, @xmath for the Newtonian gauge,
@xmath for comoving gauge and @xmath for synchronous gauge [ 38 ] .

Let us now expand Eq. ( 1.26 ) to second order in @xmath to give [ 41 ]
¹³ ¹³ 13 No linear order terms in @xmath can exist since they have to
vanish in order to extremise the action.

  -- -------- -- --------
     @xmath      (1.45)
  -- -------- -- --------

where we have used Eq. ( 1.41 ) and the action, upon variation with
respect to @xmath , and a Fourier transform (such that @xmath ) gives
the following equation of motion ¹⁴ ¹⁴ 14 This is known as the
‘Mukhanov-Sasaki’ equation [ 39 , 40 ] .

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

where @xmath is the (comoving) spatial Laplacian. Note that Eq. ( 1.46 )
now characterises the dynamics of the entire scalar sector on both super
( @xmath ) and sub-horizon ( @xmath ) scales.

Note that @xmath and its canonical momentum conjugate

  -- -------- -- --------
     @xmath      (1.47)
  -- -------- -- --------

can be expanded in a Fourier basis in terms of its mode functions such
that

  -- -------- -- --------
     @xmath      (1.48)
     @xmath      (1.49)
  -- -------- -- --------

where @xmath and @xmath are the creation and annihilation operators,
respectively. These are normalised according to the standard commutation
relations

  -- -------- -- --------
     @xmath      (1.50)
  -- -------- -- --------

which in conjuction with satisfying the equal-time commutation relations
of the field operators of Eq. ( 1.48 ) and Eq. ( 1.49 ) (in order for
the theory to be causal)

  -- -------- -- --------
     @xmath      (1.51)
     @xmath      (1.52)
  -- -------- -- --------

give rise to the following Wronskian normalisation

  -- -------- -- --------
     @xmath      (1.53)
  -- -------- -- --------

Substituting into Eq. ( 1.46 ) the leading order slow-roll expansion for
@xmath at a point @xmath in time, ¹⁵ ¹⁵ 15 To leading order in slow roll
expansion about @xmath , the change in scale factor can be expressed as

@xmath

where @xmath . Equivalently, one finds that the first slow roll
parameter varies according to

@xmath

one finds

  -- -------- -- --------
     @xmath      (1.54)
  -- -------- -- --------

Eq. ( 1.54 ) has the following solution to leading-order in the slow
roll (such that @xmath and @xmath are constant)

  -- -------- -- --------
     @xmath      (1.55)
  -- -------- -- --------

where: @xmath and @xmath are Hankel functions of the first and second
kind, respectively; both @xmath and @xmath here are constants to be set
by initial conditions; and we have defined ¹⁶ ¹⁶ 16 Note that due to the
expansion in Eq. ( 1.45 ), one can gain more physical intuition by using
Eq. ( 1.39 ) and Eq. ( 1.34 ) to rewrite Eq. ( 1.56 ) as

@xmath

which holds more generically for test fields as well (fields whose
energy density is so sub-dominant that, effectively, @xmath ).

  -- -------- -- --------
     @xmath      (1.56)
  -- -------- -- --------

A subtle, yet deep issue arises when naïvely attempting to set the
initial conditions @xmath and @xmath of Eq. ( 1.55 ). Notice that the
mode functions which satisfy Eq. ( 1.54 ) will have a time-dependent
frequency. Due to this fact, it becomes problematic to define the vacuum
state unambiguously. Consider that the set of mode functions for which
the Hamiltonian, constructed out of Eqs. ( 1.48 ), ( 1.49 ) and ( 1.53
), is minimised (to find the ground state) at one point in time @xmath
will not be the same set of mode functions to minimise the Hamiltonian
at a later time @xmath . The solution to this problem of ambiguity in
the ground state lies in noticing that the sub-Hubble limit @xmath of
Eq. ( 1.54 ) removes this time dependence. Hence we may asymptotically
define a ground state that is identical to that in Minkowski space known
as the Bunch-Davies vacuum

  -- -------- -- --------
     @xmath      (1.57)
  -- -------- -- --------

and hence by comparison to the sub-Hubble limit of Eq. ( 1.55 ) (up to
an irrelevant phase factor of @xmath which the power spectrum cannot
observe) we see that the necessary initial conditions to set for the
Bunch-Davies vacuum are

  -- -------- -- --------
     @xmath      (1.58)
  -- -------- -- --------

Now that we are able to set the conditions in Eq. ( 1.58 ), our solution
which asymptotically matches the Bunch-Davies vacuum is

  -- -------- -- --------
     @xmath      (1.59)
  -- -------- -- --------

In slow roll @xmath and hence we can approximate the amplitude-squared
of Eq. ( 1.59 ) in the super-horizon limit, i.e, the limit where @xmath
, as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (1.60)
  -- -------- -------- -- --------

In order to calculate the variance of @xmath itself, the integral in the
Fourier basis of Eq. ( 1.48 ) gives rise to an additional factor of
@xmath in Eq. ( 1.60 ), hence we may define the power spectrum @xmath
which quantifies the variance of field fluctuations through

  -- -------- -- --------
     @xmath      (1.61)
  -- -------- -- --------

where @xmath in this expression is to be understood as an ensemble
average (computed from a quantum average) over the field fluctuations.
By comparison of Eq. ( 1.60 ) with Eq. ( 1.61 ), we arrive at

  -- -------- -- --------
     @xmath      (1.62)
  -- -------- -- --------

on super-horizon scales, indicating a scale-invariant spectrum.

The variable @xmath in Eq. ( 1.44 ) can also be directly related to the
comoving curvature peturbation @xmath (which can be shown to be constant
super-Hubble scales as long as the fluctuations are adiabatic [ 6 , 9 ,
38 , 42 , 43 , 44 ] , making it extremely useful for translating the
curvature perturbation to later epochs) by fixing @xmath such that

  -- -------- -- --------
     @xmath      (1.63)
  -- -------- -- --------

Therefore, the power spectrum of @xmath that is sourced by the field
@xmath is

  -- -------- -- --------
     @xmath      (1.64)
  -- -------- -- --------

which is typically evaluated at some pivot scale @xmath of the comoving
wave vector. Varying Eq. ( 1.64 ) with respect to @xmath up to second
order, we find a new pair of parameters which can be constrained from
CMB data

  -- -------- -------- -- --------
     @xmath   @xmath      (1.65)
     @xmath   @xmath      (1.66)
  -- -------- -------- -- --------

which are the spectral index @xmath and running of the spectral index
@xmath , respectively. Notice that the last equalities in both
expressions are valid only for single-field models to leading order in
slow roll.

The fluctuations in the spacetime metric can be decomposed into more
than just the scalar degree of freedom that we have studied so far. In
fact it is known that, due to the conservation of angular momentum,
vector perturbations decay during inflation. In contrast, one can expand
the tensor degrees of freedom — two tensor helicities, @xmath and @xmath
, are available ¹⁷ ¹⁷ 17 This is due to the constraint that the full
tensor degree of freedom @xmath arising from the tensor-perturbed
metric, with line element

@xmath

must be transverse @xmath and trace-free @xmath . — out of the full
action up to second order to find an equivalent expression to Eq. ( 1.45
). Varying this expression with respect to the metric, we arrive at the
equations of motion for each polarisation of the tensor perturbations
which are the same as for the massless scalar

  -- -------- -- --------
     @xmath      (1.67)
  -- -------- -- --------

where @xmath . In order to compute the same vacuum fluctuations as in
the scalar case, we must normalise @xmath in the same way such that the
newly defined tensor perturbation is

  -- -------- -- --------
     @xmath      (1.68)
  -- -------- -- --------

Finally, using the same reasoning as for the scalars, Eq. ( 1.67 ) and
accounting for the two separate polarisations, we compute the power
spectrum of tensor perturbations as ¹⁸ ¹⁸ 18 This becomes clear from its
definition @xmath .

  -- -------- -- --------
     @xmath      (1.69)
  -- -------- -- --------

where, as before, we used the slow roll equation ( 1.38 ) to compute the
second equality. Using Eq. ( 1.69 ) and Eq. ( 1.64 ) we can define the
tensor-to-scalar ratio

  -- -------- -- --------
     @xmath      (1.70)
  -- -------- -- --------

which is used to compare inflationary models to CMB data, and where we
applied slow roll to obtain the last equality.

In this section, we obtained the observables @xmath , @xmath , @xmath
and @xmath all from classical inflationary field dynamics. Let us now
take a quick example of a popular potential @xmath from which we can
compute the observables. The Starobinksy potential [ 23 ] is a plateau
inflationary model with

  -- -------- -- --------
     @xmath      (1.71)
  -- -------- -- --------

The slow-roll parameters for this model, which may be calculated from
Eq. ( 1.34 ) and Eq. ( 1.41 ), are [ 35 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.72)
     @xmath   @xmath      (1.73)
     @xmath   @xmath      (1.74)
  -- -------- -------- -- --------

At a value of, e.g., 60 @xmath -folds before the end of inflation, ¹⁹ ¹⁹
19 In many models, 50-60 is the typical number of @xmath -folds before
the end of inflation at which the observable perturbations crossed the
Hubble radius [ 45 ] . Eq. ( 1.40 ) gives us a value of @xmath [ 35 ] .
From Eqs. ( 1.65 ), ( 1.66 ), ( 1.70 ) and this value we find that, to
leading order in slow roll, @xmath , @xmath and @xmath .

#### 1.2.3 Resumming divergences

So far the extent to which fluctuations of the quantum field @xmath have
been taken into account is in describing how cosmological perturbations
are sourced from its vacuum fluctuations with a Bunch-Davies initial
condition. What we shall consider now is a consequence of these
fluctuations leaving the Hubble radius on large scales and accumulating
in the Infra-Red (IR) limit. To begin with, let us rewrite Eq. ( 1.29 )
for a massless test field @xmath in terms of conformal time

  -- -------- -- --------
     @xmath      (1.75)
  -- -------- -- --------

where we are now including the inhomogeneity of the field explicitly
such that the comoving spatial Laplacian @xmath is non-vanishing.
Expanding the field of Eq. ( 1.75 ) in a Fourier basis, similarly to
Eq. ( 1.48 ), we find

  -- -------- -- --------
     @xmath      (1.76)
  -- -------- -- --------

and hence the equation of motion that @xmath satisfies is simply

  -- -------- -- --------
     @xmath      (1.77)
  -- -------- -- --------

where the Bunch-Davies solution to this equation is equivalent to the
massless limit of Eq. ( 1.59 )

  -- -------- -------- -- --------
     @xmath   @xmath      (1.78)
              @xmath      (1.79)
  -- -------- -------- -- --------

where Eq. ( 1.79 ) is obtained by using the fact that, in de Sitter,
@xmath is constant and so @xmath . Returning to the @xmath form of the
field, we are now ready to calculate an expectation value (in the
quantum sense) between spatially-separated points @xmath and @xmath .
Denoting the vacuum state with @xmath , ²⁰ ²⁰ 20 This is defined such
that @xmath . the two-point function is [ 46 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (1.80)
  -- -------- -------- -- --------

where we have obtained the second equality by an angular integral over
@xmath . Substituting Eq. ( 1.79 ) into Eq. ( 1.80 ) and expanding about
the super-horizon limit @xmath , we obtain the following @xmath
-behaviour in the indefinite form of the integral ²¹ ²¹ 21 Note that
this result coincides with integrating the result from Eq. ( 1.60 ) in
the spatially flat gauge, where @xmath .

  -- -------- -- --------
     @xmath      (1.81)
  -- -------- -- --------

where we have implicitly also used the fact that the spatial separation
must satisfy @xmath for the correlator to be causal. This example
demonstrates that the correlation functions of quantum fields in an
inflationary spacetime exhibit logarithmic divergences in the IR limit.
²² ²² 22 Taking @xmath , there is a divergence, but in practice there is
a cutoff because @xmath is impossible as an initial condition [ 46 ] .

In addition to the divergence of Eq. ( 1.81 ), we will now show that an
additional problem emerges when one wishes to consider interactions [ 46
, 47 ] . Using Eq. ( 1.46 ) in the spatially flat gauge (where @xmath ),
one can write the full equation of motion for an inhomogenous test field
where the potential @xmath is now included (and hence the interaction
terms within it)

  -- -------- -- --------
     @xmath      (1.82)
  -- -------- -- --------

and perturbatively expand @xmath such that @xmath is the free field,
@xmath follows Eq. ( 1.82 ) where @xmath is the source to any
interactions and so on to higher order. ²³ ²³ 23 Note that this
expansion is separate from Eq. ( 1.42 ) since the former is a mean field
expansion and the latter is performed for the expansion of cosmological
perturbations. In such a picture, one uses the inhomogenous solution to
the free field Eq. ( 1.82 )

  -- -------- -- --------
     @xmath      (1.83)
  -- -------- -- --------

where @xmath here is the mass of the free field potential (and hence
does not depend on the field itself) and @xmath is the retarded Greens
function, which we can calculate using Eq. ( 1.76 ) and Eq. ( 1.79 ).

We now collect all remaining terms of the potential (beyond free field)
using the following method. Using @xmath to construct the Yang-Feldman
equation [ 48 ] , one integrates the interactions of the field in Eq. (
1.82 ) up to all orders in the expansion

  -- -------- -- --------
     @xmath      (1.84)
  -- -------- -- --------

where @xmath is now the full potential. Note here that the vertex
integration contributes a factor of @xmath , causing a (rather
catastrophic) break down in the perturbative expansion after some
critical timescale [ 47 ] and hence originating an additional IR
logarithm that must be removed.

It transpires that the first of these divergences may be removed through
the application of a cutoff. Notice that, because the observable
perturbations are super-horizon during inflation, one can choose to
place a cutoff in Eq. ( 1.76 ) on the modes up to a Fourier
coarse-graining scale @xmath (where @xmath ) such that our new field has
the UV modes integrated out like so

  -- -------- -- --------
     @xmath      (1.85)
  -- -------- -- --------

However, if we were to substitute the remaining modes (by simply
flipping the @xmath in Eq. ( 1.85 )) into Eq. ( 1.79 ) and compute the
two-point function, we would find that Eq. ( 1.81 ) is rendered finite
since the integrand is predominantly oscillatory in that mode range.
This means that first divergence we identified in the two-point function
has been removed!

Let us now compute the commutator of @xmath using the free field mode
functions

  -- -- -------- -- --------
        @xmath      
        @xmath      
        @xmath      (1.86)
  -- -- -------- -- --------

The emergence of solely classical fluctuations of the field, i.e. those
for which the commutator becomes much smaller than the corresponding
anticommutator, can be immediately seen in the super-horizon limit
@xmath . This feature exists for @xmath in the same way — since the only
difference would be the removal of the @xmath regulator in the upper
limit of the integral — and is one example of the quantum-to-classical
transition [ 49 , 50 ] that explains why cosmological perturbations with
a quantum source are observed as classical. ²⁴ ²⁴ 24 In more detail,
this is thought to be a consequence of the unique two-mode squeezed
quantum state [ 51 , 52 , 53 ] that fields find themselves in during
inflation. In addition, one must also study the transition without
taking the super-horizon limit.

So far, we have demonstrated that by a redefinition of the field @xmath
, which leaves the observables unchanged through the application of a
regularisation procedure that cannot affect the observables in the IR,
one can successfully remove the divergence in the free field correlation
functions. Furthermore, we have shown that the new IR field @xmath has a
vanishing commutator which implies that it may be described as a
classical, stochastic field. An additional problem still appears to
persist, however. In order to describe an interacting field, one can
attempt to use @xmath in Eq. ( 1.84 ). Perturbation theory breaks down
after a finite timescale in the vertex integration itself, which
contributes a secular growth factor of @xmath , and this problem has not
yet been resolved. For practical applications of Eq. ( 1.85 ), this
remaining problem suggests that a non-perturbative solution is required
in order to take into account of the time evolution of the system.

Let us return to Eq. ( 1.37 ) for the dynamics of a field during
slow-roll inflation. This equation is still valid for an inhomogeneous
field @xmath in the super-horizon limit (where the gradient term @xmath
may safely be neglected). Combining Eq. ( 1.85 ) and Eq. ( 1.37 ), we
find ²⁵ ²⁵ 25 This is easily confused with a similar type of expansion
as Eq. ( 1.42 ). This is true only instantaneously since Eq. ( 1.87 )
represents the slow-roll expansion evaluated at each new moment in time
(rather than the expansion performed about, e.g., the end of inflation).
This optimisation of the perturbative expansion is similar to a
renormalisation group flow — an observation we will make later.

  -- -------- -- --------
     @xmath      (1.87)
  -- -------- -- --------

where we remind the reader that @xmath is the number of @xmath -folds
and we have defined a new term [ 54 ] ²⁶ ²⁶ 26 The identity @xmath has
been used here as well as

@xmath

  -- -- -------- -- --------
        @xmath      
        @xmath      (1.88)
  -- -- -------- -- --------

which is valid in slow roll, where @xmath . Evaluating the two-point
function of this new @xmath term, under the assumption of massless mode
functions, we find

  -- -- -------- -- --------
        @xmath      
        @xmath      (1.89)
  -- -- -------- -- --------

where we have used the fact that @xmath . Note that to give the temporal
correlation in terms of @xmath -folds, one simply relates @xmath . In
the super-horizon limit Eq. ( 1.89 ) thus informs us that @xmath becomes
a white noise with an amplitude of @xmath in Eq. ( 1.87 ).

In light of this new development, one is correct in the interpretation
of Eq. ( 1.87 ) as a Langevin equation — a stochastic differential
equation. If one were to evolve it under many realisations and integrate
over time, the result would be that a Probability Density Function (PDF)
could be constructed over the values that the field could take over a
specified interval and given an appropriate initial condition. Note that
this is a non-perturbative resummation which transcends the need for an
expansion of the form in Eq. ( 1.84 ), as long as the slow roll is
satisfied. ²⁷ ²⁷ 27 In fact, this method can be applied to more general
situations than slow roll. Applying this technique to the full phase
space requires a second noise (and accompanying coupled Langevin
equation) for the conjugate momentum [ 55 ] . It transpires that slow
roll is still an attractor, however, and since we shall predominately
consider test fields on a slow-roll background Eq. ( 1.87 ) will be
adequate for our needs. This is due to the fact that the backreaction
from small quantum fluctuations is inherently included into the
background evolution described by Eq. ( 1.87 ), thus optimising the
perturbative expansion at each new scale in time — a cosmological analog
to (but not exactly the same as [ 56 ] ) the renormalisation group flow
[ 57 ] . Let us also note that massless mode functions were used to
evaluate the white noise in Eq. ( 1.87 ), hence if the massless
assumption ( @xmath ) were no longer correct then it would invalidate
this current approach. Applying Eq. ( 1.87 ) to non-perturbatively
calculate the IR behaviour of light (effectively massless) fields in an
inflationary background is known as the stochastic inflation formalism [
32 , 58 , 54 ] .

If one considers how the background energy density is affected by the
evolution of @xmath , there are two distinct possibilities: it is an
inflaton (or ‘non-test field’) meaning that inflation proceeds with
@xmath being contributed to by @xmath ; or, it is a ‘test field’ which
is sub-dominant to the overall energy density of the Universe during
inflation and thus one can effectively treat @xmath as independent of
@xmath . In the former case it has been shown that in order to correctly
reproduce the results from Quantum Field Theory (QFT) on curved
spacetime, one must use @xmath as the time variable in Eq. ( 1.87 ).
Many works have considered this issue [ 59 , 60 , 61 , 62 ] and
incorporated the quantum diffusion given by Eq. ( 1.87 ) directly into
the inflationary dynamics, with interesting results. For example, the
power spectrum ( 1.64 ) becomes [ 62 , 63 , 64 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (1.90)
  -- -------- -------- -- --------

where @xmath and one can see that the backreaction onto the inflationary
dynamics, caused by these divergences, leads to the sensitivity of the
power spectrum (among other observables [ 63 , 64 ] ) to the entire
inflationary domain. ²⁸ ²⁸ 28 A modified form of the separate Universe
approach [ 65 ] (and in Sec. 1.2.2 ) has been employed to obtain the
perturbations here. Though this is a fascinating area of current
research, in this thesis we shall focus primarily on the latter
situation where @xmath is a test field.

The noise amplitude, calculated in Eq. ( 1.89 ), is @xmath in the
super-horizon limit, hence the corresponding Fokker-Planck equation to
Eq. ( 1.87 ) is

  -- -------- -- --------
     @xmath      (1.91)
  -- -------- -- --------

where we have defined @xmath as the one-point PDF. ²⁹ ²⁹ 29 There is a
subtlety in defining the diffusion term ( @xmath ) in this equation with
the interpretation of stochastic process (either Itô or Stratonovich).
Here we choose Itô as one can show that this exceeds the accuracy of the
approximation one makes in the stochastic formalism in its current
implementation [ 62 ] . Notice that Eq. ( 1.91 ) is similar to a
continuity equation so that one may define a probability current @xmath
as follows

  -- -------- -- --------
     @xmath      (1.92)
  -- -------- -- --------

where @xmath itself can be deduced as

  -- -------- -- --------
     @xmath      (1.93)
  -- -------- -- --------

In the limit where @xmath , ³⁰ ³⁰ 30 In later chapters we shall
demonstrate why @xmath is an interesting limit. Suffice it here to state
that when there is only one field, integrability at infinity enforces
@xmath . and @xmath is a test field, the equilibrium distribution of
this Fokker-Planck equation is

  -- -------- -- --------
     @xmath      (1.94)
  -- -------- -- --------

and we shall return to discussing the stochastic formalism in more
detail in later chapters, though predominately in Chapter 4 .

### 1.3 Perturbative reheating

Inflation itself leaves the Universe empty of SM particles. So far, the
discussion of inflation has been confined to the processes that take
place throughout its duration. A crucially important phase after
inflation which is required to set cosmological initial conditions
correctly is reheating. Reheating is the process by which the Universe
fills with SM particles and it typically achieved through the
thermalisation of the inflaton. The most thorough non-perturbative
calculations of this process to date typically are performed by a
lattice simulation [ 3 ] . In this section however, we shall follow the
perturbative arguments in Refs. [ 66 , 67 , 68 , 6 ] to attain a brief,
overall picture for this process.

In Sec. 1.1.3 we noted that the continuity equation derived from the
Einstein field equations (Eq. ( 1.10 )) could be verified by integrating
Eq. ( 1.13 ) in the collisionless limit over @xmath and combining with
Eqs. ( 1.14 ), ( 1.22 ) and ( 1.23 ). ³¹ ³¹ 31 We can see that this is
straightforward by using the chain rule

@xmath

where after a @xmath integration, the expression becomes @xmath . In
perturbative reheating one approximates the thermalisation of the
inflaton as a decay process (such as a trilinear interaction) modeled by
the following integrated Boltzmann equation

  -- -------- -- --------
     @xmath      (1.95)
  -- -------- -- --------

where the term on the RHS is an approximate form for the collision
operator and @xmath is the decay rate. The mechanism is such that when
the Hubble rate drops to and below the decay rate @xmath , the
thermalisation occurs and the inflaton field decays into SM particles.
By considering the coherent oscillations of scalar fields in a
cosmological background one can deduce, e.g., that if @xmath oscillates
about a quartic minimum @xmath then @xmath and if it oscillates about a
quadratic minimum @xmath then @xmath [ 69 ] . For a potential minimum
with the shape @xmath , one expects @xmath [ 70 ] .

A term such as the one on the RHS can be estimated through the physics
of decay associated with @xmath . In particular, if the decay of @xmath
were gravitationally mediated, one would expect a relation of the form [
71 , 72 ]

  -- -------- -- --------
     @xmath      (1.96)
  -- -------- -- --------

which is, in practice, the smallest decay rate expected in the early
Universe and hence it is essentially a lower bound on all possible decay
rates.

The standard post-inflationary phenomenology is thus as follows:
inflation terminates due to slow-roll violation @xmath ; shortly after,
the mass of the inflaton becomes of the same order as the Hubble rate
@xmath , it dynamically unfreezes and begins to coherently oscillate;
and finally, after some time, the Hubble rate lowers to the same order
as the decay rate of the inflaton @xmath and the field thermalises. This
sequence of events is depicted in Fig. 1.4 .

At the time of decay, assuming that the products of the process are in
equilibrium with the thermal bath of SM particles, we can use Eq. ( 1.22
) to relate energy densities @xmath contained in radiation fluids to
temperatures through

  -- -------- -- --------
     @xmath      (1.97)
  -- -------- -- --------

where @xmath is the effective number of degrees of freedom

  -- -------- -- --------
     @xmath      (1.98)
  -- -------- -- --------

which one calculates through a rescaling to account for both Bosonic and
Fermionic degrees of freedom: @xmath and @xmath , respectively.

#### 1.3.1 The curvaton mechanism

We will now apply the tools developed in the previous sections to
compute the observables of the curvaton model [ 73 , 74 , 75 ] . This is
a two-field model where the generic potential is of the form ³² ³² 32
Note that the curvaton itself is not required to specifically have a
quadratic potential, though in the original realisation of the model
this is the case [ 73 , 74 , 75 ] as this proves useful to the reheatic
kinematics.

  -- -------- -- --------
     @xmath      (1.99)
  -- -------- -- --------

During inflation, additional light (masses smaller than the Hubble rate
@xmath ) test (energetically sub-dominant such that @xmath is
independent of them) fields, such as @xmath , can fluctuate in an
orthogonal direction to the inflaton perturbations (also known as
adiabatic). These are known as isocurvature perturbations and can be
observed directly as relic fluctuations in the relative number density
of a given particle species [ 76 ] . In the case of the curvaton model,
one typically assumes that these relic number density variations have
fully thermalised and reached thermodynamic equilibrium with the
background radiation. When this happens, the perturbations of @xmath can
be shown to contribute only to the adiabatic perturbations [ 77 , 78 ,
79 ] . ³³ ³³ 33 Some curvaton models leave non-adiabatic fluctuations
even after thermalisation of the decay products, e.g., in the presence
of a conserved quantum number, like baryon number (see [ 80 ] ). A
curvaton then provides a mechanism to source the observed primordial
density perturbations in the CMB independently of the inflaton.

After inflation, the inflaton field energy density @xmath decays into
radiation and the energy density contained in the curvaton field, @xmath
, may grow relative to the background energy density, until it also
decays into radiation. If isocurvature perturbations do not persist but
instead fully thermalise into an adiabatic perturbation when inflation
ends, the total adiabatic power spectrum is given by the sum of the
power spectra,

  -- -------- -- ---------
     @xmath      (1.100)
  -- -------- -- ---------

where in the case of observational interest that @xmath (reminding the
reader that @xmath )

  -- -------- -- ---------
     @xmath      (1.101)
  -- -------- -- ---------

Here we have calculated the amplitude of the perturbation coming from
@xmath in Eq. ( 1.101 ) by perturbing to linear order with an
isocurvature fluctuation @xmath from a uniform density hypersurface,
such that

  -- -------- -- ---------
     @xmath      (1.102)
  -- -------- -- ---------

and estimating ³⁴ ³⁴ 34 Note that @xmath is a gauge-invariant quantity
and so we have been able to compute this in the spatially flat gauge
where @xmath [ 42 ] . There is energy conservation of each species (see
Eq. ( 1.10 )) on super-horizon scales as they evolve along their own
FLRW comoving worldlines.

  -- -------- -- ---------
     @xmath      (1.103)
  -- -------- -- ---------

where @xmath . Note that here we have used the fact that the equation of
state of the curvaton during its oscillations will be @xmath due to its
quadratic minimum and, in order to obtain Eq. ( 1.102 ), we have assumed
the sudden-decay approximation for the curvaton [ 81 , 82 ] . Note also
that @xmath can vary from zero to unity in the case that @xmath
dominates the background energy density at the time it decays.

The spectral index @xmath and tensor-to-scalar ratio @xmath of this
model, following our definitions in Eqs. ( 1.65 ) and ( 1.70 ), are
given to leading order in slow roll by [ 83 ]

  -- -------- -------- -- ---------
     @xmath   @xmath      (1.104)
     @xmath   @xmath      (1.105)
  -- -------- -------- -- ---------

where here we have defined @xmath and @xmath while @xmath denotes the
fraction of the total perturbations originating from @xmath ,

  -- -------- -- ---------
     @xmath      (1.106)
  -- -------- -- ---------

Note that Eq. ( 1.106 ) may be evaluated by inserting Eq. ( 1.101 ).
When the primordial density perturbation is entirely due to curvaton
field fluctuations then the original curvaton model [ 73 , 74 , 75 ] is
realised.

Another way to detect the curvaton is through primordial non-linearity
of the density perturbations, of which the key observable is the local
non-Gaussianity of the bispectrum, parametrised by @xmath through the
relation [ 84 ]

  -- -------- -- ---------
     @xmath      (1.107)
  -- -------- -- ---------

where @xmath is the spatially varying metric potential ( @xmath during
matter domination) and @xmath is a single Gaussian random field.

In curvaton models, the value of @xmath can be approximately related to

  -- -------- -- ---------
     @xmath      (1.108)
  -- -------- -- ---------

where we have assumed sudden-decay approximation for the curvaton here
as well [ 85 ] . Note that this formula follows naturally if one
perturbs on constant density hypersurfaces to second order in @xmath
such that [ 82 ]

  -- -------- -- ---------
     @xmath      
                 (1.109)
  -- -------- -- ---------

where we have used Eq. ( 1.102 ) and @xmath [ 82 ] .

## Chapter 2 Statistical introduction

Abstract. In this chapter we will very briefly review some topics in
Bayesian statistics [ 86 , 87 , 88 ] , dealing with the mathematical
formulation of inference and model selection. In addition, some useful
concepts in classical information theory [ 89 ] will be covered as well
as a short review of the fundamentals for Bayesian experimental design [
90 ] in order to prepare for its application in Chapter 6 .

### 2.1 Bayesian inference

The robustness of the scientific method relies upon a continual
comparison between theory and experiment. Rigorous statistical analysis
is thus a cornerstone of any scientific result, where there still exits
a lively debate over the optimal method. ¹ ¹ 1 Though the debate between
methods is philosophical in nature, it is important to still acknowledge
that the perspective taken in this thesis will be largely that of a
‘Bayesian point of view’, and hence we will avoid addressing these
fundamental questions in favour of a more direct technical application
of the formalism itself.

In probability theory, one can denote the probability of an event @xmath
occurring by @xmath . If one has another event @xmath , upon which
@xmath may or may not rely, then one may construct: the probability of
@xmath occurring @xmath ; the probability of @xmath occurring given that
@xmath has occurred @xmath (and its converse); and the joint probability
of both @xmath and @xmath occurring, @xmath . The essential concept of
Bayesian statistics originates from considering the following identity
between conditional probabilities of @xmath and @xmath and their joint
probability

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

Adapting Eq. ( 2.1 ), we immediately find Bayes’ theorem

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

Eq. ( 2.2 ) informs us on the correct procedure that one must take in
updating knowledge about @xmath with @xmath . Hence, it is Eq. ( 2.2 )
which forms the basis upon which all Bayesian reasoning is founded.

Statistical inference in the Bayesian paradigm falls naturally out of
Eq. ( 2.2 ). If one wishes to update knowledge of a parameter @xmath
with data @xmath to obtain a posterior distribution over it @xmath ,
Eq. ( 2.2 ) tells us to multiply the likelihood function over a
collection of data @xmath to some given prior information @xmath , such
that

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

Let us illustrate the Bayesian update of @xmath into @xmath using the
following simple example: consider a Gaussian prior

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

and likelihood function

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

which share the same mean @xmath but have different standard deviations
@xmath and @xmath , respectively. The posterior distribution which
corresponds to these distributions can be calculated using Eq. ( 2.3 )
(ignoring the normalisation), where one finds

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

Comparing Eq. ( 2.6 ) with Eq. ( 2.4 ), we see that the prior standard
deviation has been updated by the data using Bayes’ theorem @xmath .
From this example, we see that the net results will always increase the
precision over @xmath for finite @xmath .

If we were to go a step further and assume that a model @xmath had a
defined set of parameters @xmath , the posterior probability @xmath of
its parameters @xmath would be expressed as

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

where @xmath is the likelihood and represents the probability of
observing the data @xmath assuming the model @xmath is true and @xmath
are the actual values of its parameters and @xmath is the prior
distribution on the parameters @xmath . Notice that, in contrast to
Eq. ( 2.3 ), we have now specifically defined @xmath as the
normalisation constant called the Bayesian evidence, which we shall
discuss further in Sec. 2.3 .

Eq. ( 2.7 ) shows that @xmath is an important quantity to construct when
a statistical inference is to be performed. It is possible to conduct an
inference on parameters with very little information about this
quantity, ² ² 2 We refer the reader to the many reviews on the topic,
e.g., Refs. [ 91 , 92 , 93 ] . however in this thesis we shall primarily
focus on situations where the likelihood function is well known and
parameterised in an optimal way, e.g., such as that of
LABEL:Ringeval:2013lea . The dimensionality of @xmath is often an
important indication of what methodology to use — splitting @xmath into
two approximately categories, either:

1.  The number of dimensions is low enough such that one can perform
    Importance (or Rejection) sampling [ 95 , 96 ] . We will make use of
    this technique combined with Nested sampling in Chapter 5.C , where
    more detail can be found in Appendix 5.C .

2.  The number of dimensions is too high, in which case one may select
    from a number of sampling techniques, e.g., Metropolis-Hastings,
    Gibbs and Hamiltonian Monte Carlo sampling [ 95 , 96 ] .

### 2.2 The Kullback-Leibler divergence

Information theory can provide a powerful insight into statistical
inference. In particular, it is quite common to find quantities which
are reparameterisation invariant and hence extremely useful for robust
analysis. The relative (or conditional) entropy between the prior @xmath
and posterior @xmath distributions on some parameter @xmath is called
the Kullback-Leibler divergence, and is defined for a 1-dimensional
@xmath -space as

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

where we have chosen a base of @xmath such that @xmath is measured in
bits and the integration limits are those specified by the domain of
@xmath . This is a measure of the amount of information provided by the
data about the parameter @xmath . Since it uses a logarithmic score
function, it is a well-behaved measure of information [ 97 ] . Note that
Eq. ( 2.8 ) can easily be generalised to an arbitrary number of
parameter dimensions, but we shall here keep @xmath as 1-dimensional for
simplicity.

The @xmath is indeed invariant under a generic reparameterisation @xmath
. This is because the prior and posterior on @xmath can be calculated
according to

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

and hence one can determine that

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

Another very important property of the Kullback-Leibler divergence is
that it is always positive, due to Gibbs’ inequality which states that
for two continuous normalised distributions @xmath and @xmath , one has
³ ³ 3 One may also show this from Jensen’s inequality, due to the fact
that the logarithm is a concave function.

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

In order to gain some immediate insight into how @xmath is affected by
the shape of the prior and posterior distributions, let us compute its
value in the case where both distributions are 1-dimensional Gaussians,
with mean values @xmath and @xmath respectively, and with standard
deviations of @xmath and @xmath , respectively. Their distributions
should take the form

  -- -------- -------- -- --------
     @xmath   @xmath      (2.12)
     @xmath   @xmath      (2.13)
  -- -------- -------- -- --------

Defining @xmath , one obtains

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

where the first term accounts for the update in the preferred value and
can be understood as follows: if the change in the preferred value is
large compared to the uncertainty level of the prior, then non-trivial
information is gained and the value of @xmath is large. In contrast, the
other terms depend only on the ratio @xmath , and therefore yield a
contribution to @xmath which increases when @xmath decreases,
corresponding to improved measurements of @xmath .

Let us also define a quantity which we dub the ‘information density’
@xmath , which one can view as the information gained in each bin @xmath
of the parameter @xmath , such that

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

Contrary to @xmath , this quantity is parameterisation dependent, but it
indicates where information is mostly gained and lost. We shall use both
@xmath and @xmath in later chapters.

### 2.3 Bayesian model selection

Let us now consider that a higher-dimensional @xmath contains
information about an additional parameter @xmath (or many parameters)
that we do not want to study, one should marginalise out @xmath (or all
of the parameters)

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

where now the integration limits correspond to the domain of @xmath .
Marginalisation is a generic feature of probability distributions and
considering where it is present within Eq. ( 2.2 ) will yield us a tool
which is key for Bayesian model selection. In Eq. ( 2.7 ) we can use
Eq. ( 2.16 ) to marginalise out @xmath , leaving

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

which is often known as the marginal likelihood or the Bayesian evidence
[ 98 , 99 ] .

The Bayesian evidence is a full integration over the parameter space of
@xmath (or its analogue in an arbitrary number of dimensions), and hence
contains all of the marginal information about the fit of the model to
the data which is therefore reparameterisation-invariant. ⁴ ⁴ 4 Note
that this is obvious since @xmath has no explicit dependence on @xmath
since it has been integrated out. An equivalent statement is @xmath .
Motivated by this basic property of @xmath , we can use it in a Bayesian
equivalent to a classic maximum likelihood ratio test to compare two
models @xmath and @xmath

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

which is known as the Bayes factor. The benefit of using Eq. ( 2.18 ) to
compare between the relative fitting performance of models to data is
that it manifestly penalises against too much model structure. A very
simple example of this is to once again consider a Gaussian distribution
for the likelihood of the same form as Eq. ( 2.5 ), but with a mean set
to @xmath , and a prior constructed from a finite-domain Dirac comb

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

with @xmath denoting the number of delta functions, hence acting as a
crude metric for model structure. Notice also that the normalisation
factor of @xmath in Eq. ( 2.19 ) is necessary for the prior to be
normalised to @xmath . Using Eq. ( 2.17 ) one can show that the evidence
in this example becomes

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

Eq. ( 2.20 ) thus demonstrates how increasing the structure of a model,
i.e., increasing @xmath decreases @xmath , the evidence for model
decreases as a penalty for overfitting the data.

Before we move on to the next section, we shall mention here briefly
that, although there is no universally derivable threshold for the
Bayes’ factor @xmath to take the value of such that it indicates a
‘ruling-out’ of @xmath with respect to @xmath , a useful guideline is
provided by the Jeffreys threshold [ 98 , 100 ] . This essentially
suggests that @xmath is a reasonable criterion to use.

### 2.4 Choice of prior

In Sec. 2.1 we highlighted the importance of accurate computation for
the likelihood function @xmath for rigorous statistical inference. We
will now discuss how best to choose a prior distribution @xmath such
that the scientific question one seeks to answer through the inference
is well posed. Priors may be constructed from either subjective
theoretical prejudice (here described as ‘informative’) or derived using
general methodologies (here described as ‘non-informative’).

Taking the non-informative viewpoint, an optimal prior from the
perspective of the likelihood is the ‘Jeffreys prior’ [ 101 ] . This
prior is @xmath , where @xmath is the Fisher information matrix. @xmath
of a general distribution @xmath , equipped with a set of
hyperparameters @xmath , is defined as ⁵ ⁵ 5 Notice that Taylor
expanding either @xmath from Sec. 2.2 about their minimum values (
@xmath where @xmath ) with respect to the shape parameters in @xmath ,
we find that both quantities vanish at first order in the expansion
leaving terms @xmath .

  -- -- -- --------
           (2.21)
  -- -- -- --------

In the case of constructing the Jeffreys prior out of @xmath , one makes
the choice @xmath . The key property of this prior is that it is
invariant under a reparameterisation of the likelihood [ 101 ] , and
hence it may be used to motivate a choice of logarithmic prior for scale
parameters. Such a choice for scale parameters may also be motivated in
other ways, as we shall discuss below.

Continuing in our discussion of non-informative priors is a similar
notion to the eigenfunction of @xmath . Such priors are known as
‘conjugate priors’ which have the property that the family of
probability distribution of the posterior @xmath , computed through
Eq. ( 2.2 ), is ensured to be the same as @xmath up to a variation in
hyperparameters of that family [ 95 ] . For example, Eq. ( 2.4 )
demonstrates that a Gaussian prior with known @xmath is conjugate to a
Gaussian posterior distribution.

Symmetry can also be used to motivate a non-informative prior choice. If
a prior is invariant under location transformations

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

with a domain of @xmath , then it is known that the measure choice which
leaves the prior volume invariant will be @xmath which may be shown by
the solution to the corresponding differential equation. Similarly, if
the prior is invariant under scale transformations of the form

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

then the prior volume is left invariant if one chooses the logarithmic
prior measure @xmath . These are both very simple examples of Haar
measures [ 102 ] , which generalise this concept to measures which are
invariant under left and right actions from an arbitrary group @xmath .

In this thesis we will also make use of informative priors, which we
derive through theoretically-motivated calculations — see, e.g.,
Chapters 3 and 5 .

### 2.5 Bayesian experimental design

In Bayesian analysis, one can forecast a future observation @xmath ,
given the current data @xmath using the posterior distribution over
@xmath given @xmath . One achieves this by the following marginalisation

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

In the same vein, one may forecast any @xmath -dependent quantity, say
@xmath , by inserting it in place of @xmath in Eq. ( 2.24 ). The
quantity one thus constructs is an expectation value @xmath . If one now
identifies @xmath with a utility function [ 90 , 103 , 104 ] , which
attributes a value to each possible realisation forecast by the
posterior, then the expected performance of a given probabilistic
process will be given by

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

where @xmath can be, e.g., the information gain @xmath between the
current and future posteriors. Eq. ( 2.25 ) will be adapted to forecast
the performance of astronomical experiments in Chapter 6 . We shall
leave further development of these concepts until then.

## Chapter 3 Curvaton reheating

Abstract. In this chapter we will study the situation where inflation is
driven by a single scalar inflaton field, but an extra light (relative
to the inflationary Hubble scale) scalar field can also contribute to
the total amount of curvature perturbations. This field is essentially a
‘curvaton’ — which we introduced in Sec. 1.3.1 — and is assumed to be
subdominant during inflation but can store a substantial part of the
energy budget of the Universe during reheating. We demonstrate that when
an additional field exists, and contributes to the curvature
perturbation, it leads to a substantial gain in information about the
precise temperature of the Universe at reheating [ 105 ] .

### 3.1 Introduction

How inflation ends and is connected to the subsequent hot Big-Bang phase
through the reheating era is still poorly constrained. The main reason
is that at linear order, in absence of entropic perturbations, curvature
perturbations are preserved on large scales [ 106 , 34 ] , hence their
statistical properties at recombination time carry limited direct
information about the microphysics at play during the reheating epoch.

Nevertheless, the amount of expansion between the end of inflation and
the onset of the radiation epoch determines the amount of expansion
between the Hubble crossing time of the physical scales probed in the
CMB and the end of inflation [ 107 , 108 , 109 , 110 , 111 , 112 ] . As
a consequence, the kinematic properties of reheating set the time frame
during which the fluctuations probed in cosmological experiments emerge,
hence defining the location of the observational window along the
inflationary potential. If inflation is realised with a single
slowly-rolling field for instance, this effect can be used to extract
constraints on a certain combination of the averaged equation-of-state
parameter during reheating and the reheating temperature, the so-called
“reheating parameter”, yielding an information gain of about 1 bit on
the reheating history [ 113 , 114 ] .

Since the reheating parameter is related to quantities such as the
effective potential of the inflationary fields during reheating and the
couplings between these fields and their decay products, this provides
an indirect probe into the fundamental microphysical parameters of
reheating [ 115 ] . Deriving such a relationship for concrete reheating
models is therefore an important, although often laborious, task. Let us
also notice that since the dependence of inflationary predictions on the
reheating history is now of the same order as the accuracy of the data
itself, different prescriptions for the reheating dynamics give rise to
substantially different results regarding which inflationary models are
preferred by the data [ 113 , 116 ] . Therefore, improving our
understanding of reheating has become crucial to derive meaningful
constraints on inflation itself.

We will follow this line of research and study the situation where
inflation is driven by a single scalar inflaton field @xmath , but an
extra light (relative to the inflationary Hubble scale) scalar field
@xmath can also contribute to the total amount of curvature
perturbations. This additional field @xmath is assumed to be subdominant
during inflation but can store a substantial part of the energy budget
of the Universe during reheating. In the limit where it is entirely
responsible for the observed primordial curvature perturbations, the
class of models this describes is essentially the curvaton scenario
of Refs. [ 117 , 74 , 73 , 75 , 118 ] and Sec. 1.3.1 . Here however, we
address the generic setup where both @xmath and @xmath can a priori
contribute to curvature perturbations [ 119 , 120 , 121 , 122 ] . The
reasons why we focus on these scenarios are threefold. First, from a
theoretical perspective, most physical setups that have been proposed to
embed inflation contain extra scalar fields that can play a role either
during inflation or afterwards. This is notably the case in string
theory models where extra light scalar degrees of freedom are usually
considered [ 123 , 124 , 125 , 126 , 127 ] . Second, from an
observational point of view, these scenarios predict levels of
non-Gaussianities that may lie within the reach of the next generation
of cosmological surveys [ 128 , 129 , 130 , 131 ] . Their observational
status is therefore likely to evolve in the coming years, which is why
it is important to improve our understanding of these models. Third, at
the practical level, these scenarios are interesting since the reheating
parameter is an explicit function of the decay rates of both fields, the
mass of the light field @xmath and its vev at the end of inflation. This
means that the same parameters determine the direct imprint of @xmath on
the statistics of curvature perturbations and the reheating kinematic
effect on the location of the observational window along the inflaton
potential. The associated increased sensitivity of the data to these
parameters should allow us to better constrain them.

These scenarios have recently been brought into the full domain of
Bayesian analysis in Refs. [ 132 , 133 , 134 ] . In this chapter, we
make use of the Bayesian inference techniques developed in these works
to derive constraints on the inflationary energy scale and the reheating
temperatures, and quantify the gain in information about these
quantities from current observations.

In Sec. 3.2 , we present in greater details the scenarios at hand and
explain how information on reheating can be extracted using Bayesian
inference. In Sec. 3.3 , we provide our main results and analyse their
implications for the physics of reheating and the amount of information
that has been gained. In Sec. 3.4 , we extend the discussion by
considering the role played by the inflationary energy scale in plateau
potentials, the impact of gravitino overproduction bounds and the
constraints on decay rates. We present our conclusions in Sec. 3.5 and
then end the chapter with several appendices. In Appendix 3.A , we
present the Kullback-Leibler divergence as a tool to quantify
information gain. In Appendix 3.B , we present our results for
individual reheating scenarios. In Appendix 3.C finally, we discuss
information gain densities.

### 3.2 Method

The method we employ here combines the analytical work of
LABEL:Vennin:2015vfa with the numerical tools developed in Refs. [ 94 ,
36 , 134 ] . In this section, we describe its main aspects and explain
the use of Bayesian inference techniques and information gain
quantification to analyse constraints on the parameters of reheating.

#### 3.2.1 Curvaton and reheating

As explained in Sec. 3.1 , we study the case where inflation is driven
by a single field @xmath slowly rolling down its potential @xmath , and
an extra light scalar field @xmath (with mass @xmath smaller than the
inflationary Hubble scale) is present both during inflation and
reheating. We therefore consider potentials of the type given in Eq. (
1.99 ).

We remind the reader that this extra field @xmath is taken to be
subdominant at the level of the background energy density during the
whole inflationary epoch. Both fields are assumed to be slowly rolling
during inflation, and eventually decay into radiation fluids with decay
rates ¹ ¹ 1 Here, @xmath (respectively @xmath ) are effective values for
which assuming instantaneous decay at @xmath (respectively @xmath )
provides a good description of the full decay dynamics. respectively
denoted @xmath and @xmath , during reheating. While we require that
@xmath becomes massive at the end of inflation, we do not make any
assumption as to the ordering of the three events: @xmath becomes
massive, @xmath decays and @xmath decays. Nor do we restrict the epochs
during which @xmath can dominate the energy content of the Universe.
This leaves us with 10 possible cases (including situations where @xmath
drives a secondary phase of inflation [ 120 , 135 , 85 , 136 ] ),
depending on the vev of @xmath at the end of inflation @xmath . These
ten “reheating scenarios” are listed and detailed in
LABEL:Vennin:2015vfa but are sketched in Fig. 3.2 . The usual curvaton
scenario corresponds to case number 8 but one can see that a much wider
class of models is covered by the present analysis.

In this section, we also assume that all particles are in full thermal
equilibrium after @xmath and @xmath decay. Therefore, there are no
residual isocurvature modes [ 77 , 78 ] , that would otherwise give rise
to additional constraints. Such constraints depend on the specific
processes of decay and thermalisation [ 120 , 137 , 138 , 139 , 79 ] .
Thermal equilibrium also allows us to relate energy densities @xmath
contained in radiation fluids to temperatures through Eq. ( 1.97 ). When
this expression is evaluated at the onset of the Big-Bang radiation
epoch, it yields the “reheating temperature” @xmath . In reheating
scenarios 1, 2, 4 and 7 (see Fig. 3.2 ), this corresponds to the
temperature of the thermalised decay products of @xmath , while for
scenarios 3, 5, 6, 8, 9 and 10, this corresponds to the decay products
of @xmath . However, it can also happen that a transient radiation epoch
takes place during reheating (as in reheating scenarios 2, 5, 8 and 9),
in which case the energy density of the Universe at the beginning of
this first radiation phase is called “early reheating temperature” and
is noted @xmath . In reheating scenarios 5, 8 and 9, this corresponds to
the decay products of @xmath , while in scenario 2, this corresponds to
the decay products of @xmath .

In LABEL:Vennin:2015vfa , the @xmath formalism [ 140 , 141 , 142 , 143 ,
65 , 144 , 145 ] and the sudden decay approximation [ 81 , 82 ] were
employed to relate observables of the models considered here to
variations in the energy densities of both fields at the decay time of
the last field. This allows one to calculate all relevant physical
quantities by only keeping track of the background energy densities.
Analytical expressions have been derived for all @xmath reheating
scenarios, that have been implemented in the publicly available ASPIC
library [ 146 ] . For a given inflaton potential, and from the values of
@xmath , @xmath , @xmath and @xmath , this code returns the value of the
first three slow-roll parameters (or equivalently at second order in the
slow-roll approximation, of the scalar spectral index @xmath and its
running, and of the tensor-to-scalar ratio @xmath ) and of the
local-type non-Gaussianity parameter @xmath . In LABEL:Vennin:2015egh ,
this has been interfaced with the “effective likelihood via slow-roll
reparametrisation” of LABEL:Ringeval:2013lea , and Bayesian constraints
were derived for the models that we consider here. The results presented
in this chapter are obtained from this numerical pipeline, where the
Planck 2015 @xmath data are combined with the high- @xmath @xmath
likelihood and the low- @xmath temperature plus polarisation likelihood
(PlanckTT,TE,EE+lowTEB in the notations of LABEL:Aghanim:2015xee , see
table 1 there), together with the BICEP2-Keck/Planck likelihood
described in LABEL:Ade:2015tva .

An important result of LABEL:Vennin:2015egh is that the models favoured
by the data are of two types: either the inflaton has a “plateau
potential” (i.e. is a monotonically increasing function of @xmath that
asymptotes a constant positive value at infinity) and the reheating
scenario can be any of the 10 cases listed in Fig. 3.2 , or the inflaton
has a “quartic potential” (i.e. is proportional to @xmath ) and
reheating occurs in scenario 5 or 8. For this reason, we restrict the
following analysis to these two kinds of potential. As an example of a
plateau potential, we consider the one of Higgs inflation ( @xmath )

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

which also matches the Starobinsky model [ 23 ] (in Sec. 3.4.1 , another
plateau potential is studied, “Kähler moduli II inflation”, to
investigate the role played by the inflationary energy scale in plateau
models). The other potential we consider is the one of quartic inflation
( @xmath )

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

Here, “ @xmath ” and “ @xmath ” refer to the terminology of
LABEL:Martin:2013tda and stand for the purely single-field versions of
these models. When the prefix “ @xmath ” is appended (for “Massive
Curvaton”), the index following the prefix refers to the reheating
scenario number. For example, @xmath corresponds to the case where the
inflaton potential is of the quartic type, and where the reheating
scenario is of the fifth kind.

In Fig. 3.1 , some of the results of LABEL:Vennin:2015egh have been
summarised for the @xmath models (blue disks, where the white circled
disk stands for the single-field version of the model and the other
disks represent the @xmath reheating scenarios) and the @xmath models
(red disks). On the horizontal axis, the Bayesian evidence is displayed.
One can see that for Higgs inflation, adding a light scalar field
slightly decreases the Bayesian evidence of the model but at a level
which is inconclusive for most reheating scenarios (and never more than
weakly disfavoured). For quartic inflation, the single-field version of
the model is strongly disfavoured and so are most of the reheating
scenarios when a light scalar field is added. Two exceptions are to be
noted however, namely cases 5 and 8, which lie in the favoured region.
On the vertical axis, the information gained on @xmath is displayed, as
will be defined and analysed in Sec. 3.3.2 .

#### 3.2.2 Inverse problem for reheating parameters

As mentioned in Sec. 3.1 , a specific feature of the models considered
in this section is that the same parameters determine the expansion
history during reheating as well as the contribution from the additional
light scalar field to the total curvature perturbations. This is
responsible for a high level of interdependency between these
parameters, that plays an important role in shaping the constraints we
obtain in Sec. 3.3 . For this reason, it is important to first better
understand their origin.

The number of @xmath -folds @xmath elapsed between the Hubble exit time
of the CMB pivot scale @xmath and the end of inflation is given by [ 107
, 108 , 109 ]

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

which can be calculated by stitching together separate epochs with known
equations of state. In this expression, @xmath is the averaged equation
of state parameter during reheating, @xmath is the energy density of the
Universe at the end of reheating, @xmath is the energy density
calculated @xmath @xmath -folds before the end of inflation (all the
quantities with a subscript “*” are evaluated at that time), @xmath is
the present value of the scale factor, and @xmath is the the energy
density of radiation today rescaled by the number of relativistic
degrees of freedom. Taking the pivot scale @xmath to be @xmath and
@xmath to its measured value, the last term is @xmath .

Let us first illustrate the use of Eq. ( 3.3 ) to constrain reheating in
the simple case of single-field quartic inflation, where the potential
is given by Eq. ( 3.2 ) and there is no additional light scalar field
@xmath . As mentioned above, we require that @xmath becomes massive at
the end of inflation, so that in this case, one simply has @xmath .
Inflation ends by slow-roll violation at @xmath , so that @xmath . On
the other hand, the slow-roll trajectory is given by @xmath , so that
@xmath . For this reason, @xmath also appears in the right hand side of
Eq. ( 3.3 ) and this formula should be viewed as an implicit equation
for @xmath . In fact, this is all the more true since @xmath also
implicitly depends on @xmath . Indeed, this mass scale can be fixed by
requiring that the correct scalar power spectrum amplitude @xmath is
obtained (where @xmath has been evaluated at leading order in slow roll
in quartic inflation). Making use of Eq. ( 1.97 ) to express @xmath in
terms of @xmath , one then obtains

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (3.4)
  -- -------- -------- -- -------

This equation can be inverted using the @xmath branch of the Lambert
function @xmath , and one finds

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.5)
              @xmath               (3.6)
              @xmath   @xmath      (3.7)
  -- -------- -------- -------- -- -------

where in the second equality, we have used @xmath [ 20 ] , @xmath (which
is calculated from the SM effective degrees of freedom above the EW
scale ² ² 2 There are 28 Bosonic (2 photon helicities, 3 massive gauge
Bosons each with 3 spins, 1 Higgs Boson and 8 gluons each with 2 spins)
and 90 Fermionic (12 quarks each with 3 colours and 2 spins, 6 charged
leptons each with 2 spins and 6 neutrinos) degrees of freedom, giving
@xmath . — see Fig. 1.2 ) and the value given above for @xmath , and the
last expression corresponds to the limit @xmath . This makes explicit
the dependence of @xmath on the reheating temperature @xmath . Since
observable quantities such as the scalar spectral index @xmath or the
tensor-to-scalar ratio @xmath depend on @xmath through @xmath , this
means that the reheating temperature is directly constrained by CMB
measurements,

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

From these expressions, it is clear that observational constraints on
@xmath and @xmath directly translate into constraints on the reheating
temperature @xmath . As this simple calculation shows, this is the
consequence of many interdependencies between the parameters of the
problem.

When a light scalar field is added, these dependencies are substantially
more complicated. For instance, the averaged equation of state parameter
@xmath does not vanish anymore but is a non-trivial function of @xmath ,
@xmath , @xmath , @xmath and @xmath , that is different for each of the
10 reheating scenarios of Fig. 3.2 (this function is given in Appendix B
of LABEL:Vennin:2015vfa ). Then, the mass scale of the potential @xmath
is not simply related to the amplitude of the scalar power spectrum
since @xmath also receives a contribution from the light scalar field
@xmath , and this contribution depends on @xmath , @xmath , @xmath ,
@xmath and @xmath . As a result, the dependency of observable quantities
on these parameters is much more complicated than the one obtained for a
purely single-field model, and the constraints one can infer on the
reheating temperatures for instance are a priori much less trivial. The
goal of this chapter is precisely to derive these constraints.

#### 3.2.3 Bayesian inference and prior choices

Starting from the data sets @xmath mentioned in Sec. 3.2.1 , our goal is
to derive observational constraints on the energy scale of inflation
@xmath and the reheating temperatures @xmath and @xmath . This can be
done using Bayesian inference techniques [ 86 , 87 , 88 , 149 , 150 ] .
Following Eq. ( 2.7 ), we assume a model @xmath , where the posterior
probability @xmath of its parameters @xmath (labeled by @xmath ) is
expressed as

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

In this expression, @xmath is the likelihood and represents the
probability of observing the data @xmath assuming the model @xmath is
true and @xmath are the actual values of its parameters, @xmath is the
prior distribution on the parameters @xmath , and @xmath is a
normalisation constant called the Bayesian evidence, which using Eq. (
2.17 ), is

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

The Bayesian evidence of the models considered in this section have been
computed in LABEL:Vennin:2015vfa and here, we are interested in the
posterior distributions @xmath for the energy scale of inflation and the
reheating temperatures. Notice that these quantities are not necessarily
“fundamental” parameters that we start from but can be derived from
them. For example, as stressed in Sec. 3.2.2 , @xmath is a complicated
function of the parameters @xmath characterising the inflaton potential,
@xmath , @xmath , @xmath and @xmath . In this case, for a derived
parameter @xmath that can be expressed as @xmath , one marginalises the
distribution obtained in Eq. ( 3.9 ) according to Eq. ( 2.16 ) such that

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

In this method, the priors are important quantities as they encode
physical information one has “a priori” on the values of the parameters
that describe the models. For the parameters of the potential @xmath ,
we use the same priors as the ones proposed in LABEL:Martin:2013nzq ,
based on LABEL:Martin:2013tda . Because the extra field @xmath is
supposed to be still light at the end of inflation, its mass @xmath must
be smaller than the Hubble scale at the end of inflation, @xmath . The
same condition applies to the two decay rates, @xmath , since both
fields decay after inflation. On the other hand, we want the Universe to
have fully reheated before Big Bang Nucleosynthesis (BBN), which means
that the two decay rates are also bounded from below by @xmath . The
same lower bound applies to @xmath since, assuming perturbative decay,
@xmath . Between these two values, the order of magnitude of @xmath and
of the two decay rates is a priori unknown, which is why a
logarithmically flat prior (or “Jeffreys prior”) is chosen:

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

The relative orderings identified in Fig. 3.2 then determine which of
the 10 reheating scenarios is realised for a given set of parameters.
For @xmath , two different priors are considered. The first one, denoted
@xmath , is logarithmic and consists in assuming that the order of
magnitude of @xmath is unknown,

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

Here, @xmath and @xmath are the boundary values given for each reheating
case in Fig. 3.2 . For cases 1, 4 and 7, the lower bound is taken to be
@xmath , corresponding to the minimal quantum dispersion of the field,
and for cases 3, 6 and 10, the upper bound @xmath is set by the
condition that the extra phase of inflation driven by @xmath is
sufficiently short so that the pivot scale @xmath exits the Hubble
radius during the first phase of inflation, driven by @xmath . The
second prior relies on the equilibrium distribution of a light spectator
field in a Sitter space-time with Hubble scale @xmath [ 140 , 151 ] ,

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

which is the same as Eq. ( 1.94 ) as will be referred to as the
“stochastic” prior on @xmath . A few words of caution regarding the use
of this prior are in order here. In practice, the timescale of
equilibration can be very large for small values of @xmath , and the
initial conditions for spectator fields are not necessarily erased
during inflation [ 151 ] . Also note that in non-plateau models, the
time variation of @xmath , even in the slow-roll regime, is such that
the distribution ( 3.14 ) is not an equilibrium solution anymore, even
approximatively. Moreover, since @xmath depends on @xmath itself (see
the discussion of Sec. 3.2.2 ), Eq. ( 3.14 ) is not a simple Gaussian
function of @xmath . This is why the use of Eq. ( 3.14 ) should only be
seen as a way to study the effects of picking a specific preferred scale
for @xmath . In practice, we therefore implement this prior by simply
rejecting realisations for which the argument of the exponential
function in Eq. ( 3.14 ) is smaller than @xmath or larger than @xmath
(we have checked that when changing these arbitrary values to, say,
@xmath and @xmath , very similar results are obtained). In what follows,
the inclusion of these two priors for @xmath allow us to examine prior
dependency of the reheating constraints.

### 3.3 Results and analysis

Let us now present our main results. In Sec. 3.3.1 , we display and
analyse the constraints obtained on the energy scale of inflation @xmath
and the two reheating temperatures @xmath and @xmath . In Sec. 3.3.2 ,
we quantify how much information has been gained about these quantities.

#### 3.3.1 Constraints on inflationary energy and reheating temperatures

The posteriors on @xmath , @xmath and @xmath for all 10 individual
reheating scenarios (see Fig. 3.2 ) are given in Appendix 3.B . In this
section, for the sake of conciseness, as well as to allow direct
comparison with purely single-field models, only the constraints
averaged over the reheating scenarios are shown. Such distributions can
be computed in the following manner. For the purpose of illustration,
let us consider two toy models @xmath and @xmath , that both depend on
the same parameter @xmath . In model @xmath , @xmath is assumed to lie
within the range @xmath with a flat prior distribution, while in model
@xmath , @xmath lies within the range @xmath with a flat prior
distribution too. The model @xmath is defined to be the “union” of
@xmath and @xmath , where @xmath lies in @xmath with a flat prior
distribution, so that @xmath and @xmath are simply sub-models of @xmath
(in the same manner as all 10 reheating scenarios @xmath , for @xmath
and some inflaton potential @xmath , are submodels of @xmath ). From
Eq. ( 3.9 ), one can see that

  -- -------- -------- -- --------
     @xmath               
              @xmath      (3.15)
  -- -------- -------- -- --------

In this expression, the Bayesian evidence of @xmath can be evaluated
with Eq. ( 3.10 ), which gives rise to

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

By combining Eqs. ( 3.15 ) and ( 3.16 ), the posterior distribution of
the parameter @xmath within model @xmath can be written as

  -- -------- -- -- --------
     @xmath         
                    (3.17)
  -- -------- -- -- --------

In other words, it is given by the averaged sum of the posterior
distributions within each sub-model, weighted by the product of the
Bayesian evidence and the fractional prior volume of the sub-models.
These fractional prior volumes can be viewed as priors for the
sub-models themselves. In particular, one can check that Eq. ( 3.17 ) is
correctly normalised.

The above formula can easily be generalised for arbitrary priors and
arbitrary number of sub-models. In practice, the Bayesian evidence and
fractional prior volumes of all 10 reheating scenarios are given in
LABEL:Vennin:2015egh for the inflaton potentials considered here, and we
compute posterior distributions averaged over reheating scenarios
adopting this approach. They correspond to the constraints one would
obtain starting from the priors ( 3.12 ), without the ordering
conditions of Fig. 3.2 , and simply computing observables according to
the reheating scenario in which each sampled point falls.

##### Energy density at the end of inflation

In Fig. 3.3 , the posterior distributions on @xmath , the energy density
at the end of inflation, is displayed. If the inflaton potential is of
the plateau type (Higgs inflation, top panels), the difference between
the purely single-field result and the one with an extra light scalar
field, averaged over all @xmath reheating scenarios, is very small. One
can check that this is also the case at the level of the individual
posterior distributions for the different reheating scenarios in Fig.
3.8 of Appendix 3.B.1 . This is consistent with the generic robustness
of plateau models under the introduction of extra light scalar fields
noticed in LABEL:Vennin:2015egh . In particular, the range of values
allowed for @xmath is remarkably narrow. The stochastic prior tends to
favour slightly larger values of the energy density. This is because
this prior samples larger values of @xmath , hence larger contributions
of @xmath to the total curvature power spectrum [ 134 ] , hence bluer
values of @xmath . This effect can be compensated for by increasing
@xmath , hence @xmath [see Eq. ( 3.3 )], which decreases @xmath back
into the data’s sweet spot [ 133 ] .

The situation is quite different for the quartic potential (bottom
panels). In this case, the single-field version of the model provides a
very poor fit to the data due to values of the tensor-to-scalar ratio
@xmath that are too large. When a light scalar field is introduced,
@xmath is typically decreased, and so is @xmath . In scenarios where the
amount of non-Gaussianities remains small, i.e. scenarios 5 and 8, this
explains why lower values of @xmath are favoured, see Fig. 3.8 . In
other cases, @xmath increases when @xmath decreases, and the trade-off
between both effects leads to bimodal posterior distributions. Since
scenarios 5 and 8 are favoured however (see Fig. 3.1 ), the clear
preference is for lower values of @xmath . If a stochastic prior on
@xmath is used, the maximum of the distribution is switched back to the
single-field prediction, but all reheating scenarios are moderately or
strongly disfavoured in this case anyway [ 134 ] .

##### Reheating temperature

In Fig. 3.4 , the posterior distributions on the reheating temperature
@xmath are displayed. In the single-field version of the plateau model
of Higgs inflation, the reheating temperature is rather unconstrained.
This is because all reheating temperatures can accommodate the data
equally well for this model (at least when @xmath , see
LABEL:Martin:2016oyk otherwise). When a light scalar field is introduced
however, a slight preference is found for lower reheating temperatures.
Looking at Fig. 3.9 of Appendix 3.B.2 , one can see that in the case of
the logarithmic prior on @xmath , this trend is mostly due to reheating
scenarios 1, 2, 5, 6, 8 and 9, for which @xmath is bounded from above.
For scenarios 3, 4, and 10 however, the distributions have a maximum
around the scale @xmath , and for scenario 7, larger values of @xmath
are even preferred. A similar dichotomy is observed with the stochastic
prior on @xmath where scenarios 1, 2, 5 and 6 prefer smaller values of
@xmath , scenarios 3, 7, 9 and 10 prefer larger values of @xmath , and
scenarios 4 and 8 leave @xmath unconstrained. When averaging over the 10
reheating scenarios, the resulting distributions show preference for
lower values of @xmath , but because of these opposite individual
behaviours, the constraint is not very strong.

For the single-field version of quartic inflation, larger values of the
reheating temperature are preferred since they lead to smaller values
for the tensor-to-scalar ratio @xmath as well as larger values of @xmath
that are in better agreement with the data, as shown explicitly in Eq. (
3.8 ). When a light scalar field is introduced, one can note in Fig. 3.9
that the same variety of individual behaviours of the 10 reheating
scenarios is obtained as with Higgs inflation. However, since scenarios
5 and 8 strongly dominate the averaged posterior distribution due to
their large Bayesian evidence, and since they both show preference for
lower values of @xmath , better constraints are obtained from the
averaged posterior distribution than with a plateau potential. In
practice, an upper bound on the reheating temperature can be derived,

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

This value has been obtained with the logarithmic prior @xmath on @xmath
. With the stochastic prior, the constraint would be much weaker, but
one should remember that this prior is not well motivated in that case
and that @xmath is strongly disfavoured [ 134 ] when @xmath is used
anyway.

##### Early reheating temperature

The weighted posterior distributions on the early reheating temperature
@xmath are displayed as the solid red lines in Fig. 3.4 . Obviously,
these distributions are averaged over the scenarios for which @xmath is
defined only, that is to say cases 2, 5, 8 and 9, and the individual
posteriors are given in Fig. 3.10 in Appendix 3.B.3 for these scenarios.
Contrary to the reheating temperature discussed in Sec. 3.3.1 , one can
see that larger values are preferred and that lower bounds on @xmath can
be obtained,

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.19)
  -- -------- -------- -- --------

with a logarithmic flat prior on @xmath . In this case, from Fig. 3.10 ,
one can see that the constraint mostly comes from scenarios 8 and 9,
while the posterior distribution for scenarios 2 and 5 has a maximum
around @xmath for Higgs inflation and @xmath for quartic inflation. If
one uses the stochastic prior instead, one obtains

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.20)
  -- -------- -------- -- --------

In this case, one can check in Fig. 3.10 that all reheating scenarios
favour large values for @xmath .

#### 3.3.2 Information gain

In Sec. 3.3.1 , the posterior distributions on @xmath , @xmath and
@xmath have been displayed and it was shown that, compared to
single-field models, different constraints are obtained when a light
scalar field is included. In Sec. 3.2.2 , we explained that both
situations are indeed qualitatively different, since in the latter case
the same parameters define both the contribution from @xmath to the
curvature power spectrum and the kinematic properties of reheating that
determine the location of the observational window along the inflaton
potential. This leads to an increased interdependence between these
parameters and observations, which yields more information about these
quantities. This is why in this section, we quantify the information
gain on reheating parameters to quantitatively describe this effect.

A first remark is that since the induced priors on @xmath , @xmath and
@xmath are not logarithmically flat, information gain cannot be simply
assessed by measuring how the distributions of Sec. 3.3.1 are peaked, or
more generally deviate from a flat profile. For example, in Fig. 3.5 ,
the induced priors ³ ³ 3 In practice, induced priors are reconstructed
using a fiducial, constant likelihood in our Bayesian inference code (so
that the posteriors we extract correspond to the actual induced priors),
where only the value of @xmath is used to normalise the mass scale
@xmath appearing in the inflaton potentials. This is because @xmath is
so accurately measured that it effectively reduces the support of the
posterior to a hypersurface in parameter space, and distributions are
considered along this hypersurface only. on @xmath are displayed in the
case of Higgs inflation, for the single-field model (dashed blue line),
for the 10 reheating scenarios (coloured solid lines), and when averaged
over all reheating scenarios (solid blue line). The prior is exactly
flat in the single-field case since @xmath is directly related to @xmath
in this case, over which the logarithmically flat prior @xmath is
chosen. When a light scalar field is added however, @xmath is either
related to @xmath (in cases 1, 2, 4 and 7) or to @xmath (in cases 3, 5,
6, 8, 9 and 10). Since the ordering conditions of Fig. 3.2 are further
imposed on top of the logarithmically flat priors for these quantities,
the non-flat induced priors of Fig. 3.5 are obtained.

This is why the posterior distributions are not sufficient to estimate
the information gain, but one needs to compute the relative information
between the prior and posterior distributions. This can be done using
the Kullback-Leibler divergence [ 89 ] @xmath between the prior @xmath
and the posterior @xmath of some parameter @xmath (here, for display
convenience, the notations of Sec. 3.2.3 are simplified, @xmath , etc.),
as introduced in Sec. 2.2 . ⁴ ⁴ 4 The application of @xmath here between
the derived marginalised priors and posteriors over the reheating
temperatures and energy densities can be contrasted with the more
conventional application of @xmath over the entire space of parameters.
In this latter application, the reparameterisation invariance becomes
manifest.

In this section, only the integrated Kullback-Leibler divergences are
discussed. The numbers obtained for all models previously discussed are
given in table 3.2 in Appendix 3.C . In table 3.1 , the results are
summarised and the divergence obtained in the single-field versions of
the models are compared with the ones obtained from the averaged
distributions over all 10 reheating scenarios. The averaged posterior
distribution has been defined in Sec. 3.3.1 , and the averaged prior
distribution is simply the averaged sum of all prior distributions
weighted by the fractional prior volume of the sub-models. Let us note
that this divergence cannot be obtained by a simple weighted summation
over each individual value. For instance, in table 3.2 , one can check
that the divergence between averaged distribution can be larger than all
individual divergences, as further discussed in Sec. 3.3.2 .

##### Energy density at the end of inflation

In table 3.1 , one can see that more than one bit of information is
gained on @xmath for the two single-field models considered here, @xmath
and @xmath . The main reason is that, since these single-field
potentials have no free parameters (apart from the overall mass scale
@xmath ), as shown in Sec. 3.2.2 , @xmath is entirely fixed by @xmath ,
up to a small dependence on @xmath . In this case, the support of both
the priors and the posteriors on @xmath are very narrow, and even a
small difference between their preferred values is enough to yield a
large Kullback-Leibler divergence, see the discussion around Eq. ( 2.14
) in Appendix 3.A . However, as soon as another free parameter is
introduced in the inflaton potential for instance, this effect
disappears as will be explicitly checked in Sec. 3.4.1 . Therefore,
these large values of @xmath for @xmath and @xmath are mostly a
consequence of the very sharp measurement on @xmath .

When a light scalar field is added, a few tenths of bits of information
on @xmath are typically gained with the plateau potential of Higgs
inflation. This number can be larger for individual reheating scenarios,
see for instance @xmath and @xmath in table 3.2 where, depending on the
prior chosen for @xmath , one gains between one and two bits of
information. The situation is particularly interesting for quartic
inflation, where the by far favoured reheating scenarios are 5 and 8
(see Fig. 3.1 ). For these models, one typically obtains one bit of
information with the logarithmic prior on @xmath and @xmath bits with
the stochastic prior, see table 3.2 . This is because, as explained in
Sec. 3.3.1 , the data favours regions of parameter space where @xmath
provides the main contribution to curvature perturbations and @xmath is
smaller than its single-field counterpart, yielding non-trivial
information about the energy density at the end of inflation. The
divergence between the averaged distributions displayed in table 3.1 is
even larger, the additional information coming from the update in the
relative degrees of belief between the different reheating scenarios,
namely the fact that the data strongly favours scenarios 5 and 8.

##### Reheating temperature

For the reheating temperature, very little information is gained with
the single-field versions of the models. One may wonder whether this is
consistent with LABEL:Martin:2016oyk , where it is found that almost one
bit of information is obtained on the reheating parameter of
single-field models, on average. This is in fact the case since, in
LABEL:Martin:2016oyk , @xmath is allowed to vary between @xmath and
@xmath . In Eq. ( 3.3 ), one can see that the dependence of @xmath on
@xmath is maximal when @xmath [that is to say, the multiplying factor
@xmath between @xmath and @xmath is maximal when @xmath ], which
explains why most of the information measured in LABEL:Martin:2016oyk is
gained close to @xmath . In the present section however, one imposes
@xmath in the single-field models, to allow fair comparison with the
situation where an extra light scalar field is introduced where it is
assumed that the inflaton is massive between the end of inflation and
its decay.

For the plateau potential of Higgs inflation, although more information
on @xmath is gained once an extra light scalar field is introduced, the
Kullback-Leibler divergences remain small. With a quartic potential
however, @xmath bits of information are obtained with the logarithmic
prior on @xmath , which is a sizeable value. Looking at table 3.2 , one
can see that it is in fact much more than any individual reheating
scenario for the quartic potential. This means that these @xmath bits of
information mostly correspond to the selection of scenarios 5 and 8
amongst all 10 possible reheating scenarios, similarly to what was
discussed in Sec. 3.3.2 for @xmath .

The values of the individual Kullback-Leibler divergences on @xmath are
also shown in Fig. 3.1 , together with the Bayesian evidence of the
models they correspond to.

##### Early reheating temperature

The early reheating temperature is defined only for scenarios 2, 5, 8
and 9. One obtains small information gains with plateau potentials, and
depending on the prior one uses on @xmath , @xmath or @xmath bits with
the quartic potential.

In summary, one finds that more information about reheating can be
extracted from the data in models where an extra light scalar field is
added than in purely single-field setups. In particular, the
Kullback-Leibler divergences on the reheating temperatures can be
substantial if the inflaton potential is quartic, and are more modest
for a plateau potential.

### 3.4 Discussion

In Sec. 3.3 , constraints were derived on the energy scale of inflation,
the reheating temperature and the early reheating temperature. In this
section, we extend the discussion in a few directions to investigate the
physical implications of the constraints we obtained.

#### 3.4.1 Inflationary energy scale in plateau models

As explained in Sec. 3.1 , the Bayesian model comparison program applied
to the scenarios discussed in the present chapter show that [ 134 ] the
models favoured by the data are of two types: either plateau potentials,
in any of the 10 reheating scenarios, or quartic potentials in scenarios
5 and 8. Quartic potentials are rather uniquely defined but several
versions of plateau inflation have been proposed in the literature. So
far, the potential of Higgs inflation (or equivalently the Starobinsky
model) has been used to study these models. As noticed in Fig. 3.3 and
further commented on in Sec. 3.3.2 , this leads to very sharp
constraints on @xmath , which, in the absence of any other free
parameter in the potential, is mostly fixed by @xmath . However, plateau
potentials exist where inflation can be realised at different energies.
To study how the conclusions drawn above are dependent on the specific
shape (and energy scale) of the plateau potential considered, in this
section, we include another plateau potential in our analysis, Kähler
moduli II inflation (KMIII in the terminology of LABEL:Martin:2013tda ),

  -- -------- -------- -- -- --------
     @xmath   @xmath         (3.21)
  -- -------- -------- -- -- --------

The posterior constraints on @xmath , @xmath and @xmath are shown in
Fig. 3.6 , and the individual reheating scenarios are displayed in
Appendix 3.B .

Compared to Fig. 3.3 , one can see that inflation proceeds at lower
energy, with a wider range of allowed energy scales due to the presence
of the free parameters @xmath and @xmath in Eq. ( 3.21 ). This leads to
a much smaller Kullback-Leibler divergence on @xmath than in the case of
single-field Higgs or quartic inflation, see table 3.2 . However, one
still notices that the @xmath posteriors when an extra light scalar
field is added are very close to the single-field constraints. For the
reheating temperatures, the same remarks apply as in Secs. 3.3.1 and
3.3.1 for Higgs inflation. In particular, small reheating temperatures
and large early reheating temperatures are preferred. Therefore, apart
from the large value of @xmath for @xmath , the results obtained above
for Higgs inflation seem to characterise plateau potentials in general.

#### 3.4.2 Gravitino overproduction bounds

Reheating affects cosmology in different ways. First, as explained in
Sec. 3.2.2 , it contributes to the expansion history through its
averaged equation-of-state parameter and its energy density at
completion. This is the effect we used to constrain reheating in
single-field models. Second, it may produce additional features (such as
gravitational waves, magnetic fields, topological defects, baryon
asymmetries or dark matter, etc.), and enhance the contribution from
light scalar fields (that are otherwise spectator fields during
inflation) to curvature perturbations. This is the case of the scenarios
considered in the present section and this additional effect is the one
we have used to constrain reheating in these setups. Third, it affects
the subsequent thermal history of the Universe, since it determines the
temperature at the onset of the radiation dominated epoch.

To illustrate how this last effect can be important to constrain
reheating, in this section, we consider gravitinos, the gauge fermion
supersymmetric partners of the graviton of supergravity theories.
Gravitinos are produced from scatterings in the hot plasma during
reheating, and their abundance is directly related to the magnitude of
the reheating temperature [ 152 ] . Their lifetime depends on their mass
@xmath , and if they survive long enough, their decay products can
produce spectral distortions of the CMB. Combining current constraints
on CMB spectral distortions and BBN, upper bounds can be derived on
@xmath . In LABEL:Dimastrogiovanni:2015wvk , it is found that, with
@xmath , one typically obtains the most stringent constraint @xmath . ⁵
⁵ 5 In full generality, combining these constraints in a rigorous
analysis would require deriving a likelihood function that takes into
account correlations between this data on smaller scale fluctuations
with those on the larger scale fluctuations from CMB experiments. The
constraint also assumes that local supersymmetry is indeed the correct
extension to the standard model of particles.

This value is shown in Fig. 3.4 and the bottom panels of Fig. 3.6 where
the posterior distributions on @xmath and @xmath are displayed. One can
see that it excludes a large set of possible temperatures. However,
scenarios where an extra light scalar field is added seem to more easily
evade the gravitino overproduction bound than their single-field
counterpart. For instance, in quartic inflation with an additional light
field, the reheating temperature is typically smaller than @xmath [see
the bottom left panel of Fig. 3.4 and Eq. ( 3.18 )], which is not the
case of the single-field versions of Higgs inflation, quartic inflation
or even Kähler moduli III inflation in Fig. 3.6 . On the other hand,
since large early reheating temperatures are preferred in general, the
gravitino problem might be worsened if gravitinos are generated from the
decay products of the first decaying field in scenarios 2, 5, 8 and 9.

Interestingly, this also shows that if gravitinos exist, they provide a
powerful indirect way to further constrain the models discussed in this
section. In particular, gravitino production bounds seem to yield less
additional constraints for quartic models than for plateau models (with
an extra light scalar field in both cases). If they were explicitly
included in the set of observations, they would therefore probably lead
to a slight preference of the former against the later.

#### 3.4.3 Decay mediation scale

So far, the decay rate of the additional scalar field @xmath , @xmath ,
and its mass @xmath , have been assumed to be independent (up to the
ordering conditions of Fig. 3.2 ). However, these scales may be related
by the physics of the decay of @xmath , and in this section we study the
implications of the results we obtained on such processes. More
specifically, we consider the case where spontaneous decay of @xmath by
dimension @xmath operators is mediated by some scale @xmath . The decay
rate and the mass are then given by Eq. ( 1.96 ) with @xmath replaced by
the new scale such that

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

Let us study which values of @xmath are typically predicted by the
scenarios considered in this section. In Fig. 3.7 , the averaged (over
reheating scenarios) posterior distributions for @xmath are displayed.
For electroweak suppressed decay for instance, one should have @xmath .
Although such values are well within the distributions when a
logarithmically flat prior on @xmath is used, higher mediation scales
are typically preferred, which is in agreement with the standard
curvaton picture where gravitationally mediated decay [ 72 ] is assumed.

One can also see that the large-field quartic models favour slightly
higher mediation scales than the plateau potential of Higgs inflation
(that has a very similar posterior on @xmath as Kähler moduli II
inflation introduced in Sec. 3.4.1 , which is why this other plateau
potential is not displayed here). This is due to the fact that the most
likely scenarios for the quartic potential, cases 5 and 8, yield large
values compared to the other scenarios, while for plateau potentials all
reheating cases contribute to the distributions plotted in Fig. 3.7 .
For this reason, individual cases 5 and 8 are also displayed (green and
red dashed lines respectively) for the quartic potential in Fig. 3.7 .
Interestingly, while these two scenarios are indistinguishable with
respect to all criteria discussed so far, they give slightly different
preferred values for @xmath , which suggests that requiring specific
mediated decay scales may be a way to distinguish between these cases.

When the stochastic prior on @xmath is used, one notices that mediated
decay cannot happen for @xmath below @xmath . This is in sharp contrast
with the result obtained with a logarithmically flat prior on @xmath and
can be understood as follows. When @xmath is super-Planckian, @xmath
drives a second phase of inflation (cases 6, 9 and 10 in Fig. 3.2 ), the
duration of which is roughly given by @xmath in numbers of @xmath
-folds. Therefore, @xmath cannot be much larger than, say, @xmath .
Therefore the stochastic prior on @xmath , which implies that @xmath
[see Eq. ( 3.14 )], yields a lower bound on @xmath , that does not exist
when a logarithmically flat prior on @xmath is used. This explains why
higher values of @xmath , hence of @xmath , are obtained with the
stochastic prior.

### 3.5 Conclusion

In this section, we have presented the first systematic observational
constraints on reheating in scenarios where inflation is driven by a
single scalar inflaton field @xmath , but an extra light scalar field
@xmath can also contribute to the total amount of curvature
perturbations. Following the results of LABEL:Vennin:2015egh , the
analysis was performed in the two classes of models that are favoured by
the data, where the inflationary potential is either of the plateau or
the quartic type.

Bayesian inference techniques were employed to derive posterior
constraints on the energy density at the end of inflation @xmath , and
the temperature of the Universe @xmath (and @xmath ) at the onset of the
radiation dominated epoch(s). If inflation is realised with a plateau
potential, it was found that the constraints on @xmath are scarcely
altered by the introduction of a light scalar field (compared to the
purely single-field case), in agreement with the strong robustness of
these models under the introduction of an additional scalar field noted
in LABEL:Vennin:2015egh . For a quartic inflationary potential however,
it was found that lower values of @xmath are favoured with an extra
light scalar field. Indeed, quartic inflation predicts a value of the
tensor-to-scalar ratio that is not too large only when the extra field
provides the dominant contribution to curvature perturbations, in which
case @xmath is smaller than in the single-field scenario.

For the reheating temperature, plateau potentials yield constraints on
@xmath that depend on the reheating scenario (these scenarios are listed
in Fig. 3.2 and the constraints are given in Fig. 3.9 ). For quartic
inflation, the only favoured reheating scenarios are 5 and 8, and both
show a preference for lower reheating temperatures than with the
single-field counterpart of the model. When a logarithmically flat prior
on the vev of the extra light field at the end of inflation is used, one
obtains the averaged @xmath upper bound @xmath . In reheating scenarios
2, 5, 8 and 9, the Universe undergoes a transient early radiation
dominated epoch during a two-stage reheating process and the constraints
on the temperature at its onset, @xmath , were also derived. Contrary to
@xmath , lower bounds can be derived on @xmath , typically larger than
@xmath for a plateau potential and larger than @xmath for the quartic
potential.

In general, it was observed that tighter constraints on reheating are
derived with an additional light scalar field than without, in agreement
with the results of LABEL:Vennin:2015egh where Bayesian complexity was
used to quantify the number of unconstrained parameters. Indeed, when
the extra field is present, the same parameters define both its
contribution to curvature perturbations and to the expansion history of
reheating that determines the location of the observational window along
the inflationary potential. More information about reheating can
therefore be gained in scenarios with an additional scalar field,
compared to the single-field case where only the later effect allows one
to constrain reheating from observations. This information gain was
quantified by computing the Kullback-Leibler divergence between the
prior and posterior distributions of @xmath , @xmath and @xmath . Even
if the information gain remains modest when the inflationary potential
is of the plateau type, it becomes substantial in quartic inflation
(where, for instance, more than 3 bits of information are gained on the
energy density at the end of inflation).

Since the process of reheating determines the temperature of the
Universe at the onset of the radiation dominated epoch, it affects its
subsequent thermal history. The constraints we derived thus have
implications for post-inflationary physics. For instance, we have
considered gravitino overproduction bounds and shown that since models
with an additional scalar field predict lower reheating temperatures,
they evade those bounds more easily than their single-field counterpart.
This is particularly true if the inflationary potential is of the
quartic type, so that if gravitino bounds were explicitly included in
the set of observations used to constrain the models, they would
probably lead to a slight preference of quartic inflation with an extra
light scalar field (in reheating scenarios 5 and 8) over all other
models, including the single-field plateau ones.

The sensitivity to the microphysics of reheating has also been
demonstrated with the mass mediation scale of the extra scalar field
decay, on which constraints have been derived. Notably, it was found
that reheating scenarios 5 and 8 in quartic inflation, otherwise
indistinguishable with respect to all other criteria discussed in this
chapter, give slightly different preferred values for this mass scale.

In this analysis, the crucial role played by the prior on the vev of the
extra light scalar field at the end of inflation, @xmath , has also been
highlighted. Even though the main conclusions quoted above are robust
under changes of priors on @xmath , the detailed constraints on
reheating and the relative parameter space volume associated with the 10
reheating scenarios depend on the assumptions one makes about its value.
In particular, for quartic inflation, which, in reheating scenarios 5
and 8, is one of the most favoured models, if @xmath is set by the
quantum diffusion effects during inflation, one finds that the Gaussian
distribution ( 3.14 ) is not an equilibrium solution of the stochastic
dynamics of @xmath . In fact, there is no equilibrium solution in this
case, and the typical value acquired by the additional scalar field at
the end of inflation both depends on its value at the onset of inflation
and on the total duration of inflation. This may be relevant to the
question [ 140 , 154 , 151 , 155 ] whether observations can give access
to scales beyond the classical horizon, and we plan to study this
question further in later chapters.

## Appendix 3.A Kullback-Leibler divergence

We introduced the Kullback-Leibler divergence in Sec. 2.2 as a quantity
which computes the information gain between prior and posterior
distributions.

In table 3.2 , the Kullback-Leibler divergences on the energy scale of
inflation and the reheating temperatures are given for the three
potentials considered in this section (Higgs inflation, quartic
inflation and Kähler moduli II inflation), for the single-field versions
of the model as well as for all 10 reheating scenarios, where the
divergence between the averaged priors and posteriors are also given.
The left tables were obtained with a logarithmically flat prior on
@xmath , and the right priors with the stochastic prior ( 3.14 ).

## Appendix 3.B Individual reheating scenarios constraints

In this appendix, we display the posterior constraints on @xmath ,
@xmath and @xmath , for the individual 10 reheating scenarios of Fig.
3.2 , for the three potentials considered in this section (Higgs
inflation, quartic inflation and Kähler moduli II inflation) and when
the logarithmically flat prior or the stochastic prior ( 3.14 ) on
@xmath are used. For the Kähler moduli II cases denoted “n.c.” in table
3.2 , well-converged distributions could not be inferred due to the
numerical difficulty in sampling these scenarios.

#### 3.b.1 Energy density at the end of inflation

#### 3.b.2 Reheating Temperature

#### 3.b.3 Early reheating temperature

## Appendix 3.C Information density

#### 3.c.1 Energy density at the end of inflation

#### 3.c.2 Reheating temperature

#### 3.c.3 Early reheating temperature

## Chapter 4 Spectator field condensates

Abstract. In this chapter we will study the dynamics of light
(sub-Hubble mass) test (energetically sub-dominant) fields — also dubbed
‘spectator fields’ — in an inflationary background. We have already
shown in Sec. 1.2.3 that the dynamics of such fields may be accurately
described by a stochastic approach. Here we shall focus on implementing
this formalism to compute the typical variance acquired by these fields
(effectively a condensate) up to the end of inflation: for different
spectator field potentials; in different slow-roll inflationary
backgrounds; and for multiple coupled spectators. In this review we
combine work from Refs. [ 156 , 157 ] , more recent work on
non-minimally coupled fields and introduce the publicly available code,
nfield , (which now supports multiple test and non-test fields during
inflation) as a new computational tool. Motivated originally by the
requirement to set the initial conditions for the curvaton in the
previous chapter: the results from this chapter are crucial to setting
the initial conditions for many other models of post-inflationary
physics, including the majority discussed in this thesis. The results
from this chapter are thus applicable to a great variety of models for
the early Universe.

### 4.1 Introduction

From a theoretical point of view, inflation takes place in a regime that
is far beyond the reach of terrestrial particle accelerators, and the
physical details of how the inflaton is connected with the standard
model of particle physics and its extensions are still unclear. In
particular, most physical setups that have been proposed to embed
inflation contain extra scalar fields. This is notably the case in
string theory models where many extra light moduli fields may be present
[ 123 , 124 , 125 , 158 , 126 , 127 ] .

Even if such fields are purely spectators during inflation (i.e. masses
smaller than the Hubble rate and contribute a negligible amount to the
total energy density of the Universe), as we have shown already in
Chapter 3 , they can still play an important dynamical role afterwards.
The details of their post-inflationary contribution typically depend on
the field displacement they acquire during inflation. In this context,
if inflation provides initial conditions for cosmological perturbations,
it should also be seen as a mechanism that generates a distribution of
initial field displacements for light degrees of freedom. In this
chapter, we investigate what possibilities this second channel offers to
probe the physics of inflation. In practice, we study how the field
value acquired by light scalar spectator fields at the end of inflation
depends on the inflaton field potential, on the spectator field
potential and on the initial distribution of spectator field values.

As an illustration of post-inflationary physical processes for which the
field value acquired by spectator fields during inflation plays an
important role, we may consider the curvaton scenario of Sec. 1.3.1 ,
Chapter 3 and, originally, of Refs. [ 117 , 74 , 73 , 75 ] . We are
reminded that the curvaton density perturbation is given by @xmath ,
where @xmath denotes the energy density contained in @xmath , and the
effect of this perturbation on the total density perturbation of the
Universe is reduced by the relative energy density of the curvaton field
to the total energy density. The curvaton field, like every light scalar
field, is perturbed at Hubble radius exit by an amount @xmath , where
@xmath is the Hubble parameter evaluated at the time of Hubble radius
crossing during inflation and @xmath is the reduced Planck mass. If the
curvaton perturbations produce the entire observed primordial density
perturbation with amplitude @xmath , the average field value in our
Hubble patch, @xmath , is of order @xmath . An important question is
therefore whether such a field value can naturally be given to the
curvaton during inflation. In the limit of low energy scale inflation in
particular, this implies that @xmath .

The requirement for a very sub-Planckian spectator field value in models
where an initially isocurvature field perturbation is later converted
into the observed adiabatic curvature perturbation is common but not
completely generic, and may be intuitively understood by realising that
if the spectator field fluctuations are negligible compared to the
background value (i.e. @xmath ), then it is difficult to make the
primordial density perturbation have a significant dependence on @xmath
if the background value is not very sub-Planckian. This is discussed in
the conclusions of LABEL:Byrnes:2008zz , which shows that it typically
also applies to scenarios such as modulated reheating [ 160 , 158 ] .
The dark energy model proposed in LABEL:Ringeval:2010hf also requires
sub-Planckian spectator fields during inflation, and the new results we
derive on the field value distribution of a spectator field with a
quartic potential may have implications for the stability of the Higgs
vacuum during inflation as well, see e.g. Refs. [ 162 , 163 , 164 ] .

This naturally raises the question of whether having a sub-Planckian
spectator field value represents a fine tuning of the initial conditions
or not. Provided that inflation lasts long enough, we address this
question here by calculating the stochastically generated distribution
of spectator field values. We will show cases in which sub-Planckian
field values are natural, and others in which super-Planckian field
values are preferred.

If the spectator field value is driven to become significantly
super-Planckian, it can drive a second period of inflation, which may
have observable effects even if the inflaton field perturbations
dominate, because the observable scales exit the Hubble radius at a
different time during the first period of inflation, when the inflaton
is traversing a different part of the potential [ 133 , 134 ] . In some
cases, we will show that the spectator field value may naturally become
so large that it drives more than 60 @xmath -folds of inflation. In this
case we would not observe the initial period of inflation at all, but
its existence remains important for generating the initial conditions
for the second, observable period of inflation.

If no isocurvature perturbations persist after reheating, the linear
perturbations from the inflaton and spectator field are likely to be
observationally degenerate. Non-linear perturbations, especially the
coupling between primordial long- and short-wavelength perturbations,
help to break this degeneracy. We will not study non Gaussianity in this
chapter, but highlight that the results calculated here help to motivate
a prior distribution for the initial spectator field value, which is a
crucial ingredient of model comparison between single- and
multiple-field models of inflation [ 132 , 133 , 134 , 165 ] .

#### 4.1.1 Stochastic single spectator

As we have seen in Sec. 1.2.3 , in the stochastic framework, the short
wavelength fluctuations behave as a classical noise acting on the
dynamics of the super-Hubble scales as they cross the coarse-graining
scale. The coarse-grained fields can thus be described by a stochastic
classical theory, following Langevin equations

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

In this expression, @xmath denotes a coarse-grained field with potential
@xmath . The time variable @xmath has been used but the choice of the
time variable is irrelevant for test fields [ 59 , 60 , 61 , 62 ] . We
are also reminded that @xmath is a Gaussian white noise with vanishing
mean and unit variance such that @xmath and @xmath , where @xmath
denotes ensemble average. The Langevin equation ( 4.1 ) is valid for a
light test field with @xmath . In the Itô interpretation, it gives rise
to a Fokker-Planck equation for the probability density @xmath of the
coarse-grained field @xmath at time @xmath [ 58 , 166 ]

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

which is the same as we found in Sec. 1.2.3 . As in Eq. ( 1.93 ), this
equation can be written as @xmath , where @xmath is the probability
current.

When @xmath is constant, a stationary (equilibrium) solution @xmath to
Eq. ( 4.2 ) can be found, however we need to demonstrate that @xmath
vanishes in order to identify this solution with Eq. ( 1.94 ). Since
@xmath does not depend on time, the probability current does not depend
on @xmath (or on time either). Therefore, if @xmath vanishes at the
boundaries of the field domain, it vanishes everywhere. So we can find
that the solution now matches Eq. ( 1.94 ) like so

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

where the overall integration constant is fixed by requiring that the
distribution is normalised, @xmath . In the following, the solution (
4.3 ) will be referred to as the “de Sitter equilibrium”. For instance,
if the spectator field has a quadratic potential @xmath , the de Sitter
equilibrium is a Gaussian with standard deviation @xmath . In this case,
it will be shown in Sec. 4.2.1 that this equilibrium solution is in fact
an attractor of Eq. ( 4.3 ), that is reached over a time scale @xmath .
Therefore, provided inflation lasts more than @xmath @xmath -folds, the
typical field displacement is of order @xmath at the end of inflation in
this case [ 167 ] .

#### 4.1.2 Limitations of the adiabatic approximation

In the absence of more general results prior to this chapter, the de
Sitter results derived in Sec. 4.1.1 have been commonly used and/or
assumed to still apply to more realistic slow-roll backgrounds, see e.g.
Refs. [ 167 , 168 , 163 , 132 , 134 , 169 ] . The reason is that @xmath
varies slowly during slow-roll inflation, which thus does not deviate
much from de Sitter. This is why in practice, Eq. ( 4.3 ) is often used
to estimate the field value acquired by spectator fields during
inflation. However, one can already see why this “adiabatic”
approximation, which assumes that one can simply replace @xmath by
@xmath in Eq. ( 4.3 ) and track the local equilibrium at every time, is
not always valid. Indeed, the time scale over which @xmath varies by a
substantial amount in slow-roll inflation is given by @xmath , which can
be deduced from Eq. ( 1.34 ). During inflation, @xmath , so that @xmath
. However, in order to see whether a spectator field tracks the de
Sitter equilibrium, one should not compare @xmath to @xmath , but to
@xmath , the number of @xmath -folds required by the spectator field to
relax towards the equilibrium. In other words, only if the adiabatic
condition

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

holds can @xmath be considered as a constant over the time required by
the spectator field to relax to the equilibrium, and only in this case
can the stationary distribution ( 4.3 ) be used.

If the inflaton potential is of the plateau type and asymptotes to a
constant as the field value asymptotes to infinity, one typically has [
170 , 171 ] @xmath in the limit where @xmath , where @xmath denotes the
number of @xmath -folds at the end of inflation where @xmath . This
leads to

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

where @xmath is the asymptotic value of @xmath at large-field value,
hence @xmath , meaning that @xmath cannot change by more than a factor
of order one throughout the entire inflationary phase. For instance, if
one considers the Starobinsky potential of Eq. ( 1.71 ), one finds
@xmath and @xmath . In this case, the de Sitter equilibrium ( 4.3 ),
@xmath , only changes by a relatively small fraction and therefore
provides a useful estimate for the order of magnitude of spectator field
displacements at the end of inflation [using either @xmath or @xmath in
Eq. ( 4.3 )]. Note that the same can be true for hilltop potentials
where @xmath also asymptotes a constant in the infinite past.

In the context of single-field inflation however, plateau potentials are
known to provide a good fit to the data only in the last @xmath @xmath
-folds of inflation. The shape of the inflaton potential is not
constrained beyond this range and is typically expected to receive
corrections when the field varies by more than the Planck scale. In
multiple-field inflation, observations allow the inflaton potential to
be of the large-field type all the way down to the end of inflation [
134 ] . Therefore we also consider monomial inflaton potentials @xmath
with @xmath . In these models, one has

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

If @xmath , this corresponds to convex inflaton potentials (meaning
@xmath ), while this describes concave inflaton potentials ( @xmath )
for @xmath , and the de Sitter case is recovered in the limit @xmath .
From Eq. ( 4.6 ), one has @xmath , so that @xmath . If the spectator
field has a quadratic potential for instance, as mentioned above, it
will be shown in Sec. 4.2.1 that @xmath . In this case, the adiabatic
condition ( 4.4 ) reads @xmath . If @xmath , one can see that this can
never be realised since @xmath and @xmath . If @xmath , the adiabatic
condition is satisfied when @xmath is sufficiently large, that is to say
at early enough times when @xmath . If @xmath for instance, this number
of @xmath -folds is larger than @xmath as soon as @xmath (and larger
than @xmath for @xmath ), which means that even in this case, the
adiabatic regime lies far away from the observable last @xmath @xmath
-folds of inflation. One concludes that in most cases, the de Sitter
equilibrium solution does not provide a reliable estimate of the field
value acquired by spectator fields during inflation. In the following,
we therefore study the dynamics of such fields beyond the adiabatic
approximation.

### 4.2 Quadratic spectator

In this section, we consider a quadratic spectator field, for which

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

In this case, the Langevin equation ( 4.1 ) is linear, which allows one
to solve it analytically. In Appendix 4.A , we explain how to calculate
the first two statistical moments of the spectator field @xmath . The
first moment is given by

  -- -- -- -------
           (4.8)
  -- -- -- -------

which corresponds to the classical solution of Eq. ( 4.1 ) in the
absence of quantum diffusion, and where we have set @xmath at the
initial time @xmath . For the second moment, one obtains

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (4.9)
  -- -------- -------- -- -------

In this expression, the structure of the first term in the right-hand
side is similar to the first moment ( 4.8 ) while the second term is due
to quantum diffusion, so that the variance of the distribution @xmath is
given by the same formula as the second moment (i.e. one can replace
@xmath by @xmath in Eq. ( 4.9 ) and the formula is still valid).

One can also show that the Fokker-Planck equation ( 4.2 ) admits
Gaussian solutions,

  -- -- -- --------
           (4.10)
  -- -- -- --------

where @xmath and @xmath are given by Eqs. ( 4.8 ) and ( 4.9 )
respectively. However, let us stress that Eqs. ( 4.8 ) and ( 4.9 ) are
valid for any (i.e. not only Gaussian) probability distributions.

#### 4.2.1 Plateau inflation

As explained in Sec. 4.1.2 , if the inflaton potential is of the plateau
type, @xmath can be approximated by a constant. In this case, the mean
coarse-grained field ( 4.8 ) is given by

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

It follows the classical trajectory as already pointed out below Eq. (
4.8 ), and becomes small when @xmath . For the second moment, Eq. ( 4.9
) gives rise to

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

When @xmath , it approaches the constant value @xmath . One can check
that this asymptotic value corresponds to the de Sitter equilibrium in
Eq. ( 4.3 ). Moreover, one can see that the typical relaxation time that
is required to reach the attractor is given by

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

which corresponds to the value reported in Sec. 4.1.1 .

#### 4.2.2 Monomial inflation

If the inflaton potential is monomial and of the form @xmath , the
Hubble factor is given by Eq. ( 4.6 ). Substituting this expression for
@xmath into Eq. ( 4.8 ), one obtains (for @xmath )

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

where @xmath is the value of @xmath at an initial time @xmath , and we
have defined

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

In Eq. ( 4.14 ), time is parametrised by @xmath instead of @xmath for
convenience but the two are directly related through Eq. ( 4.6 ). For
the second moment (or for the variance), by substituting Eq. ( 4.6 )
into Eq. ( 4.9 ), one obtains

  -- -------- -- --------
     @xmath      
     @xmath      (4.16)
  -- -------- -- --------

where @xmath denotes the incomplete Gamma function. One can note that
both Eqs. ( 4.14 ) and ( 4.16 ) can be expressed as functions @xmath
only, which is directly proportional to the ratio @xmath . As noted in
Sec. 4.1.2 , for @xmath this ratio is always small, while for @xmath ,
it is large unless @xmath is sufficiently large. The two cases @xmath
and @xmath must therefore be treated distinctly.

##### Case where @xmath

If @xmath , one has @xmath and the quantity @xmath in Eqs. ( 4.14 )
and ( 4.16 ) is always much smaller than one. This implies that the
argument of the exponential in Eq. ( 4.14 ) can be neglected, and @xmath
stays constant. Therefore, the distribution remains centred at the
initial value. Note that the case @xmath is singular and gives rise to

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

which also yields @xmath unless @xmath .

For the second moment, the second arguments of the incomplete Gamma
functions in Eq. ( 4.16 ) are always much smaller than one and in this
limit, one finds

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

In this expression, one can see that @xmath can only increase as time
proceeds, in a way that does not depend on the mass (as long as it is
sub-Hubble). The result is therefore the same as if one set the mass to
zero, and corresponds to a free diffusion process. This is consistent
with the fact that @xmath stays constant in this case. If @xmath , Eq. (
4.16 ) is singular and one has

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.19)
  -- -------- -------- -- --------

In this case, it was also shown in Sec. 4.1.2 that @xmath so there is no
adiabatic regime either. Unless @xmath , in the limit @xmath , Eq. (
4.19 ) coincides with Eq. ( 4.18 ) evaluated at @xmath so in practice
the latter formula can be used for all values of @xmath .

An important feature of Eq. ( 4.18 ) is that it strongly depends on the
initial conditions @xmath and @xmath . This is because there is no
adiabatic regime in this case and hence no attractor that would erase
initial conditions. As a consequence, the typical spectator field
displacement at the end of inflation cannot be determined without
specifying initial conditions.

One should also note that the present analysis relies on the assumption
that the inflaton is not experiencing large stochastic diffusion, which
allows us to use Eq. ( 4.6 ). This is in fact the case if @xmath , where

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

is the scale above which a regime of so-called ‘‘eternal inflation’’
takes place. ¹ ¹ 1 More precisely, @xmath is defined [ 172 ] as the
scale above which, over the typical time scale of an @xmath -fold, the
mean quantum diffusion received by the inflaton field, @xmath , is
larger than the classical drift, @xmath . Since @xmath in monomial
inflation ( 4.6 ), this condition gives rise to @xmath where @xmath is
given by Eq. ( 4.20 ). For this reason, @xmath is the largest value one
can use for @xmath in order for the calculation to be valid. Setting
@xmath , and substituting Eq. ( 4.20 ) into Eq. ( 4.18 ), one obtains at
the end of inflation

  -- -- -- --------
           (4.21)
  -- -- -- --------

This expression is displayed in the left panel of Fig. 4.1 . It means
that the field value of the spectator field is at least of the order of
the Planck mass at the end of inflation. If one assumes the de Sitter
equilibrium distribution ( 4.3 ) at the end of eternal inflation for
instance, @xmath , even much larger field displacements are obtained at
the end of inflation.

##### Case where @xmath

If @xmath , whether the ratio @xmath is small or large depends on the
value of @xmath . More precisely, if @xmath , where

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

one is in the adiabatic regime and @xmath . As soon as @xmath drops
below @xmath however, one leaves the adiabatic regime. In order to set
initial conditions during the adiabatic regime, it should apply after
the eternal inflationary phase during which our calculation does not
apply, which implies that @xmath . Making use of Eqs. ( 4.20 ) and (
4.22 ), this condition gives rise to

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

Let us distinguish the two cases where this relation is and is not
satisfied.

###### Starting out in the adiabatic regime

If Eq. ( 4.23 ) is satisfied, one can set initial conditions for the
spectator field @xmath in the adiabatic regime while being outside the
eternal inflationary phase, that is to say one can take @xmath . From
Eq. ( 4.14 ), this implies that @xmath and the distribution becomes
centred around smaller field values as time proceeds. Regarding the
width of the distribution, two regimes of interest need to be
considered.

At early time, i.e. when @xmath , the incomplete Gamma functions in
Eq. ( 4.16 ) can be expanded in the large second argument limit and one
obtains

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

In this expression, one can see that as soon as @xmath decreases from
@xmath , the first term is exponentially suppressed and one obtains
@xmath , which corresponds to the de Sitter equilibrium formula ² ² 2
More precisely, in a de Sitter universe where @xmath is constant and
equal to the instantaneous value @xmath for a given @xmath in the case
at hand, the asymptotic value reached by @xmath at late time is the same
as the instantaneous value @xmath obtained from Eq. ( 4.24 ). In this
sense, the time evolution of @xmath can be neglected and this
corresponds, by definition, to an adiabatic regime. and confirms that
one is in the adiabatic regime. This also shows that the de Sitter
equilibrium is an attractor of the stochastic dynamics in this case, and
that it is reached within a number of @xmath -folds @xmath , which
exactly corresponds to @xmath given in Eq. ( 4.13 ) when @xmath .

At later times, i.e. when @xmath , one leaves the adiabatic regime and
while the first incomplete Gamma function in Eq. ( 4.16 ) can still be
expanded in the large second argument limit, the second one must be
expanded in the small second argument limit and this gives rise to

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

Interestingly, this expression does not depend on @xmath , meaning that
@xmath stays constant as soon as one leaves the adiabatic regime (and
obviously stops tracking the adiabatic solution). One can also check
that in this expression, the limit @xmath gives rise to @xmath , that is
to say the de Sitter equilibrium formula.

An important consequence of this result is that in the case @xmath and
if @xmath , where @xmath corresponds to the lower bound on @xmath given
by Eq. ( 4.23 ), even if the end of inflation lies far outside the
adiabatic regime, the existence of an early adiabatic phase allows
initial conditions to be erased. At the end of inflation, the field
value of the spectator field only depends on @xmath , @xmath and @xmath
. This is in contrast with the case @xmath where there is no adiabatic
regime, even at early time, and initial conditions remain important even
at the end of inflation. A second important consequence is that the
typical field displacement is always sub-Planckian at the end of
inflation in this case. Indeed, substituting the expression given for
@xmath by Eq. ( 4.23 ) into Eq. ( 4.25 ), one obtains

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

This expression is displayed in the right panel of Fig. 4.1 for a few
values of @xmath . One can see that as soon as @xmath , the spectator
field is always sub-Planckian at the end of inflation.

###### Starting out away from the adiabatic regime

If the condition ( 4.23 ) is not satisfied, the adiabatic regime cannot
be used to erase initial conditions dependence. If both @xmath and
@xmath are much smaller than @xmath , the incomplete Gamma functions in
Eq. ( 4.16 ) can be expanded in the small second argument limit and one
obtains Eq. ( 4.18 ) again. When @xmath becomes small compared to @xmath
, @xmath reaches a constant and the distribution remains frozen until
the end of inflation. Letting @xmath as in Sec. 4.2.2 , this gives rise
to Eq. ( 4.21 ) and one concludes that, in this case, the spectator
field acquires a super-Planckian field value at the end of inflation.
The situation is summarised in the first line of table 4.1 in Sec. 4.10
. If @xmath and @xmath , quadratic spectator fields acquire
sub-Planckian field values at the end of inflation, while if @xmath or
if @xmath with @xmath , they are typically super-Planckian.

#### 4.2.3 Can a spectator field drive a second phase of inflation?

If inflation is driven by a monomial potential @xmath with @xmath , in
Sec. 4.2.2 it was shown that quadratic spectator fields typically
acquire super-Planckian field values at the end of inflation. This can
have important consequences as discussed in Sec. 4.1 , amongst which is
the ability for the spectator field to drive a second phase of
inflation. This can happen if @xmath , and the probability associated to
this condition is given by

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

In the second expression, we have assumed that the probability
distribution of the spectator field value at the end of inflation is a
Gaussian with vanishing mean and variance @xmath , and @xmath denotes
the complementary error function. This probability is displayed in the
left panel of Fig. 4.2 . If a second phase of inflation starts driven by
the quadratic potential with initial field value @xmath , then the
number of @xmath -folds realised is given by @xmath . The mean duration
of this additional inflationary period can thus be calculated according
to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.28)
  -- -------- -------- -- --------

where in the second expression, again, we have assumed that the
probability distribution of the spectator field value at the end of
inflation is a centred Gaussian. This mean number of @xmath -folds is
shown in the right panel of Fig. 4.2 . When @xmath is super-Planckian,
one has a non-negligible probability of a second phase of inflation. For
instance, with @xmath , one finds @xmath and @xmath .

### 4.3 Quartic spectator

In Sec. 4.2 , it was shown that quadratic spectator fields with
potential @xmath typically acquire super-Planckian field displacements
at the end of inflation if the inflaton potential is of the form @xmath
with @xmath at large-field values or with @xmath and @xmath . In this
section, we investigate whether these super-Planckian field values can
be tamed by making the spectator field potential steeper at large-field
values. In practice, we consider a quartic spectator field,

  -- -------- -- --------
     @xmath      (4.29)
  -- -------- -- --------

where @xmath is a dimensionless constant. Contrary to the quadratic case
in Sec. 4.2 , the Langevin equation ( 4.1 ) is not linear for quartic
spectators and cannot be solved analytically. Numerical solutions are
therefore presented in this section, where a large number (typically
@xmath or @xmath ) of realisations of Eq. ( 4.1 ) are generated with a
fourth order Runge-Kutta method, over which moments of the spectator
field value are calculated at fixed times. These results have been
checked with independent numerical solutions of the Fokker-Planck
equation ( 4.2 ).

#### 4.3.1 Plateau inflation

As explained in Sec. 4.1.2 , if the inflaton potential is of the plateau
type, @xmath can be approximated by a constant and the spectator field
value reaches the de Sitter equilibrium ( 4.3 ) where the typical field
displacement, for the quartic spectator potential ( 4.29 ), is given by

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

The relaxation time required to reach this asymptotic value can be
assessed as follows. Since the equilibrium ( 4.3 ) is of the form @xmath
, with @xmath , let us assume that the time evolving distribution for
@xmath is more generally given by

  -- -------- -- --------
     @xmath      (4.31)
  -- -------- -- --------

where @xmath is a free function of time and the prefactor is set so that
the distribution remains normalised, and track the stochastic dynamics
with this ansatz. By substituting Eq. ( 4.31 ) into Eq. ( 4.2 ), an
ordinary differential equation for @xmath is derived in Appendix 4.B ,
that reads

  -- -------- -- --------
     @xmath      (4.32)
  -- -------- -- --------

If @xmath is a constant, this equation can be solved analytically and
the solution is given by Eq. ( 4.97 ). Since Eq. ( 4.31 ) gives rise to
@xmath , one obtains for the second moment

  -- -------- -- --------
     @xmath      
     @xmath      (4.33)
  -- -------- -- --------

In the late time limit, one recovers the de Sitter equilibrium value (
4.30 ). Let us stress however that Eq. ( 4.33 ) is not an exact solution
to Eq. ( 4.2 ) but only provides an approximation under the ansatz (
4.31 ). This approximation will be shown to be reasonably accurate in
Sec. 4.3.2 , but for now, expanding @xmath when @xmath at late time, it
provides an estimate of the relaxation time as

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

It is interesting to notice that this expression is consistent with the
numerical exploration of LABEL:Enqvist:2012xn , see Eq. (2.12) of this
reference.

#### 4.3.2 Monomial inflation

If the inflaton potential is monomial and of the form @xmath , the
Hubble factor is given by Eq. ( 4.6 ) and varies over time scales of
order @xmath as explained in Sec. 4.1.2 . Making use of Eq. ( 4.34 ),
the adiabatic condition @xmath then requires @xmath , where

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

A fundamental difference with the quadratic spectator is that in the
quartic case, for all values of @xmath , there always exists an
adiabatic regime at early times. However, it is not guaranteed that this
regime is consistent with the classical inflaton solution ( 4.6 ),
i.e. extends beyond the eternal inflationary phase. This is the case
only if @xmath , where @xmath is given in Eq. ( 4.20 ), that is to say
if @xmath is large enough,

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

Let us distinguish the case where this condition is satisfied and one
can use the stationary solution ( 4.3 ) to describe the distribution in
the adiabatic regime independently of initial conditions, and the case
where this is not possible.

##### Starting out in the adiabatic regime

If the condition ( 4.36 ) is satisfied, one can set initial conditions
for the spectator field @xmath in the adiabatic regime after the eternal
inflationary phase. In Fig. 4.3 , we present the results of a numerical
integration of the Langevin equation ( 4.1 ) in this case (with the
values used for @xmath and @xmath , one can check that Eq. ( 4.36 ) is
satisfied up to @xmath ). The values of @xmath given by Eq. ( 4.35 ) are
denoted by the vertical coloured dashed lines. When @xmath , the
numerical results follow the de Sitter stationary solution ( 4.30 )
represented by the black dashed line. When @xmath drops below @xmath ,
this is not the case anymore, and the distributions are wider at the end
of inflation than the adiabatic approximation would naively suggest.

In this regime, the behaviour of @xmath can in fact still be tracked
analytically by making use of the quartic ansatz ( 4.31 ) introduced in
Sec. 4.3.1 . Indeed, in the case where @xmath is given by Eq. ( 4.6 ),
one can cast Eq. ( 4.32 ) into a Ricatti equation and in Appendix 4.B it
is shown that its solution reads

  -- -- -- --------
           (4.37)
  -- -- -- --------

In this expression, @xmath is a modified Bessel function of the second
kind. One can note that the argument of the Bessel functions is directly
proportional to @xmath , confirming that this ratio controls the
departure from the adiabatic solution ( 4.30 ). At early times when
@xmath , or equivalently @xmath , one can expand the Bessel functions in
the large argument limit, @xmath , and one recovers the adiabatic
approximation ( 4.30 ). The formula ( 4.37 ) is displayed in Fig. 4.3
with the solid coloured lines. One can see that even when @xmath , it
still provides a reasonable approximation to the numerical solutions.
One can also notice that the lower @xmath is, the better this quartic
approximation. At the end of inflation, @xmath , so the Bessel functions
can be expanded in the small argument limit, which depends on the sign
of the index of the Bessel function. ³ ³ 3 In the limit @xmath , if
@xmath , @xmath , if @xmath , @xmath and if @xmath , @xmath , where
@xmath is the Euler constant [ 173 ] . Because the index of the Bessel
function in the denominator of Eq. ( 4.37 ) is proportional to @xmath ,
this leads to different results whether @xmath is smaller or larger than
@xmath , namely

  -- -------- -- --------
     @xmath      (4.38)
  -- -------- -- --------

where we have defined @xmath , where @xmath is the Euler constant.
Ignoring the overall constants of order one, if @xmath , one finds
@xmath , and if @xmath , @xmath . This needs to be compared to the de
Sitter case ( 4.30 ) where @xmath . In monomial inflation, @xmath is
therefore larger than in plateau inflation for the same value of @xmath
, by a factor @xmath if @xmath and @xmath if @xmath . One should also
note that the condition ( 4.36 ) for the adiabatic regime to extend
beyond the eternal inflationary phase can be substituted into Eq. ( 4.38
) and gives rise to @xmath if @xmath and @xmath if @xmath . In both
cases, the spectator field displacement at the end of inflation is
therefore sub-Planckian.

##### Starting out away from the adiabatic regime

If the condition ( 4.36 ) is not satisfied, the adiabatic regime lies
entirely within the eternal inflationary phase and cannot be used to
erase initial conditions. In this case, the spectator field displacement
at the end of inflation is thus strongly dependent on initial conditions
at the start of the classical inflaton evolution. In this section, we
derive a lower bound on @xmath , assuming that it vanishes when @xmath
and solving the subsequent stochastic dynamics numerically. The result
is presented in Fig. 4.4 where @xmath is displayed as a function of
@xmath for @xmath (left panel) and for @xmath (left panel). The two
cases @xmath and @xmath must be treated separately.

###### Case where @xmath

If @xmath , it was shown in Sec. 4.2.2 that a light quadratic spectator
field always acquires a super-Planckian field value at the end of
inflation. The mean effective mass of the quartic spectator field is
given by

  -- -- -- --------
           (4.39)
  -- -- -- --------

and is smaller than @xmath for @xmath if @xmath . This explains why, in
Fig. 4.4 , in the regime @xmath , one recovers Eq. ( 4.21 ) that is
displayed with the horizontal coloured lines, and which shows that the
spectator field acquires a super-Planckian field value in this case.
Otherwise, if @xmath [the upper bound coming from breaking the
inequality ( 4.36 )], one can see in Fig. 4.4 that the field
displacement can be made sub-Planckian, but that its effective mass
becomes of order @xmath . ⁴ ⁴ 4 Strictly speaking, the present
calculation does not apply when the effective mass of the spectator
field is of order @xmath or larger. However, if the effects of the mass
were taken into account, the amplitude of the noise term in Eq. ( 4.1 )
would not be @xmath but would become smaller as @xmath approaches @xmath
. This would result in a smaller value for @xmath , hence for @xmath ,
and therefore a larger noise amplitude. One can expect the two effects
to compensate for a value of @xmath around @xmath . In this regime, the
spectator field cannot be considered as light anymore.

###### Case where @xmath

If @xmath , it was shown in Sec. 4.2.2 that a quadratic spectator field
acquires a super-Planckian field value at the end of inflation if its
mass is smaller than @xmath , see Eq. ( 4.23 ). When evaluated at the
Planck scale, the effective mass ( 4.39 ) of the quartic spectator field
is smaller than this threshold when @xmath , which exactly corresponds
to breaking the inequality ( 4.36 ). One can check in Fig. 4.4 that when
@xmath , one does indeed recover Eq. ( 4.21 ) which is displayed with
the horizontal dashed coloured lines. One concludes that in this case,
the spectator field always acquires a field value at least of order the
Planck mass at the end of inflation.
The situation is summarised in the second line of table 4.1 in Sec. 4.10
. If @xmath , the spectator field is sub-Planckian at the end of
inflation. Otherwise, if @xmath , either the spectator field is
super-Planckian or not light at the end of inflation, and if @xmath , it
is always super-Planckian. Considering the quadratic spectator discussed
in Sec. 4.2 where it was shown that super-Planckian field displacements
are usually generated at the end of inflation, one thus concludes that
an additional self-interacting term @xmath in the potential can render
the field value sub-Planckian if @xmath is large enough, namely if
@xmath . One can check that for such a value of @xmath , if @xmath with
@xmath , the quartic term always dominates over the quadratic one when
@xmath , which is consistent.

### 4.4 Axionic spectator

In Sec. 4.2 , it was shown that quadratic spectator fields with
potential @xmath typically acquire super-Planckian field displacements
at the end of inflation if the inflaton potential is of the form @xmath
with @xmath at large-field value or with @xmath and @xmath . In Sec. 4.3
, we discussed how adding a quartic self-interaction term in the
potential could help to tame these super-Planckian values. In this
section, we investigate another possibility, which consists in making
the field space compact and of sub-Planckian extent. This is typically
the case for axionic fields, with periodic potentials of the type

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

In this expression, @xmath and @xmath are two mass scales that must
satisfy @xmath in order for the curvature of the potential to remain
smaller than the Hubble scale throughout inflation, i.e. for the axionic
field to remain light, which we will assume in the following.

#### 4.4.1 Plateau inflation

As explained in Sec. 4.1.2 , if the inflaton potential is of the plateau
type, @xmath can be approximated by a constant and the spectator field
value reaches the de Sitter equilibrium ( 4.3 ). If @xmath , such a
distribution is approximately flat, in which case @xmath if @xmath is
restricted to one period of the potential ( 4.40 ). In this regime, the
classical drift due to the potential gradient in Eq. ( 4.1 ) can be
neglected and the spectator field experiences a free diffusion process.
The relaxation time is therefore the time it takes to randomise @xmath
over the period of the potential and is given by @xmath . In the
opposite limit when @xmath , the distribution is localised close to the
minimum of the potential where it can be approximated by a quadratic
function @xmath with mass @xmath . In this case, according to Sec. 4.2.1
, one has @xmath , and the relaxation time is of order @xmath .

#### 4.4.2 Monomial inflation

If inflation is realised by a monomial potential @xmath , there is
always an epoch when @xmath in the past and during which the spectator
field distribution is made flat within a number of @xmath -folds of
order @xmath . Therefore, contrary to the quadratic and to the quartic
spectators, the field displacement of an axionic spectator at the end of
inflation is always independent of initial conditions, provided that
inflation lasts long enough. If @xmath , the distribution remains flat
until the end of inflation. In the opposite case, when @xmath drops
below @xmath , the subsequent dynamics of @xmath depends on whether
@xmath or @xmath .

##### Case where @xmath

If @xmath , in Sec. 4.2 it was shown that the evolution of a quadratic
field with mass @xmath is effectively described by a free-diffusion
process where the potential drift can be neglected. For an axionic
spectator, the potential is always flatter than its quadratic expansion
around its minimum and can therefore also be neglected. As a
consequence, the distribution remains flat until the end of inflation
and one finds @xmath .

##### Case where @xmath

If @xmath , in Sec. 4.2 it was shown that the distribution of a
quadratic field with mass @xmath tracks the adiabatic equilibrium until
@xmath , where @xmath is given by Eq. ( 4.22 ), and remains frozen
afterwards. This implies that an axionic spectator distribution narrows
down from a flat profile if @xmath , which gives rise to

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

Notice that for this condition to be compatible with the light-field
prescription given below Eq. ( 4.40 ), one must have @xmath for @xmath
(which makes sense, otherwise the distribution would be randomised over
one @xmath -fold even towards the end of inflation). In this case,
@xmath settles down to @xmath , which gives rise to

  -- -------- -- --------
     @xmath      (4.42)
  -- -------- -- --------

If Eq. ( 4.41 ) is not satisfied however, the field distribution remains
flat until the end of inflation and one has @xmath .
In order to check the validity of these considerations, in Fig. 4.5 we
present numerical solutions of the Langevin equation ( 4.1 ). When
@xmath , one can check that the distributions remain flat until the end
of inflation. The values of the parameters @xmath , @xmath and @xmath
have been chosen to satisfy Eq. ( 4.41 ), which explains why for @xmath
, the distributions narrow down once @xmath drops below @xmath
(otherwise, we have checked that even when @xmath , the distributions
remain flat). However, one can see that when the distributions start
moving away from the flat configuration, they do not exactly follow the
adiabatic solution displayed with the black dotted line, even though
@xmath . This is because in the above discussion, we have approximated
the axionic potential with its quadratic expansion around its minimum,
which is not strictly valid at the stage where the distribution is still
flat and sensitive to the full potential shape. Nonetheless, the
distributions converge towards the adiabatic profile at later time and
the final value of @xmath is well described by Eq. ( 4.42 ).

The situation is summarised in the third line of table 4.1 in Sec. 4.10
. If @xmath , @xmath , or @xmath with @xmath , the distribution of the
axionic spectator remains flat until the end of inflation and @xmath .
Only if @xmath with @xmath does the distribution narrow down and @xmath
. In all cases, if @xmath is sub-Planckian, the typical field
displacement obviously remains sub-Planckian as well.

### 4.5 Non-minimally coupled spectator

In this section we extend the calculations made in Sec. 4.2 to include
the existence of a non-minimal coupling to gravity. During inflation,
scalar fields can radiatively generate a non-minimal coupling between
themselves and the background [ 174 , 175 ] . One then may expect such
fields to appear with an effective potential of the form

  -- -------- -- --------
     @xmath      (4.43)
  -- -------- -- --------

where @xmath is the non-minimal coupling strength and, during inflation,
the Ricci scalar is @xmath ( @xmath being the Hubble parameter and here
we will assume that @xmath is negligible during inflation) and, hence,
so long as @xmath the spectator can remain light and acquire a non-zero
variance during inflation. We also note here that it has recently been
checked that neglecting metric fluctuations of the background is
consistent with the known behaviour of a spectator field in the Einstein
frame [ 176 ] . Thus, at this level, we may confidently ignore
differences between Jordan and Einstein frames.

As we have already discussed in Sec. 4.2 the limit where the non-minimal
coupling is negligible, we shall now take the opposite limit @xmath such
that Eq. ( 4.43 ) during inflation becomes

  -- -------- -- --------
     @xmath      (4.44)
  -- -------- -- --------

Given Eq. ( 4.44 ) and following the same reasoning as was used to
obtain Eq. ( 4.9 ), one may find the variance with the implicit solution

  -- -------- -------- -- --------
     @xmath   @xmath      (4.45)
  -- -------- -------- -- --------

We note here that, as in the minimally-coupled quadratic case, the
Fokker-Planck equation (Eq. ( 4.2 )) for this case admits stationary
Gaussian solutions. The variance computed from Eq. ( 4.45 ) is hence
sufficient to characterise the entire stationary (and near-stationary)
PDF. Upon complete departure from equilibrium, however, the PDF can
deviate from Gaussianity.

#### 4.5.1 Plateau inflation

In a plateau inflationary background, @xmath does not evolve in time and
one immediately finds the following explicit solution to Eq. ( 4.45 )

  -- -- -- --------
           (4.46)
  -- -- -- --------

hence in the limit where @xmath we find that @xmath . From Eq. ( 4.46 )
we may also read off the relaxation timescale

  -- -------- -- --------
     @xmath      (4.47)
  -- -------- -- --------

#### 4.5.2 Monomial inflation

Going beyond a plateau inflationary background, if @xmath (where we
remind the reader that @xmath in a monomial background with power @xmath
, i.e., @xmath ) the system may relax after each successive time step,
and hence we may use the solution quoted in Eq. ( 4.46 ). If @xmath ,
however, we must understand how the system changes in time.

Using @xmath in a monomial background, as given in Eq. ( 4.6 ), and
rewriting Eq. ( 4.45 ) in terms of @xmath as the time variable, the
solution to Eq. ( 4.45 ) is

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.48)
  -- -------- -------- -- --------

We can see from Eq. ( 4.5.2 ) that the non-minimally coupled spectator
follows the same qualitative behaviour as in the quartic case: at early
times there is always an adiabatic regime, however this can be so early
as to be beyond the self-reproducing regime of inflation. Hence, using
Eq. ( 4.47 ), the condition analogous to Eq. ( 4.36 ) that ensures an
adiabatic initial condition is

  -- -------- -- --------
     @xmath      (4.49)
  -- -------- -- --------

Given that Eq. ( 4.49 ) holds and that the field is light ( @xmath , as
discussed before), we can expand Eq. ( 4.5.2 ) in the late-time limit to
find the variance. Taking the @xmath limit, the initial variance @xmath
has been washed away and the second incomplete Gamma function in Eq. (
4.5.2 ) becomes negligible, leaving us with a small second-argument
expansion of the first incomplete Gamma function ⁵ ⁵ 5 The small
argument limit of the (upper) incomplete Gamma function can be obtained
by rewriting it as a combination of the Gamma function @xmath in the
first argument and the lower incomplete Gamma function @xmath

@xmath

  -- -------- -- --------
     @xmath      (4.50)
  -- -------- -- --------

This expression coincides with stationary limit of Eq. ( 4.46 ) when
@xmath , which is consistent with the expectation that, in the same
limit, monomial inflation approaches a plateau.

The overall picture for the non-minimally coupled spectator in a
monomial background is as follows. For values of @xmath , the spectator
will never follow the de Sitter equilibrium distribution and hence will
acquire an initial variance that will be unchanged from the point at
which it becomes light during inflation. For values of @xmath , the
spectator will follow the de Sitter equilibrium distribution at early
times, followed by a transition away from this solution at the point
when @xmath .

### 4.6 Information retention from initial conditions

When calculating the field value acquired by spectator fields at the end
of inflation, we have found situations in which initial conditions are
erased by the existence of an adiabatic regime at early times, and
situations in which this is not the case. In this section, building from
Sec. 2.2 , we propose to quantify this memory effect using information
theory in order to better describe the amount of information about early
time physics (potentially pre-inflationary) available in the final field
displacements of spectator fields. As in Eq. ( 2.8 ), the relative
information between two distributions @xmath and @xmath can be measured
using the Kullback-Leibler divergence [ 89 ] @xmath ,

  -- -------- -- --------
     @xmath      (4.51)
  -- -------- -- --------

It is invariant under any reparametrisation @xmath , and since it uses a
logarithmic score function as in the Shannon’s entropy, it is a
well-behaved measure of information [ 97 ] . Considering two initial
distributions separated by an amount of information @xmath , giving rise
to two final distributions separated by @xmath , we define the
information retention criterion by

  -- -------- -- --------
     @xmath      (4.52)
  -- -------- -- --------

When @xmath , the initial information is contracted by the dynamics of
the distributions. This is typically the case when there is an
attractor, or an adiabatic regime, which tends to erase the initial
conditions dependence of final states. When @xmath , the initial
information is amplified and the final state is sensitive to initial
conditions. Values of @xmath might signal the presence of chaotic
dynamics in which case initial conditions are difficult to infer. For
this reason, @xmath represents an optimal situation in terms of initial
conditions reconstruction. In practice, @xmath depends both on the
initial (or final) state around which the infinitesimal variation is
performed, and on the direction in the space of distributions along
which it is performed.

For concreteness, let us restrict the analysis to the space of symmetric
Gaussian distributions, fully characterised by a single parameter,
@xmath . In this case, Eq. ( 2.14 ) gives rise to the equivalent
expression in this case

  -- -- -- --------
           (4.53)
  -- -- -- --------

where @xmath (respectively @xmath ) is the variance of @xmath
(respectively @xmath ). One then has @xmath , which gives rise to ⁶ ⁶ 6
The same expression is obtained if one uses the Jensen-Shannon
divergence as a measure of the relative information between two
distributions,

@xmath (4.54)

which is a symmetrised and smoothed version of the Kullback-Leibler
divergence. The Jensen-Shannon divergence between two Gaussian
distributions cannot be expressed in a closed form comparable to Eq. (
4.53 ). However, in the limit where the two Gaussian distributions have
variances @xmath and @xmath infinitesimally close one to the other, one
can expand the integrands of Eq. ( 4.54 ) at quadratic order in @xmath
and obtain @xmath . As a consequence, @xmath and the same information
retention criterion is obtained.

  -- -------- -- --------
     @xmath      (4.55)
  -- -------- -- --------

In practice, the functional relationship between @xmath and @xmath
depends on the details of the stochastic dynamics followed by @xmath .
When @xmath is independent of @xmath for instance, initial conditions
are irrelevant to determine the final state and @xmath .

For quadratic spectator fields, in Sec. 4.2 it was shown that the
distributions remain Gaussian if they were so initially, and the
relationship ( 4.9 ) between @xmath and @xmath was derived. The
formula ( 4.55 ) can therefore directly be evaluated, and it is
displayed in Fig. 4.6 in the case where inflation is driven by a
monomial potential @xmath and initial conditions are taken at the time
when the inflaton exits the eternal inflationary epoch. When @xmath ,
there is no adiabatic regime and therefore no erasure of initial
conditions. Since quantum diffusion contributes a field displacement of
order the Planck mass, if the initial field value is much smaller than
the Planck mass, it provides a negligible contribution to the final
field value and one has @xmath . If it is much larger than the Planck
mass it provides the dominant contribution to the final field value and
@xmath . In the left panel, the value of @xmath has been chosen so that
the condition ( 4.23 ) is satisfied for @xmath . In this case, initial
conditions are erased during the adiabatic regime and one has @xmath .
In the right panel, the value chosen for @xmath is such that Eq. ( 4.23
) is not satisfied and the situation for @xmath is similar to the cases
@xmath .

For quartic spectator fields, in Sec. 4.3 it was shown that either the
condition ( 4.36 ) is satisfied and initial conditions are erased during
an early adiabatic phase, leading to @xmath ; or if the condition ( 4.36
) is not satisfied, the dynamics of the spectator field is described by
a free diffusion process and the situation is the same as in the right
panel of Fig. 4.6 .

For axionic spectator fields finally, in Sec. 4.4 , initial conditions
were shown to always be erased at early times, yielding @xmath .

The amount of information one can recover about the initial state from
the final one therefore depends both on the potential of the spectator
field and on the inflationary background. Let us stress that in some
situations, initial conditions are not erased ( @xmath ). This suggests
that, if observations yield non-trivial constraints on spectator field
values at the end of inflation in our local patch, one may be able to
infer a non-trivial probability distribution on its field value at much
earlier time, for instance when one leaves the regime of eternal
inflation. This might be relevant to the question [ 154 ] of whether
observations can give access to scales beyond the observational horizon.

### 4.7 Multiple spectator condensates from inflation

Consider now the evolution of multiple spectator fields in the
inflationary background. As we have shown in Sec. 1.2.3 , the quantum
correction to the classical field dynamics can thus be well-described as
a stochastic system of drift and diffusion captured by the following
Langevin equation for an indexed field @xmath appearing in a multi-field
potential @xmath

  -- -------- -- --------
     @xmath      (4.56)
  -- -------- -- --------

where @xmath is a Gaussian white noise term (without cross-correlation)
with a unit amplitude ensemble-average @xmath . In all equations
throughout the remainder of this chapter, we will use the indices @xmath
, where @xmath is the number of spectator fields.

We note here that the noise term in Eq. ( 4.56 ) originates from the
effectively massless and uncoupled mode functions derived from the
vacuum solutions to the field in a quasi-de Sitter background. Should
the effective mass @xmath of the field @xmath exceed the Hubble rate,
then this formalism is no longer valid and other methods must be
developed [ 177 , 178 , 179 ] . Hence, it seems natural here to consider
the evolution of light fields up until the threshold where their
effective mass is equal to the Hubble rate, and beyond which we shall
refer to the condensate as having ‘collapsed’ to the Hubble scale and
the effective mass has also saturated to @xmath . We shall return to
this point in Sec. 4.9 where we, e.g. evaluate the critical couplings
required to achieve this saturation.

We stress here another point raised in Sec. 1.2.3 which is that, for
interacting fields in de Sitter spacetimes, another critical value is
known to exist which signals the breakdown of the semi-classical
approximation. As discussed in Sec. 1.2.2 , in the mean-field
approximation, one separates a classical ‘mean’ background field from
perturbatively small quantum fluctuations. For quartic scalar fields, in
LABEL:Burgess:2010dd , it was shown that a breakdown in this peturbative
expansion occurs in the regime where the bare mass is less than @xmath
which cannot be removed by reorganising the perturbative expansion to
include a running effective mass. We stress here that non-peturbative
methods of resummation, such as those of this chapter, are potentially
unaffected by such a bound. This is due to the fact that the
backreaction from small quantum fluctuations is inherently included into
the background evolution described by Eq. ( 4.56 ), thus optimising the
perturbative expansion at each new scale in time — a cosmological analog
to (but not exactly the same as [ 56 ] ) the Renormalisation Group flow
[ 57 ] .

The corresponding multi-field Fokker-Planck equation to Eq. ( 4.56 ) is

  -- -------- -- --------
     @xmath      (4.57)
  -- -------- -- --------

where we have implicitly made use of the test field condition @xmath and
defined @xmath as the probability distribution function over field
values at a given @xmath , when normalised. Thus, the evolution of modes
as they accumulate outside of the horizon typically yields an @xmath
-dimensional distribution of field displacements throughout the
inflationary phase @xmath . It has recently been remarked [ 180 ] that,
when more than one field is present, one must use the Stratonovich
interpretation of the stochastic process which maintains general
covariance over the field space at the cost of introducing spurious
frame dependencies into the noise term of Eq. ( 4.57 ) — which has been
obtained from the Itô interpretation. Due to the fact that we are
considering test fields, however, the backreaction onto @xmath from all
of the @xmath fields is negligible. In this case, one can likely remove
these without any loss of information about the physical system because,
as is further remarked in LABEL:Pinol:2018euk by analogy with non-linear
sigma models, the Riemann curvature of field space only enters the mass
matrix. This is equivalent to test fields developing a preferred set of
field space coordinates due to their potential gradients only entering
into the drift term.

Eq. ( 4.57 ) may also be written essentially as a continuity equation [
181 , 63 ]

  -- -------- -- --------
     @xmath      (4.58)
  -- -------- -- --------

where @xmath is the probability current and the right hand side of the
equation must vanish for probability conservation. By inspection of
Eq. ( 4.57 ), one may verify that in this case

  -- -------- -- --------
     @xmath      (4.59)
  -- -------- -- --------

In de Sitter-like inflation the Hubble parameter is effectively constant
in time, hence there is a stationary ⁷ ⁷ 7 @xmath in this context.
solution to Eq. ( 4.57 ), @xmath , corresponding to a vanishing
divergence @xmath of the probability current — an incompressible flow of
the vector field with components @xmath . Where @xmath in an unbounded
field domain ⁸ ⁸ 8 In the case of a bounded field domain, probability
conservation at the specified boundary implies that @xmath directly. one
can show that in order for the distribution to have a finite
normalisation @xmath (and hence @xmath ) as @xmath . Furthermore, given
@xmath , one can also show that in the stationary limit, the vanishing
divergence of @xmath simply reduces to @xmath , and @xmath must
therefore vanish @xmath . Hence, the left hand side of Eq. ( 4.59 ) may
always be set to zero and the well-known exponential solution to Eq. (
4.57 ) for the stationary probability distribution is obtained [ 58 ]
@xmath .

For unbounded @xmath with arbitrary @xmath , it is still natural to
consider a boundary condition where @xmath as @xmath to restrict
unphysical possibilities, and this may even in practice occur at a set
finite scale @xmath that denotes the chosen cutoff of the theory.
However, one can no longer generally state that @xmath vanishes
everywhere throughout the @xmath -field domain since any class of
incompressible vector @xmath flows are permitted. Because @xmath is
still possible, it is true that one stationary solution to Eq. ( 4.57 )
is

  -- -------- -- --------
     @xmath      (4.60)
  -- -------- -- --------

but it is no longer unique, and one must use either use further
analytical arguments or full numerical solutions for verification.

For any @xmath , the stationary distribution @xmath is in practice only
reached after some equilibration timescale @xmath . The timescale @xmath
is defined as the number of @xmath -folds it takes for @xmath — an
@xmath -dimensional Dirac delta function ⁹ ⁹ 9 We note that, for the
symmetric potentials about the origin used in this chapter, this is of
course equivalent to the more general definition of a Dirac function at
the global minimum, @xmath . — to relax to @xmath . Hence, @xmath can be
thought of as the time it takes for the effective condensate to grow to
its maximal value in every field dimension. It is also important to note
here that the definition of @xmath used in this chapter relies on the
inflationary background being de Sitter-like. In slow-roll backgrounds
where @xmath varies more substantially, such as those permitted by a
monomial @xmath inflationary potential, this timescale will have to be
recomputed [ 156 ] .

### 4.8 Vanishing probability current with symmetric potentials

In the previous section, we stated that the exponential form (Eq. ( 4.60
)) of the stationary solution to Eq. ( 4.57 ) may no longer be stable
when any divergence-free (incompressible) probability currents are
potentially allowed. For any choice of @xmath , only the divergence of
the current must vanish for a stationary solution, which leaves the
possibility of a curl in the vector field @xmath . Because @xmath
vanishes, where @xmath is the normal to the boundary, the total integral
of the curl over the domain of the fields @xmath vanishes according to
Stokes’ theorem

  -- -------- -- --------
     @xmath      (4.61)
  -- -------- -- --------

however there are still an infinite number of functions for @xmath that
can satisfy this criterion. Examining Eq. ( 4.59 ), and using the
general properties of the totally antisymmetric symbol @xmath , one can
show that

  -- -------- -- --------
     @xmath      (4.62)
  -- -------- -- --------

Our first remark is that Eq. ( 4.62 ) vanishes at the extrema of @xmath
and @xmath (a fact that we numerically verify for a given potential in
Sec. 4.9.3 ) but not necessarily everywhere in the domain of @xmath .
Secondly, for all choices of potential and initial distribution, if the
gradients of @xmath and @xmath align, i.e. @xmath , then Eq. ( 4.62 )
vanishes and hence @xmath must be true at this point. If one takes a
derivative of Eq. ( 4.60 ), it is clear that the stationary solution
that we have quoted satisfies this criterion.

Without an alternative ansatz to compute @xmath , it is difficult to
make any general claims about stationary solutions to Eq. ( 4.57 ), even
when @xmath is symmetric ¹⁰ ¹⁰ 10 Indeed, even with symmetric @xmath and
@xmath (the latter can be proved to follow from a symmetric initial
condition), if @xmath it can be shown that

@xmath (4.63)

where @xmath is an arbitrary function of both variables. Eq. ( 4.63 )
trivially satisfies the integral constraint from Stokes’ theorem (Eq. (
4.61 )) and hence we are left with no further determination of its exact
form without working through an explicit example. Note, however, that
Eq. ( 4.63 ) gives @xmath and hence, if one can also demonstrate that
@xmath for symmetric potentials, it must be true that @xmath . .
However, we conjecture that when @xmath is symmetric, the solution for
@xmath — which we assume has a been evolved from a symmetric initial
condition — typically has a gradient which aligns with @xmath and hence
Eq. ( 4.60 ) is a stable stationary solution to Eq. ( 4.57 ). We have
verified numerically that Eq. ( 4.60 ) provides a stable solution to the
late-time dynamics with symmetric potentials in Sec. 4.9 . Note also
that in asymmetric potentials ¹¹ ¹¹ 11 For example, some of the
potentials we introduce and discuss in Sec. 4.9.2 . we can no longer
assume that the @xmath components vanish everywhere, and Eq. ( 4.60 ) is
no longer the stationary solution. In such instances, one can also turn
to numerical methods.

### 4.9 Computation and analytic arguments

The general problem for arbitrary @xmath defined by Eqs. ( 4.56 ) and (
4.57 ) cannot be solved analytically, and so in this section we shall
make our computations for the condensates formed from multi-field
spectator potentials combining both analytic and numerical methods. The
details of our numerical implementation can be found in Appendix 4.C ,
where we briefly outline our development of a new publicly available
python code, nfield .

In light of our discussion in Sec. 4.8 , we cannot always expect to use
moments of the distribution in Eq. ( 4.60 ) to reliably evaluate the
stationary variance for asymmetric potentials. However, we shall not
need this distribution to hold true in order to still gain an insight
from some approximations.

Consider a general multi-field interacting spectator potential. In the
limit of small field displacements, one can typically perform a Taylor
expansion about the minimum of a potential which defines an effective
mass in each orthogonal field dimension ¹² ¹² 12 Where we have already
implicitly performed any necessary rotations in field space such that
@xmath cross-terms vanish. as

  -- -------- -- --------
     @xmath      (4.64)
  -- -------- -- --------

Hence, a generic multi-field potential can be approximated by

  -- -------- -- --------
     @xmath      (4.65)
  -- -------- -- --------

where one may account for interactions (both self and with other fields)
through the typical values that one finds for @xmath . For example,
quartic self-interacting terms where @xmath may be approximately written
as @xmath . As another example, consider the situation where @xmath due
to interaction terms, then the effective mass becomes approximately
@xmath . This approximation will prove sufficient to calculate the
desired quantities in Sec. 4.9.1 .

Using Eq. ( 4.65 ), one can derive a second-moment evolution equation
from Eq. ( 4.56 ) of the form [ 54 ]

  -- -------- -- --------
     @xmath      (4.66)
  -- -------- -- --------

and hence the stationary ¹³ ¹³ 13 @xmath in this context, hence this
need only be ‘stationary’ in the @xmath th field dimension. variance can
be immediately derived ¹⁴ ¹⁴ 14 Notice that this equation is indeed
consistent with inserting Eq. ( 4.65 ) into Eq. ( 4.60 ) and taking the
second-order moment. [ 54 ]

  -- -------- -- --------
     @xmath      (4.67)
  -- -------- -- --------

Note that in the limit where Eq. ( 4.65 ) is no longer an approximation,
such as for a quadratic non-interacting spectator, then Eq. ( 4.66 ) and
Eq. ( 4.67 ) are precise equations with @xmath corresponding to the bare
mass.

In Eq. ( 4.67 ), the inverse-proportionality between the effective mass
and the variance indicates that there is a critical value for @xmath
above which the stationary condensate collapses to the Hubble rate
@xmath . Taking a two-field example for illustration, we have plotted a
schematic diagram of the physical situation in Fig. 4.7 for a symmetric
potential. In the left panel, the condensate (dashed black circle) is
relatively large because the effective mass @xmath . In the right panel,
the condensate collapses to the value of the Hubble rate (dashed red
circle) because @xmath . For the shaded red region the suppression
@xmath in the variance from Eq. ( 4.67 ) is no longer valid and the
stochastic approach can no longer be used. This is because when @xmath
the mode functions which source the fluctuations of the field can no
longer be accurately described by the simple form of noise correlator in
the definition of Eq. ( 4.56 ).

Other calculations do exist for situations considering a constant
super-Hubble mass @xmath [ 177 , 178 , 179 ] where, in these instances,
the variance is known to experience further suppression. However, the
assumption of constant @xmath is one we cannot make for the potentials
studied in this section. We anticipate that a similar suppression occurs
but leave the verification of this to future work. Even if this is not
always true (e.g. for many non-interacting quadratic spectators), the
‘saturation’ value is still of interest since it characterises the
fundamental domain of validity for the stochastic formalism. Hence, in
this regard, we shall leave the calculation of possible condensates in
the @xmath regime to future work, and therefore we will focus our
efforts on the regime where the stochastic formalism is valid.

#### 4.9.1 The critical coupling

In this subsection, we will demonstrate that when one generalises the
formation of spectator field condensates to many coupled fields, a
critical value for the coupling appears, above which the equilibrium
variances of all fields have collapsed to the Hubble scale and effective
mass of each field has saturated to @xmath . To show this we will
consider a simplified potential that will allow us to calculate this
critical coupling both analytically and numerically, for verification.

Now consider the multi-field spectator potential

  -- -------- -- --------
     @xmath      (4.68)
  -- -------- -- --------

Mindful of the approximation made with @xmath in Eq. ( 4.65 ), one thus
expects that incrementally strengthening the interaction between
spectator fields @xmath can lead to the eventual saturation of the
condensate value at the Hubble scale due to the effective mass of each
field being progressively larger, and we therefore anticipate a critical
value for the inter-field coupling @xmath to exist, for a given @xmath ,
above which the stationary condensate collapses to @xmath .

By inspection between Eqs. ( 4.65 ) and ( 4.68 ), the typical value of
the effective mass in the @xmath th field dimension corresponds to
@xmath , where in the second equality we have assumed that the
distribution (using Eq. ( 4.68 ) as the potential) has reached
stationarity @xmath and, hence, due to symmetry @xmath . Because @xmath
, given in Eq. ( 4.67 ), we can now obtain an approximate relation for
the critical coupling ¹⁵ ¹⁵ 15 Note that because Eq. ( 4.68 ) is a
symmetric potential — i.e. @xmath for any permutation of field indices
@xmath — our discussion in Sec. 4.8 indicates the stability of Eq. (
4.60 ) in this situation. Hence, another way to compute Eq. ( 4.69 )
would be to take the second moment of Eq. ( 4.60 ).

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.69)
              @xmath      (4.70)
  -- -------- -------- -- --------

where we have found @xmath by setting @xmath in Eq. ( 4.69 ).

For illustration, we plot the time evolution for variances, averaging
over multiple Langevin realisations (realisations of Eq. ( 4.56 )), of
an example where @xmath in Fig. 4.8 and Eq. ( 4.69 ) is shown to be a
good description of the stationary values against the numerically
evaluated variances (all identical to each other due to the symmetry).
The approximate form of Eq. ( 4.70 ) must also be verified numerically,
and hence we plot in Fig. 4.9 the comparison between numerical and
analytic approaches to obtain the functional relationship between @xmath
. Due to the apparently excellent agreement between the two calculations
in Fig. 4.9 we can be confident in Eq. ( 4.70 ) as a reliable formula to
extrapolate to large @xmath .

We further note that one may derive the equilibration timescale for each
field dimension @xmath for the @xmath potential, and this is
approximately be given by

  -- -------- -- --------
     @xmath      (4.71)
  -- -------- -- --------

The first relation of Eq. ( 4.71 ) can be derived from Eq. ( 4.66 ) (see
also Refs. [ 58 , 167 , 156 ] ), where it is also natural to consider
the ‘steepness’ of the effective potential in Eq. ( 4.65 ) to control
the rate of equilibration. Note that Eq. ( 4.71 ) has been derived by
assuming the stationary variance, however, because @xmath is precisely
the time it takes to relax to the stationary limit, this assumption is
not strictly valid and requires comparison with full numerical
solutions. Interestingly, in the example with @xmath plotted in Fig. 4.8
, Eq. ( 4.71 ) appears to perform well regardless of its less
trustworthy origin.

#### 4.9.2 The decoupling limit

We will now investigate another limit of the inter-field coupling, which
can also be analytically estimated for some specific potentials and the
numerical verification will also serve to showcase further applications
of the nfield code.

Consider two further examples of interacting spectator potentials

  -- -------- -------- -- --------
     @xmath   @xmath      (4.72)
     @xmath   @xmath      (4.73)
  -- -------- -------- -- --------

@xmath a generalisation from @xmath by introducing additional masses
@xmath and @xmath , with a hierarchy parameter @xmath , but we have now
specified that @xmath to capture the essential phenomenology. @xmath is
another generalisation from @xmath to include self-interactions. We note
here that, in each case, decoupling the system in the limit where @xmath
will yield the well-known formulae [ 58 , 167 , 156 ] for the stationary
variance of each non-interacting field (see Eq. ( 4.67 ))

  -- -------- -------- -- --------
     @xmath   @xmath      (4.74)
     @xmath   @xmath      (4.75)
     @xmath   @xmath      (4.76)
     @xmath   @xmath      (4.77)
  -- -------- -------- -- --------

In this same limit one can also obtain the respective equilibration
timescales

  -- -------- -------- -- --------
     @xmath   @xmath      (4.78)
     @xmath   @xmath      (4.79)
     @xmath   @xmath      (4.80)
     @xmath   @xmath      (4.81)
  -- -------- -------- -- --------

where we recall that the effective masses @xmath are defined in Eq. (
4.64 ). We note there that, as in Eq. ( 4.71 ), these timescales have
been derived using the stationary form of the variances which is not
strictly valid, hence they must be checked for validity against the
numerical implementation to ensure that they are still accurate.

A ‘decoupling’ value of @xmath can be derived analytically from these
stationary variances by obtaining the value of @xmath above which the
main contribution to the effective mass is from the coupling term @xmath
and not from the bare mass or self-interaction. Looking at the effective
mass of either of the fields in each potential, one can hence show that
in the stationary limit

  -- -------- -------- -- --------
     @xmath   @xmath      (4.82)
     @xmath   @xmath      (4.83)
  -- -------- -------- -- --------

If one were to re-derive Eq. ( 4.82 ) and Eq. ( 4.83 ) by replacing
@xmath , it is trivial to show that the same formulae are obtained.

If @xmath and @xmath however, then neither the equations above, nor the
symmetry of @xmath , can be exploited for analytic calculations and
hence one must rely upon the numerically evaluated solution in order to
study the system. In Fig. 4.10 and Fig. 4.12 we plot these numerical
solutions (and their corresponding effective masses in Fig. 4.13 and
Fig. 4.14 ) given some specific values of @xmath for both fields in the
quadratic and quartic potentials, respectively. The variances are all
initialised with @xmath and hence the number of @xmath -folds it takes
for each solution to reach the effectively decoupled stationary values
(dotted horizontal lines in the relevant colour using Eqs. ( 4.74 ), (
4.75 ), ( 4.76 ) and ( 4.77 )) is well-approximated by the analytic
relaxation timescales derived in Eqs. ( 4.78 ), ( 4.79 ), ( 4.80 ) and (
4.81 ) (depicted with vertical dotted lines in the relevant colour) in
cases where @xmath (the top row plots of both sets of Figs.). In all
plots, one can also clearly see the strong deviation from the decoupled
predictions with larger values of @xmath , which highlights the
importance for a numerical solution from nfield in this large regime of
parameter values to obtain the correct equilibrium as well as
out-of-equilibrium behaviour.

#### 4.9.3 Non-vanishing probability currents

In Fig. 4.10 there is also an important anomaly which appears to be
repeated in Fig. 4.12 . In both figures we have also provided (dashed
horizontal lines) an alternative calculation for the stationary variance
using the numerically calculated second moment of Eq. ( 4.60 ). There is
generally excellent agreement between this solution and the one obtained
from the many realisations of Eq. ( 4.56 ) in nfield for @xmath ,
however these no longer agree precisely when @xmath in both sets of
plots. This deviation has been checked for numerical robustness by
increasing the number of Langevin realisations to @xmath and altering
the initial conditions — see Fig. 4.11 for illustration.

We are left with the interesting conclusion that for a sufficiently
large coupling @xmath , and an asymmetric potential induced by the mass
hierarchy parameter @xmath , Eq. ( 4.60 ) is no longer sufficient to
describe the stationary probability distribution. In Sec. 4.8 we
conjectured that Eq. ( 4.60 ) is the stationary solution for symmetric
potentials (here when @xmath ). However, when @xmath , since only the
divergence of the probability current @xmath must vanish and not its
curl @xmath , Eq. ( 4.60 ) is no longer the true stationary solution and
hence the solution must be elucidated through full numerical evaluation
of either Eq. ( 4.56 ) or Eq. ( 4.57 ). We have plotted @xmath for
different choices of parameter in Fig. 4.15 and Fig. 4.16 , where one
can see in particular that the only component of @xmath is much larger
when @xmath is increased for the @xmath cases plotted in Fig. 4.16 . As
a further numerical check, we have verified that when the symmetry of
the potential is restored ( @xmath ) in Fig. 4.15 , the curl vanishes up
to some numerical noise.

Note that @xmath also vanishes at the origin in both Fig. 4.15 and Fig.
4.16 . This is confirmed by the analytic expression in Eq. ( 4.62 ), in
which the curl is indeed vanishing at the extrema @xmath .

### 4.10 Conclusions

The typical field value acquired by spectator fields during inflation is
an important parameter of many post-inflationary physical processes.
Often, in slow-roll inflationary backgrounds, it is estimated using the
stochastic equilibrium solution in de Sitter space-times ( 4.3 ), since
slow roll is parametrically close to de Sitter. However, slow roll only
implies that the Hubble scale @xmath varies over time scales larger than
one @xmath -fold. Since the relaxation time of a spectator field
distribution towards the de Sitter equilibrium is typically much larger
than an @xmath -fold, this does not guarantee that the spectator
distribution adiabatically tracks the de Sitter solution. In practice,
we have found that when the inflaton potential is monomial everywhere,
the de Sitter approximation is never a reliable estimate of the
spectator typical field value at the end of inflation. Instead,
spectator fields acquire field displacements that depend on the details
of both the spectator potential and the inflationary background. These
results are summarised in table 4.1 .

In some cases, the existence of an adiabatic regime at early times leads
to an erasure of initial conditions and the spectator field distribution
is fully determined by the microphysical parameters of the model. When
this is the case, we have shown that spectator fields always acquire
sub-Planckian field values at the end of inflation (even when the
spectator is dominated by a non-minimal coupling term). However, it can
also happen that adiabatic regimes either do not exist or take place at
a stage where quantum corrections to the inflaton dynamics are large and
our calculation does not apply. In such cases, a dependence on the
initial conditions is unavoidable if the inflaton dynamics are indeed
dominated by quantum corrections, which we have quantified in the
context of information theory. This suggests that observations might
have the potential to give access to scales beyond the observable
horizon, through processes that are integrated over the whole
inflationary period, such as spectator field displacements.

In general, we have found that light spectator fields acquire much
larger field displacements during inflation than the de Sitter
approximation suggests, which has important consequences. As an
illustration, let us mention one of the curvaton models which is
favoured by observations, where inflation is driven by a quartic
potential in the presence of a quadratic spectator field, the curvaton,
that later dominates the energy budget of the Universe and provides the
main source of cosmological perturbations. In order for this model to
provide a good fit to the data, the field value of the curvaton at the
end of inflation should lie in the range [ 133 , 134 ] @xmath , where
@xmath and @xmath are the decay rates of the inflaton and of the
curvaton, respectively. In this case however, we have found that if
inflation starts from the eternal inflation regime, then the curvaton
typically acquires a super-Planckian field value at the end of
inflation, which challenges this model, at least in its simplest form.
As shown in this section, possible solutions could be to add either
quartic coupling or non-minimal coupling terms to the curvaton
potential, or to consider axionic curvaton potentials. Whether the model
is still in agreement with the data in this case is an important
question that we plan to study in a future work.

In this chapter we have also demonstrated the usefulness of numerical
solutions in order to evaluate the variances of multiple light coupled
fields during inflation. In doing so we have identified a lower limit
@xmath in some example two-field potentials on the coupling @xmath , for
interactions of the form @xmath , below which the fields may be
considered as effectively decoupled and the standard formulae for
stationary variances may be used. We have further verified that for
choices of @xmath , the analytic decoupling approximation for the
variances breaks down. In such situations, the solutions from either
evaluating the moments of Eq. ( 4.60 ) (Eqs. ( 4.72 ) and ( 4.73 ),
stable in the stationary limit when the potential is either symmetric
@xmath or decoupled @xmath ) or full numerical solutions (for all
potentials and generic initial conditions) are the methods to obtain
correct values.

In Sec. 4.8 we have given a general argument as to why it is possible
for Eq. ( 4.60 ) to still remain stable for some symmetric potentials
due to vanishing of the probability current everywhere in the domain.
Conversely, we have shown that by breaking the symmetry in the potential
(e.g. @xmath in Eqs. ( 4.72 ) and ( 4.73 )) the form of Eq. ( 4.60 ) may
no longer be stable as a solution to the stationary behaviour of the
multi-spectator system. We have supported these conclusions with the
numerically obtained figures provided in Sec. 4.9.2 and Figs. 4.15 and
4.16 .

A simple generalisation for future work may be to check how this limit
changes as the number of coupled fields @xmath is increased, where we
anticipate that because increasing @xmath typically increases the
contribution from the coupling to the effective mass of each field, the
lower limit on @xmath should decrease in order to compensate. Due to the
complexity of such a system, a numerical scheme such as the one we have
developed in this chapter ¹⁶ ¹⁶ 16 One can go to the following
repository to access the code: https://github.com/umbralcalc/nfield . (
nfield ) will likely be required for such an extension.

By considering an arbitrary @xmath in the symmetric potential of Eq. (
4.68 ) we have also discovered a critical value for @xmath that varies
@xmath (see Eq. ( 4.70 ) for a more precise form) above which the
formation of stationary spectator condensates collapses to the Hubble
rate. For values of @xmath , we cannot yet precisely say that the
formation of stationary condensates in such a potential is suppressed
(as it is when increasing @xmath up to this point) because this
phenomenon results from the effective mass @xmath of each field reaching
@xmath . At this point the mode functions which source the fluctuations
of the field can no longer be accurately described by the simple form of
noise correlator in the definition of Eq. ( 4.56 ), and hence the
stochastic formalism cannot be exactly trusted when @xmath . It is known
[ 177 , 178 , 179 ] , however, that the suppression may be further
enhanced when @xmath — assuming that @xmath is constant — and so we
anticipate that further (perhaps fully QFT-theoretic) computations to
include a field-dependent effective mass in future work may support our
current conjecture beyond this point.

## Appendix 4.A Statistical moments of quadratic spectators

In this section, we derive the first two statistical moments of
quadratic spectator fields, for which @xmath . If the initial
distribution is Gaussian, it remains so throughout the entire evolution
so these two moments fully characterise the distribution at any time.
Otherwise, higher-order moments can be derived along the same lines.

The first moment can be obtained by taking the stochastic average of
Eq. ( 4.1 ), which gives rise to

  -- -------- -- --------
     @xmath      (4.84)
  -- -------- -- --------

In this expression, the fact that @xmath is a test field plays an
important role since it implies that @xmath does not depend on @xmath
and is thus a classical (i.e. non-stochastic) quantity. Interestingly,
Eq. ( 4.84 ) is the same as Eq. ( 4.1 ) in the absence of quantum
diffusion, which is why @xmath follows the classical dynamics

  -- -- -- --------
           (4.85)
  -- -- -- --------

where @xmath is the value of @xmath at the initial time @xmath .

The second moment can be obtained by multiplying Eq. ( 4.1 ) by @xmath
and taking the stochastic average, which leads to

  -- -------- -- --------
     @xmath      (4.86)
  -- -------- -- --------

where @xmath needs to be calculated separately. This can be done by
noticing that a formal solution to Eq. ( 4.1 ) is given by

  -- -------- -- --------
     @xmath      (4.87)
  -- -------- -- --------

where @xmath is an integration constant. This gives rise to

  -- -------- -------- -- --------
     @xmath               
              @xmath      
              @xmath      (4.88)
  -- -------- -------- -- --------

where the factor @xmath comes from the fact that the delta function is
centred at one of the boundaries of the integral (recall that @xmath ).
One can then write Eq. ( 4.86 ) as

  -- -------- -- --------
     @xmath      (4.89)
  -- -------- -- --------

This equation can be solved and one obtains

  -- -------- -- --------
     @xmath      (4.90)
  -- -------- -- --------

In this expression, @xmath is an integration constant that can be solved
requiring that @xmath at the initial time @xmath . This gives rise to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.91)
  -- -------- -------- -- --------

In this expression, the structure of the first term is similar to the
first moment ( 4.85 ), so that the variance of the distribution @xmath
evolves according to the same formula as the second moment (i.e. one can
replace @xmath by @xmath in Eq. ( 4.A ) and the formula is still valid).

## Appendix 4.B Adiabatic solution for quartic spectators

For quartic spectator fields, the Langevin equation is not linear
anymore and cannot be solved analytically. In this section we provide a
solution using the ansatz

  -- -------- -- --------
     @xmath      (4.92)
  -- -------- -- --------

This ansatz is satisfied by the de Sitter equilibrium ( 4.3 ), so we
expect the solution to be valid at least in the adiabatic regime and
potentially beyond. By plugging Eq. ( 4.92 ) into Eq. ( 4.2 ), one
obtains

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.93)
  -- -------- -------- -- --------

Multiplying this equation by @xmath and integrating over @xmath , this
gives rise to

  -- -- -------- -- --------
        @xmath      
        @xmath      (4.94)
  -- -- -------- -- --------

From the ansatz ( 4.92 ), the moments @xmath , @xmath , @xmath and
@xmath are directly related to @xmath , through

  -- -------- -- --------
     @xmath      (4.95)
  -- -------- -- --------

By substituting these expressions into Eq. ( 4.94 ), one obtains

  -- -------- -------- -- --------
     @xmath   @xmath      (4.96)
  -- -------- -------- -- --------

Notice that if one had directly integrated Eq. ( 4.93 ) over @xmath and
substituted Eq. ( 4.95 ), one would have obtained a trivial
relationship, which is why we first multiplied Eq. ( 4.93 ) by @xmath
before integrating over @xmath .

If the inflaton potential is of the plateau type and @xmath can be
approximated by a constant, this equation can be solved and one finds

  -- -------- -- --------
     @xmath      (4.97)
  -- -------- -- --------

which gives rise to Eq. ( 4.33 ) for the second moment @xmath .

If the inflaton potential is monomial, the function @xmath is given by
Eq. ( 4.6 ) and although an analytical solution still exists, it is less
straightforward to derive. The first step consists of writing Eq. ( 4.96
) in terms of an equation for @xmath using Eq. ( 4.95 ),

  -- -------- -- --------
     @xmath      (4.98)
  -- -------- -- --------

The next step is to use @xmath as a time variable, which gives rise to

  -- -------- -- --------
     @xmath      (4.99)
  -- -------- -- --------

This equation is of the Ricatti type and can be transformed into a
second-order linear differential equation making use of the change of
variables

  -- -- -- ---------
           (4.100)
  -- -- -- ---------

By plugging Eq. ( 4.100 ) into Eq. ( 4.99 ), one obtains

  -- -------- -- ---------
     @xmath      (4.101)
  -- -------- -- ---------

This equation can be solved in terms of modified Bessel functions of the
first kind @xmath . Making use of Eq. ( 4.100 ), the solution one
obtains gives rise to

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (4.102)
  -- -------- -------- -- ---------

where we have defined

  -- -------- -- ---------
     @xmath      (4.103)
  -- -------- -- ---------

where @xmath is an integration constant that can be set as follows: In
the asymptotic past, @xmath and the Bessel functions can be expanded in
this limit, @xmath . Unless @xmath , the term inside square brackets in
Eq. ( 4.B ) goes to @xmath and one finds @xmath which would not be
consistent. As a consequence, @xmath is the only choice that allows the
solution ( 4.B ) to be defined over the entire inflationary period.
Setting @xmath , Eq. ( 4.B ) can be simplified and one obtains

  -- -------- -- ---------
     @xmath      (4.104)
  -- -------- -- ---------

where @xmath is the modified Bessel function of the second kind.

## Appendix 4.C Numerical implementation

Few analytic solutions to either Eq. ( 4.56 ) or Eq. ( 4.57 ) for @xmath
are known to exist, except in the stationary limit of various cases, as
given in Eq. ( 4.60 ). A robust method for numerical evaluation of a
coupled system of Langevin equations of the form in Eq. ( 4.56 ) is the
modified Improved Euler scheme, introduced in LABEL:2012arXiv1210.0933R
, where it is also proven to exhibit strong first-order convergence. Due
to the more complicated potentials studied, a relatively simple
implementation of this scheme was developed for the numerical solutions
obtained in this section.

The code is written in the python language and achieves runtimes of
@xmath 5-10 minutes on a standard netbook laptop for @xmath realisations
of with any potential up to @xmath for @xmath @xmath -folds. For
increased performance, e.g. @xmath or more, then it is advised to use a
computer cluster. The code has also been made publicly available at the
following repository: https://github.com/umbralcalc/nfield . The
repository also contains an example script with 5 fields to help the
user get started.

In Fig. 4.15 and Fig. 4.16 we have plotted some binned realisations of
Eq. ( 4.56 ) that are used in the code. These plots can also serve as a
useful tool to test for numerical convergence, e.g. to check that no
arbitrary asymmetry has appeared or if the divergence of the probability
current has not vanished due to elevated numerical noise. In such
instances, the code may simply be rerun with more realisations to ensure
convergence. Even though @xmath realisations were used for these plots,
numerical noise (and noise from a finite number of samples) still
appears for those values of @xmath and @xmath which are meant to vanish.
Up to this noise amplitude, however, a strong signal can still be seen
in @xmath for the @xmath potential in Fig. 4.16 , and we leave further
improvements to these visualisations for future work.

## Chapter 5 Probing inflation with extra fields

Abstract. In this chapter we shall use the initial conditions derived
from Chapter 4 to compute observable predictions. In detail, we argue
that spectator field condensates represent a sensitive probe of the
entire inflationary potential [ 183 ] and demonstrate this through two
explicit examples of post-inflationary physics: freeze-in dark matter,
which is shown to constrain the energy scale of inflation [ 184 ] ; and
the curvaton model, which can constrain the number of inflationary
@xmath -folds [ 185 ] .

### 5.1 ‘A quantum window’

If inflation is driven by a single scalar field @xmath with potential
@xmath , the power spectrum of curvature perturbations @xmath at scale
@xmath , given in Eq. ( 1.64 ), is

  -- -- -- -------
           (5.1)
  -- -- -- -------

where @xmath is the value of @xmath when @xmath exits the Hubble radius.
The range of scales probed e.g. in the CMB then translates into a time
interval during inflation of length @xmath , measured by the number of
@xmath -folds @xmath . If one includes the large-scale structure of our
Universe, this window is extended but cannot exceed the last @xmath
@xmath -folds of inflation. But can we ever learn about larger scales,
hence earlier times?

As discussed at length in Sec. 1.2.3 and Chapter 4 , during inflation,
the coarse-grained fields (i.e. scales larger than the Hubble radius)
are constantly sourced by the small-wavelength quantum fluctuations as
they cross the Hubble radius. This quantum backreaction on the dynamics
of the Universe can be modeled through the stochastic inflation
formalism [ 58 ] . The system then explores parts of the potential that
would be inaccessible under the classical dynamics. For example, the
power spectrum ( 5.1 ) is now computed by Eq. ( 1.90 ) such that

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (5.2)
  -- -------- -------- -- -------

Contrary to Eq. ( 5.1 ), this expression does not only depend on the
potential evaluated at @xmath , but relies on the properties of the
potential in the entire inflationary domain. For this reason, even the
limited range of scales probed in the CMB may contain imprints from
early features of the inflationary dynamics and in this sense, quantum
diffusion in an expanding background greatly extends the observational
window. In practice, when @xmath , Eq. ( 5.2 ) is well approximated by
Eq. ( 5.1 ) so the dependence on the potential function outside the
standard observational window is usually Planck suppressed. This is
however not the case when several fields drive inflation [ 63 , 64 , 186
] , or in very flat regions of the potential that can drive the dynamics
at smaller (but still accessible [ 187 ] ) scales than the ones probed
in the CMB.

Another, less direct but more sensitive, cosmological probe sensitive to
the early stages of inflation through quantum diffusion is the field
displacement acquired by spectator fields [ 167 , 188 , 156 ] . Let us
consider the toy model depicted in Fig. 5.1 where the inflaton potential
@xmath is made of a plateau (i.e. asymptotically constant) part between
@xmath and @xmath and a monomial large-field (i.e. @xmath ) part at
@xmath . The equation for such a potential would be

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where, in this expression, @xmath such that the potential is of the
plateau type when observable scales leave the Hubble radius.
Observations of the CMB constrain the potential to be of the plateau
type in the last few @xmath -folds of inflation [ 36 ] so in the
standard setup, the only constraint one has is that @xmath should be
located at least @xmath @xmath -folds before the end of inflation.

A spectator field @xmath on top of this inflationary background evolves
under its potential @xmath and according to Eq. ( 4.1 ) (where @xmath is
to be replaced by @xmath ). If @xmath is constant, the probability
distribution @xmath relaxes towards the de Sitter equilibrium solution
of Eq. ( 4.3 ), where any initial condition is erased. However, as we
demonstrated in Chapter 4 , this does not always happen on the
large-field part of the inflationary potential, since the relaxation
time towards Eq. ( 4.3 ) can be larger than the variation time scale of
@xmath there. For example, if the spectator potential is quadratic,
@xmath , Eq. ( 4.3 ) can never be attained in the early phase of
large-field evolution where the typical field displacement remains
strongly dependent on initial conditions. By setting @xmath at the exit
point of eternal inflation (where the dynamics of @xmath is itself
dominated by stochastic corrections), one can derive a lower bound on
the number of @xmath -folds @xmath spent on the plateau part of the
inflaton potential using Eqs. ( 4.12 ) and ( 4.21 ) so that the details
of the large-field phase are erased from the distribution of @xmath at
the end of inflation [ 156 ] ,

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

for @xmath . It is displayed in the left panel of Fig. 5.2 for @xmath
(but the result depends only mildly on @xmath ). Compared to the
standard constraint @xmath , one can see that the observational window
on the inflaton potential extends by orders of magnitude. In Chapter 4
we also found that for a quartic spectator @xmath , Eq. ( 4.3 ) is
adiabatically tracked at early time in the large-field phase. In this
case, initial conditions on the spectator field displacement can be
erased during this adiabatic epoch, and, using Eqs. ( 4.33 ) and ( 4.38
), the minimal number of @xmath -folds spent on the plateau such that no
imprint is left from the large-field epoch on the distribution of @xmath
at the end of inflation is given by [ 156 ]

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

for @xmath . It is displayed in the right panel of Fig. 5.2 where one
can see again that the observational window on the inflaton potential
extends by orders of magnitude.

Thus the quantum dynamics of cosmological fields in the early Universe
gives access to a vast range of scales that extend the classical window
by orders of magnitude and allow us to explore high-energy gravity
beyond the observable horizon.

### 5.2 Freeze-in dark matter

Amongst the parameters that are relevant to inflationary perturbations,
two have been measured: the amplitude of the curvature power spectrum,
@xmath , and the corresponding spectral tilt, @xmath (given for
classical single field slow-roll evolution by Eq. ( 1.64 ) and Eq. (
1.65 ), respectively), which the Planck collaboration have recently
measured to an accuracy of @xmath and @xmath [ 189 ] . However, the
energy scale at which inflation — or more accurately, the last @xmath
@xmath -folds of inflation — happened is still unknown. The energy scale
of inflation can be characterised by the value of the Hubble parameter
during inflation, @xmath . In single-field slow-roll models of
inflation, this can be expressed by the primordial tensor-to-scalar
ratio @xmath by rewriting Eq. ( 1.70 ) as

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

The current upper bound provided by the joint analysis of BICEP2/Keck
Array and Planck data is @xmath ( @xmath c.l.) [ 22 , 189 ] , whereas no
strict lower bound exists other than the requirement for realising
successful BBN at @xmath MeV [ 190 , 191 , 192 , 193 ] . Hence, there is
a huge gap between the scales at which the dynamics of the Universe is
understood. It is elementary then, and of great importance to
understanding the physics between these scales, to quantify how large
the gap is.

The next-generation experiments may be able to push the upper bound for
the tensor-to-scalar ratio down to @xmath from BICEP3 [ 194 ] and @xmath
from LiteBIRD [ 195 ] or COrE [ 196 , 197 ] , or any of these may detect
it above these limits. However, these numbers illustrate that if no
detection is made, even in the best possible case the planned
experiments cannot determine the inflationary scale by primordial tensor
modes if it was smaller than @xmath GeV. It would therefore be
interesting if one could find scenarios in which the inflationary scale
could be determined by other means. This will be our aim in the next few
sections.

Based on Refs. [ 198 , 199 , 200 ] , we present a scenario where the
scale of inflation @xmath is determined by three observables: the dark
matter (DM) isocurvature perturbation amplitude, its mass and
self-coupling constant. This determination is made completely
independently of the tensor-to-scalar ratio @xmath , increasing the
range in @xmath that one can infer to values for the inflationary scale
well below the current lower bound, or below the sensitivity of the
next-generation experiments. Furthermore, we find that in this scenario
the inflationary scale can be determined almost solely from the
spectator field dynamics discussed in Chapter 4 .

As a representative example of this kind of scenario, we study a generic
real singlet scalar extension to the SM. The new singlet scalar particle
is a Feebly-Interacting Massive Particle (FIMP) [ 201 , 202 , 203 ] ,
which we assume to constitute the DM abundance. Due to a feeble coupling
between the singlet scalar and the SM sector, the singlet never
thermalises with the SM and the DM abundance is produced by the
“freeze-in” mechanism instead of the standard freeze-out. We discuss
this in detail throughout the following sections.

We begin by presenting a simple version of the scenario where the energy
scale of inflation can be determined without measuring the
tensor-to-scalar ratio. The model we consider is a minimal extension to
the SM Lagrangian, where in addition to the SM particle content there is
a @xmath -symmetric real singlet scalar, @xmath , coupled to the SM via
the Higgs portal [ 204 , 205 ]

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

In this expression, @xmath is the SM Lagrangian ¹ ¹ 1 Radiative
corrections in a curved background generate an extra term to the scalar
potential, @xmath , constituting of the non-minimal couplings to gravity
@xmath , @xmath of both the Higgs and singlet, respectively [ 174 , 175
] . For this scenario, we shall consider the case where the singlet has
negligible @xmath . The value of the SM Higgs non-minimal coupling to
gravity is not relevant for our purposes. and the SM Higgs doublet in
the unitary gauge is written as @xmath , where @xmath is the vacuum
expectation value of the Higgs field. We assume that the portal coupling
takes a small value ² ² 2 Note that this does not impose a fine-tuning
issue, as the running of the portal coupling is always very small in
this model [ 206 , 207 ] . , @xmath , so that the singlet @xmath does
not thermalise with the SM in the early Universe, but remains a FIMP DM
candidate [ 201 , 202 ] . The @xmath particles can constitute all the DM
if the Higgs field can produce sufficient number of @xmath particles
from Higgs decay after electroweak symmetry breaking or, if the decay is
not kinematically allowed, if Higgs-mediated gauge boson annihilations
into @xmath particles are frequent enough [ 201 , 208 , 203 ] . For the
basic scenario, the exact production mechanism is not relevant, and we
will discuss the low-energy dynamics in more detail in Sec. 5.3.3 .

Let us see how to determine the scale of inflation with the known
behaviour of spectator fields during inflation. During inflation, if
@xmath is a spectator, it approaches the de Sitter equilibrium
distribution [ 58 ] characterised by @xmath for a sufficiently
slowly-varying Hubble rate [ 167 , 209 , 156 ] , with a typical value
obtained from Eq. ( 4.30 )

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

In deriving Eq. ( 5.8 ) we require that the quartic terms in the scalar
potential dominate over the quadratic ones, @xmath ; we will verify that
this is always the case in Sec. 5.3.1 .

Both the Higgs and @xmath field fluctuations represent isocurvature
perturbations relative to the adiabatic inflaton perturbations during
inflation ³ ³ 3 Unless one of them is the inflaton, but in this chapter
we do not consider this possibility. . Soon after inflation the Universe
becomes radiation-dominated; once the Hubble rate drops below their
effective mass the fields start to oscillate about their minima. The
Higgs field then decays into radiation quickly, typically within a few
@xmath -folds [ 210 ] , reaching thermal equilibrium and thus leaving
only adiabatic perturbations in the SM radiation. However, due to the
feeble coupling between the singlet scalar and the SM, the @xmath
condensate (denoted by @xmath from now on) does not thermalise and
therefore its fluctuations remain isocurvature perturbations relative to
the adiabatic perturbations of the SM radiation. Even though the @xmath
condensate is assumed not to decay into SM radiation, the condensate may
fragment into @xmath particles which eventually become cold
(non-relativistic) DM particles and inherit the primordial isocurvature
perturbations from the condensate. This happens if @xmath is large
enough, so that the @xmath condensate fragments while still in an
effectively quartic potential [ 198 , 199 ] , and this condition will be
carefully checked in Sec. 5.3.2 . We sketch the main sequence of events
for this scenario in Fig. 5.3 .

The CMB constraint on DM isocurvature matter perturbations (over @xmath
) can thus be expressed as an upper bound on the DM energy density
sourced by the @xmath condensate as [ 199 ]

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

where @xmath and @xmath are the isocurvature and adiabatic contributions
to the DM density evaluated at last scattering of the CMB at @xmath eV —
that is, in our case, the @xmath particle DM sourced by the primordial
@xmath condensate and Higgs decays, respectively. In this expression,
@xmath is the primordial curvature power spectrum [ 189 ] , @xmath is
the primordial isocurvature power spectrum and @xmath is the
isocurvature parameter constrained by the Planck data [ 2 ] . We require
that the Higgs decays into @xmath particles dominate over the DM yield
from the primordial @xmath condensate.

By assuming that the comoving number densities of the singlet scalars
produced by the decay of the primordial @xmath condensate and Higgs
decays are separately conserved, and together constitute all of the
observed DM, @xmath , where @xmath is the reduced Planck mass, one finds
that [ 199 ]

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

In this expression, @xmath parametrises the Hubble parameter today,
@xmath is the dimensionless photon density parameter today and @xmath is
the spectator field value during the last 60 @xmath -folds of inflation
(where it remains effectively constant).

By then using the typical value for @xmath given by Eq. ( 5.8 ), one
obtains

  -- -- -- --------
           (5.11)
  -- -- -- --------

and we can determine the Hubble scale to be

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.12)
  -- -------- -------- -- --------

given our previously outlined assumptions, where for the second line we
have used @xmath , @xmath and @xmath [ 189 ] . This result for @xmath
then allows one to determine the energy scale of inflation independent
of the inflationary tensor perturbations.

The value obtained for @xmath , and the corresponding value for the
tensor-to-scalar ratio @xmath , are shown in Fig. 5.4 . The constraints
on the DM self-interaction cross-section from observations of
small-scale structure, namely the Bullet Cluster, have been
superimposed. Indeed, in the limit where the singlet mass is much
smaller than the Higgs mass, @xmath , the singlet scalar
self-interaction cross-section divided by its mass is given by [ 211 ]

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

where the upper bound applies when the @xmath particles constitute all
DM. The exclusion zone that would be obtained from more stringent
constraints on @xmath is also displayed, in order to assess how
parameter space could be even more reduced by improving the constraints
on, or by measuring, the DM self-interaction cross-section. The result
is not displayed in the grey region either, since it corresponds to
values of the parameters for which fragmentation does not occur in the
part of the potential dominated by the quartic term, and our calculation
does not apply.

As shown in Appendix 5.A the result is valid for @xmath , and for @xmath
keV because, otherwise, the @xmath particle DM is too hot and suppresses
structure formation [ 212 ] . As discussed above, we also require @xmath
, as otherwise the singlet sector would thermalise with the SM sector
and the primordial isocurvature perturbations would be washed away,
@xmath . Furthermore, despite the fact that the primordial singlet
condensate yields only a subdominant contribution to the total DM
abundance, the SM particle decays and annihilations can produce the rest
of the DM abundance. This amounts to choosing a sufficiently large value
for @xmath , which for @xmath GeV is roughly @xmath [ 208 , 198 , 199 ,
200 ] . The exact value, however, is not relevant for the minimal
scenario (but will be in the extended one).

As discussed in Refs. [ 198 , 199 , 200 ] , the above result for @xmath
in Eq. ( 5.12 ) is a generic consequence of a model where the additional
scalar field is light and energetically subdominant during inflation and
does not thermalise with the SM radiation after it. The result, however,
is subject to a number of uncertainties related to dynamics in the
inflaton sector, reheating history, and low-energy dynamics. We
carefully consider these in the next section.

### 5.3 Freeze-in: extended scenario

Due to uncertainties in the inflationary dynamics, reheating history,
and low-energy dynamics, relaxing one or several assumptions we made
above introduces modifications to our result ( 5.12 ). For example, even
in slow-roll inflation, the Hubble rate may have a finite time
dependence during inflation and the typical field displacement acquired
by the spectator field at the end of inflation may change, or reheating
might have taken a finite time, which introduces an arbitrary expansion
history during which the primordial @xmath condensate grows its energy
density with respect to the background, leading to different DM
abundance today.

These modifications can be effectively parameterised in Eq. ( 5.12 ) as

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

where @xmath , @xmath , @xmath are effective correction coefficients
induced by inflationary dynamics, reheating history, and low-energy
dynamics, respectively. Their detailed effect will be discussed one by
one in the following subsections.

#### 5.3.1 Varying the inflationary dynamics

In this section we quantify the degree to which a finite time dependence
of the Hubble rate during the early stages of inflation, e.g. due to
large-field corrections, @xmath , to the inflaton potential, may affect
our result. As was shown in LABEL:Hardwick:2017fjo , the variance of
@xmath at the end of inflation can be significantly larger than that
given by Eq. ( 5.8 ) depending on whether the distribution for @xmath
has sufficient time to relax to the equilibrium distribution for a fixed
value of @xmath — the “adiabatic” regime in our terminology — or
whether, instead, the Hubble rate varies too fast (while still being in
the slow-roll regime) for the system to relax to the equilibrium
distribution. This can lead to a larger value for the variance than
would be expected for a given, constant value of @xmath .

In order to illustrate this effect, we shall consider a potential for
the inflaton field @xmath which interpolates between a plateau
potential, consistent with Planck constraints on the inflaton potential
when observable scales leave the Hubble radius [ 36 , 189 ] , and a
large-field model at early times when @xmath . This is the same
potential as Eq. ( 5.3 ) where we have also sketched it in Fig. 5.1 .

In both regimes we can identify the number of @xmath -folds associated
with two characteristic timescales: the relaxation timescale for the
@xmath field to relax to the equilibrium distribution for a quartic
potential from Eq. ( 4.34 ) is @xmath [ 167 , 156 ] , and the timescale
associated with a variation in the Hubble parameter is, as usual, @xmath
. Using these timescales, the effect of the inflationary background
evolution (i.e., the inflaton field rolling down in the potential ( 5.3
)) on the variance of @xmath can be divided into three phases:

1.  At early times in the large-field regime we know from Eq. ( 1.41 )
    that @xmath , and the @xmath field evolves adiabatically (hence the
    far-right label in Fig. 5.1 ) because its relaxation timescale is
    shorter than the timescale associated with the variation of the
    Hubble parameter of the background, @xmath .

2.  Still within the large field regime, the value of @xmath gradually
    increases and @xmath decreases over time until @xmath , at which
    point the evolution of @xmath ceases to be adiabatic and its
    variance effectively freezes in until the end of this phase [ 156 ]
    with a value we label @xmath .

3.  After the large-field regime ends, @xmath increases such that the
    condition @xmath is quickly fulfilled again. The @xmath field then
    begins to relax to its new equilibrium distribution on the plateau,
    but starting with an initial variance @xmath determined by the
    preceding large-field regime.

At the end of the large-field regime, the spectator field @xmath
acquires a typical field displacement given by [ 156 ]

  -- -- -- --------
           (5.15)
  -- -- -- --------

where we have used Eq. ( 4.38 ), @xmath has been defined in Eq. ( 5.3 )
and @xmath denotes the value of the Hubble parameter at the end of
inflation (which is of the same order as the one along the plateau). The
number of @xmath -folds that must be realised to reach the stationary
distribution ( 5.8 ) is given by @xmath . Therefore for the equilibrium
distribution Eq. ( 5.8 ) to be valid, we require a large number of
@xmath -folds on the plateau, @xmath .

The variance of the spectator field at the end of the plateau phase,
subject to the initial condition set by Eq. ( 5.15 ), can be written as

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

where @xmath defines the correction to Eq. ( 5.8 ) and is given by [ 183
]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.17)
  -- -------- -------- -- --------

where we have substituted Eq. ( 5.15 ) into Eq. ( 4.33 ), obtaining the
result by comparison with Eq. ( 5.16 ). Note that since @xmath (hence
@xmath ) appears in both sides of the last equality in Eq. ( 5.10 ),
through @xmath directly and through @xmath indirectly, see Eq. ( 5.11 ),
the power of @xmath in Eq. ( 5.16 ) indeed yields a factor @xmath in
Eq. ( 5.14 ).

The correction factor @xmath is displayed in Fig. 5.5 as a function of
the number of @xmath -folds spent on the plateau, @xmath , for several
values of @xmath and @xmath . One can check that when @xmath is
sufficiently large, @xmath , and that the number of @xmath -folds that
need to be spent on the plateau in order to erase the imprint of the
large-field early stage decreases with @xmath , in agreement with the
formula @xmath given above. The result is almost independent of @xmath .
Since at least @xmath @xmath -folds must be realised on the plateau, one
can check that @xmath is always of order one, so that the value of
@xmath computed from Eq. ( 5.14 ) is impacted by the large-field
corrections to the spectator field dynamics by at most an @xmath
constant. This is also illustrated in Fig. 5.6 , where @xmath is
displayed as a function of @xmath and @xmath taking @xmath , and where
the differences with Fig. 5.4 are very mild.

Finally, let us check that, as assumed in the above calculation, during
inflation the quartic term in the scalar potential dominates over the
quadratic one, @xmath . Using Eq. ( 5.16 ) to estimate @xmath in the
first condition @xmath , one obtains @xmath . In all following figures,
we make sure that this condition is always satisfied. Using a relation
similar to Eq. ( 5.16 ) to estimate @xmath in the second condition
@xmath , one obtains @xmath , where @xmath is the self-interaction
strength of the Higgs. As noted above, to prevent the singlet @xmath
from thermalising with the SM in the early Universe, one must have
@xmath , and since we assume @xmath [ 210 ] , the lower bound on @xmath
used in all figures is such that this condition is always satisfied too.

#### 5.3.2 Varying the reheating history

We now turn our attention to the second possible modification in Eq. (
5.14 ), namely the reheating expansion history. So far we have assumed
that after inflation, the energy density of the background decays as
radiation. If this is not the case, the abundance of DM obtained from
the particles into which the condensate fragments is different, hence
the inferred value of @xmath changes.

In Appendix 5.A we provide a detailed calculation of the energy density
contained in the singlet particles at the end of the multi-stage process
depicted in Fig. 5.3 , for an arbitrary background expansion history
between the end of inflation and the fragmentation time (for the result
we use about fragmentation rate to apply, the Universe needs to be in a
radiation era at the fragmentation time). We find that the result only
depends on the average equation-of-state parameter during the
oscillation phase of the condensate, @xmath , and on the quartic
coupling constant @xmath . More precisely, an analogous expression to
Eq. ( 5.10 ) is obtained,

  -- -------- -------- -- --------
     @xmath   @xmath      (5.18)
  -- -------- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

One can check that the power to which @xmath appears in Eq. ( 5.18 ) is
such that it appears with power one in Eq. ( 5.14 ). In this expression,
@xmath is a numerical constant that comes from the calculation of the
fragmentation rate. When @xmath , @xmath and Eq. ( 5.10 ) is recovered.
In Appendix 5.A , we also derive and carefully study the conditions
under which the assumptions made in the timeline of Fig. 5.3 are
satisfied. In particular, this results in the “no fragmentation”
exclusion zone in Figs. 5.4 , 5.6 , 5.8 and 5.11 .

The correction factor @xmath is plotted as a function of @xmath for a
few values of @xmath in Fig. 5.7 . Unlike the correction factor @xmath
in the preceding subsection, we see that @xmath can vary by many orders
of magnitude when @xmath departs from @xmath . This is also illustrated
in Fig. 5.8 , where @xmath is displayed as a function of @xmath and
@xmath taking @xmath , and where the difference with Fig. 5.4 is quite
large. There even are regions (in red) for which the predicted value of
the tensor-to-scalar ratio is too large to satisfy observational bounds
[ 148 ] .

One notices that if @xmath , @xmath and the inferred value of @xmath in
the minimal setup is smaller than the actual one, while if @xmath ,
@xmath and the inferred value of @xmath is larger than the actual one.
The large effect from the reheating expansion history on our estimate of
@xmath should be taken with a grain of salt since in practice, @xmath
may not depart too much from @xmath . At the end of the oscillating
phase indeed, one must have a background equation of state @xmath (for
our expression for the fragmentation rate in Eq. ( 5.38 ) to apply), so
@xmath receives a contribution from values close to @xmath . Let us also
note that linear instabilities on small scales have been shown to yield
@xmath very quickly after the end of inflation, in fact well before the
inflaton field has effectively decayed [ 213 ] . Such a mechanism would
yield @xmath , leaving no imprint from the reheating expansion history
on our result.

#### 5.3.3 Low-energy dynamics

In addition to corrections arising from dynamics during and immediately
after inflation, there are corrections arising from particle dynamics at
low energies, namely below the electroweak scale after the SM particle
decays and annihilations have yielded the initial @xmath particle
abundance. Contrary to the variations in the inflationary and the
reheating dynamics studied in Secs. 5.3.1 and 5.3.2 , respectively, the
low-energy dynamics effect is not a variation to the minimal setup but
rather an inevitable correction that is inherent to it. It should
therefore be understood as part of the minimal scenario.

Even though the portal coupling between DM and the SM sector is assumed
to be so small that the @xmath particles never enter thermal equilibrium
with the SM particles, it may happen that the @xmath particles reach
chemical equilibrium within the singlet sector if the singlet sector has
sufficient self-interactions. This leads to a characteristic hidden
sector temperature @xmath different from the SM photon temperature
@xmath . If the singlet self-interactions are sufficiently strong, they
can maintain the equilibrium for some time also after the singlet
particles have become non-relativistic, leading to so-called DM
cannibalism [ 214 ] , where number-changing interactions, such as @xmath
annihilations ⁴ ⁴ 4 The @xmath annihilations are in our case forbidden
due to the assumed @xmath symmetry of the scalar field. (see Fig. 5.9 ),
reduce the singlet particle number density and heat the singlet sector
with respect to the SM sector. Depending on the strength of singlet
self-interactions, the @xmath number density can be significantly
depleted before its final freeze-out from the equilibrium in the singlet
sector. Thus the final DM abundance depends not only on the portal
coupling @xmath and the mass @xmath , but on a combination of the
parameters @xmath , @xmath and @xmath . This production mechanism is
called dark or hidden freeze-out [ 214 , 215 , 216 , 200 , 217 , 207 ,
203 ] .

The main result ( 5.12 ) applies only if there are no number-changing
interactions in the singlet sector, i.e. if the quartic scalar
self-interaction strength @xmath is small enough. The critical value
above which the number-changing interactions play a significant role in
determining the final DM abundance is [ 200 ]

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

where @xmath is the effective number of relativistic degrees of freedom
in the SM plasma at temperature @xmath and @xmath is the value of the
portal coupling that yields the observed DM abundance for a given mass
@xmath in the usual freeze-in case. For @xmath the usual freeze-in
picture and the result ( 5.12 ) are sufficient. Recalling that we assume
@xmath in order for Eq. ( 5.13 ) to hold, the value of @xmath is
determined by the usual freeze-in relation [ 201 , 202 , 203 ]

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

If the number-changing interactions in the singlet sector become active,
the @xmath particles equilibrate among themselves before the formation
of the CMB. After the equilibration, the singlet scalar particles from
both origins — Higgs decays and primordial @xmath condensate
fragmentation — contribute to the thermal bath of DM, so that the
relative abundance of the isocurvature component with respect to the
total DM abundance remains constant from there on, as discussed in
LABEL:Heikinheimo:2016yds . We assume that the thermalisation of the
@xmath particles takes place at @xmath , which is the latest moment when
the @xmath particles can reach chemical equilibrium with themselves.

The abundances from the primordial isocurvature condensate source @xmath
and the adiabatic Higgs freeze-in source @xmath at the time of the
thermalisation can be found by scaling the result in Eq. ( 5.10 ) by
@xmath from the CMB temperature today, @xmath K, up to @xmath , and
scaling the usual freeze-in abundance of scalars by @xmath down to the
same temperature. The isocurvature abundance is [ 199 ]

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

where @xmath is the effective number of entropy degrees of freedom in
the radiation heat bath, and the usual freeze-in abundance of scalars is
[ 200 ]

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath and @xmath are the singlet scalar and Higgs number
densities, respectively, @xmath is the scale factor at the time the
photon temperature is @xmath , and where in the limit @xmath ,

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

To derive this expression, we have assumed that the @xmath particles
obey Maxwell-Boltzmann statistics after the electroweak symmetry
breaking, that the singlet scalars are produced by @xmath at @xmath ,
and that the thermalisation of scalars takes place no earlier than
@xmath .

Plugging Eqs. ( 5.22 ) and ( 5.3.3 ) into Eq. ( 5.9 ), and using Eq. (
5.11 ) as before, we then obtain

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

Because the result now depends explicitly on @xmath , its exact value
becomes important. As discussed above, we require that the singlet
particles constitute all DM, which allows us to fix @xmath in terms of
@xmath and @xmath , as shown in Appendix 5.B , see Eq. ( 5.59 ). This
gives rise to

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

The correction factor @xmath is plotted in Fig. 5.10 , where one can see
that the reduction in @xmath caused by variations in the low-energy
dynamics is at most of order @xmath .

The corresponding effect on @xmath is shown in Fig. 5.11 . In the grey
region over the top right hand side of the plot shown in Fig. 5.11 , the
dark freeze-out occurs while the singlet particles are still
(semi-)relativistic, @xmath , and finding a solution that yields the
correct DM abundance in that region requires a detailed numerical
analysis, as discussed in LABEL:Heikinheimo:2016yds . We will postpone
that for future work. Above the grey region the freeze-out occurs at
temperatures where the DM is non-relativistic, @xmath , and below this
region the singlet particles do not thermalise within the singlet sector
and the usual freeze-in picture is sufficient. In general,
thermalisation of the singlet sector increases the number density of the
@xmath particles, resulting in a larger final DM abundance than in the
standard freeze-in scenario, and in order to produce the observed DM
abundance, a smaller initial abundance sourced by the SM particles is
needed. Thus, an initial population of scalars produced from the decay
of the primordial @xmath condensate contributes a larger fraction of the
total DM energy density than it would in the standard freeze-in
scenario, and hence the isocurvature contribution is larger. Thus, to
keep the ratio ( 5.9 ) constant for fixed @xmath , a smaller value for
@xmath , i.e. a smaller value for @xmath , is needed. This explains why
the correction factor @xmath is always less than @xmath .

### 5.4 The duration of inflation with a curvaton

The overall duration of inflation is not generally known, however, we
have seen already in this chapter how one way to circumvent this cosmic
amnesia is through spectator fields [ 183 , 185 ] , whose field
displacements are sensitive to a much longer phase of the inflationary
epoch and which can be observationally accessible [ 154 ] .

Since current CMB measurements are compatible with single-field models
of inflation (if the potential is of the plateau type) [ 2 , 35 , 36 ] ,
such extra fields may not be directly required by the data. It is of
course always possible to fit the data with complex multi-field
inflationary models, but the amount of fine tuning required in these
models may be large, which is why models should be compared in a
Bayesian framework (building from Chapter 2 ) that correctly accounts
for the quality of the fit and the waste of parameter space.

The questions we will seek to answer in the remaining sections of this
chapter are therefore: Are there multiple-field models of inflation that
are as favoured by the data as single-field plateau inflation from a
Bayesian perspective? What insight can be gained on the inflationary
history in these models?

We will investigate these questions with the curvaton model, whose
potential is given by Eq. ( 1.99 ). We outlined the general model in
Sec. 1.3.1 , however we shall briefly review it here for context.

After inflation, the inflaton field decays into radiation and the energy
density contained in the curvaton field, @xmath , may grow relative to
the background energy density, until it also decays into radiation.
Assuming that no isocurvature perturbations persist [ 77 , 78 , 79 ] ,
the total adiabatic power spectrum is given by combining Eq. ( 1.100 )
and Eq. ( 1.101 ). Observations are also often discussed in terms of the
spectral index @xmath and the tensor-to-scalar ratio @xmath in Eq. (
1.104 ). When the primordial density perturbation is entirely due to
curvaton field fluctuations then the original curvaton model [ 73 , 74 ,
75 ] is realised. Hence, in this section we term situations where @xmath
as the “curvaton scenario”.

At the pivot scale, the latest 2015 BICEP2/Keck Array and Planck [ 22 ,
189 ] combined observations give @xmath , @xmath and @xmath ( @xmath
c.l.). If the inflaton potential is of the large-field type @xmath , in
the curvaton limit @xmath , Eq. ( 1.104 ) implies that @xmath , and the
observed value of the spectral index means that the inflaton field
potential must be close to quartic, @xmath . The “simplest” curvaton
scenario with a quadratic inflaton and curvaton field is now disfavoured
by the data [ 218 , 132 , 134 , 219 ] .

The observational constraints on @xmath and @xmath imply that when any
inflaton potential is included in the analysis, only two classes of
models with an additional spectator field are found to be favoured [ 134
] : plateau inflation, which cannot fit the data in the curvaton
scenario (thereby requiring @xmath ), and quartic inflation, which can
only fit the data in the curvaton scenario ( @xmath ). An advantage of a
quartic potential is that the inflaton field energy decreases like
radiation when it oscillates, making the model more predictive by
removing the dependence of post-inflationary dynamics on the inflaton
decay rate into radiation.

Another way to detect the curvaton is through primordial non-linearity
of the density perturbations, of which the key observable is the local
non-Gaussianity of the bispectrum, parametrised by @xmath . Its value in
the sudden-decay approximation is given by LABEL:Ichikawa:2008iq and
Eq. ( 1.108 ), where the observational non-Gaussianity constraint of
@xmath implies that either we predominantly observe inflaton
perturbations, @xmath , or the the spectator must have a non-negligible
energy density at its decay, @xmath .

The contribution from the curvaton to the primordial power spectrum
crucially depends on its field value, @xmath , when observable modes
exit the Hubble radius. Combining Eqs. ( 1.101 ) and ( 1.106 ), one can
see that the curvaton dominates the perturbations, @xmath , if @xmath .
Therefore @xmath must be sub-Planckian (if it is super-Planckian, it may
drive a second phase of inflation and the above formulas do not apply,
but below we show that this case is excluded). In practice, the value of
@xmath is determined by the details of the inflaton’s potential @xmath
over the entire inflating domain, as we demonstrated in Chapter 4 . This
makes the model more predictive since the typical value of @xmath is not
a free parameter anymore but depends on @xmath . This will play an
important role in the Bayesian analysis below. In particular, the value
of @xmath also depends on the total duration of inflation, which will
allow us to constrain it.

Most previous analyses of curvaton models assumed no knowledge a priori
about spectator field values. Instead, we adopt a physical prior for the
typical field displacement @xmath of the curvaton. This prior depends on
the inflaton potential @xmath and the total duration of inflation, as
one can see immediately from the results of Sec. 4.2 . Using these
results, in the presence of a plateau inflationary potential, if
inflation lasts more than the relaxation timescale @xmath @xmath -folds
[ 58 , 167 ] , the vev of @xmath reaches a Gaussian equilibrium
distribution with a variance given by

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

In the presence of a quartic large-field inflationary potential ( @xmath
), we find that Eq. ( 4.18 ) can be rewritten to give

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

with a strong dependence upon initial conditions. The distributions (
5.28 ) and ( 5.29 ) define the prior we take on @xmath for plateau and
quartic inflation, respectively. In Eq. ( 5.29 ), @xmath is the total
number of @xmath -folds  elapsed during quartic inflation and @xmath
denotes the variance of the curvaton vev distribution at the onset of
inflation. In the following we will take @xmath for the sake of
simplicity. This is important as it means @xmath is now the maximum
number of @xmath -folds. A more specific model for the curvaton could
readily specify @xmath from, e.g, a symmetry breaking mechanism, however
we shall leave @xmath such that our argument in this section represents
a proof-of-principle.

The expansion history of reheating depends on the mass of the curvaton
and the decay rates of the inflaton and the curvaton. We impose that the
onset of the radiation-dominated period occurs after the end of
inflation and before the electro-weak symmetry breaking. We also assume
that the inflaton and the curvaton decay at least as fast as they would
through their minimal coupling to the gravitational sector, given in
Eq. ( 1.96 ). ⁵ ⁵ 5 Here @xmath (or @xmath ) denotes the value of @xmath
below which the energy density contained in @xmath (or @xmath ,
respectively), or its decay products, redshift like radiation. Using
non-informative priors, as discussed in Sec. 2.4 , this leads to

  -- -------- -------- -- --------
     @xmath   @xmath      (5.30)
     @xmath   @xmath      (5.31)
     @xmath   @xmath      (5.32)
  -- -------- -------- -- --------

where @xmath is the Hubble scale at the end of inflation, @xmath is the
Hubble scale at electro-weak symmetry breaking, and we remind the reader
that @xmath means that @xmath is uniformly distributed between @xmath
and @xmath .

As discussed in Sec. 1.3 , if the inflaton has a quartic potential, its
coherent oscillations around the minimum of its potential give rise to a
radiation-like era of expansion immediately after inflation [ 69 ] . In
this case we set @xmath and reheating can be described by two parameters
only, the mass and decay rate of the curvaton.

### 5.5 Duration of inflation: results

The Bayesian analysis is performed on the January 2015
BICEP2/Keck-Array/Planck data combination [ 148 ] , using the
machine-learned effective inflationary likelihood described in
LABEL:Ringeval:2013lea , which has been marginalised over late-time
background cosmology, reionisation, and astrophysical foregrounds. The
predictions of the models are computed with the curvaton extension of
the ASPIC library [ 146 ] , making use of the method presented in Refs.
[ 134 , 105 ] . The Bayesian evidences are integrated using the
MultiNest algorithm [ 220 , 221 ] ; further technical details on the
numerical integration can be found in the appendix. The Bayesian
evidences are displayed in Fig. 5.13 and the corresponding posterior
distributions in Fig. 5.14 .

#### 5.5.1 Single-field versus spectator model

One can check in Fig. 5.13 that for single-field models, plateau
potentials are favoured while a quartic potential is strongly
disfavoured (and even ruled out at the level of its maximum likelihood).
When a light spectator field is included, the evidence of plateau
potentials remains stable, and the two-field model cannot be
distinguished from its single-field counterpart in terms of its Bayesian
evidence [ 87 ] . This is because, in spite of the significant
enlargement in prior parameter space caused by the introduction of the
spectator field, most of the prior mass in the distribution ( 5.28 )
reproduces single-field phenomenology, which gives a very good fit to
the data irrespective of the value of the reheating parameters. This
result is consistent with what was found in Refs. [ 134 , 105 ] .

For the quartic potential, the evidence obtained once a spectator field
is included depends on the total duration of inflation, @xmath , through
the prior distribution ( 5.29 ) for the curvaton vev. We give the
Bayesian evidence for a few values of @xmath in Fig. 5.13 . We take
@xmath as an upper bound, since for larger values the inflaton would
initially be in the “self-reproducing” regime [ 222 , 172 ] where
stochastic corrections to its dynamics become important and the
calculation of LABEL:Hardwick:2017fjo does not apply.

In all cases, one can check that quartic models with a spectator field
are favoured with respect to their single-field counterpart, but are
still moderately or strongly disfavoured with respect to the plateau
potential. If one restricts the parameter space to the curvaton model,
i.e. if one imposes @xmath at the level of the prior, one obtains an
evidence similar to that of single-field plateau models irrespective of
the duration of inflation (see the lighter blue points in Fig. 5.13 ),
indicating that the dependence of the evidence on the number of @xmath
-folds  of inflation actually reflects the proportion of @xmath values
that correspond to the curvaton scenario in each case.

In terms of the observables shown in Fig. 5.14 , plateau inflation (the
Higgs inflation or Starobinsky model in the present case) with a
spectator field gives very similar predictions to its single-field
counterpart, namely a small tensor-to-scalar ratio, a value for the
spectral index that is in good agreement with observations, and a
slow-roll suppressed value for @xmath that is currently (and in the
foreseeable future) undetectable. For quartic inflation, independently
of the duration of inflation, the tensor-to-scalar ratio and the
spectral index are correlated, with bluer spectra corresponding to
reduced gravitational waves, and non-Gaussianity has the typical
amplitude @xmath , which, from Eq. ( 1.108 ), corresponds to a
preference for values @xmath , i.e. to situations where the curvaton
dominates the energy budget of the Universe when it decays and provides
the dominant contribution to primordial density perturbations.

Post-2020 CMB experiments [ 195 , 196 , 197 ] will shrink the @xmath
constraints on the inflationary observables to @xmath and @xmath , while
cross-correlation with future LSS experiments should drive the
constraint on local non-Gaussianity down to @xmath [ 223 ] . This would
be enough to distinguish between plateau inflation (with or without a
spectator field) and quartic inflation with a curvaton, or even to rule
out both models.

#### 5.5.2 Measuring the duration of inflation

For quartic potentials with a spectator field, the data shows strong
preference for curvatonic phenomenology (see the difference between the
dark and light points in Fig. 5.13 ), which corresponds to sub-Planckian
spectator field values of a few @xmath . This yields an “optimal” value
for the total number of @xmath -folds  of quartic inflation such that it
maximises the parameter volume that falls within this range of values.

A smaller variance for the prior distribution ( 5.29 ) of @xmath
(requiring a shorter duration of inflation) limits the spectator field
vev so that single-field quartic inflation is recovered, which is ruled
out observationally. A larger variance (due to a longer duration of
inflation or larger initial variance) locates most of the prior mass in
spectator vevs so large that they drive a second phase of quadratic
inflation, which is also ruled out. ⁶ ⁶ 6 If the light spectator field
is displaced by @xmath during inflation, then it may drive a second
period of inflation, which lasts for @xmath @xmath -folds . The
amplitude of the curvaton perturbations generated during the first
period of inflation is [ 224 ]

@xmath

Independently of the inflaton potential, the tensor-to-scalar ratio is
given by

@xmath

where @xmath . The observational bound on @xmath then imposes

@xmath

Since we require @xmath , because otherwise the first period of
inflation would end before the observable modes exit the horizon, this
implies that a quadratic spectator field that then inflates the Universe
cannot generate the majority of the observed perturbations.

Adapting Eq. ( 2.3 ), the posterior @xmath on the total duration of
inflation can be computed according to

  -- -- -- --------
           (5.33)
  -- -- -- --------

where @xmath is the evidence of the quartic plus spectator field model
with prior ( 5.29 ) on @xmath corresponding to @xmath , and @xmath is
the prior we set on the duration of inflation.

We reconstruct this posterior in Fig. 5.15 , where one can see that
inflation is constrained to last less than a few tens of thousands of
@xmath -folds . In particular, cases where inflation starts close to the
“self-reproducing” regime ( @xmath ), are strongly disfavoured [ 226 ] .
This is because in such cases, Eq. ( 5.29 ) yields @xmath (which is true
in any large-field inflationary potential [ 156 ] ) and the spectator
field drives a second phase of inflation. Note that if the initial
variance @xmath does not vanish then the constraint that we have
obtained is only an upper bound on the duration of inflation, but the
conclusion that it should not start in the self-reproducing regime
remains true.

### 5.6 Conclusions

In this chapter, we presented a novel way to determine the energy scale
of inflation in the case where the DM component is a feebly-interacting
singlet scalar. Assuming it is light and energetically subdominant
during inflation, we have shown that the inflationary energy scale
@xmath can be expressed as a function of the DM isocurvature
perturbation amplitude @xmath and the DM self-interaction cross-section
divided by its mass @xmath , with only a very weak dependence on the DM
four-point self-coupling @xmath ,

  -- -------- -- --------
     @xmath      (5.34)
  -- -------- -- --------

This relation is obtained combining Eqs. ( 5.12 ) and ( 5.13 ), and is
valid for the case of freeze-in only. It connects observables that
constrain two seemingly unrelated topics, namely the one of inflation
and the one of DM. By doing so, it opens up the possibility to access
the energy scale of inflation by studying the properties of DM, and vice
versa.

To illustrate this, in the upper panel of Fig. 5.3.3 we have displayed
the value of @xmath (and the corresponding value of the tensor-to-scalar
ratio @xmath ) one would infer from measuring @xmath to certain fixed
values, as a function of @xmath . One can see that because of the weak
dependence on @xmath , if @xmath were measured, the energy scale of
inflation would be given up to a few orders of magnitude at most, a huge
improvement compared to the @xmath orders of magnitude that are a priori
allowed. One should also note that a detection of @xmath close to the
current threshold ( 5.13 ) would allow one to probe values of @xmath
between @xmath and @xmath , which cannot be reached by present day CMB
technology. On the lower panel conversely, we have displayed the value
of the @xmath one would infer from measuring @xmath to certain fixed
values. One can see that current constraints on @xmath already almost
rule out the target of the next generation of CMB experiments @xmath [
195 , 196 , 197 ] . In fact, if such a value were detected, then in this
model @xmath would be predicted to be close to @xmath . Since this value
is within the reach of forthcoming observations [ 227 ] , that would
open up the possibility to either confirm or rule out the scenario
presented in this section.

In addition to presenting the basic scenario, we have also discussed the
robustness of this result and quantified how it changes under various
effects related to inflation, reheating, and DM dynamics at low
energies. We have characterised these effects by correction factors
introduced in Eq. ( 5.14 ). We found that the change in the background
evolution during inflation and the possible thermalisation of scalar
particles within the singlet sector and the following “DM cannibalism”
phase introduce only at most @xmath and @xmath corrections,
respectively, to the result for @xmath , whereas variations in the
reheating history can in principle have a larger effect, depending on
the duration of reheating.

Although the result obtained in this section is model dependent, it is
generic to a large class of scenarios and allows one to measure or
constrain the energy scale of inflation even in models where the
associated predicted value for the tensor-to-scalar ratio is well below
the current lower bound or sensitivity of the next-generation of CMB
experiments. Conversely, a detection of the tensor-to-scalar ratio would
allow one to infer a measurement for the DM self-interaction
cross-section. This could represent a new promising chapter in
constraining DM.

In this chapter we have also studied the observational consequences of
Chapter 4 when applied to the curvaton. We found that if the
inflationary potential is of the plateau type, the single-field limit is
the preferred one (the predictions of the model are robust under the
introduction of a spectator field), while quartic potentials are
favoured only in the curvaton limit. Both options, plateau inflation in
the single-field limit and quartic inflation in the curvaton limit, are
equally favoured by current data, but we have shown that future CMB and
LSS measurements may allow us to distinguish between them.

The contribution from spectator fields to cosmological perturbations
strongly depends on their field values at the end of inflation [ 156 ] .
The accumulation of long-wavelength quantum fluctuations during the
entire inflationary period gives rise to a distribution for the local
field displacement that depends on the total duration of inflation. As a
consequence, we found that the number of @xmath -folds elapsed during
inflation, @xmath , enters as a parameter of the model due to the lack
of early adiabatic regime. Hence, @xmath itself can be constrained by
the data.

In the curvaton limit, the inflationary potential is constrained to be
close to the quartic type. In that case, @xmath cannot be too small
otherwise the spectator field does not acquire a large enough field
value to source cosmological perturbations, and cannot be too large
otherwise the spectator field acquires too large a field value that
drives a second phase of inflation. The posterior distribution on @xmath
is displayed in Fig. 5.15 , where we find that according to the data,
inflation cannot last more than a few tens of thousands of @xmath
-folds. In particular, it is very unlikely that one starts quartic
inflation in the so-called “self-reproducing” regime.

For the first time, we have thus quantified how much cosmological data
can constrain the pre-inflationary history, much beyond the @xmath epoch
probed by potential large scale CMB anomalies. One should note that the
mechanism we presented is not only sensitive to the duration of
inflation but also on the shape of the inflationary potential over its
entire inflating domain, and on the spectator field displacement prior
to inflation. This opens up a new observational window that extends the
conventional scales by orders of magnitude and allows us to explore the
physics of the very early Universe beyond our currently observable
horizon.

## Appendix 5.A Calculation of the dark matter abundance

In this appendix we track the energy density contained in the @xmath
field from the end of inflation up until the measured abundance of dark
matter today, in the sequence of events depicted in Fig. 5.3 . This
figure also a reference guide to the various subscripts used throughout
this section.

At the end of inflation, we assume that @xmath takes a specific
realisation resulting from its stochastic dynamics during inflation,
@xmath , where @xmath is given in Eq. ( 5.16 ). After the end of
inflation, @xmath continues to be slowly-rolling (while quantum
diffusion is shut off) until it becomes effectively massive, at the time
@xmath , when it starts to oscillate. One can check that the value of
@xmath barely changes during this phase and to the approximation level
at which the calculation is performed, it can be taken as effectively
frozen, @xmath . The oscillations start when the effective mass of the
condensate, @xmath , becomes of order @xmath . The time at which this
happens can be calculated by introducing the mean equation-of-state
parameter between the end of inflation and the beginning of the @xmath
oscillations

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

The relation @xmath can then be integrated as

  -- -- -- --------
           (5.36)
  -- -- -- --------

By equating @xmath , one obtains

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

Let us note that for this number to be positive, the condition @xmath
must be satisfied, which is always the case for the typical value of
@xmath given by Eq. ( 5.16 ) if @xmath .

After the condensate @xmath becomes effectively massive, it oscillates
about the minimum of its quartic potential, so its energy density decays
as the one of radiation, @xmath , until it fragments into @xmath
particles. Fragmentation occurs when the fragmentation rate @xmath is of
order @xmath . In LABEL:Tenkanen:2016idg , it was found that

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

where @xmath is a numerical constant, and @xmath is the envelope of the
background @xmath time evolution, i.e. @xmath , where @xmath is an
oscillatory function. Notice that this expression is valid if the
background is radiation-dominated, so reheating must have occurred at
this stage for consistency. Since @xmath , during this epoch @xmath and
one has

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

On the other hand, similarly to Eq. ( 5.36 ), one has

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

where @xmath is the mean equation-of-state parameter in the oscillation
phase. By equating the two previous formulas, one finds that

  -- -------- -------- -- --------
     @xmath   @xmath      (5.41)
  -- -------- -------- -- --------

where in the second equality we have used that @xmath . One can see that
in order for @xmath to be positive, one must have @xmath , which is
again always satisfied if @xmath . Combining @xmath , Eqs. ( 5.40 )
and ( 5.41 ), one then obtains

  -- -------- -- --------
     @xmath      (5.42)
  -- -------- -- --------

On the other hand, combining Eq. ( 5.41 ) with the formula @xmath , one
can further obtain

  -- -------- -- --------
     @xmath      (5.43)
  -- -------- -- --------

Finally, let us note that at the time of fragmentation, we have assumed
the singlet scalar potential to be still approximated as quartic. This
means that @xmath , i.e. @xmath , which implies the following
consistency relation

  -- -------- -- --------
     @xmath      (5.44)
  -- -------- -- --------

In the second equality, we have used Eq. ( 5.16 ). As we will see below,
this condition is in fact always satisfied if another condition, derived
in Eq. ( 5.47 ), is verified.

Moving on to the fragmentation products, the @xmath particles are
created with a typical 3-momentum @xmath [ 199 ] , which redshifts as
the inverse of the scale factor, so that

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.45)
  -- -------- -------- -- --------

where in the second equality Eq. ( 5.43 ) has been used. When the energy
becomes of order the mass @xmath of the particles, they stop being
relativistic. This happens at the time @xmath at which @xmath (or,
roughly equivalently, when @xmath ), which yields

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

Requiring that @xmath is positive, one finds another consistency
relation, namely

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

In practice, one can show that if this condition is satisfied, Eq. (
5.44 ) is always satisfied too. Hence, Eq. ( 5.47 ) guarantees that both
consistency relations are verified, and corresponds to the grey region
labeled “no fragmentation” in Figs. 5.4 , 5.6 , 5.8 and 5.11 .

During this epoch, the energy density of the @xmath particles decays as
the one of radiation, so one has

  -- -------- -- --------
     @xmath      (5.48)
  -- -------- -- --------

where in the second equality, we have combined Eqs. ( 5.43 ) and ( 5.46
). Let us also notice that since the Universe must have reheated before
fragmentation in order for the result ( 5.38 ) to apply, at the
fragmentation time it is radiation-dominated so one has @xmath , which
gives rise to

  -- -------- -- --------
     @xmath      (5.49)
  -- -------- -- --------

Finally, when the particles are non-relativistic and their energy
density decays as matter we can scale this up to the value it would take
today, given by

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.50)
  -- -------- -------- -- --------

In this expression, @xmath stands for the energy density of radiation
today rescaled by the number of relativistic degrees of freedom, and
@xmath is the energy density of the Universe at the time when the @xmath
particles became non-relativistic. This is because, as stated above,
reheating must have occurred before fragmentation for consistency. Using
the Friedmann equation, this gives rise to

  -- -------- -- --------
     @xmath      (5.51)
  -- -------- -- --------

from which one obtains

  -- -------- -- --------
     @xmath      (5.52)
  -- -------- -- --------

By using Eq. ( 5.49 ), one finally has

  -- -------- -------- -- -- --------
     @xmath   @xmath         (5.53)
  -- -------- -------- -- -- --------

By comparing this expression with Eq. ( 5.18 ), one obtains the value
for @xmath given in Eq. ( 5.19 ).

## Appendix 5.B Calculation of the portal coupling

In all of the scenarios presented in this chapter, we require that the
@xmath particles fully constitute the DM. Through this constraint, we
demonstrate here that the value of the portal coupling @xmath can be
determined directly from the value of the self-interaction strength
@xmath and mass @xmath of the scalar field.

The time at which the dark freeze-out happens in the usual units of
@xmath is [ 214 ]

  -- -------- -- --------
     @xmath      (5.54)
  -- -------- -- --------

where one can compute the ratio between the entropy density of the
hidden sector and that of the SM degrees of freedom, @xmath , once the
scalars have reached chemical equilibrium within the singlet sector, as

  -- -------- -- -- --------
     @xmath         (5.55)
  -- -------- -- -- --------

To derive this expression, we have used that

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (5.56)
  -- -------- -------- -- --------

where @xmath GeV is the vacuum expectation value of the Higgs field and
where we take @xmath . Thus, the time of the dark freeze-out is

  -- -------- -- --------
     @xmath      (5.57)
  -- -------- -- --------

On the other hand, the dark freeze-out temperature can be estimated as
the temperature at which the @xmath interaction rate drops below the
Hubble rate [ 200 ]

  -- -------- -- --------
     @xmath      (5.58)
  -- -------- -- --------

where @xmath . Equating Eq. ( 5.58 ) with Eq. ( 5.57 ) and requiring
@xmath then yields a relation between the model parameters @xmath ,
@xmath , @xmath and allows one to fix @xmath in terms of the other two
parameters. The value we find is

  -- -------- -- --------
     @xmath      (5.59)
  -- -------- -- --------

where @xmath is the 0-branch of the Lambert W function. When plugging
this expression into Eq. ( 5.26 ), one obtains Eq. ( 5.27 ).

## Appendix 5.C Statistical computation

In the models presented in this chapter, the total power of the
primordial density perturbations constitutes an additional free
parameter, which we have omitted because it affects both models equally.
For numerical purposes, we use a log-uniform prior which comfortably
contains the posterior observed by Planck for this parameter. Thus, the
total parameter space sampled is @xmath , and our posteriors and
evidences are conditioned to the model producing close to the right
amount of power.

In the quartic inflaton case, the radiation-like reheating of the
inflaton, described as @xmath , is imposed via a half log-normal @xmath
. This needs to be done for numerical purposes, since @xmath is a
derived quantity that depends of the full parameter combination and can
only be computed a posteriori.

We ensure the correct normalisation of the evidences by dividing the
marginal likelihood by the total prior mass in the same parameter
domain, obtained with a quick MultiNest integration of a mock unit
likelihood. All results are obtained with 1000 live points and a very
low sampling efficiency of 0.01 (i.e. inverse of ellipsoid enlargement
factor). A significant enlargement of the ellipsoids is needed to
properly account for the hard edges of the prior and the fact that in
the quartic case the mode of the spectator field value is located at the
edge of the prior (otherwise if a mode at the edge of the prior is
partially or totally missed by the initial sample of live points, the
final evidence will be undervalued). This low efficiency produces a lot
of rejected points that spoil the computation of the weights used by the
Importance Nested Sampling estimator [ 229 ] , what makes it numerically
unstable, most often severely undervalued. Thus, we use the standard
nested sampled estimator in this chapter.

## Chapter 6 The probable future

Abstract. In this chapter we shall consider a probabilistic perspective
on the future of inflationary model building and selection. Building
from Chapter 2 , we develop a new formalism to forecast the performance
of an astronomical survey [ 230 ] with respect to its expected
information gain, capability to measure parameters and decisiveness in a
space of pre-determined models. We also introduce a new computational
forecasting code, foxi , which is based on our formalism and can be
readily applied to other experimental design problems.

### 6.1 Introduction

We begin this chapter with a brief review of inflationary model
selection using data from the CMB. The recent Planck collaboration
results [ 20 , 21 , 2 ] marked a significant milestone. In the case of
single-field models, the decreased upper bound on the tensor-to-scalar
ratio combined with a red-tilted spectral index lead the analysis to
mostly favour inflationary potentials with a plateau [ 109 , 231 , 36 ,
2 , 37 ] . Additionally, multi-field inflation has also recently begun
to be rigorously statistically analysed, e.g. in the context of curvaton
models [ 132 , 134 , 165 ] .

Despite the significant reduction in the number of observationally
viable models, it has become abundantly clear that there are still quite
a number of models that satisfy the Planck constraints, especially those
classed in the plateau category of potential. This dissatisfying state
of affairs is only mitigated by the potential for other future surveys
to augment the current constraints such as CMB Stage-4 [ 232 ] ,
LiteBIRD [ 195 ] and COrE [ 197 , 196 ] . Despite the promise of further
observations, the future of inflationary model selection is still
tremendously unclear. In the face of an uncertain future, we seek to
answer the following question: To what extent can one be certain of a
future survey being capable of deciding between models, or within the
space of many models? The answer is probabilistic and clearly dependent
not only on the particular model choice, but also on the current
constraints made by the Planck collaboration. Since a decision must be
made, the natural framework to answer this question uses Bayesian
probability.

It seems clear that there are many interesting unanswered questions one
can pose relating to the predictive probabilities of future survey
performance. In this section, we will restrict ourselves to focus on
using a futuristic set of measurement 1- @xmath error bars to compute
our defined expected utilities for model distinguishability. Therefore,
the specific question we pose for this chapter is as follows: How much
more do we stand to learn about single-field inflationary models given a
forecast set of future measurement 1- @xmath error bars over the
slow-roll parameters? To this end, we set up six classes of survey over
the space of slow-roll parameters @xmath , defined in Eq. ( 1.34 ),
where the corresponding choices of measurement 1- @xmath error bars (for
@xmath ) of each fictitious experiment are defined in Table 6.1 . Our
expectation will be a clear trend between decreasing measurement error
bars and an improvement in the score from our utility functions, e.g. as
can be seen from Fig. 6.1 , where we have plotted the quantity @xmath —
defined as a score of decisive merit between models in later chapters —
against our mock surveys.

We acknowledge that the broad question we seek to answer in this chapter
has been approached, to some degree, at various angles by Refs. [ 116 ,
132 , 196 ] (though no work yet appears to apply this to CMB experiments
and models of inflation). In each case, the authors target a slightly
different problem with specific surveys in mind. Further to this, we
note that some of the quantities we will later define (such as @xmath )
have already been introduced in similar works for Dark Energy models [
103 ] , likelihood parameter inference for Planck [ 233 ] and to
classify the cosmic web in [ 234 ] — yet the formalism will be extended
and improved in this section to properly quantify the ability of future
surveys to distinguish between models of inflation.

In this chapter we will outline a simple method to compute any expected
utility for a future survey given a previous set of measurements on the
same variables from an independent survey (which, in our case, shall
always be the Planck 2015 constraints). In Sec. 6.2 we outline in detail
our definition of the utility functions to be used throughout this
section, as well as introducing some new methods of computation —
including our outline of the new foxi algorithm.

The foxi (Futuristic Observations and their eXpected Information)
package is a general-purpose, publicly available, python class for use
on any forecasting problem. It outputs LaTeX  compile-able tables and
has a variety of plotting options. One can fork the code and other
details through the website: https://sites.google.com/view/foxicode . We
have also included some robustness checks and a brief summary of the
computational methods used by the algorithm in Appendix 6.B .

Since literally hundreds of single-field models have been proposed in
the literature [ 35 ] , including all of them in our analysis would be
numerically too expensive. In order to infer results that are
representative of the full model set one must therefore choose a variety
of models that fill e.g. the @xmath diagram using their calculated
@xmath and @xmath values from Eq. ( 1.65 ) and Eq. ( 1.70 ). In Appendix
6.A we list the 5 representative single-field models — employed in the
ASPIC library [ 35 , 146 ] : Higgs Inflation (HI), Kähler Moduli
Inflation II (KMIII), Kachru-Kallosh-Linde-Trivedi Inflation ( @xmath ),
Loop Inflation ( @xmath ) and Radion Gauge Inflation (RGI) --- that we
have chosen, neglecting many reasonable alternatives for the sake of
brevity and capturing the essential information about the competition
between models. Though no favouritism for these 5 is intended in this
chapter, ¹ ¹ 1 foxi copes relatively well with the inclusion of many
models, though the number of model pairs to analyse scales with the
Binomial coefficient @xmath , where @xmath is the number of models.
Already with @xmath , we note that @xmath model pairs must be
considered. as they are merely representative of the explored parameter
space shown by our representation of each prior volume over the @xmath
-plane in Fig. 6.2 , we nonetheless have provided very brief
introduction for each (which includes both their potentials and priors
on their parameters) in Appendix 6.A .

Our results can be found in Sec. 6.3 , where we employ a comprehensive
suite of expected utilities to analyse the future of model selection for
inflation.

We have additionally included a small section (Sec. 6.3.4 ) on the
interesting possibility of using our framework to examine the future
prospects of inferring the reheating temperature in the example of the
HI model as well as a computation of the probability in the future that
each of the various survey configurations will be able to exceed a
@xmath - @xmath detection of the running of the scalar spectral index
@xmath in Sec. 6.3.5 (with a preliminary calculation in Appendix 6.D ).
Both of these short examples are intended to give an impression of the
possible scope of usage for our code foxi with a model-focused question
in mind. Finally, in Sec. 6.4 we present our conclusions.

### 6.2 Formalism

#### 6.2.1 Probability measures primer

Due to the fact that all of the models of inflation considered here are
slow-roll models, there exists a general parameterisation of the power
spectrum (which we observe) that includes @xmath slow-roll parameters
@xmath that is sufficient to constrain their observational
characteristics once the amplitude has been measured and fixed. The
precise relationship between @xmath and single-field models of inflation
is discussed in more detail in Sec. 1.2.2 . The current data, using
Planck CMB measurements [ 20 , 21 , 2 ] , limits our capabilities to
constrain up to essentially @xmath slow-roll parameters [ 94 , 20 , 21 ,
2 ] . Even though future surveys may in principle be able to constrain
parameters further up the slow-roll hierarchy, e.g. @xmath , they will
first need to constrain @xmath at the level that is consistent with slow
roll, which we find to be difficult even for the most futuristic of our
toy surveys considered here (see Sec. 6.3.5 ). Hence, though all of the
formalism in this section can be applied to any @xmath -dimensional
parameter spaces, we shall consider here only the space of slow-roll
parameters @xmath as a first example. This space will subsequently be
equipped with three distinct probability measures.

#### The posterior given the current data

Hereafter, the fiducial point vector @xmath spans the real @xmath
-dimensional parameter space of central points for future measurements.
This, naturally, has a probability measure associated to it which is
derived from the current observations over each separate direction in
the space. We can therefore define the integral measure over the domain
of @xmath (such as will be used in Eq. ( 6.7 )) as the posterior
distribution of current data @xmath . There is a subtlety in obtaining
@xmath , that is revealed through Bayes’ rule

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

which includes the prior information @xmath over the space of @xmath ,
the former containing some initial information @xmath about the sampling
space.

Based on the principles outlined in Sec. 2.4 and within the specific
choice of parameterisation @xmath , throughout this chapter we will make
two choices of prior where @xmath and

  -- -------- -------- -- -------
     @xmath   @xmath      (6.2)
     @xmath   @xmath      (6.3)
  -- -------- -------- -- -------

corresponding to either flat, or, flat in all dimensions except a log
prior over the component @xmath i.e. the first slow-roll parameter
@xmath , respectively. By setting the hard prior limits in Eq. ( 6.3 ),
we have artificially chosen the lower bound on @xmath , which seems
reasonable when none of the models we study here are capable of lower
values than this and, in the absence of an absolute lower fundamental
limit ² ² 2 We restrict @xmath , otherwise we would need to include
second-order effects in perturbation theory [ 235 ] . In addition, this
lower bound encompasses the predictions from all of our chosen model
priors. on @xmath , that limit is also placed so as to not overweight
too much of the prior volume on very low values which will likely never
be detectable. The upper limit on @xmath and the bounds on both @xmath
and @xmath are set by slow-roll consistency.

To give an indication of the volume of permitted @xmath points used in
this section, the @xmath prior has been used in Fig. 6.2 to display the
68% and 95% contour limits (in solid black) for the current Planck 2015
posterior marginalised over the @xmath -plane.

#### The prior from each model

We define @xmath as a real @xmath -dimensional vector over the same
observables represented by @xmath (hence, for this section, over @xmath
). To generate a model prior @xmath over @xmath one simply varies the
parameters that are specific to the model (e.g. parameters in the
inflationary potential — see Appendix 6.A ) over their priors and
computes the distribution over the @xmath domain that this generates.

Distributions denoted with a bar — such as @xmath , @xmath and @xmath —
are defined over each individual model observable value @xmath , with
measure @xmath and are typically twice integrated in order to compute
the expected utility: once over the @xmath space and the second time
over the space of @xmath so as to take into account the uncertainty in
the values that a future measurement may be centred on.

#### The posterior given the future data

Finally, we shall also consider the likelihood (defined with @xmath and
@xmath ) and posterior probability from a future survey, with measure
@xmath , which is specified over the @xmath (another real @xmath
-dimensional parameter vector sharing the same space of observables
represented by @xmath ) domain. The futuristic dataset @xmath is centred
on @xmath with a vector of mutually independent forecast error bars
@xmath which we can specify either ‘by hand’ or through e.g. a Fisher
forecasting method, given a specific survey.

All distributions denoted with a hat, such as @xmath , @xmath and @xmath
are defined over @xmath . Through Bayes’ rule, we can connect the
posterior probability distribution given the current data (the same
distribution as the one defined over @xmath ) to the probability
distribution over the future data, once a future likelihood function has
been specified

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

Note that this distribution, and hence the points @xmath , are
independent of the space of models @xmath (although, of course, still
dependent on an overall underlying cosmological model such as @xmath
CDM). Hence, this will be useful for defining model-independent
utilities later e.g. the forecast information gain. In this chapter, we
shall assume

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

where the multivariate Gaussian distribution here can be defined
generally as

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

and where, crucially, we will be ignoring possible covariances and when
a parameter restricted to a positive-only range is used (such as @xmath
) a half-Gaussian is used. Both this and Eq. ( 6.5 ) will prove to be a
key assumption of this section. It is clear that forecasting for
proposed missions for which the configuration of the detectors and
physics of the measurement is well-understood, realistic future
likelihoods may be inferred and are probably extremely complex,
rendering the Gaussian assumption possibly a poor fit (we check this
assumption explicitly in Appendix 6.C ).

We consider this section to be a new step in developing a set of
numerical forecasting tools, in which, the natural first step is to
assume a Gaussian ansatz. Furthermore, we have two main reasons to focus
initially on Eq. ( 6.5 ):

1.  Our Gaussian mock forecasts represent the simplest first
    approximation to the full calculation where detector noises are
    carefully translated into error bars over the slow-roll parameters.

2.  The narrow-variance limit of all possible @xmath distributions is
    well-modeled by a Dirac delta measure in @xmath -space, hence the
    shape of our ansatz for @xmath becomes irrelevant when this limit is
    met (we will show that this shape-independence appears for our more
    futuristic surveys in Sec. 6.3 ). This is an important feature that
    can also be exploited for more rapid computation (see Appendix 6.B
    for further details).

Hence, we shall implement Eq. ( 6.5 ) throughout this section. A more
detailed discussion of the limitations of the Gaussian assumption is
provided in Appendix 6.C .

We have now clarified the important distinctions between the probability
measures used within this section, so we are ready to introduce our
formalism fully.

#### 6.2.2 Defining the expected utility

We discuss the introductory principles of Bayesian experimental design
in Sec. 2.5 . Building from this section, to correctly manipulate our
probability spaces, it is natural to define a utility function @xmath
which has a dependence on the target parameters @xmath (e.g.
parameterisations of the survey geometry, as discussed in
LABEL:Bassett:2004st ). One typically seeks to maximise the expected
value of @xmath in achieving a goal e.g. optimising the expected
information gain from a survey with a certain configuration. Using the
posterior given the current data, we can define the expected utility
@xmath (which can be dependent on the set of indexed models @xmath , for
example) as

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

and, given an appropriate @xmath , its corresponding centred
second-moment equivalent

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

where @xmath is defined as the measure of uncertainty in the value that
the future measurement is centred on, @xmath , which is conditioned on
the current data @xmath — which in the present case is the Planck data.
Computing both Eq. ( 6.7 ) and Eq. ( 6.8 ) above is sufficient to answer
all of the questions in this section through appropriate choice of
utility @xmath .

To clarify the formalism, we have illustrated the procedure defined in
this section with Fig. 6.3 . We note that the top left hand rectangle
(inside the blue region), which represents the input from the Planck
data [ 20 , 21 , 2 ] , may in principle be replaced with data from any
measurement design problem.

#### 6.2.3 The utility functions

We begin by defining @xmath and @xmath which denote the Bayesian
evidences for two models @xmath and @xmath respectively, given a future
survey (and a fiducial cosmology such as @xmath CDM), whose form for
@xmath is given by adapting Eq. ( 2.17 ) into

  -- -------- -------- -- -------
     @xmath   @xmath      (6.9)
  -- -------- -------- -- -------

which uses the likelihood function @xmath from some future dataset
@xmath (assumed to be Eq. ( 6.5 ) in this section) defined over the
model point space @xmath , centred at @xmath and multiplied by the prior
probability measure @xmath for each model.

The key quantity for model comparison is the Bayes factor @xmath between
two models, defined, as in Sec. 2.3 , as the ratio of their evidences

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

which favours models that realise a good compromise between quality of
fit and a lack of fine tuning. ³ ³ 3 In this context, the degree of
‘fine-tuning’ corresponds to the degree to which only a narrow region of
a given models’ possible observable characteristics actually fit the
data well. Thus, one favours @xmath within the set @xmath that
extremizes @xmath with respect to the others. In Sec. 2.3 we also
introduced a threshold to rule @xmath out with respect to @xmath — the
Jeffreys threshold [ 98 , 100 ] , where one needs to satisfy @xmath .
Therefore, in logarithmic terms @xmath marks the point at which @xmath
may be considered ‘strongly disfavoured’ versus @xmath .

Consider now the choices of utility

  -- -------- -------- -- --------
     @xmath   @xmath      (6.11)
     @xmath   @xmath      (6.12)
  -- -------- -------- -- --------

which — though utilities in Eq. ( 6.7 ) may be defined generally over
the indexed model space @xmath — we have defined individually for each
pair of models @xmath and @xmath . Depending on how observationally
separable the two models are, computing the expectation value through
Eq. ( 6.7 ) of Eq. ( 6.11 ) may provide a strong indication of the most
probable absolute value of the Bayes factor, where the typical spread
away from this mean value can be estimated through the centred
second-moment in Eq. ( 6.8 ).

Turning our attention to the other utility defined by Eq. ( 6.12 ), the
decisiveness @xmath between @xmath and @xmath , is defined as

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

and @xmath , where we note that this quantity has been previously
defined in LABEL:Trotta:2010ug . @xmath incorporates the Jeffreys
threshold into the decision between models, where its value is that of a
real number selected from the closed interval @xmath (or the odds of a
clear decision). In this way, model pairings with a large decisiveness
value will be imminently distinguishable in the future, with the
opposite holding true for a low decisiveness value.

Our last, model-independent, ⁴ ⁴ 4 At least dependent only upon the
background cosmology. utility function is the information gained (in the
same space of observables as @xmath and @xmath , e.g. @xmath for our
single-field inflation problem) by improving the measurement with error
bars @xmath at each possible @xmath

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

also referred to as the Kullback-Leibler divergence [ 89 ] between the
two distributions, which we define here as

  -- -------- -- --------
     @xmath      
     @xmath      (6.15)
  -- -------- -- --------

By defining the normalisation

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

we can rewrite Eq. ( 6.15 ), using Eq. ( 6.4 ) and @xmath , as

  -- -- -------- -- --------
        @xmath      
        @xmath      (6.17)
  -- -- -------- -- --------

#### 6.2.4 The maximum-likelihood average

Throughout this section, we will use the notation @xmath to denote the
current-data posterior averaging as in Eq. ( 6.7 ). While this is
perfectly adequate to obtain expected utilities, in the case of both
model-dependent utility functions (defined by Eq. ( 6.11 ) and Eq. (
6.12 )), one should also consider averaging over only those @xmath
points that generate future likelihood distributions which do not
immediately rule both models out. Indeed, in cases where both models are
ruled out, the fact that one model is even more ruled out than the other
does not provide valuable information and one may wish to simply discard
such situations from forecasts. The removal of such situations restricts
the space of future scenarios to those for which a Bayesian model
selection is even necessary to conduct.

An averaging scheme that can solve this problem removes the @xmath
points for which the maximum likelihood of both models is too low in
comparison to the global maximum likelihood. We will refer to this
method hereafter as the ‘maximum-likelihood averaging’ scheme, defined
as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (6.18)
  -- -------- -------- -- --------

where for this section we set @xmath but this threshold value can be
arbitrarily defined, ⁵ ⁵ 5 Hence, we are quite restrictive, permitting
only those models for which the maximum likelihood is @xmath , e.g.
within roughly @xmath - @xmath of the global maximum likelihood. we have
suppressed the dependence @xmath for brevity and @xmath is the maximum
likelihood point for a given distribution. Thus, expected utilities
generated using @xmath will effectively subsample all of those possible
‘futures’ that still require a model selection procedure to provide new
information. We have also defined a normalisation factor @xmath in Eq. (
6.18 ), where @xmath is defined as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (6.19)
  -- -------- -------- -- --------

hence in the limit of low accuracy @xmath , @xmath and, in the limit of
infinite accuracy, @xmath measures the volume (weighted by the posterior
of the current measurement) of the union of the priors between the two
models. With Eq. ( 6.19 ) we may also keep track of the proportion of
the @xmath space that has already ruled both models @xmath and @xmath
out with respect to the maximum likelihood point. ⁶ ⁶ 6 This choice is
justified since the maximum likelihood point can be viewed as the
optimal ‘benchmark’ model to compare all other models in the space to.

In Eq. ( 6.13 ) we defined @xmath as the decisiveness between models
@xmath and @xmath . Hence, using our newly developed maximum-likelihood
averaging scheme in Eq. ( 6.18 ), we define a new expected utility
@xmath which we dub the ‘decisivity’ between @xmath and @xmath . We
shall make extensive use of this new quantity for the analysis Sec. 6.3
.

#### 6.2.5 A novel computational forecasting method

The utility functions we study here contain either of the two integrals
Eq. ( 6.15 ) and Eq. ( 6.9 ), which must be nested inside the integral
over the @xmath point domain defined by Eq. ( 6.7 ) in order to compute
the expected utility. The canonical approach would be to perform
Nested-Nested sampling with a modification to the MultiNest algorithm [
221 ] , but this would make this problem too computationally expensive
due to the length of time required for (even efficient) Nested sampling
to converge. Furthermore, in the particular case of the Bayes factor, we
cannot always rely on the models being nested within one another, as in
the implementation with the SDDR ⁷ ⁷ 7 The Savage-Dickey Density Ratio
is a way to compute the Bayes factor — valid only when the models
involved are nested — which reduces the often-intractable problem of
computing the Bayesian evidence to a conditional prior volume ratio. [
237 , 238 , 103 ] , therefore we must still perform the integrals for
the evidences of each model from Eq. ( 6.9 ) explicitly.

This issue can, in fact, be resolved by with a relatively simple
computational programme. By relaxing the infinitessimal element in Eq. (
6.17 ) to be finite, we may rewrite the integral as a discrete summation

  -- -------- -- --------
     @xmath      
     @xmath      (6.20)
  -- -------- -- --------

where we assume the @xmath to be drawn from Markov chains that sample
directly from @xmath and we have normalised the future likelihood @xmath
in a particular way, such that

  -- -------- -- --------
     @xmath      (6.21)
  -- -------- -- --------

Using Eq. ( 6.21 ), Eq. ( 6.20 ) and a sufficiently large number of
points, one can efficiently compute Eq. ( 6.14 ) such that the expected
utility integral in Eq. ( 6.7 ) --- which also must be approximated by a
discrete summation --- is tractable over reasonable timescales. ⁸ ⁸ 8
@xmath - @xmath days on the Sciama High Performance Compute cluster,
with @xmath likelihood samples and @xmath - @xmath models with @xmath
prior samples each.

Eq. ( 6.10 ) may also be computed as a discrete summation with an
appropriate weighting scheme implied by the priors of each model, where
we find the following formula

  -- -- -- --------
           (6.22)
  -- -- -- --------

in which the summations are over the Markov chains that sample directly
from @xmath (numerator) and @xmath (denominator) — modulo a
normalisation @xmath that exists due to varying the number of points
within each chain, respectively. We note here that a related method to
compute the Bayesian evidence for the Markov chains themselves was
recently introduced by LABEL:Heavens:2017hkr , whereas the goal for this
chapter is forecasting with futuristic distributions which instead
simplifies the integration procedure to multiple evaluations of a
distribution function.

Our method can effectively construct the Bayesian evidence for any model
defined by its prior over @xmath and has been incorporated in our public
code, foxi . The algorithm to compute whichever @xmath is
straightforward and robust (see appendices 6.B and 6.C ), requiring only
a minimal number of samples. The main procedure of this computation is:

1.   Draw a value from the Markov chain representing the distribution
    @xmath .

2.   Compute the utilities @xmath using either Eq. ( 6.10 ) or by
    integrating over the whole set of future posterior samples to
    compute the integral in Eq. ( 6.17 ), given the corresponding @xmath
    in @xmath .

3.   Store the contribution to the integral Eq. ( 6.7 ).

4.   If the integral has not yet converged, go to 1.

5.   Compute Eq. ( 6.7 ) and Eq. ( 6.8 ) using the contributions stored
    in 3.

In order to calculate expected utilities with the @xmath average, one
simply discards points at steps 1. and 4. which do not satisfy the
condition within Eq. ( 6.18 ). We also note that higher-order statistics
such as Eq. ( 6.8 ) can be computed trivially from the samples generated
by this algorithm.

We shall now progress to analyse the results obtained for the surveys
introduced in Table 6.1 . We refer the interested reader to Appendix 6.B
for further details on the computational strategies and robustness
checks we have implemented in the code.

### 6.3 Results and analysis

In all of the analysis below we will consider probability distributions
over the various utilities defined in the previous section given a set
of futuristic measurement 1- @xmath error bars. In Table 6.1 we listed
the different settings used for each futuristic scenario, where in each
case we represented the characteristic measurement errors that might be
forecast for a particular configuration of experiment. The
specifications of the first two experiments are relatively close to
being realised by either CMB Stage-4 [ 232 ] , LiteBIRD [ 195 ] or COrE
[ 197 , 196 ] and are therefore optimistically labeled ‘Proposed’ with
P1 (CMB Stage-4) and P2 (LiteBIRD/COrE). The other four configurations
represent a futuristic order of magnitude improvement in the constraint
on each of the three slow roll parameters (F1-3), where the final one
represents the simultaneous improvement in all three previous
configurations (F4).

In Table 6.1 we have also displayed the expectation value on the @xmath
(information gain) between the current Planck data and each future
dataset in turn. The 95% bound in each case is also depicted with the
dashed lines in Fig. 6.4 where the solid lines represent the predicted
probability density in the future of the @xmath value. The distinction
between a choice of prior is striking (left and right plots correspond
to Eq. ( 6.2 ) and Eq. ( 6.3 ) respectively) where e.g. all of the F1-4
datasets saturate an effective numerical upper bound on the expected
information gain achievable @xmath . Notice indeed that Eq. ( 6.21 ) is
limited by the number of samples in the Markov chains representing
@xmath , such that the typical number of samples used for computations
over this space in this chapter ( @xmath ) yields this upper bound
directly @xmath . ⁹ ⁹ 9 This arises from equal-weight, normalised
independent samples.

The value of @xmath appears to rise far more quickly towards the
numerical bound in the case of the flat prior over @xmath as opposed to
logarithmic @xmath , which can be attributed to the improvements in
measurement errors that squeeze up to the hard prior lower bound in the
former case, which is @xmath from Eq. ( 6.2 ). Due to this strong hard
prior bound dependence there is a large information gain, which is to be
expected when the measurement precision over @xmath becomes of the same
order as this bound. From Fig. 6.2 one can also see that two of the
models are already ruled out by such a measurement (KMIII and @xmath )
due to their tensor-to-scalar ratios (given by @xmath , see Eq. ( 1.70
)) being both orders of magnitude below this bound. For this reason we
will only consider the logarithmic prior over @xmath defined by Eq. (
6.3 ) when considering our model selection utilities, since it is a far
more conservative choice.

Turning our attention now to the values of @xmath sampled by the @xmath
points using a logarithmic prior over @xmath in Fig. 6.4 , we see a
clear trend and increase in information gain by each survey
configuration, which is matched by the values of @xmath in Table 6.1 .
Notably, the optimal expected information gain (measured by @xmath )
between surveys F1-3 is achieved through improvements to the measurement
over @xmath in F3. This is clearly due to the fact that the current
constraints are the least constraining over @xmath when compared with
the other two parameters in the slow-roll hierarchy. We shall return to
this interesting point for further discussion in Sec. 6.4 .

#### 6.3.1 General statements

The combined results of this chapter span Tables 6.2 , 6.3 and 6.6 . We
have performed the analysis computing @xmath , @xmath , @xmath and
@xmath as expected utilities using all possible pairs of the models
defined in Appendix 6.A , where the latter two expected utilities make
use of the maximum-likelihood average @xmath from Eq. ( 6.18 ). In
addition, we have also provided the ratio of rejected points @xmath
according to this alternative averaging scheme defined by Eq. ( 6.19 )
in each table.

The increasing decisivity between models is best summarised in Fig. 6.1
, where the general trend begins with survey P1, where no value of
@xmath is above a probability of 0.1, towards complete certainty of a
decision between all model pairs ( @xmath ) in survey F4. An important
detail to note at this point is that between F1-3 the best decisive
outcome between all model pairs is achieved by survey F2, which
corresponds to an order of magnitude decrease in the measurement errors
over the second slow-roll parameter @xmath . This already gives a strong
indication that the possible future directions for selection between
inflationary models may rely more on increased precision over the
spectral index @xmath and less on the tensor-to-scalar ratio @xmath . We
shall, once again, return to this discussion point later in Sec. 6.4 .

#### 6.3.2 Forecasts using P1 and P2

We first examine Tables 6.2 and 6.3 (P1 and P2 surveys, respectively
corresponding to CMB Stage-4 and COrE/LiteBIRD-like surveys) which use
the measurement error bars that are expected to be achievable in the
relatively near future, whence, the label ‘P’ for ‘Proposed’. For P1 the
@xmath values suggest that already @xmath of the possible future
realisations will rule both models of each pair out at the level of
either model’s maximum likelihood given our threshold of @xmath or above
(see Sec. 6.2.4 ), where @xmath . Note that this is not the same as all
of the model pairs being ruled out at once but instead reflects the
specific decision question for each model in-turn. P2 has a far more
striking result — in @xmath of the possible future measurements, both
models in each pair (in all 10 possible combinations) will have been
eliminated at the maximum likelihood level. We can infer from these
results alone that the upcoming future surveys of the P2-type will have
strong decision-making capabilities even before any further analysis or
detailed model selection program is initiated. This indicates that an
important first threshold in the space of possible CMB missions exists,
somewhere between the capabilities of P1 and P2, where most single-field
model pairs will already be ruled out at the level of their maximum
likelihoods. This threshold can be crossed in the future by a
COrE/LiteBIRD-like mission.

Let us move on to the expected model selection utilities by improving
measurement bounds by an order of magnitude on both @xmath and @xmath .
In doing so we advance from P1 to P2, where most model pairs receive a
very large amplitude increase in @xmath e.g. all of the pairs that
include the RGI model increase by an order of magnitude in @xmath
-scale. The uncertainties associated to this expected utility also
become significantly larger in most cases. Though it is instructive to
consider the expected Bayes factor utilities, the variance in their
value for each model pair (especially in the case of survey P2) leads to
significant uncertainty in assertions about the future that rely on
these utilities alone. Therefore, we can support our claims by
considering the decisivity @xmath for the same pairs of models, where
most receive a greater-than factor of 4 increase in the odds of a
decisive model selection with survey P2 when compared to P1.

#### 6.3.3 Forecasts using F1-4

We begin our analysis of the results using surveys F1-4 in Table 6.6 by
noting that, from this point onward, because the measurement errors for
each survey are so small it will no longer be informative to use @xmath
and @xmath since their magnitudes are all above the Jeffrey’s threshold
@xmath (and probably above the numerical precision). It is, however, far
more illuminating to examine the values of @xmath and @xmath together:
firstly to assert whether or not the proportion of @xmath points
remaining is already very small for which Bayesian model selection
techniques are unnecessary (i.e. how large @xmath is will dictate how
likely it is in the future for a given model pair to be totally ruled
out at the level of the maximum likelihood, and hence whether there are
any likely futures for which Bayesian model selection will be required
at all), and secondly in the event of model selection being required,
whether or not @xmath gives good odds of successfully deciding between
those models.

Survey F1 increases the measurement precision over @xmath from P2 by an
order of magnitude. Using Table 6.6 , for each pair of models this
improvement is expected to leave a @xmath chance of avoiding a
ruling-out with respect to the maximum likelihood of each model. Of the
expected remaining @xmath points, there is varied performance by
Bayesian model selection to be decisive — one the one hand, KMIII - HI
and @xmath - HI are always decided between ( @xmath up to rounding
errors @xmath ), whereas on the other hand, there are only chances of
0.12 and 0.18 to decide between RGI - @xmath and RGI - @xmath ,
respectively.

In contrast, survey F2 increases the measurement precision over @xmath
from P2 by an order of magnitude. For this improvement, one lowers
slightly further the chance of avoiding a ruling-out with respect to the
maximum likelihood of each model down to @xmath . Of the expected
remaining @xmath points, there is a very impressive performance
expected, yielding at worst chances of 0.47 and 0.5 to decide between
the pairs KMIII - HI and RGI - HI (also @xmath - HI) respectively where,
in fact, most other model pairs have high decisivity @xmath . It is for
this reason that we will conclude later that an F2 strategy for survey
design is superior to F1 for single-field inflationary model selection.

Survey F3 increases the measurement precision over @xmath from P2 by an
order of magnitude. Between F1-3 this survey configuration has the
greatest chance of ruling out a given model pair at the level of the
maximum likelihood, which is @xmath . Of the remaining @xmath points,
there is a wildly varied chance of a decisive conclusion between models
e.g. 0.12 for RGI - @xmath , but conversely, a chance of @xmath for all
model pairs including @xmath .

The decisiveness @xmath drops dramatically from F1 and F2 to F3 (and
also F4 which inherits this feature from F3). This is as a feature that
arises from situations where the Bayesian evidence of both models being
too low to numerically evaluate, and hence the algorithm assigns @xmath
, which results in a contribution of 0 to the decisiveness at that
point. If this happens frequently enough then the value of @xmath drops
accordingly, as is the case when the measurement precision over @xmath
is improved enough for it to be a decisive observable. In principle this
can be rectified by hand by assuming that @xmath for all of these
points, but this is not strictly correct, and hence we have not quoted
@xmath for F3 and F4 accordingly. This numerical problem does not exist
for the decisivity @xmath , and hence provides another supporting
argument for its use.

Finally, because using F4 always appears to give values of @xmath , we
can immediately conclude that the survey configuration F4 is close to
the ultimate goal for, essentially, absolute certainty in deciding
between the plateau models at the level of their maximum likelihood
values alone. The fact that @xmath saturates to a constant value for
most model pairs in moving from F1-3 to F4 indicates that there is a
second threshold in the space of CMB missions (the first being between
P1 and P2). The value of @xmath saturates to a constant when the
measurement over @xmath is so precise that it is effectively a Dirac
delta function when compared with the priors over a pair of models.
Hence, the value of @xmath in this limit (as discussed previously in
Sec. 6.2.4 ) corresponds to the total prior union volume of the two
models relative to the total volume in the @xmath space that is weighted
by the current likelihood @xmath .

Furthermore, in this limit, the Bayes factor between all model pairs
reduces to a trivial prior point ratio

  -- -------- -- --------
     @xmath      (6.23)
  -- -------- -- --------

and note that this becomes independent of the future measurement error
bars @xmath . Hence, to go any further than this measurement precision
will require a reformulation of a new space of models @xmath with priors
that are coarse-grained to much finer detail so as to remain
competitive.

#### 6.3.4 Deciding between reheating scenarios

Full statistical inference of the temperature of reheating for a given
inflationary model is an exciting new research topic within early
Universe cosmology [ 113 , 105 , 196 , 114 ] . In principle, if one can
infer a micro-physical parameter, such as temperature, from the thermal
bath at high energies then the early Universe can become a laboratory
for high-energy physics. In addition to this, one can potentially
distinguish between inflationary models with the same potential, e.g.
Higgs inflation [ 240 ] and Starobinsky inflation [ 241 ] , that are
realised in different theoretical frameworks by using their possibly
different reheating temperatures.

In this short section we use our formalism to study 3 nested models
within the HI model: @xmath , @xmath and @xmath , which correspond to
the HI potential at fixed reheating temperatures @xmath , @xmath and
@xmath , respectively. Motivations for the reheating temperatures
include the various relic species overproduction problems, e.g., the
so-called ‘gravitino problem’ [ 153 ] for the lower temperature at
@xmath , reheating temperatures of @xmath are favoured by Supergravity
channels for Starobinsky inflation [ 152 ] and @xmath is typical for
Higgs inflation [ 242 ] .

By performing the same analysis to compute the expected utilities for
the comparison between these nested models, we will give a qualitative
impression of how our formalism can be used to indicate the future
performance of any survey with respect to carrying out inference on
reheating.

Table 6.4 lists our full results for this analysis. The chance of ruling
out all of the reheating temperatures at the level of the maximum
likelihood reaches 1.0 with surveys F1-4, and the reheating temperatures
are essentially measured to extremely good precision, therefore we have
not included these results in the table since they are essentially
trivial.

Considering the results using the P1 configuration first, the chance of
ruling out each pair of temperatures at the level of the maximum
likelihood is low ( @xmath ). In addition, we find that model selection
offers no additional benefit of deciding between temperatures for the HI
model since @xmath is well below @xmath (even with the typical standard
deviation added) and @xmath supports this by indicating a 0.0 (up to
rounding errors of 0.005) chance of decisive selection of temperature.

We now turn our attention to the P2 configuration. According to Table
6.4 , the improvements to the measurement bounds in moving from P1 to P2
indicate that one can nearly be certain (chance of @xmath ) that they
will be able to select away from each pair of reheating temperatures at
the level of the maximum likelihood, boding well in this regard for the
prospects of future surveys like COrE [ 196 ] . ¹⁰ ¹⁰ 10 In addition,
supporting the conclusions made by LABEL:Finelli:2016cyd

If one now considers the values of the @xmath utility for the P2 survey,
these suggest that future values of @xmath occur more regularly at
@xmath - @xmath for all three reheating temperatures, and hence they may
be distinguished between, which is indeed consistent with
LABEL:Finelli:2016cyd . We note, however that this does not mean that
such temperatures can be decisively ruled out with respect to one
another — a fully decisive future with @xmath appears to occur only very
infrequently at the beyond 5- @xmath level.

We have demonstrated the versatility that our formalism has, as well as
the range of applicable problems that the foxi package can deal with. We
continue to the next section with another example.

#### 6.3.5 Measuring the scalar running

Another example of our formalism at work is in the forecasting of the
probability that as-of-yet unobserved parameters will be measured in the
future by a given survey with forecast error bars @xmath . Consider the
running ¹¹ ¹¹ 11 This is also a good consistency check with our
assumption that the @xmath is currently a sufficient space (and not
including higher-order slow-roll parameters e.g. @xmath ) to
characterise the single-field model selection capabilities of future CMB
missions. @xmath of the scalar spectral index in single-field inflation,
defined in Eq. ( 1.66 ).

In Appendix 6.D we derive a relation connecting the observed fiducial
point and measurement 1- @xmath error bar ( @xmath and @xmath ,
respectively) over @xmath to the future error bars over the slow-roll
parameters @xmath , which we compute for each given realisation over the
measured @xmath points. We shall not quote the relation here, but by
referring to the functional dependencies @xmath and @xmath we can show
that the probability which we seek is implicitly

  -- -------- -------- -- --------
     @xmath               (6.24)
              @xmath      (6.25)
  -- -------- -------- -- --------

where we have specified a @xmath -measurement over @xmath to be
identified as having ‘measured @xmath ’.

In Table 6.5 we quote the probabilities of measurement over @xmath for
each of the survey configurations studied in this chapter. We find that
for the survey P2 one obtains a substantial improvement over P1 in the
probability of measuring @xmath — moving from @xmath to a probability of
0.93. When one reconsiders the posterior prediction, made this time when
assuming that the Higgs Inflation model is ‘correct’, we replace @xmath
in Eq. ( 6.25 ) with the posterior distribution @xmath . From this
change we see that there are significant probabilities for a detection
of @xmath to be made by F2, F3 (and F4) surveys, hence improving the
measurement over either @xmath or @xmath by an order of magnitude from
the P2 survey. This can be seen explicitly through the relation in Eq. (
6.39 ), where the otherwise relatively large term in the expression for
@xmath can only be reduced in size by decreasing either the measurement
width over @xmath or @xmath .

### 6.4 Concluding remarks

In this chapter we have outlined a simple method to compute any expected
utility for a future survey given a previous set of measurements on the
same variables from an independent survey. The tools that we have
developed have all been included in foxi , a publicly available python
package that can be readily used in any survey forecasting problem.
Crucially, our calculation relies on the assumption that the future
likelihood can be modeled by an uncorrelated Gaussian distribution over
the space of slow-roll parameters, hence, incorporating the level of
detail required to tackle forecasting for proposed surveys like
COrE/LiteBIRD must be an inevitable next step.

We have also modified the form of the expected utility in order to
partition each possible future into either the rejection of models at
the level of the maximum-likelihood or the decision between models using
Bayesian model comparison. With the new expected utilities generated by
this procedure, we have forecast the future of single-field inflationary
model selection using 5 plateau potentials that are both indicative of
the class and span the range of observables @xmath — the slow-roll
parameters — that is typical for models of this type (see Appendix 6.A
for their definitions). Our analysis finds two important thresholds in
the space of missions:

1.  Increasing precision from a P1-type survey capabilities (like CMB
    Stage-4) to P2 (like LiteBIRD/COrE), we cross the first threshold
    where most of the possible future measurements that could be made
    will rule out both single-field models of each pair at the level of
    their maximum likelihoods.

2.  Increasing precision from F1-3 to F4-type toy survey capabilities,
    we cross a second threshold where our utility functions saturate to
    constant values that do not depend on the precision of the
    measurement. In this limit, the error bars of the future likelihoods
    are much smaller than the prior volumes from the models that we
    consider. For both models of a given pair not to be rejected at the
    level of the maximum likelihood, the value of @xmath must fall
    within at least one of their prior volumes. If this is so then the
    Bayes factor becomes the ratio between their prior densities at that
    point (see Eq. ( 6.23 )) which does not depend on the future
    measurement error bars.

The prior volume-dominated limit, arising from threshold 2 above, is
analogous to the threshold reached within our computational procedure
(outlined in Appendix 6.B ), where in the latter case we devise a method
to calculate the Bayesian evidence that relies upon Eq. ( 6.23 ). Once
the threshold of this regime has been crossed it is essential for more
theoretical progress in the understanding of the remaining models to
occur, which would result in more narrow priors on their parameters,
before one builds a new survey to choose between them

Though the space of surveys that we explore in this section may be
simplistic, the broad conclusions we draw are unlikely to change. Our
results using only information theory considerations (the expected
Kullback-Leibler divergence @xmath ) indicat1e that the greatest
information to be gained is on @xmath , since it is currently the least
constrained of the three slow-roll parameters (and may also be used to
detect a scalar running). However, our analysis also suggests that the
most-likely decisive gains in selecting between single-field
inflationary models are made by improving the second slow-roll parameter
@xmath constraint (which can also potentially be used to detect a scalar
running) — which can be measured through more precision on the scalar
spectral index @xmath . Finally, as is suggested by many theoretical
studies into the fundamental physics of quantum gravity, the
tensor-to-scalar ratio @xmath might be the most important CMB observable
and hence @xmath may be considered the most fundamentally attractive to
theorists. Therefore, to order this trichotomy, we have compiled the
following list:

1.  Improve the measurement over @xmath , hence @xmath will be
    constrained to a greater degree and therefore one optimises the
    single-field slow-roll decisivity. Also we may potentially observe
    @xmath .

2.  Improve the measurement over @xmath , hence @xmath will be
    constrained to a greater degree and we may learn more about
    fundamental physics.

3.  Improve the measurement over @xmath , hence @xmath will be
    constrained to a greater degree which is optimal from an
    information-theoretic standpoint.

We also considered the applications of our framework to forecasting the
potential of surveys to infer the temperature of reheating, given the
Higgs inflationary potential. This is an avenue which we only very
briefly have explored in this section but a clear extension would be to
conduct a more thorough analysis on reheating temperatures taking into
account different choices of inflationary potentials that still match
observations. This also serves to illustrate the next step in the
challenges set to model-builders in the future: one must be more
specific in predicting reheating temperatures that arise from a given
inflationary potential as one approaches the second threshold.

In Sec. 6.3.5 we have promoted an additional application of our
framework to obtaining probabilities of measuring a given parameter in
the future. In this case, we considered the probability of measuring the
scalar running @xmath , initially when assuming no preferred model, and
then subsequently when assuming that a slow-roll single-field model (the
HI model in this case) is preferred and hence the current data is the
posterior prediction of the model from Planck . Our results broadly
indicate that though a P2-like survey is generally expected to measure
@xmath , if the Planck posterior is consistent with a slow-roll
single-field model then the probability of such a measurement drops
dramatically and it is only with more advanced mock surveys like F2 or
F3 that the chances of measuring @xmath become significant once again.
This can be traced to the fact that @xmath is typically small to be
consistent with slow-roll single-field models, and hence a more advanced
survey is required to measure its potential deviation away from 0.

## Appendix 6.A The single-field models

The observational predictions from each of the models defined below have
all been calculated using the publicly available ASPIC library:
http://cp3.irmp.ucl.ac.be/ ringeval/aspic.html . The model priors were
obtained from LABEL:Martin:2013nzq and we have also provided arguments
for the choice of each model as representatives of the full sample.

Higgs Inflation (HI) , as in Eq. ( 1.71 ), has the following potential

  -- -------- -- --------
     @xmath      (6.26)
  -- -------- -- --------

and was chosen in our analysis of plateaus to represent models with a
relatively large tensor-to-scalar ratio. In addition, the fact that it
is effectively a 0-free-parameter model is attractive with respect to
Bayesian inference.

Loop Inflation ( @xmath ) with a particular prior choice for the @xmath
parameter

  -- -------- -- --------
     @xmath      (6.27)
  -- -------- -- --------

was considered here for its relatively large spectral index, thus
ideally providing a decisive tension with the HI and KMIII models in
particular.

Radion Gauge Inflation (RGI) was chosen with the following potential and
prior

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

and is a good all-round representative of a standard plateau model that
is favoured by observations with a reasonably large tensor-to-scalar
ratio. The model is also in a good position between HI and @xmath in
values of the spectral index.

Kähler Moduli Inflation II (KMIII) is a good example of a two-parameter
plateau model with the following potential and choices of parameters

  -- -------- -- --------
     @xmath      (6.29)
  -- -------- -- --------

where one calculates @xmath and sets @xmath through the ratio @xmath .
This model also has a much lower order of magnitude for the
tensor-to-scalar ratio in comparison with the three above, mapping out a
more complete region of the @xmath -diagram.

Kachru-Kallosh-Linde-Trivedi Inflation ( @xmath ) phenomenologically
interpolates between much of the currently available parameter space
with the potential and the following potential and priors

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

thus it is a good final addition to our small sample of models.

A summary plot of the available parameter space on the @xmath -diagram
for each of the models is shown in Fig. 6.2 , where it is immediately
clear that we have selected a reasonable sample of single-field models
to span the available parameter space.

## Appendix 6.B Computational methods in foxi

In Fig. 6.5 we provide a reference diagram illustrating the various
situations which arise during computation of the utility functions in
the main body of the section. In particular, the Bayesian evidence
approximation of Eq. ( 6.22 ) practically requires the integration over
the probability densities described by both a Gaussian function and
prior samples. These distributions can be easily combined when the
future likelihood described by the Gaussian function has relatively wide
@xmath - @xmath contour limits compared to the typical inter-point
distance of the prior chains — such as is true for the category A
situations depicted in Fig. 6.5 and some situations within category B.

Category D (and category B points with a relatively small error contour)
represent situations where we must adopt a different computational
approach. A convenient non-parametric method is to approximate the model
prior probability density @xmath using Kernel Density Estimation

  -- -------- -- --------
     @xmath      (6.31)
  -- -------- -- --------

or ‘kernel smoothing’, as illustrated in the right-hand column of boxes
in Fig. 6.5 . @xmath in Eq. ( 6.31 ) is simply the number of samples
within the Markov chains representing the prior of @xmath . In this
section, the Kernel @xmath we select is simply a Gaussian function

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

with bandwidth vector @xmath . Though Category D situations are easily
identifiable because the maximum likelihood obtained from direct samples
is much lower than the kernel-smoothed equivalent, in general, we have
to use an optimal estimate ¹² ¹² 12 In our case we use the in-built
Least-Squares Cross-Validation (LSCV) method implemented in the
statsmodels package in python. LSCV is based on minimising the
integrated square error between the estimated distribution @xmath and
the underlying true distribution @xmath i.e. minimising

@xmath (6.33)

with @xmath samples, by minimising Silverman’s [ 243 ] estimator

@xmath (6.34)

of @xmath to identify whether kernel smoothing is necessary in Category
B i.e. if we are in regions where the local density of points is too
sparse, we will find that one or more of the dimensions within @xmath
will fall outside the corresponding dimension of the @xmath - @xmath
futuristic likelihood contour.

In the limit where the futuristic likelihood contour is very small
compared with the typical @xmath one finds for the smoothed prior
chains, to good approximation we find that the local value @xmath and
therefore we need only compute the evidence (and the maximum likelihood
point) using a single prior value centred at the @xmath point

  -- -------- -- --------
     @xmath      (6.35)
  -- -------- -- --------

Though this estimate can be shown to be very accurate, the foxi
algorithm itself actually computes the Bayesian evidence in the regime
of some category B and all category D situations by implementing the
combined approach of both Eq. ( 6.35 ) and drawing typically 1000
samples from the future likelihood (Eq. ( 6.5 )) to sum over for the
integral. This method is more computationally robust than Eq. ( 6.35 )
alone since it can accommodate for scenarios where the magnitudes of
error in each dimension in @xmath are very different, offering greater
flexibility to the algorithm, at a cost of some additional computation
time and efficiency.

## Appendix 6.C Checking for numerical robustness

This section aims to quantify empirically the accuracy of the Gaussian
assumption used throughout this section with respect to the direct
applicability of our mock forecasts to ‘real-world’ surveys. Note that
we are not suggesting that the assumption is ‘incorrect’ in any sense,
but that by definition, forecasting using the Gaussian assumption does
not necessarily coincide with a true likelihood that would be obtained
from a specific survey forecast.

We compared our results for each model pair using Eq. ( 6.22 ) with
those obtained from the MultiNest [ 221 , 36 ] algorithm in each case,
where we obtained both @xmath and @xmath for Eq. ( 6.22 ) through the
prior samples and a Gaussian likelihood with mean and marginalised
variances computed from the chains ¹³ ¹³ 13 The specifications used to
forecast the likelihood for LiteCOrE are given in LABEL:Finelli:2016cyd
and correspond to what is referred to as ‘LiteCORE-120’. used by
MultiNest , respectively. A comparison is in Table 6.8 for the Planck
2015 data [ 244 ] , where there is good general agreement up to the
@xmath level, and the forecast data for the LiteCOrE forecast dataset [
197 , 196 ] using HI fixed with @xmath as the fiducial model, where
there is less consistent agreement up to the @xmath level, which is
significantly smaller than the typical amplitude of the 2- @xmath
uncertainties over @xmath for a P2 experiment.

When comparing the values from MultiNest and our method, we note that
the former method is permitted many more samples from the model (in
order to converge the integral for the Bayesian evidence) than the
latter (which must limit the number of samples because many more
computations of the same integral are required). Hence, the disagreement
in values between the two methods that is not limited by the Gaussian
likelihood assumption itself is likely to originate from this limitation
of our computational resources.

The differences between the uncorrelated Gaussian likelihood and the
sampled likelihood forecast for LiteCOrE (using the @xmath prior) are
minute in the slicing of @xmath -space depicted by Fig. 6.6 . Therefore,
inaccuracies that can appear in the Bayesian evidence that arise from an
imprecise analogy between a more realistic likelihood forecast and our
mock forecasts are clearly far smaller than the disagreement that comes
from our limited computational resources. The points for which the
methods are in most disagreement are Category B and D (see Appendix 6.B
), since they are characterised by a poor inter-point distance, but
these points are sampled only very occasionally (see Table 6.7 ) and so
we can expect minimal impact on our main conclusions in this section.

We shall leave the future application of our formalism to a proposed
survey, such as COrE [ 196 ] , for later work.

## Appendix 6.D Identifying the constraint on @xmath

To leading-order in the slow-roll expansion, the running of the scalar
spectral index @xmath is given by Eq. ( 1.66 ). When no
cross-correlations are observed — as is the assumption in all of the
forecast constraints in this section — it can be shown that the generic
cross-correlator from such a measurement reduces down to factors of
correlators

  -- -------- -------- -- --------
     @xmath   @xmath      (6.36)
  -- -------- -------- -- --------

For a Gaussian measurement on each of the slow-roll parameters, the
fiducial point @xmath can be derived from

  -- -------- -------- -- --------
     @xmath   @xmath      (6.37)
              @xmath      (6.38)
  -- -------- -------- -- --------

The error bar of the measurement over @xmath can thus be unpacked into
an expression containing only the fiducial points and error bars on the
slow-roll parameters, i.e. @xmath

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.39)
  -- -------- -------- -- --------

Using Eq. ( 6.38 ) and Eq. ( 6.39 ) for a specified collection of 1-
@xmath error bars on @xmath , @xmath and @xmath , we may identify all of
the remaining fiducial points @xmath that satisfy a @xmath - @xmath
measurement of @xmath and can therefore compute the probability defined
in Eq. ( 6.24 ).

## Chapter 7 Discussion and conclusions

Abstract. This thesis has demonstrated how, even when observations prove
indecisive to learning about the inflationary paradigm, one can still
extract valuable information about the physics of inflation by
considering the precise predictions of well-motivated models. Adding to
this careful study, we have explored the possible futures which
observations might guide the theoretical developments toward. In this
final chapter, we conclude with a summary of all of the results obtained
in this thesis, an overview of their significance to the field of
research and a discussion of future possible directions that the work
could take.

### 7.1 Outlining the results

It is crucial to learning about the physics of inflation that the best
inflationary models are studied carefully for their potentially unique
observational characteristics and then compared to current observations
in a statistically rigorous way. It has been the principle aim of this
thesis to study the observational modifications to inflation that arise
from the introduction of additional scalar degrees of freedom and, with
those predictions, perform a statistical analysis in order to compare
them to the available data.

In Chapter 3 we introduced the curvaton model as an alternative
reheating model from which we obtained distinct observational
predictions to the standard single-field setup. Using Bayesian
inference, we demonstrated that the reheating temperatures one generally
infers from CMB perturbations are lower in the case of curvaton models,
where one also obtains more information on the exact value of the
reheating temperature with the latter.

The initial conditions to the curvaton as well as all other scalar
fields potentially sourced from an inflationary background were
extensively reviewed and studied in detail to include new effects
arising from couplings to multiple fields, alternative spectator
potentials and generic slow roll inflationary backgrounds in Chapter 4 .
The developments made in this chapter lead us to build detailed models
for post-inflationary phenomenology (namely, the curvaton and freeze-in
dark matter models) and to discover powerful new probes of inflation
itself in Chapter 5 .

Lastly, in Chapter 6 we discussed the future prospects for inflationary
model selection. In the process we developed a new Bayesian experimental
design formalism which incorporates toy survey configurations into a
forecast for model selection and information gain performance. We found
in particular that the most likely observable to optimise model
selection between single-field inflationary models, through an order of
magnitude precision improvement in the future, will be the scalar
spectral index.

#### 7.1.1 Impact on the scientific community

The potential ramifications of the results here are broad with respect
to building scalar field models of dark matter [ 184 , 245 ] , dark
energy [ 246 ] and Higgs dynamics where the initial conditions must be
specified from inflation. The effect of our work in Sec. 4.4 on the QCD
axion was recently taken into account in LABEL:Graham:2018jyp , where
low-scale inflation was found to permit axions with a lower mass range
than previously thought ( @xmath ).

In Chapter 3 we studied the effect on the reheating temperature inferred
by CMB observations by including an additional field. A multi-field
extension to our analysis was conducted in LABEL:Hotinli:2017vhx , where
it was found that post-inflationary curvaton behaviour obtained
observables with the greatest distinguishability from standard single
field reheating.

### 7.2 Future directions

We shall conclude here with a brief discussion of potential future areas
of research based on the results of this thesis.

#### 7.2.1 Dark matter initial conditions

The freeze-in real singlet scalar dark matter model of Chapter 5 is
among the simplest possible cases of dark matter generation using
inflation as the primary source for the field. Though its portal
coupling to the Higgs is @xmath by construction, we have already
demonstrated that this is well above the critical coupling value below
which the two spectator fields can be treated as separable in the
Fokker-Planck equation (this was calculated in Sec. 4.9.2 ). The initial
conditions of each field should therefore be recalculated numerically to
take this effect into account. In the same vein, one might consider the
possibility of extending the model to many more fields and performing a
Bayesian inference on its predictions with the same principles as in
Chapter 3 . Fermionic extensions are also possible and interesting to
consider [ 200 ] as well as scenarios with a dominant non-minimal
coupling term, as we discussed in Sec. 4.5 .

#### 7.2.2 Higgs stability

The SM Higgs vacuum is known to be unstable during inflation at a higher
energy scale than @xmath [ 163 , 249 ] unless there is an @xmath
non-minimal coupling. Due to their coupling to the Higgs, the
gravitational generation of light top quarks has been shown to affect
this instability criterion [ 250 ] . Similarly to [ 251 ] , it would be
interesting to numerically explore the couplings of scalar dark matter
required to do the same given the updates to the initial condition
implied by Chapter 4 . We imagine this to be either a modification to
the inflationary background that includes generic slow-roll in @xmath
and thus a possibility to leave equilibrium, or in the equilibrium
limit, the inclusion of additional scalars requiring full numerical
evaluation due to the probability current issue described in Sec. 4.9.3
. Trilinear couplings to the Higgs are also of interest to the question
of stability [ 252 ] as well as a delay in the reheating decay
efficiency of the inflaton through Higgs thermal blocking [ 253 ] .

#### 7.2.3 New gravitational wave signals

We also draw attention to a particular class of Axion-SU(2) model,
originally proposed as ‘Natural Inflation’ [ 254 ] , which has evolved
into what is known as ‘Chromo-Natural Inflation’ [ 255 ] and has
recently been studied as a spectator field during inflation [ 256 , 257
] . Due to parity violation of the SU(2)-gauge field background that the
axion is coupled to via a Chern-Simons term, this model is known to
predict a chiral primordial gravitational wave spectrum. It remains an
interesting project to further analyse the axion dynamics, and their
effect on the spectrum for gravitational waves produced, in the context
of our work in Sec. 4.4 .

#### 7.2.4 Survey design

In Chapter 7 we entered the new territory of Bayesian experimental
design for model selection in the context of cosmological experiments.
Our analysis could be performed for a specific survey by specifying more
detail in the functional form of @xmath in Eq. ( 6.7 ) that includes
detector behaviour. Extensions in this regard might include analytic
approximations such as those made by Refs. [ 258 , 259 ] . A more
speculative, though interesting alternative may arise from the
application of Information Geometry [ 260 , 261 ] .

Given a set of financial constraints and a fully characterised detector
behaviour, it would also be straightforward to translate our formalism
into searching for optimal specifications of a survey (e.g. number of
detectors, frequency channels, noise sensitivity, angular resolution,
telescope size, etc…). An optimisation problem of this kind would
require some change in numerical methodology, however, due to the
computational expense of efficiently scanning the search space of many
survey designs.