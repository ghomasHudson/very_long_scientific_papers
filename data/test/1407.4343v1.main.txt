## Fisher information

We now introduce a quantity which is of great importance to our work,
the quantum Fisher information. We begin by a predecessor that naturally
appears in estimation theory, the Fisher information (sometimes called “
classical Fisher information” in contrast to the quantum Fisher
information, in a bit of a misnomer).

Historically, the Fisher information arose in the study of the method of
maximum likelihood, which is a procedure, started by Fisher in 1912 [ 94
] , to find the best fit of given data to a theoretical curve with free
parameters. This method rivals the minimum variance unbiased estimator,
which basically consists in the least squares method constrained to
unbiased estimators, as well as the method of moments, which fits @xmath
parameters of a theoretical curve so that the @xmath first moments of
curve and data coincide (for more on these methods, see [ 98 ] ). The
importance of the Fisher information goes beyond this particular method
as it has relevant properties concerning any estimation, as we will see
by the Cramér-Rao bound, Eq. ( 59 ). Already suggested in 1922 by Fisher
in works such as [ 95 ] , he explicitly called it an information in 1925
in [ 96 ] , then later again in 1934 in [ 97 ] , among others ¹⁹ ¹⁹ 19
Due to the plethora of works by Fisher in those decades, see [ 104 ,
p.564] , it is not easy to pinpoint all the appearances of the Fisher
information in the literature of the time. . A more detailed
introduction to both “classical” and quantum Fisher information starting
from the maximum-likelihood estimation can be found in [ 99 ] (in
Portuguese).

The Fisher information is useful when there is some parameter @xmath
that is to be estimated. This parameter has a true value @xmath , a
value that one can never exactly obtain, but is considered to exist. The
definition further assumes that one performs some sort of procedure
related to the parameter, which produces an outcome @xmath out of a
given set @xmath . These outcomes can occur with certain probabilities
@xmath , which should depend on the true value @xmath of @xmath ; this
dependence is denoted by @xmath . Since @xmath is not known, one must
work, for every possible value of @xmath , with @xmath , the probability
distribution as if the parameter had true value @xmath . For each @xmath
, the distribution is normalized as @xmath . One can naturally repeat
the estimation many times to enhance the result. Adaptations for the
case of a continuous distribution are straightforward, but do not
concern us here.

The estimation procedure itself cannot yield @xmath or @xmath . The
@xmath must be obtained for each @xmath , usually by models, and the
actual outcomes are then compared to predictions from the models. An
estimation can be understood as a way to extract, from the outcome(s)
@xmath that has(have) been obtained, a value for the parameter @xmath .
The simplest form of doing that is perhaps to average the numerical
values obtained (a subcase of the method of moments). The
maximum-likelihood estimation searches instead for the true value of
@xmath which would be most likely to produce the observed outcome(s) by
maximizing with respect to @xmath a certain function of the
probabilities @xmath with @xmath restricted to the set of observed
outcomes (see [ 99 , Sect.2.1.1] or [ 104 , p.498] ).

A well-defined estimation procedure then entails a parameter @xmath with
an unknown true value @xmath , an outcome set @xmath , and a set of
outcome probabilities @xmath for each possible value @xmath . The Fisher
information with respect to parameter @xmath is defined as

  -- -------- -- ------
     @xmath      (52)
  -- -------- -- ------

It is intuitive that, for an actual estimation to be relevant, the
probability distribution of the outcomes @xmath must in some way depend
on @xmath . The presence of the derivative of @xmath expresses this
necessity of an @xmath -dependence of @xmath for the Fisher information
to be nonzero: if the pointer of your meter does not depend in any way
of the parameter @xmath , it cannot convey any information on @xmath .
To say that “even a broken clock is right twice a day” may be
heartwarming or funny, but one knows better than to try to estimate time
from it (by “broken clock” we consider a clock that has come to a full
halt). If a broken clock displays, e.g., the time 9:47, its outcome
probabilities are @xmath and @xmath for any other time. The clock has no
(Fisher) information on the actual time because these probabilities do
not depend on it.

Another useful expression for the Fisher information is

  -- -------- -- ------
     @xmath      (53)
  -- -------- -- ------

which is directly implied by Eq. ( 52 ).

Let us give a physical example. Estimation of physical parameters is
typically made by experiments. The outcomes @xmath can correspond to the
sets of raw data obtained after each repetition, but it is more
insightful to assign to @xmath the obtained numerical values of the
parameter at hand. Let us say a group of undergraduate students is
tasked with finding the gravitational acceleration @xmath on the surface
of the Earth by an inclined-plane experiment ²⁰ ²⁰ 20 Readers
familiarized with the undergraduate Physics courses of the University
should readily identify the reference to “FisExp”. . Imprecision is
naturally present due to imperfection on the measurement devices,
finite-sized markings for registering position, parallax, among many
others ²¹ ²¹ 21 There may even be a certain contribution due to subideal
interest by the students, on rare occasions. . Considering that
uncertainty only allows @xmath to be estimated up to a single decimal
place in SI, we expect a higher probability of reaching values around
@xmath , but the set of possible outcomes @xmath is the set of values
spaced by the precision of @xmath ,

  -- -------- -- ------
     @xmath      (54)
  -- -------- -- ------

Such a coarse graining by precision limitations will always be present
in physical experiments and is the reason why we are concerned with
discrete outcome sets @xmath .

It is crucial that the probability of obtaining a given outcome depend
on the true value @xmath . Suppose the estimation is made in two
different places on Earth, the high mountains of Huascarán, in the
Peruvian Andes, and the Arctic Sea, such that @xmath is different in
these cases. Furthermore, in addition to the simple didactic laboratory
used by the undergraduate students, the measurement of @xmath in each of
those places is also done by higher-precision satellites, allowing for
an extra decimal place ²² ²² 22 For completeness, we mention that actual
satellite experiments, as in [ 100 ] , can be a thousand times more
precise; the argument does not depend on such a high precision, though.
. In Fig. 4 , we show a simulation of the distributions of @xmath in the
four cases, assuming @xmath (Huascarán, Andes) and @xmath (Arctic Sea);
these two values are inspired by measured data taken from [ 100 ] . The
@xmath or @xmath cannot be obtained by measurements; instead, models (of
measurement and dynamics) assign @xmath for each possible @xmath , and
the actual measurements are then compared to distributions from the
models.

The capability of @xmath to discern a minute difference in the true
value of @xmath is essential for a precise estimation. The higher
precision of the satellite experiments is translated in the way it is
easier to distinguish the true values of @xmath from the @xmath of these
measurements. The Fisher information is a measure of this very property:
how much does the outcome distribution change by a change of the
underlying true value of the parameter?

This interpretation is helped out by the definition of the Hellinger
distance, a distance between probability distributions @xmath for a
given set @xmath of outcomes. If one assumes that two probability
distributions are different because they belong to two different values
@xmath , @xmath of the parameter, the Hellinger distance @xmath can be
written as a function of these values [ 101 , p.33] (or [ 99 , p.16] )

  -- -------- -- ------
     @xmath      (55)
  -- -------- -- ------

We remark nonetheless that @xmath is a distance only on the set of
probability distributions. It obeys Eq. ( 34 ), and especially Eq. ( 34a
), for the probability distributions @xmath , @xmath , not necessarily
for parameter values @xmath , @xmath . In other words, @xmath does not
measure variations of the parameter @xmath , but instead how
distinguishable the distribution @xmath becomes if @xmath is varied. If
distinct parameter values correspond to the same distribution, as in the
broken clock, @xmath will be zero.

These aspects of the Hellinger distance are analogous to some of what
has been said about the Fisher information, and we now show how they are
mathematically related. The first step is to rewrite the Fisher
information as

  -- -------- -- ------
     @xmath      (56)
  -- -------- -- ------

and then to write @xmath for infinitesimally separated arguments @xmath
, @xmath :

  -- -------- -- ------
     @xmath      (57)
  -- -------- -- ------

By comparing the two equations, it is easy to see that, to lowest order
in @xmath ,

  -- -------- -- ------
     @xmath      (58)
  -- -------- -- ------

i.e., the Fisher information is the core of the infinitesimal form of
that distance, measuring how probability distributions grow apart due to
an infinitesimal variation of the parameter.

Another sign of the importance of the Fisher information is that it
bounds the precision of any parameter estimation. This connection is
established by the Cramér-Rao bound, shown independently by Rao [ 103 ]
and Cramér [ 104 , p.480] , although some results had been anticipated
by Fisher, as recognized in [ 105 ] . The Cramér-Rao relation states
that the error @xmath of an estimation is bounded from below:

  -- -------- -- ------
     @xmath      (59)
  -- -------- -- ------

Our interest will be to use the Fisher information not in estimation
theory, but as (the square of) a speed related to the geometry of
quantum states, so the reader interested in this result (and its proof)
is referred to a more detailed discussion to be found in [ 102 , Sect.2]
or in [ 99 , Sect.2.1.2 onwards] , which are works dedicated
specifically to parameter estimation.

#### The quantum Fisher information

The Fisher information can naturally be applied to the estimation of a
parameter via a physical measurement, be it on a classical or quantum
system. Although no estimation, in either case, can be exact, there is
an important difference in the sources of imprecisions in the classical
and quantum scenarios. Classically, it is the imperfection of the
measurement/estimation process that introduces errors; classical states
themselves would allow for perfect estimations if probed by perfect,
idealized apparatus. In quantum mechanics, indeterminacy originates
additionally from the probabilistic nature of quantum states. Even with
ideal measurements, one cannot in general obtain complete information
about a parameter on which a quantum state depends, because it is not
possible, in general, to distinguish between two non-orthogonal quantum
states. The quantum Fisher information aims to quantify how much about a
certain parameter can be learned by a quantum state that depends on it,
assuming the best measurements possible. The classical counterpart to
this quantity would be trivially infinite — different classical states
are always perfectly distinguishable —; the goal here is to measure how
imperfect the information possessed by a quantum state is
(alternatively, how finite it is).

An important difference between the original Fisher information and its
quantum version is that, whereas the former is defined for each specific
estimation procedure, the latter is a function solely of the quantum
state and of its dependence on the parameter to be estimated. This is
possible because the Fisher information requires a set of outcomes and
its occurrence probabilities, while quantum measurement theory, by
indicating what the possible measurements are, supplies both of these.
The quantum Fisher information is, in fact, the Fisher information of
the best measurement available on the quantum state.

Let us now give an introductory example, admittedly oversimplified.
Consider that one wishes to measure the coupling constant @xmath of an
interaction between a field and a two-level atom ²³ ²³ 23 The
interaction in this example is given by the Jaynes-Cummings model on
resonance. . Atom and field will be left to interact for a certain time
@xmath , and the experiment makes a measurement solely on the atom. The
main idea is that the atom starts in a state @xmath and is driven to
@xmath by the field. The stronger the coupling constant @xmath , the
closer to @xmath the final state will be. Let us assume for the sake of
simplicity that there is a maximal value to @xmath , which is @xmath ,
and that the total interaction time @xmath is so chosen that the final
state will be exactly @xmath if @xmath . Other values of @xmath will
leave the state after @xmath in a mixture of @xmath and @xmath ,

  -- -------- -- ------
     @xmath      (60)
  -- -------- -- ------

with the representation @xmath , @xmath .

By letting the system interact for a time @xmath and measuring @xmath in
this basis, @xmath , one can make a crude estimate of the value of
@xmath . Since @xmath and @xmath , the Fisher information for this
estimation is

  -- -------- -- ------
     @xmath      (61)
  -- -------- -- ------

where the subscript @xmath indicates the measurement basis. One can see
from this expression that the estimate is worst for values of @xmath
close to @xmath , as expected ²⁴ ²⁴ 24 A possibility to reduce error is,
of course, to repeat the experiment multiple times. It has been shown [
99 , p.17] that the Fisher information is additive , i.e., in @xmath
independent runs of an estimation, @xmath . . Due to the idealizations
in this model, when @xmath equals @xmath or @xmath , the measurement
outcome is certain. This is reflected by the behavior @xmath on these
two values, which corresponds to the possibility of making an error-free
measurement. A more realistic description would be to assume some degree
of irremovable mixture on the initial and final states, which would
produce a well-behaved @xmath . We nevertheless keep treating this
idealization in order to present some of the important ideas.

As crude as this estimation may be, it is certainly better than to
measure in the “rotated” basis @xmath , with @xmath . The outcomes on
this basis have no dependence on @xmath ( @xmath for both measurements
for every @xmath ) and hence yield no information whatsoever on the
parameter, @xmath . It can be shown that the original basis @xmath is,
in fact, the most capable of distinguishing values of @xmath . The
quantum Fisher information for the estimation of @xmath , denoted @xmath
, of the state @xmath from Eq. ( 60 ) is precisely the Fisher
information of the best measurement,

  -- -------- -- ------
     @xmath      (62)
  -- -------- -- ------

Now turning to a more formal discussion, we know from Section POVMs that
all possible measurements on a quantum system are given by POVMs. In the
above example, simple orthogonal projectors were used, @xmath , @xmath ,
@xmath , @xmath , and the POVMs employed to obtain the Fisher
information were @xmath for @xmath and @xmath for @xmath . In general,
the quantum Fisher information for estimation of parameter @xmath is
defined as the maximum of the Fisher information over all POVMs, i.e.,

  -- -- -- ------
           (63)
  -- -- -- ------

where we have used that @xmath .

The Cramér-Rao bound is still valid for @xmath , but it is now a bound
not on the error of a specific estimation procedure, but on the error of
any estimation of @xmath from state @xmath . The quantum Cramér-Rao
bound reads

  -- -------- -- ------
     @xmath      (64)
  -- -------- -- ------

We are interested, however, in viewing the quantum Fisher information in
a different light. We have seen that it is a quantity depending only on
the state @xmath and on its dependence on the parameter @xmath . The
example given in Fig. 4 shows that the “classical” Fisher information
can measure how much probability distributions grow apart as the
parameter varies. Since the quantum version maximizes the Fisher
information over all possible measurements, @xmath should be sensitive
to any variation of @xmath . In fact, we now show an important result
that substantiates this interpretation.

Suppose one is interested in distinguishing two neighboring states,
characterized by parameter values @xmath and @xmath , using measurements
indicated by the POVM @xmath . The Hellinger distance Eq.( 55 ) between
the two probability distributions is

  -- -------- -- ------
     @xmath      (65)
  -- -------- -- ------

Now let us assume that @xmath and @xmath are infinitesimally separated,
@xmath . We know from Eq. ( 58 ) that @xmath is related to the
(“classical”) Fisher information @xmath , so that

  -- -------- -- ------
     @xmath      (66)
  -- -------- -- ------

The subscript on the right-hand side serves as a reminder that this
equation is valid for any POVM. By choosing the POVM that maximizes this
equation, both left- and right-hand sides at the same time. By writing
the above for such a POVM, we obtain, due to the definition of the
quantum Fisher information and to Eq. ( 33 ),

  -- -------- -- ------
     @xmath      (67)
  -- -------- -- ------

or, solving for @xmath ,

  -- -------- -- ------
     @xmath      (68)
  -- -------- -- ------

This very important relation shows that, as we have mentioned less
formally, the quantum Fisher information is a measure of the rate at
which a state becomes distinct following the variation of a parameter.
When the parameter in question is time, @xmath can be understood as a
speed of the evolving state. This result will be relevant for our
geometrically-derived bound in the next Section.

Another important expression for the quantum Fisher information can be
obtained by the use of the symmetric logarithmic derivative @xmath [ 106
, 107 ] . For a given parameter @xmath and a given state @xmath , @xmath
is the Hermitian operator implicitly defined by

  -- -------- -- ------
     @xmath      (69)
  -- -------- -- ------

This is, in fact, a way to quantize the classical expression @xmath
accounting for the non-commutativity of @xmath and @xmath . The
existence of such an operator is guaranteed by an application of the
Riesz-Fréchet theorem to Hilbert spaces [ 107 , p.257] .

We reproduce the derivation in [ 99 , p.37] of the relation linking
@xmath to @xmath . It begins with a bound on @xmath , obtained observing
that

  ---------------------------------------------------------------------- -------- -------- -- -------
                                                                                              
                                                                         @xmath   @xmath      (70a)
                                                                                              (70b)
                                                                                              (70c)
                                                                                  @xmath      (70d)
  But the inner product @xmath obeys the Cauchy-Schwarz inequality, so                        
                                                                                              
                                                                         @xmath   @xmath      (70e)
                                                                                  @xmath      (70f)
  ---------------------------------------------------------------------- -------- -------- -- -------

The quantum Fisher information is then bounded by

  -- -------- -------- -- -------
                          
     @xmath   @xmath      (71a)
              @xmath      (71b)
              @xmath      (71c)
  -- -------- -------- -- -------

To demonstrate the equality, we must show that there is a POVM @xmath
such that both inequalities in Eqs. ( 70 ) turn into equalities for all
@xmath . For Eq. ( 70d ), equality amounts to

  -- -------- -- ------
     @xmath      (72)
  -- -------- -- ------

while equality in the Cauchy-Schwarz relation of Eq. ( 70e ) is
equivalent to

  -- -------- -- ------
     @xmath      (73)
  -- -------- -- ------

for some ²⁵ ²⁵ 25 The case @xmath need not obey Eq. ( 73 ), but attains
both equalities in Eqs. ( 70d , 70e ) trivially, since @xmath . complex
@xmath . We remark that if a POVM obeys Eq. ( 73 ) with real @xmath for
all @xmath , both conditions are met. But this last equation can be
rewritten as

  -- -------- -- ------
     @xmath      (74)
  -- -------- -- ------

By taking projector POVMs, such that @xmath , we can assure that there
is at least one solution to the above for each @xmath , because @xmath
is Hermitian and hence diagonalizable with real eigenvalues.

We have thus shown that the quantum Fisher information can be written as

  -- -------- -- ------
     @xmath      (75)
  -- -------- -- ------

This can be understood as an alternate definition of the quantum Fisher
information, somewhat analogous to Eq. ( 52 ). The concision of this
expression does not incur in an easier calculation of @xmath , since the
symmetric logarithmic derivative is often cumbersome to obtain. We show
in Section Calculating the quantum Fisher information a more feasible
method of calculating the quantum Fisher information developed by our
group [ 112 , 111 ] .

We now turn to the Section where we present our main result.

### The most general quantum speed limit

We are now ready to derive our main result, the bound on quantum
evolutions be they unitary or not. This is a bound that encompasses any
kind of evolution a quantum system can undergo. Because non-unitary
evolutions can turn pure states into mixed ones, the first step will be
to define a distance valid for mixed as well as pure states. We make
extensive use of the purifications presented in Section Purifications .

#### A distance for all quantum states

Along the lines of Section Geometric Approach , we are interested in
metrics that can be computed by integrating a differential form. Let us
define the differential form of the distance between two neighboring
states @xmath and @xmath as the minimal Fubini-Study differential of
their respective purifications @xmath and @xmath ,

  -- -------- -- ------
     @xmath      (76)
  -- -------- -- ------

where the minimum is taken over all purifications of @xmath and @xmath ,
but can equivalently be taken over the purifications of only one of the
states. The corresponding length is

  -- -------- -- ------
     @xmath      (77)
  -- -------- -- ------

We are interested in minimizing not the integrand, but the integrated
length. The first condition to do so is to have a non-negative
integrand, which @xmath is by definition. A second potential hindrance
would be the fact that each state @xmath along the path belongs to two
differentials on the integration, @xmath and @xmath , except for the
path endpoints. The purification of @xmath used to minimize the distance
of the first pair could, in principle, not be compatible with minimizing
the latter pair. This is however not the case, because we know @xmath
can be expressed as a decreasing function of the fidelity @xmath (or
overlap) of two pure states, and we have seen in Eq. ( 31 ) that the
maximization of the fidelity of two purifications can be performed
varying the purification of only one of the mixed states. We may then
write

  -- -------- -- ------
     @xmath      (78)
  -- -------- -- ------

where minimization is now performed over all purifications of each state
of the path.

A distance can, as before, be defined as the length of the shortest path
between two states,

  -- -------- -- ------
     @xmath      (79)
  -- -------- -- ------

but the order of the minimizations may be inverted, so that

  -- -------- -- ------
     @xmath      (80)
  -- -------- -- ------

with the minimization being performed over all purifications @xmath ,
@xmath of @xmath , @xmath . Because @xmath is a decreasing function of
the fidelity, we can write

  -- -------- -- ------
     @xmath      (81)
  -- -------- -- ------

where we have used Uhlmann’s theorem, Eq. ( 31 ).

This distance is called Bures angle (among other names, see footnote on
p. Comments on another distance ), and is not only valid as a distance
for mixed quantum states, but also possesses the most important of the
Riemannian features, that of being able to be obtained as an integral of
a differential @xmath . Just as with the Fubini-Study distance on p. 13
, a consistency check left to reader is to verify that @xmath for
infinitesimally separated @xmath , @xmath .

It is indeed quite intuitive to generalize the Fubini-Study distance to
mixed states by replacing the pure-state fidelity for the Bures
fidelity, but there are two reasons for carrying the derivation as
above. Firstly, it explicitly shows the relation between the finite
Bures angle and its differential @xmath . Secondly, there are other
functions of two mixed states that recover the pure-state fidelity in
the proper limit; this route reinforces the importance of the Bures
fidelity by naturally arriving at it via Uhlmann’s theorem.

#### The bound

We now have a proper distance also for mixed states, but what is its
relation to the dynamics of a quantum system? This is our main result,
obtained in collaboration with B.M. Escher, L. Davidovich, R.L. de Matos
Filho and published in [ 82 ] .

Let us consider a state @xmath which evolves in time from @xmath to
@xmath and travels a given path. The length of this path is necessarily
greater than (or equal to) the distance between @xmath and @xmath . This
statement, written in a shorthand notation in which @xmath is the
distance between these two states (and analogously for any @xmath at
other times), reads

  -- -------- -- ------
     @xmath      (82)
  -- -------- -- ------

But @xmath can be written in terms of @xmath by noting that

  -- -------- -- ------
     @xmath      (83)
  -- -------- -- ------

so that, with @xmath and taking @xmath to be infinitesimal,

  -- -------- -- ------
     @xmath      (84)
  -- -------- -- ------

The length is then written as

  -- -------- -- ------
     @xmath      (85)
  -- -------- -- ------

Since only through the Bures fidelity does the distance depend on the
states, and hence on the parameter @xmath , the integrand can be
calculated using the chain rule,

  -- -------- -- ------
     @xmath      (86)
  -- -------- -- ------

where @xmath and @xmath is a notation used to stress that the distance
@xmath is a function of @xmath . We know from the relation between these
two (Eq. 81 ) that @xmath tends to infinity in the limit at hand, @xmath
. Furthermore, Eq. ( 68 ) informs us that the first derivative of @xmath
, @xmath vanishes for @xmath . The indeterminacy can be removed with the
aid of l’Hôpital’s rule,

  -- -------- -- ------
     @xmath      (87)
  -- -------- -- ------

The numerator is, due to Eq. ( 68 ), proportional to the quantum Fisher
information. The denominator, when multiplied and divided by @xmath ,
yields

  -- -------- -- ------
     @xmath      (88)
  -- -------- -- ------

The first factor in parentheses can be calculated independently of
@xmath by replacing the limit @xmath by @xmath since the metric @xmath
only depends on @xmath through @xmath . The second factor in parentheses
is simply a recurrence of @xmath , the term we are calculating.
Substituting in ( 87 ) and rearranging the terms, one finds

  -- -------- -- ------
     @xmath      (89)
  -- -------- -- ------

Multiplying and dividing by @xmath , the length is given by

  -- -------- -- ------
     @xmath      (90)
  -- -------- -- ------

and substitution in Eq. ( 82 ) leads to the general bound

  -- -- -- ------
           (91)
  -- -- -- ------

Let us make three comments about the formula above. First, the integral
of the quantum Fisher information is to be interpreted as a path
integral parametrized by time @xmath . @xmath is a local quantity,
dependent on the state at @xmath and its neighboring values, and hence
dependent on the chosen path. Another relevant remark is that the
freedom to regauge the distance by a constant @xmath , @xmath , does not
affect the bound, since the @xmath -dependent prefactor in the equation
cancels such a constant. Lastly, because @xmath diverges at @xmath , the
bound can be rewritten as

  -- -------- -- ------
     @xmath      (92)
  -- -------- -- ------

and this shows that this prefactor depends on the curvature of the graph
of @xmath as a function of @xmath at @xmath .

We can now replace @xmath for @xmath :

  -- -------- -- ------
     @xmath      (93)
  -- -------- -- ------

where the prefactor tends to one. This is the main result of the present
thesis. It can be summarized as: the length of the traveled path in
state space must be less than (or equal to) the distance between initial
and final states. For infinitesimal variations, the length is in fact
equal to the distance. This implies that the relation above is an
equality in the immediate vicinity of @xmath . Eq. ( 68 ) applied to
time serves as a suitable expansion to show that the bound is saturated
up to second order in time:

  -- -------- -- ------
     @xmath      (94)
  -- -------- -- ------

Although originally defined in quantum metrology, the quantum Fisher
information for time estimation is closely related to the dynamics of
the system. This is seen best by remembering that @xmath and seeing that

  -- -------- -- ------
     @xmath      (95)
  -- -------- -- ------

where the dot over @xmath represents the time derivative. In fact, there
is a closed form for @xmath for unitary evolutions which clearly
reflects the dynamics of the system. Any unitary evolution can be
written as

  -- -------- -- ------
     @xmath      (96)
  -- -------- -- ------

with @xmath , and equivalently as

  -- -------- -- ------
     @xmath      (97)
  -- -------- -- ------

with @xmath being the Hamiltonian governing the evolution, @xmath .

For a system always in pure states, the relation @xmath can be derived
with respect to time, so

  -- -------- -- -------
     @xmath      (98)
     @xmath      (99)
     @xmath      (100)
  -- -------- -- -------

such that

  -- -------- -- -------
     @xmath      (101)
     @xmath      (102)
  -- -------- -- -------

The last two, together with @xmath , allow us to write

  -- -------- -------- -- -------
     @xmath   @xmath      (103)
              @xmath      (104)
              @xmath      (105)
              @xmath      (106)
              @xmath      (107)
              @xmath      (108)
  -- -------- -------- -- -------

where @xmath is the variance of @xmath . We thus see that, for unitary
pure-state evolutions, the quantum Fisher information for time
estimation is simply the energy variance of the system. Substituting
this result in the general bound, Eq. ( 93 ), we exactly recover the
Mandelstam-Tamm bound for unitary evolutions, Eqs. ( 16 ), ( 50 ). The
result of Eq. ( 108 ) will be of utmost importance to the method we will
present in Section Calculating the quantum Fisher information to
calculate the quantum Fisher information.

This geometric derivation provides, as before, a clear criterion for
saturation. Equality will prevail on Eq. ( 93 ) if, and only if, the
state travels on a geodesic. We note that pure-state geodesics are still
geodesics on the space of density operators, but that there are more
geodesic paths, even for a qubit. In Chapter Applying the bounds , we
apply this bound to different examples, and in some cases we will see
saturation, i.e., evolution on geodesics.

A last comment is that related derivations are possible for parameter
estimation, with which the precision of estimates of parameter @xmath
can be bound employing the quantum Fisher information for estimation of
@xmath , @xmath .

### Additional results

We now present additional bounds, which may not have the generality of
the main result above, but are steps in the way of establishing the
Margolus-Levitin bound in a more structured, geometric framework. We
later show that one of these bounds can be saturated in conditions under
which neither the Mandelstam-Tamm nor the Margolus-Levitin bounds are.
The contents of this Section can be considered as partial results in a
work in progress.

This calculation is valid for pure states only, evolving unitarily under
a time-independent Hamiltonian. We base our derivation partially on the
calculations by Zwierz [ 50 ] . If the governing Hamiltonian is denoted
@xmath , the state @xmath of the system (initially in @xmath ), obeys

  -- -------- -- -------
     @xmath      (109)
  -- -------- -- -------

where @xmath is a real function explicitly depicting the freedom to
choose the ground-state energy. The distance @xmath between initial and
final states varies in time according to

  -- -------- -- -- -------
     @xmath         (110)
                    (111)
                    (112)
  -- -------- -- -- -------

where we used the fact that @xmath . This implies that the bound can
only be saturated while the distance decreases monotonically.
Furthermore, since @xmath , the square root on the last equation reduces
to @xmath , so that we can write

  -- -- -- -------
           (113)
  -- -- -- -------

where the argument @xmath of @xmath has been simplified to @xmath for
cleanness. The derivative of @xmath can be bounded by

  -- -- -- -- -------
              (114)
              (115)
              (116)
              (117)
  -- -- -- -- -------

such that

  -- -- -- -------
           (118)
  -- -- -- -------

This bound is valid for any real function @xmath but, unlike the
equation of motion, it is (non-trivially) affected by the choice of
@xmath . We could simply minimize the right-hand side over @xmath in
order to arrive at the tightest bound possible from the above equation,
but we can obtain a more insightful bound making a different
minimization ²⁶ ²⁶ 26 It is left as an exercise to the reader to show
that the direct minimization of Eq. ( 118 ) yields @xmath . The
impracticality of this expression can be seen from the difficulty to
assign a physical meaning to this quantity. .

Let us expand @xmath in the energy eigenbasis, @xmath . We obtain, for
the numerator of the right-hand side of Eq. ( 118 ),

  -- -------- -- -------
     @xmath      (119)
  -- -------- -- -------

where we have used the triangle inequality for complex numbers. The
right-hand side of this equation, when substituted in Eq. ( 118 ), still
leads to a bound on @xmath . We then choose to minimize the quantity on
the right-hand side. The value of @xmath yielding this minimum is
independent of @xmath , and we write it simply as @xmath . Our goal is,
then, to minimize

  -- -- -- -------
           (120)
  -- -- -- -------

with respect to @xmath , given @xmath and @xmath , i.e., given a
probability distribution for the set of energy values. This minimization
is performed in Appendix Minimization yielding the median , and yields
@xmath equal to the median of the energy distribution, @xmath .

We can obtain

  -- -- -- -------
           (121)
  -- -- -- -------

using the fact that @xmath granted by Eq. ( 119 ). This substitution
makes the bound less tight, but has the advantage of possessing a simple
time-dependence, since the right-hand side of the above is
time-independent. Integration with respect to time in this case is
straightforward,

  -- -- -- -------
           (122)
  -- -- -- -------

and, upon inversion, one finds

  -- -- -- -------
           (123)
  -- -- -- -------

A tighter bound, however, is obtained replacing @xmath directly in Eq. (
118 ). This is licit because this equation is valid for any @xmath . We
thus arrive at

  -- -- -- -------
           (124)
  -- -- -- -------

Integrating with respect to time, we obtain

  -- -- -- -------
           (125)
  -- -- -- -------

Both bounds can be thought of as of the Margolus-Levitin kind due to
their dependence on the average energy, but are independent from the
known Margolus-Levitin bound in the sense that they do not recover it.
We show in Section Application of the additional bound that the latter
bound, Eq. ( 125 ), can be tight in cases where neither the
Mandelstam-Tamm nor the Margolus-Levitin bound are, a fact which vouches
for its usefulness.

##### Chapter Summary and Next Steps

We have derived our novel results in this Chapter, preceded by the
necessary framework. The most general (and most important) bound is
given by Eq. ( 93 ) in Section The most general quantum speed limit . We
begin the next Chapter by presenting an important method for calculating
the quantum Fisher information in Section Calculating the quantum Fisher
information , instrumental to the application of our main bound to
physical examples, which is done later in Section Application to
non-unitary channels . Application of our additional bounds is left to
Section Application of the additional bound .

## Applying the bounds

After having presented our novel results in the last Chapter, we now
devote ourselves to the application of those bounds to physical
evolutions. We start by introducing in Section Calculating the quantum
Fisher information an important technique, developed by collaborators
B.M. Escher, N. Zagury, R.L. de Matos Filho and L. Davidovich [ 112 ,
111 ] , for obtaining the quantum Fisher information, a quantity central
to our main result of Eq. ( 93 ). In Section Application to non-unitary
channels we proceed to the actual application of the bound to
non-unitary evolutions. Section Application of the additional bound is
left to the application of the additional bounds of Eqs. ( 123 , 125 ).

### Calculating the quantum Fisher information

#### A purification-based expression

An apparent disadvantage of our bound of Eq. ( 93 ) is the difficulty to
calculate the quantum Fisher information. We here present a method which
enables the calculation of this quantity based on purifications.

The basic idea is that the non-unitary evolution of a given system can
be described by the unitary evolution of its purification. We have seen
in Eq. ( 108 ) that the quantum Fisher information of a unitary
evolution is easy to evaluate. We will see how the quantum Fisher
information of the original system and that of its purification are
related.

Let us consider, as in Section Purifications , a system @xmath in state
@xmath evolving non-unitarily. A purification of @xmath requires an
auxiliary system, denoted @xmath (for “environment”), and is given by a
joint state @xmath such that

  -- -------- -- -------
     @xmath      (126)
  -- -------- -- -------

Let us consider @xmath to be an arbitrary purification of @xmath out of
the infinitely many possible. Because @xmath contains all information
about @xmath , it is physically reasonable that the quantum Fisher
information of the former is at least as great as that of the latter. In
fact, the quantum Fisher information of @xmath , denoted @xmath , acts
as an upper bound on the quantum Fisher information of @xmath . This can
be shown by using the definition of quantum Fisher information, Eq. ( 63
), as well as the fact that a POVM element @xmath acting only on @xmath
can be understood as @xmath , where @xmath is the identity on @xmath :

  -- -------- -- -------
     @xmath      (127)
  -- -------- -- -------

We can then write the quantum Fisher information of the state of @xmath
as

  -- -------- -- -------
     @xmath      (128)
  -- -------- -- -------

whereas that of the purification reads

  -- -------- -- -------
     @xmath      (129)
  -- -------- -- -------

where @xmath is a POVM element acting on the joint system @xmath . The
quantum Fisher information of the purification is then the result of a
maximization over all POVMs on @xmath , a larger family than that of the
original system, i.e., @xmath is maximized on a subset of that used for
@xmath . Hence @xmath .

The state @xmath remains pure along its evolution, which must then be
describable by a unitary operator @xmath . The Hamiltonian governing the
evolution can always be found by @xmath , and we know from Eq. ( 108 )
that the quantum Fisher information of a unitary evolution is
proportional to the variance of its Hamiltonian, so that

  -- -------- -- -------
     @xmath      (130)
  -- -------- -- -------

Bringing these results together, we can find a bound on evolution times
written in terms of @xmath ,

  -- -------- -- -------
     @xmath      (131)
  -- -------- -- -------

Written in this form, in terms of any purification of @xmath , the bound
may or may not be tight. The choice of purification in fact affects the
saturation of the speed limit.

We show in Appendix Tightness of the bound on the quantum Fisher
information that for each evolution there is at least one purification
whose quantum Fisher information equals that of the original system,
i.e., there is a purification such that @xmath . It can be obtained by
minimizing @xmath , or equivalently @xmath , over all purifications such
that @xmath has the same dimension as @xmath . This means that all
saturation features of our main bound carry over to the above if one
minimizes over such purifications.

In some situations it may, however, be advantageous to forgo the exact
obtention of @xmath and minimize @xmath over a restricted family of
purifications for the sake of practicality. We undertake both full and
partial optimization in the examples in the next Section.

Before we move on to the non-unitary channels, we mention that which is
perhaps the simplest application of this purification procedure: an
initially mixed state of @xmath evolving unitarily. It is possible to
purify it such that the Hamiltonian governing the evolution of the
purification @xmath is the original Hamiltonian acting on the mixed
state. Applying this to Eq. ( 131 ), one can generalize Eqs. ( 7 , 50 )
to

  -- -------- -- -------
     @xmath      (132)
  -- -------- -- -------

where the standard deviation @xmath of the Hamiltonian is calculated in
the pure or mixed state of system @xmath . This result for unitary
evolutions has been shown by Uhlmann in [ 42 ] also by geometric means.
In this case, the purification yielding the minimum is in fact the one
governed by the original Hamiltonian, so that the bound above is tight
under the same conditions of the general bound.

### Application to non-unitary channels

We now consider some examples of non-unitary evolutions, or channels, to
which we apply our bound. As mentioned previously, our description is
made in terms of purifications. Given a state @xmath of system @xmath
that evolves non-unitarily, let @xmath be a purification of it. The
evolution of this pure state in time can always be described by a
suitable unitary operator, denoted @xmath , so that @xmath .

We know from the previous Section that, in order to obtain the quantum
Fisher information (or a useful bound on it), we need the variance of
the Hamiltonian @xmath respective to @xmath ,

  -- -------- -- -------
     @xmath      (133)
  -- -------- -- -------

This variance is, in principle, to be evaluated at time @xmath , i.e.,
in state @xmath . There is nevertheless a tactic to make this evaluation
easier: the expectation value of an operator in state @xmath can be cast
as an expectation value in the initial state @xmath if the evolution
operators are “absorbed” by @xmath . For an operator that satisfies

  -- -------- -- -------
     @xmath      (134)
  -- -------- -- -------

its averaging obeys

  -- -- -- -------
           (135)
  -- -- -- -------

and the same goes for any polynomial function of @xmath . This
definition presents a practical advantage: the form of the state in
which the expectation values are taken is simplified, because there is
no time dependence anymore, but the operator maintains a similar level
of complexity when expressed in terms of @xmath ,

  -- -------- -- -------
     @xmath      (136)
  -- -------- -- -------

(compare Eq. 133 ). This equation can, in fact, be taken as a definition
of @xmath . This tactic is not restricted to @xmath , along this Chapter
we define several analogous operators based on different unitaries. The
use of fraktur/gothic or other modified fonts always denotes the
employment of this tactic for initial-state averaging, see Table 1 . We
note that, for self-commuting Hamiltonians, @xmath , this tactic does
not change the operator, i.e., @xmath .

Another important point is that the purification @xmath of the process
characterized by @xmath is not unique. The freedom to choose different
purifications can be expressed in the following manner: given a first
purification @xmath and its unitary evolution operator @xmath , every
other purification of the process can be obtained through

  -- -------- -- -------
     @xmath      (137)
  -- -------- -- -------

by varying @xmath , a unitary operator acting only on system @xmath
(note that @xmath is also unitary). When we need to minimize over all
purifications, as required by Section Calculating the quantum Fisher
information , it suffices to minimize over all unitary operators @xmath
acting on the environment @xmath only.

Moreover, we are interested in minimizing the variance of the
Hamiltonian corresponding to the unitary operator @xmath . We once again
use the tactic for initial-state averaging, so that we are faced with
the problem of minimizing the variance of

  -- -------- -- -------
     @xmath      (138)
  -- -------- -- -------

It is straightforward to show that @xmath can be written as

  -- -------- -- -------
     @xmath      (139)
  -- -------- -- -------

where @xmath is defined from @xmath analogously to the way @xmath was
from @xmath , see Table 1 . The minimization over @xmath then amounts to
minimizing over all possible Hermitian operators @xmath .

Turning once more to the mixed state evolving unitarily, the suitable
first purification is that whose evolution is governed by the original
Hamiltonian. It is then straightforward to see that @xmath ,
corresponding to @xmath , yields the minimal variance of @xmath from
Eq. ( 139 ).

#### Amplitude-damping channel

The first example to which we apply our bound is the so-called
amplitude-damping channel. This channel is useful for describing energy
loss: a qubit (system @xmath ) initially in the excited state @xmath
that decays onto the ground state @xmath . We suppose there is a
probability @xmath of @xmath not decaying to @xmath in the interval
@xmath (conversely, a probability @xmath of a @xmath -decay up to time
@xmath ; it should be clear that @xmath ). This evolution of @xmath is
described by

  -- -- -- -------
           (140)
  -- -- -- -------

with the representation @xmath , @xmath . The most prevalent case of the
amplitude-damping channel is when @xmath and the system is initially in
the excited state @xmath . In this scenario, the qubit evolves along
mixtures of @xmath and @xmath with varying weights. In the Bloch sphere,
this corresponds to a path along the axis connecting @xmath to @xmath ,
see Fig. 5 .

For the purposes of calculating the quantum Fisher information, we now
need to write the evolution of @xmath in the form of a purification,
which explicitly includes an auxiliary system @xmath . System @xmath
only needs to be a qubit, so whenever the initial state of @xmath is
pure the channel can be described by

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (141a)
     @xmath               (141b)
  -- -------- -------- -- --------

where @xmath is chosen as the initial state of @xmath and @xmath is
orthogonal to it ²⁷ ²⁷ 27 It is left as an exercise to the reader to
show that Eq. ( 140 ) is recovered by taking the partial trace (over
@xmath ) of Eq. ( 141 ) . This is actually the most common way of
describing the amplitude-damping channel. We presented the @xmath
-contained form of Eq. ( 140 ) to emphasize that we are interested in
treating the evolution of @xmath , not of @xmath , and that the
auxiliary system @xmath is, as far as this treatment is concerned, a
tool which we take full liberty to explore.

The evolution of this purification is given by the following unitary
operator on @xmath

  -- -------- -- -------
     @xmath      (142)
  -- -------- -- -------

where @xmath are raising and lowering operators of qubit @xmath ( @xmath
, @xmath , @xmath ), and analogously for @xmath on @xmath . The
Hamiltonian for this evolution (corrected for initial-state averaging)
is

  -- -------- -- -------
     @xmath      (143)
  -- -------- -- -------

from which we obtain the bound @xmath on the quantum Fisher information:

  -- -- -- -------
           (144)
  -- -- -- -------

where the variance is calculated in the initial state of @xmath (hence
the expectation value @xmath is to be calculated in the initial state of
@xmath ). The corresponding bound on evolution time is given by

  -- -- -- -------
           (145)
  -- -- -- -------

A first result is that if the initial state of @xmath is @xmath , the
bound shows exactly that the distance @xmath remains zero, as it must
according to Eq. ( 141a ). Furthermore, if @xmath is a monotonic
(decreasing) function of @xmath , integration can be performed at once
and yields

  -- -- -- -------
           (146)
  -- -- -- -------

An example is the exponential damping @xmath , for which

  -- -- -- -------
           (147)
  -- -- -- -------

or

  -- -- -- -------
           (148)
  -- -- -- -------

If system @xmath is initially in state @xmath , the expectation value
@xmath and the bound is saturated, since for this case @xmath , see
Eq. ( 146 ). We can draw a couple of conclusions from this fact.
Firstly, saturation implies that @xmath above is the minimum over
different purifications for initial states @xmath or @xmath , i.e.
@xmath . This is, in fact, an exception: we see in the next Subsections
that the first, most intuitive purification does not usually yield the
minimum, and an optimization must be performed.

Secondly, saturation implies that the path from @xmath to @xmath through
mixed states of Fig. 5 is a geodesic. We have seen in Section Geometric
Approach that great circles of the Bloch sphere are the geodesics
between two orthogonal states; the inclusion of mixed states adds this
path (among others) to the set. We should also note that the geometry of
the Bures angle is radically different from the usual, Euclidean
geometry on the Bloch sphere, since both a diameter and a great
semi-circle have here the same length (as shown in Fig. 5 ).

Another feature of the result is that the bound saturates for any
monotonic @xmath . This is a manifestation of the geometric nature of
the bound, since varying @xmath among monotonic functions can be
understood as a rescaling of the time parameter, still on the route of
Fig. 5 . A non-monotonic @xmath would imply going back and forth along
the path, which cannot constitute a geodesic, and the bound is no longer
saturated.

A special case of this channel is a two-level atom interacting with an
external field modeled by the resonant Jaynes-Cummings Hamiltonian when
there is only one quantum of energy in the compound system. If we take
the atom to be system @xmath and the external field as @xmath , the
interaction is given by @xmath , @xmath being a coupling constant. Eq. (
141 ) is obeyed with @xmath up to the first root of @xmath , which is
the relevant short-time regime for speed limits. The bound is then also
saturated, since it predicts

  -- -------- -- -------
     @xmath      (149)
  -- -------- -- -------

#### Single-qubit dephasing

We now present an interaction typically used to describe the generation
of decoherence, the dephasing. In this Markov evolution, a qubit (system
@xmath ) loses information on the relative phase between its @xmath and
@xmath components. This channel can arise physically when a system
interacts with many external degrees of freedom without energy loss. An
example is a particle scattering off of many different atoms in a
medium, with each scattering being elastic. Energy is a constant of
motion, but the relative phase accumulated between the energy
eigenstates depends on the time during which scattering took place. This
time is usually not known (partly because it is a function of the
precise path in physical space traveled by the particle, which is also
unknown), hence there is a gradual loss of phase information.

The system Hamiltonian is @xmath , with @xmath being the Pauli operator
on @xmath ( @xmath , @xmath ) and analogously for @xmath , @xmath . The
evolution can be written as

  -- -------- -- -------
     @xmath      (150)
  -- -------- -- -------

where, in addition to the Hamiltonian term ( @xmath ), there is a term
proportional to @xmath modeling the loss of phase information. In terms
of the Bloch sphere, the term in @xmath is responsible for a rotation
around the @xmath -axis, whereas the term in @xmath reduces the @xmath ,
@xmath components of the vector, or the distance from the vector to the
@xmath -axis. The trajectory is contained in a plane perpendicular to
the @xmath -axis, and the expectation value @xmath is constant
throughout the motion, see Fig. 6 . For sufficiently long times, the
state is an incoherent mixture of @xmath , @xmath . It is customary to
treat the dephasing channel in the interaction picture so that the
Hamiltonian part of the evolution (rotation around the @xmath -axis)
does not manifest itself in the state of the system, but it is not licit
to do so in our problem for the reasons pointed out on p. Main concepts
and existing literature .

Let us now introduce a purification describing the dephasing channel.
The auxiliary system @xmath once again only needs to be a qubit. With
the initial state of @xmath assumed pure, @xmath can be initially
separable, and hence the initial state of @xmath can be chosen to be
@xmath :

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (151a)
     @xmath   @xmath      (151b)
  -- -------- -------- -- --------

with ²⁸ ²⁸ 28 It is left once again as an exercise to the reader to show
that Eq. ( 150 ) is recovered by taking the partial trace (over @xmath )
of Eq. ( 151 ) and deriving the resulting @xmath with respect to time.
@xmath . The purity of the initial state of @xmath poses no restriction,
since, in this channel, every evolution starting in a mixed state of
@xmath can be seen as part of a longer evolution (starting earlier in
time) from a pure state.

The matching evolution operator on @xmath is

  -- -------- -- -------
     @xmath      (152)
  -- -------- -- -------

where @xmath is a Pauli operator acting on qubit @xmath . The
corresponding Hamiltonian corrected for initial-state averaging is

  -- -------- -- -------
     @xmath      (153)
  -- -------- -- -------

The bound @xmath on the quantum Fisher information obtained from this
@xmath is

  -- -------- -- -------
     @xmath      (154)
  -- -------- -- -------

where @xmath is the variance of @xmath , again to be evaluated in the
initial state of @xmath . A quantum speed limit can already be obtained
from it, but this is just one of the many possible purifications of this
channel; any additional unitary operator @xmath applied to the
right-hand side of Eq. ( 151 ) maintains its partial trace unaltered. To
minimize @xmath over different purifications, we have to minimize the
variance of @xmath from Eq. ( 139 ) over all possible operators @xmath .
Since @xmath is a qubit, we only need to minimize over all Hermitian
@xmath operators, which can in general be written in terms of the Pauli
operators and the identity. Furthermore, the addition of an identity
does not affect the variance of an operator, so that, for our purposes,
the most general form of @xmath is

  -- -------- -- -------
     @xmath      (155)
  -- -------- -- -------

where @xmath , @xmath , @xmath are real parameters to minimize over, and
@xmath , @xmath , @xmath are Pauli operators acting on qubit @xmath .
This minimization is performed in Appendix Optimization of the bound for
the dephasing channel , and the result is

  -- -------- -- -------
     @xmath      (156)
  -- -------- -- -------

dependent on the initial-state variance @xmath of @xmath . This leads to
the following implicit bound on @xmath

  -- -------- -- -------
     @xmath      (157)
  -- -------- -- -------

where @xmath is the standard deviation of @xmath .

A first feature of the bound is that it correctly portrays the
non-evolution of eigenstates of @xmath . Moreover, in the two extreme
cases @xmath or @xmath , Eq. ( 157 ) reduces to simple analytical
expressions. For the former, the evolution becomes once again unitary,
and the Mandelstam-Tamm bound is recovered [compare Eq. ( 7 )]

  -- -------- -- -------
     @xmath      (158)
  -- -------- -- -------

For the latter, the bound reduces to

  -- -------- -- -------
     @xmath      (159)
  -- -------- -- -------

from which one sees that the distance from initial to final states
cannot exceed @xmath . Equivalently, we can write

  -- -------- -- -------
     @xmath      (160)
  -- -------- -- -------

The bound can be saturated in this “pure-dephasing” ( @xmath ) case:
this happens when the initial state of the system is on the equator of
the Bloch sphere ( @xmath ), for which the bound yields

  -- -------- -- -------
     @xmath      (161)
  -- -------- -- -------

and the actual value of @xmath is indeed @xmath .

We can also analyze the asymptotic behavior of the bound for @xmath .
Integration of Eq. ( 157 ) over the region @xmath arrives at the
elliptic integral of the second kind ²⁹ ²⁹ 29 We adopt the notation
where the second argument @xmath is the so-called parameter of the
elliptic integral in all occurrences of @xmath . @xmath ,

  -- -------- -- -------
     @xmath      (162)
  -- -------- -- -------

with @xmath . Given the way the bound has been constructed, a bound for
@xmath serves as bound for the distance at any other time @xmath . In
Fig. 7 we have plotted the bound for @xmath for @xmath , an expression
bounding the distance at any time and for any initial state. From this
graph, we see that, analogously to Eq. ( 159 ), the bound guarantees
that orthogonal states are not reachable in finite time for certain
values of @xmath , namely @xmath (compare the amplitude-damping channel,
where @xmath evolves to @xmath ).

The integral in the general result on Eq. ( 157 ) is in fact solvable in
terms of elliptic integrals of the second kind @xmath ,

  -- -------- -- -------
     @xmath      (163)
  -- -------- -- -------

In Fig. 8 , we plot the relative discrepancy between the bound and the
distance as calculated exactly from its evolution. The exact distance in
the dephasing channel obeys

  -- -- -- -------
           (164)
  -- -- -- -------

and we see that the bound remains close to the exact result up to the
first minimum of the latter, which is the region of interest for quantum
speed limits. This is a display of the usefulness of the bound even when
it is not strictly tight.

#### Dephasing and entanglement

Another display of the usefulness of the bound lies in the discussion of
the relation between entanglement and quantum evolution time. This issue
concerns quantum systems composed of many ( @xmath ) subsystems and
consists in understanding the interplay between correlations among the
subsystems (especially entanglement) and the speed of evolution of the
system as a whole.

##### Established results for unitary evolutions

Several works [ 45 , 52 , 54 , 55 , 56 , 58 ] have shown that in unitary
evolutions entanglement is a resource that allows for a speed-up of
quantum evolution. Let us then compare the speed of separable and
entangled states. We assume that the subsystems do not interact among
themselves in order to guarantee that no entanglement is created in the
initially separable states.

We begin by applying the quantum speed limit to a separable pure state
in a unitary evolution, as done in [ 45 ] . Let us assume the bound
saturates for some time @xmath for the whole state,

  -- -------- -- -------
     @xmath      (165)
  -- -------- -- -------

Each subsystem @xmath has fidelity @xmath compared to its initial state
and energy spread @xmath , with @xmath and @xmath . Now, the quantum
speed limit can be applied to each subsystem, such that

  -- -------- -- -------
     @xmath      (166)
  -- -------- -- -------

and, inserting Eq. ( 165 ) into Eq. ( 166 ),

  -- -------- -- -------
     @xmath      (167)
  -- -------- -- -------

Moving @xmath to the left-hand side, squaring and summing on @xmath ,
one finds

  -- -------- -- -------
     @xmath      (168)
  -- -------- -- -------

where @xmath was also used. But a property of the function @xmath is
that it is subadditive in the sense that the left-hand side of the above
must be less than or equal to the right-hand side ³⁰ ³⁰ 30 The relation
@xmath for @xmath can be proven first for two variables and then by
induction. For two variables, one can use that, for any given value of
@xmath , equality holds for @xmath and that the derivative of the
left-hand side is greater than that of the right-hand side for @xmath .
. The only solution for Eq. ( 168 ), then, is for equality to hold. But
the condition for equality is that all arguments @xmath except for a
single @xmath , for which @xmath . This means that a separable state
cannot reach the quantum speed limit unless only a single subsystem
evolves and the remaining are stationary. For mixed separable states,
@xmath , the same is true of each term @xmath of the decomposition [ 45
] .

In contrast, an @xmath -party Greenberger-Horne-Zeilinger (GHZ) state of
the form @xmath — an example of a fully entangled state — can reach the
quantum speed limit. Saturation occurs on an evolution under a
Hamiltonian @xmath with @xmath and @xmath being the eigenstates of
@xmath . This can be seen by taking @xmath , where @xmath is the @xmath
Pauli operator acting on qubit @xmath . One obtains @xmath , with @xmath
.

A measure of the speed-up due to entanglement is obtained by comparing,
for @xmath , the @xmath -dependence of the evolution time of states
symmetric on all subsystems. For our purposes, we assume each subsystem
has energy spread @xmath (unaffected by variation of @xmath ) and the
global Hamiltonian is of the form @xmath . For separable states, the
bound on each subsystem is tighter than that for the state as a whole,
so relation ( 165 ) is eclipsed by the more relevant relation

  -- -------- -- -------
     @xmath      (169)
  -- -------- -- -------

where it was used that the fidelity for each subsystem relative to its
initial state equals @xmath . We then say that there is a @xmath scaling
of the time @xmath with the number of subsystems @xmath , where @xmath
is the time necessary to reach a certain distance (or fidelity). Every
separable state is limited by this scaling, there are states that reach
this bound, e.g., an initial state @xmath under @xmath . Note that the
scaling does not depend on the value of @xmath .

On the other hand, this scaling does not hold for entangled systems, the
GHZ state serves as a counterexample. It is symmetric in all subsystems
and, assuming the same evolution under @xmath , it obeys

  -- -------- -- -------
     @xmath      (170)
  -- -------- -- -------

with a clear @xmath scaling. The change in scaling from @xmath to @xmath
in going from separable to entangled states expresses the evolution
speed-up due to the presence of entanglement.

It can then be said that separable states are ‘‘slow’’ as compared to
the speed that entangled ones can reach ³¹ ³¹ 31 It should be noted that
entangled states are not necessarily fast, as can be seen by the
evolution of a fully entangled initial state @xmath under the same
@xmath as before. Assuming an even number of subsystems, this state does
not evolve at all. . Fröwis [ 58 ] has shown this shift in behavior in a
multi-qubit system by showing that the quantum Fisher information of a
unitary evolution of @xmath qubits is upper-bounded by @xmath for