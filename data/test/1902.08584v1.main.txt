### 2.1 Minimal cones

In this section we discuss two classical results on the theory of
minimal surfaces: Simons flatness result on stable minimal cones in low
dimensions and the Bombieri-De Giorgi-Giusti counterexample in high
dimensions. The main purpose of these lecture notes is to present the
main ideas and computations leading to these deep results – and to
related ones in subsequent sections. Therefore, to save time for this
purpose, we do not consider the most general classes of sets or
functions (defined through weak notions), but instead we assume them to
be regular enough.

Throughout the notes, for certain results we will refer to three other
expositions: the books of Giusti [ 28 ] and of Colding and Minicozzi [
16 ] , and the CIME lecture notes of Cozzi and Figalli [ 17 ] . The
notes [ 13 ] by the first author and Capella have a similar spirit to
the current ones and may complement them.

###### Definition 2.1 (Perimeter).

Let @xmath be an open set, regular enough. For a given open ball @xmath
we define the perimeter of @xmath in @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the @xmath -dimensional Hausdorff measure (see
Figure 2.1 ).

The interested reader can learn from [ 28 , 17 ] a more general notion
of perimeter (defined by duality or in a weak sense) and the concept of
set of finite perimeter.

###### Definition 2.2 (Minimal set).

We say that an open set (regular enough) @xmath is a minimal set (or a
set of minimal perimeter ) if and only if, for every given open ball
@xmath , it holds that

  -- -------- --
     @xmath   
  -- -------- --

for every open set @xmath (regular enough) such that @xmath .

In other words, @xmath has least perimeter in @xmath among all (regular)
sets which agree with @xmath outside @xmath .

To proceed, one considers small perturbations of a given set @xmath and
computes the first and second variations of the perimeter functional .
To this end, let @xmath be a one-parameter family of maps @xmath such
that @xmath is the identity @xmath and all the maps @xmath have compact
support (uniformly) contained in @xmath .

Consider the sets @xmath . We are interested in the perimeter functional
@xmath . One proceeds by choosing @xmath , which shifts the original set
@xmath in the normal direction @xmath to its boundary. Here @xmath is
the outer normal to @xmath and is extended in a neighborhood of @xmath
to agree with the gradient of the signed distance function to @xmath ,
as in [ 28 ] or in our Subsection 2.1.3 below. On the other hand, @xmath
is a scalar function with compact support in @xmath (see Figure 2.2 ).

It can be proved (see chapter 10 of [ 28 ] ) that the first and second
variations of perimeter are given by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (2.1)
     @xmath   @xmath   @xmath      (2.2)
  -- -------- -------- -------- -- -------

where @xmath is the mean curvature of @xmath at @xmath and @xmath is the
sum of the squares of the @xmath principal curvatures @xmath of @xmath
at @xmath . More precisely,

  -- -------- --
     @xmath   
  -- -------- --

In ( 2.2 ), @xmath (sometimes denoted by @xmath ) is the tangential
gradient to the surface @xmath , given by

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

for any function @xmath defined in a neighborhood of @xmath . Here
@xmath is the usual Euclidean gradient and @xmath is always the normal
vector to @xmath . Being @xmath the tangential gradient, one can check
that @xmath depends only on @xmath . It can be therefore computed for
functions @xmath defined only on @xmath (and not necessarily in a
neighborhood of @xmath ).

###### Definition 2.3.

1.  We say that @xmath is a minimal surface (or a stationary surface )
    if the first variation of perimeter vanishes for all balls @xmath .
    Equivalently, by ( 2.1 ), @xmath on @xmath .

2.  We say that @xmath is a stable minimal surface if @xmath and the
    second variation of perimeter is nonnegative for all balls @xmath .

3.  We say that @xmath is a minimizing minimal surface if @xmath is a
    minimal set as in Definition 2.2 .

We warn the reader that in some books or articles “minimal surface” may
mean “minimizing minimal surface”.

###### Remark 2.4.

1.  If @xmath is a minimal surface (i.e., @xmath ), the second variation
    of perimeter ( 2.2 ) becomes

      -- -------- -- -------
         @xmath      (2.4)
      -- -------- -- -------

2.  If @xmath is a minimizing minimal surface, then @xmath is a stable
    minimal surface. In fact, in this case the function @xmath has a
    global minimum at @xmath .

##### 2.1.1 The Simons cone. Minimality

###### Definition 2.5 (The Simons cone).

The Simons cone @xmath is the set

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

In what follows we will also use the following notation:

  -- -------- --
     @xmath   
  -- -------- --

Let us consider the open set

  -- -------- --
     @xmath   
  -- -------- --

and notice that @xmath (see Figure 2.3 ).

###### Exercise 2.1.

Prove that the Simons cone has zero mean curvature for every integer
@xmath . For this, use the following fact (that you may also try to
prove): if

  -- -------- --
     @xmath   
  -- -------- --

for some function @xmath , then the mean curvature of @xmath is given by

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

###### Remark 2.6.

It is easy to check that, in @xmath , @xmath is not a minimizing minimal
surface. In fact, referring to Figure 2.4 , the shortest way to go from
@xmath to @xmath is through the straight line. Thus, if we consider as a
competitor in @xmath the interior of the set

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the triangle with vertices @xmath , @xmath , @xmath ,
and @xmath is the symmetric of @xmath with respect to @xmath , we have
that @xmath has less perimeter in @xmath than @xmath .

In 1969 Bombieri, De Giorgi, and Giusti proved the following result.

###### Theorem 2.7 (Bombieri-De Giorgi-Giusti [5]).

If @xmath , then @xmath is a minimal set in @xmath . That is, if @xmath
, the Simons cone @xmath is a minimizing minimal surface.

The following is a clever proof of Theorem 2.7 found in 2009 by G. De
Philippis and E. Paolini ( [ 23 ] ). It is based on a calibration
argument . Let us first define

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

clearly we have that

  -- -------- --
     @xmath   
  -- -------- --

Let us also consider the vector field

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

###### Exercise 2.2.

Check that if @xmath , @xmath has the same sign as @xmath in @xmath .

###### Proof of Theorem 2.7.

By Exercise 2.2 we know that if @xmath , @xmath has the same sign as
@xmath , where @xmath and @xmath are defined in ( 2.7 ) and ( 2.8 ). Let
@xmath be a competitor for @xmath in a ball @xmath , with @xmath regular
enough. We have that @xmath .

Set @xmath (see Figure 2.5 ). By using the fact that @xmath in @xmath
and the divergence theorem, we deduce that

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

Since @xmath on @xmath , and @xmath (since in fact @xmath ) everywhere
(and hence in particular on @xmath ), from ( 2.9 ) we conclude

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

With the same reasoning it is easy to prove that ( 2.10 ) holds also for
@xmath . Putting both inequalities together, we conclude that @xmath .

Notice that the proof works for competitors @xmath which are regular
enough (since we applied the divergence theorem). However, it can be
generalized to very general competitors by using the generalized
definition of perimeter, as in [ 23 , Theorem 1.5] . ∎

Theorem 2.7 can also be proved with another argument – but still very
much related to the previous one and that also uses the function @xmath
. It consists of going to one more dimension @xmath and working with the
minimal surface equation for graphs, ( 2.11 ) below. This is done in
Theorem 16.4 of [ 28 ] (see also the proof of Theorem 2.2 in [ 13 ] ).

In the proof above we used a vector field @xmath satisfying the
following three properties (with @xmath ):

1.  @xmath in @xmath and @xmath in @xmath ;

2.  @xmath on @xmath ;

3.  @xmath in @xmath .

###### Definition 2.8 (Calibration).

If @xmath satisfies the three properties above we say that @xmath is a
calibration for @xmath in @xmath .

###### Exercise 2.3.

Use a similar argument to that of our last proof and build a calibration
to show that a hyperplane in @xmath is a minimizing minimal surface.

In an appendix, and with the purpose that the reader gets acquainted
with another calibration, we present one which solves the isoperimetric
problem: balls minimize perimeter among sets of given volume in @xmath .
Note that the first variation (or Euler-Lagrange equation) for this
problem is, by Lagrange multipliers, @xmath , where @xmath is a
constant.

The following is an alternative proof of Theorem 2.7 . It uses a
foliation argument , as explained below. This second proof is probably
more transparent (or intuitive) than the previous one and it is used
often in minimal surfaces theory, but requires to know the existence of
a (regular enough) minimizer (something that was not necessary in the
previous proof). This existence result is available and can be proved
with tools of the Calculus of Variations (see [ 17 , 28 ] ).

The proof also requires the use of the following important fact. If
@xmath , @xmath are two connected hypersurfaces (regular enough), both
satisfying @xmath , and such that @xmath and @xmath lies on one side of
@xmath , then @xmath in @xmath . Lying on one side can be defined as
@xmath , @xmath , and @xmath . The same result holds if @xmath satisfies
@xmath and @xmath satisfies @xmath .

This result can be proved writing both surfaces as graphs in a
neighborhood of a common point @xmath . The minimal surface equation
@xmath then becomes

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

for @xmath such that @xmath is a piece of @xmath (after a rotation and
translation). Then, assuming that @xmath also satisfies ( 2.11 ) – or
the appropriate inequality –, one can see that @xmath is a
(super)solution of a second order linear elliptic equation. Since @xmath
(due to the ordering of @xmath and @xmath ), the strong maximum
principle leads to @xmath (since @xmath at the touching point). See
Section 7 of Chapter 1 of [ 16 ] for more details.

###### Alternative proof (of Theorem 2.7).

Note that the hypersurfaces

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , form a foliation of @xmath , where @xmath is the function
defined in ( 2.7 ).

Let @xmath be a minimizer of the perimeter in @xmath among sets that
coincide with @xmath on @xmath , and assume that it is regular enough.
Since @xmath is a minimizer, in particular @xmath is a solution of the
minimal surface equation @xmath . Since @xmath , by ( 2.6 ) and Exercise
2.2 , the leaves of our foliation @xmath are subsolutions of the same
equation for @xmath , and supersolutions for @xmath .

If @xmath , there will be a first leaf (starting either from @xmath or
from @xmath ) @xmath , with @xmath , that touches @xmath at a point in
@xmath that we call @xmath (see Figure 2.6 ).

The point @xmath cannot belong to @xmath , since it holds that

  -- -------- --
     @xmath   
  -- -------- --

and the level sets of @xmath do not intersect each other. Thus, @xmath
must be an interior point of @xmath . But then we arrive at a
contradiction, by the “strong maximum principle” argument commented
right before this proof, applied with @xmath and @xmath .

As an exercise, write the details to prove the existence of a first leaf
touching @xmath at an interior point.

This same foliation argument will be used, in a simpler setting for
graphs and the Allen-Cahn equation, in the proof of Theorem 2.26 in the
next section. ∎

###### Remark 2.9.

The previous foliation argument gives more than the minimality of @xmath
. It gives uniqueness for the Dirichlet (or Plateau) problem associated
to the minimal surface equation with @xmath as boundary value on @xmath
.

###### Remark 2.10.

In our alternative proof of Theorem 2.7 we used a clever foliation made
of subsolutions and supersolutions. This sufficed to prove in a simple
way Theorem 2.7 , but required to (luckily) find the auxiliary function
@xmath . Instead, in [ 5 ] , Bombieri, De Giorgi, and Giusti considered
the foliation made of exact solutions to the minimal surface equation
@xmath , when @xmath . To this end, they proceeded as in the following
exercise and wrote the minimal surface equation, for surfaces with
rotational symmetry in @xmath and in @xmath , as an ODE in @xmath ,
finding Equation ( 2.12 ) below. They then showed that the solutions of
such ODE in the @xmath -plane do not intersect each other (and neither
the Simons cone), and thus form a foliation (see Remark 2.17 for more
information on this).

###### Exercise 2.4.

Let us set @xmath and @xmath for @xmath . Check that the following two
ODEs are equivalent to the minimal surface equation @xmath written in
the @xmath -variables for surfaces with rotational symmetry in @xmath
and in @xmath .

1.  As done in [ 5 ] , if we set a parametric representation @xmath ,
    @xmath , we find

      -- -------- -- --------
         @xmath      (2.12)
      -- -------- -- --------

2.  as done in [ 19 ] , if we set @xmath , @xmath we get

      -- -------- --
         @xmath   
      -- -------- --

The previous ODEs can be found starting from ( 2.6 ) when @xmath depends
only on @xmath and @xmath . Alternatively, they can also be found
computing the first variation of the perimeter functional in @xmath
written in the @xmath -variables:

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

for some positive constant @xmath , that becomes

  -- -------- --
     @xmath   
  -- -------- --

with the parametrization in point (ii).

###### Remark 2.11.

For @xmath , there exist other minimizing cones, such as some of the
Lawson’s cones , defined by

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and @xmath . For details, see [ 19 ] .

Notice that if @xmath is a cone (i.e., @xmath for every @xmath ), in the
expressions ( 2.1 ), ( 2.2 ), and ( 2.4 ) we will always consider @xmath
with compact support outside the origin (thus, not changing the possible
singularity of the cone at the origin).

The next theorem was proved by Simons in 1968 ⁴ ⁴ 4 Theorem 2.12 was
proved in 1965 by De Giorgi for @xmath , in 1966 by Almgren for @xmath ,
and finally in 1968 by Simons in any dimension @xmath . (it is Theorem
10.10 in [ 28 ] ). It is a crucial result towards the regularity theory
of minimizing minimal surfaces.

###### Theorem 2.12 (Simons [36]).

Let @xmath be an open set such that @xmath is a stable minimal cone and
@xmath is regular. Thus, we are assuming @xmath and

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

for every @xmath with compact support outside the origin.

If @xmath , then @xmath is a hyperplane.

###### Remark 2.13.

Simons result (Theorem 2.12 ), together with a blow-up argument and a
monotonicity formula (as main tools), lead to the flatness of every
minimizing minimal surface in all of @xmath if @xmath (see [ 28 ,
Theorem 17.3] for a proof). The same tools also give the analyticity of
every minimal surface that is minimizing in a given ball of @xmath if
@xmath (see [ 28 , Theorem 10.11] for a detailed proof). See also [ 17 ]
for a great shorter exposition of these results.

The dimension @xmath in Theorem 2.12 is optimal, since by Theorem 2.7
the Simons cone provides a counterexample in dimension @xmath .

The following is a very rough explanation of why the minimizer of the
Dirichlet (or Plateau) problem is the Simons cone (and thus passes
through the origin) in high dimensions – in opposition with low
dimensions, as in Figure 2.4 , where the minimizer stays away from the
origin. In the perimeter functional written in the @xmath -variables (
2.13 ), the Jacobian @xmath becomes smaller and smaller near the origin
as @xmath gets larger. Thus, lengths near @xmath become smaller as the
dimension @xmath increases.

In order to prove Theorem 2.12 , we start with some important
preliminaries. Recalling ( 2.3 ), for @xmath , we define the tangential
derivative

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the exterior normal to @xmath on @xmath , @xmath are
Euclidean partial derivatives, and we used the standard convention of
sum @xmath over repeated indices. As mentioned right after definition (
2.3 ), even if to compute @xmath requires to extend @xmath to a
neighborhood of @xmath , @xmath is well defined knowing @xmath only on
@xmath – since it is a tangential derivative. Note also that we have
@xmath tangential derivatives @xmath and, thus, they are linearly
dependent, since @xmath is @xmath -dimensional. However, it is easy to
check (as an exercise) that

  -- -------- --
     @xmath   
  -- -------- --

We next define the Laplace-Beltrami operator on @xmath by

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

acting on functions @xmath . For the reader knowing Riemannian calculus,
one can check that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the tangential gradient introduced in ( 2.3 ) and @xmath
denotes the (tangential) divergence on the manifold @xmath .

According to ( 2.6 ), we have that

  -- -------- --
     @xmath   
  -- -------- --

We will also use the following formula of integration by parts :

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

for every (smooth) hypersurface @xmath and @xmath with compact support.
Equation ( 2.16 ) is proved in Giusti’s book [ 28 , Lemma 10.8] .
However, there are two typos in [ 28 , Lemma 10.8] : @xmath is missed in
the identity above, and there is an error of a sign in the proof of [ 28
, Lemma 10.8] .

Replacing @xmath by @xmath in ( 2.16 ), we deduce that

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

From this, replacing @xmath by @xmath in ( 2.17 ) and using that @xmath
, we also have

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

###### Remark 2.14.

For a minimal surface @xmath , the second variation of perimeter given
by ( 2.4 ) can also be rewritten, after ( 2.18 ), as

  -- -------- --
     @xmath   
  -- -------- --

The operator @xmath appearing in this expression is called the Jacobi
operator . It is the linearization at the minimal surface @xmath of the
minimal surface equation @xmath .

Towards the proof of Simons theorem, let us now take @xmath in ( 2.14 ),
where @xmath and @xmath are still arbitrary ( @xmath with compact
support outside the origin) and will be chosen later. We obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where at the last step we used integration by parts ( 2.17 ). This leads
to the inequality

  -- -------- --
     @xmath   
  -- -------- --

where the term @xmath appearing in the first integral is the linearized
or Jacobi operator at @xmath acting on @xmath .

Now we make the choice @xmath and we arrive, as a consequence of
stability, to

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

At this point, Simons proof of Theorem 2.12 uses the following
inequality for the Laplace-Beltrami operator @xmath of @xmath (recall
that @xmath is the sum of the squares of the principal curvatures of
@xmath ), in the case when @xmath is a stationary cone.

###### Lemma 2.15 (Simons lemma [36]).

Let @xmath be an open set such that @xmath is a cone with zero mean
curvature and @xmath is regular. Then, @xmath is homogeneous of degree
@xmath and, in @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

In Subsection 2.1.3 we will give an outline of the proof of this result.
We now use Lemma 2.15 to complete the proof of Theorem 2.12 .

###### Proof of Theorem 2.12.

By using ( 2.19 ) together with Lemma 2.15 we obtain

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

for every @xmath with compact support outside the origin. By
approximation, the same holds for @xmath Lipschitz instead of @xmath .

If @xmath , we now choose @xmath to be the Lipschitz function

  -- -------- --
     @xmath   
  -- -------- --

By directly computing

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

we realize that if

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

then in ( 2.20 ) we have @xmath . If @xmath were an admissible function
in ( 2.20 ), we would then conclude that @xmath on @xmath . This is
equivalent to @xmath being an hyperplane.

Now, for @xmath to have compact support and hence be admissible, we need
to cut-off @xmath near @xmath and infinity. As an exercise, one can
check that the cut-offs work (i.e., the tails in the integrals tend to
zero) if (and only if)

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

or equivalently, since they have the same homogeneity,

  -- -------- --
     @xmath   
  -- -------- --

By recalling that the Jacobian on @xmath (in spherical coordinates) is
@xmath , ( 2.21 ), and that, by Lemma 2.15 , @xmath is homogeneous of
degree @xmath , we deduce that ( 2.23 ) is satisfied if @xmath and
@xmath . That is, if

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

If @xmath then @xmath , i.e., @xmath , and thus we can choose @xmath and
@xmath satisfying ( 2.24 ) and ( 2.22 ). It then follows that @xmath ,
and hence @xmath is a hyperplane. ∎

The argument in the previous proof (leading to the dimension @xmath ) is
very much related to a well known result: Hardy’s inequality in @xmath –
which is presented next.

##### 2.1.2 Hardy’s inequality

As already noticed in Remark 2.14 , for a minimal surface @xmath the
second variation of perimeter ( 2.4 ) can also be rewritten, by
integrating by parts, as

  -- -------- --
     @xmath   
  -- -------- --

This involves the linearized or Jacobi operator @xmath . If @xmath ,
with @xmath , then @xmath (if @xmath is a cone and thus @xmath is
homogeneous of degree @xmath ), where @xmath depends only on the angles
@xmath . Thus, we are in the presence of the “Hardy-type operator”

  -- -------- --
     @xmath   
  -- -------- --

notice that @xmath and @xmath scale in the same way. Thus, for all
admissible functions @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Let us analyze the simplest case when @xmath and @xmath . Then, the
validity or not of the previous inequality is given by Hardy’s
inequality, stated and proved next.

###### Proposition 2.16 (Hardy’s inequality).

If @xmath and @xmath , then

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

In addition, @xmath is the best constant in this inequality and it is
not achieved by any @xmath .

Moreover, if @xmath , then the Dirichlet spectrum of @xmath in the unit
ball @xmath goes all the way to @xmath . That is,

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

where the infimum is taken over @xmath .

###### Proof.

Using spherical coordinates, for a given @xmath we can write

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

Here we integrated by parts, using that @xmath .

Now we apply the Cauchy-Schwarz inequality in the right-hand side to
obtain

  -- -------- -- --------
     @xmath      (2.28)
  -- -------- -- --------

Putting together ( 2.27 ) and ( 2.28 ) we get

  -- -------- --
     @xmath   
  -- -------- --

that is,

  -- -------- --
     @xmath   
  -- -------- --

By integrating in @xmath we conclude ( 2.25 ). An inspection of the
equality cases in the previous proof shows that the best constant is not
achieved.

Let us now consider @xmath with @xmath . Take

  -- -------- --
     @xmath   
  -- -------- --

and cut it off near the origin to be admissible. If we consider the main
terms in the quotient ( 2.26 ), we get

  -- -------- --
     @xmath   
  -- -------- --

Thus it is clear that, as @xmath , the denominator remains finite
independently of the cut-off, while the numerator is as negative as we
want after the cut-off. Hence, the quotient tends to @xmath . ∎

###### Remark 2.17.

As we explained in Remark 2.10 , in [ 5 ] , Bombieri, De Giorgi, and
Giusti used a foliation made of exact solutions to the minimal surface
equation @xmath when @xmath . These are the solutions of the ODE ( 2.12
) starting from points @xmath in the @xmath -axis and with vertical
derivative @xmath . They showed that, for @xmath , they do not intersect
each other, neither intersect the Simons cone @xmath . Instead, in
dimensions @xmath and @xmath they do not produce a foliation and, in
fact, each of them crosses infinitely many times @xmath , as showed in
Figure 2.7 . This reflects the fact that the linearized operator @xmath
on @xmath has infinitely many negative eigenvalues, as in the simpler
situation of Hardy’s inequality in the last statement of Proposition
2.16 .

##### 2.1.3 Proof of the Simons lemma

As promised, in this section we present the proof of Lemma 2.15 with
almost all details. We follow the proof contained in Giusti’s book [ 28
] , where more details can be found (Simons lemma is Lemma 10.9 in [ 28
] ). We point out that in the proof of [ 28 ] there are the following
two typos:

-   as already noticed before, the identity in the statement of [ 28 ,
    Lemma 10.8] is missing @xmath in the second integrand. We wrote the
    corrected identity in equation ( 2.16 ) of these notes;

-   the label (10.18) is missing in line -8, page 122 of [ 28 ] .

Alternative proofs of Lemma 2.15 using intrinsic Riemaniann tensors can
be found in the original paper of Simons [ 36 ] from 1968 and also in
the book of Colding and Minicozzi [ 16 ] .

###### Notation.

We denote by @xmath the signed distance function to @xmath , defined by

  -- -------- --
     @xmath   
  -- -------- --

As we are assuming @xmath to be regular, we have that @xmath is @xmath
in a neighborhood of @xmath .

The normal vector to @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

we write

  -- -------- --
     @xmath   
  -- -------- --

where we adopt the abbreviated notation

  -- -------- --
     @xmath   
  -- -------- --

for partial derivatives in @xmath . As introduced after Theorem 2.12 ,
we will use the tangential derivatives

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , and thus

  -- -------- --
     @xmath   
  -- -------- --

where we adopted the summation convention over repeated indices.
Finally, recall the Laplace-Beltrami operator defined in ( 2.15 ):

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 2.18.

Since

  -- -------- -- --------
     @xmath      (2.29)
  -- -------- -- --------

it holds that

  -- -------- --
     @xmath   
  -- -------- --

Thus, we have

  -- -------- --
     @xmath   
  -- -------- --

which leads to

  -- -------- --
     @xmath   
  -- -------- --

###### Exercise 2.5.

Using @xmath , verify that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -- --------
     @xmath      (2.30)
  -- -------- -- --------

The identities

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

will be used often in the following computations. The first one follows
from the definition of @xmath , while the second is immediate from (
2.29 ).

The next lemma will be useful in what follows.

###### Lemma 2.19.

The following equations hold for every smooth hypersurface @xmath :

  -- -------- -- --------
     @xmath      (2.32)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

for all indices @xmath and @xmath .

For a proof of this lemma, see [ 28 , Lemma 10.7] .

Equation ( 2.33 ) is an important one. It says that the normal vector
@xmath to a minimal surface solves the Jacobi equation @xmath on @xmath
. This reflects the invariance of the equation @xmath by translations
(to see this, write a perturbation made by a small translation as a
normal deformation, as in Figure 2.2 ).

If @xmath is stationary, from ( 2.32 ) and by means of simple
calculations, one obtains that

  -- -------- -- --------
     @xmath      (2.34)
  -- -------- -- --------

Equation ( 2.34 ) is the formula with the missed label (10.18) in [ 28 ]
.

We are ready now to give the

###### Outline of the proof (of Lemma 2.15).

By ( 2.30 ) we can write that

  -- -------- --
     @xmath   
  -- -------- --

Then, using ( 2.33 ), ( 2.34 ), and the fact @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

and by ( 2.32 )

  -- -------- --
     @xmath   
  -- -------- --

Now, if @xmath , we can choose the @xmath -axis to be the same direction
as @xmath . Thus, @xmath and at @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Hence, computing from now on always at the point @xmath , and by using (
2.32 ) and ( 2.31 ), we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where all the greek indices indicate summation from @xmath to @xmath .

On the other hand, we have

  -- -------- --
     @xmath   
  -- -------- --

and hence

  -- -------- --
     @xmath   
  -- -------- --

Now remember that @xmath is a cone with vertex at the origin, and thus
@xmath on @xmath . Since we took @xmath at @xmath , we may choose
coordinates in such a way that @xmath lies on the @xmath -axis. In
particular, @xmath at @xmath and

  -- -------- --
     @xmath   
  -- -------- --

which leads to

  -- -------- --
     @xmath   
  -- -------- --

If now the letters @xmath run from @xmath to @xmath , he have

  -- -------- --
     @xmath   
  -- -------- --

From ( 2.32 ), @xmath and @xmath at @xmath . Since @xmath is a cone,
@xmath is homogeneous of degree 0 and hence @xmath is homogeneous of
degree @xmath . Thus, by Euler’s theorem on homogeneous functions, we
have

  -- -------- --
     @xmath   
  -- -------- --

and hence

  -- -------- --
     @xmath   
  -- -------- --

The proof is now completed. ∎

##### 2.1.4 Comments on: harmonic maps, free boundary problems, and
nonlocal minimal surfaces

Here we briefly sketch arguments and results similar to the previous
ones on minimal surfaces, now for three other elliptic problems.

###### Harmonic maps

Consider the energy

  -- -------- -- --------
     @xmath      (2.35)
  -- -------- -- --------

for @xmath maps @xmath from a domain @xmath of @xmath into the closed
upper hemisphere

  -- -------- --
     @xmath   
  -- -------- --

A critical point of @xmath is called a (weakly) harmonic map . When a
map minimizes @xmath among all maps with values into @xmath and with
same boundary values on @xmath , then it is called a minimizing harmonic
map.

From the energy ( 2.35 ) and the restriction @xmath , one finds that the
equation for harmonic maps is given by

  -- -------- --
     @xmath   
  -- -------- --

In 1983, Jäger and Kaul proved the following theorem, that we state here
without proving it (see the original paper [ 29 ] for the proof).

###### Theorem 2.20 (Jäger-Kaul [29]).

The equator map

  -- -------- --
     @xmath   
  -- -------- --

is a minimizing harmonic map on the class

  -- -------- --
     @xmath   
  -- -------- --

if and only if @xmath .

We just mention that the proof of the “if” in Theorem 2.20 uses a
calibration argument.

Later, Giaquinta and Souček [ 27 ] , and independently Schoen and
Uhlenbeck [ 35 ] , proved the following result.

###### Theorem 2.21 (Giaquinta-Souček [27]; Schoen-Uhlenbeck [35]).

Let @xmath be a minimizing harmonic map, homogeneous of degree zero,
into the closed upper hemisphere @xmath . If @xmath , then @xmath is
constant.

Now we will show an outline of the proof of Theorem 2.21 following [ 27
] . More details can also be found in Section 3 of [ 13 ] . This theorem
gives an alternative proof of one part of the statement of Theorem 2.20
. Namely, that the equator map @xmath is not minimizing for @xmath .

###### Outline of the proof (of Theorem 2.21).

After stereographic projection (with respect to the south pole) @xmath
from @xmath to @xmath , for the new function @xmath , the energy ( 2.35
) (up to a constant factor) is given by

  -- -------- --
     @xmath   
  -- -------- --

In addition, we have @xmath since the image of @xmath is contained in
the closed upper hemisphere.

By testing the function

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a smooth radial function with compact support in @xmath
, in the equation of the first variation of the energy, that is

  -- -------- --
     @xmath   
  -- -------- --

one can deduce that either @xmath is constant (and then the proof is
finished) or

  -- -------- --
     @xmath   
  -- -------- --

that we assume from now on.

Since @xmath is a minimizer, we have that the second variation of the
energy satisfies

  -- -------- --
     @xmath   
  -- -------- --

By choosing here the function

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a smooth radial function with compact support in @xmath
(to be chosen later), and setting

  -- -------- --
     @xmath   
  -- -------- --

one can conclude the proof by similar arguments as in the previous
section and by using Lemma 2.22 , stated next. ∎

###### Lemma 2.22.

If @xmath is a harmonic map, homogeneous of degree zero, and with @xmath
, we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

This lemma is the analogue result of Lemma 2.15 for minimal cones. See [
27 ] for a proof of the lemma, which also follows from Bochner identity
(see [ 35 ] ).

###### Free boundary problems

Consider the one-phase free boundary problem:

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

where @xmath is homogeneous of degree one and positive in the domain
@xmath and @xmath is a cone. We are interested in solutions @xmath that
are stable for the Alt-Caffarelli energy functional

  -- -------- --
     @xmath   
  -- -------- --

with respect to compact domain deformations that do not contain the
origin. More precisely, we say that @xmath is stable if for any smooth
vector field @xmath with @xmath we have

  -- -- --
        
  -- -- --

The following result due to Jerison and Savin is contained in [ 30 ] ,
where a detailed proof can be found.

###### Theorem 2.23 (Jerison-Savin [30]).

The only stable, homogeneous of degree one, solutions of ( 2.36 ) in
dimension @xmath are the one-dimensional solutions @xmath , @xmath .

In dimension @xmath this result had been established by Caffarelli,
Jerison, and Kenig [ 14 ] , where they conjectured that it remains true
up to dimension @xmath . On the other hand, in dimension @xmath , De
Silva and Jerison [ 22 ] provided an example of a nontrivial minimizer.

The proof of Jerison and Savin of Theorem 2.23 is similar to Simons
proof of the rigidity of stable minimal cones in low dimensions: they
find functions @xmath (now involving the second derivatives of @xmath )
which satisfy appropriate differential inequalities for the linearized
equation.

Here, the linearized problem is the following:

  -- -------- --
     @xmath   
  -- -------- --

For the function

  -- -------- --
     @xmath   
  -- -------- --

they found the following interior inequality which is similar to the one
of the Simons lemma:

  -- -------- --
     @xmath   
  -- -------- --

In addition, they also need to prove a boundary inequality involving
@xmath . Furthermore, to establish Theorem 2.23 in dimension @xmath , a
more involved function @xmath of the second derivatives of @xmath is
needed.

###### Nonlocal minimal surfaces

Nonlocal minimal surfaces, or @xmath -minimal surfaces (where @xmath ),
have been introduced in 2010 in the seminal paper of Caffarelli,
Roquejoffre, and Savin [ 15 ] . These surfaces are connected to
fractional perimeters and diffusions and, as @xmath , they converge to
classical minimal surfaces. We refer to the lecture notes [ 17 ] and the
survey [ 24 ] , where more references can be found.

For @xmath -minimal surfaces and all @xmath , the analogue of Simons
flatness result is only known in dimension @xmath by a result for
minimizers of Savin and Valdinoci [ 34 ] .

#### 2.2 The Allen-Cahn equation

This section concerns the Allen-Cahn equation

  -- -------- -- --------
     @xmath      (2.37)
  -- -------- -- --------

By using equation ( 2.37 ) and the maximum principle it can be proved
that any solution satisfies @xmath . Then, by the strong maximum
principle we have that either @xmath or @xmath . Since @xmath are
trivial solutions, from now on we consider @xmath .

We introduce the class of 1-d solutions :

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

The solution @xmath is sometimes referred to as the layer solution to (
2.37 ); see Figure 2.8 . The fact that @xmath depends only on one
variable can be rephrased also by saying that all the level sets @xmath
of @xmath are hyperplanes.

###### Exercise 2.6.

Check that the @xmath -d functions introduced above are solutions of the
Allen-Cahn equation.

###### Remark 2.24.

Let us take @xmath and consider the 1-d solution @xmath . It is clear
that the following two relations hold:

  -- -------- -- --------
     @xmath      (2.38)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

The energy functional associated to equation ( 2.37 ) is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the double-well potential in Figure 2.9 :

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 2.25 (Minimizer).

A function @xmath is said to be a minimizer of ( 2.37 ) when

  -- -------- --
     @xmath   
  -- -------- --

for every open ball @xmath and functions @xmath such that @xmath on
@xmath .

Connection with the theory of minimal surfaces. The Allen-Cahn equation
has its origin in the theory of phase transitions and it is used as a
model for some nonlinear reaction-diffusion processes. To better
understand this, let @xmath be a bounded domain, and consider the
Allen-Cahn equation with parameter @xmath ,

  -- -------- -- --------
     @xmath      (2.40)
  -- -------- -- --------

with associated energy functional given by

  -- -------- -- --------
     @xmath      (2.41)
  -- -------- -- --------

Assume now that there are two populations (or chemical states) A and B
and that @xmath is a density measuring the percentage of the two
populations at every point: if @xmath (respectively, @xmath ) at a point
@xmath , we have only population A at @xmath (respectively, population
B); @xmath means that at @xmath we have @xmath of population A and
@xmath of population @xmath .

By ( 2.41 ), it is clear that in order to minimize @xmath as @xmath
tends to @xmath , @xmath must be very small. From Figure 2.9 we see that
this happens when @xmath is close to @xmath . These heuristics are
indeed formally confirmed by a celebrated theorem of Modica and Mortola.
It states that, if @xmath is a family of minimizers of @xmath , then, up
to a subsequence, @xmath converges in @xmath , as @xmath tends to @xmath
, to

  -- -------- --
     @xmath   
  -- -------- --

for some disjoint sets @xmath having as common boundary a surface @xmath
. In addition, @xmath is a minimizing minimal surface. Therefore, the
result of Modica-Mortola establishes that the two populations tend to
their total separation, and in such a (clever) way that the interface
surface @xmath of separation has least possible area.

Finally, notice that the @xmath -d solution of ( 2.40 ),

  -- -------- --
     @xmath   
  -- -------- --

makes a very fast transition from @xmath to @xmath in a scale of order
@xmath . Accordingly, in Figure 2.10 , @xmath will make this type of
fast transition across the limiting minimizing minimal surface @xmath .
The interested reader can see [ 1 ] for more details.

##### 2.2.1 Minimality of monotone solutions with limits @xmath

The following fundamental result shows that monotone solutions with
limits @xmath are minimizers (as in Definition 2.25 ).

###### Theorem 2.26 (Alberti-Ambrosio-Cabré [1]).

Suppose that @xmath is a solution of ( 2.37 ) satisfying the
monotonicity hypothesis ( 2.38 ) and the condition ( 2.39 ) on limits.
Then, @xmath is a minimizer of ( 2.37 ) in @xmath .

See [ 1 ] for the original proof of the Theorem 2.26 . It uses a
calibration built from a foliation and avoids the use of the strong
maximum principle, but it is slightly involved. Instead, the simple
proof that we give here was suggested to the first author (after one of
his lectures on [ 1 ] ) by L. Caffarelli. It uses a simple foliation
argument together with the strong maximum principle, as in the
alternative proof of Theorem 2.7 given in Subsection 2.1.1 .

###### Proof of Theorem 2.26.

Denoting @xmath , let us consider the functions

  -- -------- --
     @xmath   
  -- -------- --

By the monotonicity assumption ( 2.38 ) we have that

  -- -------- -- --------
     @xmath      (2.42)
  -- -------- -- --------

Thus, by ( 2.39 ) we have that the graphs of @xmath , @xmath , form a
foliation filling all of @xmath . Moreover, we have that for every
@xmath , @xmath are solutions of @xmath in @xmath .

By simple arguments of the Calculus of Variations, given a ball @xmath
it can be proved that there exists a minimizer @xmath of @xmath such
that @xmath on @xmath . In particular, @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

By ( 2.39 ), we have that the graph of @xmath in the compact set @xmath
is above the graph of @xmath for @xmath large enough, and it is below
the graph of @xmath for @xmath negative enough (see Figure 2.11 ). If
@xmath , assume that @xmath at some point in @xmath (the situation
@xmath somewhere in @xmath is done similarly). It follows that, starting
from @xmath , there will exist a first @xmath such that @xmath touches
@xmath at a point @xmath . This means that @xmath in @xmath and @xmath .

By ( 2.42 ), @xmath , and the fact that @xmath on @xmath , the point
@xmath cannot belong to @xmath . Thus, @xmath will be an interior point
of @xmath .

But then we have that @xmath and @xmath are two solutions of the same
semilinear equation (the Allen-Cahn equation), the graph of @xmath stays
below that of @xmath , and they touch each other at the interior point
@xmath . This is a contradiction with the strong maximum principle.

Here we leave as an exercise (stated next) to verify that the difference
of two solutions of @xmath satisfies a linear elliptic equation to which
we can apply the strong maximum principle. This leads to @xmath , which
contradicts @xmath on @xmath . ∎

###### Exercise 2.7.

Prove that the difference @xmath of two solutions of a semilinear
equation @xmath , where @xmath is a Lipschitz function, satisfies a
linear equation of the form @xmath , for some function @xmath . Verify
that, as a consequence, this leads to @xmath in the previous proof.

By recalling Remark 2.24 , we immediately get the following corollary.

###### Corollary 2.27.

The 1-d solution @xmath is a minimizer of ( 2.37 ) in @xmath , for every
unit vector @xmath .

As a corollary of Theorem 2.26 , we easily deduce the following
important energy estimates.

###### Corollary 2.28 (Energy upper bounds; Ambrosio-Cabré [2]).

Let @xmath be a solution of ( 2.37 ) satisfying ( 2.38 ) and ( 2.39 )
(or more generally, let @xmath be a minimizer in @xmath ).

Then, for all @xmath we have

  -- -------- -- --------
     @xmath      (2.43)
  -- -------- -- --------

for some constant @xmath independent of @xmath . In particular, since
@xmath , we have that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

###### Remark 2.29.

The proof of Corollary 2.28 is trivial for @xmath -d solutions. Indeed,
it is easy to check that @xmath and, as a consequence, by applying
Fubini’s theorem on a cube larger than @xmath , that ( 2.43 ) holds.
This argument also shows that the exponent @xmath in ( 2.43 ) is optimal
(since it cannot be improved for @xmath -d solutions).

The estimates in Corollary 2.28 are fundamental in the proofs of a
conjecture of De Giorgi that we treat in the next subsection.

The estimate ( 2.43 ) was first proved by Ambrosio and the first author
in [ 2 ] . Later on, in [ 1 ] Alberti, Ambrosio, and the first author
discovered that monotone solutions with limits are minimizers (Theorem
2.26 above). This allowed to simplify the original proof of the energy
estimates found in [ 2 ] , as follows.

###### Proof of Corollary 2.28.

Since @xmath is a minimizer by Theorem 2.26 (or by hypothesis), we can
perform a simple energy comparison argument. Indeed, let @xmath satisfy
@xmath in @xmath , @xmath in @xmath , @xmath in @xmath , and @xmath .
Consider

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath on @xmath , we can compare the energy of @xmath in @xmath
with that of @xmath . We obtain

  -- -------- --
     @xmath   
  -- -------- --

for every @xmath , with @xmath independent of @xmath . In the second
inequality of the chain above we used that @xmath in @xmath for some
constant @xmath independent of @xmath . This is a consequence of the
following exercise. ∎

###### Exercise 2.8.

Prove that if @xmath is a solution of a semilinear equation @xmath in
@xmath and @xmath in @xmath , where @xmath is a continuous nonlinearity,
then @xmath in @xmath for some constant @xmath depending only on @xmath
and @xmath . See [ 2 ] , if necessary, for a proof.

##### 2.2.2 A conjecture of De Giorgi

In 1978, E. De Giorgi [ 20 ] stated the following conjecture:

Conjecture (DG). Let @xmath be a solution of the Allen-Cahn equation (
2.37 ) satisfying the monotonicity condition ( 2.38 ). Then, @xmath is a
@xmath -d solution (or equivalently, all level sets @xmath of @xmath are
hyperplanes), at least if @xmath .

This conjecture was proved in 1997 for @xmath by Ghoussoub and Gui [ 26
] , and in 2000 for @xmath by Ambrosio and Cabré [ 2 ] . Next we state a
deep result of Savin [ 33 ] under the only assumption of minimality.
This is the semilinear analogue of Simons Theorem 2.12 and Remark 2.13
on minimal surfaces. As we will see, Savin’s result leads to a proof of
Conjecture (DG) for @xmath if the additional condition ( 2.39 ) on
limits is assumed.

###### Theorem 2.30 (Savin [33]).

Assume that @xmath and that @xmath is a minimizer of ( 2.37 ) in @xmath
. Then, @xmath is a @xmath -d solution.

The hypothesis @xmath on its statement is sharp. Indeed, in 2017 Liu,
Wang, and Wei [ 31 ] have shown the existence of a minimizer in @xmath
whose level sets are not hyperplanes. Its zero level set is asymptotic
at infinity to the Simons cone. However, a canonical solution described
in Subsection 2.2.3 (and whose zero level set is exactly the Simons
cone) is still not known to be a minimizer in @xmath .

Note that Theorem 2.30 makes no assumptions on the monotonicity or the
limits at infinity of the solution. To prove Conjecture (DG) using
Savin’s result (Theorem 2.30 ), one needs to make the further assumption
( 2.39 ) on the limits only to guarantee, by Theorem 2.26 , that the
solution is actually a minimizer. Then, Theorem 2.30 (and the gain of
one more dimension, @xmath , thanks to the monotonicity of the solution)
leads to the proof of Conjecture (DG) for monotone solutions with limits
@xmath .

However, for @xmath the conjecture in its original statement (i.e.,
without the limits @xmath as hypothesis) is still open. To our knowledge
no clear evidence is known about its validity or not.

The proof of Theorem 2.30 uses an improvement of flatness result for the
Allen-Cahn equation developed by Savin, as well as Theorem 2.12 on the
non-existence of stable minimal cones in dimension @xmath .

Instead, the proofs of Conjecture (DG) in dimensions @xmath and @xmath
are much simpler. They use the energy estimates of Corollary 2.28 and a
Liouville-type theorem developed in [ 2 ] (see also [ 1 ] ). As
explained next, the idea of the proof originates in the paper [ 3 ] by
Berestycki, Caffarelli, and Nirenberg.

Motivation for the proof of Conjecture (DG) for @xmath . In [ 3 ] the
authors made the following heuristic observation. From the equation
@xmath and the monotonicity assumption ( 2.38 ), by differentiating we
find that

  -- -------- -- --------
     @xmath      (2.44)
  -- -------- -- --------

If we were in a bounded domain @xmath instead of @xmath (and we forgot
about boundary conditions), from ( 2.44 ), we would deduce that @xmath
is the first eigenfunction of @xmath and that its first eigenvalue is
@xmath . As a consequence, such eigenvalue is simple. But then, since we
also have that

  -- -------- --
     @xmath   
  -- -------- --

the simplicity of the eigenvalue would lead to

  -- -------- -- --------
     @xmath      (2.45)
  -- -------- -- --------

where @xmath are constants. Now, we would conclude that @xmath is a 1-d
solution, by the following exercise.

###### Exercise 2.9.

Check that ( 2.45 ), with @xmath being constants, is equivalent to the
fact that @xmath is a 1-d solution.

To make this argument work in the whole @xmath , one needs a
Liouville-type theorem. For @xmath it was proved in [ 3 ] and [ 26 ] .
Later, [ 2 ] used it to prove Conjecture (DG) in @xmath after proving
the crucial energy estimate ( 2.43 ). The Liouville theorem requires the
right hand side of ( 2.43 ) to be bounded by @xmath .

In 2011, del Pino, Kowalczyk, and Wei [ 21 ] established that
Conjecture (DG) does not hold for @xmath – as suggested in De Giorgi’s
original statement.

###### Theorem 2.31 (del Pino-Kowalczyk-Wei [21]).

If @xmath , there exists a solution of ( 2.37 ), satisfying ( 2.38 ) and
( 2.39 ), and which is not a @xmath -d solution.

The proof in [ 21 ] uses crucially the minimal graph in @xmath built by
Bombieri, De Giorgi, and Giusti in [ 5 ] . This is a minimal surface in
@xmath given by the graph of a function @xmath which is antisymmetric
with respect to the Simons cone. The solution of Theorem 2.31 is built
in such a way that its zero level set stays at finite distance from the
Bombieri-De Giorgi-Giusti graph.

We consider next a similar object to the previous minimal graph, but in
the context of the Allen-Cahn equation: a solution @xmath which is
antisymmetric with respect to the Simons cone.

##### 2.2.3 The saddle-shaped solution vanishing on the Simons cone

As in Section 2.1 , let @xmath and denote by @xmath the Simons cone (
2.5 ). For @xmath , @xmath and @xmath denote the two radial variables

  -- -------- -- --------
     @xmath      (2.46)
  -- -------- -- --------

The Simons cone is given by

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 2.32 (Saddle-shaped solution).

We say that @xmath is a saddle-shaped solution (or simply a saddle
solution) of the Allen-Cahn equation

  -- -------- -- --------
     @xmath      (2.47)
  -- -------- -- --------

whenever @xmath is a solution of ( 2.47 ) and, with @xmath and @xmath
defined by ( 2.46 ),

1.  @xmath depends only on the variables @xmath and @xmath . We write
    @xmath ;

2.  @xmath in @xmath ;

3.  @xmath in @xmath .

###### Remark 2.33.

Notice that if @xmath is a saddle-shaped solution, then we have @xmath
on @xmath (see Figure 2.12 ).

While the existence of a saddle-shaped solution is easily established,
its uniqueness is more delicate. This was accomplished in 2012 by the
first author in [ 9 ] .

###### Theorem 2.34 (Cabré [9]).

For every even dimension @xmath , there exists a unique saddle-shaped
solution @xmath of ( 2.47 ).

Due to the minimality of the Simons cone when @xmath (and also because
of the minimizer from [ 31 ] referred to after Theorem 2.30 ), the
saddle-shaped solution is expected to be a minimizer when @xmath :

###### Open problem 2.35.

Is the saddle-shaped solution a minimizer of ( 2.47 ) in @xmath , or at
least in higher even dimensions?

Nothing is known on this open problem except for the following result.
It establishes stability (a weaker property than minimality) for @xmath
. Below, we sketch its proof.

###### Theorem 2.36 (Cabré [9]).

If @xmath , the saddle-shaped solution @xmath of ( 2.47 ) is stable in
@xmath , in the sense of the following definition.

###### Definition 2.37 (Stability).

We say that a solution @xmath of @xmath in @xmath is stable if the
second variation of the energy with respect to compactly supported
perturbations @xmath is nonnegative. That is, if

  -- -------- --
     @xmath   
  -- -------- --

In the rest of this section, we will take @xmath and @xmath to be the
Allen-Cahn nonlinearity, i.e., @xmath

###### Outline of the proof (of Theorem 2.36).

Notice that

  -- -------- -- --------
     @xmath      (2.48)
  -- -------- -- --------

for @xmath and @xmath , is equation ( 2.47 ) expressed in the @xmath
variables. Let us introduce the function

  -- -------- -- --------
     @xmath      (2.49)
  -- -------- -- --------

Differentiating ( 2.48 ) with respect to @xmath (and to @xmath ), one
finds equations satisfied by @xmath (and by @xmath ) – and which involve
a zero order term with coefficient @xmath . These equations, together
with some more delicate monotonicity properties of the saddle-shaped
solution established in [ 9 ] , can be used to prove the following fact.

For @xmath , one can choose @xmath in ( 2.49 ) (see [ 9 ] for more
details) such that @xmath is a positive supersolution of the linearized
problem, i.e.:

  -- -------- -- --------
     @xmath      (2.50)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (2.51)
  -- -------- -- --------

Next, using ( 2.50 ) and ( 2.51 ), we can verify the stability condition
of @xmath for any @xmath test function @xmath with compact support in
@xmath . Indeed, multiply ( 2.51 ) by @xmath and integrate by parts to
get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, using the Cauchy-Schwarz inequality, we are led to

  -- -------- --
     @xmath   
  -- -------- --

Finally, by a cut-off argument we can prove that this same inequality
holds also for every function @xmath . ∎

###### Remark 2.38.

Alternatively to the variational proof seen above, another way to
establish stability from the existence of a positive supersolution to
the linearized problem is by using the maximum principle (see [ 4 ] for
more details).

#### 2.3 Blow-up problems

In this final section, we consider positive solutions of the semilinear
problem

  -- -------- -- --------
     @xmath      (2.52)
  -- -------- -- --------

where @xmath is a smooth bounded domain, @xmath , and @xmath is @xmath .

The associated energy functional is

  -- -------- -- --------
     @xmath      (2.53)
  -- -------- -- --------

where @xmath is such that @xmath .

##### 2.3.1 Stable and extremal solutions. A singular stable solution
for @xmath

We define next the class of stable solutions to ( 2.52 ). It includes
any local minimizer, i.e., any minimizer of ( 2.53 ) under small
perturbations vanishing on @xmath .

###### Definition 2.39 (Stability).

A solution @xmath of ( 2.52 ) is said to be stable if the second
variation of the energy with respect to @xmath perturbations @xmath
vanishing on @xmath is nonnegative. That is, if

  -- -------- -- --------
     @xmath      (2.54)
  -- -------- -- --------

There are many nonlinearities for which ( 2.52 ) admits a (positive)
stable solution. Indeed, replace @xmath by @xmath in ( 2.52 ), with
@xmath :

  -- -------- -- --------
     @xmath      (2.55)
  -- -------- -- --------

Assume that @xmath is positive, nondecreasing, and superlinear at @xmath
, that is,

  -- -------- -- --------
     @xmath      (2.56)
  -- -------- -- --------

Note that also in this case we look for positive solutions (when @xmath
), since @xmath . We point out that, for @xmath , @xmath is not a
solution.

###### Proposition 2.40.

Assuming ( 2.56 ), there exists an extremal parameter @xmath such that
if @xmath then ( 2.55 ) admits a minimal stable classical solution
@xmath . Here “minimal” means the smallest among all the solutions,
while “classical” means of class @xmath . Being classical is a
consequence of @xmath if @xmath .

On the other hand, if @xmath then ( 2.55 ) has no classical solution.

The family of classical solutions @xmath is increasing in @xmath , and
its limit as @xmath is a weak solution @xmath of ( 2.55 ) for @xmath .

###### Definition 2.41 (Extremal solution).

The function @xmath given by Proposition 2.40 is called the extremal
solution of ( 2.55 ).

For a proof of Proposition 2.40 see the book [ 25 ] by L. Dupaigne. The
definition of weak solution (the sense in which @xmath is a solution)
requires @xmath , @xmath , and the equation to be satisfied in the
distributional sense after multiplying it by test functions vanishing on
@xmath and integrating by parts twice (see [ 25 ] ). Other useful
references regarding extremal and stable solutions are [ 6 ] , [ 7 ] ,
and [ 11 ] .

Since 1996, Brezis has raised several questions regarding stable and
extremal solutions; see for instance [ 6 ] . They have led to
interesting works, some of them described next. One of his questions is
the following.

Question (Brezis). Depending on the dimension @xmath or on the domain
@xmath , is the extremal solution @xmath of ( 2.55 ) bounded (and
therefore classical) or is it unbounded? More generally, one may ask the
same question for the larger class of stable solutions to ( 2.52 ).

The following is an explicit example of stable unbounded (or singular)
solution.

It is easy to check that, for @xmath , the function @xmath is a solution
of ( 2.52 ) in @xmath , the unit ball, for @xmath . Let us now consider
the linearized operator at @xmath , which is given by

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , then its first Dirichlet eigenvalue in @xmath is
nonnegative. This is a consequence of Hardy’s inequality ( 2.25 ):

  -- -------- --
     @xmath   
  -- -------- --

and the fact that @xmath if @xmath . Thus we proved the following
result.

###### Proposition 2.42.

For @xmath , @xmath is an @xmath stable weak solution of @xmath in
@xmath , @xmath in @xmath , @xmath on @xmath .

Thus, in dimensions @xmath there exist unbounded @xmath stable weak
solutions of ( 2.52 ), even in the unit ball and for the exponential
nonlinearity. It is believed that @xmath could be the optimal dimension
for this fact, as we describe next.

##### 2.3.2 Regularity of stable solutions. The Allard and Michael-Simon
Sobolev inequality

The following results give @xmath bounds for stable solutions. To avoid
technicalities we state the bounds for the extremal solution but, more
generally, they also apply to every stable weak solution of ( 2.52 )
which is the pointwise limit of a sequence of bounded stable solutions
to similar equations (see [ 25 ] ).

###### Theorem 2.43 (Crandall-Rabinowitz [18]).

Let @xmath be the extremal solution of ( 2.55 ) with @xmath or @xmath ,
@xmath . If @xmath , then @xmath .

###### Outline of the proof (in the case @xmath).

Use the equation in ( 2.55 ) for the classical solutions @xmath ( @xmath
), together with the stability condition ( 2.54 ) for the test function
@xmath (for a positive exponent @xmath to be chosen later). More
precisely, start from ( 2.54 ) – with @xmath replaced by @xmath – and to
proceed with @xmath , write @xmath , and integrate by parts to use (
2.55 ). For every @xmath , verify that this leads, after letting @xmath
, to @xmath . As a consequence, by Calderón-Zygmund theory and Sobolev
embeddings, @xmath if @xmath . This requires that @xmath . ∎

Notice that the nonlinearities @xmath or @xmath with @xmath satisfy (
2.56 ).

In the radial case @xmath we have the following result.

###### Theorem 2.44 (Cabré-Capella [12]).

Let @xmath be the extremal solution of ( 2.55 ). Assume that @xmath
satisfies ( 2.56 ) and that @xmath . If @xmath , then @xmath .

As mentioned before, this theorem also holds for every @xmath stable
weak solution of ( 2.52 ), for any @xmath . Thus, in view of Proposition
2.42 , the dimension @xmath is optimal in this result.

We turn now to the nonradial case and we present the currently known
results. First, in 2000 Nedev solved the case @xmath .

###### Theorem 2.45 (Nedev [32]).

Let @xmath be convex and satisfy ( 2.56 ), and @xmath be a smooth
bounded domain. If @xmath , then @xmath .

In 2010, Nedev’s result was improved to dimension four:

###### Theorem 2.46 (Cabré [8]; Villegas [37]).

Let @xmath satisfy ( 2.56 ), @xmath be a smooth bounded domain, and
@xmath . If @xmath assume either that @xmath is a convex nonlinearity or
that @xmath is a convex domain. Then, @xmath .

For @xmath , [ 8 ] requires @xmath to be convex, while @xmath needs not
be convex. Some years later, S. Villegas [ 37 ] succeeded to use both [
8 ] and [ 32 ] when @xmath to remove the requirement that @xmath is
convex by further assuming that @xmath is convex.

###### Open problem 2.47.

For every @xmath and for every @xmath satisfying ( 2.56 ), is the
extremal solution @xmath – or, in general, @xmath stable weak solutions
of ( 2.52 ) – always bounded in dimensions @xmath ?

We recall that the answer to this question is affirmative when @xmath ,
by Theorem 2.44 . We next sketch the proof of this radial result, as
well as the regularity theorem in the nonradial case up to @xmath . In
the case @xmath , we will need the following remarkable result.

###### Theorem 2.48 (Allard; Michael and Simon).

Let @xmath be an immersed smooth @xmath -dimensional compact
hypersurface without boundary.

Then, for every @xmath , there exists a constant @xmath depending only
on the dimension @xmath and the exponent @xmath such that, for every
@xmath function @xmath ,

  -- -------- -- --------
     @xmath      (2.57)
  -- -------- -- --------

where @xmath is the mean curvature of @xmath and @xmath .

This theorem dates from 1972 and has its origin in an important result
of Miranda from 1967. It stated that ( 2.57 ) holds with @xmath if
@xmath is a minimal surface in @xmath . See the book [ 25 ] for a proof
of Theorem 2.48 .

###### Remark 2.49.

Note that this Sobolev inequality contains a term involving the mean
curvature of @xmath on its right-hand side. This fact makes, in a
remarkable way, that the constant @xmath in the inequality does not
depend on the geometry of the manifold @xmath .

###### Outline of the proof (of Theorems 2.44, 2.45, and 2.46).

For Theorem 2.45 the test function to be used is @xmath , for some
@xmath depending on @xmath (as in the proof of Theorem 2.43 ).

Instead, for Theorems 2.44 and 2.46 , the proofs start by writing the
stability condition ( 2.54 ) for the test function @xmath , where @xmath
. This was motivated by the analogous computation that we have presented
for minimal surfaces right after Remark 2.14 . Integrating by parts, one
easily deduces that

  -- -------- -- --------
     @xmath      (2.58)
  -- -------- -- --------

Next, a key point is to choose a function @xmath satisfying an
appropriate equation for the linearized operator @xmath . In the radial
case (Theorem 2.44 ) the choice of @xmath and the final choice of @xmath
are

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , @xmath , and @xmath is later truncated near the origin to
make it Lipschitz. The proof in the radial case is quite simple after
computing the equation satisfied by @xmath .

For the estimate up to dimension 4 in the nonradial case (Theorem 2.46
), [ 8 ] takes

  -- -------- -- --------
     @xmath      (2.59)
  -- -------- -- --------

where, in dimension @xmath , @xmath is chosen depending on the solution
@xmath itself.

We make the choice ( 2.59 ) and, in particular, we take @xmath in ( 2.58
). It is easy to check that, in the set @xmath , we have

  -- -------- -- --------
     @xmath      (2.60)
  -- -------- -- --------

Taking an orthonormal basis in which the last vector is the normal
@xmath to the level set of @xmath (through a given point @xmath ), and
the other vectors are the principal directions of the level set at
@xmath , one easily sees that ( 2.60 ) can be written as

  -- -------- -- --------
     @xmath      (2.61)
  -- -------- -- --------

where @xmath is the squared norm of the second fundamental form of the
level set of @xmath passing through a given point @xmath , i.e., the sum
of the squares of the principal curvatures of the level set. In the
notation of the first section on minimal surfaces, @xmath . On the other
hand, as in that section @xmath denotes the tangential gradient to the
level set. Thus, ( 2.61 ) involves geometric information of the level
sets of @xmath .

Therefore, using the stability condition ( 2.58 ), we conclude that

  -- -------- -- --------
     @xmath      (2.62)
  -- -------- -- --------

Let us define

  -- -------- --
     @xmath   
  -- -------- --

for @xmath .

We now use ( 2.62 ) with @xmath , where @xmath is a Lipschitz function
in @xmath with @xmath . The right hand side of ( 2.62 ) becomes

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

by the coarea formula . Thus, ( 2.62 ) can be written as

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

We conclude that

  -- -------- -- --------
     @xmath      (2.63)
  -- -------- -- --------

for all Lipschitz functions @xmath with @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

for every regular value @xmath of @xmath . We recall that, by Sard’s
theorem, almost every @xmath is a regular value of @xmath .

Inequality ( 2.63 ), with @xmath and @xmath as defined above, leads to a
bound for @xmath (that is, to an @xmath estimate and hence to Theorem
2.46 ) after choosing an appropriate test function @xmath in ( 2.63 ).
In dimensions 2 and 3 we can choose a simple function @xmath in ( 2.63 )
and use well known geometric inequalities about the curvature of
manifolds (note that @xmath involves the curvature of the level sets of
@xmath ). Instead, in dimension 4 we need to use the geometric Sobolev
inequality of Theorem 2.48 on each level set of @xmath . Note that
@xmath . This gives the following lower bound for @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Comparing this with @xmath , which appears in the right hand side of (
2.63 ), we only know how to derive an @xmath -estimate for @xmath (i.e.,
a bound on @xmath ) when the exponent @xmath in the above inequality is
larger than or equal to the exponent @xmath in @xmath . This requires
@xmath . See [ 8 ] for details on how the proof is finished. ∎

#### 2.4 Appendix: a calibration giving the optimal isoperimetric
inequality

Our first proof of Theorem 2.7 used a calibration. To understand better
the concept and use of “calibrations”, we present here another one. It
leads to a proof of the isoperimetric problem.

The isoperimetric problems asks which sets in @xmath minimize perimeter
for a given volume. Making the first variation of perimeter (as in
Section 2.1 ), but now with a volume constraint, one discovers that a
minimizer @xmath should satisfy @xmath (with @xmath a constant), at
least in a weak sense, where @xmath is the mean curvature of @xmath .
Obviously, balls satisfy this equation – they have constant mean
curvature. The isoperimetric inequality states that the unique
minimizers are, indeed, balls. In other words, we have:

###### Theorem 2.50 (The isoperimetric inequality).

We have

  -- -------- -- --------
     @xmath      (2.64)
  -- -------- -- --------

for every bounded smooth domain @xmath . In addition, if equality holds
in ( 2.64 ), then @xmath must be a ball.

In 1996 the first author found the following proof of the isoperimetric
problem. It uses a calibration (for more details see [ 10 ] ).

###### Outline of the proof (of the isoperimetric inequality).

The initial idea was to characterize the perimeter @xmath as in ( 2.9
)-( 2.10 ), that is, as

  -- -------- --
     @xmath   
  -- -------- --

Taking @xmath to be a gradient, we have that

  -- -------- --
     @xmath   
  -- -------- --

for every function @xmath such that @xmath on @xmath . Let us take
@xmath to be the solution of

  -- -------- -- --------
     @xmath      (2.65)
  -- -------- -- --------

where @xmath is a constant that, by the divergence theorem, is given by

  -- -------- --
     @xmath   
  -- -------- --

It is known that there exists a unique solution @xmath to ( 2.65 ) (up
to an additive constant).

Now let us see that @xmath (where @xmath was the notation that we used
in the proof of Theorem 2.7 ) can play the role of a calibration. In
fact, in analogy with Definition 2.8 we have:

1.  (i-bis) @xmath ;

2.  (ii-bis) @xmath ;

3.  (iii-bis) @xmath , where

      -- -------- --
         @xmath   
      -- -------- --

    is the lower contact set of @xmath , that is, the set of the points
    of @xmath at which the tangent plane to @xmath stays below @xmath in
    @xmath .

The relations (i-bis) and (ii-bis) follow immediately from ( 2.65 ). In
the following exercise, we ask to establish (iii-bis) and finish the
proof of ( 2.64 ).

We point out that this proof also gives that @xmath must be a ball if
equality holds in ( 2.64 ). ∎

###### Exercise 2.10.

Establish (iii-bis) above. For this, use a foliation-contact argument
(as in the alternative proof of Theorem 2.7 and in the proof of Theorem
2.26 ), foliating now @xmath by parallel hyperplanes.

Next, finish the proof of ( 2.64 ). For this, consider the measures of
the two sets in (iii-bis), compute @xmath using the area formula , and
control @xmath using the geometric-arithmetic means inequality.

  Acknowledgments. The authors wish to thank Lorenzo Cavallina for
  producing the figures of this work.
  The first author is member of the Barcelona Graduate School of
  Mathematics and is supported by MINECO grants MTM2014-52402-C3-1-P and
  MTM2017-84214-C2-1-P. He is also part of the Catalan research group
  2017 SGR 1392.
  The second author was partially supported by PhD funds of the
  Università di Firenze and he is a member of the Gruppo Nazionale
  Analisi Matematica Probabilitá e Applicazioni (GNAMPA) of the Istituto
  Nazionale di Alta Matematica (INdAM). This work was partially written
  while the second author was visiting the Departament de Matemàtiques
  of the Universitat Politècnica de Catalunya, that he wishes to thank
  for hospitality and support.