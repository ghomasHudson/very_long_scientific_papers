##### Keywords:

Signal processing, compressed sensing, sparse estimation, community
detection, generalized linear models, generalized bilinear models,
matrix factorization, low-rank matrix compressed sensing, phase
retrieval, phase transitions, Bayesian inference, belief propagation,
message-passing algorithms, state evolution analysis, replica method.

\@openrightfalse

### Résumé

Le développement récent de l’acquisition comprimée a permis de
spectaculaires avancées dans la compréhension des problèmes d’estimation
linéaire parcimonieuse ainsi que de leurs algorithmes de résolution. Ce
développement a également suscité un intérêt renouvelé pour les
problèmes d’inférence linéaire et bilinéaire généralisée. Ceux-ci
trouvent diverses applications en traitement du signal et constituent de
plus le composant de base des réseaux neuronaux profonds. Ces problèmes
ont en commun de combiner un étape linéaire avec une étape non linéaire
et probabiliste, à l’issue de laquelle des mesures sont effectuées. Ce
type de situations se présente dans des problèmes aussi variés que
l’imagerie médicale, l’astronomie, le clustering ou la séparation de
sources audio.

Cette thèse s’intéresse à des algorithmes pour la résolution de ces
problèmes ainsi qu’à leur analyse théorique. Pour cela, nous utilisons
des algorithmes de passage de message, qui permettent d’échantillonner
efficacement des distributions de haute dimension et rendent ainsi
possible une approche d’inférence bayésienne. Ces algorithmes
connaissent des changements de phase tout comme de nombreux systèmes
physiques. Les différentes phases se laissent analyser à l’aide de la
méthode des répliques, initialement développée dans le cadre de la
physique statistique des milieux désordonnés. L’analyse révèle qu’elles
correspondent à des domaines dans l’espace des paramètres dans lesquels
l’inférence est facile, difficile ou impossible, selon le paysage
énergétique du problème.

Les principales contributions de cette thèse peuvent être regroupées en
trois catégories. D’abord, l’application d’algorithmes connus à des
problèmes concrets : détection de communautés, codes correcteurs
d’erreurs ainsi qu’un système d’imagerie innovant. Ensuite, un nouvel
algorithme traitant une classe de problèmes d’inférence appelée
calibration aveugle de capteurs, potentiellement applicable à de
nombreux systèmes de mesure utilisant des réseaux de capteurs physiques.
Enfin, une analyse théorique des performances qui peuvent être atteintes
en inférence bayésienne pour le problème de reconstruction de matrices à
petit rang à partir de projections linéaires, ainsi qu’une analyse d’une
instabilité présente dans les algorithmes d’inférence bilinéaire.

###### Mots-clés:

Traitement du signal, acquisition comprimée, estimation parcimonieuse,
détection de communautés, modèles linéaires généralisés, modèles
bilinéaires généralisés, décomposition de matrices, reconstruction de
matrices de petit rang, reconstruction de phase, transitions de phase,
inférence bayésienne, belief propagation , algorithmes de passage de
messages, state evolution , méthode des répliques.

\@openrighttrue

### Sommario

Lo sviluppo degli algoritmi di compressed sensing ha permesso grandi
progressi nella comprensione dei problemi sparsi di teoria della stima e
degli algoritmi necessari per risolverli. Inoltre, ha contribuito a far
crescere l’interesse per i problemi di inferenza lineare e bilineare
generalizzati, che hanno molte applicazioni nella teoria dei segnali e
sono fondamentali per la descrizione dei modelli di reti neurali
profonde. Questi problemi di inferenza hanno in comune il fatto che
combinano un passo lineare ed uno non lineare, probabilistico, al
termine del quale sono effettuate le misure del segnale di interesse.
Inoltre, sono utili a risolvere problemi che emergono in contesti
diversi come quello della ricostruzione di immagini in medicina e in
astronomia, la determinazione di componenti diversi di un sistema
(problema del clustering ) e quello del filtraggio di un segnale da un
rumore in assenza di molte informazioni ( blind sensor calibration ).

L’obiettivo di questa tesi è di proporre soluzioni efficienti a questo
tipo di problemi e di farne un’analisi teorica. Dunque si fa uso della
belief propagation , grazie a cui il sampling di distribuzioni in alte
dimensioni può essere fatto in modo efficiente. Questo rende trattabile
un approccio Bayesiano al problema. Gli algoritmi sviluppati hanno
transizioni di fase proprio come i sistemi fisici e queste transizione
di fase possono essere studiate utilizzando il metodo delle repliche,
sviluppato inizialmente nella meccanica statistica dei sistemi
disordinati. Le analisi rivelano che ci sono fasi in cui l’inferenza è
facile ed altre in cui è difficile o impossibile, a seconda del
paesaggio di energia del problema.

I contributi principali di questa tesi si possono dividere in tre parti.
Nella prima, l’applicazione di algoritmi noti a problemi concreti: la
ricostruzione di comunità in un grafo ( community detection ), lo studio
degli sparse superposition codes e un nuovo sistema di imaging. Nella
seconda, un nuovo algoritmo per i problemi di inferenza della classe
blind sensor calibration , che potrebbe essere utile a migliorare le
stime dei sensori fisici. Nella terza, un’analisi teorica delle
prestazioni raggiungibili nell’inferenza Bayesiana nel problema di
compressed sensing applicato alle matrici di basso rango, e di
un’instabilità presente negli algoritmi di inferenza bilineare.

###### Parole chiavi:

Elaborazione del segnale, compressed sensing , segnali sparsi, community
detection , generalized linear models , generalized bilinear models ,
matrix factorization , low-rank matrix compressed sensing , phase
retrieval , transizioni di fase, Bayesian inference , belief propagation
, message-passing algorithms , state evolution analysis , metodo delle
repliche.

###### Contents

-    Remerciements
-    Abstract
-    Introduction
    -    Organization of the thesis
    -    Main contributions
-    I Statistical physics of inference problems
    -    1 Inference and statistical physics
        -    1.1 Inference
            -    1.1.1 General setting
            -    1.1.2 Achievable performances
            -    1.1.3 Decoding strategies
        -    1.2 Statistical physics
            -    1.2.1 Equilibrium statistical physics in a nutshell
            -    1.2.2 Disordered systems
        -    1.3 Statistical physics for non-physical problems
            -    1.3.1 Possibilities and limitations
            -    1.3.2 Examples
        -    1.4 Inference problems examined in this thesis
            -    1.4.1 Community detection
            -    1.4.2 Generalized linear and bilinear models
    -    2 Community detection
        -    2.1 Setting
            -    2.1.1 Graphs
            -    2.1.2 Random graphs
        -    2.2 Approaches and algorithms
            -    2.2.1 Spectral algorithms
            -    2.2.2 Bayesian inference
            -    2.2.3 Modularity maximization
        -    2.3 Belief propagation
            -    2.3.1 BP equations
            -    2.3.2 Mod-bp
        -    2.4 Algorithmic phase transitions
            -    2.4.1 Paramagnetic, recovery and spin glass phase
            -    2.4.2 Model-based critical temperatures
            -    2.4.3 Degenerate groups
        -    2.5 Coexistence of phases
            -    2.5.1 Location of critical temperatures
            -    2.5.2 Running mod-bp with @xmath
            -    2.5.3 Results on real networks
            -    2.5.4 Discussion
        -    2.6 Conclusion
-    II Linear and bilinear inference problems
    -    3 Compressed sensing and generalizations
        -    3.1 Compressed sensing
            -    3.1.1 Setting
            -    3.1.2 Geometric interpretation
            -    3.1.3 Solving strategies
            -    3.1.4 A CS solver: Iterative thresholding
        -    3.2 Generalized linear models
            -    3.2.1 General setting
            -    3.2.2 Additional conditions
            -    3.2.3 GAMP
        -    3.3 Replica analysis
            -    3.3.1 Replica analysis: free entropy
            -    3.3.2 Replica symmetric assumption
            -    3.3.3 State evolution equations
            -    3.3.4 Bayes optimal analysis
            -    3.3.5 Partial information on @xmath
        -    3.4 Compressed sensing analysis
        -    3.5 Quantized sensing
            -    3.5.1 1 bit CS of continuous and binary signals
            -    3.5.2 Applications: perceptron
            -    3.5.3 Neural networks inference
        -    3.6 Conclusion
    -    4 Generalized bilinear models
        -    4.1 Gain calibration
            -    4.1.1 Convex formulation
            -    4.1.2 Applications
        -    4.2 Matrix factorization
            -    4.2.1 Algorithm and analysis
            -    4.2.2 Applications
        -    4.3 Matrix compressed sensing
            -    4.3.1 Setting
            -    4.3.2 Link to matrix factorization
            -    4.3.3 Existing work for the AWGN channel
        -    4.4 Conclusion
-    III Main contributions
    -    5 Vectorial GAMP and applications
        -    5.1 Complex GAMP
            -    5.1.1 Vectorial GAMP
            -    5.1.2 Complex GAMP
        -    5.2 CS with fast operators and superpositions codes
            -    5.2.1 Complex CS state evolution
            -    5.2.2 Compressed sensing with fast operators
            -    5.2.3 Superposition codes
        -    5.3 Phase retrieval
            -    5.3.1 Imaging through scattering media
        -    5.4 Conclusion
    -    6 Blind sensor calibration
        -    6.1 Setting
        -    6.2 Cal-AMP
            -    6.2.1 Derivation
            -    6.2.2 Comparison to GAMP
        -    6.3 Case studies
            -    6.3.1 Gain calibration
            -    6.3.2 Faulty sensors
            -    6.3.3 1-bit threshold calibration
        -    6.4 Encountered issues
            -    6.4.1 Blind deconvolution
            -    6.4.2 State evolution
        -    6.5 Conclusion
    -    7 Analysis of matrix compressed sensing
        -    7.1 Matrix compressed sensing
            -    7.1.1 Notations
            -    7.1.2 Message-passing algorithm
        -    7.2 Asymptotic analysis
            -    7.2.1 Replica analysis: free entropy
            -    7.2.2 Replica symmetric assumption
            -    7.2.3 State evolution equations
            -    7.2.4 Bayes optimal analysis
        -    7.3 Stability analysis
            -    7.3.1 Blind matrix calibration state evolution
            -    7.3.2 Instability of the Nishimori line
        -    7.4 Case Study
            -    7.4.1 Phases and phase transitions
            -    7.4.2 Comparison with algorithmic performances
        -    7.5 Conclusion
    -    Conclusion and perspectives
-    A Useful functions
    -    A.1 Standard functions
        -    A.1.1 Gaussians
        -    A.1.2 Other useful functions and integrals
    -    A.2 Update functions
-    B Introducing the conjugate variable @xmath
-    C Blind sensor calibration state evolution
-    D Sparse phase retrieval state evolution

###### List of Figures

-    1.1 General setting of an inference problem
-    1.2 A decoder
-    1.3 Convex minimization
-    1.4 Non-convex minimization
-    1.9 Inference problems with mixing and sensing
-    2.1 Community detection
-    2.2 Adjacency matrices of SBM networks
-    2.3 Detectability transition in community detection
-    2.4 A factor graph
-    2.5 Phase transitions of group degeneracies
-    2.6 Effective groups
-    2.7 Phase transitions in “political books”
-    (a) Modularity
-    (b) Number of groups
-    2.8 Degenerate phase transitions
-    (a) Degenerate @xmath s.
-    (b) Distinct @xmath s.
-    2.9 Overview of political books and blogs
-    (a) Political books
-    (b) Political blogs
-    2.10 Retrieval modularities as a function of the effective number
    of groups
-    (a) Political books
-    (b) Political blogs
-    2.11 Overview of the air transportation network
-    (a) 4 communities.
-    (b) 7 communities.
-    (c) Coexistence of phases.
-    (d) Increase of @xmath .
-    3.1 Noiseless compressed sensing
-    3.2 Geometric insight into compressed sensing
-    (a) 2 dimensions
-    (b) 3 dimensions
-    3.3 Generalized linear models
-    3.4 Algorithm dynamics and state evolution
-    3.5 Phases and phase transitions in CS
-    (a) Phase diagram of CS.
-    (b) First and second order phase transitions.
-    3.6 Free entropy and fixed points in CS
-    (a) Free entropy.
-    (b) Fixed points of the state evolution.
-    3.7 Geometric insight into quantized sensing
-    (a) @xmath -bit measurements in @xmath dimensions.
-    (b) MSEs of @xmath -bit CS.
-    3.8 Phase diagram of @xmath -bit CS of binary signals
-    (a) Binary signal with values @xmath
-    (b) Binary signal with values @xmath
-    3.9 Neural firing patterns
-    (a) @xmath
-    (b) @xmath
-    4.1 Blind gain calibration
-    (a) Supervised gain calibration.
-    (b) Blind gain calibration.
-    4.2 Generalized matrix factorization
-    4.3 Matrix compressed sensing
-    5.1 GAMP factor graph
-    5.2 Phase diagram of complex CS
-    5.3 Convergence of complex CS
-    (a) Experimental and theoretical convergence.
-    (b) Times to convergence.
-    5.4 Importance of the phase in Fourier measurements
-    (a) Original images.
-    (b) Reconstructions with switched phases.
-    5.5 Experimental convergence of PR-GAMP
-    (a) @xmath
-    (b) @xmath
-    5.6 Scattering medium
-    5.7 Experimental setup
-    5.8 Focusing through a multiply scattering medium
-    6.1 Cal-AMP general setting
-    6.2 Cal-AMP factor graph
-    6.3 Phase diagram for real gain calibration
-    6.4 Position of phase transition with decalibration amplitude
-    (a)
-    (b)
-    6.5 Comparison of gain calibration with Cal-AMP and @xmath
    minimization
-    6.6 Phase diagram for complex gain calibration
-    6.7 Phase diagram for the faulty sensors problem
-    6.8 Bayes optimal @xmath -bit threshold calibration
-    (a) nMSE on the signal
-    (b) nMSE on the thresholds
-    6.9 @xmath -bit threshold calibration with mismatching prior
-    (a) @xmath
-    (b) @xmath
-    (c) @xmath
-    7.1 Generalized matrix compressed sensing
-    7.2 Factor graph of matrix compressed sensing
-    7.3 Nishimori line instability: MSE
-    7.4 Nishimori line instability: @xmath
-    7.5 Matrix compressed sensing: Free entropy landscape
-    7.6 State evolution fixed points
-    (a) @xmath
-    (b) @xmath
-    7.7 Phase diagram for matrix compressed sensing
-    7.8 Experimental and theoretical fixed points 1
-    (a) @xmath , @xmath
-    (b) @xmath , @xmath
-    7.9 Experimental and theoretical fixed points 2
-    (a) @xmath , @xmath
-    (b) @xmath , @xmath
-    7.10 Experimental phase transition
-    (a) @xmath
-    (b) @xmath

### Introduction

#### Organization of the thesis

The thesis is subdivided in 3 parts. The first one introduces key
concepts in inference and statistical physics, and shows how the latter
can be used to solve problems of the former. The second part introduces
a broad class of problems as well as related algorithms and analysis
techniques. The last part contains my main contributions to this class
of problems.

##### Part I: Statistical physics of inference problems

###### Chapter 1: Inference and statistical physics

The first chapter separately introduces key concepts of inference and of
statistical physics. The goals of inference and the challenges commonly
encountered are described, along with two general solving strategies.
The simple examples of denoising and linear estimation are given in
order to illustrate the concepts, at the same time introducing two
fundamental tools for all the problems encountered subsequently. The
fundamental tools of statistical physics i.e. the partition function and
the related free entropy and free energy are introduced. Phase
transitions are illustrated by the examples of the Ising model, the
SK-model and their respective phase diagrams. Strength and limitations
of the statistical physics approach to inference problems are discussed,
followed by an overview of the inference problems treated in the thesis.

###### Chapter 2: Community detection

The second chapter shows how insight gained from statistical physics can
help solving an inference problem. To this end, the problem of community
detection is described along with its challenges. Belief propagation is
introduced as an algorithm for estimating high-dimensional probability
distributions. A study of a such an algorithm, published in [ 131 ] is
made, showing the existence of algorithmic transitions between phases
similar to the ones found in physical systems.

##### Part II: Linear and bilinear inference problems

###### Chapter 3: Compressed sensing and generalizations

This chapter presents generalized linear models, focusing on compressed
sensing. The replica method—coming from physics of disordered systems—is
used to perform a theoretical analysis of inference of generalized
linear models. A Bayesian algorithm using belief propagation is
introduced (GAMP). The performances reached by GAMP are compared to the
theoretical predictions previously obtained. Limitations of GAMP are
mentioned as well as possible remedies.

###### Chapter 4: Generalized bilinear models

Chapter 4 presents generalized bilinear models, closely related to
generalized linear models but more difficult to solve in practice.
Results of the theoretical analysis and a Bayesian message-passing
algorithm for generalized matrix factorization are briefly presented.
Generalized matrix compressed sensing is introduced.

##### Part III: Main contribution

Part III contains my main contributions to inference of linear and
bilinear models.

###### Chapter 5: Vectorial GAMP and applications

###### Chapter 6: Blind sensor calibration

###### Chapter7: Analysis of matrix compressed sensing

Details about these chapters are given in the following section.

#### Main contributions

The main contributions of my thesis are published (or in preparation) in
the following papers:

-   “Blind calibration in compressed sensing using message passing
    algorithms” [ 129 ] ,

-   “Reference-less measurements of the transmission matrix of a highly
    scattering material using a DMD and phase retrieval techniques” [ 43
    ] ,

-   “Approximate message-passing with spatially coupled structured
    operators, with application to compressed sensing and sparse
    superposition codes” [ 10 ] ,

-   “Blind sensor calibration using approximate message passing” [ 130 ]
    ,

-   “Multiple phases in modularity-based community detection” [ 131 ] ,

-   “Phase diagram of matrix compressed sensing” [ 132 ] .

They treat different inference problems using methods of statistical
physics, relying on belief propagation and on the replica method.

##### Community detection

Ref [ 131 ] analyzes a recently published community detection algorithm
called mod-bp, based on belief propagation and on a physical intuition
of the origin of the computational hardness in community detection. In [
131 ] , I reveal the existence of more algorithmic phases than
previously known in community detection. I introduce a new set of order
parameters which allows to define an effective number of communities. A
study on synthetic and real-world networks is made, and a simple
multiresolution strategy for hierarchical networks is described and
tested on a real-world network.

##### Applications of GAMP

The GAMP algorithm can be applied to all problems of the class of
generalized linear models and can therefore be used in many specific
applications. In chapter 5 , I give a derivation of complex-valued GAMP
(for which no derivation was published until recently) and present two
applications of GAMP, treated in [ 10 , 43 ] .

In [ 10 ] , we perform a theoretical analysis of complex compressed
sensing. Furthermore, we use structured operators (Fourier and Hadamard
operators) as measurement matrices in compressed sensing, which allows a
drastic speed-up and allows to treat problems of bigger sizes. The
second part of the paper focuses on superposition codes, that are
capacity-achieving in a certain configuration using a message-passing
decoder closely related to GAMP.

In [ 43 ] , GAMP is used in an optics experiment. The goal of the
experiment is to determine the transmission matrix of a highly
scattering material, thus allowing imaging or focusing through the
medium. The use of phase retrieval—for which complex GAMP can be
used—greatly simplifies the necessary experimental setup, opening the
way to further developments.

##### Blind sensor calibration

In chapter 6 , I present the work published in [ 129 , 130 ] . Blind
sensor calibration can be seen as a generalization of compressed
sensing. While special cases of blind calibration (e.g. blind gain
calibration) have been studied before using different types of
algorithms, I propose a Bayesian message-passing algorithm called
Cal-AMP that can handle much more general situations. Additionally to
real and complex gain calibration, two such situations are examined and
Cal-AMP tested on them.

##### Bilinear inference

In chapter 7 , I present two contributions to bilinear inference
problems. First, I provide an analysis that explains the convergence
difficulties encountered by some algorithms in bilinear inference
problems. Secondly, I provide a theoretical analysis of low-rank matrix
compressed sensing (in preparation in [ 132 ] ). I show that the
theoretical analysis gives the same results as the one of the problem of
matrix factorization. I perform an analysis of a special case, which I
compare with the results obtained by a recently published algorithm,
PBiGAMP. Beside an excellent global agreement, interesting finite-size
effects are observed that allow successful inference in a hard phase.

#### Minor contributions

Besides these main contributions that have been published, a few minor
but possibly useful contributions are present in this thesis:

-   The use of a coherent set of notations for the estimators and
    variances updated in algorithms, using hats, bars, upper and
    lower-case letters. This allows to keep the number of variables to a
    minimum and to easily recognize the signification of each quantity.

-   The use of the @xmath functions defined in Appendix A.2 , that allow
    simplified expressions for the state evolution equations,
    exclusively using functions used in the algorithms. Besides, the
    relation ( A.30 ) allows to obtain the general state equations from
    the replica free entropy.

-   The full derivation of the GAMP state evolution equations starting
    from the replica analysis (which is nothing but a special case of
    the analysis made in [ 67 ] ).

-   The phase diagrams of noisy @xmath -bit CS and @xmath -bit CS of
    binary variables (Fig. 3.6(b) , Fig. 3.8 ).

-   Preliminary results on the state evolution for blind sensor
    calibration in Appendix C and for phase retrieval in Appendix D .

## Part I Statistical physics of inference problems

### Chapter 1 Inference and statistical physics

In recent years, questions in fields such as signal processing, machine
learning and information theory have increasingly drawn the attention of
statistical physicists. The differences in background, goals and spirit
that separate mathematicians and physicists have turned out to be very
fruitful and have lead to a new understanding of a number of problems.
Therefore, the field is developing and several books already present
information theory and statistical physics in a joint manner [ 93 , 105
] , such that the way between the two has become smoother.

The goal of this chapter is to introduce the concepts and notations of
inference (sec. 1.1 ) and statistical physics (sec. 1.2 ). This concise
introduction only aims at presenting what will be directly used in this
thesis, good reference books are [ 140 , 93 , 105 ] . In sec. 1.3 , I
will explain how the statistical physics approach can contribute to the
understanding of inference problems, as well as its limitations.
Finally, in sec. 1.4 , I will briefly introduce the different inference
problems on which I have worked and that will be treated in the rest of
the thesis.

#### 1.1 Inference

##### 1.1.1 General setting

Often, a signal of interest cannot be observed directly, but only
through a channel that provides indirect measurements. This channel is
characterized by a probability distribution function (pdf) that
describes the statistical relation between signal and measurement. In
the most general setting, let us call

  -------- -----------------------
  @xmath   the signal,
  @xmath   the measurements, and
  @xmath   the channel.
  -------- -----------------------

The ensembles @xmath and @xmath can be discrete or continuous and of
various dimensions, such as @xmath , @xmath , @xmath , @xmath , etc…The
channel often depends on a set of parameters @xmath , although we do not
explicitly indicate this dependence for notational lightness. This
general inference setting, illustrated in Fig. 1.1 , is ubiquitous in a
large number of fields, ranging from scientific experiments to
telecommunications or internet advertising.

The goal of inference is to obtain the best possible estimate @xmath of
@xmath from the measurements @xmath . In order to reach this goal, three
essential questions have to be answered:

1.   What is a “good” estimate of @xmath ? Obviously, the ideal estimate
    is @xmath . But as nothing assures us that this estimate is possible
    to obtain, one needs to define a measure of success (or metric) that
    quantifies how good an estimate @xmath is.

2.   What is the best possible performance achievable in this setting?
    This depends both on the distribution of @xmath and on the channel,
    and it is the most interesting question from an
    information-theoretical point of view.

3.   How do we produce a good estimate @xmath ? In order to concretely
    obtain an estimate @xmath , one needs to design a function that
    returns an estimate @xmath for every possible measurement @xmath .
    This function, illustrated in Fig. 1.2 , is usually called the
    decoder or the solver and has to be carefully designed.

Answering to the first question is part of a satisfying description of
the problem and corresponds to choosing a distance (or metric) over the
ensemble @xmath . For instance, for @xmath , the distance usually
considered is the mean squared error (MSE) \marginnote MSE [1.1cm]

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

while if @xmath is a discrete ensemble, a good metric is the overlap ,
i.e. the fraction of correctly guessed signal components \marginnote
Overlap [0.8cm]

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

Answering to the second question is making the theoretical analysis of
the problem, while answering to the third one is actually solving it.

##### 1.1.2 Achievable performances

In order to make an information-theoretical analysis of a problem such
as presented in Fig. 1.1 , two approaches coexist [ 98 ] .

The first one is the worst case analysis. In it, we assume that it is
not equally easy to obtain a good estimator @xmath for all possible
signals. The worst case scenario focuses on the signals for which the
achievable performance is the worst. Results obtained with this approach
are strong in the sense that they give a strict lower bound, but are
usually overly pessimistic and do not reflect the usually achievable
performances.

The second approach is the typical case analysis, in which we focus on
the performances usually achievable. In order to characterize this “
usually ”, we need to focus on a specific class of signals. We therefore
consider @xmath to be a realization of a random variable @xmath ,
distributed according to a pdf @xmath . The typical case analysis is
therefore made in a statistical framework. Furthermore, @xmath can be
used to design a decoder.

###### Elements of statistics

Let us briefly recall a few elements and notations of statistics. We
write

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

to signify that a random variable @xmath is distributed according to
@xmath . This means that the probability of the random variable @xmath
to take the value @xmath is @xmath . For notational lightness, we will
abusively use the same notation @xmath both for the random variable and
its realization. The differential entropy of @xmath is then defined by
\marginnote Differential entropy [0.7cm]

  -- -------- -------- -- -------
     @xmath   @xmath      (1.4)
  -- -------- -------- -- -------

and is a quantity that measures the uncertainty of @xmath : a random
variable with zero differential entropy has no uncertainty, meaning it
can only take a single value. Another useful quantity is the
Kullback-Leibler (KL) divergence between two probability distribution
functions @xmath and @xmath , defined by \marginnote KL divergence
[0.7cm]

  -- -------- -------- -- -------
     @xmath   @xmath      (1.5)
  -- -------- -------- -- -------

and that, although not symmetric, is a kind of measure of distance
between pdfs.

Furthermore, we say that @xmath and @xmath are independent random
variables, if and only if their joint pdf @xmath can be written as a
product in the following way: \marginnote Independence [0.7cm]

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

If this is not the case, we say that @xmath and @xmath are correlated,
and the conditional probability of @xmath knowing @xmath is given by
\marginnote Conditional probability [0.7cm]

  -- -------- -------- -- -------
     @xmath   @xmath      (1.7)
  -- -------- -------- -- -------

We can then define the mutual information \marginnote Mutual information
[0.75cm]

  -- -------- -------- -- -------
     @xmath   @xmath      (1.8)
  -- -------- -------- -- -------

that measures the degree to which @xmath and @xmath are correlated.

###### Analysis of given decoders

These quantities and formulas defined above are instrumental for
analysing the achievable performances of an inference problem from an
information-theoretical point of view. Another interesting task is the
analysis of the performances of a given decoding scheme.

##### 1.1.3 Decoding strategies

Interesting inference problems are characterized by the fact that
obtaining a good estimate @xmath is not trivial, i.e. there is no
analytic formula allowing to obtain @xmath from @xmath . In that case, a
decoding strategy has to be designed and implemented in an algorithm. In
the following, we describe two approaches to designing a decoder.

###### Minimization approach

In the minimization approach, the problem of decoding is reformulated as
a minimization problem. A cost function @xmath is chosen and the
estimator @xmath is taken as \marginnote Minimization problem [0.6cm]

  -- -------- -------- -- -------
     @xmath   @xmath      (1.9)
  -- -------- -------- -- -------

The advantage of this approach is that minimization problems are very
well studied and that fast and reliable methods exist if the function to
minimize has the right properties. In particular, as illustrated in Fig.
1.3 , minimization of convex functions is both well posed and
efficiently solvable, and is furthermore very well documented [ 20 ] .

On the other hand, if the cost function is not convex, minimization can
be a very difficult task (Fig. 1.4 ). In that case, solving eq. ( 1.9 )
is not straightforward and a general strategy is to approach @xmath by a
convex function @xmath \marginnote Convex relaxation and solve the new
minimization problem. However, the two problems are in general not
equivalent, and minimizing the convex relaxation @xmath of @xmath leads
to suboptimal results compared to minimizing @xmath .

###### Bayesian approach

A second approach is probabilistic. Using eq. ( 1.7 ) it is easy to show
Bayes’ theorem \marginnote Bayes’ theorem [0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.10)
  -- -------- -------- -- --------

and thus estimate the probability that the measurements @xmath were
generated by a signal @xmath . If @xmath is known, a sensible inference
strategy is to use the maximum a posteriori (MAP) estimator \marginnote
MAP estimator [0.45cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.11)
  -- -------- -------- -- --------

Though intuitive, this estimator is not always the best, and other
estimators can be constructed using the posterior distribution. One of
the most commonly used is the minimum mean square error (MMSE) estimator
\marginnote MMSE estimator [0.65cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.12)
  -- -------- -------- -- --------

that minimizes the expected MSE between the signal and its estimator.

When \marginnote Bayes optimality the functions @xmath (called the prior
) and @xmath (called the likelihood ) in eq. ( 1.10 ) are known exactly,
the probabilistic approach is said to be Bayes optimal . It is also
starting from eq. ( 1.10 ) that the information-theoretical analysis of
the problem is performed. An important advantage of the probabilistic
approach to inference is therefore that a Bayes optimal decoder should
be able to reach the performances predicted by the information-theoretic
analysis of the problem. If on the other hand the functions used
in eq. ( 1.10 ) are not the right ones, for instance if wrong parameters
@xmath are used, we say that there is a mismatch and the setting is not
Bayes optimal.

The main drawback of the probabilistic approach is that in general,
estimating @xmath is hard, because the denominator in eq. ( 1.10 ) has
to be calculated by marginalization over @xmath , \marginnote
Marginalization [0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.13)
  -- -------- -------- -- --------

In most cases, no analytical formula of this integral is known, and it
thus has to be evaluated numerically, which is hard when @xmath belongs
to a high-dimensional space, such as @xmath with large integer @xmath
for instance. The same problem occurs for eq. ( 1.12 ).

###### The two approaches

are not contradictory.As a matter of fact, it is simple to see that the
MAP problem eq. ( 1.11 ) can be written as minimization problem using
the cost function @xmath .

###### Challenges

Two recurring difficulties in the implementation of both approaches are
the curse of dimensionality and the problem of finding a global minimum
.

The curse of dimensionality is the fact that with increasing dimension
of the signal @xmath , the number of points necessary for sampling a
function defined on @xmath with a given precision increases
exponentially. To illustrate this, consider a function

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

with the regularity condition @xmath . We would like to be able to
approximate the function’s value at any point by its value at the
closest point of an @xmath -dimensional grid of spacing @xmath (thus
containing @xmath sampling points). The closest point @xmath is then at
maximal distance of @xmath , such that the error of the estimate is
bounded by

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

which can be rewritten as a function of the number of sampling points
\marginnote Curse of dimensionality [0.8cm]

  -- -------- -- --------
     @xmath      (1.16)
  -- -------- -- --------

from which one sees that the number of sampling points necessary to
estimate a function with a given precision increases exponentially with
the dimension @xmath . This makes it rapidly impossible to solve
extremization problems such as eq. ( 1.9 ) or eq. ( 1.11 ) by sampling
the function, and makes the numerical estimation of @xmath -dimensional
integrals such as eq. ( 1.12 ) or eq. ( 1.13 ) very difficult as well.
In short, none of the two previously described decoding strategies are
easy in high dimension.

The second difficulty is that of finding the global minimum of a
function. As mentioned before, in high dimension, performing this task
by sampling would be very time consuming. In Fig. 1.3 we have
illustrated that finding the global minimum of a convex function is easy
nonetheless. For a non-convex function, however, there is no efficient
method for finding the global minimum, as illustrated in Fig. 1.4 .

#### 1.2 Statistical physics

Statistical physics (or mechanics) has emerged as a field of physics
with the work of Boltzmann at the end of the 19th century. His work
aimed at explaining the laws of thermodynamics from a microscopic
approach, relying on the atomistic theory that was still an unproven
conjecture at the time. The probabilistic approach used in statistical
physics is in apparent contradiction with the deterministic approach of
classical point mechanics, but has proven to be correct and incredibly
powerful.

In this section, I introduce some of the key concepts of statistical
mechanics, independently of the previous section. The link between
inference and statistical physics will be illustrated in chapter 2 .

##### 1.2.1 Equilibrium statistical physics in a nutshell

Statistical mechanics typically studies a physical system at thermal
equilibrium, composed of a large number @xmath of particles, described
by @xmath , whose energy @xmath is given by a Hamiltonian @xmath . The
system is closed but can exchange energy with a thermal bath at
temperature @xmath (and inverse temperature @xmath ). The system’s
probability to be in a microscopic state @xmath is then given by the
Boltzmann distribution \marginnote Boltzmann distribution [0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.30)
  -- -------- -------- -- --------

The denominator @xmath is a normalization constant called the partition
function : \marginnote Partition function [0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (1.31)
  -- -------- -------- -- --------

Statistical physics makes the assumption that microscopic states @xmath
cannot be observed or measured, but that it is possible to measure
global quantities called observables. An observable @xmath is a
real-valued function of the microscopic state @xmath , but cannot be
measured instantaneously. Instead, measurement instruments always
average observables over a period of time @xmath :

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

If the system is ergodic , \marginnote Ergodicity it means that in the
period @xmath , the system explores all possible microscopic states
@xmath and that the total fraction of time it spends in a state is equal
to @xmath . Therefore, the expectation value of @xmath can be written as

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

This microscopic description of a system is closely linked to its
macroscopic description through the thermodynamic potentials . The most
used ones are the internal energy @xmath , the entropy @xmath and the
free energy @xmath , linked by the formula \marginnote Free energy
[0.65cm]

  -- -------- -- --------
     @xmath      (1.34)
  -- -------- -- --------

The free energy is of particular importance for systems at thermal
equilibrium, as it is the thermodynamic potential that these systems
minimize. The internal energy @xmath is the average of the observable
@xmath :

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

From this expression, we see that @xmath can be obtained from the
partition function as follows:

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

Similarly, the free energy @xmath and the closely related free entropy
@xmath can be expressed as functions of @xmath : \marginnote Free
entropy and energy [0.8cm]

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

###### The thermodynamic limit

The power of statistical physics is its ability to deal with large
system sizes @xmath . The thermodynamic potentials such as @xmath ,
@xmath and @xmath are extensive (they increase with @xmath ), which
leads to the definition of the intensive quantities

  -- -------- -------- -- --------
     @xmath   @xmath      (1.38)
  -- -------- -------- -- --------

called the free entropy density and free energy density respectively.
The fact that these limits exist is the key point of the thermodynamic
limit. The study of @xmath and @xmath can reveal discontinuities (in
value or slope) at some critical points @xmath : at these temperatures,
the system undergoes a phase transition (of first or second order).

Let us sketch a proof that the free energy @xmath is the thermodynamic
potential that a system minimizes at thermal equilibrium. We look at the
distributions of energies per particle, @xmath , of a system of size
@xmath at thermal equilibrium:

  -- -------- -------- -- --------
     @xmath   @xmath      (1.39)
              @xmath      (1.40)
  -- -------- -------- -- --------

In the first line, we introduce the number @xmath of states with energy
@xmath . In the second line, we introduce the entropy per particle,
defined as @xmath , and the free energy density @xmath . In the
thermodynamic limit (when @xmath ), @xmath and @xmath converge to @xmath
and @xmath , and

  -- -------- -------- -- --------
     @xmath   @xmath      (1.41)
  -- -------- -------- -- --------

where \marginnote Free energy minimization [0.7cm]

  -- -------- -- --------
     @xmath      (1.42)
  -- -------- -- --------

Therefore, in the thermodynamic limit, the system only explores the
states of minimal free energy (or equivalently, of maximal free
entropy). However, in physical systems, @xmath is finite and the
Boltzmann distribution allows fluctuations around the states of minimal
free energy.

##### 1.2.2 Disordered systems

We speak of a disordered system when the Hamiltonian of the system is a
function of the realization of a random variable @xmath :

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

All thermodynamic potentials and observables of this system then
explicitly depend on the realization @xmath . However, we can expect
that systems with different realizations of @xmath but large system size
@xmath have the same characteristics. We are therefore interested in
computing the thermodynamic potentials averaged over the disorder @xmath
, starting with the average free energy

  -- -------- -------- -- --------
     @xmath   @xmath      (1.47)
  -- -------- -------- -- --------

To calculate this average of a logarithm, the replica method can be
used, that starts from the identity \marginnote Replica trick [1cm]

  -- -------- -- --------
     @xmath      (1.48)
  -- -------- -- --------

and uses a series of non-rigorous mathematical tricks to calculate this
quantity. \marginnote Glassy phases The characteristic of disordered
systems is that they can have glassy phases in which their energy
landscape is chaotic, with exponentially many local minima. In these
glassy phases, the system gets stuck in metastable states, corresponding
to such local minima. The exponential number of these metastable state
make the dynamics of the system extremely slow, such that thermal
equilibrium is never reached.

#### 1.3 Statistical physics for non-physical problems

In the probabilistic framework of statistical physics, many methods have
been developed. Some of them are analytical, such as the replica method,
and were originally developed for the theoretic study of a certain class
of physical systems, such as spin glasses [ 94 ] . Others, such as Monte
Carlo algorithms, are numerical methods that have been developed to
simulate physical systems. Though developed for a given class of
physical systems, these methods can be applied to any non-physical
problem having a probabilistic formulation. This is the case of
inference problems, but also of many other problems in computer science,
such as constraint satisfaction [ 75 ] or coding [ 68 ] .

##### 1.3.1 Possibilities and limitations

Let us mention a few advantages and limits of statistical physics
methods when applied to non-physical problems. The work presented in the
following chapters of this thesis is naturally as well concerned by all
of those limitations.

###### Rigour

###### Limits

To the contrary of mathematics, physics use many non-rigorous methods—if
they give useful results. Physicists do not shy away from using unproven
identities, integrating a function without further verifications or
inverting the order of limits. While time-saving, this approach has the
obvious disadvantage that no results found with methods from physics
should be considered to be rigorous until made rigorous with methods
from mathematics.

###### Advantages

The bright side of the medal is that history has shown that non-rigorous
physicist’s methods can lead to accurate results. As in physics of
physical systems, theoretical results can be used to make predictions
and design experiences to validate or disprove them. In some of the
problems of computer science examined by physicists, results obtained
with non-rigorous methods could be verified by simulations, thus raising
the interest of mathematician who, guided and inspired by the announced
result, could prove them using rigorous methods.

###### Finite sizes

###### Limits

In statistical physics, the thermodynamic limit allows great
simplifications in many calculations. The corollary of this is that it
is usually much more difficult to obtain results for finite-sized
systems. In physical systems, finite size effects are often minimal or
unobservable because of the sheer number of particles (typically, @xmath
) that constitute macroscopic systems.

###### Advantages

The advantage is that the behaviour of small-sized systems is often
astonishingly close to the behaviour of their @xmath counterpart.

###### Typical vs. worst case

###### Limits

Adding to the fact that statistical physics methods are not rigorous,
and as a side effect of the importance of the thermodynamic limit,
results from statistical physics focus on the average case. In
information theoretical terms, this means that it is not possible to do
worst case analyses with statistical physics. When it comes to
algorithms, worst case analyses can be very important as they give a
lower bound on the algorithms’ performances.

###### Advantages

On the other hand, one can argue that worst case analyses often reveal
little or nothing about the usual performances of an algorithm.
Furthermore, with increasing system sizes, the probability of the “worst
case” actually happening decreases exponentially, and a typical instance
of a problem is ever likelier to be close to the average instance.

##### 1.3.2 Examples

In example LABEL:ex:neuralNetworks , we expose the problem of neural
networks, that comes from biology and computer science but was studied
extensively by physicists as well. Other non-physical problems studied
by the physicists include optimization, constraint satisfaction problems
and error-correcting codes.

#### 1.4 Inference problems examined in this thesis

##### 1.4.1 Community detection

The goal of community detection is to detect communities in a network.
For example, in a recurrent neural network as in example
LABEL:ex:neuralNetworks , a community could be a sub-network of neurons
that performs a specific task. If the neurons belonging to such a
functional community are more connected with each other than with
neurons of other communities, then finding these communities is a priori
an inference problem that could be possible to solve.

Some aspects of community detection as well as my contributions to it
will be presented in chapter 2 .

##### 1.4.2 Generalized linear and bilinear models

We will present generalized linear models and generalized bilinear
models in chapter 3 and chapter 4 respectively, but briefly introduce
them here. Figure 1.9 presents a general inference setting.

The table below explains how this general setting particularizes to the
inference problems described in the following paragraphs.

###### Compressed sensing

The compressed sensing (CS) problem is closely related to the problem of
linear measurements of example LABEL:ex:linearMeasurements . The
difference is that the measurement—or sensing —matrix @xmath is taken to
be random and have a compressive measurement rate @xmath . While in the
general case, it is impossible to recover @xmath , in CS, we consider
the case in which the signal @xmath is known to be sparse : only a
fraction @xmath of its components are non-zero. In that case,
information theoretical arguments show that the problem has a unique
solution as soon as @xmath . CS has applications in fields such as
medical imaging, which are motivations for developing ever more
efficient algorithms.

###### Generalized linear models

Generalized linear models (GLM) are a class of problems generalizing the
linear estimation problem. In it, the variable @xmath is unobserved, but
measured through a sensing channel @xmath . The measurements @xmath
therefore contain in general less information about @xmath then they do
in CS. As in CS, one generally considers the setting in which the
measurement matrix @xmath is random. The compressive regime @xmath can
still be studied if the signal is sparse, but depending on the
measurement channel, oversampling regimes @xmath can be necessary to
compensate for the loss of information induced by the sensing channel
and allow good estimates of @xmath .

###### Blind sensor calibration

The blind sensor calibration problem is similar to the one of GLM, with
the difference that the sensing channel depends on a variable @xmath ,
which is unknown and different for each sensor. This variable can for
instance be a threshold, as @xmath is in example LABEL:ex:singleLayer .
The presence of these additional unknowns @xmath makes this inference
problem harder than a GLM, in the sense that in general, more
measurements are necessary for successful inference to be possible. An
alternative to increasing the measurement rate @xmath is to measure a
set of @xmath different unknown signals @xmath .

###### Generalized bilinear models

As blind sensor calibration, the generalized bilinear model (GBM)
setting extends the GLM setting by introducing further variables. The
novelty is that the measurement matrix @xmath itself is unknown. To
compensate for these additional unknowns, the number @xmath of measured
signals generally has to increase with the signal size, i.e. @xmath .
For an AWGN sensing channel, the setting particularizes to the well
studied problems of dictionary learning or matrix factorization,
depending on the hypotheses made on @xmath and @xmath .

###### Illustration

We can illustrate this class of generalized linear and bilinear models
with the following toy example.

### Chapter 2 Community detection

In chapter 1 , I have presented important concepts of statistical
physics, only mentioning that they can be used for solving inference
problems. In the present chapter I show how, by treating one specific
inference problem: community detection.

One motivation of community detection is the analysis of the
subcommunities a social group is divided into and how to detect these
communities [ 145 ] . Initially limited by the difficulty of keeping
track of social interactions in large social groups, community detection
has experienced a revival of interest with the spectacular rise of
online social networks such as facebook and twitter. Thanks to those,
very large datasets are available, such that large-scale studies can be
made, encouraging further and faster algorithms to be developed and
studied.

After a formal presentation of community detection as an inference
problem (sec. 2.1 ) and of two solving approaches (sec. 2.2 ), I will
focus on the mod-bp algorithm, introduced in [ 148 ] by Zhang and Moore,
that treats community detection as a statistical physics problem. As
such, concepts like temperature and energy-entropy competition naturally
appear, as well as phase transitions and glassy phases. With mod-bp, we
will present the belief propagation algorithm, that allows to sample
from high-dimensional probability distributions.

My contribution to the field of community detection is a deeper study of
the mod-bp algorithm, published in [ 131 ] and presented in sec. 2.4
and sec. 2.5 . The main results are the definition of a new set of order
parameters, the existence of multiple phase transitions and a study of
several real networks.

#### 2.1 Setting

The general inference scheme in community detection is presented in Fig.
2.1 .

The setting is very general and applies to a great variety of domains in
which networks appear. Networks can be used as soon as a system of many
interacting subsystems is studied [ 135 ] . For example:

-   Social networks. Nodes of the network are people, edges of the
    network are a certain kind of social interactions.

-   Transportation networks, in which nodes represent cities or
    airports, and edges represent roads or flights.

-   Functional networks, such as networks of neurons or gene regulation
    networks.

-   The internet, in which nodes are web pages, edges are hyperlinks.

-   Citation networks, in which nodes are books or articles and edges
    are citations.

After these examples, let us define the community detection problem in
mathematical terms.

##### 2.1.1 Graphs

An graph \marginnote Graphs is a pair @xmath of a set of @xmath nodes
(or vertices) @xmath and a set of @xmath edges (or links) @xmath . We
will consider only undirected graphs, in which edges are bidirectional:
if nodes @xmath and @xmath are linked, then so are @xmath and @xmath and
they are said to be neighbours. The number of neighbours of a node
@xmath is called the degree of the node, @xmath . A practical way of
representing a graph is with its adjacency matrix @xmath , defined by

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

In community detection, \marginnote Groups we consider networks that are
subdivided (or partitioned ) into @xmath groups. Thus, each node @xmath
has a label @xmath that indicates which of the @xmath groups it belongs
to. Furthermore, the edges are considered to be the result of a
probabilistic edge creation process that depends on the labels of the
nodes. For many types of networks, such as social networks, this edge
creation process depends on many other parameters that are in general
unknown. We call @xmath the fraction of nodes that are in group @xmath .

The simplest assumption \marginnote Assortativity that can be made is
that the edge creation process is assortative , meaning that two nodes
belonging to the same group are more likely to be linked than two nodes
belonging to different groups.

The goal of community detection \marginnote Partitions is to find the
nodes’ hidden labels from the knowledge of the set of edges. An
estimated set of labels @xmath is called a partition . As the
probabilistic edge creation process is in general unknown, Bayes optimal
community detection is impossible in most settings.

The natural measure to compare the true partition @xmath (called ground
truth ) to an estimated partition @xmath is the overlap, defined
in eq. ( 1.2 ). Due to the permutation symmetry between group labels, a
more adapted definition of the overlap in the case of community
detection is [ 35 ] \marginnote Overlap [1.15cm]

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where the maximum is over the set of all permutations @xmath of @xmath .
An overlap equal to @xmath means that the nodes’ labels were correctly
inferred (up to a global renumbering of groups).

##### 2.1.2 Random graphs

Let us introduce three simple models of graphs that are random, in the
sense that the edge creation process is probabilistic. The first two
models are models of random graphs without underlying groups, while the
third is a model of graphs with groups.

###### The Erdős-Renyi model

In an Erdős-Renyi graph [ 46 ] , the edge creation process is the
simplest possible. Each pair of nodes @xmath is taken once, and added to
the set of edges @xmath with a constant probability @xmath . This edge
creation process does not take into account possible groups of the
nodes. It produces graphs with a random number of edges and is
characterized by a Poissonian distribution of degrees.

###### The configurational model

In the configurational model [ 97 ] , edges are created from the set of
nodes @xmath and the list of their degrees, @xmath . The advantage of
this model is that it allows to create random graphs with any desired
degree distribution. This is useful because the Poisson distribution
obtained for Erdős-Renyi graphs is unrealistic, in the sense that real
networks usually do not have Poissonian degree distributions, but rather
power-law, “heavy-tailed” distributions [ 135 ] . As in the Erdős-Renyi
model, the edge creation process is independent of possible node labels.
Therefore, neither of these two models can be used for community
detection. However, they can serve as null models .

###### The stochastic block model

The stochastic block model (SBM) is a simple model in which the edge
creation process is linked to the labels of the nodes [ 60 ] .
Therefore, the structure of the resulting graph can be expected to
contain information about the ground truth partition @xmath , and
inference should be possible.

In the SBM, edges are created by taking each pair of nodes @xmath once,
and adding it to @xmath with a probability that depends only on the
labels @xmath . The SBM is therefore fully characterized by a @xmath
matrix containing the probabilities @xmath of two nodes of respective
groups @xmath and @xmath to create an edge.

In its simplest version, this matrix is taken to have two distinct
elements: one for the diagonal and one for the off-diagonal entries:

  -- -- -- -------
           (2.3)
  -- -- -- -------

In that version, we can define the parameter

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

and the network structure is assortative if @xmath .

Two limiting cases are interesting: for @xmath , only nodes of the same
group can form edges, while for @xmath , the model is equivalent to the
Erdős-Renyi model. In the first case, the strategy for inference of
groups is trivial, as nodes that are linked are known to belong to the
same group. Note, however that while @xmath , perfect recovery is in
general impossible. As @xmath increases, inference gets harder, and is
obviously impossible for @xmath .

In order to generate an instance of the SBM, two other parameters have
to be fixed: the number of groups @xmath and the fractions @xmath of
nodes in each group, taken to be all equal to @xmath in the simplest
version.

The main advantage of the SBM is its simplicity: it only requires to fix
@xmath , @xmath , @xmath and @xmath in its simplest form. Varying these
parameters, one can interpolate between an easy and a hard inference
problem, study the performance of algorithms and compare them. Another
advantage of the SBM is that it can easily be generalized by leaving the
“diagonal” scenario of eq. ( 2.3 ). The simplicity of the model is also
its main drawback. Just like the Erdős-Renyi model, the SBM produces
unrealistic degree distributions, which indicates that the edge creation
processes in real networks do not follow the SBM. Figure 2.2 shows the
adjacency matrices of graphs generated with different parameters of the
SBM.

#### 2.2 Approaches and algorithms

In this section, we describe three of the many different approaches that
exist in community detection.

##### 2.2.1 Spectral algorithms

The first approach is a spectral approach, that is based on the
computation of the eigenvalues and eigenvectors of a matrix. Several
different choices of matrices can be made, reviewed in [ 87 ] , but it
is natural to use the adjacency matrix @xmath of the graph as a part of
it, as it contains the entire structure of the network. Another useful
matrix is the diagonal, @xmath by @xmath matrix @xmath that contains the
degrees of the networks nodes. From these two matrices, we can construct
the graphs Laplacian and normalized Laplacian matrices, defined as
follows:

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

For one of these two matrices, or other related matrices, we then
calculate the eigenvalues @xmath , with @xmath . For a clustering of the
networks into @xmath groups, the @xmath smallest eigenvalues are kept,
as well as their corresponding @xmath eigenvectors @xmath . These
eigenvectors are then clustered with a @xmath -means clustering
algorithm, after which each node can be assigned to a group.

Spectral algorithms remain popular for community detection, but have
several limits. The most important of them is their bad performances
when it comes to clustering sparse networks, i.e. networks for which the
average degree @xmath is much smaller than the number of nodes. This is
often the case in real networks: for instance, each person is befriended
with a small number of people, that is not growing with the world
population.

##### 2.2.2 Bayesian inference

A second method is more principled and overcomes some of the
inconvenients of spectral algorithms. It follows the probabilistic
approach to inference using Bayes’ formula (eq. ( 1.10 )). The present
section presents the results obtained by Decelle et al. in reference [
35 ] .

As mentioned previously, the edge creation process is usually unknown in
real networks. Therefore, the “channel” @xmath is in general unknown,
and Bayes’ formula cannot be used. For this reason, we focus on Bayesian
inference of the SBM. With eq. ( 2.3 ), one can write

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

and thus

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

from which one can write the posterior probability

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

where @xmath is the prior distribution, with @xmath being the fraction
of nodes in group @xmath . As explained in chapter 1 , the problem of
such posterior probability distributions is that they are hard to
calculate. Remember that the denominator @xmath has to be calculated by
marginalization of the numerator, which implies a sum over all possible
partitions @xmath . As there are @xmath of them, the sum is intractable
even for reasonable network sizes. The solution proposed in [ 35 ] is to
use belief propagation to calculate eq. ( 2.8 ). Belief propagation
(BP), presented in more details in sec. 2.3 , is an iterative algorithm
that allows to estimate high-dimensional probability distributions
as eq. ( 2.8 ). Though not giving correct estimates under all
circumstances, it is known for being exact in many cases. In the present
case, BP returns for each node @xmath and group @xmath the estimated
probability

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

that verify @xmath . Using these probabilities, the estimated partition
@xmath is obtained using the MAP estimator defined in eq. ( 1.11 ):

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

The main finding of [ 35 ] is that in Bayes optimal inference of
community detection for the SBM, there are different phases , that are
separated by phase transitions, depending on the value of the parameter
@xmath , just as in physical systems. Taking the vocabulary of the Ising
model (example LABEL:ex:Ising ), there is a ferromagnetic and
paramagnetic phase. Just as the value of the magnetization @xmath
defines theses phases in the Ising model (example LABEL:ex:Ising ), the
overlap @xmath plays the role of an order parameter in community
detection: In the paramagnetic phase, @xmath , while @xmath in the
ferromagnetic phase. In the language of community detection, this means
that below a critical @xmath , the group structure is detectable, while
above @xmath , the group structure is undetectable. Figure 2.3 , taken
from [ 35 ] , shows the phase transition.

###### Non Bayes optimal case

Probabilistic inference starting from eq. ( 2.8 ) can also be made if
the true edge creation process @xmath and the true prior @xmath are not
known. In that case, the inference setting is not Bayes optimal, but can
still lead to good results if the supposed distributions @xmath and
@xmath are close enough to their true counterparts.

One simple way to study such a setting is to generate a graph with the
SBM and a set of parameters @xmath and to perform inference with a
different set of parameters @xmath . Thanks to the simplicity of
expression eq. ( 2.8 ) as a function of these parameters, a step to
optimality can be made by treating the parameters @xmath as variables
that have to be inferred as well. This corresponds to performing
inference starting from the posterior distribution

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

which can be done with BP and an expectation-maximization (EM)
procedure. Note that:

-   @xmath is not included in the set of learnable parameters @xmath .
    This comes from the fact that BP uses the set of @xmath variables
    @xmath . In EM, the values of the parameters to be learnt change
    from iteration to iteration. As @xmath is “hard-coded” in the BP
    equations, it cannot vary as the other parameters. The number of
    groups @xmath is therefore a special parameter. In order to learn it
    with a BP based algorithm, one has to run BP several times with
    different values of @xmath and compare the results: this is a model
    selection procedure.

-   Few additional variables have to be learned (there are @xmath of
    them) compared to the @xmath probabilities @xmath infered by the
    algorithm without parameter learning. This allows EM to be
    successful. If the number of parameters to learn was comparable to
    @xmath , a whole different algorithm would be necessary.

###### Advantages and limit

The findings of [ 35 ] have had an important impact on the theoretical
understanding of community detection. The existence of a phase
transition in the Bayes optimal inference of the SBM has been confirmed
by theoretical results [ 90 , 100 , 102 ] , proving that for the SBM
with @xmath groups, it is impossible for any algorithm to label nodes
better than randomly when @xmath . Unlike spectral methods based on the
network’s Laplacian, the BP based algorithm proposed in [ 35 ] also
works in the interesting regime of sparse networks. Furthermore, this
algorithm has inspired a novel spectral method for community detection,
based on the so-called nonbacktracking matrix, that has the same phase
transition as the BP algorithm and nearly as good performances [ 76 ] .
Other advantages of the method are its speed (unlike spectral methods,
BP does not require to diagonalize matrices) and the fact it can be used
with parameter learning. However, its main limitation is that it is
entirely constructed on a model that is not relevant for most real
networks.

##### 2.2.3 Modularity maximization

The main disadvantage of the Bayesian inference scheme presented above
is that it heavily relies on the SBM. As mentioned already, the SBM is
not a good model for real networks, for which the edge creation process
is in general complex and unknown. For this reason, it is desirable to
design an inference strategy that makes the least possible assumptions
on how the network was created. Another flaw of our presentation of
community detection methods until now is the lack of an indicator that
allows to estimate how good a proposed partition is. In fact, the
overlap can only be used for networks for which the true labels are
known–and therefore do not require community detection. The overlap is
still useful as it allows to test the performances of algorithms on
synthetic or labelled real-world networks. But in interesting cases, the
overlap is not known and we thus have to introduce another indicator of
success.

The modularity is a quantity that measures the goodness of a partition
based on the sole hypothesis that the network has an assortative
structure and on the nodes’ degrees. The modularity is defined in [ 104
] by \marginnote Modularity [1.2cm]

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

The first term simply increases modularity each time two nodes connected
by an edge are assigned to the same group. The sum of the second term
goes over all pairs of nodes @xmath and depends on the nodes’ degrees.
This term can be seen as choosing the configurational model as the null
model for modularity: it makes sure that the modularity of a random
partition stays small. High values of the modularity indicate that there
are more edges between nodes of the same group than between nodes of
different groups: Thus, the higher the modularity, the better the
partition.

With this quantity defined, a logical community detection strategy is
modularity maximization , for which several algorithms have been
proposed [ 103 , 44 , 5 , 23 ] . One obvious handicap of modularity
maximization is that finding the partition with highest modularity is a
discrete combinatorial optimization problem [ 21 ] . This is the
discrete version of the curse of dimensionality presented in section
1.1.3 . Effective heuristics thus have to be developed to perform
modularity maximization. Another drawback of modularity maximization is
that it is prone to overfitting: Even in Erdős-Renyi random graphs,
high-modularity partitions exist and can be found [ 55 , 117 , 78 ] .
This fact greatly weakens the claim that modularity is a good indicator
of successful community detection. Finally, there is a fundamental
resolution limit [ 49 ] that prevents the recovery of small-sized
groups.

###### Insights from statistical physics

In [ 148 ] , Zhang and Moore introduce a community detection algorithm
based on modularity that tackles the two first mentioned issues and
propose a multiresolution strategy to overcome the third. The algorithm,
called mod-bp, is of polynomial complexity with respect to @xmath (and
thus fast), and is shown to not overfit, in the sense that it does not
return high-modularity partitions for Erdős-Renyi graphs. This is
achieved by treating modularity maximization as a statistical physics
problem with an energy

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

Finding the ground state of this system, i.e. its state of minimal
energy, is equivalent to maximizing the modularity of the network. A
further link to physics can be made by noting that the obtained model is
a disordered Potts model . A Potts spin is a spin that can take @xmath
different values. An Ising spin is a particular Potts spin with @xmath .
The Hamiltonian ( 2.13 ) describes @xmath Potts spins interacting
pairwise if they have the same value:

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

This system therefore presents great similarities with the SK model
introduced in example LABEL:ex:SK . The main differences are that Ising
spins are replaced by Potts spins and that the couplings @xmath are not
Gaussian random variables, but depend on the graph. However, as the edge
creation process is probabilistic, the couplings @xmath are random and
therefore the model is disordered, like the SK model.

This similarity encourages us to consider that the phenomenology of both
systems are similar, and in particular to predict the existence of
paramagnetic, ferromagnetic and glassy phases. With this analysis,
modularity maximization corresponds to finding the state of lowest
energy, i.e. the equilibrium state at temperature @xmath . In the SK
phase diagram of example LABEL:ex:SK , it is interesting to see that at
@xmath , the system is always in the spin glass phase . Let us remind
that this glassy phase is characterized by a chaotic energy landscape
with exponentially many local minima spread all over the space of
configurations. This picture perfectly agrees with the fact that
modularity maximization of Erdős-Renyi random graphs succeeds in finding
many high-modularity partitions that are very different from one
another.

This physical insight has led the authors of [ 148 ] to adopt an
alternative strategy to modularity maximization, which is to minimize
the free energy of the system with the Hamiltonian ( 2.14 ) at @xmath .
In the SK phase diagram of example LABEL:ex:SK , we see that at high
enough temperature, the system leaves the glassy phase, that is the
cause of the problems of modularity maximization. The starting point of
the mod-bp algorithm is therefore the Boltzmann distribution over
partitions

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

As eq. ( 2.8 ) in Bayesian inference of the SBM, this high-dimensional
probability distribution can be estimated using BP. The results of
mod-bp will be presented after an introduction to BP in sec. 2.3 .

###### Note:

As shown in [ 148 ] , performing community detection using eq. ( 2.16 )
is equivalent to making Bayesian inference (though not Bayes optimal in
general) of a generative model called degree-corrected SBM [ 71 ] . This
illustrates again the permeability between Bayesian inference and
inference by cost function minimization and should be kept in mind: in
that sense, using eq. ( 2.16 ) is not completely model-free.

#### 2.3 Belief propagation

The belief propagation (BP) algorithm [ 77 , 110 ] was discovered
independently in the fields of physics, coding and artificial
intelligence for different purposes. It allows to estimate (or sample
from) a probability distribution over a high-dimensional space that
takes the form

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

where @xmath and each @xmath represents a constraint involving a subset
@xmath of components of @xmath . The BP algorithm estimates a pdf of
this kind by passing messages @xmath from each variable @xmath to each
of the constraints @xmath it is involved in, and messages @xmath from
each constraint @xmath to each of the variables @xmath .

The distribution ( 2.17 ) is usually visually represented by a so-called
factor graph, composed of two types of nodes:

-   Variable nodes, represented as circles, that stand for individual
    components @xmath

-   Factor nodes, represented as squares, that stand for the constraints
    @xmath .

An edge is present between the variable node @xmath and the factor node
@xmath when @xmath . In this factor graph representation, a pair of
messages @xmath is passed along each edge of the graph, as represented
in Fig. 2.4 .

More detailed introductions to BP and interpretations leading to a
better understanding of it can be found in [ 93 , 144 ] .

##### 2.3.1 BP equations

In the sum-product version of BP, the messages are updated iteratively
following the rule \marginnote BP equations [1.3cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (2.18)
     @xmath   @xmath      (2.19)
  -- -------- -------- -- --------

Note that the messages are probability distribution functions, hence the
@xmath sign that indicates they have to be normalized. The messages are
often initialized at random, the only constraint being that they form a
valid pdf (i.e. they are positive and sum to one). After convergence of
these equations (i.e. when iterating them does not change their value
anymore), the marginal distributions @xmath is estimated by the belief
\marginnote Beliefs [0.9cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (2.20)
  -- -------- -------- -- --------

Said differently, the marginals are fixed points of the BP iterations.
However, the BP equations are only bound to converge to the correct
marginals when the factor graph associated to the distribution is a tree
(by theorem). Else, one speaks of loopy BP , as the factor graph
contains loops. There is no theorem guaranteeing the convergence of
loopy BP, nor that the fixed points of loopy BP are the correct ones. In
many cases though, loopy BP turns out to converge empirically and to
give correct results, encouraging its use on factor graphs that are not
trees.

An important quantity linked to BP is the Bethe free entropy . Given a
set of marginals @xmath , the Bethe free entropy is defined by
\marginnote Bethe free entropy [0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (2.21)
  -- -------- -------- -- --------

where

  -- -------- -------- -- --------
     @xmath   @xmath      (2.22)
     @xmath   @xmath      (2.23)
     @xmath   @xmath      (2.24)
  -- -------- -------- -- --------

Derivating @xmath with respect to the messages @xmath gives back the BP
equations ( 2.19 , 2.18 ) and is one way of deriving them. Therefore,
the BP fixed points are extrema of the Bethe free entropy [ 93 ] .

##### 2.3.2 Mod-bp

Let us now write the BP equations for eq. ( 2.16 ) in order to obtain
the mod-bp algorithm. Note that the calculations to obtain the Bayes
optimal inference algorithm of the SBM are very similar.

First of all, let us rewrite eq. ( 2.16 ) under the generic form
of eq. ( 2.17 ):

  -- -------- -------- -- --------
     @xmath   @xmath      (2.25)
  -- -------- -------- -- --------

We see that the factor nodes of the corresponding factor graph are all
the pairs @xmath . The factor graph is therefore very loopy, and BP is
not guaranteed to converge. As each factor node @xmath has only two
neighbouring variable nodes @xmath and @xmath , we have @xmath .
Furthermore, as the labels @xmath are discrete variables, the integral
in ( 2.19 ) becomes a sum:

  -- -------- -------- -- --------
     @xmath   @xmath      (2.26)
     @xmath   @xmath      (2.27)
  -- -------- -------- -- --------

and we introduce the simplifying notation

  -- -------- -------- -- --------
     @xmath   @xmath      (2.28)
  -- -------- -------- -- --------

Furthermore, as each factor node has only two neighbours, we can rewrite
the BP equations ( 2.26 , 2.27 ) in one equation of a single type of
messages, @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (2.29)
  -- -------- -------- -- --------

which is the BP equation for mod-bp. The messages are initialized at
random with the condition that they are positive and that for each pair
@xmath , @xmath . After convergence of the algorithm, the beliefs can be
obtained by

  -- -------- -------- -- --------
     @xmath   @xmath      (2.30)
  -- -------- -------- -- --------

Note that the normalization constants @xmath and @xmath are nothing but
the sums over @xmath of the non-normalized versions of @xmath and @xmath
.

Just as in Bayesian inference of the SBM, the estimated label of @xmath
is obtained by the MAP estimate

  -- -------- -------- -- --------
     @xmath   @xmath      (2.31)
  -- -------- -------- -- --------

from which one can calculate the retrieval modularity

  -- -------- -------- -- --------
     @xmath   @xmath      (2.32)
  -- -------- -------- -- --------

As in the Bayesian SBM inference, the authors of [ 148 ] detect the
existence of two phases: a paramagnetic and a recovery phase.
Additionally, they detect the existence of a spin glass phase. In [ 131
] , I reveal the existence of further phases, as explained in the rest
of the chapter.

#### 2.4 Algorithmic phase transitions

As in numerous statistical physics problems, the study of eq. ( 2.25 )
leads to phase transitions at some given temperatures. As previously
noted, using the modularity as an energy function is similar to studying
a Potts model in statistical mechanics [ 62 ] , for which [ 119 ] has
shown that a phase transition is always present.

##### 2.4.1 Paramagnetic, recovery and spin glass phase

Zhang and Moore report the existence of three temperature ranges, in
which the algorithm has a different qualitative behaviour.

-   At very low temperatures, the system is in a spin glass phase. In
    that phase, the problem is similar to modularity maximization: a
    chaotic energy landscape results in exponentially many local energy
    minima spread all over the space of partitions. In such a spin glass
    phase, BP does not converge to a fixed point.

-   At high temperature, the system is in a paramagnetic phase in which
    the BP fixed point is the so-called factorized or trivial fixed
    point: @xmath .

-   In networks with communities, there can be an intermediate range of
    temperatures (the recovery phase), in which the algorithm converges
    to a nontrivial fixed point, from which group assignments can be
    obtained using eq. ( 2.31 ).

##### 2.4.2 Model-based critical temperatures

Modularity as a measure of goodness of a partition is appealing for
real-world networks because it makes only the assumption of
assortativity about the underlying edge creation process. The drawback
of this absence of model is that as a result, it is not clear how to
choose the temperature @xmath at which to actually run mod-bp. Zhang and
Moore analyze two generative models allowing to find useful
characteristic temperatures.

-   For the configurational model, Zhang and Moore show that the phase
    transition between the spin-glass phase and the paramagnetic phase
    takes place at

      -- -------- -------- -- --------
         @xmath   @xmath      (2.33)
      -- -------- -------- -- --------

    where @xmath is the average excess degree , calculated from the
    average degree @xmath and the average square degree @xmath , given
    by

      -- -------- -- --------
         @xmath      (2.34)
      -- -------- -- --------

-   In the SBM with @xmath groups and @xmath , Zhang and Moore show that
    mod-bp is as successful as the Bayes-optimal algorithm, and that the
    phase transition between the paramagnetic and the recovery phase
    takes place at

      -- -------- -------- -- --------
         @xmath   @xmath      (2.35)
      -- -------- -------- -- --------

The recommendation of Zhang and Moore is to run mod-bp at @xmath , which
seems to always lie inside the recovery phase. On the other hand, @xmath
cannot really be used, as it would require fitting the network to a
stochastic block model and finding the parameters @xmath and @xmath . As
the SBM is a bad model for real networks, this is not a good strategy.
However, ( 2.35 ) provides a useful upper bound for @xmath :

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

which is the @xmath limit of eq. ( 2.35 ). Indeed, above this
temperature, even for SBM networks with disconnected components, mod-bp
will converge to the paramagnetic solution, and is therefore useless.

##### 2.4.3 Degenerate groups

The rest of this chapter describes my contributions to the understanding
of mod-bp, as published in [ 131 ] .

In the paramagnetic phase, we said earlier that at the BP fixed point,
@xmath . In practice, due to the numerical precision of the computer or
incomplete convergence of the algorithm, there are small fluctuations
around @xmath . Due to these fluctuations, calculating a retrieval
partition using eq. ( 2.31 ) is in general still possible and would lead
to random labels and thus a probably small, but non vanishing retrieval
modularity @xmath .

However, if the marginals were all strictly equal to @xmath , then
@xmath would be impossible to determine. And in fact, the meaning of the
paramagnetic phase is that all groups are strictly equivalent, or
degenerate , which is to say that all nodes are in the same group and
@xmath should therefore be exactly zero. In order to obtain this, the
algorithm has to check for degenerate groups before assigning a group to
each node and assign the same “effective” group to nodes for which the
maximization eq. ( 2.31 ) leads to different but degenerate groups.

This can be done by introducing a distance @xmath between two groups
@xmath and @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (2.37)
  -- -------- -------- -- --------

If @xmath is smaller than a chosen threshold @xmath , then we can
consider that the groups @xmath and @xmath are degenerate and that they
should not be distinguished. It generalizes the concept of degeneracy of
all groups in the paramagnetic phase to any pair of groups.

An effective (or estimated ) \marginnote Effective groups @xmath number
of groups @xmath can then be defined as the number of distinguishable
groups. We can define a mapping @xmath between the @xmath groups used by
the algorithm and the @xmath effective groups: For each group @xmath ,
@xmath is an integer between @xmath and @xmath representing one of the
effective groups, and

  -- -------- -- --------
     @xmath      (2.38)
  -- -------- -- --------

With this mapping, we replace the group assignment procedure eq. ( 2.31
) by

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

With this assignment procedure, @xmath is strictly zero in the
paramagnetic phase. Figure 2.5 shows that choosing a threshold @xmath is
meaningful because @xmath undergoes a phase transition at which it
sharply drops by several orders of magnitude. The main finding is that
group degeneracy is observed not only in the paramagnetic phase, but
also inside the retrieval phase, in which case only a subset of groups
are degenerate. Figure 2.5 shows this for the popular network “political
books” [ 1 ] , on which mod-bp was run at different temperatures.

#### 2.5 Coexistence of phases

Thanks to the correct group assignment procedure in eq. ( 2.39 ), one
realizes that up to @xmath phases can exist for any network for which
mod-bp is run with @xmath groups: One for each @xmath plus a spin-glass
phase. Figure 2.6 shows this for the network “political books”.

In this network, several phases coexist at lower temperature, whereas
for higher temperatures, the phases exist in well-separated temperature
intervals. In the latter case, we can define “critical” temperatures
@xmath , separating a phase with @xmath from one with @xmath . As can be
seen on Fig. 2.7 , the number of iterations needed for mod-bp to
converge greatly increases around these critical temperatures. As noted
previously, @xmath is a good reference temperature, and normalizing all
temperatures by @xmath is a good way of introducing a unified
temperature scale that allows to compare critical temperatures of
different networks and at different values of @xmath .

##### 2.5.1 Location of critical temperatures

In some cases, a subset of @xmath critical temperatures can be
degenerate, in which case there is a phase transition betweel a phase
with @xmath and a phase with @xmath . This is for instance the case for
networks generated by the SBM with eq. ( 2.3 ). The picture (Fig. 2.7(a)
) then agrees with the description of three phases given in [ 148 ] .

In contrast, the SBM can be modified such that @xmath if @xmath . The
degeneracy of @xmath ’s is then lifted (Fig. 2.7(b) ). This figure also
shows that, starting above @xmath and lowering the temperature, the
groups are inferred in order of their strength. To show this, we use the
recall score , which allows us to see if one of the inferred groups
corresponds well to a given real group. To quantify the similarity
between a real group @xmath and an inferred group @xmath that are not
necessarily of the same size, we can use the Jaccard score (used in [ 61
] for instance), defined by

  -- -------- -- --------
     @xmath      (2.40)
  -- -------- -- --------

The recall score is the maximum of the Jaccard score:

  -- -------- -------- -- --------
     @xmath   @xmath      (2.41)
  -- -------- -------- -- --------

A recall score close to @xmath means that one of the inferred groups
@xmath is almost identical to group @xmath . Figure 2.7(b) therefore
shows that around @xmath , the group with the biggest in-connectivity is
nearly exactly returned by the algorithm, whereas the two groups with
lower in-connectivity are not. Only by further lowering the temperature
does @xmath reach @xmath , and all groups are correctly (though not
perfectly) inferred.

##### 2.5.2 Running mod-bp with @xmath

In networks generated with the SBM, the real number of groups @xmath is
known and it is thus interesting to look at what happens when mod-bp is
run with @xmath . The behaviour for @xmath is described in [ 148 ]
and Fig. 2.7(a) . If @xmath then mod-bp cannot return @xmath and will
merge some of the groups together to obtain @xmath groups. The more
interesting case is when @xmath is bigger than @xmath .

First of all, it must be noted that as @xmath increases, the range of
(normalized) temperatures of the spin-glass phase grows. If @xmath is
only slightly above the detectability threshold @xmath [ 35 , 101 ] ,
then increasing @xmath can lead to a situation in which there is no
recovery phase between the spin-glass phase and the paramagnetic phase.

However, we will focus on the case when @xmath is small enough for
intermediate phases to be present. As described previously, the phase
transitions are degenerate if @xmath is the same for all groups.
Therefore, we generally observe only one intermediate phase, with @xmath
. However, this is not always the case and mod-bp can return partitions
with different values of @xmath , depending on the initialization,
similarly to what is observed in real networks in Fig. 2.7 . For the
SBM, two phenomena can often be observed, separately or simultaneously.

1.  The first phenomenon is to have @xmath , with @xmath groups
    corresponding very well to real groups and a last group containing a
    very small fraction of nodes. Depending on the initialization, this
    last group can even contain no node at all, in which case it can
    simply be discarded. This phenomenon is likely to come from the
    stochasticity of the SBM and is also present for large networks with
    @xmath nodes. The modularity of such partitions with an additional
    group is usually equal or slightly higher than those found in the
    @xmath phase of mod-bp run with @xmath , which explains why they are
    found. On the other hand, I never observed more than one of these
    additional, almost empty groups, such that @xmath is always at most
    equal to @xmath .

2.  The second phenomenon is that of distinct groups merging together in
    the retrieval partition, leading to @xmath . Such partitions have
    lower modularities than partitions with @xmath (found for different
    initializations), showing that the algorithm is not able to
    correctly maximize the modularity starting from any initialization.
    This is likely due to the existence of “hard but detectable” phases
    [ 35 ] , in which frozen variables cause algorithms to be stuck in
    suboptimal solutions. A simple way out of this problem is to run the
    algorithm several times with different initial conditions and to
    select the configuration with the highest modularity.

These two effects might coexist and produce retrieval partitions in
which two of the groups are merged into a single one, but an additional,
almost empty group is present. In this case @xmath , but the retrieval
partition is incorrect. The existence of both of these phenomena should
be considered as a warning on the reliability of mod-bp for inference of
the SBM.

##### 2.5.3 Results on real networks

For community detection on real networks, @xmath is in general unknown
and there is no available ground truth. From Fig. 2.6(b) and the
previous section, we know that mod-bp can converge to partitions with
different @xmath at the same temperature, depending on the
initialization. This motivates us to run mod-bp several times at each
temperature, which allows us to quantify the probability that a given
@xmath is found for a given temperature @xmath . Fig 2.9 shows the
coexistence of phases in the “political books” [ 1 ] and “political
blogs” [ 2 ] datasets for different values of @xmath . The analysis made
in these figures is similar to the one proposed in [ 120 ] for
multiresolution community detection.

These figures suggest that, at a given normalized temperature @xmath ,
the results returned by mod-bp only marginally depend on the chosen
@xmath as long as @xmath . Moreover, we observe that within a phase with
a given number @xmath of groups found, the partition @xmath only
marginally depends on the temperature @xmath . Averaging over the
several partitions found at different temperatures and with different
initial conditions, we show in Fig. 2.10 that @xmath depends essentially
on @xmath and only minimally on @xmath . As in [ 148 ] , we consider
that the largest @xmath leading to a significant increase of @xmath with
respect to @xmath is a plausible estimate of @xmath , which agrees well
with the commonly accepted ground truths of @xmath for “political books”
and @xmath for “political blogs”.

To validate our results on a hierarchical network, we ran mod-bp on the
“air transportation network”, which is a network of cities in which an
edge is present between each pair of cities connected by direct flights
[ 54 , 126 ] . A coarse-grained clustering results in a few communities
of cities that are well connected to each other. Each of these
communities corresponds to geographical and geopolitical units that are
clearly recognizable, which can be further subdivided in
sub-communities. For example, the U.S and Mexico are two sub-communities
of the “North America” cluster. We ran mod-bp with @xmath for
temperatures from @xmath to @xmath and present the results in Fig. 2.11
. As expected, the number of found communities increases with decreasing
@xmath , thus revealing substructures with increasing geographical
precision. Based on the modularity and the temperature range of the
phases, @xmath seems to be a meaningful number of communities. Further
decreasing the temperature splits the communities into smaller ones, and
individual countries appear as single or even several communities.

##### 2.5.4 Discussion

In addition to not requiring the knowledge of the generative model, a
futher advantage of mod-bp is that it has only two adjustable
parameters, @xmath and @xmath . However, for a given network, it is not
clear how to choose them in order to obtain the optimal partition. The
recommendation of Zhang and Moore is to run mod-bp at @xmath , defined
in Eq. ( 2.33 ), for increasing values of @xmath , until it does not
lead to any further significant increase in modularity. Based on the
experiments on synthetic and real networks presented in [ 131 ] , we
conclude that an important additional step in this procedure is to
calculate the effective number of groups @xmath of each partition
returned by the algorithm, which can be different from @xmath .
Furthermore, this phenomenon leads to a new rule for assigning a group
to each node, given that some groups might be merged, which also affects
the modularity.

Another possible way to proceed is to run mod-bp with a large value of
@xmath , and sweep the temperature scale from @xmath downwards. As
@xmath is lowered, the network is clustered into an increasing number of
effective groups @xmath , and the found partitions have increasing
modularities. Again, the procedure can be stopped once the modularity
does not increase anymore in a significant way as @xmath is increased.

For real networks, in which the generating process is in general not
known and not as straightforward as in the SBM, the number of groups is
in part let as a choice to the user. In this case, running mod-bp with a
quite large value of @xmath and using @xmath as the parameter to search
for the optimal partition seem both desirable and efficient. To make the
optimal choice, in addition to the value of the modularity of a
partition with @xmath groups, the range of temperatures where this
@xmath phase exists might indicate how relevant it is (as shown in Fig.
2.9 ). In particular, if a @xmath phase only exists on a narrow range of
temperatures, then it is likely to be less important, because less
stable with respect to changes in the model parameter ( @xmath in the
present case).

Furthermore, as seen on graphs generated by the SBM, it may occur that
some group contains a very small number of nodes. In this case, merging
them with bigger groups will only slightly change the modularity and
result into a more meaningful and stable partition.

#### 2.6 Conclusion

This chapter treats the problem of community detection as a statistical
physics problem. Introducing a temperature, different phases are
observed, that correspond to the ferromagnetic, paramagnetic and spin
glass phases of a disordered physical system. Understanding the
characteristics of these phases is important in order to understand the
phenomenology and the difficulty of community detection. My contribution
to the understanding of community detection is published in [ 131 ] and
shows that the ferromagnetic phase is in fact subdivided into different
phases. This is important to be aware of while performing
modularity-based community detection and suggests a new multiresolution
clustering strategy that was tested on the “air transportation network”.

## Part II Linear and bilinear inference problems \@openrightfalse

### Notations

From now on, I will use the following conventions.

###### Acronyms and abbreviations

  --------- -------------------------------------------------------------
  AMP       Approximate message passing
  AWGN      Additive white Gaussian noise
  BiGAMP    Bilinear generalized approximate message passing
  BP        Belief propagation
  Cal-AMP   Calibration approximate message passing
  CS        Compressed sensing
  DL        Dictionary learning
  DMD       Digital micromirror device
  e.g.      “for example”
  i.i.d.    independent and identically distributed
  i.e.      “that is“
  GLM       Generalized linear model
  GAMP      Generalized approximate message passing
  GBM       Generalized bilinear model
  LASSO     Least absolute shrinkage and selection operator
  MCS       Matrix compressed sensing
  MRI       Magnetic resonance imaging
  @xmath    Mean squared error
  @xmath    Normalized mean squared error
  PBiGAMP   Parametric bilinear generalized approximate message passing
  pdf       Probability distribution function
  PR-GAMP   Phase retrieval GAMP
  RIP       Restricted isometry property
  SP        Saddle point
  TAP       Thouless Anderson Palmer
  --------- -------------------------------------------------------------

###### Ensembles

  -------- -----------------------------------------------------------------------------
  @xmath   set of complex numbers.
  @xmath   @xmath .
  @xmath   set of natural numbers.
  @xmath   set of real numbers.
  @xmath   @xmath
  @xmath   set of symmetric, positive-definite @xmath matrices with real coefficients.
  -------- -----------------------------------------------------------------------------

###### Operators

  -------- ---------------------------------------------------------
  @xmath   complex conjugate of @xmath .
  @xmath   (complex) transpose of @xmath .
  @xmath   elementwise product of @xmath and @xmath .
  @xmath   unless stated otherwise, elementwise square of @xmath .
  @xmath   inverse of @xmath .
  @xmath   elementwise inverse of @xmath .
  -------- ---------------------------------------------------------

###### Variables

  -------- --------------------------------------
  @xmath   scalar.
  @xmath   vector or matrix.
  @xmath   vector or matrix of only ones.
  @xmath   identity matrix.
  @xmath   vector of unusual size.
  @xmath   mean/estimate of @xmath .
  @xmath   mean/estimate of @xmath .
  @xmath   variance/uncertainty of @xmath .
  @xmath   variance/uncertainty of @xmath .
  @xmath   @xmath -th component of @xmath .
  @xmath   vector or matrix indexed by @xmath .
  -------- --------------------------------------

###### Functions

  -- -------- -------- -------- --
     @xmath   @xmath            
     @xmath                     
     @xmath   @xmath            
     @xmath   @xmath            
              @xmath            
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

###### Norms

  -- -------- -------- -- --
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath               
  -- -------- -------- -- --

###### Other

  -- -------- -------- -- --
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
  -- -------- -------- -- --

\@openrighttrue

### Chapter 3 Compressed sensing and generalizations

In chapter 2 I have shown, on the example of community detection, how
tools and concepts from statistical physics could help in solving and
understanding inference problems. The mod-bp algorithm, using belief
propagation, undergoes a set of algorithmic phase transitions just as a
physical system does.

This chapter introduces another broad class of inference problems called
“generalized linear models”, that can also be solved using BP and for
which different phases exist as well. This class of problems—along with
their bilinear generalization (chapter 4 )—were the main focus of my
work. In the context of compressed sensing, I introduce notations that
are useful in all the inference problems I have studied. I also show how
to use the replica method to perform a theoretical analysis of an
inference problem. Finally, I show experimental and theoretical results
for compressed sensing and quantized sensing.

My main contributions in the field of compressed sensing and generalized
linear models are presented in chapter 5 .

#### 3.1 Compressed sensing

The idea behind compressed sensing (CS) is the following: Much of the
digital data we acquire (pictures or music for example) can be reduced
to a fraction of their initial size using compression algorithms. The
fact that compression is (nearly) lossless reveals that the uncompressed
data contain no more information than their compressed version. In other
words, the initial acquisition scheme of the picture is suboptimal, in
the sense that much more data is acquired than what is necessary to
store the picture in a compressed format. The idea of CS is to change
the acquisition process of signals, in order to acquire them in a
“compressed” format in the first place.

##### 3.1.1 Setting

###### The signal

The fundamental concept in CS is sparsity . The definition of a @xmath
-sparse signal (with @xmath ) is

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (3.1)
  -- -------- -------- -- -------

We call sparsity rate @xmath the ratio \marginnote Sparsity rate [1cm]

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

A signal @xmath can be compressed without loss if there is a basis of
@xmath in which the signal is sparse.

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

###### The matrix

The setting of noiseless CS is illustrated by Fig. 3.1 : linear
measurements of a sparse signal are made with a measurement matrix
@xmath . The ratio of @xmath and @xmath is called the measurement rate :
\marginnote Measurement rate [0.8cm]

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

The goal of CS is to recover the signal @xmath from the linear
measurements

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

in the regime where @xmath . CS is therefore the linear estimation
problem of example LABEL:ex:linearMeasurements with the only difference
that @xmath is sparse. This sparsity assumption is, however, a very
strong one, and therefore perfect recovery of @xmath can become possible
despite having @xmath .

Note that not all matrices are suitable for compressed sensing. Many of
the original papers focused on rigorous mathematical statements about
the necessary properties of CS matrices. A good review of them can be
found in the book [ 45 ] . Let us simply give an example to provide an
intuition. Consider for instance a signal that is sparse in the
canonical basis. If the rows of @xmath are vectors of the canonical
basis (and all different), each measurement component @xmath is one
random component of @xmath . In order to be sure to reconstruct the
signal correctly no matter which of its components are zeros, the only
solution is to measure all components, as each measurement carries
information about one single signal component. Such a measurement matrix
would therefore be completely unadapted to CS, as it would require
@xmath . On the contrary, a good measurement matrix carries information
about all of the signals components in each of the measurements.

Random matrices with independent identically distributed (i.i.d.)
entries are commonly used in CS, as they satisfy the right conditions
with high probability. (In fact, nearly all matrices are suitable
matrices for CS [ 39 ] ). Most of the time, we will therefore consider
measurement matrices that are random matrices with i.i.d. entries.

###### Canonical setting

Although CS can be applied to any compressible signal, we will
exclusively deal with signals that are sparse in the canonical base.
This simplifies the treatment of the problem, but note that one can
always go to this setting: If @xmath is compressible in the base @xmath
, then @xmath is equivalent to @xmath with @xmath and @xmath sparse in
the canonical base.

##### 3.1.2 Geometric interpretation

In order to see how sparse signals can be recovered from an
underdetermined linear system, one can rely on the geometric
interpretation sketched in Fig. 3.2 . The key point is that the ensemble
of signals compatible with the measurements @xmath is a subspace of
dimension @xmath . If @xmath is known to be @xmath -sparse, a sufficient
condition for exact inference of @xmath to be possible is that this
subspace contains only one @xmath -sparse element.

##### 3.1.3 Solving strategies

###### Oracle solver

An oracle CS solver is a solver that knows which components of @xmath
are non-zero. Dropping the zero components of @xmath , the linear system
can be rewritten

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

with @xmath and @xmath . It is then obvious that @xmath and thus @xmath
can uniquely be recovered as soon as @xmath is invertible.

###### Combinatorial optimization

If the positions of the signal’s zeros are unknown, a naive solving
strategy would be to try out all the possible combinations of zero
components and solve the corresponding reduced system ( 3.6 ). Because
of the curse of dimensionality, this strategy becomes very rapidly
unfeasable: for @xmath and @xmath , there are @xmath combinations to
test.

This combinatorial optimization problem can be replaced by the following
minimization problem:

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

Under this form, no assumption is made on the exact sparsity of @xmath .
However, finding the sparsest possible @xmath verifying @xmath is the
right strategy, as illustrated in Fig. 3.1(b) . The problem with eq. (
3.7 ) is that the cost function is hard to minimize, as the @xmath
“norm” (which is not a norm properly speaking) is not a convex function.

###### Lasso

A natural way to deal with eq. ( 3.7 ) is to use a convex relaxation of
the cost function. The @xmath “norm” can be replaced by the @xmath norm,
which is convex. The condition @xmath can be enforced by a Lagrange
multiplier, which also allows to consider the case of noisy CS,

  -- -------- -------- -- -------
     @xmath   @xmath      (3.8)
  -- -------- -------- -- -------

This leads to the basis pursuit or LASSO (least absolute shrinkage and
selection operator) problem [ 138 ] : \marginnote LASSO [0.9cm]

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

in which the (inverse) Lagrange multiplier @xmath can be adapted to the
noise variance. In principle, there is no guarantee that the problems (
3.7 ) and ( 3.9 ) are equivalent. The pioneering paper of CS [ 26 ]
proves that under some conditions, they actually are in the limit @xmath
. This discovery has triggered a huge interest in CS, as it revealed
that the combinatorial problem ( 3.7 ), that was considered hopelessly
untractable, could be solved by the simple convex minimization problem (
3.9 ).

A sufficient condition for LASSO being equivalent to eq. ( 3.7 ) is that
@xmath verifies the so-called restricted isometry property (RIP) [ 27 ]
.

##### 3.1.4 A CS solver: Iterative thresholding

Here we present a class of simple CS solvers called iterative
thresholding algorithms [ 19 , 34 ] . Successive estimates @xmath of
@xmath are produced with the iterative rule \marginnote Iterative
thresholding [0.55cm]

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

in which @xmath is a step size and @xmath is a nonlinear thresholding
function that acts elementwise on its input. Though usually written in
this compact form, I present it in an expanded and annotated form
in algorithm 1 .

Main loop: while @xmath , calculate following quantities:

  -- -------- -------- -- --
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
  -- -------- -------- -- --

Algorithm 1 Iterative thresholding

The two parameters that can be chosen in this algorithm are the step
size @xmath of the gradient descent step and the thresholding function
@xmath . A natural choice for the latter is the hard thresholding
function [ 19 ] : \marginnote Hard thresholding [0.7cm]

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

This thresholding function makes sure that the estimate @xmath has
always the right sparsity, by assuming that the smallest components of
the estimate @xmath should be zeros. Note that this choice of
thresholding function also assumes that the exact sparsity @xmath of the
signal is known, which is not the case in general.

Another choice of thresholding function is the soft thresholding
function , defined by \marginnote Soft thresholding [1cm]

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

With @xmath , the resulting iterative soft thresholding algorithm can be
shown to correctly solve the LASSO problem ( 3.9 ) in certain regimes,
and can be made faster by good choices of step sizes @xmath , varying
across iterations [ 14 ] .

In the rest of this thesis, I will focus on probabilistic inference
rather than minimization problems such as LASSO. However, the basic
structure of all algorithms presented in the rest is the same as the
structure of algorithm 1 : iterative estimates of the different basic
variables of the problem, obtained by linear combinations of previous
estimators or by applying nonlinear thresholding functions to them.

#### 3.2 Generalized linear models

The noiseless CS problem presented in the previous section is a special
case of the broader class of generalized linear models (GLM), whose
general setting is illustrated by Fig. 3.3

##### 3.2.1 General setting

In the most general setting, an unknown signal @xmath is multiplied by a
known matrix @xmath in a mixing step, producing an intermediary variable
@xmath . In the subsequent sensing step, a sensing channel leads to the
measurements @xmath . The sensing channel always acts componentwise on
@xmath : components of @xmath are never mixed in the sensing step. In
other words, the distribution @xmath is separable:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.13)
  -- -------- -------- -- --------

##### 3.2.2 Additional conditions

We consider a simplified setting with further conditions on the signal,
the matrix and the sensing channel.

###### The signal

As we will follow a probabilistic approach to inference for GLMs, we
describe the signal by a prior distribution @xmath . Unless stated
otherwise, @xmath has a variance of order @xmath , such that typical
components of @xmath have a magnitude of order one, and is separable,
i.e.

  -- -------- -------- -- --------
     @xmath   @xmath      (3.14)
  -- -------- -------- -- --------

Note that the components are chosen to be i.i.d. but that the
generalization to the case in which they are only independent is easy.
However, independence of the components is an important assumption which
is less straightforward to relax.

###### The matrix

As in CS, we will usually consider random measurement matrices with
components that are i.i.d. as matrices sampled this way satisfy the RIP
with high probability. Unless stated otherwise, we consider that the
matrix is drawn from a distribution

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

and that it is exactly known. Note that the variance of @xmath ensures
that @xmath has a magnitude of order @xmath .

###### The sensing channel

We will focus on the case in which the channel is the same for every
measurement:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.16)
  -- -------- -------- -- --------

As for the signal distribution, this condition can be easily relaxed to
the more general case of eq. ( 3.13 ).

##### 3.2.3 Gamp

In [ 41 ] , the authors proposed an inference algorithm for noisy
compressed sensing based on belief propagation and named approximate
message passing (AMP). This algorithm was generalized in [ 113 ] to GLMs
and called generalized approximate message passing (GAMP). A very
similar algorithm was previously proposed in [ 66 , 65 ] along with a
theoretical analysis, but had not drawn attention at the time. Being a
probabilistic inference algorithm, GAMP’s starting point is the
posterior probability distribution obtained from Bayes’ formula:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.20)
  -- -------- -------- -- --------

As GAMP treats real, continuous signals, it uses the MMSE
estimator eq. ( 1.12 ). The probability distribution ( 3.20 ) is
high-dimensional and GAMP estimates it using belief propagation.

###### From BP to TAP

GAMP is presented in algorithm 2 : Its full derivation can be found in [
113 ] and in sec. 5.1.1 (in a slightly more general setting). It is
obtained in three steps:

1.  First, the BP equations corresponding to eq. ( 3.20 ) are written.
    In the case of mod-bp for community detection (chapter 2 ), @xmath
    was a discrete variable with @xmath values, and therefore a finite
    set of messages was introduced. In the present case, the messages
    @xmath are distributions of continuous variables. Under this form,
    the BP equations are untractable.

2.  In the @xmath limit, the messages @xmath can be expressed as
    functions of Gaussians, parametrized by one mean and one variance
    per message. These means and variances are the messages passed and
    updated in approximate message passing. Means can be seen as
    estimators and are noted with hats ( @xmath ), whereas variances can
    be seen as uncertainties and are noted with bars ( @xmath ).
    Upper-case and lower-case quantities are estimators/variances of the
    same variable: as in algorithm 1 , lower-case estimators take into
    account the previous upper-case estimators and the additional
    knowledge coming from the prior (for @xmath ) or the measurements
    (for @xmath ). The term “approximate” in AMP comes from the fact
    that this parametrization of the messages with Gaussians is exact
    only in the @xmath limit. However, this parametrization relies on
    the central limit theorem, which is approximately verified even for
    finite values of @xmath . Under this form, AMP can be implemented by
    iteratively updating @xmath variables.

3.  The complexity of the algorithm can be greatly reduced using the TAP
    approximation, first introduced by Thouless, Anderson and Palmer in
    the context of spin glasses [ 137 ] . It allows to only update local
    beliefs instead of messages and relies on the fact that the factor
    graph is fully connected. As a result, the number of variables to
    update at each iteration is @xmath instead of @xmath , allowing a
    great simplification of the algorithm as well as a speedup. In
    particular, it allows the use of fast transforms as in [ 10 ] .

These three steps are illustrated in table 3.1 .

###### The GAMP algorithm

The final GAMP algorithm is the TAP version and is presented
in algorithm 2 . As we did for algorithm 1 , we expand the algorithm,
that could be written in a more compact form, for better legibility.
Note its similarity to algorithm 1 : it relies on estimates of the same
quantities as iterative thresholding does. The difference is the way
these estimates are produced and the fact that along with the estimators
of each quantity, a corresponding uncertainty is calculated. One of
these uncertainties is used as the step size in the gradient descent
step.

Initialize @xmath and @xmath at random or according to @xmath .
Main loop: while @xmath , calculate following quantities:

  -- -------- -------- -- --
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
  -- -------- -------- -- --

Stop when @xmath , @xmath or @xmath .

Algorithm 2 GAMP

###### Intialization

The quantities @xmath need to be initialized. @xmath can be fixed to
@xmath , @xmath can be drawn at random from @xmath , @xmath can be fixed
to the variance of @xmath . Other initialization schemes are possible.

###### Update functions

The update functions @xmath and @xmath that appear in GAMP are (in
general) nonlinear functions of their arguments and act on them
componentwise.

@xmath and @xmath are the mean and variance of the pdf @xmath (as @xmath
is a variance it is positive). They can therefore be written as

  -- -------- -------- -- --------
     @xmath   @xmath      (3.21)
     @xmath   @xmath      (3.22)
  -- -------- -------- -- --------

where we define, for all @xmath ,

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

Similarily, we can define @xmath and @xmath as being the mean and
variance of the pdf @xmath and

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

These functions are used to calculate new estimators and variances of
@xmath ,

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (3.25)
  -- -------- -------- -------- -------- -- --------

that are used to calculate the auxiliary “gradient” terms

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (3.26)
  -- -------- -------- -------- -------- -- --------

In words, @xmath and @xmath are estimates of @xmath and @xmath obtained
only from previous estimates. @xmath is an estimate of @xmath based on
@xmath but taking into account the prior @xmath , and @xmath is an
estimate of @xmath based on @xmath but taking into account the
measurement @xmath .

As these functions are means and variances of distributions, there is no
general analytical formula for them, and evaluating them requires
numerical integration ( 3.23 , 3.24 ). However, as they are integrals
over a single variable, these integrals can often reliably be performed
numerically, or in the best case be expressed as known functions.
Furthermore, note that in algorithm 2 , only matrix multiplications or
elementwise operation are present. Last, note that @xmath can in
principle be negative, because @xmath can have positive or negative
elements. Looking at eq. ( 3.26 ), a sufficient condition for @xmath to
be positive is that @xmath . This condition is not respected for all
sensing channels, which can lead to problematic negative “variances”
@xmath that have to be handled carefully.

###### Stopping conditions

Different stopping conditions can be implemented. Additionally to
setting a maximum number of iterations, GAMP can be stopped if @xmath
becomes smaller than a given threshold @xmath , at which the algorithm
can be considered to have converged. Another indicator of convergence is
@xmath : when then algorithm converges to the right solution, the
elements of @xmath , which are uncertainties, become smaller and
smaller.

#### 3.3 Replica analysis

The GLM setting can be analyzed with statistical physics methods in the
thermodynamic limit, i.e. when the dimensions of the signal @xmath and
of the measurements @xmath go to infinity, while the measurement ratio
@xmath remains fixed. This analysis can be done with the replica method,
which allows to calculate the free entropy linked to the pdf ( 3.20 ).
In this section, we perform the replica analysis that results in a
simple set of state evolution equations. The analysis is very similar to
the one of related inference problems [ 105 , 124 , 123 ] . For the GLM
setting, the analysis was performed in [ 66 ] in a slightly more general
setting, but only up to the general formula for the free entropy. The
full analysis can be found in [ 73 ] for the special case of noisy CS,
and in [ 143 ] for the special case of @xmath -bit CS. For a
comprehensive introduction to the replica method, we refer the reader to
[ 29 , 105 , 93 ] .

##### 3.3.1 Replica analysis: free entropy

Treating an inference problem as a statistical physics problem consists
in writing an energy function corresponding to the problem and studying
the partition function of the system. Here, the relevant partition
function is the normalization constant of the probability distribution (
3.20 ):

  -- -------- -- --------
     @xmath      (3.34)
  -- -------- -- --------

from which the free entropy @xmath can be calculated. Equation ( 3.34 )
is the partition function of a disordered system, as introduced in sec.
1.2.2 . In order to determine the average properties of such a
disordered system, one needs to average @xmath over all possible
realizations of @xmath and @xmath , for which we use the replica method
[ 93 , 105 ] . It uses the identity

  -- -------- -------- -- --------
     @xmath   @xmath      (3.35)
  -- -------- -------- -- --------

where @xmath denotes the average over @xmath and @xmath and relies on
the fact that an expression for @xmath can be found for integer @xmath .
This expression is then used for caculating the @xmath limit in ( 3.35
). Let us therefore start by calculating

  -- -------- -- --------
     @xmath      (3.36)
  -- -------- -- --------

and its average with respect to the realizations of @xmath , generated
by @xmath and @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.37)
  -- -------- -------- -- --------

The indices @xmath represent so-called replicas of the system and are
initially independent from each other. Carrying on the calculation
requires to couple them. To be more precise, each variable @xmath is the
sum of a large number of independent random variables and can therefore
be approximated as a Gaussian random variable, with mean

  -- -------- -------- -- --------
     @xmath   @xmath      (3.38)
  -- -------- -------- -- --------

because @xmath has zero mean. This allows to considerably reduce the
number of integrals caused by the averaging over @xmath . However,
@xmath and @xmath from different replicas @xmath and @xmath are not
independent, as they are generated with the same matrix @xmath . This
can be seen by calculating the cross-correlation

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.39)
  -- -------- -------- -- --------

The multivariate random variable @xmath is thus Gaussian with mean
@xmath and covariance matrix @xmath . As in ( 3.37 ), @xmath can be
anything, we have to integrate over it, such that

  -- -------- -------- -- --------
     @xmath               
              @xmath      (3.40)
  -- -------- -------- -- --------

Here, we use the convention that @xmath if @xmath . We now see that the
different replicas are coupled via @xmath in the first line. As we did
with @xmath , we now introduce the vector @xmath and we use the integral
representation of the @xmath function, introducing the conjugate
variable @xmath (details in appendix B ), which leads to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.41)
  -- -------- -------- -- --------

Finally, we assume the @xmath ’s and @xmath ’s to be identically
distributed. With the notations @xmath and @xmath , this leads to:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.42)
  -- -------- -------- -- --------

In the “thermodynamic” limit, we take @xmath and @xmath going to
infinity with constant ratio @xmath . This motivates us to rewrite the
last equation as

  -- -------- -------- -- --------
     @xmath   @xmath      (3.43)
  -- -------- -------- -- --------

and to use the saddle point method, according to which

  -- -------- -------- -- --------
     @xmath   @xmath      (3.44)
  -- -------- -------- -- --------

In the thermodynamic @xmath limit, the @xmath term has a vanishing
contribution. We are therefore left with a minimization problem over the
space of the matrices @xmath and @xmath , representing a total of @xmath
free paramters (as both matrices are symmetric).

##### 3.3.2 Replica symmetric assumption

The idea of the replica symmetric assumption is that the @xmath replicas
introduced in ( 3.36 ) are all equivalent, as they are purely a
mathematical manipulation. Based on this, we make the assumption that a
sensible matrix @xmath does not make any distinction between the @xmath
introduced replicas. We therefore parametrize @xmath and @xmath in the
following way: \marginnote RS assumption [1.3cm]

  -- -------- -- -------- -- -- --------
     @xmath      @xmath         (3.45)
  -- -------- -- -------- -- -- --------

allowing to be left with @xmath instead of @xmath parameters over which
to perform the extremization ( 3.44 ). Furthermore, @xmath is in fact
known, as it is the second moment of the prior @xmath and therefore we
can set

  -- -------- -------- -- --------
     @xmath   @xmath      (3.46)
  -- -------- -------- -- --------

and thus the extremization is only over 6 variables: @xmath .

Let us now look in more details at the function @xmath to extremize:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.47)
  -- -------- -------- -- --------

Thanks to the parametrization ( 3.45 ), the different terms have simple
expressions. The trace can simply be written as

  -- -------- -------- -- --------
     @xmath   @xmath      (3.48)
  -- -------- -------- -- --------

while we can use that

  -- -------- -------- -- --------
     @xmath   @xmath      (3.49)
  -- -------- -------- -- --------

and the Gaussian transformation @xmath , where @xmath is a Gaussian
integration measure:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.50)
  -- -------- -------- -- --------

in order to write

  -- -------- -------- -- --------
     @xmath   @xmath      (3.51)
  -- -------- -------- -- --------

The second line in ( 3.47 ) can be simplified as well. The first step
consists in writing the coupled Gaussian random variables @xmath as a
function of @xmath independent, standard Gaussian random variables
@xmath (for @xmath ) and one additional standard Gaussian random
variable @xmath that couples them all:

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (3.52)
  -- -------- -------- -------- -------- -- --------

Making the change of variables in the integral, we obtain the following
expression for @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.53)
  -- -------- -------- -- --------

Looking back at the replica trick ( 3.35 ), we have to study the
quantity @xmath and therefore the quantities

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.54)
              @xmath      
  -- -------- -------- -- --------

as well as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.55)
  -- -------- -------- -- --------

We use the shorter notations @xmath for @xmath as defined in Appendix
A.2 . In the end, we obtain the free entropy @xmath as a saddle point
\marginnote GLM free entropy [0.9cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.56)
  -- -------- -------- -- --------

over a set of @xmath variables (because @xmath ). Note that the shift
from a minimum in ( 3.44 ) to a saddle point in the equation above is a
consequence to the hazardous @xmath limit in the replica method.

Note that @xmath , @xmath and thus @xmath can be expressed using the
information-theoretical quantities introduced in sec. 1.1.2 : mutual
information, entropy and Kullback-Leibler divergence.

##### 3.3.3 State evolution equations

In the previous section, we have derived an expression for the free
entropy as an extremum of a function over a set of parameters. In order
to find the extremum in ( 3.56 ), we simply set all the partial
derivatives of @xmath to @xmath , which gives us saddle point equations
. This requires calculating the derivatives of the integrals @xmath and
@xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (3.57)
  -- -------- -------- -- --------

For @xmath , we use the identity ( A.30 ), taking @xmath or @xmath .
After an integration by parts, we obtain

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (3.58)
  -- -------- -------- -- --------

These expressions will be injected into the extremization equations of
@xmath with respect to the elements of @xmath and @xmath (remember that
@xmath and @xmath ):

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath   @xmath      (3.59)
  -- -------- -------- -------- -------- -- --------

and using the update functions defined in ( 3.21 )–( 3.23 ), we obtain

  -- -------- -------- -- --------
     @xmath   @xmath      (3.60)
     @xmath   @xmath      (3.61)
     @xmath   @xmath      (3.62)
  -- -------- -------- -- --------

These equations can be further simplified by using the transformation
@xmath and integrating by parts eq. ( 3.61 ): \marginnote GLM saddle
point / state evolution equations [2cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.63)
     @xmath   @xmath      (3.64)
     @xmath   @xmath      (3.65)
  -- -------- -------- -- --------

and for the conjugate variables, we obtain \marginnote GLM saddle point
/ state evolution equations [2cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.66)
     @xmath   @xmath      (3.67)
     @xmath   @xmath      (3.68)
  -- -------- -------- -- --------

The equations ( 3.63 , 3.64 , 3.65 ) along with the equations ( 3.66 ,
3.67 , 3.68 ) constitute a closed set of equations that hold at the
saddle points of @xmath in equation ( 3.56 ). (Note that eq. ( A.27 )
can be used in order to calculate the derivatives.)

When they are iterated, they constitute the so-called state evolution
equations. These can also be obtained by the analysis of the BP
algorithm ( [ 41 , 73 ] for the special case of CS, [ 113 , 67 ] for a
generic sensing channel) and are known to accurately describe the
algorithm’s behaviour when the replica symmetric hypothesis is verified.

Looking at the definition ( 3.39 ), the “physical” meaning of @xmath is
the overlap between @xmath and the estimate @xmath obtained by sampling
from ( 3.20 ). In the same way, @xmath is the squared @xmath norm of
@xmath , and @xmath is the overlap between two estimates @xmath and
@xmath obtained by sampling from ( 3.20 ):

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (3.69)
  -- -------- -------- -------- -------- -------- -------- -- --------

From this, one can simply deduce the predicted mean squared error
achieved by GAMP:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.70)
  -- -------- -------- -- --------

##### 3.3.4 Bayes optimal analysis

Until now, we have not assumed exact knowledge of the true signal
distributions and of the true measurement channel. When this is the
case, the state evolution equations greatly simplify because of the
so-called Nishimori conditions [ 146 ] . In our case, these ensure that
the following equalities hold:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.71)
  -- -------- -------- -- --------

Then, we only need to keep track of the variables @xmath , and the state
evolution is obtained by choosing an initial value for @xmath and
iterating for @xmath the equations \marginnote Bayes optimal GLM state
evolution [1.8cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.72)
     @xmath   @xmath      (3.73)
  -- -------- -------- -- --------

until convergence. The expression of the predicted mean squared error (
3.70 ) simplifies to

  -- -------- -------- -- --------
     @xmath   @xmath      (3.74)
  -- -------- -------- -- --------

The initialial value @xmath indicates how close to the solution the
algorithm is at initialization. In case of a random initialization of
the algorithm, the expected initial overlap @xmath is of order @xmath ,
and should therefore be set to that value (or less) in the state
evolution equations.

Note that the state evolution run with matching priors without imposing
the Nishimori conditions ( 3.71 ) should in principle give the exact
same results as the Bayes optimal state evolution analysis presented
above, and thus be naturally attracted and follow the so-called
“Nishimori line” defined by ( 3.71 ), as shown in [ 73 ] .

##### 3.3.5 Partial information on @xmath

In some cases, it can be useful to consider that partial information on
@xmath is available through additional measurements @xmath taken through
a separable channel @xmath . In that case, the @xmath functions are
replaced by @xmath and in the analysis, integration has to be performed
over the realizations of @xmath as well. The state evolution equations (
3.66 – 3.68 ) are unchanged, but equations ( 3.63 – 3.65 ) are replaced
by

  -- -------- -------- -- --------
     @xmath   @xmath      (3.75)
     @xmath   @xmath      (3.76)
     @xmath   @xmath      (3.77)
  -- -------- -------- -- --------

Written in this more general form, the DE equations for @xmath are even
more similar to their counterparts for @xmath and require integration
over 2 variables as well.

#### 3.4 Compressed sensing analysis

GAMP particularizes to a CS solver using the update functions presented
in example LABEL:ex:csGAMP . These same update functions can be injected
into the state evolution equations in order to perform a theoretical
analysis of compressed sensing. As in example LABEL:ex:csGAMP , we look
at the case of Bayes optimal CS through an AWGN channel and with
Gauss-Bernoulli priors.

###### Algorithm dynamics and state evolution

Figure 3.4 illustrates the crucial point that the state evolution
equations accurately describe the dynamics of GAMP . This can come as a
surprise considering that the state evolution equations have been
obtained independently of the algorithm. However, they can be obtained
as well starting from the GAMP algorithm and analyzing the distributions
of the different updated quantities. Such an analysis can be found in [
41 ] or in sec. 5.2.1 (for complex compressed sensing). For real-valued
compressed sensing, it has been made rigorous [ 11 , 12 ] . This
correspondence between the replica analysis and the belief propagation
equations is linked to the hypothesis of replica symmetry, which is
always verified in Bayes optimal inference [ 146 ] .

###### Phase transitions

As seen in Fig. 3.4 , GAMP converges to the right solution or not
depending on the values of @xmath and @xmath . The MSE is therefore an
order parameter of the problem that defines different phases depending
on whether it is zero. The corresponding phase diagram is shown on Fig.
3.4(a) . The phases A-D have the following characteristics:

1.  Easy phase: Both AMP and Bayes optimal GAMP converge to the
    solution. The LASSO phase transition is known as the Donoho-Tanner
    phase transition [ 38 ] .

2.  Easy phase: The convex relaxation LASSO ceases to be equivalent to
    CS, but Bayes optimal GAMP converges to the solution.

3.  Hard phase: Neither of the two algorithms converge to the solution.
    However, as an oracle algorithm would find it, recovery is possible.
    Specially designed, so-called spatially coupled matrices allow
    recovery using Bayes optimal GAMP in this phase [ 73 ] . The line
    separating B and C is known as the spinodal , while the line
    separating C and D is the static phase transition.

4.  Impossible phase: The problem is hopelessly underdetermined as even
    oracle algorithms would fail. Recovery is impossible for any
    algorithm.

Figure 3.4(b) shows that the phase transition can be of first order (for
Bayes optimal CS, there is a discontinuity in the MSE) or of second
order (for LASSO, the MSE goes to zero continuously).

###### Energy landscapes and state evolution fixed points

The phase diagram in Fig. 3.4(a) can be understood looking at the
system’s free entropy, just as for the Ising model in example
LABEL:ex:Ising . In Bayes optimal CS, the free entropy ( 3.56 ) can be
written as a function of only @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (3.78)
  -- -------- -------- -- --------

with

  -- -------- -------- -- --------
     @xmath   @xmath      (3.79)
     @xmath   @xmath      (3.80)
     @xmath   @xmath      
              @xmath      (3.81)
  -- -------- -------- -- --------

The free entropy ( 3.78 ) is plotted on Fig. 3.5(a) as a function of the
MSE (which is a function of @xmath ). It can have one or two local
maxima depending on the values of @xmath . At the phase transition, a
second maximum appears at a location that is different from the first,
which explains why the phase transition is of second order. On Fig.
3.5(b) , we show the fixed points of the state evolution equations,
which correspond to the local extrema of the free entropy.

###### Convergence issues

GAMP can have convergence issues, for example when the measurement
matrix @xmath does not have zero mean or is low-rank. In that case, some
quantities in the algorithm diverge after a few iterations. For non-zero
mean matrices, the reason of this divergence has been explained and
analyzed with state evolution equations in [ 24 ] . Several approaches
exist in order to solve such convergence issues, all requiring to change
the algorithm.

###### Damping

of some of the variables in the algorithm can be used. While slowing
down the algorithm, damping attenuates oscillations that can otherwise
lead to diverging quantities. A multitude of damping schemes can be
implemented, most of them are not first-principled and it is not clear
how to analyze the resulting algorithm. For some special cases, damping
was proven to allow convergence for any measurement matrix [ 114 ] .
Other damping schemes use damping coefficients that vary from iteration
to iteration depending on an energy function [ 139 ] .

###### Sequential updates

of the algorithm’s variables can replace the parrallel scheme of GAMP in
which all estimators of each signal component are update at each time
step. The swept approximate message passing (SWAMP) was proposed in [ 89
] . Like damping, sequential updating slows down the algorithm
significantly, but greatly improves its convergence for certain
measurement matrices.

###### Ut-Amp

is a modified version of AMP that was proposed in [ 56 ] , and only
makes minimal changes to the algorithm, which runs at the same speed. In
UT-AMP, the singular vector decomposition

  -- -------- -- --------
     @xmath      (3.82)
  -- -------- -- --------

is calculated and GAMP is applied to the system

  -- -------- -- --------
     @xmath      (3.83)
  -- -------- -- --------

While being very robust and not slowing down the algorithm as damping or
sequential update, the limit of this trick is that it is restricted to
CS and cannot be applied to GAMP with a general sensing channel.

#### 3.5 Quantized sensing

Another example of a GLM is quantized sensing, studied with GAMP in [ 70
] . In quantized sensing, the measurements can only take a discrete set
of values @xmath that are assigned to @xmath depending on the magnitude
of a noisy version of @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (3.84)
  -- -------- -------- -- --------

where @xmath are thresholds that indicate how @xmath is discretized. The
corresponding function @xmath used in GAMP is then

  -- -------- -------- -- --------
     @xmath   @xmath      (3.85)
  -- -------- -------- -- --------

from which @xmath and @xmath can be easily obtained using relation (
A.27 ) and ( A.15 ).

##### 3.5.1 1 bit CS of continuous and binary signals

In the case where @xmath , each measurement takes 1 bit to be stored and
we speak of 1-bit CS. This setting was studied with the replica method
in [ 142 , 143 ] and with GAMP in [ 70 ] . The threshold @xmath is
usually taken to be zero, but can be different. In [ 69 ] , a setting is
examined in which the threshold can be adapted to the measurements
already taken.

###### Continuous signals

It can be intuitively understood that a continuous signal cannot be
perfectly reconstructed from 1-bit measurements. A geometrical insight
into this fact is given on Fig. 3.6(a) . For this reason, there is no
phase transition in @xmath -bit CS. Instead, the reconstruction
performance improves continuously with the measurement rate: Fig. 3.6(b)
shows the achievable MSE for binary sensing of Bernoulli-Gauss
distributed signals. Note that increasing the sparsity allows to obtain
lower MSEs (not represented on the figure), but unlike in CS, the
sparsity constraint is not sufficient to allow perfect reconstruction.

###### Quantized signals

On the other hand, a signal that is quantized itself can be perfectly
recovered from @xmath -bit measurements. Figure 3.8 shows phase diagrams
obtained for @xmath -bit sensing of binary signals following the
distribution \marginnote Binary prior [0.65cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (3.86)
  -- -------- -------- -- --------

with @xmath equal to @xmath or @xmath .

The fact that perfect recovery is possible for quantized signals comes
from the fact that the constraint imposed by the prior ( 3.86 ) is much
stronger than the one imposed by the Bernoulli-Gaussian prior (
LABEL:eq:gaussBernouilli ). In other words, the entropy of the binary
prior is much smaller than the entropy of the Bernoulli-Gaussian prior.
Therefore, quantized signals can also be perfectly recovered in settings
with noisy measurements, which will be used in sec. 5.2.3 in the context
of sparse superposition codes.

Note that as in CS, there is a hard phase in which inference is
possible, but in which GAMP fails to perfectly recover the signal, as it
gets trapped in a local free entropy maximum. In noiseless CS, the
position of the static phase transition separating the impossible from
the hard phase could be obtained by counting the number of equations and
non-zero unknowns. This was related to the fact that CS measurements are
linear. As this is not the case in quantized sensing, there is a priori
no simple expression giving the position of the static phase transition.
The spinodal separates the easy and hard phases.

##### 3.5.2 Applications: perceptron

1-bit CS is particularly interesting because in it, the measurement
process is precisely the firing process of an idealized neuron (example
LABEL:ex:neuralNetworks ). The sensing channel of 1-bit CS is the
equivalent of the neuron’s activation function , which is usually taken
to be a sigmoid-shaped function such as the logistic function or the
hyperbolic tangent. These are often approximated by the channel ( 3.84 )
with @xmath and a well chosen noise level @xmath .

1-bit CS can therefore be applied to the much older problem of the
perceptron, presented in example LABEL:ex:singleLayer , from which we
take over the notations. The perceptron is a supervised learning problem
in which a collection of @xmath known signals @xmath (which are not
sparse) are given along with their correct classifications @xmath and
the goal is to learn a matrix @xmath such that:

  -- -------- -- --------
     @xmath      (3.87)
  -- -------- -- --------

This problem can be restated as a GLM by considering that @xmath is a
measurement matrix and that the vectors @xmath are signals of @xmath to
recover:

  -- -------- -- --------
     @xmath      (3.88)
  -- -------- -- --------

##### 3.5.3 Neural networks inference

Another application of 1-bit CS is inference of neural connectivity
matrices in recurrent neural networks (example LABEL:ex:neuralNetworks
). The ultimate goal is to be able to infer the synaptic weights @xmath
of a real network of biological neurons whose activity is measured in an
experiment. Neural activities can be recorded with different
experimental techniques such as direct measurements using arrays of
electrodes that record the electrical potentials in individual neurons,
or indirect measurements with fluorescence imaging. Fluorescence imaging
can reveal neural activities by using fluorescent molecules that emit
light in the presence of @xmath ions, which are released by firing
neurons. A modified version of GAMP was proposed in [ 48 ] in order to
infer neural weights from fluorescence data.

More generally, there is a great interest in inference of neural weights
[ 122 , 147 ] , due to the very rapidly increasing quantity and quality
of experimental data. In physics, the problem is known as the inverse
Ising model [ 36 , 95 , 28 ] .

###### Generating model

In a preliminary study, I have tried to apply GAMP to inference of
neural weights of a simulated network of neurons. The setting was the
following:

-   @xmath neurons are initialized in a random state @xmath .

-   A matrix @xmath of synaptic weights is sampled from a distribution
    @xmath .

-   For @xmath , the new state at time @xmath is determined from the
    state at time @xmath :

      -- -------- -- --------
         @xmath      (3.89)
      -- -------- -- --------

    where @xmath is i.i.d. AWGN of variance @xmath and @xmath is the
    Heaviside step function applied elementwise.

Figure 3.9 shows an example of firing patterns obtained by such a
simulation. These firing patterns have very different properties
depending on the noise level @xmath and the distribution of synaptic
weights @xmath . For example, if @xmath is very large, the firing of
neurons at time @xmath is essentially random and nearly independent of
the state at time @xmath . On the contrary, if @xmath , the firing
pattern is deterministic and entirely determined by the initial @xmath
and by @xmath . Depending on the parameters, the firing patterns can
thus have very different aspects. In [ 22 ] , these firing patterns are
classified in different phases, in which the firing of neurons is
synchronous or asynchronous, regular or irregular, with fast or slow
oscillations.

In Fig. 3.9 , the firing patterns were produced using the following
distribution of weights:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.90)
  -- -------- -------- -- --------

with @xmath and @xmath . The values of these parameters are used in
other studies and are inspired by insights from biological experiments,
in which the following was found. (a) Neurons are connected to a small
fraction of the other neurons. (b) Neurons have more excitatory than
inhibitory synapses (hence @xmath ), but that the latter have a larger
weight (hence @xmath ). This model is very simplistic, but similar
models are used as they produce firing patterns that have some of the
properties observed in real firing patterns [ 37 ] .

###### Inference

Once a firing pattern is produced, it can be used in order to perform
inference of @xmath with GAMP. This can be done independently for each
neuron @xmath by transposing eq. ( 3.89 ):

  -- -- -- --------
           (3.91)
  -- -- -- --------

The system ( 3.91 ) is thus a simple 1-bit CS problem. The measurement
rate is @xmath and the weights @xmath are ternary. Just like the binary
signals in Fig. 3.8 , ternary signals can be exactly reconstructed from
1-bit measurements provided @xmath is big enough.

However, ( 3.91 ) presents a serious problem for applying GAMP: the
measurement matrix @xmath has a non-zero mean and more importantly, its
elements can be strongly correlated, which can even be noted visually by
looking at the firing patterns in Fig. 3.9 . To avoid divergences due to
the non-zero mean, I used SWAMP [ 89 ] , which overcomes the problem and
successfully performs 1-bit inference of ternary signals using a
measurement matrix with i.i.d. elements that are 0 or 1. It seems
however that the correlations in @xmath are usually too important to
allow successful inference. Results were very dependent on the
realization and and the reconstructions usually had very high MSEs.
Taking very large measurement rates @xmath did not seem to
systematically improve results.

###### Discussion

The study was aborted due to difficulty to obtain reproducible results.
The main reason for this seems to be the presence of strong correlations
in the firing patterns, that act as measurement matrices. Following
future research directions could lead to interesting results:

-   Use different distributions @xmath that lead to firing patterns that
    present a greater variability.

-   Make an analysis the noise level’s influence. As @xmath increases,
    @xmath becomes more random and becomes a better measurement matrix.
    But at the same time, a higher noise level generally makes inference
    harder.

-   Introduce a fraction of neurons that fire at random, thus simulating
    external stimuli and allowing a greater variability of firing
    patterns.

-   Build a model of correlated matrices and attempt to analyse the
    achievable inference performances with these matrices. In the
    pioneering work [ 66 ] , the replica analysis was made with a more
    general model of random matrices than the i.i.d. model used in this
    thesis. However, it does not seem to be directly useful for the
    present study.

#### 3.6 Conclusion

Compressed sensing is a special case of a larger class of inference
problems called generalized linear models. Just like in community
detection, inference of GLMs can be performed using BP. The resulting
algorithm is called GAMP and its performances can be compared to the
theoretical performances of GLM inference, obtained by using the replica
method.

In some special cases of GLMs, such as compressed sensing or quantized
sensing of binary signals, phase transitions separating easy , hard and
impossible inference exist, just as in community detection. These phase
transitions can be understood in terms of free entropy landscapes and of
fixed points of the state evolution equations.

GAMP is highly successful for solving inference problems but also
supervised learning problems that can be simply reformulated as
inference problems. The main limitation of GAMP is that it can encounter
convergence issues for some measurement matrices or sensing channels.
Several techniques to overcome these issues exist and can partially
solve them, at the cost of speed. Further examples of applications of
GAMP are treated in chapter 5 .

### Chapter 4 Generalized bilinear models

In chapter 3 , I have presented generalized linear models and their
theoretical analysis with the replica method. Among the many
applications of GLMs, I presented the examples of compressed and
quantized sensing; further examples are treated in chapter 5 .

Conceptually, GLMs are easy to generalize to generalized bilinear
models, presented in this chapter. As GLMs, the GBM setting can be
analyzed with the replica method and message-passing algorithms for
probabilistic inference can be derived. However, the computational
complexity of these problems is considerably higher than for GLMs, which
leads to much slower algorithms. Furthermore, stability issues are much
more present, such that message-passing algorithms often do not
converge.

This chapter presents 3 bilinear problems of increasing complexity:
blind gain calibration, generalized matrix factorization and generalized
matrix compressed sensing. My contributions to these problems will be
presented in chapter 6 and chapter 7 .

#### 4.1 Gain calibration

We focus on the noiseless setting in which measurements @xmath are
generated as follows:

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

Equation ( 4.1 ) is linear both in @xmath and in @xmath and is thus
bilinear . As in CS, the signal can be sparse and the measurement matrix
@xmath is supposed to have i.i.d. random entries.

###### Supervised vs blind calibration

The difference between supervised and blind calibration is presented
on Fig. 4.1 . In a supervised setting, where it is possible to measure
known signals, it is straightforward to recover @xmath by measuring a
single signal, as

  -- -------- -------- -- -------
     @xmath   @xmath      (4.3)
  -- -------- -------- -- -------

In blind calibration, it is not possible to measure known signals. The
problem is harder in the sense that there are more unknowns. As @xmath
is fixed and independent of the signal measured, it introduces a
correlation in the measurements of independent signals that can be
exploited in order to jointly infer the signals and the gains.

A simple way to see this is to consider a simplified case, in which the
elements of @xmath are either @xmath or @xmath . As the elements of
@xmath are iid, @xmath has the same variance (let’s call it @xmath ) for
all @xmath s. The variance of @xmath , however, is either @xmath or
@xmath . Measuring enough signals, the empirically calculated variances
obtained for each @xmath approach the true variance, making it possible
to determine if @xmath is @xmath or @xmath . If the gains are continuous
variables, this naive method will not be efficient, as the convergence
of the empirical variance to the true one is slow with increasing @xmath
.

###### Scaling invariance

An important remark about this problem is that it does not have a unique
solution because of a fundamental scaling invariance: For any scalar
@xmath , the couple @xmath generates the same measurements as the couple
@xmath . This ambiguity is lifted if the exact mean of @xmath or of
@xmath is known. However, @xmath and @xmath are random variables, and
even if their distribution is known, their empirical mean is not exactly
equal to the mean of the distribution because of the finite size of
@xmath and @xmath . Therefore, it is reasonable to consider this scaling
invariance as unliftable.

For inference algorithms, this means that the MSE ceases to be a
satisfying measure of success, as

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

which does not reflect that the estimate @xmath cannot be improved
without further informations. Therefore a better measure of success is
the normalized cross-correlation, which takes into account the scaling
invariance: for @xmath and @xmath , \marginnote Normalized
cross-correlation [0.7cm]

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

The normalized cross-correlation varies between @xmath (uncorrelated
signals) and @xmath ( @xmath and @xmath are equal up to a multiplicative
constant). If the scaling invariance is restricted to positive scalars
@xmath , a related measure of success is the normalized MSE: \marginnote
Normalized MSE [0.8cm]

  -- -- -- -------
           (4.6)
  -- -- -- -------

which varies from @xmath (uncorrelated signals) to @xmath ( @xmath and
@xmath are equal up to a positive multiplicative constant).

###### Bounds

A first qualitative analysis of the problem can make it look hopeless:
in fact, there are @xmath measurements for @xmath unknowns (the signal +
the gains). An obvious lower bound for @xmath is the compressed sensing
phase transition, as the problem reduces to CS if the sensors are
perfectly calibrated ( @xmath is known):

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

To overcome this problem, we consider a setting in which @xmath
different real-valued signals are measured:

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

Considering only the non-zero components of the signal, there are @xmath
measurements for @xmath non-zero unknowns. Inference should therefore be
possible if @xmath , or equivalently

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

In fact, consider an oracle algorithm that knows the locations of the
signal’s zeros. For each of the @xmath sensors, the @xmath measurements
can be combined into @xmath independent linear equations of the type

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

In total, there are @xmath such linear equations and @xmath unknowns,
such that the system can be solved as soon as @xmath , which confirms
the bound ( 4.9 ).

##### 4.1.1 Convex formulation

Blind gain calibration was studied in [ 53 ] using convex optimization.
As in CS, sparsity is enforced by an @xmath norm. For the problem to be
convex, the change of variable @xmath is necessary, leading to the
formulation

  -- -------- -------- -- --------
     @xmath   @xmath      (4.11)
  -- -------- -------- -- --------

where the diagonal terms of the matrix @xmath are the components of the
vector @xmath and its non-diagonal elements are zeros. Note that the
condition on the trace imposes the mean of @xmath , thus lifting the
scaling invariance.

In [ 17 ] , the authors of [ 53 ] generalize the algorithm to the
complex setting in which

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

###### Complexity and convergence

The results presented in [ 53 ] show that a small number @xmath of
signals is usually sufficient for successful inference. In the realized
experiments, @xmath or @xmath signals allow perfect reconstruction in
large parts of the @xmath space. As in CS, a phase transitions is
visible between regions of successful and unsuccessful inference. For
@xmath , the experimental phase transition is nearly superposed with the
Donoho-Tanner phase transition of CS.

Being a convex minimization problem, the formulation of eq. ( 4.11 ) can
be implemented with standard libraries such as the CVX package for
MATLAB [ 52 , 51 ] . This ensures a fast and reliable convergence of the
algorithm.

In chapter 6 I present a Bayesian algorithm for blind gain calibration,
motivated by the fact that in CS, the Bayesian approach outperforms the
convex minimization approach.

##### 4.1.2 Applications

The blind gain calibration problem can be encountered when signals are
measured by physical devices (sensors) that introduce a multiplicative
gain. Ideally, sensor gains are known, either through a precise
fabrication process, or experimentally determined after fabrication. The
system can then be calibrated accordingly. However, the gain of a sensor
could vary over time (with the aging of the device or exterior
conditions such as temperature, humidity…), thus requiring regular
calibration. Supervised calibration might not always be possible
(see application LABEL:appli:radioAstronomy ) or simply not desirable
because it is not user-friendly. Therefore blind calibration procedures
can be necessary. Two applications of blind calibration are given below.
Other applications include calibration of microphone arrays [ 96 ] or
time-interleaved AD converters [ 125 ] .

#### 4.2 Matrix factorization

As blind gain calibration, matrix factorization (MF) is a bilinear
inference problem. In this section, I present a “generalized” version of
it, illustrated by Fig. 4.2 , as considered in [ 74 , 67 ] .

In matrix factorization, the number of unknowns is even higher than in
blind calibration, as the measurement matrix itself is unknown. For this
reason I use the notations @xmath instead of @xmath to clarify the
equivalence of signal and matrix. In a mixing step, @xmath and @xmath
produce an intermediate variable @xmath whose components are given by

  -- -------- -------- -- --------
     @xmath   @xmath      (4.16)
  -- -------- -------- -- --------

As eq. ( 4.1 ), this equation is bilinear. As in GLMs, this mixing step
is followed by a sensing step through a probabilitic channel @xmath that
produces the measurements, hence the name generalized bilinear model .
Specific settings of matrix factorization are discussed in sec. 4.2.2 ,
depending on the distributions of @xmath and @xmath and on the sensing
channel. We define the measurement rates

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

###### Invariances

As in blind gain calibration, there is a scaling invariance in matrix
factorization. However, it is a much more general invariance: For every
invertible matrix @xmath , the couples @xmath and @xmath produce the
same measurements. As in blind gain calibration, this invariance might
in theory be lifted if the distributions of @xmath and @xmath are known.
However, for the same reason of finite system size, the invariance
cannot be expected to be completely lifted. Furthermore, it might
introduce correlations between components of @xmath and @xmath that are
supposed to be independent.

In some applications, the goal is to recover @xmath : as @xmath is not
affected by the invariances, a good measure of success is the MSE on
@xmath . In other applications, the goal is to recover @xmath and @xmath
, in which case the invariance might be a real issue.

##### 4.2.1 Algorithm and analysis

As for GLMs, a message-passing algorithm can be derived starting from
the probabilitic approach to the inference problem. This approach can be
analyzed with the replica method, exactly as was done in chapter 3 .
Derivations of the algorithm, called BiGAMP, can be found in [ 108 , 67
] , a derivation of the replica analysis in [ 67 ] . As a very similar
derivation is done in chapter 7 , I will only present the results using
notations that are coherent with those used in chapter 3 .

###### BiGAMP

BiGAMP is presented in algorithm 3 . It performs Bayesian inference of
generalized matrix factorization in the same probabilistic framework as
described for GAMP in sec. 3.2.2 , starting from the posterior
distribution

  -- -------- -------- -- --------
     @xmath   @xmath      (4.18)
  -- -------- -------- -- --------

Its structure is very similar to GAMP: for each variable of the problem,
there are two estimators along with their uncertainties, and the @xmath
variables for the gradient descent. The update functions exactly
correspond to those in GAMP (see Appendix A.2 ).

Initialize @xmath and @xmath at random or according to @xmath and @xmath
.
Main loop: while @xmath , calculate following quantities:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Stop when @xmath , @xmath or @xmath .

Algorithm 3 BiGAMP

###### Free entropy and state evolution equations

The free entropy expressed as a saddle point reads \marginnote
Generalized MF free entropy [1.2cm]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.19)
  -- -------- -------- -- --------

where @xmath are the exact equivalents of @xmath ( 3.54 ), @xmath is
identical to ( 3.55 ) and

  -- -------- -------- -- --------
     @xmath   @xmath      (4.20)
  -- -------- -------- -- --------

such that the saddle point has to be performed over the 12 variables
@xmath and @xmath . The resulting state evolution equations are given by

  -- -------- -------- -- --------
     @xmath   @xmath      (4.21)
     @xmath   @xmath      (4.22)
     @xmath   @xmath      (4.23)
  -- -------- -------- -- --------

the same @xmath equations with @xmath and \marginnote Generalized MF
state evolution [2.2cm] \marginnote Generalized MF state evolution
[-2.9cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (4.24)
     @xmath   @xmath      (4.25)
     @xmath   @xmath      (4.26)
  -- -------- -------- -- --------

with

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (4.27)
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (4.28)
  -- -------- -------- -------- -------- -------- -------- -- --------

As for GLMs, the Bayes optimal setting greatly simplifies the state
evolution to the following 3 equations: \marginnote Bayes optimal
generalized MF state evolution [2.5cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (4.29)
     @xmath   @xmath      (4.30)
     @xmath   @xmath      (4.31)
  -- -------- -------- -- --------

In [ 67 ] , several settings of generalized matrix factorization are
examined with these Bayes optimal state evolution equations. For reasons
explained below, the theoretically predicted performances are
unfortunately not always reached using algorithm 3 .

###### Complexity and convergence

In most settings of matrix factorization, @xmath , @xmath and @xmath are
of the same order. For this reason, matrix factorization algorithms are
very slow and it is problematic to run them for @xmath bigger than a few
hundreds. In comparison, GAMP can perform inference on problems with
@xmath on a standard laptop. An interesting special case of matrix
factorization in which @xmath is of order one is examined in [ 91 , 82 ]
.

Unlike GAMP for CS or quantized sensing, BiGAMP does not converge in the
form in which it is presented in algorithm 3 . The convergence issue is
similar to the one of GAMP when the matrix does not have zero mean or
when it is low rank: after a few iterations, some of the estimators go
to infinity. To correct this behaviour, BiGAMP can be modified to
include damping. Such a damping scheme is presented in [ 108 ] ,
allowing to significantly improve convergence properties of BiGAMP.
Numerous experimental results are given in [ 107 ] for different
applications of matrix factorization. However, the performance predicted
by the state evolution analysis can in general not be obtained, meaning
that there is still room for improvements. The reasons for the bad
convergence properties of BiGAMP and the necessity of damping are not
well understood. Therefore, damping schemes are mainly empirical and can
probably be improved upon.

A very simple damping scheme that works quite well in some simple
configuration is the following, that damps only one variable:

  -- -------- -- --------
     @xmath      (4.32)
  -- -------- -- --------

with @xmath , applied right before updating @xmath . Furthermore,
setting @xmath and @xmath in the update equations for @xmath and @xmath
greatly reduces the risk of negative variances appearing, while
emulating the Nishimori conditions [ 67 ] .

##### 4.2.2 Applications

###### Dictionary learning

Dictionary learning (DL) can be considered as a more difficult version
of CS, in which the measurement matrix ( @xmath or @xmath ) itself is an
unknown. As in gain calibration, the blind scenario is the most
difficult, when only unknown signals can be measured. The measurement
matrix is then usually called the dictionary . The sensing channel is
AWGN and the signals ( @xmath or @xmath ) are sparse, such that each
measurement is a linear combination of a few entries of the dictionary.
A simple couting bound for DL, obtained with the same reasoning as eq. (
4.9 ) is

  -- -------- -- --------
     @xmath      (4.33)
  -- -------- -- --------

showing that both @xmath and @xmath have to be of the same order as
@xmath for successful inference.

It is possible to interpolate between CS and DL thanks to the “blind
matrix calibration” setting [ 67 , 74 ] , in which a noisy estimate of
@xmath is known:

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

where @xmath is AWGN with of variance @xmath . Varying the parameter
@xmath between @xmath and @xmath is interpolating between CS and DL and
is a good setting to study in order to understand the problems arising
in DL. In the state evolution, equations ( 4.21 – 4.23 ) are replaced by
equations ( 3.75 – 3.77 ) for @xmath , as it is partially known. In sec.
7.3 , I will use the blind matrix calibration setting to examine the
stability of the Nishimori line ( 3.71 ) in bilinear inference problems.

###### Low-rank matrix completion

Another interesting application of matrix factorization is low-rank
matrix completion. In that setting, the unknown to be infered is @xmath
, which is observed through a channel such that only a fraction @xmath
of its components are measured. The other elements of @xmath are
unknown, but the matrix is known to be low-rank, therefore

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

The number of variables of the problem is therefore reduced to @xmath ,
and a simple counting bound on @xmath is

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

A real-world application of low-rank matrix completion is the netflix
prize [ 16 ] . In that challenge, the goal is to complete a matrix
containing grades given by users to different movies by observing only a
fraction of the entries. The goal is to be able to predict which movies
a user likes in order to make the best possible recommendation.

Low-rank matrix completion is an application for which BiGAMP works
quite well with a simple damping scheme.

#### 4.3 Matrix compressed sensing

A third example of bilinear inference problem is matrix compressed
sensing (MCS). MCS is similar to CS with the difference that the signal
is a low-rank matrix instead of a sparse vector. The measurements are
made from linear combinations of the matrice’s elements, with the usual
probabilistic sensing channel @xmath for the generalized extension. The
setting is illustrated in Fig. 4.3 .

In chapter 7 , I derive a Bayesian message-passing algorithm for MCS and
perform the theoretical analysis using the replica method.

##### 4.3.1 Setting

As in matrix factorization, the matrices @xmath and @xmath are
multiplied, but we call @xmath their product:

  -- -------- -------- -- --------
     @xmath   @xmath      (4.37)
  -- -------- -------- -- --------

The elements of @xmath are mixed with a linear operator @xmath that can
be represented by a matrix @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (4.38)
  -- -------- -------- -- --------

or, written componentwise:

  -- -------- -------- -- --------
     @xmath   @xmath      (4.39)
  -- -------- -------- -- --------

As for CS, we generally consider that the matrix elements of @xmath are
i.i.d. random variables, which allows @xmath to satisfy the
generalization of the RIP for matrix compressed sensing with high
probability [ 116 ] . As for matrix factorization, we consider the
generalized setting, in which the measurement @xmath are taken through
an element-wise, probabilistic sensing channel:

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

##### 4.3.2 Link to matrix factorization

Matrix factorization can be seen as a special case of MCS when @xmath is
the identity (in that case the i.i.d. assumption on the elements of
@xmath does obviously not hold).

But more generally, the setting is very similar to MF if @xmath : if
@xmath has i.i.d. elements, it is with high probability a bijection, and
does not introduce any further difficulty into the problem. If @xmath ,
and @xmath has i.i.d. elements, it is with high probability injective
and the setting is very similar to the matrix completion scenario
examined in sec. 4.2.2 with @xmath .

In that sense, matrix compressed sensing is the most general inference
setting considered in this thesis as it contains matrix factorization
and thus generalized linear models, which corresponds to knowing @xmath
.

##### 4.3.3 Existing work for the AWGN channel

Most previous work on matrix compressed sensing (which is known under
different names, such as “matrix sensing”, “matrix completion”, “affine
rank minimization”) consider the AWGN sensing channel. As CS, MCS can be
expressed as a minimization problem:

  -- -------- -------- -- --------
     @xmath   @xmath      (4.41)
  -- -------- -------- -- --------

Note that the rank plays the role of the @xmath “norm” in CS. Under this
form, the minimization problem is hard to solve (it is in general
NP-hard). The algorithms developed in this context often rely on the
minimization of the nuclear norm of @xmath , which is the sum of its
singular values, while taking into account the measurements @xmath [ 40
, 116 ] . They therefore aim at solving the minimization problem

  -- -------- -------- -- --------
     @xmath   @xmath      (4.42)
  -- -------- -------- -- --------

which is a convex relaxation of ( 4.41 ), just as LASSO is a convex
relaxation of the @xmath minimization problem in CS. As in CS, there are
conditions under which the convex relaxation ( 4.42 ) is equivalent to
the rank minimization ( 4.41 ): under these conditions, matrix
compressed sensing can be solved using convex minimization techniques.

One limitation of this approach is that the equivalence of the problems
does not hold in all ranges of parameters and that it performs the
minimization in the high-dimensional space @xmath .

Other works rely on the decomposition of @xmath into the product @xmath
. This allows to reduce the search space and to take into account
potential further requirements on @xmath and @xmath such as sparsity [
81 ] , but has several disadvantages. First, by using the @xmath
decomposition the problem becomes non-convex. Second, decomposing @xmath
into @xmath using singular values decomposition is computationally
demanding and therefore has to be avoided if possible.

Such algorithms use alternating minimizations producing estimates of
@xmath and @xmath [ 149 , 63 ] , or focus on the case in which @xmath is
positive semi-definite (therefore @xmath ) [ 150 ] and use gradient
descent.

Initialization : Initialize @xmath at random.
Main loop: while @xmath :
Fix @xmath , update @xmath such that

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

Fix @xmath , update @xmath such that

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

Result: @xmath .

Algorithm 4 Power factorization

An example of a simple alternating minimization scheme is the “Power
Factorization” algorithm proposed in [ 57 ] and given in algorithm 4 .
Note that both steps are simple and fast, that no singular value
decomposition is needed and that results are claimed to be better than
those obtained by nuclear norm minimization. On the other hand, unlike
nuclear norm minimization, power factorization is not convex and thus no
theoretical bounds on its performance are known.

#### 4.4 Conclusion

Generalized bilinear models are a vast class of inference problems with
numerous applications. One subclass is the generalized matrix
factorization setting, that can be analyzed using the replica method,
just as GLMs.

Despite its similarity to GLMs, inference of generalized matrix
factorization using the Bayesian message-passing algorithm BiGAMP is in
general much more problematic for several reasons. First, unliftable
invariances make the problem naturally ill-posed. Second, the complexity
of inference is higher due to a higher number of variables to infer,
such that inference is only practical for moderate signal sizes.
Finally, the stability issues occasionally encountered in GAMP seem
omnipresent in its counterpart BiGAMP. One reason for this instability
is given in chapter 7 . As a result, convergence of BiGAMP heavily
relies on mainly heuristic damping and restarting strategies. Improving
those in order to obtain a more reliably algorithm is a major axis for
future research.

Two other subclasses of generalized bilinear models are blind gain
calibration and matrix compressed sensing, which I treat in more details
in chapter 6 and chapter 7 respectively.

## Part III Main contributions

### Chapter 5 Vectorial GAMP and applications

Many physical signals are best represented by variables with both a real
and an imaginary part. This is the case for propagating waves such as
sound and light, that have both an amplitude and a phase. Two important
applications in this case are magnetic resonance imaging and
crystallography.

In this chapter, I give a derivation of GAMP for vectorial variables,
from which GAMP for complex variables (c-GAMP) can be obtained, and I
analyze the resulting complex CS algorithm with the state evolution
formalism.

I present two applications of vectorial GAMP. The first one is in the
field of coding theory, and focusses on so-called superposition codes.
The second one is phase retrieval , for which I present both a theoretic
study and the results of an optics experiment. These two applications
are presented in publications I have coauthored: [ 10 , 43 ] .

#### 5.1 Complex GAMP

Consider the same setting as in GAMP except all variables are complex:

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

and @xmath and @xmath are generated as

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

The posterior probability distribution still reads

  -- -------- -------- -- -------
     @xmath   @xmath      (5.3)
  -- -------- -------- -- -------

with complex instead of real variables. In general, the prior @xmath and
the channel @xmath do not treat the real and imaginary parts of their
respective variables independently. For example, @xmath can enforce the
real and imaginary parts of @xmath to be zero at the same locations.
This joint sparsity assumption is stronger than the simpler assumption
that both the real and the imaginary part of @xmath are sparse. In order
to take advantage of this, it is important to treat each component of
@xmath (and of @xmath and @xmath ) as a single, complex variable, and
not as two independent real variables. Therefore the generalization of
GAMP to the complex setting is not entirely trivial—although the
resulting algorithms differ only very slightly, in a way that could be
guessed. One possible systematic way to derive complex GAMP is presented
below.

##### 5.1.1 Vectorial GAMP

For the derivation, I consider a setting that is more general than the
complex variables scenario of ( 5.1 – 5.2 ). Namely, let us consider the
following scenario:

  -- -------- -------- -- -------
     @xmath   @xmath      (5.4)
  -- -------- -------- -- -------

with ( @xmath ) of order one, and

  -- -------- -------- -- -------
     @xmath   @xmath      (5.5)
  -- -------- -------- -- -------

with @xmath of order one as well.

In order for the elements of @xmath to be @xmath , we take the elements
of @xmath to have variance @xmath . We take the matrices @xmath to be
i.i.d. random variables, but the elements of each @xmath are not
necessarily independent.

The complex GAMP case corresponds to @xmath with

  -- -------- -- -------- -- -------- -- -- -------
     @xmath      @xmath      @xmath         (5.6)
  -- -------- -- -------- -- -------- -- -- -------

and

  -- -------- -- -- -------
     @xmath         (5.7)
  -- -------- -- -- -------

###### Update functions

Let us first introduce the equivalents of the @xmath -functions used in
real-valued GAMP. The equivalent of means @xmath and variances @xmath
are vectorial means @xmath and covariance matrices @xmath , where @xmath
is the ensemble of symmetric, positive-definite @xmath matrices with
real coefficients. For any function @xmath , we define

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath               (5.8)
     @xmath   @xmath      
     @xmath   @xmath      (5.9)
     @xmath   @xmath      
     @xmath   @xmath      (5.10)
  -- -------- -------- -- --------

where @xmath is a multivariate Gaussian (reminders are given in Appendix
A.1.1 ). From these, we define the update functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.11)
     @xmath   @xmath   @xmath      (5.12)
  -- -------- -------- -------- -- --------

and the auxiliary functions (using matrix inversions)

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.13)
     @xmath   @xmath   @xmath      (5.14)
  -- -------- -------- -------- -- --------

As in GAMP, we will use these functions for @xmath (denoted by ’ @xmath
’) and @xmath (denoted by ’ @xmath ’) in order to calculate new
estimators of @xmath and @xmath respectively.

The factor graph representing the distribution ( 5.3 ) is shown on Fig.
5.1 . With the help of it, I derive the c-GAMP algorithm, following the
exact same steps as for the derivation of GAMP, explained in sec. 3.2.3
, which the reader is suggested to re-read at this point. The derivation
of GAMP can be recovered by taking @xmath .

###### Step 1: BP

We start by writing the BP equations ( 2.18 , 2.19 ) for the factor
graph of Fig. 5.1 :

  -- -------- -------- -- --------
     @xmath   @xmath      (5.15)
     @xmath   @xmath      (5.16)
  -- -------- -------- -- --------

As each @xmath is a continuous, @xmath -dimensional variable, these
equations are problematic, as they would have to be calculated on a
@xmath -dimensional grid of points @xmath , and as the right
normalization constants could therefore only be approximated: Remember
that the messages are probability distribution fuctions. Furthermore,
@xmath @xmath -dimensional integrations are required for each update of
the @xmath messages: performing these numerically requires a lot of time
and computational power. In short, under this form, the BP equations are
close to useless.

###### Step 2: AMP

The second step consists in transforming equations ( 5.15 , 5.16 ) such
that they have a simple expression as a function of @xmath , and
reducing the number of integrals, such that they can easily be evaluated
for any @xmath . For this, we use the (multidimensional) central limit
theorem to approximate each component of @xmath by a Gaussian variable.
This is because

  -- -------- -------- -- --------
     @xmath   @xmath      (5.17)
  -- -------- -------- -- --------

is a sum of a large number @xmath of the random variables @xmath . In (
5.15 ), each @xmath (for @xmath ) is a random variable distributed with
the pdf @xmath . Let us call @xmath and @xmath the mean and covariance
matrix of this pdf. For the central limit theorem to hold, the random
variables have to be independent, which actually is an assumption of BP.
The mean of @xmath is then

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.18)
  -- -------- -------- -- --------

Note that @xmath is treated separately because in eq. ( 5.16 ) it is a
constant. The covariance matrix of @xmath is

  -- -------- -------- -- --------
     @xmath   @xmath      (5.19)
  -- -------- -------- -- --------

Note that as @xmath is an additive constant in eq. ( 5.17 ), it does not
contribute to this covariance matrix . As a result, eq. ( 5.16 ) can be
rewritten with one single @xmath -dimensional integral instead of @xmath
of them:

  -- -------- -------- -- --------
     @xmath   @xmath      (5.20)
  -- -------- -------- -- --------

We recognize the @xmath -function defined in eq. ( 5.8 ) (with @xmath ,
denoted by the exponent @xmath ) and therefore we can write @xmath in
the simplified functional form

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

Now, let us express the messages @xmath in a simpler form as well. We
start by noting that @xmath and approximate the function by the first
terms of its Taylor series:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (5.22)
  -- -------- -------- -- --------

where the gradient @xmath is taken with respect to @xmath , and @xmath
is the Hessian of @xmath . Around @xmath , we can approximate @xmath by
a multivariate Gaussian:

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

by identifying the coefficients of the Taylor expansion eq. ( 5.22 )
with the Taylor expansion of a Gaussian with @xmath :

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

The expressions obtained by identification are

  -- -------- -------- -- --------
     @xmath   @xmath      (5.25)
     @xmath   @xmath      (5.26)
  -- -------- -------- -- --------

Writing the messages @xmath under the form ( 5.23 ) allows to find a
simpler form for the @xmath messages as well. The product of Gaussians
in

  -- -------- -------- -- --------
     @xmath   @xmath      (5.27)
  -- -------- -------- -- --------

is itself a Gaussian, whose mean and covariance matrix are given in the
appendix by eq. ( A.11 ). Using that formula, we obtain

  -- -------- -------- -- --------
     @xmath   @xmath      (5.28)
  -- -------- -------- -- --------

where

  -- -------- -------- -- --------
     @xmath   @xmath      (5.29)
     @xmath   @xmath      (5.30)
  -- -------- -------- -- --------

This allows to express @xmath and @xmath , the mean and covariance of
@xmath , as

  -- -------- -------- -- --------
     @xmath   @xmath      (5.31)
     @xmath   @xmath      (5.32)
  -- -------- -------- -- --------

These manipulations allow us to implement the BP equations easily. Each
message is entirely characterized by only two parameters: a mean and a
variance, and the AMP algorithm iteratively updates these quantities at
each time step. Algorithm 5 gives a better overview of these update
rules. Initialization and stopping conditions are as in algorithm 2 .

Main loop: while @xmath , calculate for all @xmath :

  -- -------- -------- -------- -------- --
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
  -- -------- -------- -------- -------- --

Algorithm 5 AMP version of vectorial GAMP

###### Step 3: TAP

The AMP algorithm 5 can be simplified by updating only local quantities
instead of messages. This gives a so-called TAP version of the algorithm
with lowered complexity. Remembering the expression of the local
belief ( 2.20 ),

  -- -------- -------- -- --------
     @xmath   @xmath      (5.33)
  -- -------- -------- -- --------

we introduce the local means and variances

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (5.34)
     @xmath   @xmath   @xmath   @xmath      (5.35)
  -- -------- -------- -------- -------- -- --------

and we do the same for the local estimates of @xmath :

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (5.36)
     @xmath   @xmath   @xmath   @xmath      (5.37)
     @xmath   @xmath   @xmath   @xmath      (5.38)
  -- -------- -------- -------- -------- -- --------

We now see that the messages in algorithm 5 differ from the local
quantities only by one single term of order @xmath or @xmath , which
motivates us to write them as a function of the local quantities. The
tricky part for obtaining the TAP equations is to keep the necessary
corrective terms by analyzing their order of magnitude as a function of
@xmath . Let us start the analysis by noting that

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

As a consequence,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (5.40)
  -- -------- -------- -- --------

using the fact that @xmath (See Appendix A.2 ). Let us now look at

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (5.41)
  -- -------- -------- -- --------

and therefore

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (5.42)
  -- -------- -------- -- --------

from which we deduce

  -- -------- -------- -- --------
     @xmath   @xmath      (5.43)
  -- -------- -------- -- --------

From these expansions, let us try to obtain update equations of the
beliefs as a function of only beliefs.

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
                          
              @xmath      (5.44)
  -- -------- -------- -- --------

Here, the important phenomenon is that the second term (called Onsager
term) is of order one. This is due to the fact that the matrix @xmath
has strictly positive diagonal terms. The parenthesis is therefore a sum
of @xmath positive terms of order @xmath and is of order @xmath . The
manipulation with @xmath gives

  -- -------- -------- -- --------
     @xmath   @xmath      (5.45)
  -- -------- -------- -- --------

These two terms therefore differ from the ones one would have obtained
by carelessly replacing all messages by their respective beliefs. At
this point, we neglect all terms that are @xmath and we obtain the TAP
version of vectorial GAMP, algorithm ( 6 ).

Initialize for all @xmath , @xmath and @xmath at random or according to
@xmath .
Main loop: while @xmath , calculate for all @xmath :

  -- -------- -------- -------- -------- --
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
  -- -------- -------- -------- -------- --

Stop when @xmath , @xmath or @xmath .

Algorithm 6 TAP version of vectorial GAMP

The disadvantage of this algorithm is that, on the contrary of GAMP, it
requires a matrix inversion (for the calculation of @xmath ), and that
the update functions require to integrate over multi-dimensional
variables. Other ways of taking into account joint or structured
sparsity exist, for example turbo-GAMP [ 151 ] .

##### 5.1.2 Complex GAMP

Complex GAMP is a special case of algorithm 5 , characterized by the
relations ( 5.6 , 5.7 ). With a few additional assumptions, the
algorithm can be rewritten with only scalars, such that no matrix
inversion is necessary. First, note that all covariance matrices are by
definition of the form

  -- -- -- --------
           (5.46)
  -- -- -- --------

In @xmath and @xmath , covariance matrices are multiplied on the right
and on the left by @xmath , giving a matrix of the form

  -- -- --
        
  -- -- --

Let us focus on the case in which @xmath and @xmath are independent of
each other and distributed as @xmath . We also assume that the values of
@xmath for all @xmath . Then, in the summation over @xmath of the
matrices above,

-   @xmath because @xmath ,

-   @xmath because it is a sum of positive and negative terms,

-   @xmath are the only terms with contributions to leading order.

As a result, the terms that do not contribute in the sum can be ignored
and the summation made over diagonal matrices:

  -- -------- -- --
     @xmath      
  -- -------- -- --

Finally, as only the sum @xmath is necessary here, it is not necessary
to compute the four terms of the covariance matrix, but only @xmath .
Notice that @xmath is now a multiple of identity: the variance of both
the real and the imaginary part of @xmath is @xmath , therefore the
variance of the complex estimate @xmath is @xmath . As a result, let us
redefine the @xmath -functions (for @xmath and @xmath ):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.47)
     @xmath   @xmath   @xmath      (5.48)
     @xmath   @xmath   @xmath      (5.49)
  -- -------- -------- -------- -- --------

as well as the update functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.50)
     @xmath   @xmath   @xmath      (5.51)
  -- -------- -------- -------- -- --------

where @xmath is the circular-symmetric complex Gaussian

  -- -------- -------- -- --------
     @xmath   @xmath      (5.52)
  -- -------- -------- -- --------

Once this is done, all covariance matrices are multiples of the identity
and can therefore be replaced by scalars. Finally, noting that @xmath is
the matrix representation of the complex conjugate @xmath and that
@xmath , the simplified, scalar version of complex GAMP is given
in algorithm 7 .

Initialize for all @xmath , @xmath and @xmath at random or according to
@xmath .
Main loop: while @xmath , calculate for all @xmath :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Stop when @xmath , @xmath or @xmath .

Algorithm 7 c-GAMP

This final version of c-GAMP differs from GAMP only by the magnitudes
@xmath replacing the squares and by the complex conjugate @xmath . For
complex CS, a shorter different derivation of c-GAMP is provided in [ 92
] using expectation propagation.

#### 5.2 CS with fast operators and superpositions codes

In this section, I describe the work published jointly with Jean Barbier
and Florent Krzakala in [ 10 ] , that is in part based on my work on
complex CS.

##### 5.2.1 Complex CS state evolution

The replica analysis is only one way to derive the state evolution
equations of GAMP and c-GAMP. Another way is to use the state evolution
formalism, that analyzes the statistical fluctuations of the quantities
iterated by the algorithm. For the case of compressed sensing, this
analysis is simpler to perform than the replica analysis, and here I
derive it for complex CS using algorithm 7 .

First, let us explicitly write out the AWGN sensing channel in the
complex case:

  -- -------- -------- -- --------
     @xmath   @xmath      (5.53)
  -- -------- -------- -- --------

which results in the update functions

  -- -------- -------- -- --------
     @xmath   @xmath      (5.54)
     @xmath   @xmath      (5.55)
  -- -------- -------- -- --------

which are the same as for real-valued CS. Next, we can make a further
simplification, the so-called “fully-TAP” version of the algorithm, that
is made by approximating every @xmath by @xmath . This can be justified
by noticing that the difference between the quantities calculated using
@xmath and the same quantities with @xmath instead is of order @xmath [
73 ] . This leads to the variances @xmath , @xmath to be
index-independent, and so is @xmath as a consequence:

Main loop: while @xmath , calculate following quantities:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Algorithm 8 Complex CS with scalar variances

Algorithm 8 can be analyzed by examining the statistical fluctuations of
the updated quantities when the elements @xmath have a circular Gaussian
distribution with variance @xmath . First, let us rewrite @xmath
starting from eq. ( 5.34 ) by replacing @xmath by its expression @xmath
:

  -- -------- -------- -- --------
     @xmath   @xmath      (5.56)
              @xmath      (5.57)
              @xmath      (5.58)
  -- -------- -------- -- --------

again, replacing @xmath by @xmath , we obtain the expression

  -- -------- -------- -- --------
     @xmath   @xmath      (5.59)
  -- -------- -------- -- --------

The term @xmath is a random variable of the @xmath elements. It has zero
mean and can be approximated as a complex Gaussian random variable, as
it is the sum of a large number of independent random variables. It can
be verified that under the hypothesis that @xmath , the real and
imaginary parts of @xmath are independent. Therefore @xmath is a
circular Gaussian random variable, and its variance is @xmath , where

  -- -------- -------- -- --------
     @xmath   @xmath      (5.60)
  -- -------- -------- -- --------

is the complex mean squared error at time @xmath . This quantity can be
evaluated at time @xmath by writing

  -- -------- -------- -- --------
     @xmath   @xmath      (5.61)
  -- -------- -------- -- --------

The variance @xmath can be expressed in a similar way by writing

  -- -------- -------- -- --------
     @xmath   @xmath      (5.62)
  -- -------- -------- -- --------

Equations ( 5.61 5.62 ) are the state evolution equations for complex
compressed sensing. Note that in the Bayes-optimal case, the Nishimori
conditions ( 3.71 ) impose that @xmath and the state evolution can thus
be written as a single equation, \marginnote Complex CS state evolution
[0.7cm]

  -- -------- -------- -- --------
     @xmath   @xmath      (5.63)
  -- -------- -------- -- --------

Preliminary results about the state evolution of the “generalized”
setting are presented in Appendix D .

###### Phase diagram for complex CS

Equation ( 5.63 ) allows to theoretically obtain the phase transitions
of Bayes optimal c-GAMP. In Fig. 5.2 , we consider two signal
distributions:

  -- -------- -------- -- --------
     @xmath   @xmath      (5.64)
     @xmath   @xmath      (5.65)
  -- -------- -------- -- --------

which we call the joint and the independent Gauss-Bernoulli
distribution. For @xmath , c-GAMP treats the real and imaginary parts of
the signal independently using the update functions already given
in example LABEL:ex:csGAMP . For @xmath , the update functions @xmath
take a complex argument @xmath and a real argument @xmath . Their
expressions are identical to the ones in example LABEL:ex:csGAMP
replacing @xmath by @xmath and @xmath by @xmath . On Fig. 5.2 , the
theoretical “GAMP” and “c-GAMP” transitions correspond to @xmath and
@xmath respectively. The diagram shows that taking into account the
joint sparsity allows to increase the size of the region of possible
recovery.

Another complex CS algorithm exploiting joint sparsity has been proposed
in [ 88 ] under the name of CAMP. Very similar to algorithm 6 , it
solves the complex LASSO (c-LASSO) problem

  -- -------- -- --------
     @xmath      (5.66)
  -- -------- -- --------

when @xmath , where @xmath is the complex @xmath norm: @xmath . It can
be implemented with algorithm 8 using the update functions

  -- -------- -------- -- --------
     @xmath   @xmath      (5.67)
     @xmath   @xmath      (5.68)
  -- -------- -------- -- --------

The corresponding state evolution is given in [ 88 ] and leads to the
“c-LASSO” transition on Fig. 5.2 . As it takes into account joint
sparsity, it allows lowering the “LASSO” phase transition.

##### 5.2.2 Compressed sensing with fast operators

The main focus in [ 10 ] is the study of CS with structured operators as
measurement matrices, namely Hadamard operators for real-valued CS and
Fourier operators for complex-valued CS. The characteristics of these
operators are that

1.  They are not random but deterministic and in that sense structured .
    Hadamard operators are represented by a matrix with whose entries
    are @xmath . Fourier matrices have only matrix elements of the form
    @xmath . Both are orthogonal matrices.

2.  They do not need to be stored in memory (as they are constructed on
    a very simple scheme) and can be applied to vectors of size @xmath
    in only @xmath operations—instead of @xmath operations for matrix
    multiplication. These two combined properties allow to treat signals
    of much bigger size and in a significantly shorter time than with
    non-structured measurement matrices.

The main finding is that empirically, despite violating the usual
randomness assumption, both Hadamard and Fourier operators are good
matrices for CS and ensure convergence just as well as random matrices.
However, they do not follow the state evolution but instead converge
faster to the solution, as seen on Fig. 5.2(a) . This is not astonishing
as the derivation of state evolution is made with the hypothesis of
matrices with i.i.d. elements. The fact that convergence is faster is
likely due to the fact that Fourier and Hadamard matrices are
orthogonal, which is not exactly the case for random matrices.

##### 5.2.3 Superposition codes

The second focus of [ 10 ] is the application of GAMP to superposition
codes.

###### The signal

In superposition codes, the goal is to transmit a message @xmath through
an AWGN channel with noise variance @xmath . @xmath is a finite alphabet
with @xmath elements and one way to represent its @xmath -th element is
to write it as a vector:

  -- -------- -- --------
     @xmath      (5.69)
  -- -------- -- --------

We call @xmath and @xmath the vector that is the concatenation of all
@xmath @xmath ’s. It has @xmath sections @xmath of size @xmath each.

###### The code

Coding @xmath is made by multiplying @xmath with a matrix @xmath that
has as usual random i.i.d. entries:

  -- -------- -- --------
     @xmath      (5.70)
  -- -------- -- --------

and the receptor gets a version of it corrupted by AWGN:

  -- -------- -- --------
     @xmath      (5.71)
  -- -------- -- --------

###### Message passing decoder

The setting is extremely similar to CS, with the difference that each of
the @xmath sections of the signal @xmath is sampled from the
distribution

  -- -------- -------- -- --------
     @xmath   @xmath      (5.72)
  -- -------- -------- -- --------

As in complex CS, the components of @xmath are therefore not
independent, which has to be taken into account using a vectorial
version of GAMP. In the notations of sec. 5.1.1 , we have @xmath and
@xmath . Equation ( 5.70 ) can be written as

  -- -------- -- --------
     @xmath      (5.73)
  -- -------- -- --------

with @xmath . In algorithm 6 , @xmath and @xmath are actually scalars,
and it is easy to show that in the large @xmath limit, @xmath is
diagonal. As a result, the matrix formalism of algorithm 6 can be
dropped for all quantities except for the update functions @xmath .
Using the prior ( 5.72 ), they result in the new updates

  -- -------- -------- -- --------
     @xmath   @xmath      (5.74)
     @xmath   @xmath      (5.75)
  -- -------- -------- -- --------

The constraint imposed by the prior ( 5.72 ) is much stronger than the
one in compressed sensing, as it enforces binary values on the signal
components. For this reason, perfect signal reconstruction might be
possible even in a noisy setting.

This message passing decoder was derived in [ 8 ] along with the
corresponding replica analysis and state evolution equations. As for
real and complex variables, state evolution equations for vectorial
variables can be demonstrated rigorously [ 64 ] . Both the replica
theory and the experimental results, presented in [ 8 , 9 , 7 ] show
that using a specially designed type of spatially coupled measurement
matrices, this decoder is capacity-achieving : it allows transmission of
information at the highest theoretically possible rate through an AWGN
channel.

#### 5.3 Phase retrieval

One interesting application of GAMP with complex signals is the problem
of phase retrieval.

###### Setting

In phase retrieval, signal and matrix are complex, but measurements only
provide the magnitude of @xmath :

  -- -------- -- --------
     @xmath      (5.76)
  -- -------- -- --------

and considering a setting with complex noise before the measurements,

  -- -------- -- --------
     @xmath      (5.77)
  -- -------- -- --------

###### Invariances

Just like the bilinear inference problems presented in chapter 4 , phase
retrieval has an invariance that cannot be lifted: invariance up to a
global phase. As the phase is lost during measurements, it is easy to
see that the signals @xmath and @xmath produce the same measurements
@xmath . Therefore, the usual MSE is not an appropriate measure of
success. Instead, one can use the normalized cross-correlation for
complex signals:

  -- -------- -- --------
     @xmath      (5.78)
  -- -------- -- --------

where @xmath indicates the complex transpose, or the normalized mean
square error

  -- -------- -- --------
     @xmath      (5.79)
  -- -------- -- --------

###### Phase retrieval GAMP

In [ 128 ] , the authors use c-GAMP for the phase retrieval problem.
This is done by considering the probability distribution corresponding
to eq. ( 5.77 ),

  -- -------- -------- -- --------
     @xmath   @xmath      (5.80)
  -- -------- -------- -- --------

and the corresponding functions

  -- -------- -------- -- --------
     @xmath   @xmath      (5.81)
     @xmath   @xmath      (5.82)
     @xmath   @xmath      (5.83)
  -- -------- -------- -- --------

where @xmath are the modified Bessel functions of the first kind,

  -- -------- -------- -- --------
     @xmath   @xmath      (5.84)
     @xmath   @xmath      (5.85)
  -- -------- -------- -- --------

###### Convergence

Unfortunately, phase-retrieval GAMP encounters convergence problems that
are very similar to the ones of GAMP for CS with non zero-mean matrices.
In particular, note that the variances @xmath in algorithm 7 can take
negative values if no damping is used, at which point the algorithm
diverges. An additional damping scheme is therefore required, described
in [ 128 ] . The resulting algorithm is called PR-GAMP.

Additionally to damping, another way to improve convergence is learning
the sparsity and the variance of the prior @xmath with
expectation-maximization, as done in [ 73 ] . Even when they are known,
learning them instead of imposing them increases the stability of the
algorithm in many cases.

A general observation that can made is that PR-GAMP solves non-sparse
problems more efficiently than sparse problems. This is illustrated
by Fig. 5.5 : for @xmath , PR-GAMP works with little damping and the
phase transition is at @xmath . On the other hand, for @xmath and @xmath
, a lot of damping is necessary and the time to converge varies a lot
from instance to instance. In many cases, the algorithm does not
converge at all, such that it is not possible to define a clear phase
transition. The authors of [ 128 ] propose to restart PR-GAMP from a
different initialization if it does not converge and can in this way
produce experimental phase diagrams.

##### 5.3.1 Imaging through scattering media

In [ 43 ] , we propose to apply phase retrieval techniques to the
challenge of imaging through scattering media.

###### Scattering media and transmission matrix formalism

In a scattering medium—such as fog or turbid water for
example—transmitted light is not only attenuated: Photons crossing the
medium are scattered multiple times by particles or impurities of the
medium, thereby changing their trajectories (Fig. 5.6 ). As a result,
the outgoing wavefront is radically different from the incoming
wavefront: Seeing or imaging through such a medium is impossible.

Sending parallel coherent light on the medium produces a so called
speckle pattern which is the result of the interferences between the
photons leaving the medium. Just as diffraction patterns in x-ray
crystallography reflect crystalline structures, speckles reflect the
randomness of scattering media. Despite its randomness, the system can
be described in a simple way by its (complex-valued) transmission matrix
@xmath . Discretizing a plane of incoming light and of outgoing light,
the electromagnetic fields can be written as a (complex) incoming vector
@xmath and an outgoing vector @xmath , linked by the relation

  -- -------- -------- -- --------
     @xmath   @xmath      (5.86)
  -- -------- -------- -- --------

With this relation, imaging through scattering media becomes a simple
linear estimation problem.

###### Challenges and solutions

Despite the simple formula ( 5.86 ), both theoretical and practical
difficulties exist. Taking these into account, the experimental setup of
[ 43 ] is shown on Fig. 5.7 .

###### Calibration through incoming light modulation.

First of all, the transmission matrix @xmath needs to be determined for
each sample of scattering material. This can be done in a supervised
calibration step prior to imaging, by measuring the outputs of known
input signals. It is therefore necessary to modulate the incoming light
in a controlled way. This can be done with spatial light modulators ,
that can dephase light pixel by pixel [ 99 ] . The limit of this device
is that it is relatively slow (few tens of Hertz).

In [ 43 ] , a digital micromirror device (DMD) is used instead [ 127 ] .
It is an array of @xmath tilting micromirrors, that either project the
light to the scattering medium or not, depending on their position.
Unlike spatial light modulators, the phase of the light cannot be
controlled, but only its intensity, in a binary way. This limitation is
compensated by the higher functioning speed (over @xmath kHz).

###### Medium stability.

It is of crucial importance that the material is stable enough for
@xmath to vary on time scales large enough to allow both calibration and
imaging. For this reason, imaging through turbid liquids or gases—in
which Brownian motion is present—seems for now impossible. In biological
tissues, the stability time is about a few milliseconds. Therefore, in [
43 ] , a @xmath microns thick layer of white paint is used: thick enough
to mix the light and produce a complex interference pattern, it
transmits sufficient intensities for imaging and is stable enough for
@xmath to vary only weakly over a period of several minutes.

###### Phase problem.

Equation ( 5.86 ) is complex-valued. However, a CCD camera cannot
capture the complex vector @xmath , but only its intensity

  -- -------- -- --------
     @xmath      (5.87)
  -- -------- -- --------

Previous works have use reference beams in order to indirectly access
the phase of @xmath [ 111 , 32 , 30 ] . This requires an interferometric
setup, which is by nature very sensible to external perturbations. In [
43 ] instead, we use phase retrieval, allowing for a simpler
experimental setup (see Fig. 5.7 ).

###### Calibrating, imaging and focusing

###### Calibration

The determination of @xmath in a supervised calibration step can be
recast into an inference problem, just as the perceptron problem (sec.
3.5.2 ) was recast into a 1-bit CS problem. The supervised calibration
consists in measuring the outputs @xmath of @xmath different, known
inputs @xmath . Transposing the system, calibration is equivalent to
solving the inference problem

  -- -------- -- --------
     @xmath      (5.88)
  -- -------- -- --------

in which @xmath is considered as a measurement matrix and @xmath as a
signal to infer. Note that:

-   The columns of @xmath correspond to the individual pixel of the CCD
    camera and can be treated independently. No sparsity assumption is
    made on @xmath , a Gaussian prior is used instead.

-   The measurement matrix @xmath is composed of binary entries and does
    not have zero mean. This setting is not favorable to the use of
    GAMP, though such matrices can be handled using appropriate damping
    schemes [ 139 ] .

-   The measurement matrix @xmath being real, an additional invariance
    by complex conjugation prevents unique recovery of a signal. As for
    the global phase invariance, this has no effect on the algorithm’s
    performances, but has to be kept in mind during tests on synthetic
    signals.

The results presented in [ 43 ] speak in favor of good reconstruction
performances of the transmission matrix @xmath . This is verified by
looking at the nMSE between @xmath and @xmath , where @xmath is the
estimation of @xmath returned by the algorithm. Additionally to PR-GAMP,
several other algorithms were tested and the prVBEM algorithm [ 42 ] was
retained for its increased robustness compared to PR-GAMP.

The estimated transmission matrices @xmath have entries that follow a
circular Gaussian distribution, which is checked by looking at the
distribution of their eigenvalues, that approximately follow a
Marcenko-Pastur law. This makes @xmath an ideal matrix for imaging with
PR-GAMP or other compressive phase retrieval algorithms.

###### Imaging

Once the transmission matrix of a medium is determined, imaging
experiments can be made, i.e. experiments in which the incoming image
@xmath is unknown and has to be recovered using @xmath . In the work
leading to [ 43 ] , compressive imaging experiments were not successful.
This is likely due to insufficient quality of the estimation of @xmath .
In a follow-up work [ 112 ] , calibration of the matrix is performed
using a modified version of PR-GAMP, allowing more precise estimation of
@xmath and successful imaging experiments.

###### Focusing

The knowledge of the transmission matrix @xmath can as well be used for
focusing through a multiply scattering medium. This is achieved by
creating an input pattern @xmath with the DMD that creates an output
image with one or several points of high intensity. Focusing is an
optimization problem, but can also be treated a noisy inference problem:
searching for an @xmath that produces an output as close as possible to
the desired @xmath . Figure 5.8 shows the result of a focusing
experiment presented in [ 43 ] . The intensity reached on the three
target points is about an order of magnitude higher than the background
intensity. The success of the focusing experiment is an indication of
the quality of the estimation of @xmath .

#### 5.4 Conclusion

In this chapter, I have proposed a version of GAMP for vectorial
variables. Among other possible uses, it allows a derivation of
complex-valued GAMP.

Furthermore, I present two applications of GAMP to the concrete problems
of coding and imaging through multiply scattering media. The former
application makes use of phase retrieval GAMP, which is an example in
which converge of GAMP is not systematic and is not yet fully
understood.

### Chapter 6 Blind sensor calibration

In chapter 4 , I introduced the blind gain calibration problem as a
bilinear inference problem, which can be treated using a convex
formulation. In [ 129 , 130 ] , I derive a Bayesian message passing
algorithm for blind calibration, called Cal-AMP and assess its
performances experimentally.

Just like GAMP, Cal-AMP allows to handle non-linearities in the
measurement process and thus to consider a more general type of
calibration. Besides real and complex gain calibration, I have
investigated two further examples of blind sensor calibration: the
faulty sensors problem and 1-bit threshold calibration.

#### 6.1 Setting

In addition to the theoretical interest raised by the discovery of phase
transitions in CS, compressed sensing is already used both in
experimental research and in real world applications such as medical
imaging [ 86 ] , in which it can lead to significant improvements. One
issue that can arise in real-world applications of CS is a lack of
knowledge or an uncertainty regarding the exact measurement process.
Even when the measurement matrix @xmath of the mixing process is
perfectly known, the sensing process might not exactly be known, as
physical sensors are subject to failure, distortion or miscalibration.
As explained in chapter 4 in the context of gain calibration, supervised
calibration of the sensors might not always be possible, in which case
blind calibration procedures are necessary. Several algorithms have been
proposed for blind sensor calibration in the case of unknown
multiplicative gains, relying on convex optimization [ 53 , 18 ] .

The Cal-AMP algorithm proposed in [ 129 , 130 ] is based on GAMP and is
therefore not restricted to gain calibration. We consider the
measurement process illustrated by Fig. 6.1 , in which each measurement
@xmath is generated from @xmath and a sensor-dependent calibration
parameter @xmath :

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

#### 6.2 Cal-AMP

A detailed derivation of Cal-AMP is provided in [ 130 ] . As it is very
similar to other derivations of message-passing algorithms (in
particular the one provided for vectorial GAMP in chapter 5 ), I will
only describe the differences to the latter.

##### 6.2.1 Derivation

First of all, the posterior distribution that is the starting point of
Cal-AMP is

  -- -------- -------- -- -------
     @xmath   @xmath      (6.2)
  -- -------- -------- -- -------

The factor graph representing this distribution is presented on Fig. 6.2
. Compared to the factor graph on Fig. 5.1 , this factor graph has one
additional type of messages that link the calibration parameters to the
measurements. Furthermore, a set of @xmath signals is considered,
instead of just one signal, and as the measurements of all these signals
are produced with the same calibration parameters @xmath , inference can
be possible if @xmath is large enough. The derivation of Cal-AMP follows
the same three steps as explained in Table 3.1 and detailed in chapter 5
.

###### Step 1: BP

We first write the BP equations for the two types of messages. For the
signal variables, we have

  -- -------- -------- -- -------
     @xmath   @xmath      (6.3)
     @xmath               (6.4)
  -- -------- -------- -- -------

and for the calibration variables,

  -- -------- -------- -- -------
     @xmath   @xmath      (6.5)
     @xmath   @xmath      (6.6)
  -- -------- -------- -- -------

###### Step 2: AMP

In order to make the BP equations tractable, we use the central limit
theorem to approximate @xmath by a Gaussian random variable. We obtain

  -- -------- -------- -- -------
     @xmath   @xmath      (6.7)
     @xmath   @xmath      (6.8)
  -- -------- -------- -- -------

with the usual @xmath and

  -- -------- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath   @xmath      (6.9)
  -- -------- -------- -------- -------- -- -------

in which @xmath are the mean and variance of the message @xmath . These
can be expressed as a function of estimators at an earlier time step,
which allows to have iterative updates of means and variances only:

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.10)
  -- -------- -------- -------- -------- -- --------

with

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.11)
     @xmath   @xmath   @xmath   @xmath      (6.12)
  -- -------- -------- -------- -------- -- --------

The only difference with GAMP is that the functions @xmath are replaced
by @xmath that are functions of vectors @xmath , whose components are
given by:

  -- -------- -------- -- --------
     @xmath   @xmath      (6.13)
     @xmath   @xmath      (6.14)
  -- -------- -------- -- --------

Just as @xmath are defined from the functions @xmath with ( 5.13 , 5.14
), @xmath are defined from

  -- -------- -------- -- --------
     @xmath   @xmath      (6.15)
  -- -------- -------- -- --------

for @xmath . Note a slight difference in the time indices compared to [
130 ] , which turns out not to matter in practice.

###### Step 3: TAP

The resulting AMP algorithm can be brought into a TAP version by
expressing messages as a function of beliefs and keeping the “Onsager”
terms that appear. The resulting Cal-AMP is presented in algorithm 9 .

Initialize @xmath and @xmath at random or according to @xmath .
Main loop: while @xmath , calculate following quantities:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Stop when @xmath , @xmath or @xmath .

Algorithm 9 Cal-AMP

##### 6.2.2 Comparison to GAMP

The only difference between GAMP (algorithm 2 ) and Cal-AMP are that

1.  in GAMP, the updated quantities are vectors, whereas in Cal-AMP,
    they are matrices, which are the concatenation of @xmath vectors.

2.  the update functions @xmath are replaced by @xmath .

For @xmath , Cal-AMP is strictly identical to GAMP, with

  -- -------- -------- -- --------
     @xmath   @xmath      (6.16)
  -- -------- -------- -- --------

For @xmath , the step involving @xmath and @xmath is the only one in
which the @xmath signals are not treated independently. If it is
possible to perform perfect calibration of the sensors in a supervised
way, the prior @xmath can be replaced by @xmath , thus @xmath can be
calculated independently for each of the @xmath signals and Cal-AMP is
identical to GAMP with perfectly calibrated sensors.

###### Damping scheme

As for GAMP, the stability of Cal-AMP can be improved by damping some of
the variables. One can for example use the damping scheme proposed in [
58 ] , which corresponds to damping the variances @xmath and the means
@xmath as follows:

  -- -------- -------- -- --------
     @xmath   @xmath      (6.17)
     @xmath   @xmath      (6.18)
  -- -------- -------- -- --------

where @xmath , @xmath and the quantities with index @xmath are before
damping.

#### 6.3 Case studies

In this section we numerically investigate several particular settings
of blind sensor calibration.

##### 6.3.1 Gain calibration

Gain calibration was introduced in sec. 4.1 : each sensor multiplies the
component @xmath by an unknown gain @xmath . In noisy, complex gain
calibration, the measurement @xmath is produced as follows:

  -- -------- -------- -- --------
     @xmath   @xmath      (6.19)
  -- -------- -------- -- --------

The choice of dividing instead of multiplying by the gain @xmath simply
comes from the fact that this makes the calculation of @xmath easier. In
fact,

  -- -------- -------- -- --------
     @xmath   @xmath      (6.20)
  -- -------- -------- -- --------

and therefore

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.21)
  -- -------- -------- -------- -------- -- --------

where

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.22)
     @xmath   @xmath   @xmath   @xmath      (6.23)
  -- -------- -------- -------- -------- -- --------

###### Real gain calibration

For real gain calibration, Fig. 6.3 shows the experimental phase
diagrams obtained for a Gauss-Bernoulli distributed signal and gains
uniformly distributed around @xmath with a width @xmath :

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.24)
  -- -------- -------- -------- -------- -- --------

with @xmath . For such a distribution of gains, the update functions
@xmath can be expressed analytically using

  -- -------- -------- -- --------
     @xmath   @xmath      (6.25)
  -- -------- -------- -- --------

where the function @xmath is defined in appendix A.2 . A damping
coefficient of @xmath was used, increasing the stability of the
algorithm while not slowing it down significantly.

Note that the fact that this prior has a bounded support can lead to a
bad behaviour of the algorithm. Using a slightly bigger @xmath in the
prior than in the real distribution of gains (by a factor @xmath in our
implementation) solves this issue.

The exact position of the phase transition depends on the amplitude
@xmath of the decalibration. Figure 6.3(a) shows how the empirical phase
transition approaches @xmath when @xmath , i.e. @xmath for all @xmath .

In Fig. 6.5 we compare the performances of Cal-AMP and of the convex
optimization approach of [ 53 ] (see sec. 4.1.1 ). The convex algorithm
can easily be implemented using the CVX package [ 52 , 51 ] . The figure
shows that Cal-AMP requires significantly less measurements for a
successful reconstruction, especially for small @xmath . This is similar
to the improvement that Bayes optimal GAMP allows in CS over LASSO.
Furthermore, as shown on Fig. 6.3(b) , Cal-AMP is significantly faster
than the @xmath algorithm implemented with CVX.

###### Complex gain calibration

Cal-AMP can be extended to the case of complex signals and gains in the
same way as c-GAMP was derived in chapter 5 . The only change
in algorithm 9 is that @xmath indicates complex transposition.
Furthermore, the update functions are calculated with integrals over
complex variables.

Complex gains are particularly useful: As often, the physical signal to
measure is a propagating wave (sound or light), it is best represented
by a complex number. Complex gains allow to take into account both
amplitude gains introduced by sensors and shifts of phases. A particular
case of complex gain calibration is therefore phase calibration , in
which the complex gain has known amplitude and unknown phase.

For the experimental results presented on Fig. 6.6 , the signal follows
a complex Gauss-Bernoulli distribution and the complex gains a complex
Gaussian distribution:

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.26)
  -- -------- -------- -------- -------- -- --------

In the algorithm, the update functions used for the calibration
parameters are

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.27)
  -- -------- -------- -------- -------- -- --------

Simpler than the Bayes optimal update functions, they lead to good
results. Note that @xmath takes over the phase estimated by @xmath , as
the prior on the phase is flat. Just like for real gain calibration, the
empirical phase transition is quite close to the lower bounds imposed by
the counting bound @xmath and the perfectly calibrated algorithm.

##### 6.3.2 Faulty sensors

A different example of blind sensor calibration which it might not be
possible to recast into a convex minimization problem is the faulty
sensors problem. Without sparsity, this problem was treated in the
context of wireless sensor networks, for example in [ 84 , 47 ] . For a
single signal, @xmath , it was also treated using GAMP in [ 152 ] .

We assume that a fraction @xmath of sensors is faulty (characterized by
@xmath ) and only records noise @xmath , whereas the other sensors
(characterized by @xmath ) are functional and record @xmath . We then
have

  -- -------- -------- -- --------
     @xmath   @xmath      (6.28)
     @xmath   @xmath      (6.29)
  -- -------- -------- -- --------

which leads to analytical expressions for the estimators @xmath :

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.30)
  -- -------- -------- -------- -------- -- --------

with

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (6.31)
  -- -------- -------- -------- -------- -- --------

It is not known which sensors are functional and which ones are faulty.

If @xmath and @xmath are sufficiently different from the mean and
variance of the measurements taken by functional sensors, the problem
can be expected to be easy. If not, nothing indicates a priori which
sensors are functional and which ones are faulty. The algorithm thus has
to solve a problem of combinatorial optimization consisting in finding
which sensors are faulty.

###### Perfect calibration

If the sensors can be calibrated beforehand, i.e. it is known which
sensors are faulty, then the problem can be solved by a CS algorithm by
simply discarding the faulty sensors. This leads to an effective
measurement rate @xmath , and the algorithm would succeed when @xmath .
Therefore a perfectly calibrated algorithm would have a phase transition
at

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

###### Experimental phase diagram

Results of numerical experiments are shown on Fig. 6.7 . The signals
have a Gauss-Bernoulli distribution, and we consider the hardest case in
which @xmath and @xmath : the statistics of measurements taken by faulty
and functional sensors are identical. In some cases, @xmath signal is
sufficient for correct reconstruction, in which case GAMP can be used.
However, using Cal-AMP and increasing @xmath allows to close the gap to
the performances of a perfectly calibrated algorithm.

##### 6.3.3 1-bit threshold calibration

A last example of application of Cal-AMP is @xmath -bit CS with unknown
thresholds. The basic setting is the same as the one presented in sec.
3.5 , with the difference that the thresholds @xmath are unknown:

  -- -------- -------- -- --------
     @xmath   @xmath      (6.33)
  -- -------- -------- -- --------

where the thresholds are distributed following a distribution @xmath and
the noise @xmath .

###### Uncalibrated GAMP

A first approach is to ignore the thresholds, that is to run GAMP
considering them to be zero. Then the thresholds can be incorporated
into the noise, with a higher variance than @xmath (and only Gaussian if
@xmath is). Figure 3.6(b) shows the degradation of reconstruction
performances with increasing noise: if the variance of @xmath is bigger
than @xmath , we can expect reconstruction performances to be
significantly degraded.

###### Perfect calibration

If the thresholds are known, GAMP can be used to make inference
using eq. ( 3.85 ). The reconstruction performance depends on the
distribution @xmath and is best when all thresholds are zero, which
comes from the fact that the mean of @xmath is zero.

###### Experimental setting using Cal-AMP

The update functions for Cal-AMP are obtained using

  -- -------- -------- -- --------
     @xmath   @xmath      (6.34)
  -- -------- -------- -- --------

and eq. ( 6.15 ). As the integrals in eq. ( 6.15 ) need to be
numerically evaluated for most distributions @xmath , we restrict our
study to the simple case where @xmath has multiple discrete values:

  -- -------- -------- -- --------
     @xmath   @xmath      (6.35)
  -- -------- -------- -- --------

for which the integrals reduce to finite sums. Figure 6.8 shows results
using @xmath , @xmath and equidistant @xmath s in the interval @xmath .
As in the other blind calibration settings considered, Cal-AMP allows to
approach the performance of a perfectly calibrated algorithm by
increasing @xmath .

Figure 6.9 shows results for a uniform distribution of thresholds

  -- -------- -------- -- --------
     @xmath   @xmath      (6.36)
  -- -------- -------- -- --------

Instead of numerically estimating the integrals necessary for the Bayes
optimal update functions, we use the mismatching prior of eq. ( 6.35 )
using @xmath and @xmath , @xmath and equidistant @xmath s in the
interval @xmath . Increasing @xmath and @xmath allows to approach the
results of a perfectly calibrated algorithm.

#### 6.4 Encountered issues

In addition to the results published in [ 129 , 130 ] and to the study
of threshold calibration presented in this chapter, I have worked on
applying Cal-AMP to blind deconvolution and on deriving the state
evolution of Cal-AMP. I have come across multiple issues in both of
these tasks, which I describe in this section.

##### 6.4.1 Blind deconvolution

As shown in application LABEL:appli:blindDeconvolution , the problem of
blind deconvolution is very closely linked to the problem of complex
blind gain calibration. Despite this fact, I could not successfully use
Cal-AMP for blind deconvolution.

The reason for this is the fact that if @xmath is the convolution
kernel, then as formulated in eq. ( 6.19 ), @xmath , where @xmath is the
discrete Fourier transform. Although the coefficients of a typical
convolution kernel @xmath can be approximated by simple pdfs, the
corresponding distributions for @xmath do not have simple expressions.

Furthermore, a typical convolution kernel has some coefficients close to
zero, some other close to one, and its Fourier transform as well. This
results in coefficients of @xmath with a very big range of magnitudes. A
prior taking this into account has such a big variance that blind
calibration does not seem to work. Another consequence of this big range
of magnitudes is that the matrix @xmath is ill-conditioned (as explained
in example LABEL:ex:linearMeasurements ), which is the source of
additional problems.

Also, in a noisy setting, if @xmath has a very large amplitude, @xmath
is basically noise, and these measurements carry no information at all.
The theoretically achievable bounds for blind deconvolution are
therefore very different from those for blind complex gain calibration [
83 ] .

For these reasons, a more promising approach to blind deconvolution
seems to be to treat it with a different factor graph in which the
variables are the signals and the convolution kernel. The associated
@xmath functions are similar to those for the blind gain calibration
problem with @xmath : They do not have analytical expressions. A blind
deconvolution algorithm similar to Cal-AMP would require some more work
to solve this issue.

##### 6.4.2 State evolution

Just as for GAMP and BiGAMP, it should be possible to describe the
behaviour of Cal-AMP with state evolution equations. This would allow to
predict the position of the phase transitions observed experimentally
and to gain a better understanding of the specific settings studied. I
have used three different approaches:

-   Initially I have concentrated my efforts on the state evolution of
    the real gain calibration setting, starting from the algorithm (as
    done for complex CS in sec. 5.2.1 ). However, the statistical
    fluctuations of the quantities appearing in Cal-AMP are more
    difficult to describe than those in GAMP for CS. In the analysis
    done in sec. 5.2.1 , the fluctuations can be described by a Gaussian
    distribution. In real gain calibration, the fluctuations of the
    interesting quantities are more complex as they depend on a finite
    number @xmath of variables with different distributions. Despite
    finding a few simplifications, I could not obtain a set of state
    evolution equations that matched the algorithm’s behaviour.

-   A second attempt was made using population dynamics . Unlike state
    evolution, population dynamics does not give a simple closed set of
    equations that describes the algorithm’s behaviour, but rather
    simulates its average behaviour. I could apply this approach
    successfully to CS GAMP, but not to blind gain calibration.

-   Finally, I have used the replica method to derive the state
    evolution equations of the most general blind sensor calibration
    setting, as in sec. 3.3 for GAMP. Preliminary results are briefly
    presented in Appendix C . Just as the state evolution equations of
    GAMP ( 3.66 – 3.68 ) require integration over 2 variables, the state
    evolution equations for blind sensor calibration in general require
    integration over @xmath variables. Finding an efficient and reliable
    way to perform these integrations numerically should in principle
    confirm the phase transitions observed empirically.

It can come as a surprise that the state evolution equations of
generalized matrix factorization ( 4.29 – 4.31 ) require integration
over 2 variables only, as the state evolution equations of GAMP, whereas
those of Cal-AMP require integration over @xmath variables. An
explanation for this is that in generalized matrix factorization, we
consider the limit @xmath , which allows to use the central limit
theorem and replace @xmath integrals by a single one. On the other hand,
in blind sensor calibration @xmath remains finite and therefore there is
no general way of reducing the number of integrals.

#### 6.5 Conclusion

In this chapter, the problem of blind gain calibration has been treated
in a more general setting called blind sensor calibration. I derived a
Bayesian message-passing algorithm called Cal-AMP in [ 129 , 130 ] .
Experimental results of Cal-AMP in several different settings of blind
sensor calibration are presented in this chapter. In the examples
studied, Cal-AMP converges very reliably to the solution, just as GAMP
does for CS: The convergence issues present in BiGAMP for matrix
factorization are not present in blind gain calibration. The versatility
of the blind sensor calibration setting could allow the use of Cal-AMP
in concrete applications such as astronomical imaging.

### Chapter 7 Analysis of matrix compressed sensing

In chapter 4 , I introduced matrix compressed sensing as a bilinear
inference problem. In this chapter, I perform the replica analysis of
matrix compressed sensing in a probabilistic framework. As for
generalized linear models and matrix factorization, the analysis
produces state evolution equations that describe the asymptotic
performance that can be reached in Bayesian inference of matrix
compressed sensing. These theoretical results are compared to the
performance of the recently introduced PBiGAMP [ 109 ] algorithm, that
are in good agreement. These results are presented in [ 132 ] .
Furthermore, I analyse an instability of the Nishimori line in bilinear
inference problems that explains the fragility of convergence in the
BiGAMP and PBiGAMP algorithms.

Our analysis reveals a striking connection between the matrix compressed
sensing problem and the problem of matrix factorization as studied in [
67 ] . These are two different inference problems. In matrix compressed
sensing we observe a set of element-wise linear projections of the
matrix, whereas in matrix factorization we observe the elements of the
matrix directly. Yet the replica analysis of the two problems yields
equivalent equations and hence the asymptotic behaviour of the two
problems, including the phase transition, is closely linked. This
analogy was already remarked for the nuclear norm minimization in matrix
compressed sensing and matrix denoising in [ 40 ] , or for matrix
compressed sensing and matrix completion [ 118 ] .

#### 7.1 Matrix compressed sensing

We consider the setting described in sec. 4.3 , summarized by Fig. 7.1 .
Note that we replace the usual @xmath by @xmath in order to signify it
is a rank.

###### The probabilistic model and assumptions of our analysis.

In order to enable the asymptotic analysis via the replica method we
introduce the following probabilistic model for matrix compressed
sensing.

-   We assume that elements of @xmath and @xmath are sampled
    independently at random such that

      -- -------- -------- -------- -------- -- -------
         @xmath   @xmath   @xmath   @xmath      (7.1)
      -- -------- -------- -------- -------- -- -------

    We assume the distributions @xmath and @xmath to have zero mean and
    respective variances @xmath and @xmath of order one. These
    distributions might not be known exactly: instead, we use zero-mean
    priors @xmath and @xmath believed to be close to @xmath and @xmath .

-   We assume the output distribution @xmath to be separable:

      -- -------- -- -------
         @xmath      (7.2)
      -- -------- -- -------

    In the inference we use a separable distribution @xmath we believe
    to be close to it.

-   We assume the matrix @xmath of the linear operator @xmath to have
    normally distributed i.i.d. elements with zero mean and variance
    @xmath , such that the elements of @xmath have zero mean and
    variance one. This is the same assumption as is often made in
    compressed sensing, and differentiates the problem from matrix
    factorization, in which @xmath is the identity.

-   We assume the dimensions @xmath , @xmath and @xmath to be large, but
    their following ratios to be of order one:

      -- -------- -------- -------- -------- -------- -------- -------- -------- -- -------
         @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.3)
      -- -------- -------- -------- -------- -------- -------- -------- -------- -- -------

    On the other hand, @xmath can be small. @xmath is a measurement
    ratio as in CS: it is the ratio between the number of measurements
    and the number of unknowns.

###### Measures of recovery

As in matrix factorization, there is an inherent ill-posedness when it
comes to recovering the couple @xmath . As a matter of fact, for any
@xmath invertible matrix @xmath , the couple @xmath generates the same
@xmath as @xmath . In some case, this ill-posedness can be lifted thanks
to the distributions @xmath and @xmath , but this is not always the case
and might nevertheless be cause of trouble. In that case, it is possible
to have a very low @xmath but high @xmath and @xmath .

A way to remove one degree of invariance is to consider the normalized
mean squared errors

  -- -------- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath   @xmath      (7.4)
  -- -------- -------- -------- -------- -- -------

which absorbs the scaling invariance by positive multiplicative scalars,
as in eq. ( 4.6 ).

##### 7.1.1 Notations

If @xmath is a linear operator and @xmath its matrix, we write @xmath
for the linear operator associated to @xmath . Using the matrix @xmath ,
we can define two auxiliary linear operators @xmath and @xmath such that

  -- -------- -------- -- -------
     @xmath   @xmath      (7.5)
     @xmath   @xmath      (7.6)
  -- -------- -------- -- -------

##### 7.1.2 Message-passing algorithm

As done in chapter 5 for generalized linear models and in chapter 6 , we
derive a Bayesian inference algorithm using belief propagation, starting
from the posterior probability

  -- -------- -------- -- -------
     @xmath   @xmath      (7.7)
              @xmath      
  -- -------- -------- -- -------

that is represented by the factor graph on Fig. 7.2 . As the derivation
is very similar to the one done in chapter 5 , only the main steps are
explained here. The full derivation can be found in [ 132 ] .

###### Step 1: BP

As in blind sensor calibration, there are two types of message pairs
@xmath and @xmath , but here their role is completely symmetric.
Therefore, we will only treat explicitly the pair @xmath : the result
can be generalized straightforwardly to @xmath . The message-passing
update equations read:

  -- -------- -------- -- -------
     @xmath   @xmath      (7.8)
     @xmath   @xmath      
              @xmath      (7.9)
  -- -------- -------- -- -------

###### Step 2: AMP

A first simplification can be made by replacing the @xmath integrals
in ( 7.9 ) by a single one over the variable @xmath , which is the sum
of @xmath random variables. We call @xmath and @xmath respectively the
mean and variance of the variable @xmath distributed according to the
distribution @xmath (and similarly for the variables @xmath ). Note that
the product of two independent random variables @xmath and @xmath has
mean @xmath and variance @xmath . By the central limit theorem, the
variable @xmath is a Gaussian variable, and its mean and variance are:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.10)
     @xmath   @xmath      
              @xmath      
              @xmath      (7.11)
  -- -------- -------- -- --------

However, in eq. ( 7.9 ), @xmath is fixed and thus @xmath has to be
replaced by @xmath in ( 7.10 , 7.11 ). Defining @xmath to be @xmath with
@xmath and

  -- -------- -------- -- --------
     @xmath   @xmath      (7.12)
     @xmath   @xmath      (7.13)
     @xmath   @xmath      (7.14)
  -- -------- -------- -- --------

one can rewrite ( 7.9 ) with a single integral over a variable @xmath
with a Gaussian distribution. Using the @xmath -functions (see Appendix
A.2 ), the message ( 7.9 ) can be expressed as a simple function of the
mean and variance of this Gaussian:

  -- -------- -- --------
     @xmath      (7.15)
  -- -------- -- --------

where we use the simplified notation @xmath . Making a Taylor expansion
of this equation, we can express the message ( 7.8 ) as

  -- -------- -------- -- --------
     @xmath   @xmath      (7.16)
  -- -------- -------- -- --------

with

  -- -------- -------- -- --------
     @xmath   @xmath      (7.17)
     @xmath   @xmath      (7.18)
  -- -------- -------- -- --------

where

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (7.19)
  -- -------- -------- -------- -------- -- --------

and @xmath are simplified notations for the functions @xmath defined
in Appendix A.2 .

This allows us to have a simple expression for the previously introduced
mean and variance @xmath and @xmath of the message ( 7.16 ). Using the
notations ( A.23 , A.24 ),

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (7.20)
  -- -------- -------- -------- -------- -- --------

where as before, we introduce the simplifying notation @xmath . The
exact same thing can be done for the messages @xmath . The result is a
set of iterative equations on a set of means and variances

  -- -------- -- --------
     @xmath      (7.21)
  -- -------- -- --------

that constitutes the message-passing algorithm.

###### Step 3: TAP

This algorithm can be further simplified using the so-called
Thouless-Andersen-Palmer (TAP) approximation introduced in the study of
spin glasses [ 137 ] . The resulting algorithm 10 was introduced as
PBiGAMP in [ 109 ] .

###### Convergence

As its counterparts for generalized linear models (algorithm 2 ) or
generalized matrix factorization (algorithm 3 ), algorithm 10 needs some
adaptations that improve its convergence. One very simple empirical
damping scheme that allows to improve convergence (though not
guaranteeing it) consists in damping a single variable:

  -- -------- -- --------
     @xmath      (7.22)
  -- -------- -- --------

with @xmath , applied right after the calculation of @xmath .
Furthermore, setting @xmath and @xmath in the update equations for
@xmath and @xmath greatly reduces the risk of negative variances
appearing, while emulating the Nishimori conditions [ 67 ] . A more
involved, adaptive damping strategy is presented in [ 139 ] . Notice
that we defined the operators @xmath and @xmath used in algorithm 10 as
linear applications @xmath and @xmath in ( 7.5 , 7.6 ): In the
algorithm, we apply them row-wise on the matrices they act on.

Initialization:
Initialize the means @xmath and the variances @xmath at random according
to the distributions @xmath and @xmath , and @xmath .

Main loop: while @xmath , calculate following quantities:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Result : @xmath are the estimates for @xmath and @xmath are
uncertainties on these estimates.

Algorithm 10 PBiGAMP for matrix compressed sensing

#### 7.2 Asymptotic analysis

The problem of low-rank matrix compressed sensing can be analysed with
statistical physics methods in the thermodynamic limit, i.e. when the
dimensions of the signals @xmath and @xmath and of the measurements
@xmath go to infinity. @xmath can remain finite or go to infinity as
well. On the other hand, the ratios defined in ( 7.3 ) have to be fixed
and finite. As the analysis is very similar to the one in sec. 3.3 ,
only the main steps are presented here. The complete derivation can be
found in [ 132 ] .

##### 7.2.1 Replica analysis: free entropy

The relevant partition function is:

  -- -------- -- --------
     @xmath      (7.23)
  -- -------- -- --------

Let us start by calculating

  -- -------- -- --------
     @xmath      (7.24)
  -- -------- -- --------

and its average with respect to the realizations of @xmath , generated
by @xmath , @xmath and @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (7.25)
  -- -------- -------- -- --------

We treat @xmath as a random variable of @xmath and look at the
covariance between two of those variables:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (7.26)
  -- -------- -------- -- --------

As the elements of @xmath are i.i.d. with zero mean and variance @xmath
, we have

  -- -------- -- --------
     @xmath      (7.27)
  -- -------- -- --------

and thus

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (7.28)
  -- -------- -------- -- --------

We now make the following assumption:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.29)
  -- -------- -------- -- --------

This assumption corresponds to breaking the column-permutational
symmetry and more generally the rotational symmetry between different
replicas. We thus assume that the @xmath -th column of @xmath is
correlated to the @xmath -th column of @xmath and to none of the others.
We make the same assumption for @xmath . Then,

  -- -------- -------- -- --------
     @xmath   @xmath      (7.30)
  -- -------- -------- -- --------

Due to the hypothesis ( 7.29 ), the second term vanishes, and

  -- -------- -------- -- --------
     @xmath   @xmath      (7.31)
  -- -------- -------- -- --------

Note that by definition of @xmath in ( 7.29 ), @xmath . @xmath is thus a
multivariate Gaussian random variable with mean @xmath and covariance
matrix @xmath , where the elements of the matrices @xmath and @xmath are
given by:

  -- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath      (7.32)
  -- -------- -------- -------- -------- -- --------

With this, and introducing the conjugate variables @xmath and @xmath we
obtain

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (7.33)
  -- -------- -------- -- --------

We take @xmath , @xmath and @xmath going to infinity with constant
ratios, and rewrite

  -- -------- -------- -- --------
     @xmath   @xmath      (7.34)
  -- -------- -------- -- --------

and to use the saddle point method, according to which

  -- -------- -------- -- --------
     @xmath   @xmath      (7.35)
  -- -------- -------- -- --------

We are therefore left with a minimization problem over the space of the
matrices @xmath and @xmath , representing @xmath parameters (as the
matrices are symmetric).

##### 7.2.2 Replica symmetric assumption

With the replica symmetric hypothesis, the extremization is only over 12
variables: @xmath and @xmath . The function @xmath to extremize is:

  -- -------- -------- -- --------
              @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (7.36)
  -- -------- -------- -- --------

Taking its derivative with respect to @xmath and to @xmath limit, we
obtain the free entropy @xmath as an extremum

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (7.37)
  -- -------- -------- -- --------

over a set of @xmath variables. Note that the shift from a minimum in (
7.35 ) to an extremum in the equation above is a consequence to the
hazardous @xmath limit in the replica method. The functions @xmath and
@xmath are the equivalent of @xmath in eq. ( 3.54 ), the function @xmath
is the same as in eq. ( 3.55 ).

###### Equivalence to generalized matrix factorization

It is interesting to notice that if @xmath and @xmath , this free
entropy is the same as in generalized matrix factorization ( 4.19 ) [ 67
] . This is not an entirely obvious fact, as the two problems are
different and that they are identical only if @xmath is the identity: in
generalized matrix factorization,

  -- -------- -- --------
     @xmath      (7.38)
  -- -------- -- --------

In order to perform the theoretical analysis of generalized matrix
factorization as in [ 67 ] , it is important to take the limit @xmath .
In fact, it is this limit that ensures that each entry of @xmath is the
sum of a large number of random variables, which allows to consider that
it has a Gaussian distribution. This is a condition both in the
derivation of the message-passing algorithm and in the replica analysis.
For that reason, generalized matrix factorization with finite @xmath
leads to different algorithms and theoretical bounds [ 91 , 82 ] .
However, in matrix compressed sensing, the mixing of coefficients with
@xmath ensures that even if @xmath , each element of @xmath can be
considered to have a Gaussian distribution. Thanks to this, both the
algorithm and the analysis are the same, independently of @xmath .

Let us examine the case in which @xmath and @xmath and the two problems
are strictly equivalent. What differentiates the generalized matrix
compressed sensing from the generalized matrix factorization case is
that @xmath is not the identity. However, as @xmath ’s coefficients are
Gaussian i.i.d., it is with high probability a bijection when @xmath ,
and in this sense the mixing step does not introduce any further
difficulty into the problem compared to matrix factorization. If @xmath
, matrix compressed sensing is not “compressive” and therefore easier
than the corresponding matrix factorization problem, because more
measures are available. If @xmath , matrix compressed sensing is
“compressive” and equivalent to low rank matrix completion, i.e. to the
matrix factorization setting in which only a fraction of the matrix
entries is observed. Note that the two problems are treated jointly in [
118 ] .

##### 7.2.3 State evolution equations

As done in sec. 3.3.3 , we can obtain state evolution equations from the
free entropy by setting its derivatives to zero. We obtain the set of
equations

  -- -------- -------- -- --------
     @xmath   @xmath      (7.39)
     @xmath   @xmath      (7.40)
     @xmath   @xmath      (7.41)
  -- -------- -------- -- --------

the same equations hold replacing @xmath by @xmath , and

  -- -------- -------- -- --------
     @xmath   @xmath      (7.42)
     @xmath   @xmath      (7.43)
     @xmath   @xmath      (7.44)
  -- -------- -------- -- --------

and remembering that @xmath , @xmath and the definitions ( 7.3 ):

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.45)
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.46)
  -- -------- -------- -------- -------- -------- -------- -- --------

The equations ( 7.39 , 7.40 , 7.41 ) along with their equivalents for
@xmath , the equations ( 7.42 , 7.43 , 7.44 ) and ( 7.45 , 7.46 )
constitute a closed set of equations that hold at the extrema of @xmath
( 7.37 ).

When they are iterated, they constitute the so-called state evolution
equations. These can also be obtained by the analysis of the BP
algorithm and are known to accurately describe the algorithm’s behaviour
when the replica symmetric hypothesis is indeed correct.

As noted before, if @xmath , these state evolution equations are
identical to the ones in matrix factorization [ 67 ] . Therefore, they
reduce to the state evolution of GAMP when @xmath is known, which
corresponds to fixing @xmath in the equations.

##### 7.2.4 Bayes optimal analysis

If we suppose exact knowledge of the true signal distributions and of
the true measurement channel, the state evolution equations greatly
simplify because of the so-called Nishimori conditions [ 146 ] . In our
case, these ensure that following equalities hold:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.47)
  -- -------- -------- -- --------

both for @xmath and @xmath . Then, we only need to keep track of the
variables @xmath , and the state evolution is obtained by choosing
initial values for @xmath and iterating for @xmath the equations

  -- -------- -------- -- --------
     @xmath   @xmath      (7.48)
     @xmath   @xmath      (7.49)
     @xmath   @xmath      (7.50)
  -- -------- -------- -- --------

until convergence. From @xmath and @xmath , one can simply deduce the
normalized mean squared errors by the following relations:

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.51)
  -- -------- -------- -------- -------- -------- -------- -- --------

The initialization values @xmath indicate how close to the solution the
algorithm is at initialization. In case of a random initialization of
the algorithm, the expected initial @xmath and @xmath are of order
@xmath and @xmath respectively, and they should therefore be set to
these values (or less) in the state evolution equations.

Note that state evolution run with matching priors without imposing the
Nishimori conditions ( 7.47 ) should in principle give the exact same
results as the Bayes optimal state evolution analysis presented above,
and thus naturally follow the so-called “Nishimori line” defined by (
7.47 ). However, as shown in [ 24 ] , the Nishimori line can be
unstable: In that case, numerical fluctuations around it will be
amplified under iterations of state evolution that will thus give a
different result than its counterpart with imposed Nishimori conditions.
We analyse this instability in the following section.

#### 7.3 Stability analysis

In this section, we propose an explanation for the instability of both
BiGAMP and PBiGAMP by using the state evolution. In [ 24 ] , it is shown
that the non-convergence of GAMP with non-zero mean matrices comes from
an instability of the Nishimori line. Here, we make a similar analysis
for BiGAMP/PBiGAMP.

##### 7.3.1 Blind matrix calibration state evolution

We consider the setting of blind matrix calibration, presented in sec.
4.2.2 and which allows to interpolate between CS and dictionary
learning. The elements of the matrix @xmath follow a Gaussian
distribution (no sparsity) and are partially known by direct noisy
measurements @xmath :

  -- -------- -- --------
     @xmath      (7.52)
  -- -------- -- --------

while the elements of @xmath follow a Gauss-Bernoulli distribution. The
state evolution equations ( 4.21 – 4.26 ) can be implemented using (
3.75 – 3.77 ). Some quantities have analytical expressions. For the AWGN
channel,

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.53)
  -- -------- -------- -------- -------- -------- -------- -- --------

For the @xmath part, we define

  -- -------- -------- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.54)
  -- -------- -------- -------- -------- -------- -------- -------- -------- -- --------

with the help of which we write

  -- -------- -------- -- --------
     @xmath   @xmath      (7.55)
     @xmath   @xmath      (7.56)
     @xmath   @xmath      (7.57)
  -- -------- -------- -- --------

We focus on the case in which inference is Bayes optimal. In this
setting, we usually use the simplified state evolution equations ( 4.29
- 4.31 ), by imposing the Nishimori conditions

  -- -------- -------- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.58)
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (7.59)
  -- -------- -------- -------- -------- -------- -------- -------- -------- -- --------

which reduces the number of state evolution equations to @xmath .
However, in this study, we implement the @xmath state evolution
equations in the Bayes optimal setting and compare the results to those
obtained by imposing the Nishimori conditions.

##### 7.3.2 Instability of the Nishimori line

Results are presented in Fig. 7.3 and Fig. 7.4 . We observe that as by
increasing @xmath , the Nishimori line becomes unstable: when the
Nishimori conditions are not imposed, the system naturally drifts away
from them. This is interesting because in the algorithm, the Nishimori
conditions cannot be imposed. Therefore, the instability observed in the
state evolution is likely to take place as well in the algorithm.

On Fig. 7.3 , we show that this instability first causes the MSE to not
go as low as it should, while the nMSE still does. This is due to the
scaling invariance of the problem. Although one could suppose this
invariance to be lifted by the use of priors @xmath and @xmath with a
given variance, it turns out that these priors are not sufficient to
stabilize the variance of the estimates @xmath and @xmath . Note that
when the Nishimori conditions are not imposed, the nMSE writes:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.60)
  -- -------- -------- -- --------

and is thus different from

  -- -------- -------- -- --------
     @xmath   @xmath      (7.61)
  -- -------- -------- -- --------

The instability causes oscillations, that lead to parameters to take
“unphysical” values (some of the variances take negative values), if the
amplitude of the oscillations grows too much. Such negative variances
cause the algorithm to break or diverge, which is in fact the observed
behaviour of BiGAMP and PBiGAMP without damping.

###### Discussion

As mentioned before, the damping strategies used to make BiGAMP and
PBiGAMP converge are heuristic, do not allow systematic convergence and
significantly slow down the algorithm. Furthermore, it is difficult to
analyse them using the state evolution formalism, as they correlate
estimates of several previous time steps.

A possible axis of investigation to find a cure to the non-convergence
of BiGAMP and PBiGAMP is to study the state evolution equations (without
imposing the Nishimori conditions) with additional parameter learning.
Parameter learning empirically improves algorithm convergence, and can
be taken into account in the state evolution equations [ 73 ] . Finding
a parameter learning scheme that stabilizes the Nishimori line could
allow more systematic convergence of the algorithms.

Another remark is that the state evolution equations for non Bayes
optimal inference diverge after a few iterations. For that reason,
performing an analysis of bilinear inference using mismatching priors is
not straightforward. In particular schemes using @xmath minimization as
a sparsity promoter, as could be done for LASSO, would be interesting to
analyse. Investigating into a damping scheme for the state evolution
equations, allowing them to converge to a fixed point could solve that
issue and reveal fundamental limits of dictionary learning using @xmath
minimization.

#### 7.4 Case Study

In this section, we focus on one specific setting of matrix compressed
sensing for which the Bayes optimal state evolution equations are
practical to implement. An analysis of their fixed points leads to an
understanding of different phases and of the phase transitions between
them.

We look at the setting in which both @xmath and @xmath follow a
Bernoulli-Gauss distribution:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.62)
     @xmath   @xmath      (7.63)
  -- -------- -------- -- --------

and the measurements are taken through an AWGN channel:

  -- -------- -- --------
     @xmath      (7.64)
  -- -------- -- --------

Note that most previous works [ 81 , 116 , 63 , 150 ] consider this
channel. For the AWGN channel, eq. ( 7.48 ) has a simple analytical
expression:

  -- -------- -------- -- --------
     @xmath   @xmath      (7.65)
  -- -------- -------- -- --------

Further simplifying the setting to the special case @xmath and @xmath ,
the Bayes optimal state evolution equations ( 7.48 – 7.50 ) can be
written as one single equation

  -- -------- -------- -- --------
     @xmath   @xmath      (7.66)
  -- -------- -------- -- --------

in which the iteration-time indices of @xmath , @xmath (left hand side)
and @xmath (right hand side), are left out for better legibility. The
global measurement rate is

  -- -------- -- --------
     @xmath      (7.67)
  -- -------- -- --------

and is the natural quantity to compare @xmath to.

##### 7.4.1 Phases and phase transitions

As in compressed sensing or in matrix factorization, the analysis of the
free entropy and state evolution equations reveals the existence of
different phases in which the difficulty of the problem is different. In
our case study, the free entropy @xmath has the following expression:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (7.68)
  -- -------- -------- -- --------

with

  -- -------- -------- -- --------
     @xmath   @xmath      (7.69)
  -- -------- -------- -- --------

The integral can best be numerically evaluated replacing @xmath by
@xmath , which allows a reliable numerical evaluation for all possible
values of @xmath .

Figure 7.5 shows the free entropy landscapes for @xmath and different
values of @xmath . Instead of using @xmath as @xmath -axes, we use the
normalized mean squared error which is a more natural quantity to
measure the quality of reconstruction.

We can define three different phases depending on the positions of the
free entropy maxima. In the noiseless setting, these are:

1.  An “impossible” phase, in which the global maximum of the free
    entropy is not at nMSE @xmath . In that phase, no algorithm can find
    the correct solution.

2.  A “hard but possible” phase, in which the free entropy has its
    global maximum at nMSE @xmath , but also a local maximum at non-zero
    nMSE. In that phase, it is possible to find the correct solution, by
    correctly sampling from the posterior distribution ( 7.7 ). However,
    algorithms such as PBiGAMP get stuck in the local free entropy
    maximum instead of finding the global maximum.

3.  An “easy” phase, in which the free entropy function has a single
    maximum at nMSE @xmath .

In a noisy setting as in Fig. 7.5 , the lowest achievable nMSE is of the
order of the AWGN @xmath instead of @xmath .

###### State evolution fixed points

The state evolution equation ( 7.66 ) can either be iterated or
considered as a fixed point equation. Figure 7.6 shows the fixed points
of ( 7.66 ), which are all local extrema of the free entropy @xmath . On
the other hand, iterating the state evolution equations gives only one
of the local maxima.

The plots allow to see more clearly the “impossible”, “hard but
possible” and “easy” phases. They show that in the “hard but possible”
phase, the state evolution has an unstable fixed point, which
corresponds to a local minimum of the free entropy. Two interesting
facts can be noticed:

1.  In the noiseless setting, the impossible/possible phase transition
    (the apparition of the @xmath fixed point) takes place at @xmath .
    This can be expected because it is the critical @xmath at which the
    number of available equations is equal to the total number of
    non-zero components of the unknowns, just as in compressed sensing.

2.  The fixed point at nMSE=1 always exists for @xmath . This is more
    unexpected as it is not the case in compressed sensing. A
    consequence of this is the existence of a large “hard but possible”
    phase for small values of @xmath . Also, the measurement rate
    necessary for “easy” recovery is at least @xmath , even for very
    small @xmath . This radically differs from the low- @xmath regime in
    compressed sensing, in which a measurement rate @xmath is sufficient
    for easy recovery.

Figure 7.7 shows the full phase diagram for the case-study problem, with
the easy, hard and impossible phases. The “uninformed” line is obtained
by starting the state evolution starting from nMSE @xmath , with an
infinitesimally small @xmath , and defines the transition between the
“easy” and the “hard” phase. Interestingly, the entire region with
@xmath is in the hard phase, even at low values of @xmath , due to the
existence of the stable fixed point at @xmath . In the “hard” phase,
inference is possible provided a good estimation of the signal is
already known. The effect of such a partial knowledge can be simulated
by running the state evolution equation ( 7.66 ) starting with nMSE
@xmath , leading to the “informed” line, for which @xmath when @xmath .
The exact position of this line depends on the starting nMSE.

##### 7.4.2 Comparison with algorithmic performances

Figures 7.8 and 7.9 present a comparison of the theoretical fixed point
analysis performed above with the actual performances of PBiGAMP.
Experiments were done by Philip Schniter.

For the experiments, rank @xmath was used. In this setting, the only
invariance left is a scaling invariance: if @xmath is the true solution,
then for every @xmath , @xmath is a solution as well. The final nMSE
returned by the algorithm takes this invariance into account and is the
average of the error on @xmath and the error on @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      (7.70)
  -- -------- -------- -- --------

which will be compared to the theoretical expression ( 7.51 ). For each
instance of the problem, the algorithm was allowed up to @xmath restarts
from different random initializations to reach a nMSE smaller than
@xmath , and the lowest of the reached nMSE was kept.

The results show that there is a good agreement between the theory and
the performance of PBiGAMP: most of the nMSEs reached by PBiGAMP
correspond to a stable fixed point of the state evolution. The agreement
with the theory becomes better with increasing system size. For smaller
sizes, the experimental points are more spread around the theoretical
fixed points. This can be well understood by analyzing the case of fixed
points with nMSE=1. The “meaning” of such fixed points is that the
algorithm is unable to estimate the true signals better than at random.
In the @xmath limit, the nMSE between the true signals and random
signals is @xmath with probability @xmath . For finite values of @xmath
however, the nMSE between true and random signals follows a distribution
on @xmath that gets more peaked on @xmath as @xmath increases. This
explains the narrowing of the spread of experimental points around the
fixed points as @xmath increases.

###### Succeeding in the hard phase: importance of the initialization

An interesting consequence of this finite size effect is that for small
@xmath , parts of the “hard” phase are quite easy. The reason is that if
the random initialization of the algorithm is such that the nMSE is
smaller than the nMSE of the unstable fixed point, the algorithm
naturally converges to the low-nMSE solution. Therefore, running the
algorithm from a few different initializations can allow to converge to
the correct solution even in the “hard” phase, provided that @xmath is
small enough and that the unstable fixed point has a high enough nMSE.

Figure 7.10 shows that this effect is quite important for @xmath , but
nearly inexistent for @xmath . The reason for this is the higher nMSE of
the unstable fixed point for @xmath than for @xmath .

Remember that in PBiGAMP, the initial estimates of @xmath and @xmath are
random. While in some regions of the phase diagram and with small signal
sizes, running the algorithm from several of those random initial
estimates might be sufficient, in general it would be preferable to have
a procedure that systematically produces good initializations. Previous
works stress this fact as well [ 81 , 116 , 63 , 150 ] .

Another difference between figures 7.9(a) and 7.9(b) is that in the
latter, the algorithm fails for a significant fraction of instances
inside the “easy” phase, which is not the case in the former. The fact
that the fraction of such failed instances decreases with increasing
signal size @xmath seems to indicate that this is as well a finite size
effect. Unlike the previously examined finite size effect, this one
cannot be explained from the state evolution, as it has a unique fixed
point in the “easy” phase.

#### 7.5 Conclusion

In this chapter, we provide an asymptotic analysis of Bayesian low-rank
matrix compressed sensing. We employ the replica method to obtain the
so-called state evolution equations, whose fixed points allow to
determine if inference is easy, hard or impossible. The state evolution
equations describe the behaviour of the associated message passing
algorithm PBiGAMP that was derived and studied previously in [ 109 ] ,
for whose derivation we provide the key steps.

An interesting point concerning the state evolution equations is that
they are the same as those for the matrix factorization problem derived
in [ 67 ] . A related observation was made by [ 40 ] .

We analyse in detail the phase diagram for an AWGN sensing channel and
Gauss-Bernoulli priors on both the factors. We show numerically that
there is an excellent agreement between the theoretical analysis and the
performances of the PBiGAMP algorithm. We observe that for the simulated
system sizes, the algorithm performs better than what could be expected
from the asymptotic theoretical analysis. However, we explain this as a
finite size effect in terms of state evolution fixed points and stress
the importance of a good initial estimate in order to perform inference
outside of the easy phase.

The stability analysis performed in sec. 7.3 gives a theoretical
explanation for why damping schemes are necessary both for BiGAMP and
PBiGAMP to converge, and could be used to devise parameter learning
schemes that stabilize them without the need to damp (and thus slow them
down).

### Conclusion and perspectives

The main focus in this thesis was the Bayesian treatment of generalized
linear and bilinear inference problems, using methods from statistical
physics. The replica method has proven to be very adapted to the
theoretical analysis of these problems. It reveals the existence of
different phases , in which inference is either possible or impossible,
hard or easy. Belief propagation allows to design fast algorithms that
can often reach the performances predicted by the replica analysis.
However, in the case of bilinear inference or in the presence of certain
non-linearities, belief propagation algorithms are limited by unreliable
convergence properties. Several concrete applications of generalized
linear and bilinear inference problems were studied or simply mentioned,
showing how broad the applicability of these models is.

#### Open problems

Here are a few of problems I have come across, that are still open to my
knowledge and that are interesting directions for future research.

###### Phase retrieval:

As explained in sec. 5.3 , GAMP for phase retrieval does work, but is
not very reliable, especially for sparse signals. As phase retrieval has
many applications, it would be interesting to better understand where
its difficulty stems from. The preliminary results in Appendix D could
be extended to the non Bayes optimal case. It seems plausible that as in
bilinear inference, the convergence issues in phase retrieval come from
an instability of the Nishimori line.

###### Stabilizing the Nishimori line:

As seen in sec. 7.3 (and possibly in phase retrieval), the state
evolution equations sometimes predict an instability in Bayes optimal
message-passing algorithms. The empirical strategies that were proposed
to make them converge are effective in some cases, but not always.
Furthermore, they slow down the algorithms significantly. A more
principled approach to stabilizing the algorithms could be tried by
including parameter learning into the algorithm. This has already proven
to stabilize message-passing algorithm and can furthermore be analysed
with state evolution equations. By adding variables to the problems, it
might be possible to stabilize the Nishimori line without slowing down
the algorithm. More reliable bilinear inference algorithms could
represent a breakthrough for many applications.

###### Overcoming invariances:

In several of the problems examined in this thesis, a fundamental
invariance is present, e.g. the global phase invariance in phase
retrieval. In some problems, this invariance is problematic. In
dictionary learning for example, the inferred signals are often not as
sparse as they should, which seems to be a consequence of the rotational
invariance. It would be interesting to understand why sparse priors do
not seem able to enforce the right sparsity and whether this failure can
be overcome.

#### Beyond inference: deep learning

The inference problems treated in this thesis mostly follow the scheme
presented in sec. 1.1 : Information about a signal is gathered in a
measurement process and the goal is to reconstruct the initial signal.
In some other problems such as low-rank matrix completion, the
underlying signal is not uniquely recoverable and is in most
applications merely a useful low-dimensional representation of
higher-dimensional data. Representation learning [ 15 ] is the key
concept behind the power of deep learning [ 80 ] , which has imposed
itself as the state of the art technique in numerous machine learning [
59 ] and artificial intelligence tasks [ 134 ] .

Deep neural networks can be said to be unreasonably effective
considering the fact that their development is mainly heuristic and that
little about them is understood on a theoretical level. The work in this
thesis contributes to understanding the basic building block of deep
neural networks: The single, feedforward layer of neurons. This
understanding seems a prerequisite to being able to truly understand
deep neural networks.

## Appendices

### Appendix A Useful functions

#### a.1 Standard functions

##### a.1.1 Gaussians

###### Real Gaussians

We note @xmath the normalized Gaussian with mean @xmath and variance
@xmath :

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

We can note that:

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

Its derivatives with respect to its mean and variance are:

  -- -------- -------- -- -------
     @xmath   @xmath      (A.3)
     @xmath   @xmath      (A.4)
  -- -------- -------- -- -------

The following formula for a product of Gaussians with the same argument
but different means and variances is very useful:

  -- -------- -------- -- -------
     @xmath   @xmath      (A.5)
  -- -------- -------- -- -------

with

  -- -------- -------- -------- -------- --
     @xmath   @xmath   @xmath   @xmath   
  -- -------- -------- -------- -------- --

and in the case of two Gaussians, ( A.5 ) particularizes to:

  -- -------- -------- -- -------
     @xmath   @xmath      (A.6)
  -- -------- -------- -- -------

###### Multivariate Gaussians

A multidimensional variable @xmath follows a non-degenerate multivariate
normal distribution if it has the pdf

  -- -------- -- -------
     @xmath      (A.7)
  -- -------- -- -------

where @xmath is the mean of the random variable @xmath and its
covariance matrix @xmath is symmetric and positive definite. The
relations verified by real Gaussians have very close equivalents for
multivariate Gaussians:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.8)
     @xmath   @xmath      (A.9)
     @xmath   @xmath      (A.10)
  -- -------- -------- -- --------

The formula for the product reads

  -- -------- -------- -- --------
     @xmath   @xmath      (A.11)
  -- -------- -------- -- --------

with

  -- -------- -------- -------- -------- --
     @xmath   @xmath   @xmath   @xmath   
  -- -------- -------- -------- -------- --

##### a.1.2 Other useful functions and integrals

###### Complementary error function

The complementary error function is defined by

  -- -------- -------- -- --------
     @xmath   @xmath      (A.12)
  -- -------- -------- -- --------

From this definition, we can obtain analytical expressions for the
following integrals:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.13)
     @xmath   @xmath      (A.14)
  -- -------- -------- -- --------

The derivative of @xmath is given by

  -- -------- -------- -- --------
     @xmath   @xmath      (A.15)
  -- -------- -------- -- --------

###### Gamma functions

The gamma function is defined as

  -- -------- -------- -- --------
     @xmath   @xmath      (A.16)
  -- -------- -------- -- --------

and the lower incomplete gamma function is defined as

  -- -------- -- --------
     @xmath      (A.17)
  -- -------- -- --------

Using them, we can obtain an analytical expression for the integral

  -- -------- -------- -- --------
     @xmath   @xmath      (A.18)
              @xmath      
              @xmath      (A.19)
  -- -------- -------- -- --------

where @xmath is @xmath if @xmath is even and @xmath if @xmath is uneven.

#### a.2 Update functions

For any non negative function @xmath and @xmath , we define the @xmath
-th moment of the product of @xmath multiplied by a Gaussian of mean
@xmath and variance @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (A.20)
     @xmath   @xmath      
     @xmath   @xmath      (A.21)
     @xmath   @xmath      
     @xmath   @xmath      (A.22)
  -- -------- -------- -- --------

From these, we define the update functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.23)
     @xmath   @xmath   @xmath      (A.24)
  -- -------- -------- -------- -- --------

which are the mean and variance of the distribution @xmath and serve as
update functions for the MMSE estimators and their related uncertainty.
We also define the auxiliary functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.25)
     @xmath   @xmath   @xmath      (A.26)
  -- -------- -------- -------- -- --------

that allow notational compactness in the algorithms.

From ( A.3 ) and ( A.4 ) we obtain the relations:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.27)
     @xmath   @xmath      (A.28)
  -- -------- -------- -- --------

These are useful in the derivations of the message-passing algorithms
and also allow to easily obtain @xmath from @xmath . The following
relations are used as well:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.29)
     @xmath   @xmath      (A.30)
  -- -------- -------- -- --------

A useful feature of these update functions is the following: if @xmath
with @xmath , then

  -- -------- -------- -- --------
     @xmath   @xmath      (A.31)
  -- -------- -------- -- --------

As a consequence, obtaining the update functions for a sensing channel
with AWGN is straightforward once the functions for the noiseless
version have been calculated.

###### Multivariate version

These update functions can be extended to mutidimensional variables
@xmath and non negative functions @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath               (A.32)
     @xmath   @xmath      
     @xmath   @xmath      (A.33)
     @xmath   @xmath      
     @xmath   @xmath      (A.34)
  -- -------- -------- -- --------

From these, we define the update functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.35)
     @xmath   @xmath   @xmath      (A.36)
  -- -------- -------- -------- -- --------

and the auxiliary functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.37)
     @xmath   @xmath   @xmath      (A.38)
  -- -------- -------- -------- -- --------

The gradient and Jacobian of @xmath with respect to its first argument
read:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.39)
     @xmath               
  -- -------- -------- -- --------

### Appendix B Introducing the conjugate variable @xmath

In eq. ( 3.40 ), Dirac @xmath functions enforce the relations ( 3.39 ).
We use the integral representation of these @xmath functions to carry on
the calculation:

  -- -------- -------- -- -------
     @xmath   @xmath      (B.1)
  -- -------- -------- -- -------

This leads to

  -- -------- -- -------
     @xmath      (B.2)
  -- -------- -- -------

and the product of all the @xmath functions thus gives

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

Note that the summation is over @xmath because @xmath . Finally, we make
the change of variables

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (B.4)
  -- -------- -------- -- -------

which allows us to write the sums in eq. ( B.3 ) more compactly:

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (B.5)
  -- -------- -------- -- -------

where we introduce the vector @xmath . Changing the integration
variables from @xmath to @xmath , we obtain eq. ( 3.41 ).

### Appendix C Blind sensor calibration state evolution

The blind sensor calibration setting presented in chapter 6 can be
analysed using the replica method in a way very similar to the analysis
performed in sec. 3.3 for generalized linear models. These are
preliminary results: no implementation of the state evolution equations
presented below was made and therefore their correctness has not been
verified by comparison with experimental results.

In the Bayes optimal case, the state evolution equations derived
in chapter 3 for GAMP are:

  -- -------- -------- -- -------
     @xmath   @xmath      (C.1)
     @xmath   @xmath      (C.2)
  -- -------- -------- -- -------

For Bayes optimal blind sensor calibration from @xmath independent
signals, the equation for @xmath remain unchanged, but:

  -- -------- -------- -- -------
     @xmath   @xmath      (C.3)
  -- -------- -------- -- -------

where @xmath is given by eq. ( 6.15 ). Both @xmath and @xmath are @xmath
-dimensional vectors.

In general, integration over @xmath variables is therefore necessary in
order to evaluate @xmath . In particular settings, it might be possible
to reduce the number of necessary integrations. For instance, in the
real gain calibration setting, the function to integrate depends only on
the three scalars @xmath , @xmath and @xmath , and the integration over
@xmath variables can therefore be reduce to an integration over @xmath
variables. Similarly, in the faulty sensors setting, it seems that a
proper reformulation could reduce the number of integration variables to
@xmath . No numerical results have been obtained yet but a careful
analysis of the functions to integrate could allow to obtain the exact
positions of the phase transitions observed experimentally.

### Appendix D Sparse phase retrieval state evolution

The complex generalized model setting presented in chapter 5 can be
analysed using the replica method in a way very similar to the analysis
performed in sec. 3.3 for generalized linear models. These are
preliminary results: no implementation of the state evolution equations
presented below was made and therefore their correctness has not been
verified by comparison with experimental results.

In the Bayes optimal case, the state evolution equations derived
in chapter 3 for GAMP are:

  -- -------- -------- -- -------
     @xmath   @xmath      (D.1)
     @xmath   @xmath      (D.2)
  -- -------- -------- -- -------

In the complex case, these equations change and become:

  -- -------- -------- -- -------
     @xmath   @xmath      (D.3)
     @xmath   @xmath      (D.4)
  -- -------- -------- -- -------

where @xmath is a complex integration variable and @xmath as well. For
Bayes optimal complex CS, these equations give back the state evolution
equation ( 5.63 ). In the case of a the complex joint Gauss-Bernoulli
prior ( 5.64 ), @xmath can be reduced to an integral over a single, real
variable @xmath :

  -- -------- -- -------
     @xmath      (D.5)
  -- -------- -- -------

In the case of phase retrieval, @xmath can be calculated from eq. ( 5.81
). Using the scaled versions @xmath of @xmath :

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

As in Appendix C , these are preliminary analytical results that need to
be verified by implementation and comparison to algorithmic
performances.