### Contents

-    Abstract
-    Zusammenfassung
-    1 Introduction
    -    1.1 Previous Work on Quantum Kolmogorov Complexity
    -    1.2 Synopsis and Main Results
-    2 The Quantum Turing Machine
    -    2.1 Definition of Quantum Turing Machines
        -    2.1.1 Indeterminate-Length Qubit Strings
        -    2.1.2 Mathematical Framework for QTMs
    -    2.2 Halting and Universality of QTMs
        -    2.2.1 Different Notions of Universality for QTMs
        -    2.2.2 Quantum Complexity and its Supposed Invariance
        -    2.2.3 Strongly Universal QTMs
    -    2.3 Construction of a Strongly Universal QTM
        -    2.3.1 Halting Subspaces and their Orthogonality
        -    2.3.2 Approximate Halting Spaces
        -    2.3.3 Compression, Decompression, and Coding
        -    2.3.4 Proof of the Strong Universality Property
    -    2.4 Halting Stability
-    3 Quantum Kolmogorov Complexity
    -    3.1 Definition of Quantum Kolmogorov Complexity
    -    3.2 Incompressibility Theorems
    -    3.3 The Invariance Property
    -    3.4 Quantum Complexity of Classical Strings
    -    3.5 Quantum Brudno’s Theorem
        -    3.5.1 Ergodic Quantum Sources
        -    3.5.2 Proof of Quantum Brudno’s Theorem
-    4 Summary and Outlook
-    A Appendix
-    A Glossary of Symbols and Notation

## Chapter 1 Introduction

Kolmogorov complexity is an important measure of the information content
of single binary strings. It is motivated by the fact that regular
objects tend to have short descriptions. Consider for example two binary
strings @xmath and @xmath , both consisting of a million bits, namely

  -- -------- --
     @xmath   
  -- -------- --

The string @xmath is purely repetitive, while the string @xmath looks
quite irregular; in fact, it has been recorded during a physics
experiment with some radioactive source.

So why does @xmath look more irregular than @xmath ? We can easily
describe @xmath by saying that @xmath consists of @xmath repetitions of
@xmath , while we need a lot more words and effort to specify the exact
value of @xmath . Thus, it makes sense to measure the irregularity or
randomness of a binary string as the length of its shortest description.
To avoid problems, we have to beware of self-contradictory descriptions
like the following:

“Let @xmath be the smallest integer that cannot be described in less
than a hundred words.”

This statement is the well-known Berry Paradox , cf. [ 23 ] . So we
should only accept descriptions that are explicit enough to give
instructions for constructing the corresponding string unambiguously and
purely mechanically. This requirement is definitely fulfilled by
computer programs that make a predefined computer halt and output some
string in a finite amount of time. So we choose some universal computer
@xmath and measure the irregularity, or Kolmogorov complexity @xmath ,
of some binary string @xmath as the length @xmath of the shortest
program that makes the universal computer output @xmath :

  -- -------- --
     @xmath   
  -- -------- --

For regular strings like @xmath (even if they have some large length
@xmath ), we can find short computer programs like “print @xmath times
the string @xmath ” , while for strings like @xmath , there seems to be
no obvious way to compress the binary digits into a short computer
program (although there might be one which we do not know). To encode
some integer @xmath , we need about @xmath bits, where @xmath here and
in the remainder of the thesis denotes the binary logarithm. Thus,

  -- -------- --
     @xmath   
  -- -------- --

The mathematical theory of Kolmogorov complexity and some related
notions like algorithmic probability is called algorithmic information
theory. It has been developed since the 1960’s by Kolmogorov [ 21 ] ,
Solomonoff [ 41 ] , Chaitin [ 10 ] , and others, and is still a lively
field of research.

In recent years, there has been extensive study on how the extraordinary
world of quantum mechanics changes the way that information can be
transmitted, stored and processed in our universe. In this field of
research, called quantum information theory, many aspects of classical
information theory have already been extended and generalized to the
quantum situation. It is thus natural to ask whether also some quantum
counterpart of Kolmogorov complexity can be found. It is tempting to try
so for several reasons:

-   Kolmogorov complexity has applications in many areas, including
    classical computer science, information theory and statistical
    mechanics. Thus, one may hope that its quantum counterpart is
    similarly useful in areas like quantum information theory or quantum
    statistical mechanics.

-   Quantum Kolmogorov complexity promises to unite two different kinds
    of randomness in a single theory: quantum randomness, originating
    from measurements in quantum theory, and algorithmic randomness,
    corresponding to incompressibility.

-   Every quantum system in our universe that behaves according to some
    computable time evolution is a quantum computer, in the sense that
    it can in principle be simulated by a quantum Turing machine. By
    definition, the corresponding computation cannot change the
    complexity of the system’s state too much. In this case, quantum
    Kolmogorov complexity might turn out to be a useful invariant.

In the next section, we briefly describe previous work on quantum
Kolmogorov complexity, while in Section 1.2 , we describe what is done
in this thesis, why it is done, and in what way.

### 1.1 Previous Work on Quantum Kolmogorov Complexity

While classical information theory deals with finite binary strings ¹ ¹
1 Note that @xmath denotes the empty string of length zero.

  -- -------- --
     @xmath   
  -- -------- --

quantum information theory allows arbitrary superpositions of classical
strings like

  -- -------- --
     @xmath   
  -- -------- --

The idea of quantum Kolmogorov complexity is to assign some complexity
measure @xmath to every such quantum state @xmath , namely the length of
the shortest program for a universal quantum computer to produce the
state @xmath .

Yet, in contrast to the classical situation, it is not clear at the
outset what the details of such a definition should look like. What, for
example, is exactly meant by “universal quantum computer”? Then, what is
a proper “program” or “input” for a quantum computer - is it a classical
bit string, or some quantum state itself? In the second case, what is
the “length” of such a quantum state? Moreover, do we demand that the
quantum computer produces the state @xmath exactly, or do we allow some
error tolerance in the continuum of quantum states?

In recent years, there have been several attempts to define and study
quantum Kolmogorov complexity. Most of them seem to be inequivalent,
reflecting the different possibilities mentioned above. In the remainder
of this section, we will briefly discuss some of them. The definition
which is used in this thesis can be found in Section 3.1 .

The first definition of quantum Kolmogorov complexity is due to Svozil [
43 ] . He defines the algorithmic complexity @xmath of a vector @xmath
in some Hilbert space @xmath as the length of the shortest classical
program @xmath for a universal quantum computer @xmath to output that
element,

  -- -------- --
     @xmath   
  -- -------- --

Since there are countably many classical binary strings, but uncountably
many quantum states, this definition has the disadvantage that it is
undefined (or infinite) for many states @xmath .

Later, a similar definition was given by Vitányi [ 45 ] . He also allows
only classical inputs, but circumvents the aforementioned problem by
allowing some error and introducing some penalty term for non-perfect
output. His definition reads

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is some universal quantum Turing machine. In this case, the
output @xmath of the machine @xmath on input @xmath does not have to be
exactly equal to @xmath , but can differ by a small amount.
Nevertheless, if @xmath and the desired state @xmath differ too much,
then the penalty term @xmath gets large, and the minimum is attained at
another argument, not at @xmath .

Mora and Briegel [ 26 , 27 ] define the quantum Kolmogorov complexity of
some quantum state as the length of the shortest classical description
of some quantum circuit that prepares that state. Maybe this approach is
related to the ones mentioned before. In any case, it seems to have the
advantage to be more utilizable for applications than other definitions
of complexity.

The first purely quantum definition has been given by Berthiaume, van
Dam, and Laplante [ 5 ] . They explicitly allow inputs that are
themselves quantum, i.e. superpositions of classical strings of some
common length. They define

  -- -------- --
     @xmath   
  -- -------- --

that is, the complexity of @xmath is the length of the shortest quantum
input @xmath that produces @xmath with some fidelity which is larger
than @xmath . Thus, for @xmath , @xmath must be equal to @xmath , while
for @xmath , some inaccuracy in the output of the universal quantum
computer @xmath is allowed. Moreover, they define a similar notion of
complexity by means of an approximation scheme, which will be described
later on in Section 3.1 .

We argue that this kind of definition is in some sense the most natural
quantum extension of Kolmogorov complexity, since inputs and outputs are
treated symmetrically. In a quantum world, quantum computers can have
quantum inputs. Our definition in Section 3.1 is thus very similar; we
basically use the definition by Berthiaume et al., except for slight
modifications (e.g. we also allow superpositions of strings of different
lengths).

We give some evidence why this kind of definition is natural in Section
3.5 , where we prove an intimate connection between von Neumann entropy
and this kind of complexity, which seems to be impossible for all
definitions of quantum complexity that are restricted to classical
inputs.

A quite different idea of how to define quantum Kolmogorov complexity
has been elaborated by Gács [ 14 ] . His approach is motivated by
Levin’s coding theorem from classical Kolmogorov complexity. Levin’s
coding theorem is about so-called semimeasures , i.e. “probability
distributions” @xmath on the strings such that the sum @xmath may be
less than one. A semimeasure is called semicomputable if there is a
monotonically increasing, computable sequence of functions converging to
it. There is a theorem stating that there exists a so-called universal
semicomputable semimeasure @xmath , where universal means that @xmath
for every other semicomputable semimeasure @xmath , and @xmath is a
constant not depending on @xmath .

Levin’s coding theorem says that the Kolmogorov complexity of some
string @xmath equals @xmath within some additive constant. Contrariwise,
this means that Kolmogorov complexity can also be defined as the
negative logarithm of some universal semicomputable semimeasure without
reference to program lengths.

Consequently, Gács showed the existence of a universal semicomputable
semi-density matrix, and then defined its logarithm as the quantum
Kolmogorov complexity of some quantum state. It is not clear how this
approach is related to the other definitions, although he shows some
interesting estimations among the different definitions in his paper.
Moreover, the fact that his definition works without reference to any
model of a quantum computer is a striking feature, but may also make it
different to relate his notion to concrete program lengths in quantum
computation. A similar and more general idea has been elaborated by
Tadaki [ 44 ] , but for different purpose.

It is an open problem whether all these definitions are unrelated or
some of them are equivalent. The aim of this thesis is not to solve this
problem, but rather to give a rigorous analysis of the definition given
by Berthiaume et al. [ 5 ] , although some of the results on this thesis
might in the end contribute to the classification of the different
complexity notions.

### 1.2 Synopsis and Main Results

In this section, we describe how this thesis is organized. This thesis
consists of two parts. The first part is about quantum Turing machines,
the second part is about quantum Kolmogorov complexity.

As the purpose of this thesis is to develop the basics of quantum
Kolmogorov complexity in full mathematical rigour, it is necessary to
study in detail the underlying model of quantum computation, which is
the quantum Turing machine (QTM). There is nothing special about the QTM
model; other models of quantum computation like the circuit model (cf. [
30 ] ) or measurement-based quantum computers [ 36 ] are equivalent in
their computational power (see, for example, [ 31 ] ). We chose this
model as there is a large volume of existing literature discussing
various aspects of QTMs. Also, the model seems interesting in itself, as
it is a direct quantization of the popular model of classical
computation, the Turing machine (TM).

It will be shown in Chapter 3 that many important properties of quantum
Kolmogorov complexity, like the invariance property, are sensitive to
the details of quantum computation itself. Most of the previous work
studied QTMs with the purpose to analyze computational complexity , i.e.
to answer questions like how efficient (fast) quantum algorithms can be,
and how efficiently different quantum computers can simulate each other.
As quantum Kolmogorov complexity is insensitive to execution times of
algorithms, but instead studies the program lengths, different aspects
of quantum computation become important. In more detail, in Chapter 2 ,
we proceed in the following way:

-   In Section 2.1 , we start by defining the notion of a qubit string
    and give two different ways to quantify its length. Then, we give a
    mathematical framework for QTMs, based on the work by Bernstein and
    Vazirani [ 4 ] ; we define a QTM as a special kind of partial map on
    the qubit strings.

-   In Section 2.2 , we discuss the problem of defining when a QTM
    halts. We argue that the most natural and useful definition of
    halting, at least in the context of quantum Kolmogorov complexity,
    is to demand perfect halting and to dismiss any input which brings
    the QTM into some superposition or mixture of halting and
    non-halting.

    Moreover, we discuss the notion of universality of a QTM. We show
    that the previous definition of a universal QTM by Bernstein and
    Vazirani is perfectly suitable for the study of computational
    complexity, but is not sufficient for studying quantum Kolmogorov
    complexity. This is due to the restriction that in the previous
    approach, the halting time has to be specified in advance.

-   Consequently, in Section 2.3 , we give a full proof that there
    exists a universal QTM which simulates every other QTM without
    knowing the halting time in advance, and then halts perfectly. This
    result is necessary to show in Chapter 3 that quantum Kolmogorov
    complexity depends on the choice of the universal QTM only up to an
    additive constant.

    The construction of this “strongly universal” QTM is based on the
    observation that the valid inputs are organized in mutually
    orthogonal halting spaces . Moreover, these halting spaces can be
    computably approximated. We define these approximate halting spaces
    and show several properties, based on analytic estimates.

    Some slightly different universality results are needed for the
    different notions of quantum Kolmogorov complexity (e.g. with or
    without a second parameter) that we study in Chapter 3 . Thus, we
    also describe how the proof can be modified to obtain the various
    different universality results.

-   In Section 2.4 , we show a stability result for the halting scheme
    of QTMs: every input which makes a QTM almost halt can be modified
    to make the QTM halt perfectly , by adding at most a constant number
    of qubits. This shows that the halting scheme defined before in
    Section 2.1 is not “unphysical”, since it has some inherent error
    tolerance that was not expected from the beginning. It also means
    that we can to some extent use quantum programs with probabilistic
    behaviour for estimates of quantum Kolmogorov complexity.

In Chapter 3 , we then turn to the study of quantum Kolmogorov
complexity.

-   In Section 3.1 , we give four different definitions of quantum
    Kolmogorov complexity ( @xmath , @xmath , @xmath and @xmath . They
    differ on the one hand by the way we quantify the length of qubit
    strings (base length @xmath or average length @xmath ), and on the
    other hand by the way we allow some error in the QTM’s output. Yet,
    they are similar enough to be studied all at the same time. Most of
    the time, we will nevertheless restrict our analysis to the
    complexities @xmath and @xmath , since they are in some sense easier
    to handle than @xmath and @xmath .

-   In Section 3.2 , we prove some “quantum counting argument”, which
    allows to derive an upper bound on the number of mutually orthogonal
    vectors that are reproduced by quantum operations within some fixed
    error tolerance. Furthermore, we prove two incompressibility
    theorems for quantum Kolmogorov complexity.

-   We show that quantum Kolmogorov complexity is invariant in Section
    3.3 . This means that it depends on the choice of the universal QTM
    only up to an additive constant. In the classical case, the
    invariance theorem is the cornerstone for the whole theory of
    Kolmogorov complexity, and in the quantum case, we expect that it
    will be of similar importance.

-   The aim of defining a quantum Kolmogorov complexity is to find a
    generalization of classical Kolmogorov complexity to quantum
    systems. In Section 3.4 , we show that this point of view is
    justified by proving that both complexities closely coincide on the
    domain of classical strings. That is, the quantum complexity @xmath
    of classical strings equals the classical complexity @xmath up to
    some constant. For the quantum complexity @xmath with some fixed
    error tolerance @xmath for the QTM’s output, we prove that both are
    equal up to some factor @xmath .

-   In Section 3.5 , we prove that the von Neumann entropy rate of an
    ergodic quantum information source is arbitrarily close to its
    Kolmogorov complexity rate with probability one. This generalizes a
    classical theorem which has first been conjectured by Zvonkin and
    Levin [ 48 ] and was later proved by Brudno [ 9 ] .

    The case that is typically studied in quantum information theory is
    an i.i.d. source, that is, many copies of a single density operator
    @xmath . Ergodic sources generalize this model to the case where the
    source is still stationary, but the different instances can be
    correlated in complicated ways. The quantum Brudno’s theorem shows
    that for such sources, the randomness (quantum Kolmogorov
    complexity) of single strings emitted by the source typically equals
    the randomness of the source itself (its von Neumann entropy).

    This part of the thesis is joint work with F. Benatti, T. Krüger,
    Ra. Siegmund-Schultze, and A. Szkoła.

Finally, in a summary and outlook, we discuss perspectives for further
research and propose a concrete application of quantum Kolmogorov
complexity in quantum statistical mechanics.

## Chapter 2 The Quantum Turing Machine

The previous work on quantum Turing machines (QTMs) focused on
computational complexity, i.e. on questions like how efficient QTMs can
perform certain tasks or simulate other quantum computing machines.
Since quantum Kolmogorov complexity does not depend on the time of
computation, but only focuses on the length of the input, we have to
explore different aspects of QTMs which have not been analyzed in this
way before.

Note that the results on QTMs that we prove in this chapter may also be
valid for other quantum computing devices, as long as they map input
quantum states to output quantum states, and may or may not halt at some
time step.

### 2.1 Definition of Quantum Turing Machines

In 1985, Deutsch [ 12 ] proposed the first model of a quantum Turing
machine (QTM), elaborating on an even earlier idea by Feynman [ 13 ] .
Bernstein and Vazirani [ 4 ] worked out the theory in more detail and
proved that there exists an efficient universal QTM (it will be
discussed in Section 2.2 in what sense). A more compact presentation of
these results can be found in the book by Gruska [ 15 ] . Ozawa and
Nishimura [ 34 ] gave necessary and sufficient conditions that a QTM’s
transition function results in unitary time evolution. Benioff [ 2 ] has
worked out a slightly different definition which is based on a local
Hamiltonian instead of a local transition amplitude.

The definition of QTMs that we use in this thesis will be completely
equivalent to that by Bernstein and Vazirani. Yet, we will use some
different kind of notation which makes it easier (or at least more
clear) to derive analytic estimates like “ how much does the state of
the control change at most, if the input changes by some amount? ”.
Also, we use the word QTM not only for the model itself, but also for
the partial function which it generates.

We start by defining the quantum analogue of a bit string.

#### 2.1.1 Indeterminate-Length Qubit Strings

The quantum analogue of a bit string, a so-called qubit string , is a
superposition of several classical bit strings. To be as general as
possible, we would like to allow also superpositions of strings of
different lengths like

  -- -------- --
     @xmath   
  -- -------- --

Such quantum states are called indeterminate-length qubit strings . They
have been studied by Schumacher and Westmoreland [ 39 ] , as well as by
Boström and Felbinger [ 8 ] in the context of lossless quantum data
compression.

Let @xmath be the Hilbert space of @xmath qubits ( @xmath ). We write
@xmath for @xmath to indicate that we fix two orthonormal computational
basis vectors @xmath and @xmath . The Hilbert space @xmath which
contains indeterminate-length qubit strings like @xmath can be formally
defined as the direct sum

  -- -------- --
     @xmath   
  -- -------- --

The classical finite binary strings @xmath are identified with the
computational basis vectors in @xmath , i.e. @xmath , where @xmath
denotes the empty string. We also use the notation

  -- -------- --
     @xmath   
  -- -------- --

and treat it as a subspace of @xmath .

To be as general as possible, we do not only allow superpositions of
strings of different lengths, but also mixtures , i.e. our qubit strings
are arbitrary density operators on @xmath . It will become clear in the
next sections that QTMs naturally produce mixed qubit strings as
outputs. Moreover, it will be a useful feature that the result of
applying the partial trace to segments of qubit strings will itself be a
qubit string.

Furthermore, we would like to say what the length of a qubit string is.
It was already noticed in [ 39 ] and [ 8 ] that there are two different
natural possibilities, which we will give in the next definition.

Before we state the definition of a qubit string, we fix some notation:
if @xmath is a Hilbert space, than we denote by @xmath the trace-class
operators on @xmath . Moreover, @xmath shall denote the density
operators on @xmath , that is, the positive trace-class operators with
trace @xmath .

###### Definition 2.1.1 (Qubit Strings and their Length)

An (indeterminate-length) qubit string @xmath is a density operator on
@xmath . Normalized vectors @xmath will also be called qubit strings,
identifying them with the corresponding density operator @xmath .

The base length (or just length ) of a qubit string @xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

or as @xmath if the maximum does not exist. Moreover, we define the
average length @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the unbounded self-adjoint length operator . It is
defined as

  -- -------- --
     @xmath   
  -- -------- --

on its obvious domain of definition, where @xmath denotes the projector
onto the subspace @xmath of @xmath .

For example, the qubit string @xmath has length @xmath , i.e. the length
of an indeterminate-length qubit string equals the maximal length of any
computational basis vector that has non-zero coefficient in the
superposition. This is motivated by the fact that a qubit string @xmath
needs at least @xmath cells on a QTM’s tape to be stored perfectly
(compare Subsection 2.1.2 ).

On the other hand, we have @xmath . Using either @xmath or @xmath will
give two different definitions of quantum Kolmogorov complexity. The
idea to use @xmath in that definition has first been proposed by Rogers
and Vedral [ 37 ] .

In contrast to classical bit strings, there are uncountably many qubit
strings that cannot be perfectly distinguished by means of any quantum
measurement. A good measure for the difference between two quantum
states is the trace distance (cf. [ 30 ] )

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

It has the nice operational meaning to be the maximum difference in
probability for a yes-no-measurement if either applied to @xmath or
@xmath , cf. [ 30 ] .

This distance measure on the qubit strings will be used in our
definition of quantum Kolmogorov complexity in Section 3.1 .

#### 2.1.2 Mathematical Framework for QTMs

To understand the notion of a quantum Turing machine (QTM), we first
explain how a classical Turing machine (TM) is defined.

We can think of a classical TM as consisting of three different parts: a
control @xmath , a head @xmath , and a tape @xmath . The tape consists
of cells that are indexed by the integers, and carry some symbol from a
finite alphabet @xmath . In the simplest case, the alphabet consists of
a zero, a one, and a special blank symbol @xmath . At the beginning of
the computation, all the cells are blank, i.e. carry the special symbol
@xmath , except for those cells that contain the input bit string.

The head points to one of the cells. It is connected to the control,
which in every step of the computation is in one “internal state” @xmath
out of a finite set @xmath . At the beginning of the computation, it is
in the initial state @xmath , while the end of the computation (i.e. the
halting of the TM) is attained if the control is in the so-called final
state @xmath .

The computation itself, i.e. the TM’s time evolution, is determined by a
so-called transition function @xmath : depending on the current state of
the control @xmath and the symbol @xmath which is on the tape cell where
the head is pointing to, the TM turns into some new internal state
@xmath , writes some symbol @xmath onto this tape cell, and then either
turns left (L) or right (R). Thus, the transition function @xmath is a
map

  -- -------- --
     @xmath   
  -- -------- --

As an example, we consider a TM with alphabet @xmath , internal states
@xmath and transition function @xmath , given by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

We have not defined @xmath and @xmath for any @xmath ; we can define
@xmath at these arguments in an arbitrary way. We imagine that this TM
is started with some input bit string @xmath , which is written onto the
tape segment @xmath . The head initially points to cell number zero. The
computation of the TM will then invert the string and halt. As an
example, in Figure 2.1 , we have depicted the first steps of the TM’s
time evolution on input @xmath .

A QTM is now defined analogously as a TM, but with the important
difference that the transition function is replaced by a transition
amplitude . That is, instead of having a single classical successor
state for every internal state and symbol on the tape, a QTM can evolve
into a superposition of different classical successor states.

For example, we may have a QTM that, if the control’s internal state is
@xmath and the tape symbol is a @xmath , may turn into internal state
@xmath and write a one and turn right, as well as writing a zero and
turning left, both at the same time in superposition, say with complex
amplitudes @xmath and @xmath .

A symbolic picture of this behaviour is depicted in Figure 2.2 . This
can be written as

  -- -------- --
     @xmath   
  -- -------- --

Formally, the transition amplitude @xmath is thus a mapping from @xmath
to the complex functions on @xmath . If the QTM as a whole is described
by a Hilbert space @xmath , then we can linearly extend @xmath to define
some global time evolution on @xmath . We have to take care of two
things:

-   According to the postulates of quantum mechanics, we have to
    construct @xmath in such a way that the resulting global time
    evolution on @xmath is unitary .

-   The complex amplitudes which are assigned to the successor states
    have to be efficiently computable, which has the physical
    interpretation that we should be able to efficiently prepare
    hardware (e.g. some quantum gate) which realizes the transitions
    specified by @xmath .

    Moreover, this requirement also guarantees that every QTM has a
    finite classical description, that there is a universal QTM (see
    discussion below), and that we cannot “hide” information (like the
    answer to infinitely many instances of the halting problem) in the
    transition amplitudes.

Consequently, Bernstein and Vazirani ( [ 4 ] , Def. 3.2.2) define a
quantum Turing machine @xmath as a triplet @xmath , where @xmath is a
finite alphabet with an identified blank symbol @xmath , @xmath is a
finite set of states with an identified initial state @xmath and final
state @xmath , and @xmath is the so-called the quantum transition
function , determining the QTM’s time evolution in a way which is
explained below.

Here, the symbol @xmath denotes the set of complex numbers that are
efficiently computable. In more detail, @xmath if and only if there is a
deterministic algorithm that computes the real and imaginary parts of
@xmath to within @xmath in time polynomial in @xmath .

Every QTM evolves in discrete, integer time steps, where at every step,
only a finite number of tape cells is non-blank. For every QTM, there is
a corresponding Hilbert space

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a finite-dimensional Hilbert space spanned by the
(orthonormal) control states @xmath , while @xmath and @xmath are
separable Hilbert spaces describing the contents of the tape and the
position of the head. In this definition, the symbol @xmath denotes the
set of classical tape configurations with finitely many non-blank
symbols, i.e.

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

For our purpose, it is useful to consider a special class of QTMs with
the property that their tape @xmath consists of two different tracks
(cf. [ 4 , Def. 3.5.5] ), an input track @xmath and an output track
@xmath . This can be achieved by having an alphabet which is a Cartesian
product of two alphabets, in our case @xmath . Then, the tape Hilbert
space @xmath can be written as @xmath , thus

  -- -------- --
     @xmath   
  -- -------- --

The transition amplitude @xmath generates a linear operator @xmath on
@xmath describing the time evolution of the QTM @xmath . We identify
@xmath with the initial state of @xmath on input @xmath , which is
according to the definition in [ 4 ] a state on @xmath where @xmath is
written on the input track over the cell interval @xmath , the empty
symbol @xmath is written on the remaining cells of the input track and
on the whole output track, the control is in the initial state @xmath
and the head is in position @xmath . By linearity, this e.g. means that
the pure qubit string @xmath is identified with the vector @xmath on
input track cells number @xmath and @xmath .

The global state @xmath of @xmath on input @xmath at time @xmath is
given by @xmath . The state of the control at time @xmath is thus given
by partial trace over all the other parts of the machine, that is @xmath
(similarly for the other parts of the QTM). In accordance with [ 4 ,
Def. 3.5.1] , we say that the QTM @xmath halts at time @xmath on input
@xmath , if and only if

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

where @xmath is the final state of the control (specified in the
definition of @xmath ) signaling the halting of the computation. See
Subsection 2.2 for a detailed discussion of this condition (Equation (
2.3 )).

In this thesis, when we talk about a QTM, we do not mean the machine
model itself, but rather refer to the corresponding partial function on
the qubit strings which is computed by the QTM. Note that this point of
view is different from e.g. that of Ozawa [ 33 ] who describes a QTM as
a map from @xmath to the set of probability distributions on @xmath .

We still have to define what is meant by the output of a QTM @xmath ,
once it has halted at some time @xmath on some input qubit string @xmath
. We could take the state of the output tape @xmath to be the output,
but this is not a qubit string, but instead a density operator on the
Hilbert space @xmath . Hence, we define a quantum operation @xmath which
maps the density operators on @xmath to density operators on @xmath ,
i.e. to the qubit strings. The operation @xmath “reads” the output from
the tape.

###### Definition 2.1.2 (Reading Operation)

A quantum operation @xmath is called a reading operation , if for every
finite set of classical strings @xmath , it holds that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the projector onto @xmath .

The condition specified above does not determine @xmath uniquely; there
are many different reading operations. For the remainder of this thesis,
we fix the reading operation @xmath which is specified in the following
example.

###### Example 2.1.3

Let @xmath denote the classical output track configurations as defined
in Equation ( 2.2 ), with @xmath . Then, for every @xmath , let @xmath
be the classical string that consists of the bits of @xmath from cell
number zero to the last non-blank cell, i.e.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

For every @xmath , there is a countably-infinite number of @xmath such
that @xmath . Thus, to every @xmath , we can assign a natural number
@xmath which is the number of @xmath in some enumeration of the set
@xmath ; we only demand that @xmath if @xmath . Hence, if (as usual)
@xmath denotes the Hilbert space of square-summable sequences, then the
map @xmath , defined by linear extension of

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

is unitary. Then, the quantum operation

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

is a reading operation.

We are now ready to define QTMs as partial maps on the qubit strings.

###### Definition 2.1.4 (Quantum Turing Machine (QTM))

A partial map @xmath will be called a QTM, if there is a
Bernstein-Vazirani two-track QTM @xmath (see [ 4 ] , Def. 3.5.5) with
the following properties:

-   @xmath ,

-    the corresponding time evolution operator @xmath is unitary,

-    if @xmath halts on input @xmath at some time @xmath , then @xmath ,
    where @xmath is the reading operation specified in Example 2.1.3
    above. Otherwise, @xmath is undefined.

A fixed-length QTM is the restriction of a QTM to the domain @xmath of
length eigenstates. We denote the domain of definition of a QTM @xmath
by @xmath .

The definition of halting, given by Equation ( 2.3 ), is very important,
as we will discuss in Section 2.2 . On the other hand, changing certain
details of a QTM’s definition, like the way to read the output or
allowing a QTM’s head to stay at its position instead of turning left or
right, should not change the results in this thesis.

A simple example of a fixed-length QTM is the identity map on the
fixed-length qubit strings, which corresponds to a machine that moves
the contents of the input track to the output track.

###### Example 2.1.5

The identity map on the fixed-length qubit strings, i.e.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

is a fixed-length QTM.

Proof. We start by defining a classical Turing machine that moves the
content of the input track to the output track and halts. Let @xmath and
@xmath . We look for a transition function @xmath such that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

This is not a complete definition, since we do not specify the action of
@xmath on all the other configurations, but [ 4 , Corollary B.0.15]
guarantees that @xmath can be extended to a total function on all the
configurations in some way (that we are not interested in) such that the
resulting TM @xmath is reversible as long as the following two
conditions are satisfied:

-   Each state can be entered only from one direction, i.e. if @xmath
    and @xmath , then @xmath .

-   The transition function @xmath is one-to-one when direction is
    ignored.

It is easily checked that both conditions are satisfied here. Moreover,
it is not difficult to see that the classical, reversible TM @xmath
defined by the transition function @xmath moves the content of the input
track bit by bit to the output track (while remaining in state @xmath )
just until it detects the first blank symbol on the input track; in this
case, it turns one more step to the right and halts.

As @xmath is a reversible TM, @xmath is also a Bernstein-Vazirani QTM
with unitary time evolution, and thus, @xmath is a QTM in the sense of
Definition 2.1.4 , one that maps every classical binary string onto
itself. Since the halting time and the final position of the head of
@xmath only depend on the length of the input, it follows that
superpositions of classical strings of common length are mapped to
superpositions (the same is true for mixtures). Thus, @xmath for
fixed-length qubit strings @xmath . @xmath

Given that an identity machine is simple to define on fixed-length
inputs (it just moves the contents of the input track to the output
track), it is perhaps surprising that this is not a QTM on
indeterminate-length inputs. The reason is that if the input has
indeterminate length, there is no way to determine when the process of
moving the contents to the other track should halt: it halts at a
superposition of different times if it is programmed as in the previous
example, and this contradicts the halting conditions of Equation ( 2.3
).

###### Example 2.1.6

The identity map on the indeterminate-length qubit strings, i.e.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

is not a QTM.

Proof. Suppose the identity map on the indeterminate-length qubit
strings was a QTM. Let @xmath be an arbitrary indeterminate-length qubit
string, and let @xmath denote the corresponding halting time of the QTM
@xmath on input and output @xmath . Let @xmath be another qubit string
with @xmath .

For @xmath , let @xmath . It follows that @xmath . Since a QTM can only
write one cell of the output tape at a time, it follows that the halting
time corresponding to @xmath must be larger than @xmath . Note that

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

We know from the halting conditions in Equation ( 2.3 ) that

  -- -------- --
     @xmath   
  -- -------- --

Thus, we get the inequality

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which contradicts Equation ( 2.4 ). @xmath

For defining quantum Kolmogorov complexity, we will sometimes need to
give two inputs to a QTM, namely some qubit string @xmath and an integer
@xmath both at the same time. Similarly as in the classical case, we can
join @xmath and a self-delimiting description @xmath of @xmath together
by concatenation (which, in the quantum case, is just the tensor
product).

How can we do this? Since @xmath may be a superposition or mixture of
classical strings of different lengths, it makes no sense to input
@xmath into the QTM, since the QTM cannot extract @xmath from the
resulting qubit string. But there is no problem with the other way
round, i.e. to input @xmath . This leads to the following definition:

###### Definition 2.1.7 (Parameter Encoding)

Let @xmath and @xmath . We define an encoding @xmath of a pair @xmath
into a single qubit string @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Here, @xmath is the following self-delimiting description of @xmath :

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

For every QTM @xmath , we then set @xmath . Moreover, if @xmath is a
rational number with @xmath , and this fraction cannot be reduced any
further, then we define

  -- -------- --
     @xmath   
  -- -------- --

There are many other possibilities to encode an integer @xmath into some
self-delimiting binary string @xmath . We chose this encoding since it
is efficient enough for our purpose (e.g. we can prove some relation
like Lemma 3.1.2 ), but another choice of encoding will not change the
results of this thesis. See also the discussion after Lemma 3.1.2 . Also
note that

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

and the same equation holds true for average length @xmath .

In this thesis, we will sometimes consider the map @xmath for some QTM
@xmath and some fixed integer @xmath . We would like to apply everything
that we have learnt about QTMs to maps like this. Thus, the following
lemma will be useful: \MakeFramed \FrameRestore

###### Lemma 2.1.8

For every QTM @xmath and @xmath , the map @xmath is itself a QTM.

\endMakeFramed

Proof. Let @xmath be the self-delimiting description of @xmath as
specified in Equation ( 2.5 ). Moreover, let @xmath denote a classical
reversible Turing machine that, ignoring its input, prints the classical
string @xmath onto its input track cells left of the starting cell, i.e.
onto the track segment @xmath , and then halts with the head pointing to
the cell in position @xmath . As we know that these input track cells
start with the empty symbol, this can be done reversibly.

Since the reversible TM @xmath is also a QTM, there is a QTM that
carries out the computation of @xmath , followed by the computation of
@xmath (cf. [ 4 , Dovetailing Lemma] ). Nevertheless, the resulting QTM
is not exactly what we want, since it will produce @xmath ’s output on
input @xmath starting in output cell number @xmath , not in cell @xmath
.

To circumvent this problem, we construct some modification @xmath of
@xmath , which then will give the correct output, if it is joined to
@xmath . To simplify the discussion, we describe the solution for the
special case that @xmath has length one. Moreover, we restrict the proof
to the situation that @xmath is a classical reversible @xmath ; the
quantum generalization will be straightforward.

If @xmath ’s head points to some cell number @xmath , then @xmath reads
and writes cell number @xmath of the input track, and at the same time
cell number @xmath of the output track. The trick now is to program
@xmath in such a way that it effectively reads and writes input track
cell @xmath , but output track cell @xmath . We choose the control state
space @xmath of @xmath to be three times as large as @xmath ’s state
space @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Now we construct some modified transition function @xmath for the QTM
@xmath from @xmath ’s transition function @xmath . Suppose that one of
the transition rules for @xmath is, for example,

  -- -------- --
     @xmath   
  -- -------- --

which says that whenever @xmath is in state @xmath and reads the symbol
@xmath on the input track and @xmath on the output track, then it turns
into state @xmath , writes a @xmath onto the input track and a blank
symbol onto the output track and then turns left.

We decompose this step into three steps for @xmath :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Here, @xmath and @xmath denote arbitrary symbols (zero, one, or blank).
The succession of steps that @xmath performs with that transition
function is depicted in Figure 2.3 .

If the computations of @xmath are followed by the modified QTM @xmath ,
then the output of the resulting QTM will thus be @xmath . @xmath

### 2.2 Halting and Universality of QTMs

There has been a vivid discussion in the literature on the question when
we can consider a QTM as having halted on some input and how this is
compatible with unitary time evolution, see e.g. [ 29 , 24 , 32 , 40 ,
25 ] . We will not get too deep into this discussion, but rather analyze
in detail the simple definition for halting by Bernstein and Vazirani [
4 ] , which we also use in this thesis, as specified in Equation ( 2.3
). We argue below that this definition is useful and natural, at least
for the purpose to study quantum Kolmogorov complexity.

Note that whatever definition of “halting” we choose for a QTM, there is
one problem which is unavoidable in principle, originating from quantum
theory itself. Suppose we are given some classical string @xmath , and
we want to find out whether @xmath is halting for a given classical TM
@xmath or not, i.e. if @xmath halts on input @xmath or not. ¹ ¹ 1 In
this discussion as well as in the remainder of this thesis, we call some
bit or qubit string @xmath halting for a TM or QTM @xmath , if @xmath
halts on input @xmath . Then, we can always input @xmath into the TM
@xmath , and observe @xmath ’s computation for a long time. Once we
observe halting of @xmath , we know for sure that @xmath is halting, of
course. If we have waited for a very long time and have not observed
halting of @xmath , we may believe that @xmath is non-halting, although
we can never be sure. Yet, if @xmath is a very simple TM for which we
can predict the time evolution completely, then we may find a proof that
@xmath is non-halting for @xmath .

If we define some notion of “halting” for a QTM and qubit strings, this
means that we split the space of qubit strings into two parts: the
halting qubit strings @xmath and the non-halting qubit strings @xmath .

  -- -------- --
     @xmath   
  -- -------- --

It follows immediately that @xmath and @xmath cannot be orthogonal, i.e.

  -- -------- --
     @xmath   
  -- -------- --

Thus, if we have some unknown ² ² 2 “Unknown” here means that we do not
have a classical description of @xmath , e.g. we do not know exactly how
the state was created, and thus cannot obtain any copy of @xmath .
quantum state @xmath , and we are given the description of some QTM
@xmath , then it is unavoidable that at least one of the following two
problems occurs:

-   It may be true that @xmath is halting for @xmath , but we cannot
    find out with certainty by any possible measurement that this is
    true.

-   It may be true that @xmath is non-halting for @xmath , but we cannot
    prove this with certainty by any possible measurement, even if
    @xmath is so simple that we can completely predict its time
    evolution.

It is impossible to get rid of both problems at once, but the definition
of halting in this thesis avoids problem (a), i.e. in principle, one can
find out by measurement with certainty if some input is halting for a
QTM. Recall from Subsection 2.1.2 how we have defined that a QTM @xmath
halts on some input @xmath at time @xmath : according to Equation ( 2.3
), we demand that

  -- -------- --
     @xmath   
  -- -------- --

Thus, given some unknown quantum state @xmath , if it is halting, then
we can find out for sure that it is, at least in principle, by supplying
it as input to @xmath and periodically observing the control state. The
aforementioned halting conditions guarantee that projective measurements
with respect to the projectors @xmath and @xmath do not spoil the
computation.

As the control state @xmath is, in general, some mixed state on the
control’s Hilbert space @xmath , the overlap with the final state @xmath
will generally be some arbitrary number between zero and one. Hence, for
most input qubit strings @xmath , there will be no time @xmath such that
the aforementioned halting conditions are satisfied. We call those qubit
strings non-halting in accordance with the discussion above, and
otherwise @xmath -halting , where @xmath is the corresponding halting
time.

In Subsection 2.3.1 , we analyze the resulting geometric structure of
the halting input qubit strings. We show that inputs @xmath with some
fixed length @xmath that make the QTM @xmath halt after @xmath steps
form a linear subspace @xmath . Moreover, inputs with different halting
times are mutually orthogonal, i.e. @xmath if @xmath . According to the
halting conditions given above, this is almost obvious: Superpositions
of @xmath -halting inputs are again @xmath -halting, and inputs with
different halting times can be perfectly distinguished, just by
observing their halting time.

In Figure 2.4 , a geometrical picture of the halting space structure is
shown: The whole space @xmath represents the space of inputs of some
fixed length @xmath , i.e. @xmath , while the plane and the straight
line represent two different halting spaces @xmath and @xmath . Every
vector within these subspaces is perfectly halting, while every vector
“in between” is non-halting and not considered a useful input for the
QTM @xmath .

At first, it seems that the halting conditions given above are far too
restrictive. Don’t we loose a lot by dismissing every input which does
not satisfy those conditions perfectly, but, say, only approximately up
to some small @xmath ? To see that it is not that bad, note that

-   most (if not all) of the well-known quantum algorithms, like the
    quantum Fourier transform or Shor’s algorithm, have classically
    controlled halting. That is, the halting time is known in advance,
    and can be controlled by a classical subprogram.

-   in Section 2.4 , we show that every input that is almost halting can
    be modified by adding at most a constant number of qubits to halt
    perfectly , i.e. to satisfy the aforementioned halting conditions.
    This can be interpreted as some kind of “stability result”, showing
    that the halting conditions are not “unphysical”, but have some kind
    of built-in error tolerance that was not expected from the
    beginning.

Moreover, this definition of halting is very useful. Given two QTMs
@xmath and @xmath , it enables us to construct a QTM @xmath which
carries out the computations of @xmath , followed by the computations of
@xmath , just by redirecting the final state @xmath of @xmath to the
starting state @xmath of @xmath (see [ 4 , Dovetailing Lemma 4.2.6] ).
In addition, it follows from this definition that QTMs are quantum
operations (cf. Lemma 2.3.4 ), which is a very useful and plausible
property.

Even more important, at each single time step, an outside observer can
make a measurement of the control state, described by the operators
@xmath and @xmath (thus observing the halting time), without spoiling
the computation, as long as the input @xmath is halting. As soon as
halting is detected, the observer can extract the output quantum state
from the output track (tape) and use it for further quantum information
processing. This is true even if the halting time is very large, which
typically happens in the study of Kolmogorov complexity.

Finally, if we instead introduced some probabilistic notion of halting
(say, we demanded that we observe halting of the QTM @xmath at some time
@xmath with some large probability @xmath ), then it would not be so
clear how to define quantum Kolmogorov complexity correctly. Namely if
the halting probability is much less than one, it seems necessary to
introduce some kind of “penalty term” into the definition of quantum
Kolmogorov complexity: there should be some trade-off between program
length and halting accuracy, and it is not so clear what the correct
trade-off should be. For example, what is the complexity of a qubit
string that has a program of length 100 which halts with probability
@xmath , and another program of length 120 which halts with probability
@xmath ? The definition of halting that we use in this thesis avoids
such questions.

#### 2.2.1 Different Notions of Universality for QTMs

Bernstein and Vazirani [ 4 ] have shown that there exists a universal
QTM (UQTM) @xmath . It is important to understand what exactly they mean
by “universal”. According to [ 4 , Thm. 7.0.2] , this UQTM @xmath has
the property that for every QTM @xmath there is some classical bit
string @xmath (containing a description of the QTM @xmath ) such that

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

for every input @xmath , accuracy @xmath and number of time steps @xmath
.

This means that the UQTM @xmath simulates every other QTM @xmath within
any desired accuracy and outputs an approximation of the output track
content of @xmath and halts, as long as the number of time steps @xmath
is given as input in advance.

Since the purpose of Bernstein and Vazirani’s work was to study the
computational complexity of QTMs, it was a reasonable assumption that
the halting time @xmath is known in advance (and not too large) and can
be specified as additional input. The most important point for them was
not to have short inputs, but to prove that the simulation of @xmath by
@xmath is efficient, i.e. has only polynomial slowdown.

The situation is different if one is interested in studying quantum
Kolmogorov complexity instead. It will be explained in Subsection 2.2.2
below that the universality notion ( 2.7 ) is not enough for proving the
important invariance property of quantum Kolmogorov complexity, which
says that quantum Kolmogorov complexity depends on the choice of the
universal QTM only up to an additive constant.

To prove the invariance property, one needs a generalization of ( 2.7 ),
where the requirement to have the running time @xmath as additional
input is dropped. We show below in Subsection 2.2.3 that there exists a
UQTM @xmath that satisfies such a generalized universality property,
i.e. that simulates every other QTM until that other QTM has halted,
without knowing that halting time in advance, and then halts itself.

Why is that so difficult to prove? At first, it seems that one can just
program the UQTM @xmath mentioned in ( 2.7 ) to simulate the other QTM
@xmath for @xmath time steps, and, after every time step, to check if
the simulation of @xmath has halted or not. If it has halted, then
@xmath halts itself and prints out the output of @xmath , otherwise it
continues.

This approach works for classical TMs, but for QTMs, there is one
problem: in general, the UQTM @xmath can simulate @xmath only
approximately. The reason is the same as for the circuit model, i.e. the
set of basic unitary transformations that @xmath can apply on its tape
may be algebraically independent from that of @xmath , making a perfect
simulation in principle impossible. But if the simulation is only
approximate, then the control state of @xmath will also be simulated
only approximately, which will force @xmath to halt only approximately.
Thus, the restrictive halting conditions given above in Equation ( 2.3 )
will inevitably be violated, and the computation of @xmath will be
treated as invalid and be dismissed by definition.

This is a severe problem that cannot be circumvented easily. Many ideas
for simple solutions must fail, for example the idea to let @xmath
compute an upper bound on the halting time @xmath of all inputs for
@xmath of some length @xmath and just to proceed for @xmath time steps:
upper bounds on halting times are not computable. Another idea is that
the computation of @xmath should somehow consist of a classical part
that controls the computation and a quantum part that does the unitary
transformations on the data. But this idea is difficult to formalize.
Even for classical TMs, there is no general way to split the computation
into “program” and “data” except for special cases, and for QTMs, by
definition, global unitary time evolution can entangle every part of a
QTM with every other part.

Our proof idea rests instead on the observation that every input for a
QTM which is halting can be decomposed into a classical and a quantum
part, which is related to the mutual orthogonality of the halting
spaces. The proof is given in Section 2.3 . Note that we have already
published the contents of this and the following section in [ 28 ] .

#### 2.2.2 Quantum Complexity and its Supposed Invariance

As already explained in the introduction, the classical Kolmogorov
complexity @xmath of a finite bit string @xmath is defined as the
minimal length of any computer program @xmath that, given as input into
a TM @xmath , outputs the string @xmath and makes @xmath halt:

  -- -------- --
     @xmath   
  -- -------- --

For this quantity, running times are not important; all that matters is
the input length. There is a crucial result that is the basis for the
whole theory of Kolmogorov complexity (see [ 23 ] ). Basically, it
states that the choice of the computer @xmath is not important as long
as @xmath is universal; choosing a different universal computer will
alter the complexity only up to some additive constant. More
specifically, there exists a universal computer @xmath such that for
every computer @xmath there is a constant @xmath such that

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

This so-called “invariance property” follows easily from the following
fact: there exists a computer @xmath such that for every computer @xmath
and every input @xmath there is an input @xmath such that @xmath and
@xmath , where @xmath is a constant depending only on @xmath . In short,
there is a computer @xmath that produces every output that is produced
by any other computer, while the length of the corresponding input blows
up only by a constant summand. One can think of the bit string @xmath as
consisting of the original bit string @xmath and of a description of the
computer @xmath (of length @xmath ).

As the invariance property is so important for the theory of classical
Kolmogorov complexity, a study of quantum Kolmogorov complexity
naturally asks for a quantum analogue of this property. The notion of
quantum complexity that we shall define in Chapter 3 is a slight
modification of the definition given by Berthiaume et al. in [ 5 ] . A
closely related quantity has been considered recently by Rogers and
Vedral [ 37 ] .

In both cases [ 5 ] and [ 37 ] , it is claimed that quantum Kolmogorov
complexity is invariant up to an additive constant similar to ( 2.8 ).
Nevertheless, in [ 37 ] no proof is given and the proof in [ 5 ] is
incomplete: in that proof, it is stated that the existence of a
universal QTM @xmath in the sense of Bernstein and Vazirani (see
Equation ( 2.7 )) makes it possible to mimic the classical proof and to
conclude that the UQTM @xmath outputs all that every other QTM outputs,
implying invariance of quantum Kolmogorov complexity.

But this conclusion cannot be drawn so easily, because ( 2.7 ) demands
that the halting time @xmath is specified as additional input, which can
enlarge the input length dramatically, if @xmath is very large (which
typically happens in the study of Kolmogorov complexity).

As explained above in Subsection 2.2.1 , it is not so easy to get rid of
the halting time. The main reason is that the UQTM @xmath can simulate
other QTMs only approximately. Thus, it will also simulate the control
state and the signaling of halting only approximately, and cannot just
“halt whenever the simulation has halted”, because then, it will violate
the restrictive halting conditions given in Equation ( 2.3 ). As we have
chosen this definition of halting for good reasons (cf. the discussion
at the beginning of Section 2.2 above), we do not want to drop it. So
what can we do?

The only way out is to give a proof that despite our restrictive
definition of halting, there still exists some UQTM @xmath that
simulates every other QTM until that other QTM has halted, even if it
does not know the halting time in advance. Yet, it is not enough to rely
on the result ( 2.7 ) by Bernstein and Vazirani; we need another good
idea how to do it. We describe our proof idea in the next subsection,
while the proof will be given below in Section 2.3 .

#### 2.2.3 Strongly Universal QTMs

We are going to prove in Section 2.3 below that there is “strongly
universal” QTM that simulates every other QTM until the other QTM has
halted and then halts itself. Note that the halting state is attained by
@xmath exactly (with probability one) in accordance with the strict
halting definition given in Equation ( 2.3 ). \MakeFramed \FrameRestore

###### Theorem 2.2.1 (Strongly Universal Quantum Turing Machine)

There is a fixed-length quantum Turing machine @xmath such that for
every QTM @xmath and every qubit string @xmath for which @xmath is
defined, there is a qubit string @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

for every @xmath , where the length of @xmath is bounded by @xmath , and
@xmath is a constant depending only on @xmath .

\endMakeFramed

Note that @xmath does not depend on @xmath .

In Chapter 3 , we study several notions of quantum Kolmogorov complexity
at once. To prove invariance for every single notion, we shall also
prove the following slight modifications of Theorem 2.2.1 :

\MakeFramed \FrameRestore

###### Proposition 2.2.2 (Parameter Strongly Universal QTM)

There is a fixed-length quantum Turing machine @xmath with the property
of Theorem 2.2.1 that additionally satisfies the following: For every
QTM @xmath and every qubit string @xmath , there is a qubit string
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

if @xmath is defined for every @xmath , where the length of @xmath is
bounded by @xmath , and @xmath is a constant depending only on @xmath .

\endMakeFramed

It may first seem that this Proposition 2.2.2 is a simple corollary of
Theorem 2.2.1 , but this is not true. The problem is that the
computation of @xmath may take a different number of time steps @xmath
for different @xmath (typically, @xmath as @xmath ). Just using the
result of Theorem 2.2.1 would give a corresponding qubit string @xmath
that depends on @xmath , but here we demand that the qubit string @xmath
is the same for every @xmath , which will be important for proving
Theorem 3.3.1 .

We also sketch some proof idea for the following conjecture:

###### Conjecture 2.2.3 (Average-Length Strongly Universal QTM)

There is a prefix QTM @xmath such that for every prefix QTM @xmath and
every qubit string @xmath for which @xmath is defined, there is a qubit
string @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

for every @xmath , where the average length of @xmath is bounded by
@xmath , and @xmath is a constant depending only on @xmath .

We define the notion of a prefix QTM in Definition 2.3.5 . The reason
why we give a proof idea for this conjecture is that it explains why it
seems that we need the condition that @xmath has to be prefix-free. This
supports the point of view that average length @xmath is intimately
connected with the notion of prefix-free qubit strings.

We give a full proof of Theorem 2.2.1 , describing in every single
detail how the corresponding UQTM @xmath works, below in Section 2.3 .
This involves many analytic estimates to prove that certain numerical
approximations made by @xmath are accurate enough.

Since the technical details are so similar, we will only sketch the
proof of Proposition 2.2.2 in Section 2.3 . Although we have a proof
sketch of Conjecture 2.2.3 , we do not think that we have settled it
completely (in contrast to Proposition 2.2.2 ) because it depends
heavily on the property that the domain of definition of the QTM is
prefix-free, and it is not clear that this fact survives the numerical
approximations done by the QTM @xmath . In the remainder of this
subsection, we describe the ideas of the proof of Theorem 2.2.1 .

The proof of Theorem 2.2.1 relies on the observation about the mutual
orthogonality of the halting spaces, as explained above at the beginning
of Section 2.2 . Fix some QTM @xmath , and denote the set of vectors
@xmath which cause @xmath to halt at time @xmath by @xmath . If @xmath
is any halting input for @xmath , then we can decompose @xmath in some
sense into a classical and a quantum part. Namely, the information
contained in @xmath can be split into a

-   classical part: The vector @xmath is an element of which of the
    subspaces @xmath ?

-   quantum part: Given the halting time @xmath of @xmath , then where
    in the corresponding subspace @xmath is @xmath situated?

Our goal is to find a QTM @xmath and an encoding @xmath of @xmath which
is only one qubit longer and which makes the (cleverly programmed) QTM
@xmath output a good approximation of @xmath . First, we extract the
quantum part out of @xmath . While @xmath , the halting space @xmath
that contains @xmath is only a subspace and might have much smaller
dimension @xmath . This means that we need less than @xmath qubits to
describe the state @xmath ; indeed, @xmath qubits are sufficient. In
other words, there is some kind of “standard compression map” @xmath
that maps every vector @xmath into the @xmath -qubit-space @xmath .
Thus, the qubit string @xmath of length @xmath can be considered as the
“quantum part” of @xmath .

So how can the classical part of @xmath be encoded into a short
classical binary string? Our task is to specify what halting space
@xmath corresponds to @xmath . Unfortunately, it is not possible to
encode the halting time @xmath directly, since @xmath might be huge and
may not have a short description. Instead, we can encode the halting
number . Define the halting time sequence @xmath as the set of all
integers @xmath such that @xmath , ordered such that @xmath for every
@xmath , that is, the set of all halting times that can occur on inputs
of length @xmath . Thus, there must be some @xmath such that @xmath ,
and @xmath can be called the halting number of @xmath . Now, we assign
code words @xmath to the halting numbers @xmath , that is, we construct
a prefix code @xmath . We want the code words to be short; we claim that
we can always choose the lengths as

  -- -------- --
     @xmath   
  -- -------- --

This can be verified by checking the Kraft inequality:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

since the halting spaces are mutually orthogonal.

Putting classical and quantum part of @xmath together, we get

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the halting number of @xmath . Thus, the length of
@xmath is exactly @xmath .

Let @xmath be a self-delimiting description of the QTM @xmath . The idea
is to construct a QTM @xmath that, on input @xmath , proceeds as
follows:

-   By classical simulation of @xmath , it computes descriptions of the
    halting spaces @xmath and the corresponding code words @xmath one
    after the other, until at step @xmath , it finds the code word
    @xmath that equals the code word in the input.

-   Afterwards, it applies a (quantum) decompression map to
    approximately reconstruct @xmath from @xmath .

-   Finally, it simulates (quantum) for @xmath time steps the time
    evolution of @xmath on input @xmath and then halts, whatever happens
    with the simulation.

Such a QTM @xmath will have the strong universality property as stated
in Theorem 2.2.1 . Unfortunately, there are many difficulties that have
to be overcome by the proof in Section 2.3 :

-   Also classically, QTMs can only be simulated approximately. Thus, it
    is for example impossible for @xmath to decide by classical
    simulation whether the QTM @xmath halts on some input @xmath
    perfectly or only approximately at some time @xmath . Thus, we have
    to define certain @xmath -approximate halting spaces @xmath and
    prove a lot of lemmas with nasty inequalities.

-   According to the statement of Theorem 2.2.1 , we have to consider
    mixed inputs and outputs, too.

-   The aforementioned prefix code must have the property that one code
    word can be constructed after the other (since the sequence of all
    halting times is not computable), see Lemma 2.3.16 .

We show that all these difficulties (and some more) can be overcome, and
the idea outlined above can be converted to a formal proof of Theorem
2.2.1 which we give in full detail in Section 2.3 .

### 2.3 Construction of a Strongly Universal QTM

The aim of this section is to give a full proof of Theorem 2.2.1 . This
will be done in several steps: In Subsection 2.3.1 , we show that the
domain of definition of a QTM is given by mutually orthogonal halting
spaces. Afterwards, we show in Subsection 2.3.2 that these subspaces
have computable approximations, and we prove several properties of the
corresponding “approximate halting spaces”. In Subsection 2.3.3 , we
explain how the classical and quantum part of some input can be coded
and decoded by the UQTM @xmath . Finally, in Subsection 2.3.4 , we put
all these partial results together to construct the strongly universal
QTM @xmath mentioned in Theorem 2.2.1 .

#### 2.3.1 Halting Subspaces and their Orthogonality

As already explained at the beginning of Section 2.2 , restricting to
pure input qubit strings @xmath of some fixed length @xmath , the
vectors with equal halting time @xmath form a linear subspace of @xmath
. Moreover, inputs with different halting times are mutually orthogonal,
as depicted in Figure 2.4 . We will now use the formalism for QTMs
introduced in Subsection 2.1.2 to give a formal proof of these
statements. We use the subscripts @xmath , @xmath , @xmath and @xmath to
indicate to what part of the tensor product Hilbert space a vector
belongs.

###### Definition 2.3.1 (Halting Qubit Strings)

Let @xmath be a qubit string and @xmath a quantum Turing machine. Then,
@xmath is called @xmath -halting (for @xmath ) , if @xmath halts on
input @xmath at time @xmath . We define the halting sets and halting
subspaces

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Note that the only difference between @xmath and @xmath is that the
latter set contains non-normalized vectors. It will be shown below that
@xmath is indeed a linear subspace.

\MakeFramed \FrameRestore

###### Theorem 2.3.2 (Halting Subspaces)

For every QTM @xmath , @xmath and @xmath , the sets @xmath and @xmath
are linear subspaces of @xmath resp. @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. Let @xmath . The property that @xmath is @xmath -halting is
equivalent to the statement that there are states @xmath and
coefficients @xmath for every @xmath and @xmath such that

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.9)
     @xmath   @xmath   @xmath      (2.10)
  -- -------- -------- -------- -- --------

where @xmath is the unitary time evolution operator for the QTM @xmath
as a whole, and @xmath denotes the initial state of the control, output
track and head. Note that @xmath does not depend on the input qubit
string (in this case @xmath ).

An analogous equation holds for @xmath , since it is also @xmath
-halting by assumption. Consider a normalized superposition @xmath :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, the superposition also satisfies condition ( 2.9 ), and, by a
similar calculation, condition ( 2.10 ). It follows that @xmath must
also be @xmath -halting. Hence, @xmath is a linear subspace of @xmath .
As the intersection of linear subspaces is again a linear subspace, so
must be @xmath .

Let now @xmath and @xmath such that @xmath . Again by Equations ( 2.9 )
and ( 2.10 ), it holds

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

It follows that @xmath , and similarly for @xmath . @xmath

The physical interpretation of the preceding theorem is straightforward:
by linearity of the time evolution, superpositions of @xmath -halting
strings are again @xmath -halting, and strings with different halting
times can be perfectly distinguished by observing their halting time.

It is now clear what the domain of definition of a QTM looks like:
\MakeFramed \FrameRestore

###### Lemma 2.3.3 (Domain of Definition of a QTM)

If @xmath is a QTM, then its domain of definition is given by

  -- -------- --
     @xmath   
  -- -------- --

i.e. the set of density operators on the linear subspaces of pure @xmath
-halting qubit strings.

\endMakeFramed

Proof. Let @xmath have spectral decomposition @xmath , with @xmath . Let
@xmath be the halting time that corresponds to @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

It follows that each element of this convex combination must itself
satisfy this equation. Thus, @xmath , and @xmath is a density operator
on @xmath . @xmath

In general, different inputs @xmath have different halting times @xmath
and the corresponding outputs are essentially results of different
unitary transformations given by @xmath , where @xmath denotes @xmath ’s
time evolution operator. However, the action of the partial map @xmath
on @xmath may be extended to a valid quantum operation on @xmath :
\MakeFramed \FrameRestore

###### Lemma 2.3.4 (QTMs are Quantum Operations)

For every QTM @xmath there is a quantum operation @xmath , such that for
every @xmath

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. Let @xmath and @xmath be an orthonormal basis of @xmath , @xmath
, and the orthogonal complement of @xmath within @xmath , respectively.
We add an ancilla Hilbert space @xmath to the QTM, and define a linear
operator @xmath by specifying its action on the orthonormal basis
vectors @xmath :

  -- -- -- --------
           (2.11)
  -- -- -- --------

Since the right hand side of ( 2.11 ) is a set of orthonormal vectors in
@xmath , the map @xmath is an isometry (i.e. @xmath ). Thus, the map
@xmath is trace-preserving, completely positive (see [ 16 , 22 , 35 ] ).
Its composition with the partial trace, given by @xmath , is a quantum
operation. @xmath

In the following, it will turn out that it is interesting to study
prefix QTMs, i.e. QTMs which are in a certain sense quantum
generalizations of classical prefix Turing machines. A classical TM is
called prefix if its domain of definition is a prefix-free set. We can
define a natural quantum generalization by calling a QTM prefix if its
domain of definition in the qubit strings is in a certain sense
prefix-free, too. Following the lines of Schumacher and Westmoreland [
39 ] , who have defined prefix-free quantum codes , leads us to
Definition 2.3.5 below.

To state the definition, we fix some notation. If a classical string
@xmath has length @xmath , then the string @xmath is defined to consist
of the first @xmath bits of @xmath . Thus, @xmath is the prefix of
@xmath of length @xmath .

Similarly, we can define the prefix @xmath of a qubit string @xmath in a
simple way. First, we identify the qubit string @xmath with the
corresponding density operator on the QTM’s output tape Hilbert space
@xmath , such that the string is “written” onto the blank tape, starting
in cell @xmath , and ending in cell @xmath , as the input for a QTM has
been defined in Subsection 2.1.2 . Then, we define the prefix @xmath by
the partial trace

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be any configuration which is not of the form @xmath , where
@xmath is a binary string (for example, @xmath ). Then it is easy to see
that @xmath . Thus, @xmath is a superposition and mixture of classical
strings embedded on the tape, and can be identified with a corresponding
qubit string @xmath .

###### Definition 2.3.5 (Prefix QTM)

A QTM @xmath is called prefix if for every pair of pure qubit strings
@xmath , @xmath with @xmath , it holds

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the qubit string consisting of the first @xmath qubits
of @xmath as defined above.

The following lemma shows that the prefix property of QTMs resembles the
prefix property of classical TMs: \MakeFramed \FrameRestore

###### Lemma 2.3.6

If @xmath is a prefix QTM, then

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. Let @xmath be a prefix QTM, and let @xmath with @xmath . If
@xmath is the spectral decomposition of @xmath with @xmath for every
@xmath , then there must be some @xmath such that @xmath ; fix this
@xmath until the end of the proof.

Suppose @xmath with @xmath . As @xmath is prefix, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

identifying a qubit string @xmath with the corresponding vector on the
tape Hilbert space @xmath . Thus, @xmath , and since @xmath , it follows
that @xmath . But

  -- -------- --
     @xmath   
  -- -------- --

so @xmath as well cannot be halting for @xmath , and so @xmath . @xmath

#### 2.3.2 Approximate Halting Spaces

We start by defining the notion of approximate halting.

###### Definition 2.3.7 (@xmath-@xmath-halting Property)

A qubit string @xmath will be called @xmath - @xmath -halting for @xmath
for some @xmath , @xmath and @xmath a QTM, if and only if

  -- -- --
        
  -- -- --

Let @xmath be the unit sphere in @xmath , and let @xmath be an open
ball. The ball @xmath will be called @xmath - @xmath -halting for @xmath
if there is some @xmath which is @xmath - @xmath -halting for @xmath .
Moreover, we use the following symbols:

-   @xmath for any subset @xmath and @xmath ,

-   @xmath , where @xmath denotes the computational basis vectors of
    @xmath ,

-   @xmath for every vector @xmath .

The set of vectors with rational coordinates, denoted @xmath , will in
the following be used frequently as inputs or outputs of algorithms.
Such vectors can be symbolically added or multiplied with rational
scalars without any error. Also, given @xmath , it is an easy task to
decide unambiguously which vector has larger norm than the other (one
can compare the rational numbers @xmath and @xmath , for example).

\MakeFramed \FrameRestore

###### Lemma 2.3.8 (Algorithm for @xmath-@xmath-halting-Property of
Balls)

There exists a (classical) algorithm @xmath which, on input @xmath ,
@xmath , @xmath and a classical description @xmath of a fixed-length QTM
@xmath , always halts and returns either @xmath or @xmath under the
following constraints:

-    If @xmath is not @xmath - @xmath -halting for @xmath , then the
    output must be @xmath .

-    If @xmath is @xmath - @xmath -halting for @xmath , then the output
    must be @xmath .

\endMakeFramed

Proof. The algorithm @xmath computes a set of vectors @xmath such that
for every vector @xmath there is a @xmath such that @xmath , and also
vice versa (i.e. @xmath for every @xmath ).

For every @xmath , the algorithm simulates the QTM @xmath on input
@xmath classically for @xmath time steps and computes an approximation
@xmath of the quantity @xmath for every @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

How can this be achieved? Since the number of time steps @xmath is
finite, time evolution will be restricted to a finite subspace @xmath
corresponding to a finite number of tape cells, which also restricts the
state space of the head (that points on tape cells) to a finite subspace
@xmath . Thus, it is possible to give a matrix representation of the
time evolution operator @xmath on @xmath , and the expression given
above can be numerically calculated just by matrix multiplication and
subsequent numerical computation of the partial trace.

Every @xmath that satisfies @xmath for every @xmath will be marked as
“approximately halting”. If there is at least one @xmath that is
approximately halting, @xmath shall halt and output @xmath , otherwise
it shall halt and output @xmath .

To see that this algorithm works as claimed, suppose that @xmath is not
@xmath - @xmath -halting for @xmath , so for every @xmath there is some
@xmath such that @xmath . Also, for every @xmath , there is some vector
@xmath with @xmath , so

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where we have used Lemma A.4 and Lemma A.6 . Thus, for every @xmath it
holds

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which makes the algorithm halt and output @xmath .

On the other hand, suppose that @xmath is @xmath - @xmath -halting for
@xmath , i.e. there is some @xmath which is @xmath - @xmath -halting for
@xmath . By construction, there is some @xmath such that @xmath . A
similar calculation as above yields @xmath for every @xmath , so @xmath
, and the algorithm outputs @xmath . @xmath

\MakeFramed \FrameRestore

###### Lemma 2.3.9 (Algorithm @xmath for Interpolating Subspace)

There exists a (classical) algorithm @xmath which, on input @xmath ,
@xmath , @xmath , @xmath , @xmath and @xmath , always halts and returns
the description of a pair @xmath with @xmath and @xmath a linear
subspace, under the following constraints:

-    If the output is @xmath , then @xmath must be a subspace of
    dimension @xmath such that @xmath for every @xmath and @xmath for
    every @xmath .

-    If there exists a subspace @xmath of dimension @xmath such that
    @xmath for every @xmath and @xmath for every @xmath , then the
    output must be of the ³ ³ 3 @xmath will then be an approximation of
    @xmath . form @xmath .

The description of the subspace @xmath is a list of linearly independent
vectors @xmath .

\endMakeFramed

Proof. Proving this lemma is a routine (but lengthy) exercise. The idea
is to construct an algorithm that looks for such a subspace by brute
force, that is, by discretizing the set of all subspaces within some
(good enough) accuracy. We omit the details. @xmath

We proceed by defining the notion of an approximate halting space . Note
that the definition depends on the details of the previously defined
algorithms in Lemma 2.3.8 and 2.3.9 (for example, there are always
different possibilities to compute the necessary discretizations). Thus,
we fix a concrete instance of all those algorithms for the rest of the
paper.

###### Definition 2.3.10 (Approximate Halting Spaces)

We define ⁴ ⁴ 4 From a formal point of view, the notation should rather
read @xmath instead of @xmath , since this space depends also on the
choice of the classical description @xmath of @xmath . the @xmath
-approximate halting space @xmath and the @xmath -approximate halting
accuracy @xmath as the outputs of the following classical algorithm on
input @xmath , @xmath and @xmath , where @xmath is a classical
description of a fixed-length QTM @xmath :

-    Let @xmath .

-    Compute a covering of @xmath of open balls of radius @xmath , that
    is, a set of vectors @xmath ( @xmath ) with @xmath for every @xmath
    such that @xmath .

-    For every @xmath , compute @xmath and @xmath , where @xmath is the
    algorithm for testing the @xmath - @xmath -halting property of balls
    of Lemma 2.3.8 . If the output is @xmath for every @xmath , then
    output @xmath and halt. Otherwise set for @xmath and @xmath

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
         @xmath   @xmath   @xmath   
      -- -------- -------- -------- --

    If @xmath , i.e. if the set @xmath is empty, output @xmath and halt.

-    Set @xmath .

-    Let @xmath , @xmath and @xmath . Use the algorithm @xmath of Lemma
    2.3.9 to search for an interpolating subspace, i.e., compute @xmath
    . If the output of @xmath is @xmath , output @xmath and halt.

-    Set @xmath . If @xmath , then go back to step (5).

-    Set @xmath and go back to step (3).

Moreover, let @xmath .

The following theorem proves that this definition makes sense:

\MakeFramed \FrameRestore

###### Theorem 2.3.11

The algorithm in Definition 2.3.10 always terminates on any input; thus,
the approximate halting spaces @xmath are well-defined.

\endMakeFramed

Proof. Define the function @xmath by @xmath . Lemma A.4 and A.6 yield

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

so @xmath is continuous. For the special case @xmath , it must thus hold
that @xmath . If the algorithm has run long enough such that @xmath , it
must then be true that @xmath for every @xmath , since all the balls
@xmath are not @xmath - @xmath -halting. This makes the algorithm halt
in step (3).

Now consider the case @xmath . The continuous function @xmath attains a
minimum on every compact set @xmath , so let @xmath ( @xmath ). If
@xmath for every @xmath , then for every @xmath and @xmath , there is
some vector @xmath which is @xmath - @xmath -halting for @xmath , so
@xmath for every @xmath , and so @xmath in step (3). Thus, the algorithm
@xmath will by construction find the interpolating subspace @xmath and
cause halting in step (5).

Otherwise, let @xmath . Suppose that the algorithm has run long enough
such that @xmath . By construction of the algorithm @xmath , if @xmath ,
it follows that @xmath is @xmath - @xmath -halting for @xmath , but
then, @xmath , so @xmath , so there is some @xmath which is @xmath -
@xmath -halting for @xmath , so @xmath . On the other hand, if @xmath ,
it follows that @xmath is not @xmath - @xmath -halting for @xmath .
Thus, @xmath according to ( 2.12 ), so @xmath , and by elementary
estimations @xmath . By definition of the algorithm @xmath , it follows
that @xmath for @xmath and some subspace @xmath , which makes the
algorithm halt in step (5). @xmath

We are now going to show some properties of the approximate halting
spaces. These properties show that these spaces are, in some sense, good
approximation of a QTM’s “true” halting spaces.

\MakeFramed \FrameRestore

###### Theorem 2.3.12 (Properties of Approximate Halting Spaces)

The approximate halting spaces @xmath have the following properties:

-    Almost-Halting: If @xmath , then @xmath is @xmath - @xmath -halting
    for @xmath .

-    Approximation: For every @xmath , there is a vector @xmath which
    satisfies @xmath .

-    Similarity: If @xmath such that @xmath , then for every @xmath
    there is a vector @xmath which satisfies @xmath .

-    Almost-Orthogonality: If @xmath and @xmath for @xmath , then it
    holds that @xmath .

\endMakeFramed

Proof. Assume that @xmath . Let @xmath , and let @xmath be the covering
of @xmath from the algorithm in Definition 2.3.10 . By construction,
there is some @xmath such that @xmath . The subspace @xmath is computed
in step (5) of the algorithm in Definition 2.3.10 via @xmath , and since
@xmath , it follows from the properties of the algorithm @xmath in Lemma
2.3.9 that @xmath for every @xmath in step (3) of the algorithm. Thus,
@xmath , and it follows from the properties of the algorithm @xmath in
Lemma 2.3.8 that @xmath is @xmath - @xmath -halting for @xmath , so
there is some @xmath which is @xmath - @xmath -halting for @xmath .
Since @xmath , the almost-halting property follows from Equation ( 2.12
).

To prove the approximation property, assume that @xmath . Let @xmath ;
again, there is some @xmath such that @xmath , so @xmath is @xmath -
@xmath -halting for @xmath , and @xmath for every @xmath by definition
of the algorithm @xmath . For step (3) of the algorithm in Definition
2.3.10 , it thus always holds that @xmath . The output of the algorithm
is computed in step (5) via @xmath . By definition of @xmath , it holds
@xmath , and by elementary estimations it follows that @xmath , so there
is some @xmath such that @xmath . Since @xmath and @xmath , the
approximation property follows.

Notice that under the assumptions given in the statement of the
similarity property, it follows from the almost-halting property that if
@xmath , then @xmath must be @xmath - @xmath -halting for @xmath .
Consider the computation of @xmath by the algorithm in Definition 2.3.10
. By construction, it always holds that the parameter @xmath during the
computation satisfies @xmath , so @xmath is always @xmath - @xmath
-halting for @xmath , and if @xmath , it follows that @xmath . The rest
follows in complete analogy to the proof of the approximation property.

For the almost-orthogonality property, suppose @xmath and @xmath are two
arbitrary qubit strings of length @xmath with different approximate
halting times @xmath . There is some @xmath such that @xmath , so @xmath
. Since @xmath at step (5) of the computation of @xmath , it follows
from the definition of @xmath that there is no @xmath such that @xmath
for the sets defined in step (3) of the algorithm above. Thus, @xmath ,
and by definition of @xmath it follows that @xmath must be @xmath -
@xmath -halting for @xmath , so there is some vector @xmath which is
@xmath - @xmath -halting for @xmath and satisfies @xmath . Analogously,
there is some vector @xmath which is @xmath - @xmath -halting for @xmath
and satisfies @xmath .

From the definition of the trace distance for pure states (see [ 30 ,
(9.99)] and of the @xmath - @xmath -halting property in Definition 2.3.7
together with Lemma A.4 and Lemma A.6 , it follows that

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.13)
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

This proves the almost-orthogonality property. @xmath

The following corollary proves that the approximate halting spaces
@xmath are “not too large” if @xmath is small enough. Formally, we will
need this property to prove the Kraft inequality for some code in
Subsection 2.3.4 , as well as for some estimation in Section 3.4 on the
quantum complexity of classical strings.

\MakeFramed \FrameRestore

###### Corollary 2.3.13 (Dimension Bound for Halting Spaces)

If @xmath , then @xmath .

\endMakeFramed

Proof. Suppose that @xmath . Then, choose orthonormal bases in each of
the spaces @xmath , and let @xmath be the union of the first @xmath of
these basis vectors. By construction and by the almost-orthogonality
property of Theorem 2.3.12 , it follows that @xmath for every @xmath .
Lemma A.2 yields @xmath for @xmath , but @xmath , which is a
contradiction. @xmath

#### 2.3.3 Compression, Decompression, and Coding

In this subsection, we define some compression and coding algorithms
that will be used in the construction of the strongly universal QTM.

###### Definition 2.3.14 (Standard (De-)Compression)

Let @xmath be a linear subspace with @xmath . Let @xmath be the
orthogonal projector onto @xmath , and let @xmath be the computational
basis of @xmath . The result of applying the Gram-Schmidt
orthonormalization procedure to the vectors @xmath (dropping every null
vector) is called the standard basis @xmath of @xmath . Let @xmath be
the @xmath -th computational basis vector of @xmath . The standard
compression @xmath is then defined by linear extension of @xmath for
@xmath , that is, @xmath isometrically embeds @xmath into @xmath . A
linear isometric map @xmath will be called a standard decompression if
it holds that

  -- -------- --
     @xmath   
  -- -------- --

It is clear that there exists a classical algorithm that, given a
description of @xmath (e.g. a list of basis vectors @xmath ), can
effectively compute (classically) an approximate description of the
standard basis of @xmath . Moreover, a quantum Turing machine can
effectively apply a standard decompression map to its input:

\MakeFramed \FrameRestore

###### Lemma 2.3.15 (Q-Standard Decompression Algorithm)

There is a QTM @xmath which, given a description ⁵ ⁵ 5 (a list of
linearly independent vectors @xmath ) of a subspace @xmath , the integer
@xmath , some @xmath , and a quantum state @xmath , outputs some state
@xmath with the property that @xmath , where @xmath is some standard
decompression map.

\endMakeFramed

Proof. Consider the map @xmath , given by @xmath . The map @xmath
prepends zeroes to a vector; it maps the computational basis vectors of
@xmath to the lexicographically first computational basis vectors of
@xmath . The QTM @xmath starts by applying this map @xmath to the input
state @xmath by prepending zeroes on its tape, creating a state @xmath .

Afterwards, it applies (classically) the Gram-Schmidt orthonormalization
procedure to the list of vectors @xmath , where the vectors @xmath are
the basis vectors of @xmath given in the input, and the vectors @xmath
are the computational basis vectors of @xmath . Since every vector has
rational entries (i.e. is an element of @xmath ), the Gram-Schmidt
procedure can be applied exactly, resulting in a list @xmath of basis
vectors of @xmath which have entries that are square roots of rational
numbers. Note that by construction, the vectors @xmath are the standard
basis vectors of @xmath that have been defined in Definition 2.3.14 .

Let @xmath be the unitary @xmath -matrix that has the vectors @xmath as
its column vectors. The algorithm continues by computing a rational
approximation @xmath of @xmath such that the entries satisfy @xmath ,
and thus, in operator norm, it holds @xmath . Bernstein and Vazirani [ 4
, Sec. 6] have shown that there are QTMs that can carry out an @xmath
-approximation of a desired unitary transformation @xmath on their tapes
if given a matrix @xmath as input that is within distance @xmath of the
@xmath -matrix @xmath . This is exactly the case here ⁶ ⁶ 6 Note that we
consider @xmath as a subspace of an @xmath -cell tape segment Hilbert
space @xmath , and we demand @xmath to leave blanks @xmath invariant. ,
with @xmath and @xmath , so let the @xmath apply @xmath within @xmath on
its tape to create the state @xmath with @xmath . Note that the map
@xmath is a standard decompression map (as defined in Definition 2.3.14
), since for every @xmath it holds that

  -- -------- --
     @xmath   
  -- -------- --

where the vectors @xmath are the computational basis vectors of @xmath .
@xmath

The next lemma will be useful for coding the “classical part” of a
halting qubit string. The “which subspace” information will be coded
into a classical string @xmath whose length @xmath depends on the
dimension of the corresponding halting space @xmath . The dimensions of
the halting spaces @xmath can be computed one after the other, but the
complete list of the code word lengths @xmath is not computable due to
the undecidability of the halting problem. Since most well-known prefix
codes (like Huffman code, see [ 11 ] ) start by initially sorting the
code word lengths in decreasing order, and thus require complete
knowledge of the whole list of code word lengths in advance, they are
not suitable for our purpose. We thus give an easy algorithm that
constructs the code words one after the other, such that code word
@xmath depends only on the previously given lengths @xmath . We call
this “blind prefix coding”, because code words are assigned sequentially
without looking at what is coming next.

\MakeFramed \FrameRestore

###### Lemma 2.3.16 (Blind Prefix Coding)

Let @xmath be a sequence of natural numbers (code word lengths) that
satisfies the Kraft inequality @xmath . Then the following (“blind
prefix coding”) algorithm produces a list of code words @xmath with
@xmath , such that the @xmath -th code word only depends on @xmath and
the previously chosen codewords @xmath :

-    Start with @xmath , i.e. @xmath is the string consisting of @xmath
    zeroes;

-    for @xmath recursively, let @xmath be the first string in
    lexicographical order of length @xmath that is no prefix or
    extension of any of the previously assigned code words @xmath .

\endMakeFramed

Proof. We omit the lengthy, but simple proof; it is based on identifying
the binary code words with subintervals of @xmath as explained in [ 23 ]
. We also remark that the content of this lemma is given in [ 11 , Thm.
5.2.1] without proof as an example for a prefix code. @xmath

#### 2.3.4 Proof of the Strong Universality Property

To simplify the proof of Main Theorem 2.2.1 , we show now that it is
sufficient to consider fixed-length QTMs only:

\MakeFramed \FrameRestore

###### Lemma 2.3.17 (Fixed-Length QTMs are Sufficient)

For every QTM @xmath , there is a fixed-length QTM @xmath such that for
every @xmath there is a fixed-length qubit string @xmath such that
@xmath and @xmath .

\endMakeFramed

Proof. Since @xmath , there is an isometric embedding of @xmath into
@xmath . One example is the map @xmath , which is defined as @xmath for
@xmath , where @xmath and @xmath denote the computational basis vectors
(in lexicographical order) of @xmath and @xmath respectively. As @xmath
and @xmath , we can extend @xmath to a unitary transformation @xmath on
@xmath , mapping computational basis vectors to computational basis
vectors.

The fixed-length QTM @xmath works as follows, given some fixed-length
qubit string @xmath on its input tape: first, it determines @xmath by
detecting the first blank symbol @xmath . Afterwards, it computes a
description of the unitary transformation @xmath and applies it to the
qubit string @xmath by permuting the computational basis vectors in the
@xmath -block of cells corresponding to the Hilbert space @xmath .
Finally, it calls the QTM @xmath to continue the computation on input
@xmath . If @xmath halts, then the output will be @xmath ). @xmath

Proof of Theorem 2.2.1 . First, we show how the input @xmath for the
strongly universal QTM @xmath is constructed from the input @xmath for
@xmath . Fix some QTM @xmath and input length @xmath , and let @xmath .
Define the halting time sequence @xmath as the set of all integers
@xmath such that @xmath , ordered such that @xmath for every @xmath .
The number @xmath is in general not computable, but must be somewhere
between @xmath and @xmath due to Corollary 2.3.13 .

For every @xmath , define the code word length @xmath as

  -- -------- --
     @xmath   
  -- -------- --

This sequence of code word lengths satisfies the Kraft inequality:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where in the last inequality, Corollary 2.3.13 has been used. Let @xmath
be the blind prefix code corresponding to the sequence @xmath which has
been constructed in Lemma 2.3.16 .

In the following, we use the space @xmath as some kind of “reference
space” i.e. we construct our QTM @xmath such that it expects the
standard compression of states @xmath as part of the input. If the
desired accuracy parameter @xmath is smaller than @xmath , then some
“fine-tuning” must take place, unitarily mapping the state @xmath into
halting spaces of smaller accuracy parameter. In the next paragraph,
these unitary transformations are constructed.

Recursively, for @xmath , define @xmath . Since @xmath by construction
of the algorithm in Definition 2.3.10 , we have @xmath . It follows from
the approximation property of Theorem 2.3.12 together with Lemma A.5
that @xmath . The similarity property and Lemma A.5 tell us that @xmath
for every @xmath , and there exist isometries @xmath that, for @xmath
large enough, satisfy

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

Let now @xmath and @xmath . For any choice of the transformations @xmath
(they are not unique), let

  -- -------- --
     @xmath   
  -- -------- --

It follows that the spaces @xmath all have the same dimension for every
@xmath , and that @xmath . Define the unitary operators @xmath , then
@xmath , and so the sum @xmath converges. Due to Lemma A.3 , the product
@xmath converges to an isometry @xmath . It follows from the
approximation property in Theorem 2.3.12 that @xmath , so we can define
a unitary map @xmath by @xmath , and @xmath .

Due to Lemma 2.3.17 , it is sufficient to consider fixed-length QTMs
@xmath only, so we can assume that our input @xmath is a fixed-length
qubit string. Suppose @xmath is defined, and let @xmath be the
corresponding halting time for @xmath . Assume for the moment that
@xmath is a pure state, so @xmath . Recall the definition of the halting
time sequence; it follows that there is some @xmath such that @xmath .
Let

  -- -------- --
     @xmath   
  -- -------- --

that is, the blind prefix code of the halting number @xmath , followed
by the standard compression (as constructed in Definition 2.3.14 ) of
some approximation @xmath of @xmath that is in the subspace @xmath .
Note that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

If @xmath is a mixed fixed-length qubit string which is @xmath -halting
for @xmath , every convex component @xmath must also be @xmath -halting
for @xmath , and it makes sense to define @xmath , where every @xmath
(and thus @xmath ) starts with the same classical code word @xmath , and
still @xmath .

The strongly universal QTM @xmath expects input of the form

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

where @xmath is a self-delimiting description of the QTM @xmath . We
will now give a description of how @xmath works; meanwhile, we will
always assume that the input is of the expected form ( 2.15 ) and also
that the input @xmath is a pure qubit string @xmath (we discuss the case
of mixed input qubit strings @xmath afterwards):

-   Read the parameter @xmath and the description @xmath .

-   Look for the first blank symbol @xmath on the tape to determine the
    length @xmath .

-   Compute the halting time @xmath . This is achieved as follows:

    -   Set @xmath and @xmath .

    -   Compute a description of @xmath . If @xmath , then go to step
        (5).

    -   Set @xmath and set @xmath . From the previously computed code
        word lengths @xmath ( @xmath ), compute the corresponding blind
        prefix code word @xmath . Bit by bit, compare the code word
        @xmath with the prefix of @xmath . As soon as any difference is
        detected, go to step (5).

    -   The halting time is @xmath . Exit.

    -   Set @xmath and go back to step (2).

-   Let @xmath be the rest of the input, i.e. @xmath (up to a phase,
    this means that @xmath ). Apply the quantum standard decompression
    algorithm @xmath given in Lemma 2.3.15 , i.e. compute @xmath . Then,

      -- -------- --
         @xmath   
      -- -------- --

-   Compute an approximation @xmath of a unitary extension of @xmath
    with @xmath , where @xmath is some “fine-tuning map” as constructed
    above. This can be achieved as follows:

    -   Choose @xmath large enough such that @xmath , where @xmath is
        the constant defined in Equation ( 2.14 ).

    -   For every @xmath , find matrices @xmath that approximate the
        forementioned ⁷ ⁷ 7 The isometries @xmath are not unique, so
        they can be chosen arbitrarily, except for the requirement that
        Equation ( 2.14 ) is satisfied, and that every @xmath depends
        only on @xmath and @xmath and not on other parameters.
        isometries @xmath such that

          -- -------- --
             @xmath   
          -- -------- --

    Setting @xmath will work as desired, since

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

    due to Equation ( 2.14 ) and the proof of Lemma A.3 .

-   Use @xmath to carry out a @xmath -approximation of a unitary
    extension @xmath of @xmath on the state @xmath on the tape (the
    reason why this is possible is explained in the proof of Lemma
    2.3.15 ). This results in a vector @xmath with the property that
    @xmath .

-   Simulate @xmath on input @xmath for @xmath time steps within an
    accuracy of @xmath , that is, compute an output track state @xmath
    with @xmath , move this state to the own output track and halt. (It
    has been shown by Bernstein and Vazirani in [ 4 ] that there are
    QTMs that can do a simulation in this way.)

Let @xmath . Using the contractivity of the trace distance with respect
to quantum operations and Lemma A.4 , we get

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

This proves the claim for pure inputs @xmath . If @xmath is a mixed
qubit string as explained right before Equation ( 2.15 ), the result
just proved holds for every convex component of @xmath by the linearity
of @xmath , i.e. @xmath , and the assertion of the theorem follows from
the joint convexity of the trace distance and the observation that
@xmath takes the same number of time steps for every convex component
@xmath . @xmath

This proof relies on the existence of a universal QTM @xmath in the
sense of Bernstein and Vazirani as given in Equation ( 2.7 ).
Nevertheless, the proof does not imply that every QTM that satisfies (
2.7 ) is automatically strongly universal in the sense of Theorem 2.2.1
; for example, we can construct a QTM @xmath that always halts after
@xmath simulated steps of computation on input @xmath and that does not
halt at all if the input is not of this form. So formally,

  -- -------- --
     @xmath   
  -- -------- --

We are now going to sketch the proof of Proposition 2.2.2 and the proof
idea of Conjecture 2.2.3 . The reason why we do not give the full proof
is that this full proof would consist by a large part only of certain
analytic estimates that show to what accuracy the universal QTM @xmath
should do its calculations. This would be a very long proof, consisting
of many routine calculations which are not very helpful for a reader.

Remember the proof of Theorem 2.2.1 . The proof idea was to let the
universal QTM @xmath compute approximations of the halting spaces of the
other QTM @xmath and use this information to “uncompress” some cleverly
chosen input and simulate @xmath in a classically controlled manner. The
subsequent lengthy proof showed that the UQTM @xmath was really able to
approximate these halting spaces well enough to make the proof idea
work. This had to be worked out in detail at least once for this special
situation, to be sure that there are no subtle difficulties inherent to
the computable approximations. Nevertheless, since every map and
structure that we encountered was continuous and finite-dimensional, it
is not so surprising that everything worked fine.

Consequently, we will now only sketch the proof of Proposition 2.2.2 and
the proof idea of Theorem 2.2.3 , by only specifying what kind of
structures (analogues of the halting spaces) @xmath is supposed to
approximate, but without specifying in detail to what accuracy @xmath
should do its approximations.

Both proof sketches that follow are based on the idea that a QTM which
is universal in the sense of Bernstein and Vazirani (i.e. as in
Equation ( 2.7 )) has a dense set of unitaries that it can apply
exactly. We can call such unitaries on @xmath for @xmath @xmath -exact
unitaries .

This follows from the result by Bernstein and Vazirani that the
corresponding UQTM @xmath can apply a unitary map @xmath on its tapes
within any desired accuracy, if it is given a description of @xmath as
input. It does so by decomposing @xmath into simple (“near-trivial”)
unitaries that it can apply directly (and thus exactly).

We can also call an @xmath -block projector @xmath @xmath -exact if it
has some spectral decomposition @xmath such that there is a @xmath
-exact unitary that maps each @xmath to some computational basis vector
of @xmath . If @xmath and @xmath are @xmath -exact projectors on @xmath
, then @xmath can do something like a “yes-no-measurement” according to
@xmath and @xmath : it can decide whether some vector @xmath on its tape
is an element of @xmath or of @xmath with certainty (if either one of
the two cases is true), just by applying the corresponding @xmath -exact
unitary, and then by deciding whether the result is some computational
basis vector or another.

Proof Sketch of Proposition 2.2.2 . In analogy to Definition 2.3.1 , we
can define halting spaces @xmath as the linear span of

  -- -------- --
     @xmath   
  -- -------- --

Again, we have @xmath if @xmath , and now it also holds that @xmath for
every @xmath . Moreover, we can define certain @xmath -approximations
@xmath . We will not get into detail; we will just claim that such a
definition can be found in a way such that these @xmath -approximations
share enough properties with their counterparts from Definition 2.3.10
to make the algorithm given below work.

We are now going to describe how a machine @xmath with the properties
given in the assertion of the proposition works. It expects input of the
form @xmath , where @xmath is a single bit, @xmath is a self-delimiting
description of the QTM @xmath , @xmath is a qubit string, and @xmath an
arbitrary integer. For the same reasons as in the proof of Theorem 2.2.1
, we may without loss of generality assume that the input is a pure
qubit string, so @xmath . Moreover, due to Lemma 2.3.17 , we may also
assume that @xmath is a fixed-length QTM, and so @xmath is a
fixed-length qubit string.

These are the steps that @xmath performs:

-   Read the first bit @xmath of the input. If it is a @xmath , then
    proceed with the rest of the input the same way as the QTM that is
    given in Theorem 2.2.1 . If it is a @xmath , then proceed with the
    next step.

-   Read @xmath , read @xmath , and look for the first blank symbol
    @xmath to determine the length @xmath .

-   Set @xmath and @xmath (depending on @xmath ) small enough.

-   Set @xmath .

-   Compute @xmath . Find a @xmath -exact projector @xmath with the
    following properties:

    -   @xmath for every @xmath ,

    -   @xmath ,

    -   the support of @xmath is close enough to @xmath .

-   Make a measurement ⁸ ⁸ 8 It is not really a measurement, but rather
    some unitary branching: if @xmath is some superposition in between
    both subspaces @xmath and @xmath , then the QTM will do both
    possible steps in superposition. described by @xmath . If @xmath is
    an element of the support of @xmath , then set @xmath and go to step
    (7). Otherwise, if @xmath is an element of the orthogonal complement
    of the support, set @xmath and go back to step (5).

-   If @xmath , then set @xmath and go back to step (4).

-   Use a unitary transformation @xmath (similar to the transformation
    @xmath from the proof of Theorem 2.2.1 ) to do some “fine-tuning” on
    @xmath , i.e. to transform it closer (depending on the parameter
    @xmath ) to some space @xmath containing the exactly halting
    vectors. Call the resulting vector @xmath .

-   Simulate @xmath on input @xmath for @xmath time steps within some
    accuracy that is good enough, depending on @xmath .

Let @xmath be the support of @xmath . These spaces (which are computed
by the algorithm) have the properties

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

which are the same as those of the exact halting spaces @xmath . If all
the approximations are good enough, then for every @xmath there will be
a vector @xmath such that @xmath is small. If this @xmath is given to
@xmath as input together with all the additional information explained
above, then this algorithm will unambiguously find out by measurement
with respect to the @xmath -exact projectors that it computes in step
(5) what the halting time of @xmath is, and the simulation of @xmath
will halt after the correct number of time steps with probability one
and an output which is close to the true output @xmath . @xmath

Proof Idea for Conjecture 2.2.3 . The first difficulty that arises in
considering average length @xmath instead of base length @xmath is that
it is no more sufficient to consider fixed-length QTMs. Moreover, while
the pure qubit strings @xmath with base length @xmath are all elements
of some (small) subspace @xmath , this is no more true for the qubit
strings with average length @xmath . But to do numerical approximations,
we should be able to restrict to some finite-dimensional subspace.

To resolve this difficulty, note that if @xmath is any input qubit
string which makes a QTM @xmath halt after @xmath time steps, then
@xmath cannot have read more than @xmath cells of its tape. Thus, it
follows that also the restriction of @xmath to the first @xmath cells
(called @xmath and defined on page 2.3.5 ) makes the QTM behave
completely equivalently:

  -- -------- --
     @xmath   
  -- -------- --

But if @xmath is a prefix QTM, as in the statement of the theorem that
we are about to prove, then it must hold that @xmath , or equivalently,
@xmath , because otherwise, Lemma 2.3.6 would be violated. Thus,

  -- -------- --
     @xmath   
  -- -------- --

Again, we assume that we can define certain computable approximations
@xmath , where @xmath is some approximation parameter, that approximate
the true halting spaces @xmath good enough to make the algorithm that
follows work. We also assume that the approximate halting spaces @xmath
share the property @xmath for @xmath with the true halting spaces @xmath
that they approximate.

Moreover, we want to use the prefix property of @xmath , and demand that
the approximate halting spaces @xmath have the prefix property of
Definition 2.3.5 , i.e. if @xmath and @xmath for some @xmath such that
@xmath , then it holds

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

For the same reason as in the proof of Theorem 2.2.1 (i.e. the number of
steps that the following algorithm takes depends only on the running
time of the calculation that it simulates), we may restrict to pure
input qubit strings. The algorithm that @xmath performs expects input of
the form @xmath , where @xmath is the parameter from the statement of
the theorem, @xmath is some description of a QTM @xmath , and @xmath is
an arbitrary indeterminate-length qubit string. It proceeds as follows:

-   Read @xmath , read @xmath , and let @xmath .

-   Compute a description of the space @xmath . Find a @xmath -exact
    projector @xmath with the following properties:

    -   the support @xmath of @xmath is a good approximation of @xmath ,

    -   @xmath for every @xmath , i.e. for all previously computed
        @xmath -exact projectors,

    -   the collection of support subspaces @xmath satisfies Equation (
        2.16 ), i.e. is prefix-free. It is not clear if this is easy to
        achieve; this is exactly the point why the statement is just a
        conjecture, not a theorem.

-   Make a measurement ⁹ ⁹ 9 Again, this is not really a measurement,
    but rather some unitary branching. described by the projectors
    @xmath and @xmath , i.e. decide whether @xmath is an element of
    @xmath or of its orthogonal complement. In the first case, go to
    step (4). In the second case, let @xmath and go to step (2).

-   Use a unitary transformation @xmath (similar to the transformation
    @xmath from the proof of Theorem 2.2.1 ) to do some “fine-tuning” on
    @xmath , i.e. to transform it closer (depending on the parameter
    @xmath ) to some space @xmath containing the exactly halting
    vectors. Call the resulting vector @xmath .

-   Simulate the QTM @xmath for @xmath time steps on input @xmath , move
    the corresponding output to the output track and halt.

If all the approximations are good enough, then for every @xmath there
should be a vector @xmath such that @xmath is small. If @xmath is given
to the QTM @xmath as input together with @xmath and @xmath as shown
above, then this algorithm will find out by measurement with respect to
the @xmath -exact projectors given above in step (2) what the
corresponding halting time is, and the simulation of @xmath will halt
after the correct number of time steps with probability one.

Note that the “measurement” in step (3) only works because @xmath is a
prefix QTM: in the case that @xmath for some @xmath and @xmath , this
fact guarantees that the measurement result will always be that @xmath
is in the orthogonal complement of @xmath , even though the measurement
cannot access the state @xmath completely.

It also seems that if @xmath and @xmath are encoded into the input in a
clever way, then @xmath inherits the property of being prefix-free from
the QTMs that it simulates. But again, this has to be checked in more
detail once this proof idea will be turned into a complete proof. @xmath

### 2.4 Halting Stability

In this thesis, we have defined that a QTM halts at some time @xmath
according to Equation ( 2.3 ) if and only if its control is exactly in
the halting state @xmath at time @xmath , and exactly orthogonal to the
halting state before. We have argued in Section 2.2 why this halting
definition is useful and natural, at least for our purpose to study
quantum Kolmogorov complexity.

Yet, it may first seem that this halting definition is too restrictive,
since it dismisses every input which halts only approximately, but not
perfectly, even if it is very close to halting. In this section, we show
that this definition of halting has some built-in error tolerance that
was not expected at the beginning: for every input which makes a QTM
almost halt, there is another input which is at most a constant number
of qubits longer, and which makes the universal QTM halt perfectly .

Thus, the definition of halting that we use in this thesis (and that was
first considered by Bernstein and Vazirani) is not as “unphysical” as it
first seems, but makes perfect sense.

We start by showing that superpositions of almost halting input qubit
strings are again almost halting. To establish this result, we need some
estimation of a matrix element appearing in the superposition’s density
matrix.

\MakeFramed \FrameRestore

###### Lemma 2.4.1 (Halting Matrix Element)

Let @xmath be a QTM, let @xmath be @xmath - @xmath -halting for @xmath ,
and let @xmath be @xmath - @xmath -halting for @xmath . Then, the
operator @xmath satisfies

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

\endMakeFramed

Proof. Let @xmath be the unitary time evolution operator of @xmath .
Identifying @xmath with the initial state of the QTM @xmath on input
@xmath , we write

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

for every @xmath , where @xmath is an arbitrary orthonormal basis of
@xmath . Multiplying and computing the partial trace, we get

  -- -------- --
     @xmath   
  -- -------- --

By the assumptions of the theorem, it follows

  -- -------- --
     @xmath   
  -- -------- --

Similarly, for @xmath , we get the inequality

  -- -------- --
     @xmath   
  -- -------- --

where the coefficients @xmath are defined analogously as in Equation (
2.17 ). Now suppose @xmath . Then, we get by the Cauchy-Schwarz
inequality

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Using the Cauchy-Schwarz inequality again, we get for @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

The claim follows. @xmath

\MakeFramed \FrameRestore

###### Lemma 2.4.2 (Approximate Halting of Superpositions)

Let @xmath be a QTM, @xmath , and @xmath be a set of positive numbers.
Moreover, let @xmath be a set of normalized vectors, i.e. pure qubit
strings, such that every @xmath is @xmath - @xmath -halting for @xmath .
If @xmath is normalized, then @xmath is @xmath - @xmath -halting for
@xmath .

\endMakeFramed

Proof. Let @xmath . Using Lemma 2.4.1 , we get for @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Moreover, for @xmath , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

To prove the result about halting stability, we need another lemma which
states that almost halting qubit strings with different halting times
are almost orthogonal to each other.

\MakeFramed \FrameRestore

###### Lemma 2.4.3 (Almost-Orthogonality)

Let @xmath be a QTM, and let @xmath be two normalized pure qubit
strings. If @xmath is @xmath - @xmath -halting for @xmath , and @xmath
is @xmath - @xmath -halting for @xmath with @xmath , and if @xmath ,
then

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. We may assume that @xmath . Then we have

  -- -------- --
     @xmath   
  -- -------- --

By the monotonicity of the trace distance with respect to quantum
operations and the definition of the trace distance for pure states
together with Lemma A.4 , we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

The claim follows by rearranging. @xmath

We are now ready to prove the promised result about halting stability.
The idea is to show in the first part of the proof that every pure qubit
string of fixed length @xmath which makes a QTM @xmath almost halt at
time @xmath is close to some “approximation subspace” @xmath . Under
certain assumptions on the halting accuracy, the dimensions of the
spaces @xmath for different @xmath add up to at most @xmath .

Then, as the second part of the proof, we can repeat the construction
from Section 2.3 , where the halting spaces are replaced by these
approximation spaces: we split every vector from @xmath into some
classical and quantum part, and we can write a computer program for the
UQTM @xmath that extracts the approximate halting time from the
classical part, then simulates the QTM @xmath for the corresponding
number of time steps, and finally halts with probability one.

Note that it is not trivial that such subspaces @xmath with the
aforementioned properties exist; in particular, the halting spaces
@xmath themselves do not have this approximation property. It is also
does not seem that the approximate halting spaces @xmath from Definition
2.3.10 can be used instead.

\MakeFramed \FrameRestore

###### Theorem 2.4.4 (Halting Stability)

For every @xmath , there is a sequence @xmath such that every qubit
string of length @xmath which is @xmath -halting can be enhanced to
another qubit string which is only a constant number of qubits longer,
but which halts perfectly and gives the same output up to trace distance
@xmath .

Moreover, the sequence @xmath is computable.

\endMakeFramed

Remark. Here is the exact formal statement of the theorem: For every
@xmath , there exists a sequence of positive real numbers @xmath such
that for every QTM @xmath , one can find a constant ¹⁰ ¹⁰ 10 Note that
@xmath does not depend on @xmath . @xmath such that for every qubit
string @xmath which is @xmath - @xmath -halting for @xmath for some
@xmath and @xmath , there is some qubit string @xmath with @xmath such
that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is some strongly universal QTM. Furthermore, @xmath halts
perfectly on input @xmath , and the map @xmath is computable.

Proof. Assume that @xmath . We introduce two different norms that will
be useful in the proof. For every @xmath which is a basis of @xmath
consisting of normalized vectors, and for every @xmath , we define

  -- -------- --
     @xmath   
  -- -------- --

It is easily checked that @xmath is a norm on @xmath for every basis
@xmath . Suppose we have a set of vectors @xmath with the property

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

then it is easily checked that the vectors of this set must be linearly
independent. Since @xmath , @xmath must be a basis of @xmath . Thus, the
expression

  -- -------- --
     @xmath   
  -- -------- --

is well-defined for every @xmath . Yet, it might be infinite for some
@xmath . To see that it is finite for every @xmath , note that the set

  -- -------- --
     @xmath   
  -- -------- --

is compact in @xmath , and the map @xmath is continuous ¹¹ ¹¹ 11 To see
that this map is continuous, note that @xmath can be interpreted as an
invertible @xmath -matrix. Thus, @xmath , and the map @xmath is
continuous. on this set and must thus have a maximum.

One easily checks that @xmath is also a norm on @xmath . Since all norms
on finite-dimensional linear spaces are equivalent, it follows that

  -- -------- --
     @xmath   
  -- -------- --

is finite, and @xmath for every @xmath . Now we set

  -- -- --
        
  -- -- --

It is clear that the map @xmath is computable, although we do not have
an explicit formula for it.

According to Lemma 2.3.17 , we may assume that @xmath is a fixed-length
QTM. Fix some algorithm that on input @xmath and @xmath computes some
discretization

  -- -------- --
     @xmath   
  -- -------- --

of the unit sphere @xmath , with @xmath . The discretization shall be
@xmath -dense in the unit sphere @xmath , i.e. for every @xmath , there
shall be some vector @xmath such that @xmath . Moreover, we demand that
@xmath . For every @xmath , let

  -- -------- --
     @xmath   
  -- -------- --

Now we construct some coarsening @xmath in the following way: First, we
choose an arbitrary vector @xmath . Then, one after the other, we choose
vectors @xmath such that no vector is @xmath -close to the span of the
previously chosen vectors. We stop as soon as there is no more such
vector.

This way, we get a finite set @xmath with the following properties:

-   For every vector @xmath , there is a vector @xmath such that @xmath
    .

-   Equation ( 2.18 ) is valid for every @xmath .

Now we define the linear subspaces

  -- -------- --
     @xmath   
  -- -------- --

Suppose that @xmath is a normalized vector. In this case, @xmath can be
written as @xmath , where @xmath is a basis of @xmath , and every @xmath
is @xmath - @xmath -halting for @xmath . Choose some orthonormal basis
of @xmath , and append those vectors to @xmath to get a basis @xmath of
@xmath . It follows that @xmath , and Lemma 2.4.2 implies:

  -- -------- --
     @xmath   
  -- -------- --

Now suppose that @xmath is any real number satisfying

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

It follows that if @xmath is normalized, then @xmath is better than
@xmath - @xmath -halting for @xmath . If @xmath is another normalized
vector with different approximate halting time @xmath , then it follows
from Lemma 2.4.3 that @xmath .

Suppose now that @xmath . Then, by choosing orthonormal bases in all
spaces @xmath , we could choose @xmath vectors @xmath , such that their
inner product satisfies @xmath for every @xmath . Lemma A.2 would then
imply that the vectors were all linearly independent, which is
impossible. Thus,

  -- -------- --
     @xmath   
  -- -------- --

On the other hand, suppose that @xmath is @xmath - @xmath -halting for
@xmath . Then, there is some vector @xmath such that @xmath . According
to Equation ( 2.12 ), the vector @xmath is @xmath - @xmath -halting for
@xmath , so @xmath . By construction, it follows that there is another
vector @xmath with @xmath , so @xmath . The approximate outputs of
@xmath on inputs @xmath and @xmath are then also @xmath -close:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.20)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where we have used Lemma A.1 and A.6 .

From that point on, we have the same situation as in Section 2.3 where
we proved the existence of a strongly universal QTM: we have a
collection of subspaces @xmath such that their dimensions add up to at
most @xmath . We can now use a construction that is analogous to that in
Subsection 2.2.3 : For every vector @xmath that is @xmath -halting for
@xmath , we can find some vector @xmath such that ( 2.20 ) holds. We can
divide @xmath into a classical part, consisting of a prefix code @xmath
of the number of the corresponding subspace that contains @xmath , and a
quantum part @xmath , consisting of a compression of @xmath down to
@xmath qubits.

The idea now is that the universal QTM @xmath works as follows: On input
@xmath , where @xmath is a description of the QTM @xmath , the universal
QTM @xmath shall compute the halting time @xmath from @xmath ,
approximately decompress @xmath from @xmath , and then simulate @xmath
for @xmath time steps on input @xmath and halt.

Again, @xmath cannot apply these steps exactly, but has to work with
numerical approximations of the spaces @xmath . These approximations
have to be good enough such that the resulting error is bounded from
above by @xmath , such that the resulting total error (by adding ( 2.20
)) is less than @xmath .

This construction is completely analogous to the construction of the
strongly universal QTM @xmath in Section 2.3 ; it is even slightly
simpler, since we do not need any “fine tuning map” @xmath as in the
proof of Theorem 2.2.1 . @xmath

As @xmath turns to zero exponentially fast for @xmath , this theorem
only applies to almost halting inputs that are extremely close to
perfect halting. Maybe it is possible to prove more general or less
restrictive versions of this theorem by allowing a larger blow-up of the
program length (e.g. a factor larger than one, instead of an additive
constant). Another possibility might be to use a different definition of
“ @xmath -halting”: Instead of Definition 2.3.7 , one might instead
define an input as @xmath -halting at time @xmath , if an outside
observer who is continuously measuring the halting state of the control
observes halting at time @xmath with probability larger than @xmath .

Despite this restriction, the theorem proves that the definition of
halting by Bernstein and Vazirani [ 4 ] has some unexpected built-in
error tolerance, which makes that halting scheme look quite reasonable.

## Chapter 3 Quantum Kolmogorov Complexity

### 3.1 Definition of Quantum Kolmogorov Complexity

The notion of quantum Kolmogorov complexity that we study in this thesis
has first been defined by Berthiaume, van Dam, and Laplante [ 5 ] . They
define the complexity @xmath of a qubit string @xmath as the length of
the shortest qubit string that, given as input into a QTM @xmath , makes
@xmath output @xmath and halt.

Since there are uncountably many qubit strings, but a QTM can only apply
a countable number of transformations (analogously to the circuit
model), it is necessary to introduce a certain error tolerance @xmath .

This can be done in essentially two ways: First, one can just fix some
tolerance @xmath . Second, one can demand that the QTM outputs the qubit
string @xmath as accurately as one wants, by supplying the machine with
a second parameter as input that represents the desired accuracy. This
is analogous to a classical computer program that computes the number
@xmath : A second parameter @xmath can make the program output @xmath to
@xmath digits of accuracy, for example. We consider both approaches at
once, and get two different notions of quantum Kolmogorov complexity,
namely @xmath and @xmath .

Moreover, while Berthiaume et al. only allow inputs that are length
eigenstates, base length @xmath and average length @xmath coincide for
their approach. We want to be more general and allow arbitrary
superpositions and mixtures, i.e. qubit strings @xmath as inputs. Thus,
the number of possible definitions doubles again, depending on the way
we quantify the length of the input qubit strings. We get on the one
hand the complexities @xmath and @xmath for base length @xmath , and on
the other hand the complexities @xmath and @xmath for average length
@xmath .

According to Conjecture 2.2.3 , we can only hope to prove the invariance
property (cf. Section 3.3 ) for average-length complexities @xmath and
@xmath if we restrict them to prefix QTMs, i.e. if we define them as
quantum analogues of classical prefix complexity. Since classical prefix
complexity is often denoted by @xmath , while plain Kolmogorov
complexity (with no restriction on the reference Turing machine) is
denoted by @xmath , this explains why we chose the notation @xmath and
@xmath .

Another difference to the definition by Berthiaume et al. is that we use
the trace distance rather than the fidelity to quantify the similarity
of two qubit strings.

###### Definition 3.1.1 (Quantum Kolmogorov Complexity)

Let @xmath be a QTM and @xmath an indeterminate-length qubit string. For
every @xmath , we define the finite-error quantum Kolmogorov complexity
@xmath as the minimal length of any qubit string @xmath such that the
corresponding output @xmath has trace distance from @xmath smaller than
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Similarly, we define the approximation-scheme quantum Kolmogorov
complexity @xmath as the minimal length of any qubit string @xmath such
that when given @xmath as input together with any integer @xmath , the
output @xmath has trace distance from @xmath smaller than @xmath :

  -- -------- --
     @xmath   
  -- -------- --

We define two analogous notions of complexity, where base length @xmath
is replaced by average length @xmath : if @xmath is any QTM, then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Note that the specific choice of @xmath as accuracy required on input
@xmath is not important; any other computable and strictly decreasing
function @xmath that tends to zero for @xmath such that @xmath is also
computable will give the same result within an additive constant, as
long as @xmath is a strongly universal QTM and the quantum complexity
notions all have the invariance property (which we discuss in Section
3.3 ).

The idea to define some notion like @xmath is due to Rogers and Vedral [
37 ] . In Chapter 4 , we argue that the notion of complexity @xmath is
more useful for applications in statistical mechanics than @xmath ,
since the average length sometimes has a physical interpretation as the
expected energy cost of communication.

In this thesis, we will most of the time restrict to the complexity
notions @xmath and @xmath , since they are much easier to handle. The
main technical reason for this is that the pure qubit strings @xmath
with base length @xmath are all elements of one Hilbert space @xmath ,
which is not true for average length. Nevertheless, we study the
complexities @xmath and @xmath to some extent in Section 3.3 .

For later use, we note a simple relation between the two quantum
complexities @xmath and @xmath :

\MakeFramed \FrameRestore

###### Lemma 3.1.2 (Relation between Quantum Complexities)

For every QTM @xmath and every @xmath , we have the relation

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

\endMakeFramed

Proof. Suppose that @xmath , so there is a density matrix @xmath with
@xmath , such that @xmath for every @xmath . Then @xmath , where @xmath
is given in Definition 2.1.7 , is an input for @xmath such that @xmath .
Thus @xmath , where the second inequality is by ( 2.6 ). @xmath

The term @xmath in ( 3.1 ) depends on our encoding @xmath given in
Definition 2.1.7 , but if @xmath is assumed to be universal (which will
be discussed below), then ( 3.1 ) will hold for every encoding, if we
replace the term @xmath by @xmath , where @xmath denotes the classical
(self-delimiting) algorithmic complexity of the integer @xmath , and
@xmath is some constant depending only on @xmath . For more details we
refer the reader to [ 23 ] .

### 3.2 Incompressibility Theorems

In the theory of classical Kolmogorov complexity and in its
applications, a simple but powerful argument used frequently in proofs
is the so-called incompressibility theorem. It can be stated in the
following way [ 23 , Theorem 2.2.1] :

If @xmath is a positive integer, then every finite set @xmath of
cardinality @xmath has at least @xmath elements @xmath with @xmath .

In this section, we are going to prove three quantum analogues of this
theorem. The first version is a very general theorem on the number of
mutually orthonormal vectors that can be close in trace distance to the
output of some quantum operation. We call it “quantum counting
argument”, because it is a quantization of a classical counting
argument, saying that there can be no more than @xmath different bit
strings that have programs of length less than @xmath .

Nevertheless, the theorem that follows is not restricted to the study of
quantum computers, but is a general result about quantum operations. Its
proof is based on Holevo’s @xmath -quantity associated to any ensemble
@xmath , consisting of probabilities @xmath , @xmath , and of density
matrices @xmath acting on a Hilbert space @xmath . Setting @xmath , the
@xmath -quantity is defined as follows:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the relative entropy.

\MakeFramed \FrameRestore

###### Theorem 3.2.1 (Quantum Counting Argument)

Let @xmath and @xmath be separable Hilbert spaces with @xmath , and let
@xmath . If @xmath is a quantum operation, then define

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is an orthonormal system, then

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. For @xmath , the assertion of the theorem is trivial (setting, as
usual, @xmath ), so assume @xmath . We may also assume that @xmath . Let

  -- -------- --
     @xmath   
  -- -------- --

then by definition, there exist @xmath such that @xmath . For @xmath ,
define the projectors @xmath , and set @xmath . Let @xmath be an
orthonormal basis of @xmath . Now we define a quantum operation @xmath
via

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes an arbitrary orthonormal basis of @xmath . It is
clear that @xmath is completely positive (Kraus representation), and one
easily checks that @xmath is also trace-preserving. This is also true if
@xmath ; then, the corresponding infinite series is absolutely
convergent in @xmath -norm, and inherits complete positivity from its
partial sums. Moreover, for @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Consider the equidistributed ensemble @xmath , and let @xmath . Due to
the monotonicity of relative entropy with respect to quantum operations,
we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

The trace distance is also monotone with respect to quantum operations
(cf. Lemma A.1 ). Thus, for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Let now @xmath , then @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

The Fannes inequality [ 30 , 11.44] yields ¹ ¹ 1 Note that the notation
in [ 30 ] differs from the notation in this thesis: it holds @xmath .
for @xmath

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where @xmath . Altogether, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where we have used the inequality @xmath for @xmath . The claim follows
by rearranging. @xmath

We will use this “quantum counting argument” later in Section 3.4 and
3.5 ; it will be useful in several proofs. Specifying it to the case
that the quantum operation corresponds to the action of a QTM, we get
the following incompressibility theorem for quantum Kolmogorov
complexity @xmath :

\MakeFramed \FrameRestore

###### Corollary 3.2.2 (Incompressibility for Orthonormal Systems)

Let @xmath be a QTM, let @xmath , and let @xmath be a set of mutually
orthonormal pure qubit strings. Then, there is some @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. Let @xmath be a natural number such that @xmath for every @xmath
. Then, there exist qubit strings @xmath such that @xmath , where @xmath
is the quantum operation that corresponds to the QTM @xmath , cf. Lemma
2.3.4 . Thus, Theorem 3.2.1 yields

  -- -------- --
     @xmath   
  -- -------- --

It follows that @xmath . @xmath

In [ 5 , Theorem 6] , Berthiaume et al. prove the following
incompressibility result for the approximation-scheme complexity @xmath
: if @xmath is any set of qubit strings, then there is some @xmath such
that ² ² 2 The “-1”-term is missing in their paper.

  -- -------- --
     @xmath   
  -- -------- --

Note that the quantity on the right-hand side is exactly Holevo’s @xmath
-quantity associated with the ensemble @xmath . Here, we give a
generalization of this result to the complexity notion @xmath . The
proof is very similar to the proof of the quantum counting argument,
Theorem 3.2.1 ; the only difference is that we need a different quantum
operation @xmath .

\MakeFramed \FrameRestore

###### Theorem 3.2.3 (Incompressibility for Pure Qubit Strings)

Let @xmath be a QTM, and let @xmath be a set of pure normalized qubit
strings. Then, there is some @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes von Neumann entropy.

\endMakeFramed

Proof. Let @xmath be a natural number such that @xmath for every @xmath
. Then, there exist qubit strings @xmath such that @xmath , where @xmath
is the quantum operation that corresponds to the QTM @xmath , cf. Lemma
2.3.4 .

Let @xmath , let @xmath , and let @xmath be an arbitrary isometry (i.e.
a unitary map from @xmath to some @xmath -dimensional subspace of @xmath
). Let @xmath be a normalized vector from @xmath . Then, define a
quantum operation @xmath via

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes an orthonormal basis of @xmath in @xmath , and
@xmath denotes the orthogonal projector onto @xmath . It is easily
checked that @xmath is linear and trace-preserving, and it is clear that
@xmath is completely positive (Kraus representation). Moreover,

  -- -------- --
     @xmath   
  -- -------- --

As the trace distance is monotone with respect to quantum operations
(cf. Lemma A.1 ), we get

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath . Since the trace distance is jointly convex (cf. [ 30 ] ),
we also get

  -- -------- --
     @xmath   
  -- -------- --

For @xmath , the Fannes inequality [ 30 , 11.44] yields

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath . Now consider the equidistributed ensemble @xmath . The
monotonicity property of Holevo’s @xmath quantity gives

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Using that @xmath , the claim follows. @xmath

### 3.3 The Invariance Property

The most important theorem for classical Kolmogorov complexity is the
invariance theorem. Basically, it says that Kolmogorov complexity does
not depend too much on the choice of the corresponding TM. In more
detail, there is a (“universal”) TM @xmath such that for every TM @xmath
, there is some constant @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

(cf. [ 23 ] ). Consequently, if @xmath and @xmath are both universal
TMs, then the difference of the corresponding complexities @xmath is
uniformly bounded by a constant. Since additive constants do not matter
so much for many applications, this means that we can define Kolmogorov
complexity with respect to any universal computer we want.

It follows from the results in Section 2.2 and 2.3 that both quantum
Kolmogorov complexities @xmath and @xmath are invariant as well:

\MakeFramed \FrameRestore

###### Theorem 3.3.1 (Invariance of Q-Kolmogorov Complexity)

There is a fixed-length quantum Turing machine @xmath such that for
every QTM @xmath there is a constant @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Moreover, for every QTM @xmath and every @xmath with @xmath , there is a
constant @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

As a consequence, we now fix an arbitrary QTM @xmath with the property
of Theorem 3.3.1 , and define @xmath and @xmath for every qubit string
@xmath and @xmath .

Proof of Theorem 3.3.1 . First, we use Theorem 2.2.1 to prove the second
part of Theorem 3.3.1 . Let @xmath be an arbitrary QTM, let @xmath be
the (“strongly universal”) QTM and @xmath the corresponding constant
from Theorem 2.2.1 . Let @xmath , i.e. there exists a qubit string
@xmath with @xmath such that @xmath . According to Theorem 2.2.1 , there
exists a qubit string @xmath with @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Thus, @xmath , and @xmath , where @xmath is some constant that only
depends on @xmath and @xmath . So @xmath .

The first part of Theorem 3.3.1 uses Proposition 2.2.2 . Again, let
@xmath be an arbitrary QTM, let @xmath be the strongly universal QTM and
@xmath the corresponding constant from Proposition 2.2.2 . Let @xmath ,
i.e. there exists a qubit string @xmath with @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

According to Proposition 2.2.2 , there exists a qubit string @xmath with
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Thus, @xmath for every @xmath . So @xmath . @xmath

Does the invariance property also hold for the average length
complexities @xmath and @xmath ? If Conjecture 2.2.3 holds true, then we
can repeat the proof of invariance of @xmath without changes for @xmath
. Thus, we conjecture that the following holds true:

###### Conjecture 3.3.2 (Invariance of Average-Length Complexity)

There is a prefix QTM @xmath such that for every prefix QTM @xmath and
every @xmath with @xmath , there is some constant @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

What about the complexity notion @xmath ? The question whether @xmath is
invariant depends on the question whether Proposition 2.2.2 can be
generalized to average length @xmath . We think that this could be
possible, but have no idea how to prove it.

A simple consequence of the invariance property is that the quantum
Kolmogorov complexity of some qubit string is bounded from above by its
base length:

\MakeFramed \FrameRestore

###### Lemma 3.3.3

There is some constant @xmath such that

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

Similarly, for every @xmath , there is some constant @xmath such that

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

\endMakeFramed

Proof. Recall the construction used in the proof of Lemma 2.3.17 to
compress indeterminate-length qubit strings into fixed-length qubit
strings which are only one qubit longer. We are using the same idea to
construct a fixed-length QTM @xmath with @xmath . Then, Equation ( 3.2 )
follows immediately from Theorem 3.3.1 (the invariance property), and
Equation ( 3.3 ) follows from Lemma 3.1.2 .

Going back to the idea of Lemma 2.3.17 , as @xmath , we can embed @xmath
isometrically in @xmath in a simple way, e.g. by mapping computational
basis vectors to computational basis vectors. This transformation can be
extended to a unitary transformation @xmath on @xmath , again simply by
mapping computational basis vectors to computational basis vectors, such
that there is a QTM that can apply each @xmath for every @xmath (and its
inverse @xmath ) exactly, i.e. without any error.

The fixed-length QTM @xmath works as follows on input @xmath , where
@xmath is some integer, and @xmath is some fixed-length qubit string:
First, it reads and ignores @xmath . Then, it determines @xmath by
detecting the first blank symbol @xmath on its input track. Afterwards,
it applies @xmath on the corresponding @xmath -block of input track
cells exactly, moves this block to the output track and halts. Then
@xmath has @xmath . @xmath

If the complexity notion @xmath is really invariant as stated in
Conjecture 3.3.2 , then the following result might give an analogue of
Lemma 3.3.3 .

\MakeFramed \FrameRestore

###### Lemma 3.3.4

For every @xmath , there is a QTM @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

For simplicity of the proof, we let @xmath depend on @xmath here, which
can be avoided. Unfortunately, it is not clear whether @xmath can be
constructed to be prefix.

Proof. The QTM @xmath expects input of the form @xmath , where @xmath is
an arbitrary indeterminate-length qubit string, and @xmath is a
classical prefix code that encodes the natural numbers into binary
strings; it is well-known that this can be done in a way such that
@xmath .

The QTM starts by reading @xmath , and decodes @xmath from it. Then, it
determines some @xmath such that @xmath , where @xmath is defined in
Definition 2.3.5 . Finally, it moves the first @xmath qubits of @xmath
from the input to the output track and halts.

The only remaining question is how the aforementioned integer @xmath can
be determined. First suppose that @xmath is a pure qubit string.

Let @xmath be the @xmath -th classical string in lexicographical order
of length @xmath . Then, we can write

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

Thus, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

From Lemma A.4 , it follows that

  -- -------- --
     @xmath   
  -- -------- --

As quantum operations are contractive (cf. Lemma A.1 ), restricting both
states to the first @xmath qubits yields @xmath , and by the triangle
inequality

  -- -------- --
     @xmath   
  -- -------- --

Now suppose that @xmath is an arbitrary mixed qubit string. Let @xmath
be its spectral decomposition. Using the joint convexity of the trace
distance and the Cauchy-Schwarz inequality, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, @xmath just has to be chosen large enough such that the right-hand
side is less than @xmath . @xmath

### 3.4 Quantum Complexity of Classical Strings

Quantum Kolmogorov was meant to be a generalization of classical
Kolmogorov complexity. In this section, we show that this point of view
is justified by proving that at the domain of classical strings, quantum
and classical Kolmogorov complexity basically coincide up to an additive
constant. Thus, quantum Kolmogorov complexity extends classical
complexity in a similar way as von Neumann entropy generalizes Shannon
entropy.

We start with a lemma which says that classical complexity is bounded
from above by quantum complexity. This was formulated as an open problem
in the first paper on this complexity notion by Berthiaume et al. [ 5 ]
. Later, Gács proved some prefix-free analogue of ( 3.4 ) indirectly in
[ 14 ] .

\MakeFramed \FrameRestore

###### Lemma 3.4.1 (Classical Complexity @xmath Quantum Complexity)

For every QTM @xmath , there is a constant @xmath such that

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

Moreover, for every @xmath , there is a constant @xmath such that

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

\endMakeFramed

Proof. According to Lemma 2.3.17 , we may without loss of generality
assume that @xmath is a fixed-length QTM. We give a classical computer
program @xmath that, on input @xmath and @xmath , together with a
description of a QTM @xmath , approximately outputs the @xmath -th
string that is generated by the QTM @xmath on some input of length
@xmath . The program @xmath works as follows:

-   Set the time @xmath and the counter @xmath . Compute some number
    @xmath such that @xmath .

-   Compute a description of the approximate halting space @xmath . If
    @xmath , go to step (4).

-   Compute a finite set of self-adjoint matrices @xmath such that for
    every @xmath there is a matrix @xmath such that @xmath and vice
    versa. For every matrix @xmath ,

    -   simulate the QTM @xmath on input @xmath for @xmath time steps,
        that is, compute an approximation @xmath of the output of @xmath
        on input @xmath such that @xmath ;

    -   for every @xmath with @xmath , compute an approximation @xmath
        of @xmath such that @xmath ;

    -   if @xmath , then set @xmath . If @xmath , then output @xmath and
        halt.

-   Set @xmath and go back to step (2).

The proof will consist of two parts: In the first part, we show that the
program @xmath finally generates every string @xmath with @xmath for
some appropriate input @xmath . In the second part, we show that the
number @xmath is not too large, such that it can be specified by a short
binary string.

For the first part, suppose that @xmath is a binary string such that
@xmath . By definition, it follows that there is some @xmath such that
@xmath . If @xmath is the corresponding halting time and @xmath is the
spectral decomposition of @xmath , it follows that @xmath for every
@xmath . According to Theorem 2.3.12 , there are vectors @xmath such
that @xmath . Let @xmath , then @xmath according to Lemma A.4 .

If the program @xmath has run long enough that @xmath , there is by
assumption some @xmath such that @xmath . According to Lemma A.1 , we
have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, @xmath . In step (3) of the program @xmath , if @xmath , it will
then hold that @xmath , and the program @xmath will output the string
@xmath if the input @xmath has been appropriately chosen. This is true
for every string @xmath with @xmath .

Now suppose some classical string @xmath is output by @xmath on some
input @xmath . In this case, it will hold @xmath in step (3) of the
program @xmath , and thus, @xmath . Thus, if @xmath is the corresponding
halting time, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

By definition, there exists some @xmath such that @xmath , so

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Define @xmath and @xmath , and set

  -- -------- --
     @xmath   
  -- -------- --

if @xmath , and @xmath otherwise. It follows from the quantum counting
argument (Theorem 3.2.1 ) that

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be the set of strings that are generated by the program
@xmath on any input @xmath . (It will turn out that @xmath is finite; if
the input @xmath is too large, then @xmath will not halt.) As the
function @xmath is superadditive on @xmath for @xmath , and as @xmath
(compare Corollary 2.3.13 ), we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, we get

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

Now we join both parts of the proof together to show the assumption of
the lemma. Let @xmath be a classical Turing machine that expects input
@xmath of the following form:

  -- -------- --
     @xmath   
  -- -------- --

The machine @xmath first determines the length @xmath by detecting the
first blank symbol @xmath on its tape. Then, it computes the number
@xmath in the same way as given above in step (1) of the computer
program @xmath , and @xmath . Afterwards, it computes the number @xmath
as the unique ³ ³ 3 If such an integer @xmath exists, it is unique.
Otherwise, we may define the program to continue in an arbitrary way,
e.g. to halt immediately. integer satisfying

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be the number of the string @xmath in the set @xmath . The
machine @xmath computes the output @xmath of @xmath on input @xmath ,
@xmath , @xmath and @xmath , outputs @xmath and halts. We know from
Equation ( 3.6 ) that every word @xmath on the list @xmath can be
constructed in this way by choosing @xmath appropriately. We have

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is bounded, we even have

  -- -------- --
     @xmath   
  -- -------- --

Thus, if @xmath is any string on the list, then @xmath . Equation ( 3.5
) now follows from the invariance of classical Kolmogorov complexity.

To prove Equation ( 3.4 ), let @xmath be the classical Turing machine
that expects input of the form

  -- -------- --
     @xmath   
  -- -------- --

The machine @xmath first determines the length @xmath by detecting the
first blank symbol @xmath on its tape. Then, it computes @xmath and
@xmath as well as @xmath . Moreover, it computes a classical description
of the QTM @xmath , defined by @xmath (compare Lemma 2.1.8 ). Let @xmath
be the number of the string @xmath in the set @xmath . The machine
@xmath computes the output @xmath of @xmath on input @xmath , @xmath ,
@xmath and @xmath , outputs @xmath and halts.

Suppose that @xmath is a classical string with @xmath , then there is a
qubit string @xmath such that @xmath for every @xmath , in particular
for the @xmath given above. Thus,

  -- -------- --
     @xmath   
  -- -------- --

It follows that the string @xmath is an element of the set @xmath
corresponding to the input specified above. Moreover, since @xmath , the
length of the list is bounded by

  -- -------- --
     @xmath   
  -- -------- --

Thus, the length @xmath is enough to specify any element of the set
@xmath , and @xmath . Equation ( 3.4 ) now follows again from the
invariance of classical Kolmogorov complexity. @xmath

This was the most difficult part. Now, we use a few more arguments to
prove the main result of this section. \MakeFramed \FrameRestore

###### Theorem 3.4.2 (Quantum Complexity of Classical Strings)

For every classical string @xmath , it holds

  -- -------- --
     @xmath   
  -- -------- --

i.e. the absolute value of the difference of @xmath and @xmath is
bounded by a constant on the domain of classical strings. Moreover, for
every rational @xmath , there are constants @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. If @xmath is large enough such that @xmath , then we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a constant that depends only on @xmath . This follows
from the obvious monotonicity property @xmath and Lemma 3.1.2 .

Also, we claim that there is some constant @xmath such that for every
classical string @xmath , it holds

  -- -------- --
     @xmath   
  -- -------- --

This can be seen as follows: According to Bennett [ 3 ] , we can choose
the classical TM which is used in the definition of @xmath to be
reversible. But every reversible TM is also a (special case of a) QTM.
Thus, this equation follows from Theorem 3.3.1 , the invariance theorem
for @xmath .

All the remaining inequalities are shown in Lemma 3.4.1 . @xmath

### 3.5 Quantum Brudno’s Theorem

In this section, we prove a theorem that relates the von Neumann entropy
rate and the quantum Kolmogorov complexity rate of ergodic quantum
information sources. This generalizes a classical theorem that has first
been conjectured by Zvonkin and Levin [ 48 ] , and was later proved by
Brudno [ 9 ] . The content of this section is joint work with F.
Benatti, T. Krüger, Ra. Siegmund-Schultze and A. Szkoła, and has already
been published in [ 1 ] .

The idea of the classical theorem is to compare two different notions of
randomness: Kolmogorov complexity, which measures the randomness of
single binary strings, and Shannon entropy, which is a measure of
randomness for information sources, i.e. probability distributions.

In more detail, if @xmath is a stationary classical information source,
the most important parameter is its entropy rate @xmath , where @xmath
denotes the Shannon entropy of the ensembles of strings of length @xmath
that are emitted according to the probability distribution @xmath .
According to the Shannon-McMillan-Breiman theorem [ 6 , 11 ] , @xmath
represents the optimal compression rate at which the information
provided by classical ergodic sources can be compressed and then
retrieved with negligible probability of error (in the limit of longer
and longer strings). Essentially, @xmath is the number of bits that are
needed for reliable compression of bit strings of length @xmath . Thus,
@xmath can be interpreted as a measure of randomness of the source
@xmath and of the ensembles it emits.

On the other hand, one can look at the randomness of the single strings
that are emitted by the source. If @xmath is an infinite binary string
and @xmath denotes its first @xmath bits, then one can similarly define
its complexity rate as @xmath (if that limit exists), where @xmath
denotes classical Kolmogorov complexity.

Intuitively, one expects a connection between the randomness of single
strings and the average randomness of ensembles of strings. In the
classical case, this is exactly the content of a theorem by Brudno [ 9 ,
46 , 19 , 42 ] which states that for ergodic sources, the complexity
rate of @xmath -almost all infinite sequences @xmath coincides with the
entropy rate, i.e. @xmath holds @xmath -almost surely.

In this section, we prove that a similar relation holds for the von
Neumann entropy rate and the quantum Kolmogorov complexity rate of
quantum ergodic information sources (we explain this notion below in
Subsection 3.5.1 ). This is an interesting result in its own right, and
it also supports the point of view that the quantum Kolmogorov
complexity notions @xmath and @xmath are useful and natural.

#### 3.5.1 Ergodic Quantum Sources

In order to formulate our main result rigorously, we start with a brief
introduction to the relevant concepts of the formalism of quasi-local
@xmath -algebras, which is the most suitable formalism for dealing with
quantum information sources. At the same time, we fix some notation.

We would like to consider a spin chain of infinitely many qubits. This
chain is modelled by some @xmath -algebra @xmath , the quasi-local
algebra , which is constructed as follows.

We consider the lattice @xmath and assign to each site @xmath a @xmath
-algebra @xmath being a copy of a fixed finite-dimensional algebra
@xmath , in the sense that there exists a @xmath -isomorphism @xmath .
To simplify notations, we write @xmath for @xmath and @xmath . The
algebra of observables associated to a finite @xmath is defined by
@xmath . Observe that for @xmath we have @xmath and there is a canonical
embedding of @xmath into @xmath given by @xmath , where @xmath and
@xmath denotes the identity of @xmath . The infinite-dimensional
quasi-local @xmath -algebra @xmath is the norm completion of the normed
algebra @xmath , where the union is taken over all finite subsets @xmath
.

In this thesis, we only deal with qubits. Thus, in the following, we
restrict our considerations to the case where @xmath is the algebra of
observables of a qubit, i.e. the algebra @xmath of @xmath matrices
acting on @xmath .

Similarly, we think of @xmath as the algebra of observables of qubit
strings of length @xmath , namely the algebra @xmath of @xmath matrices
acting on the Hilbert space @xmath . The quasi-local algebra @xmath
corresponds to the doubly-infinite qubit strings.

The (right) shift @xmath is a @xmath -automorphism on @xmath uniquely
defined by its action on local observables

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

where @xmath is an integer interval.

A state @xmath on @xmath is a normalized positive linear functional on
@xmath . Each local state @xmath , @xmath finite, corresponds to a
density operator @xmath by the relation @xmath , for all @xmath , where
@xmath is the trace on @xmath . The density operator @xmath is a
positive matrix acting on the Hilbert space @xmath associated with
@xmath satisfying the normalization condition @xmath . The simplest
@xmath correspond to one-dimensional projectors @xmath onto vectors
@xmath and are called pure states, while general density operators are
linear convex combinations of one-dimensional projectors: @xmath ,
@xmath , @xmath .

A state @xmath on @xmath corresponds one-to-one to a family of density
operators @xmath , @xmath finite, fulfilling the consistency condition
@xmath for @xmath , where @xmath denotes the partial trace over the
local algebra @xmath which is computed with respect to any orthonormal
basis in the associated Hilbert space @xmath . Notice that a state
@xmath with @xmath , i.e. a shift-invariant state, is uniquely
determined by a consistent sequence of density operators @xmath in
@xmath corresponding to the local states @xmath , where @xmath denotes
the integer interval @xmath , for each @xmath .

As motivated in the introduction, in the information-theoretical
context, we interpret the tuple @xmath describing the quantum spin chain
as a stationary quantum source.

The von Neumann entropy of a density matrix @xmath is @xmath . By the
subadditivity of @xmath for a shift-invariant state @xmath on @xmath ,
the following limit, the quantum entropy rate, exists

  -- -------- --
     @xmath   
  -- -------- --

The set of shift-invariant states on @xmath is convex and compact in the
weak @xmath -topology. The extremal points of this set are called
ergodic states: they are those states which cannot be decomposed into
linear convex combinations of other shift-invariant states. Notice that
in particular the shift-invariant product states defined by a sequence
of density matrices @xmath , @xmath , where @xmath is a fixed @xmath
density matrix, are ergodic. They are the quantum counterparts of
Bernoulli (i.i.d.) processes. Most of the results in quantum information
theory concern such sources, but more general ergodic quantum sources
allowing correlations can be considered. This is often useful, since
such sources naturally appear, for example, in statistical mechanics.

#### 3.5.2 Proof of Quantum Brudno’s Theorem

It turns out that the rates of the quantum Kolmogorov complexities
@xmath and @xmath of the typical pure states (i.e. typical pure qubit
strings) generated by an ergodic quantum source @xmath are
asymptotically equal to the entropy rate @xmath of the source. A precise
formulation of this result is the content of the following theorem. It
can be seen as a quantum extension of Brudno’s theorem as a convergence
in probability statement, while the original formulation of Brudno’s
result is an almost sure statement.

In the remainder of this section, we call a sequence of projectors
@xmath , @xmath , satisfying @xmath a sequence of @xmath -typical
projectors .

\MakeFramed \FrameRestore

###### Theorem 3.5.1 (Quantum Brudno Theorem)

Let @xmath be an ergodic quantum source with entropy rate @xmath . For
every @xmath , there exists a sequence of @xmath -typical projectors
@xmath , @xmath , i.e. @xmath , such that for @xmath large enough every
one-dimensional projector @xmath satisfies

  -- -------- -- -------
     @xmath      (3.8)
     @xmath      (3.9)
  -- -------- -- -------

Moreover, @xmath is the optimal expected asymptotic complexity rate, in
the sense that every sequence of projectors @xmath , @xmath , that for
large @xmath may be represented as a sum of mutually orthogonal
one-dimensional projectors that all violate the lower bounds in ( 3.8 )
and ( 3.9 ) for some @xmath , has an asymptotically vanishing
expectation value with respect to @xmath .

\endMakeFramed

##### Proof of the Lower Bound

A key argument in the proof of the lower bound is the following theorem
[ 7 , Prop. 2.1] . It is closely related to the quantum Shannon-McMillan
Theorem and concerns the minimal dimension of the @xmath typical
subspaces.

\MakeFramed \FrameRestore

###### Theorem 3.5.2 ([7])

Let @xmath be an ergodic quantum source with entropy rate @xmath . Then,
for every @xmath ,

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

where @xmath .

\endMakeFramed

Notice that the limit ( 3.10 ) is valid for every @xmath . By means of
this property, we will first prove the lower bound for the complexity
notion @xmath , and then use Lemma 3.1.2 to extend it to @xmath .
\MakeFramed \FrameRestore

###### Corollary 3.5.3 (Lower Bound for @xmath)

Let @xmath be an ergodic quantum source with entropy rate @xmath .
Moreover, let @xmath , and let @xmath be a sequence of @xmath -typical
projectors. Then, there is another sequence of @xmath -typical
projectors @xmath , such that for @xmath large enough

  -- -------- --
     @xmath   
  -- -------- --

is true for every one-dimensional projector @xmath .

\endMakeFramed

Proof. The case @xmath is trivial, so let @xmath . Fix @xmath and @xmath
, and consider the set

  -- -------- --
     @xmath   
  -- -------- --

From the definition of @xmath , for all @xmath there exist associated
density matrices @xmath with @xmath such that @xmath , where @xmath
denotes the quantum operation @xmath of the corresponding strongly
universal QTM @xmath , as explained in Lemma 2.3.4 . Let @xmath be a sum
of a maximal number of mutually orthogonal projectors from the set
@xmath . Lemma 3.2.1 implies that

  -- -------- --
     @xmath   
  -- -------- --

and there are no one-dimensional projectors @xmath such that @xmath .
Thus, one-dimensional projectors @xmath must satisfy @xmath . Since
@xmath for every @xmath , we conclude

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Using Theorem 3.5.2 , we obtain that @xmath . Finally, set @xmath . The
claim follows. @xmath

\MakeFramed \FrameRestore

###### Corollary 3.5.4 (Lower Bound for @xmath)

Let @xmath be an ergodic quantum source with entropy rate @xmath . Let
@xmath with @xmath be an arbitrary sequence of @xmath -typical
projectors. Then, for every @xmath , there is a sequence of @xmath
-typical projectors @xmath such that for @xmath large enough

  -- -------- --
     @xmath   
  -- -------- --

is satisfied for every one-dimensional projector @xmath .

\endMakeFramed

Proof. According to Corollary 3.5.3 , for every @xmath , there exists a
sequence of @xmath -typical projectors @xmath with @xmath for every
one-dimensional projector @xmath if @xmath is large enough. We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where the first estimate is by Lemma 3.1.2 , and the second one is true
for one-dimensional projectors @xmath and @xmath large enough. Fix some
large @xmath satisfying @xmath . The result follows by setting @xmath .
@xmath

##### Upper Bound

In the previous paragraph, we have shown that with high probability and
for large @xmath , the quantum complexity rate @xmath is bounded from
below by @xmath , and the quantum complexity rate @xmath by @xmath . We
are now going to establish the upper bounds.

###### Proposition 3.5.5 (Upper Bound)

Let @xmath be an ergodic quantum source with entropy rate @xmath . Then,
for every @xmath , there is a sequence of @xmath -typical projectors
@xmath such that for every one-dimensional projector @xmath and @xmath
large enough

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.12)
     @xmath   @xmath   @xmath      (3.13)
  -- -------- -------- -------- -- --------

We prove the above proposition by explicitly providing a quantum
algorithm (with program length increasing like @xmath ) that computes
@xmath within arbitrary accuracy. This will be done by means of quantum
universal typical subspaces constructed by Kaltchenko and Yang in [ 18 ]
. \MakeFramed \FrameRestore

###### Theorem 3.5.6 (Universal Typical Subspaces [18])

Let @xmath and @xmath . There exists a sequence of projectors @xmath ,
@xmath , such that for @xmath large enough

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

and for every ergodic quantum state @xmath with entropy rate @xmath it
holds that

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

\endMakeFramed

We call the orthogonal projectors @xmath in the above theorem universal
typical projectors at level @xmath . Suited for designing an appropriate
quantum algorithm, we slightly modify the proof given by Kaltchenko and
Yang in [ 18 ] .

Proof. Let @xmath and @xmath . We consider an Abelian quasi-local
subalgebra @xmath constructed from a maximal Abelian @xmath block
subalgebra @xmath . The results in [ 47 , 20 ] imply that there exists a
universal sequence of projectors @xmath with @xmath such that @xmath for
any ergodic state @xmath on the Abelian algebra @xmath with entropy rate
@xmath . Notice that ergodicity and entropy rate of @xmath are defined
with respect to the shift on @xmath , which corresponds to the @xmath
-shift on @xmath .

The first step in [ 18 ] is to apply unitary operators of the form
@xmath , @xmath unitary, to the @xmath and to introduce the projectors

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

Let @xmath be a spectral decomposition of @xmath (with @xmath some index
set), and let @xmath denote the orthogonal projector onto a given
subspace @xmath . Then, @xmath can also be written as

  -- -------- --
     @xmath   
  -- -------- --

It will be more convenient for the construction of our algorithm in
3.5.2 to consider the projector

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

It holds that @xmath . For integers @xmath with @xmath and @xmath we
introduce the projectors in @xmath

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

We now use an argument of [ 17 ] to estimate the trace of @xmath . The
dimension of the symmetric subspace @xmath is upper bounded by @xmath ,
thus

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.19)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Now we consider a stationary ergodic state @xmath on the quasi-local
algebra @xmath with entropy rate @xmath . Let @xmath . If @xmath is
chosen large enough then the projectors @xmath , where @xmath , are
@xmath typical for @xmath , i.e. @xmath , for @xmath sufficiently large.
This can be seen as follows. Due to the result in [ 7 , Thm. 3.1] the
ergodic state @xmath convexly decomposes into @xmath states

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

each @xmath being ergodic with respect to the @xmath shift on @xmath and
having an entropy rate (with respect to the @xmath shift) equal to
@xmath . We define for @xmath the set of integers

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

Then, according to a density lemma proven in [ 7 , Lemma 3.1] it holds

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

Let @xmath be the maximal Abelian subalgebra of @xmath generated by the
one-dimensional eigenprojectors of @xmath . The restriction of a
component @xmath to the Abelian quasi-local algebra @xmath is again an
ergodic state. It holds in general

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

For @xmath , where we set @xmath , we additionally have the upper bound
@xmath . Let @xmath be a unitary operator such that @xmath . For every
@xmath , it holds that

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

We fix an @xmath large enough to fulfill @xmath and use the ergodic
decomposition ( 3.20 ) to obtain the lower bound

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

From ( 3.24 ) we conclude that for @xmath large enough

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

We proceed by following the lines of [ 18 ] by introducing the sequence
@xmath , @xmath , where each @xmath is a power of @xmath fulfilling the
inequality

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

Let the integer sequence @xmath and the real-valued sequence @xmath be
defined by @xmath and @xmath . Then we set

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

Observe that

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.29)
                       @xmath   @xmath   
              @xmath   @xmath            (3.30)
  -- -------- -------- -------- -------- --------

where the second inequality is by estimate ( 3.19 ) and the last one by
the bounds on @xmath

  -- -------- --
     @xmath   
  -- -------- --

Thus, for large @xmath , it holds

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

By the special choice ( 3.27 ) of @xmath it is ensured that the sequence
of projectors @xmath is indeed typical for any quantum state @xmath with
entropy rate @xmath , compare [ 18 ] . This means that @xmath is a
sequence of universal typical projectors at level @xmath . @xmath

##### Construction of the Decompression Algorithm

We proceed by applying the latter result to universal typical subspaces
for our proof of the upper bound. Let @xmath be an arbitrary real number
such that @xmath is rational, and let @xmath be the universal projector
sequence of Theorem 3.5.6 . Recall that the projector sequence @xmath is
independent of the choice of the ergodic state @xmath , as long as
@xmath .

Because of ( 3.14 ), for @xmath large enough, there exists some unitary
transformation @xmath that transforms the projector @xmath into a
projector belonging to @xmath , thus transforming every one-dimensional
projector @xmath into a qubit string @xmath of length @xmath .

As shown in [ 4 ] , a UQTM can implement every classical algorithm, and
it can apply every unitary transformation @xmath (when given an
algorithm for the computation of @xmath ) on its tapes within any
desired accuracy. We can thus feed @xmath (plus some classical
instructions including a subprogram for the computation of @xmath ) as
input into the UQTM @xmath . This UQTM starts by computing a classical
description of the transformation @xmath , and subsequently applies
@xmath to @xmath , recovering the original projector @xmath on the
output tape.

Since @xmath depends on @xmath only through its entropy rate @xmath ,
the subprogram that computes @xmath does not have to be supplied with
additional information on @xmath and will thus have fixed length.

We give a precise definition of a quantum decompression algorithm @xmath
, which is, formally, a mapping ( @xmath is rational)

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

We require that @xmath is a “short algorithm” in the sense of “short in
description”, not short (fast) in running time or resource consumption.
Indeed, the algorithm @xmath is very slow and memory consuming, but this
does not matter, since Kolmogorov complexity only cares about the
description length of the program.

The instructions defining the quantum algorithm @xmath are:

-   Read the value of @xmath , and find a solution @xmath for the
    inequality

      -- -------- --
         @xmath   
      -- -------- --

    such that @xmath is a power of two. (There is only one such @xmath
    .)

-   Compute @xmath .

-   Read the value of @xmath . Compute @xmath .

-   Compute a list of codewords @xmath , belonging to a classical
    universal block code sequence of rate @xmath . (For the construction
    of an appropriate algorithm, see [ 20 , Thm. 2 and 1] .) Since

      -- -------- --
         @xmath   
      -- -------- --

    @xmath can be stored as a list of binary strings. Every string has
    length @xmath . (Note that the exact value of the cardinality @xmath
    depends on the choice of @xmath .)

During the following steps, the quantum algorithm @xmath will have to
deal with

-   rational numbers,

-   square roots of rational numbers,

-   binary-digit-approximations (up to some specified accuracy) of real
    numbers,

-   (large) vectors and matrices containing such numbers.

A classical TM can of course deal with all such objects (and so can a
QTM): For example, rational numbers can be stored as a list of two
integers (containing numerator and denominator), square roots can be
stored as such a list and an additional bit denoting the square root,
and binary-digit-approximations can be stored as binary strings. Vectors
and matrices are arrays containing those objects. They are always
assumed to be given in the computational basis. Operations on those
objects, like addition or multiplication, are easily implemented.

The quantum algorithm @xmath continues as follows:

-   Compute a basis @xmath of the symmetric subspace

      -- -------- --
         @xmath   
      -- -------- --

    This can be done as follows: For every @xmath -tuple @xmath , where
    @xmath , there is one basis element @xmath , given by the formula

      -- -------- -- --------
         @xmath      (3.32)
      -- -------- -- --------

    where the summation runs over all @xmath -permutations @xmath , and

      -- -------- --
         @xmath   
      -- -------- --

    with @xmath a system of matrix units ⁴ ⁴ 4 In the computational
    basis, all entries are zero, except for one entry which is one. in
    @xmath .

    There is a number of @xmath different matrices @xmath which we can
    label by @xmath . It follows from ( 3.32 ) that these matrices have
    integer entries.

    They are stored as a list of @xmath -tables of integers. Thus, this
    step of the computation is exact, that is without approximations.

-   For every @xmath and @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath denotes the computational basis vector which is a
    tensor product of @xmath ’s and @xmath ’s according to the bits of
    the string @xmath . Compute the vectors @xmath one after the other.
    For every vector that has been computed, check if it can be written
    as a linear combination of already computed vectors. (The
    corresponding system of linear equations can be solved exactly,
    since every vector is given as an array of integers.) If yes, then
    discard the new vector @xmath , otherwise store it and give it a
    number.

    This way, a set of vectors @xmath is computed. These vectors
    linearly span the support of the projector @xmath given in ( 3.17 ).

-   Denote by @xmath the computational basis vectors of @xmath . If
    @xmath , then let @xmath , and let @xmath . Otherwise, compute
    @xmath for every @xmath and @xmath . The resulting set of vectors
    @xmath has cardinality @xmath .

    In both cases, the resulting vectors @xmath will span the support of
    the projector @xmath .

-   The set @xmath is completed to linearly span the whole space @xmath
    . This will be accomplished as follows:

    Consider the sequence of vectors

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath denotes the computational basis vectors of @xmath .
    Find the smallest @xmath such that @xmath can be written as a linear
    combination of @xmath , and discard it (this can still be decided
    exactly, since all the vectors are given as tables of integers).
    Repeat this step @xmath times until there remain only @xmath
    linearly independent vectors, namely all the @xmath and @xmath of
    the @xmath .

-   Apply the Gram-Schmidt orthonormalization procedure to the resulting
    vectors, to get an orthonormal basis @xmath of @xmath , such that
    the first @xmath vectors are a basis for the support of @xmath .

    Since every vector @xmath and @xmath has only integer entries, all
    the resulting vectors @xmath will have only entries that are (plus
    or minus) the square root of some rational number.

Up to this point, every calculation was exact without any numerical
error, comparable to the way that well-known computer algebra systems
work. The goal of the next steps is to compute an approximate
description of the desired unitary decompression map @xmath and
subsequently apply it to the quantum state @xmath .

According to Section 6 in [ 4 ] , a UQTM is able to apply a unitary
transformation @xmath on some segment of its tape within an accuracy of
@xmath , if it is supplied with a complex matrix @xmath as input which
is within operator norm distance @xmath of @xmath (here, @xmath denotes
the size of the matrix). Thus, the next task is to compute the number of
digits @xmath that are necessary to guarantee that the output will be
within trace distance @xmath of @xmath .

-   Read the value of @xmath (which denotes an approximation parameter;
    the larger @xmath , the more accurate the output of the algorithm
    will be). Due to the considerations above and the calculations
    below, the necessary number of digits @xmath turns out to be @xmath
    . Compute this number.

    Afterwards, compute the components of all the vectors @xmath up to
    @xmath binary digits of accuracy. (This involves only calculation of
    the square root of rational numbers, which can easily be done to any
    desired accuracy.)

    Call the resulting numerically approximated vectors @xmath . Write
    them as columns into an array (a matrix) @xmath .

    Let @xmath denote the unitary matrix with the exact vectors @xmath
    as columns. Since @xmath binary digits give an accuracy of @xmath ,
    it follows that

      -- -------- --
         @xmath   
      -- -------- --

    If two @xmath -matrices @xmath and @xmath are @xmath -close in their
    entries, they also must be @xmath -close in norm, so we get

      -- -------- --
         @xmath   
      -- -------- --

So far, every step was purely classical and could have been done on a
classical computer. Now, the quantum part begins: @xmath will be touched
for the first time.

-   Compute @xmath , which gives the length @xmath . Afterwards, move
    @xmath to some free space on the input tape, and append zeroes, i.e.
    create the state

      -- -------- --
         @xmath   
      -- -------- --

    on some segment of @xmath cells on the input tape.

-   Approximately apply the unitary transformation @xmath on the tape
    segment that contains the state @xmath .

    The machine cannot apply @xmath exactly (since it only knows an
    approximation @xmath ), and it also cannot apply @xmath directly
    (since @xmath is only approximately unitary, and the machine can
    only do unitary transformations). Instead, it will effectively apply
    another unitary transformation @xmath which is close to @xmath and
    thus close to @xmath , such that

      -- -------- --
         @xmath   
      -- -------- --

    Let @xmath be the output that we want to have, and let @xmath be the
    approximation that is really computed by the machine. Then,

      -- -------- --
         @xmath   
      -- -------- --

    A simple calculation proves that the trace distance must then also
    be small:

      -- -------- --
         @xmath   
      -- -------- --

-   Move @xmath to the output tape and halt.

##### Proof of Proposition 3.5.5

We have to give a precise definition how the parameters @xmath are
encoded into a single qubit string @xmath . (According to the definition
of @xmath , the parameter @xmath is not a part of @xmath , but is given
as a second parameter. See Definitions 2.1.7 and 3.1.1 for details.)

We choose to encode @xmath by giving @xmath 1’s, followed by one 0,
followed by the @xmath binary digits of @xmath . Let @xmath denote the
corresponding projector in the computational basis.

The parameter @xmath can be encoded in any way, since it does not depend
on @xmath . The only constraint is that the description must be
self-delimiting, i.e. it must be clear and decidable at what position
the description for @xmath starts and ends. The descriptions will also
be given by a computational basis vector (or rather the corresponding
projector) @xmath .

The descriptions are then stuck together, and the input @xmath is given
by

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is large enough such that ( 3.31 ) is fulfilled, it follows
that @xmath , where @xmath is some constant which depends on @xmath ,
but not on @xmath .

It is clear that this qubit string can be fed into the reference UQTM
@xmath together with a description of the algorithm @xmath of fixed
length @xmath which depends on @xmath , but not on @xmath . This will
give a qubit string @xmath of length

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.33)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where @xmath is again a constant which depends on @xmath , but not on
@xmath . Recall the matrix @xmath constructed in step 11 of our
algorithm @xmath , which rotates (decompresses) a compressed (short)
qubit string @xmath back into the typical subspace. Conversely, for
every one-dimensional projector @xmath , where @xmath was defined in (
3.28 ), let @xmath be the projector given by @xmath . Then, since @xmath
has been constructed such that

  -- -------- --
     @xmath   
  -- -------- --

it follows from ( 3.33 ) that

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is large enough, Equation ( 3.12 ) follows.

Now we continue by proving Equation ( 3.13 ). Let @xmath . Then, we have
for every one-dimensional projector @xmath and @xmath large enough

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.34)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where the first inequality follows from the obvious monotonicity
property @xmath , the second one is by Lemma 3.1.2 , and the third
estimate is due to Equation ( 3.12 ). @xmath

Proof of the Main Theorem 3.5.1 . Let @xmath be the @xmath -typical
projector sequence given in Proposition 3.5.5 , i.e. the complexities
@xmath and @xmath of every one-dimensional projector @xmath are upper
bounded by @xmath . Due to Corollary 3.5.3 , there exists another
sequence of @xmath -typical projectors @xmath such that additionally,
@xmath is satisfied for @xmath . From Corollary 3.5.4 , we can further
deduce that there is another sequence of @xmath -typical projectors
@xmath such that also @xmath holds. Finally, the optimality assertion is
a direct consequence of Lemma 3.2.1 , combined with Theorem 3.5.2 .
@xmath

## Chapter 4 Summary and Outlook

In this thesis, we have formally defined quantum Kolmogorov complexity,
based on work by Berthiaume et al. [ 5 ] , and have given rigorous
mathematical proofs of its basic properties. In particular, we have
shown that the quantum Kolmogorov complexity notions @xmath and @xmath
are invariant, that they coincide with classical complexity for
classical strings, they have incompressibility properties, and the
corresponding quantum Kolmogorov complexity rates agree with the von
Neumann entropy rate for ergodic quantum information sources.

The most complicated step to achieve these results was to give a
rigorous formal proof that there exists a universal quantum Turing
machine (QTM) @xmath in the following sense: that QTM @xmath can
simulate every other QTM for an arbitrary number of time steps, without
knowing the running time in advance, and then halt itself with
probability one. The question whether this is possible has been ignored
in previous work on quantum Kolmogorov complexity, but it is necessary
to prove the invariance property, i.e. the feature that quantum
Kolmogorov complexity depends on the choice of the universal quantum
computer only up to an additive constant.

We also discussed the question how the halting of a QTM can be defined.
We argued that for the purpose of studying quantum Kolmogorov
complexity, the most useful and natural definition is to demand perfect
halting. To show that this definition is not as restrictive as one might
first suppose, we proved that every input that makes a QTM halt
approximately can be enhanced by at most a constant number of qubits to
make the universal QTM halt entirely.

Furthermore, we have defined the average-length complexities @xmath and
@xmath and studied them to some extent. Because of Lemma 3.3.4 and the
proof idea of Conjecture 2.2.3 , we think that these complexities are
closely related to prefix QTMs , which we have defined in Definition
2.3.5 . Studying prefix QTMs may also be interesting for another reason:
it may give an alternative approach to Tadaki’s definition [ 44 ] of the
quantum halting probability, and it may help to clarify the relation of
the complexity notions @xmath or @xmath to the universal density matrix
approach by Gács. This speculation is supported by the fact that
classical prefix complexity is related to universal probability and
Chaitin’s halting probability by Levin’s theorem [ 23 ] .

Classical Kolmogorov complexity has a large variety of applications in
different fields of mathematics and computer science. Hence it may be
worthwhile to look for applications of quantum Kolmogorov complexity. A
very promising field for application is quantum statistical mechanics,
since classical Kolmogorov complexity has already turned out to be
useful in the classical version of that theory.

A concrete proposal for an application of quantum Kolmogorov complexity
is to analyze a quantum version of the thought experiment of Maxwell’s
demon. In one of the versions of this thought experiment, some
microscopic device tries to decrease the entropy of some gas in a box,
without the expense of energy, by intelligently opening or closing some
little door that separates both halves of the box.

It is clear that a device like this cannot work as described, since its
existence would violate the second law of thermodynamics. But then, the
question is what prevents such a little device (or “demon”) from
operating. Roughly, the answer is that the demon has to make
observations to decide whether to close or open the door, and these
observations accumulate information. From time to time, the demon must
erase this additional information, which is only possible at the expense
of energy, due to Landauer’s principle.

In [ 23 ] , this cost of energy is analyzed under very weak assumptions
with the help of Kolmogorov complexity. Basically, the energy that the
demon can extract from the gas is limited by the difference of the
entropy of the gas, plus the difference of the Kolmogorov complexity of
the demon’s memory before and after the demon’s actions. The power of
this analysis is that it even encloses the case that the demon has a
computer to do clever calculations, e.g. to compress the accumulated
information before erasing it.

It seems that quantum Kolmogorov complexity might have all the
properties needed to extend this analysis to the quantum case. Yet, the
average-length complexities @xmath or @xmath are probably more useful in
this case than @xmath or @xmath , since they resemble more closely the
fact that the expectation value of the amount of information that has to
be erased is physically important, not the maximal size of the system.

To conclude, we found that quantum Kolmogorov complexity is a beautiful
concept with a promising potential for new applications. Applications
aside, quantum Kolmogorov complexity offers the opportunity to deepen
our understanding of the theoretical aspects of quantum computation and
is interesting as a subject in its own right.

## Appendix A Appendix

The following lemma is due M. B. Ruskai ( [ 38 ] ) and can also be found
in [ 30 ] for the finite-dimensional case.

\MakeFramed \FrameRestore

###### Lemma A.1 (Quantum Operations are Contractive)

Let @xmath and @xmath be Hilbert spaces, and let @xmath be linear,
positive and trace-preserving. If @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. If @xmath is any positive trace-class operator on @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

Since every self-adjoint operator @xmath can be written as @xmath ,
where @xmath and @xmath are positive operators, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

\MakeFramed \FrameRestore

###### Lemma A.2 (Inner Product and Dimension Bound)

Let @xmath be a Hilbert space, and let @xmath with @xmath for every
@xmath , where @xmath . Suppose that

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath . In particular, the vectors @xmath are linearly
independent.

\endMakeFramed

Proof. We prove the statement by induction in @xmath . For @xmath , the
statement of the theorem is trivial. Suppose the claim holds for some
@xmath , then consider @xmath vectors @xmath , where @xmath is an
arbitrary Hilbert space. Suppose that @xmath for every @xmath . Let
@xmath , then @xmath for every @xmath , and let

  -- -------- --
     @xmath   
  -- -------- --

The @xmath are normalized vectors in the Hilbert subspace @xmath of
@xmath . Since @xmath , it follows that the vectors @xmath have small
inner product: Let @xmath , then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, @xmath , and so @xmath . @xmath

\MakeFramed \FrameRestore

###### Lemma A.3 (Composition of Unitary Operations)

Let @xmath be a finite-dimensional Hilbert space, let @xmath be a
sequence of linear subspaces of @xmath (which have all the same
dimension), and let @xmath be a sequence of unitary operators on @xmath
such that @xmath exists. Then, the product @xmath converges in operator
norm to an isometry @xmath .

\endMakeFramed

Proof. We first show by induction that @xmath . This is trivially true
for @xmath ; suppose it is true for @xmath factors, then

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

By assumption, the sequence @xmath is a Cauchy sequence; hence, for
every @xmath there is an @xmath such that for every @xmath it holds that
@xmath . Consider now the sequence @xmath . If @xmath , then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

so @xmath is also a Cauchy sequence and converges in operator norm to
some linear operator @xmath on @xmath . It is easily checked that @xmath
must be isometric. @xmath

\MakeFramed \FrameRestore

###### Lemma A.4 (Norm Inequalities)

Let @xmath be a finite-dimensional Hilbert space, and let @xmath with
@xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

Moreover, if @xmath are density operators, then

  -- -------- --
     @xmath   
  -- -------- --

\endMakeFramed

Proof. Let @xmath . Using [ 30 , 9.99] ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Let now @xmath , then @xmath is Hermitian. We may assume that one of its
eigenvalues which has largest absolute value is positive (otherwise
interchange @xmath and @xmath ), thus

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

according to [ 30 , 9.22] . @xmath

\MakeFramed \FrameRestore

###### Lemma A.5 (Dimension Bound for Similar Subspaces)

Let @xmath be a finite-dimensional Hilbert space, and let @xmath be
subspaces such that for every @xmath with @xmath there is a vector
@xmath with @xmath which satisfies @xmath , where @xmath is fixed. Then,
@xmath . Moreover, if additionally @xmath holds, then there exists an
isometry @xmath such that @xmath .

\endMakeFramed

Proof. Let @xmath be an orthonormal basis of @xmath . By assumption,
there are normalized vectors @xmath with @xmath for every @xmath . From
the definition of the trace distance for pure states (see [ 30 , (9.99)]
together with Lemma A.4 , it follows for every @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, @xmath , and it follows from Lemma A.2 that @xmath . Now apply the
Gram-Schmidt orthonormalization procedure to the vectors @xmath :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Use @xmath and calculate

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Let @xmath for every @xmath . We will now show by induction that @xmath
. This is trivially true for @xmath , since @xmath . Suppose it is true
for every @xmath , then in particular, @xmath by the assumptions on
@xmath given in the statement of this lemma, and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus, it holds that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now define the linear operator @xmath via linear extension of @xmath for
@xmath . This map is an isometry, since it maps an orthonormal basis
onto an orthonormal basis of same dimension. By substituting @xmath and
using @xmath and the geometric series, it easily follows that @xmath if
@xmath . @xmath

\MakeFramed \FrameRestore

###### Lemma A.6 (Stability of the Control State)

If @xmath and @xmath and @xmath , then it holds for every QTM @xmath and
every @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

\endMakeFramed

Proof. Using the Cauchy-Schwarz inequality, Lemma A.4 and the
contractivity of quantum operations with respect to the trace distance
(Lemma A.1 ), we get the chain of inequalities

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

The second inequality can be proved by an analogous calculation. @xmath

## Appendix A Glossary of Symbols and Notation

  Notation   Meaning                                                                                                              Page
  ---------- -------------------------------------------------------------------------------------------------------------------- --------
  @xmath     the set of bounded linear operators on some Hilbert space @xmath                                                     2.3.3
  @xmath     the Kronecker symbol: @xmath                                                                                         2.3.8
  @xmath     the domain of definition of the map (e.g. QTM) @xmath                                                                2.1.4
  @xmath     the qubit string Hilbert space @xmath                                                                                2.1.1
  @xmath     the halting space of the QTM @xmath for time @xmath and inputs of length @xmath                                      2.3.1
  @xmath     the approximate halting space of accuracy @xmath of the QTM @xmath for time @xmath and inputs of length @xmath       2.3.10
  @xmath     @xmath with some fixed computational basis                                                                           2.1.1
  @xmath     the length of some classical finite binary string, or the base length of some qubit string                           2.1.1
  @xmath     the average length of some qubit string @xmath , given by @xmath , where @xmath is the length operator               2.1.1
  @xmath     the state of the control of the QTM @xmath at time @xmath , if the input was the qubit string @xmath                 2.2
  @xmath     the state of the output tape of the QTM @xmath at time @xmath , if the input was the qubit string @xmath             2.2
  QTM        quantum Turing machine                                                                                               1.2
  @xmath     “Reading operation”: if @xmath is the state of a QTM’s output tape, then @xmath is the corresponding qubit string.   2.1.2
  @xmath     the range of some map @xmath                                                                                         2.3.4
  @xmath     the restriction of the qubit string @xmath to its first @xmath qubits                                                2.3.5
  @xmath     the set of trace-class operators on a Hilbert space @xmath                                                           2.1.1
  @xmath     the set of density operators, i.e. positive trace-class operators of trace @xmath , on some Hilbert space @xmath     2.1.1
  TM         Turing machine                                                                                                       1.2
  @xmath     the trace of the operator @xmath , if @xmath is a trace-class operator on some Hilbert space                         2.1.1
  @xmath     the partial trace over the part @xmath of the whole Hilbert space (normally, @xmath denotes a QTM’s control)         2.2
