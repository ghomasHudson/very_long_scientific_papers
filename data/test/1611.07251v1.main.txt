##### Contents

-    Acknowledgements
-    1 Introduction
    -    1.1 An abridged history of the prime numbers
    -    1.2 Motivation for explicit results
    -    1.3 Summary of thesis
-    2 The Explicit Formula
    -    2.1 The Riemann zeta-function
    -    2.2 Proof of the explicit formula
-    3 Primes in Short Intervals
    -    3.1 Primes between consecutive cubes
    -    3.2 Improvements and higher powers
    -    3.3 A result on the Riemann hypothesis
-    4 Some Results in Additive Number Theory
    -    4.1 On a theorem of Estermann
    -    4.2 On a theorem of Erdős
-    5 Solving a Curious Inequality of Ramanujan
    -    5.1 The unconditional result
    -    5.2 Estimates on the Riemann hypothesis
-    6 An Offering of Open Problems

## Chapter 1 Introduction

  The White Rabbit put on his spectacles. “Where shall I begin, please
  your Majesty?” he asked.
  “Begin at the beginning,” the King said, very gravely, “and go on till
  you come to the end: then stop.”

It is the author’s hope that this introduction will be readable to any
person acquainted with a good level of mathematics. As such, one should
find that some effort has been put in to banish the technical
particulars to later chapters so as not to obscure the basic nature of
the work.

This thesis details the recent period of research undertaken by the
author; essentially, we present a collection of new results in the
theory of prime numbers. Most of these results have already found their
place in the literature through their publication in scholarly journals.
Therefore, the primary purpose of this thesis is to present this suite
of results cohesively in the context of modern number theory. One cannot
do this, of course, until the setting has been drawn, and so the
execution of this first chapter is as follows. We will provide an
abridged history of the theory of prime numbers before describing the
author’s contributions.

### 1.1 An abridged history of the prime numbers

Number theory is an ancient branch of mathematics centred around the
positive integers:

  -- -------- --
     @xmath   
  -- -------- --

The allure, perhaps, that this field of study holds for mathematicians
and amateurs alike, is that it allows one to formulate and test a
hypothesis with apparent ease. That is, one possessing little formal
background may still conduct seemingly effective investigations into the
properties of numbers. However, much difficulty often ensues when one
resolves to prove one’s conjecture in a rigorous way. Such a claim can
be supported by first introducing the sequence of prime numbers:

  -- -------- --
     @xmath   
  -- -------- --

These are the numbers that are greater than one and are not perfectly
divisible by any other positive integer except for one and themselves.
And so, the prime numbers have now been defined precisely, but if one
were to, say, ask for a mathematical formula which identifies the prime
numbers in an efficient way, one would be disappointed by an
unimpeachable lack of returns. Put simply, the primes seem to avoid the
good behaviour that we have come to expect of straightforwardly
constructed sequences of numbers.

One might also suppose it reasonable that the number one should appear
in the above list. The short response to this is that it used to be
included, but was at some point cleaved from the list in Pluto-esque
fashion for the sake of convenience ¹ ¹ 1 It is not entirely clear when
this happened, though we note that the number one is listed as a prime
in the tables of Lehmer [ lehmerlist ] and in Northrop’s book of
paradoxes [ northrop ] . The article by Caldwell and Xiong [
caldwellxiong ] discusses this point further in some great detail. . The
typical argument that one puts forward in order to justify such a
divorce is to mention the fundamental theorem of arithmetic , which
states that every positive integer greater than one is either a prime or
a unique product of primes. For example, one may decompose 60 into a
unique product of primes viz.

  -- -------- --
     @xmath   
  -- -------- --

and this is the only way which one may do so, ignoring swapping the
order of multiplication. Now, if the number one were to find itself in
the list of primes, then we could write

  -- -------- --
     @xmath   
  -- -------- --

with any count of ones on the tail, and this would disrupt any sort of
uniqueness. Therefore, by omitting the number one from the list, the
positive integers are uniquely composed of primes through
multiplication.

The next property that can be made of the primes is that there are
infinitely many of them. This statement was first proven by Euclid of
Alexandria [ euclid ] around 300BC, and took form as Proposition 20 in
the ninth book of Euclid’s Elementa .

###### Theorem 1.1.

There are infinitely many prime numbers.

###### Proof.

Assume that there are only finitely many prime numbers that we can list
as @xmath . If we let @xmath be the product of all the primes, then it
is clear that @xmath must be divisible by a prime that we have not
listed, for any two consecutive integers can have no prime factors in
common. This contradicts our assumption that there are finitely many
primes. ∎

It should be noted that this is not Euclid’s original proof; actually,
Euclid simply delivers a rigorous proof for the case @xmath , and so
kindly introduces the well-adopted practice of leaving the remaining
cases as a homework exercise.

It is the author’s intention at this early time to give a new proof of
Euclid’s theorem. This exercise has been done in abundance (see the book
of Narkiewicz [ narkiewicz , Ch. 1] for a collection of such proofs),
the point frequently being some contradiction arising from the
assumption of having only a finite set of primes. Here, we reproduce
Euler’s contradiction that the harmonic series (incorrectly) converges,
though we do so through humbler means.

The reader should know two things in order to follow the proof. First,
we say that a number is square-free if it is not divisible by the square
of any prime number. As such, one can collect all square-free numbers
simply by taking products of distinct primes. One also needs the
familiar fact that the harmonic series

  -- -------- --
     @xmath   
  -- -------- --

diverges to infinity.

###### Proof.

We begin by assuming that there are only finitely many prime numbers,
from which it follows immediately that there are only finitely many
square-free numbers. From here, we shall use @xmath to denote the set of
square-free numbers.

Thus, it is clear that every sufficiently large integer is divisible by
the square of some integer. This means that for any positive integer
@xmath , the set @xmath can be covered by taking the union of @xmath
with all multiples of squares that do not exceed @xmath . From this, we
obtain an upper bound for the @xmath -th harmonic number:

  -- -------- --
     @xmath   
  -- -------- --

Importantly, term-by-term expansion on the two brackets will recover a
series that includes the reciprocals of numbers that are not square-free
and do not exceed @xmath . The inequality is somewhat weak, in the sense
that we will recover many numbers that are greater than @xmath . We can
bound the sum of the reciprocals of the nontrivial squares as follows:

  -- -- --
        
  -- -- --

Therefore, we have upon rearranging that

  -- -------- --
     @xmath   
  -- -------- --

for all integers @xmath . This contradicts the divergence of the
harmonic series for some sufficiently large integer @xmath and thus
completes the proof. ∎

In 1737, Euler reproved Euclid’s theorem through the remarkable identity

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

where @xmath is a real number satisfying @xmath and the product is over
all prime numbers. To verify this informally, one can subject each
member of the product to the Taylor expansion

  -- -------- --
     @xmath   
  -- -------- --

which holds for @xmath , and then expand the result; equality will
immediately follow from the fundamental theorem of arithmetic. This
argument is not airtight (see Titchmarsh [ titchmarsh1986theory , Ch. 1]
for a rigorous proof), but it will suffice to impart the main idea,
namely that ( 1.1 ) can be thought of as an analytic version of the
fundamental theorem of arithmetic, for we have encapsulated this
property of the natural numbers into an identity which holds for all
@xmath . The infinitude of primes follows from taking the limit as
@xmath ; the left hand side of ( 1.1 ) tends to infinity, and so we
deduce that the product on the right must also be infinite, and thus
composed of infinitely many parts.

In fact, Euler went somewhat further than this. If we let @xmath , then
taking the logarithm of both sides in ( 1.1 ) gives us that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

From an application of the Taylor series

  -- -------- --
     @xmath   
  -- -------- --

which holds for all @xmath , it follows that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

It is straightforward to prove that the rightmost sum is bounded above
by some large positive number @xmath . It follows that

  -- -------- --
     @xmath   
  -- -------- --

and so as @xmath , the right hand side tends to infinity, impressing the
sum over the primes towards infinity as well. This is a stronger result
than the infinitude of primes.

It is convenient at this point to introduce a modern notation. We will
let @xmath denote the number of primes that do not exceed @xmath , and
we will henceforth refer to this as the prime counting function . This
allows us to recognise Euclid’s theorem in the form

  -- -------- --
     @xmath   
  -- -------- --

It is a central problem in number theory to resolve the function @xmath
to a greater detail. In 1808, Legendre [ legendre ] asserted that the
function @xmath is approximately equal in value to

  -- -------- --
     @xmath   
  -- -------- --

for large values of @xmath and @xmath . Gauss proposed a similiar though
different formula, specifically that @xmath should be approximated by
the so-called offset logarithmic integral

  -- -------- --
     @xmath   
  -- -------- --

Such an observation was communicated from Gauss to Encke in 1849, but
Gauss’ work towards this statement seemed to have commenced as early as
1791, when he was a boy at the age of fourteen. In fact, it is said that
around this early time, the Duke of Brunswick gave Gauss a collection of
mathematics books; these included tabulations of logarithmic values.
Gauss worked to improve these tables, in fact, a computation of @xmath
can be found in his papers from the era. It has been said (see, for
example, Tschinkel [ tschinkel ] ) that his fervent work on these tables
probably led him to the statement that @xmath and @xmath are
approximately equal in value.

One can expand Legendre’s estimate via a Taylor series to get

  -- -------- --
     @xmath   
  -- -------- --

whereas integration by parts gives

  -- -------- --
     @xmath   
  -- -------- --

for the estimate of Gauss. Therefore, both estimates are of the form

  -- -------- --
     @xmath   
  -- -------- --

and so it at least seemed plausible that the function @xmath was a good
first approximation for the function @xmath . Chebyshev [ chebyshev ]
made the first serious move towards a proof of this. In 1848, he proved
the result that if the limit

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

exists then it must be equal to one. Famously, he was also able to prove
the inequality

  -- -------- --
     @xmath   
  -- -------- --

for certain positive numbers @xmath and @xmath and all sufficiently
large values of @xmath . Specifically, he showed that one could take
@xmath and @xmath . Historically, there have been some attempts to
refine these values using variations of Chebyshev’s method, though it
seems clear that this line of attack falls short of showing that the
limit in ( 1.2 ) tends to one.

It should be said that Chebyshev’s work allowed him to prove a theorem
that is well-known as Bertrand’s postulate. This states that for any
@xmath there exists a prime number @xmath that satisfies @xmath . We
will return to this result soon, for it is a good starting point with
respect to some of the work of this thesis.

In 1859, Riemann published his only paper [ riemann ] in number theory,
enunciating a new way to investigate the prime numbers. He defined, for
all complex numbers @xmath in the half-plane @xmath , the complex-valued
function

  -- -------- --
     @xmath   
  -- -------- --

which we hereby refer to as the Riemann zeta-function. It should be
noted that we employed this function earlier to prove that the series of
reciprocal primes diverges, though we considered only the case where
@xmath was real.

Now treating @xmath as a complex variable, Riemann indicated how @xmath
could be extended to a regular (single-valued and analytic) function
everywhere except for a simple pole at @xmath . Moreover, he stated that
the zeroes of @xmath are inextricably connected to the distribution of
the prime numbers, and sketched a proof that

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

amongst other things. These blueprints were finally completed close to
thirty years later by Hadamard [ hadamard ] and by de la Vallée Poussin
[ poussin ] , who finished their work independently at around the same
time. It is to these two mathematicians, building on the foundation laid
by Riemann and the others before him, that we attribute the proof of the
Prime Number Theorem, that is, the confirmation of the limit in ( 1.3 ).

As mentioned earlier, such a result is elicited from the behaviour of
the zeroes of the Riemann zeta-function. Now, it can be shown with some
work (see Titchmarsh [ titchmarsh1986theory , Ch. 2] ) that any zero
@xmath of @xmath will either be a negative even integer or will be
constrained to lie in the so-called critical-strip

  -- -------- --
     @xmath   
  -- -------- --

It is precisely these nontrivial zeroes which lie in the critical strip
that form our focus, for they weave into the zeta-function all
information regarding the distribution of the primes.

Hadamard’s proof of the Prime Number Theorem follows from showing that
@xmath , that is, by whittling down the width of the critical strip
albeit infinitesimally. However, de la Vallée Poussin was more precise
with his workings. Specifically, he proved that there exists @xmath and
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . It can, in fact, be deduced from this that

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and all sufficiently large @xmath . This proves that the
logarithmic integral proposed by Gauss is the correct model to hold
against the prime counting function.

At this point, we have given a brief overview of the development of the
Prime Number Theorem, and we have hinted at some of the interplay
between zeroes and primes. In the last century, number theory has
burgeoned incredibly, and it would be an insurmountable task to provide
a decent survey in this section. This is, however, done in an
impressively thorough fashion by Sándor, Mitrinović and Crstici [ sandor
] . We will, instead, discuss the branches of the theory that have been
the subject of the author’s investigations. Before we do this, however,
it is necessary to provide some material on explicit results.

### 1.2 Motivation for explicit results

It is clear that many results in number theory, such as de la Vallée
Poussin’s proof of the Prime Number Theorem, are stated with the use of
implied constants, where one encounters qualifiers such as “sufficiently
large”. There are, in fact, three types of results that we see in number
theory:

1.  An ineffective result shows that a statement is true for an
    unspecified constant @xmath , but one cannot actually determine the
    constant @xmath by reworking the proof and keeping track of the
    error terms.

2.  An effective but not explicit result shows that a statement is true
    for an unspecified constant @xmath with the bonus that one could
    actually determine a suitable value for @xmath by reworking the
    proof explicitly.

3.  An explicit result gives a numerical value for @xmath .

This thesis places regard on establishing explicit results in the theory
of prime numbers. It is said that in this area, one often works through
the original proof of some result whilst keeping careful bounds on any
error terms that arise. However, in some cases the original proof is
ineffective and so one must come up with a new but effective proof
first. In fact, one of the results enunciated in this thesis requires
such a remodelling; this will be discussed in more detail in Chapter 4.

It should be clear that the type of some result will depend directly on
the methods used to prove it. For example, consider Bertrand’s
postulate, the statement that there is a prime in the interval @xmath
for all @xmath . This result is explicit and, as such, would require
explicit results to prove it, namely some reasonable estimate on the
prime counting function.

To elaborate, we can consider the Prime Number Theorem in the
ineffective form as proven by Hadamard, which states that the quotient
of @xmath over @xmath tends to one as @xmath tends to infinity. It
follows a fortiori that for every @xmath there exists some @xmath such
that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Thus, choosing @xmath and letting @xmath we have that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

provided also that @xmath , where @xmath is sufficiently large so that
the second inequality holds. Therefore, we have that there is a prime in
the interval @xmath provided that @xmath . This form of Bertrand’s
postulate is ineffective, and this is simply because the ineffectiveness
of Hadamard’s result is pushed through into our proof. And whilst it is
a straightforward problem to determine a suitable value for @xmath ,
Hadamard’s proof of the Prime Number Theorem does not deliver the
details on how @xmath behaves as a function of @xmath .

It is at this point that we provide some comfort to the reader; the
Prime Number Theorem has been realised explicitly since the time of
Hadamard and de la Vallée Poussin. A more detailed discussion of this
will be found in Chapter 2. For now, it remains to motivate the reason
for developing explicit results.

In a pure sense, some statements in number theory may seem more complete
when stated explicitly. If one can prove, for example, that every
sufficiently large integer is endowed with some property of interest,
then surely the next step in strengthening such a result is to remove
the qualification of being sufficiently large. An immediate barrier to
this could be that the proof itself is ineffective, or that the proof is
too difficult to be worked through carefully. One must always weigh the
labour of furnishing an explicit result against the value of possessing
it; personal taste is clearly a deciding factor here.

However, we now find ourselves in an age where such results are not only
easier to obtain but also more valuable than before. The area of
explicit methods in number theory is gathering momentum in the wake of
high-speed computation and an enhanced interest in the prime numbers for
application. To flesh out this claim with an example, it is known that
certain properties of the prime numbers allow us to construct very
efficient computer networks (see the survey on expander graphs [
expandersurvey ] by Hoory, Linial and Wigderson). However, if one only
knows that these properties hold for “sufficiently large” prime numbers,
then one can only guarantee high connectivity in networks with a
“sufficiently large” number of computers. This is a barrier to having
any measure of practical assurance. An explicit result, on the other
hand, will allow us to state exactly which primes hold the property of
interest, and this in turn allows us to build good networks in practice.

Other areas of mathematics will, at certain times, also draw on the
properties of the integers, and thus the development of explicit results
in number theory finds utility in research of a purely mathematical
nature. For instance, a group theorist seeking explicit bounds on the
maximum order of an element in the symmetric group on @xmath letters can
achieve this via means of explicit estimates on the prime numbers. One
can see the work of Massias, Nicolas and Robin [ massiasNicolasRobin ]
for the details of this profound relationship.

### 1.3 Summary of thesis

This thesis describes a collection of new explicit results in the theory
of prime numbers. It follows from the work of Hadamard and de la Vallée
Poussin that if one wants to furnish such results on the primes, one
first needs to establish explicit bounds on the zeroes of the Riemann
zeta-function. The general framework for this approach is described in
detail in Chapter 2, but we will outline the results here.

To connect the prime numbers to the zeroes of @xmath , we require the
use of a so-called explicit formula. It is important to note that here
we do not mean explicit in the sense of determining explicit constants;
the formula explicitly connects some sum over the prime numbers to
another sum over the zeroes of @xmath . There are various types of
explicit formulas that one can use, however we will be considering
principally the Riemann–von Mangoldt explicit formula, which states that

  -- -------- --
     @xmath   
  -- -------- --

where the leftmost sum is over the prime powers that do not exceed some
positive non-integer @xmath , and the other sum is over the nontrivial
zeroes @xmath of @xmath . Clearly, knowledge regarding the distribution
of zeroes can be injected into the rightmost sum in order to gain
clarity regarding the prime numbers. More useful, however, is the
truncated Riemann–von Mangoldt explicit formula

  -- -------- --
     @xmath   
  -- -------- --

which allows its employer to insert information on the nontrivial zeroes
with height at most @xmath . In Chapter 2, we prove an actually explicit
version of this formula; this allows one to keep numerical bounds on the
error term. We do this by working through the classical version of the
proof whilst working carefully to control the error terms.

In Chapter 3, we show how our explicit formula can be used to furnish a
result on primes in short intervals. Notably, at the International
Congress of Mathematicians in 1912, Landau listed four basic problems
about the prime numbers. The third of these was a conjecture of
Legendre’s that there exists a prime between any two consecutive
squares. This is currently unresolved, however it was shown by Ingham [
ingham ] in 1937 that there exists a prime between any two sufficiently
large cubes. We make Ingham’s result explicit; specifically, we show
that there will be a prime in the interval @xmath provided that @xmath .

This result is achieved by constructing an explicit formula that detects
primes in intervals, and then substituting into it explicit information
regarding the real parts of the nontrivial zeroes of @xmath . It should
be stressed at this point, that most successes in bounding the real
parts of these zeroes are weak in comparison to the famed hypothesis of
Riemann, which asserts that every zero in the critical strip has a real
part of @xmath . In fact, working under the Riemann hypothesis, it can
be shown that there will be a prime between any two consecutive positive
cubes (see the work of Caldwell and Cheng [ caldwellcheng ] ). Our
result, therefore, is a step towards proving the theorem of Caldwell and
Cheng without the conditional sledgehammer of Riemann’s hypothesis.

On a related note, it is almost conventional for number theorists to
examine a result unconditionally first, and then to see what can be done
further on the assumption of the Riemann hypothesis. The author has
found this convention to be a tempting one, and so some of the problems
considered in this thesis are doubly assaulted. The problem of primes in
short intervals is no exception to this, and so we take such an approach
in the second part of Chapter 3.

It is already a celebrated result of Cramér [ cramer ] from 1921 that,
assuming the Riemann hypothesis, there exist some @xmath and @xmath such
that the interval @xmath contains a prime number for all @xmath . Using
explicit formulas, we prove that there will be a prime in the interval
@xmath for all @xmath . Moreover, we show that the constant @xmath can
be reduced to @xmath , where @xmath can be taken to be arbitrarily close
to zero. This result has been published by the author in the
International Journal of Number Theory [ dudekcramer ] . Moreover, the
author has refined this result in a paper coauthored with L. Grenié and
G. Molteni [ dudekmoltenigrenie ] . This paper is due to appear in the
same journal.

In Chapter 4, the author shifts his attention towards additive problems
involving primes. Such problems are borne from the zeal of number
theorists in supposing that, as every number may be composed
multiplicatively by the primes, it might also be true that one can build
numbers from primes using addition. The root of this can be traced to a
letter of Goldbach’s dating back to 1742, in which he writes to Euler
and conjectures that every even number greater than 2 can be written as
the sum of two primes, and every odd number greater than 5 can be
written as the sum of three primes. The latter conjecture was proven by
Helfgott [ helfgott2013 ] in 2013, and thus it is only the so-called
binary Goldbach conjecture which remains. This problem also made it onto
the famous problem list of Landau’s which we referred to earlier.

The best known result towards the binary Goldbach conjecture is a
theorem of Chen [ chen ] which states that every sufficiently large even
integer can be written as the sum of a prime and a product of at most
two primes. It was the author’s original intention to make Chen’s
theorem explicit, perhaps by proving that all even numbers greater than
two could be written this way. A result towards this was recently
established by Yamada [ yamada ] , where he proves that every even
integer greater than @xmath can be written this way. An earlier but
weaker result of Estermann [ estermann ] seemed to possess the
appropriate return-on-effort. As such, the author proves in the first
part of Chapter 4 that every integer greater than two is the sum of a
prime and a square-free number. This result has been accepted for
publication and will appear in the Ramanujan Journal [ dudekestermann ]
.

In the second part of Chapter 4, we consider an extension of Estermann’s
result which was first studied by Erdős [ erdos ] . Specifically, Erdős
shows that any sufficiently large positive integer @xmath can be written
as the sum of the square of a prime and a square-free number. In the
same nature as our continuation of Estermann’s work, we prove that every
integer @xmath such that @xmath can be written as the sum of the square
of a prime and a square-free number. This was collaborative work with
Dave Platt at the University of Bristol and has been accepted for
publication by the LMS Journal of Computation and Mathematics [
dudekplatt2 ] .

Chapter 5 details another collaboration with Dave Platt, where we study
a curious inequality first penned by the prodigious mathematician
Ramanujan. In one of his famous notebooks (see Berndt [ berndt ] for the
details), Ramanujan writes that

  -- -------- --
     @xmath   
  -- -------- --

holds for all sufficiently large values of @xmath . We take it upon
ourselves to make this explicit, proving that the inequality holds
unconditionally for all @xmath . We then place the inequality under the
conditional scrutiny of the Riemann hypothesis, from which it follows
that @xmath is the largest integer counterexample to Ramanujan’s
inequality. This solves the inequality completely under the assumption
of the Riemann hypothesis. This work has been published in Experimental
Mathematics [ dudekplattem ] .

Finally, we use Chapter 6 to outline some projects which are similar to
those in this thesis and could be undertaken by eager researchers. These
are projects which once found themselves on the author’s interminable
to-do list, but would probably best serve the field by tempting in young
researchers or being the talking point for new collaborations.

## Chapter 2 The Riemann–von Mangoldt Explicit Formula

  “Take some more tea,” the March Hare said to Alice, very earnestly.
  “I’ve had nothing yet,” Alice replied in an offended tone, “so I can’t
  take more.”
  “You mean you can’t take less,” said the Hatter: “it’s very easy to
  take more than nothing.”

### 2.1 The Riemann zeta-function

This chapter studies the relationship between the prime numbers and the
zeroes of the Riemann zeta-function. In this first section, the focus is
emphatically on the latter, and we deliver a terse course on the
properties of the zeta-function, referring readers to the excellent text
of Titchmarsh [ titchmarsh1986theory ] for more details.

Throughout this chapter, we will often refer to the complex variable
@xmath . As mentioned in the introduction, the Riemann zeta-function is
defined for complex numbers satisfying @xmath by the infinite series

  -- -------- --
     @xmath   
  -- -------- --

One can continue this analytically to the entire complex plane with the
exception of a simple pole at the point @xmath . Moreover, it can be
shown that the so-called functional equation

  -- -------- --
     @xmath   
  -- -------- --

holds, where @xmath denotes the gamma function. Noting that both @xmath
and @xmath are without poles in the half-plane @xmath , it follows that
the simple poles of @xmath at the negative even integers give rise to
zeroes of @xmath at the same points.

Moreover, it is known that all other zeroes @xmath of @xmath are
constrained to lie in the aforementioned critical strip, that is, they
satisfy the bound @xmath . It is also known (from the functional
equation) that these zeroes are distributed symmetrically about the line
@xmath . The holy grail of analytic number theory would be the Riemann
hypothesis, which asserts that @xmath for all zeroes in the strip. In
lieu of such a grand theorem, there is an extensive line of work towards
establishing measures on the distribution of the nontrivial zeroes.

One way to quantify this distribution is through the use of a zero-free
region in the critical strip. For example, it was first shown by de la
Vallée Poussin [ poussin ] , in his proof of the Prime Number Theorem,
that there exists @xmath such that every zero in the critical strip
satisfies

  -- -------- --
     @xmath   
  -- -------- --

The best known zero-free region was given by Korobov [ korobov ] and
Vinogradov [ vinogradovzero ] . Specifically, they show that there
exists @xmath such that any zero in the strip satisfies

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

We will need to make use of several explicit versions of these zero-free
regions at certain places within this thesis.

Another way to probe the distribution of zeroes is through the use of a
zero-density estimate . Specifically, we let @xmath denote the number of
zeroes in the critical strip such that @xmath . Then we denote by @xmath
the number of these zeroes with @xmath . A zero-density estimate is then
some upper bound on the function @xmath . A simple example can be found
in Theorem 9.15(A) of Titchmarsh [ titchmarsh1986theory ] , where it is
shown that for any fixed @xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

In comparison to the well known asymptotic formula

  -- -------- --
     @xmath   
  -- -------- --

this shows us that all but an infinitesimal proportion of zeroes of
@xmath satisfy @xmath for any @xmath .

In Chapter 3, we will use explicit versions of both zero-free regions
and zero-density estimates to attack the problem of primes in short
intervals. First, we need to prove the formula that permits such
analytic results to push through into the prime numbers.

### 2.2 Proof of the explicit formula

In this section, we derive the Riemann–von Mangoldt explicit formula
with an explicit bound on the error term. Our considerations begin with
the von Mangoldt function:

  -- -------- --
     @xmath   
  -- -------- --

As mentioned in Chapter 1, we introduce the sum @xmath to study the
distribution of the prime numbers; this is known as the Chebyshev @xmath
-function. The Riemann–von Mangoldt explicit formula can be stated thus

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where @xmath is any positive non-integer and the sum is over all
nontrivial zeroes @xmath of @xmath (see Davenport [ davenport , Ch. 17]
for details). One can see that feeding information regarding the zeroes
of @xmath into the above formula yields estimates for the prime powers,
allowing us then to obtain estimates regarding the primes. However, the
explicit formula in ( 2.2 ) relies on estimates over all of the
nontrivial zeroes of @xmath and so is impractical for certain
applications.

We often find more use in a truncated version of the explicit formula in
which one inputs information regarding the zeroes @xmath up to some
height @xmath , that is, with @xmath . It is our first intention to
provide such a formula but with an explicit error term; this will allow
us to make progress on the problem of primes between consecutive cubes.
To state such a result, we will first define the notation @xmath to mean
@xmath for some given range of @xmath . Our result is as follows.

###### Theorem 2.1.

Let @xmath be half an odd integer and suppose that @xmath . Then

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

In the remainder of this chapter, unless otherwise mentioned, we shall
assume that @xmath and @xmath are as specified in Theorem 2.1 . Notably,
the requirement that @xmath is half an odd integer minimises the error
term in Theorem 2.1 , as will become evident in the proof of Lemma . The
reason for the seemingly arbitrary bound of @xmath is as follows: we
will want to prove that there is a prime in the interval @xmath , as
this interval is related to the problem of primes between cubes. It
turns out that we can do this if @xmath using the short-interval results
provided by Ramaré and Saouter [ ramaresaouter ] .

In some of our theorems we drop these requirements. This is because we
thought the result would be useful to other mathematicians if stated
with fewer constraints, or that the error terms were reasonably small
without needing @xmath to be quite so large. For example, Kerr [ kerr ]
has used Lemma 2.8 to establish new lower bounds for the Riemann
zeta-function on short intervals of the line @xmath . At other times,
there is a clear way to improve a result that has not been pursued. In
many of these cases, the work involved more than offsets the
almost-negligible rewards, and so we eschew the messy in favour of the
neat. We will, however, provide details in such cases for the interested
reader.

It should be noted that before working on this problem, the author
attempted to locate an effective explicit formula in the literature and
found that which was given by Skewes [ skewes ] , though the error term
here is of better order. Liu and Wang [ liuwang ] give a version of
Theorem 2.1 with an improved constant, but holding only for @xmath as a
certain function of @xmath , which is useful for explicit estimates on
the ternary Goldbach conjecture but not for our application.

The method of proof for the explicit formula is well-known: we employ
Perron’s formula to express @xmath as a contour integral over a vertical
line. We then truncate this integral to one that is over a finite line
segment. This is where we will pick up the bulk of the error term, and
so more precision is needed here than anywhere else in our proof. Our
line of integration is then shifted so as to acknowledge the residues
and introduce the sum over the zeroes which accompanies @xmath in
Theorem 2.1 . The crux of our working involves keeping track of the
errors.

We proceed as laid out in Davenport’s [ davenport ] well known
expository text, though by working carefully we will obtain an explicit
result. We should also note that this derivation can be applied to other
arithmetic functions, though there are some differences to be noted. In
our case, we have the identity

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , which ties the von Mangoldt function to the Riemann
zeta-function. It is precisely this relationship that permits techniques
from complex analysis to probe the behaviour of @xmath . In this case,
properties and bounds pertaining to @xmath have ramifications for the
prime numbers. Note that in a more general context, one has an
arithmetic function @xmath and a Dirichlet series

  -- -------- --
     @xmath   
  -- -------- --

convergent for @xmath . We will now show where the complex analysis
comes in. For @xmath , we define the contour integral

  -- -------- --
     @xmath   
  -- -------- --

A good exercise (see Murty’s [ murty ] problem book) for budding
students of analytic number theory (or complex analysis) is to show that

  -- -------- --
     @xmath   
  -- -------- --

The importance of this integral becomes apparent when one wishes to
study the sum of an arithmetic function up to some value @xmath ,
particularly when that function is generated by a Dirichlet series. In
our case, we consider the following for a positive non-integer @xmath
and @xmath :

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (2.4)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Notice that keeping @xmath gives absolute convergence to the series in
the above equation, and thus justifies the interchange of integration
and summation. From before, we know that the Dirichlet series in ( 2.4 )
is equal to @xmath , and so we have that

  -- -------- --
     @xmath   
  -- -------- --

In its more general form pertaining to an unspecified arithmetic
function this is known as Perron’s formula. We may thus estimate the sum
of the von Mangoldt function through some knowledge of certain analytic
properties of @xmath . Our first step is to truncate the path of the
integral to a finite segment, namely @xmath . We define for @xmath the
truncated integral

  -- -------- --
     @xmath   
  -- -------- --

The next lemma is a variant of the first lemma in Davenport [ davenport
, Ch. 17] , and will bound the induced error term upon estimating @xmath
by @xmath . The proof is omitted here, though one can see Theorem 15 of
Estermann [ estermannbook ] for a complete proof.

###### Lemma 2.2.

For @xmath with @xmath , @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

We now employ this bound to estimate @xmath in the following way.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

We proceed to bound the sum in the above formula, by splitting it up and
estimating it in parts.

###### Lemma 2.3.

Let @xmath be half an odd integer and set @xmath . Then

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

###### Proof.

Some care needs to be taken here. When @xmath and @xmath are quite
close, the @xmath term in the sum will become large. Thus, we introduce
the parameter @xmath and break up the infinite sum:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

On the right side of the above formula, denote the @xmath th sum by
@xmath . The reader should be convinced by this division; @xmath deals
with the most inflated terms, namely when @xmath is either side of
@xmath . Then @xmath and @xmath measure the remainder of the region
which is close to @xmath . We also note that @xmath and @xmath
contribute little and can be estimated almost trivially.

Considering the range of @xmath in @xmath and @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Inserting this into these sums, pulling out terms which are independent
of @xmath , and extending the range of summation to @xmath we arrive at

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (2.6)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

The main theorem from Delange [ delange ] states that

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

for all @xmath and @xmath . We apply this to ( 2.6 ) to get

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

We now turn our attention to @xmath , which is the sum of only two
things. It follows, using the fact that @xmath and the trivial bound
@xmath , that

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

We can estimate trivially with

  -- -------- --
     @xmath   
  -- -------- --

and the bound

  -- -------- --
     @xmath   
  -- -------- --

for @xmath to get that

  -- -------- --
     @xmath   
  -- -------- --

This will actually be of little consequence to the final sum (as we will
soon see), and so we feel no remorse in collecting here the weaker but
tidier bound

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

For @xmath , we estimate @xmath and @xmath to get

  -- -------- --
     @xmath   
  -- -------- --

Bounding @xmath in this way is quite slack. It was pointed out to the
author in private correspondence with Olivier Ramaré that one could
apply the Brun–Titchmarsh theorem and save a factor of @xmath . As we
will see in Chapter 3, this would not make much of a difference in the
problem of primes between consecutive cubes, and so we do not pursue
this avenue.

Now, if we let @xmath , then the problem becomes that of summing over
@xmath . We have

  -- -- --
        
  -- -- --

and thus

  -- -------- --
     @xmath   
  -- -------- --

One can estimate this by the known bound

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is Euler’s constant to get

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

The sum @xmath is similar to this; we use @xmath and @xmath to get the
bound

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

As @xmath , we have upon setting @xmath that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Using the estimate @xmath for @xmath we have that

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.11)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Finally, we combine ( 2.8 ), ( 2.9 ), ( 2.10 ) and ( 2.11 ) to get an
inequality of the form

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

The result follows from choosing @xmath and letting @xmath . ∎

The immediate result of Lemma is that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

for @xmath , @xmath and @xmath . We now look to shifting the line of
integration so that we might involve the residues of the integrand. Let
@xmath be a positive odd number and define the line segments

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and their union @xmath along with the corresponding integrals

  -- -------- --
     @xmath   
  -- -------- --

One can note that @xmath is the conjugate of @xmath , and we will later
use this fact to bound both at once. We also denote by @xmath the
integral around the rectangle @xmath . Note that we need to account for
the fact that while @xmath is stipulated not to be the ordinate of a
zero of @xmath , it might be undesirably close to such. We show in Lemma
that there is always some good choice of @xmath nearby, and so some work
will be required later to shift our horizontal paths. Also note that any
work we do in bounding @xmath will, by the functional equation for
@xmath , also hold for @xmath and so it follows that

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

One can use Cauchy’s theorem (see Davenport [ davenport ] for full
details) to show that

  -- -------- --
     @xmath   
  -- -------- --

where as usual @xmath denotes a nontrivial zero of @xmath . Noting that
the rightmost summation is a partial sum of the series for @xmath , we
can write that

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

It remains to bound @xmath and @xmath by deriving and making use of
explicit estimates for @xmath in appropriate regions.

We first establish a bound that holds on the lengths of the rectangle
@xmath that intersect with the half-plane @xmath . The stipulation that
@xmath is a positive odd number is so that we might avoid the poles of
@xmath which occur at the odd integers.

###### Lemma 2.4.

We have that

  -- -------- --
     @xmath   
  -- -------- --

on the intersection of @xmath with @xmath .

###### Proof.

We find it easier to bound @xmath and then make the corresponding change
of variable at the end. Consider the logarithmic derivative of the
functional equation for @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath (so that @xmath ) and notice that @xmath so long as @xmath is
distanced by at least @xmath from odd integers on the real axis. We can
then use

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

to bound @xmath trivially. The result then follows by observing that

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

making the change of variable and putting it all together. ∎

We now look to the harder task of establishing a bound over the region
that includes the critical strip, as is essential for the estimation of
@xmath .

###### Lemma 2.5.

Let @xmath where @xmath and @xmath . Then

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

###### Proof.

We start with the equation (see 12.8 of Davenport [ davenport ] )

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

where @xmath . Successively, we set @xmath and @xmath and then find the
difference between the two expressions. The terms involving the @xmath
-function are dealt with using ( 2.15 ), whereas the rest are estimated
either trivially or with ( 2.16 ) to arrive at the result. ∎

We aim to estimate the sum in Lemma 2.5 by breaking it into two smaller
sums @xmath and @xmath , where @xmath ranges over the zeroes @xmath with
@xmath and @xmath is over the remaining zeroes. Note that some
optimisation could be done (see Pintz [ pintzdisproof ] ) on the size of
our disk but – as we will see in the next chapter – the marginal profits
are not worth the subsequent mopping of brow.

###### Lemma 2.6.

Let @xmath , where @xmath and @xmath . Then

  -- -- --
        
  -- -- --

###### Proof.

We can estimate the summand as follows (see Davenport [ davenport , Ch.
15] ):

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

We then have that

  -- -------- --
     @xmath   
  -- -------- --

By letting @xmath , taking real parts in ( 2.18 ) and estimating as in
the proof of Lemma 2.5 we have

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . We then use the two simple facts

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

to get

  -- -------- --
     @xmath   
  -- -------- --

Putting it all together we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

∎

We now wish to estimate the remaining sum

  -- -------- --
     @xmath   
  -- -------- --

To do this, first recall that @xmath denotes the number of zeroes of
@xmath in the critical strip up to height @xmath . Noting that @xmath ,
the contribution of the second term to the sum can be estimated
trivially by

  -- -------- --
     @xmath   
  -- -------- --

that is, by the number of terms in the sum. Now we prove the following
result.

###### Lemma 2.7.

We have that

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

for all @xmath .

###### Proof.

We can use Corollary 1 of Trudgian [ trudgianargument ] with @xmath to
verify that the bound holds as long as @xmath . To prove it for the
remaining range, we can use Odlyzko’s tables [ odlyzko ] of the zeroes
of the Riemann zeta-function. A short algorithm written in Python reads
in zeroes from the table and checks that the bound ( 2.20 ) holds in the
remaining range. Specifically, the algorithm runs a check on the values
of @xmath from 50 to 250000 in increments of @xmath . To verify that the
lemma is true for all values of @xmath , we check the sharper inequality

  -- -------- --
     @xmath   
  -- -------- --

at these discrete values and from this it follows that the result is
true for all @xmath . ∎

At this point we have established the following result.

###### Lemma 2.8.

Let @xmath , where @xmath and @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we are concerned with bounding the magnitude of the sum over
zeroes in the above lemma. Of course, the problem here is that @xmath
might be close to a zero @xmath , and this will give us significant
trouble.

At this point, we search instead for a better value of @xmath nearby,
say @xmath , which will give a workable bound. We will use this in the
next section to shift our horizontal line of integration to a better
height.

###### Lemma 2.9.

Let @xmath . There exists @xmath that does not depend on @xmath and such
that

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

###### Proof.

By @xmath , there are at most @xmath zeroes in the sum. The imaginary
ordinates of these zeroes partition the region of the strip into no more
than ( @xmath ) zero-free sections. Trivially, there will always be such
a section of height

  -- -------- --
     @xmath   
  -- -------- --

and choosing the midpoint, say @xmath , of this section will guarantee a
distance of

  -- -------- --
     @xmath   
  -- -------- --

from any zero. As such, we have, letting @xmath , that

  -- -------- --
     @xmath   
  -- -------- --

∎

Finally, we can put the previous three lemmas together to get the
following.

###### Lemma 2.10.

Let @xmath . Then there exists @xmath such that for every @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

That is, if our contour is somewhat close to a zero, we can shift it
slightly to a line where we have good bounds.

We now bound the error term @xmath in @xmath , by using our bounds and
estimating each integral trivially. Using Lemma 2.4 , we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
              @xmath   @xmath   
                                
              @xmath   @xmath   
  -- -------- -------- -------- --

We save this, for soon we will combine our estimates and bound them in
unison upon an appropriate choice for @xmath . Consider now the problem
of estimating @xmath , and the issue that @xmath might be close to the
ordinate of a zero. From Lemma 2.9 , there exists some @xmath that we
should integrate over instead. We thus aim to shift the line of
integration from @xmath to

  -- -------- --
     @xmath   
  -- -------- --

It follows from Cauchy’s theorem that

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

From @xmath , we can estimate the sum by

  -- -------- --
     @xmath   
  -- -------- --

We can bound @xmath in the same way as @xmath to obtain

  -- -------- --
     @xmath   
  -- -------- --

Bounding @xmath is done using Lemma 2.4 :

  -- -------- --
     @xmath   
  -- -------- --

We also use Lemma 2.9 to get

  -- -------- --
     @xmath   
  -- -------- --

To get an upper bound for @xmath , we note that @xmath and then ( 2.7 )
gives us that

  -- -------- --
     @xmath   
  -- -------- --

Then, estimating trivially gives us that

  -- -------- --
     @xmath   
  -- -------- --

Throwing all of our estimates for the terms in @xmath together,
implanting the information that @xmath , @xmath and letting @xmath be
equal to the odd integer closest to @xmath we obtain Theorem 2.1 . In
the next chapter, we will apply this result to the problem of primes
between cubes.

## Chapter 3 Primes in Short Intervals

  “That’s the reason they’re called lessons,” the Gryphon remarked:
  “because they lessen from day to day.”

### 3.1 Primes between consecutive cubes

Legendre’s conjecture is the assertion that there is at least one prime
between any two consecutive squares. Confirmation of this seems to be
out of reach, for applying modern techniques on the assumption of even
the Riemann hypothesis does not suffice in forming a proof (see
Davenport [ davenport ] for a discussion). It is thus the aim of this
first section to study the weaker problem of primes between cubes, where
some progress has already been made.

Consider first the more general problem of showing the existence of at
least one prime in the interval @xmath for some @xmath and for all
sufficiently large @xmath . These are short intervals; generally, any
interval of the form @xmath is said to be short if @xmath as @xmath .

In 1930, Hoheisel [ hoheisel ] was able to solve the problem for @xmath
, that is, that there will be a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

for all sufficiently large @xmath . He did this by using the Riemann–von
Mangoldt explicit formula in conjunction with an appropriate zero-free
region and zero-density estimate. Using Hoheisel’s ideas, Ingham [
ingham ] was able to prove a more general theorem, specifically that if
one has a bound of the form

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , then one can take

  -- -------- --
     @xmath   
  -- -------- --

Notably, the bound for @xmath can be used to construct a zero-density
estimate, and this in turn furnishes a value for @xmath through a
subsequent application of the explicit formula. Hardy and Littlewood
were able to give a value of @xmath , which corresponds to @xmath . From
this, one sets @xmath and it follows that for all sufficiently large
@xmath there exists a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

That is, with finitely many exceptions, there is a prime between any two
consecutive cubes. The reader should, however, note that consideration
of the interval

  -- -------- --
     @xmath   
  -- -------- --

is sufficient for primes between cubes and as such this is the interval
we use throughout this section. Expanding the expression @xmath shows
that we could use the slightly larger interval

  -- -------- --
     @xmath   
  -- -------- --

however, the difference is negligible for the large values of @xmath in
which we deal.

The purpose of this section is to make explicit the result on primes
between consecutive cubes, in that we determine a numerical lower bound
beyond which this result holds. By working through the paper of Ingham [
ingham ] , we can do this thanks to Ford’s [ ford ] explicit zero-free
region, Ramaré’s [ ramare ] explicit zero-density theorem and our
actually explicit formula (see Theorem 2.1 ). We shall bring these
together to prove our main theorem.

###### Theorem 3.1.

There is a prime between @xmath and @xmath for all @xmath .

We should note that a result has been given by Cheng [ cheng ] , in
which he purports to prove Theorem 3.1 for the range @xmath . We should
note, however, that he establishes the result for @xmath and then
incorrectly infers that @xmath . There are some other errors also,
notably in the proof of Theorem 3 in his paper [ cheng ] , the first
inequality sign is backwards and he has used a sum over prime powers
instead of the appropriate sum over primes.

Before we launch into our proof of Theorem 3.1 , we will prove a result
from the other direction. The following lemma explains our earlier
optimism in developing Theorem 2.1 for the range @xmath .

###### Lemma 3.2.

There is a prime in the interval @xmath for all @xmath .

###### Proof.

Theorem 2 in Ramaré and Saouter’s paper [ ramaresaouter ] states that
there is a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and where @xmath is a function of @xmath as given in
Table 1 of their paper. It is a straightforward task to use this table
to verify that there is a prime in @xmath for all @xmath . One simply
works through the table whilst checking that the Ramaré–Saouter interval
is contained in the short interval. ∎

Finally, we should acknowledge the striking result of Baker, Harman and
Pintz [ bakerharmanpintz ] , that the interval @xmath contains a prime
for all sufficiently large @xmath . This is tantalisingly close to
@xmath , which would furnish a proof of Legendre’s conjecture with at
most finitely many exceptions. The authors also note that their result
is effective, though furnishing an explicit result would surely make for
quite a large project.

To begin the proof of Theorem 3.1 , we define the Chebyshev @xmath
-function as

  -- -------- --
     @xmath   
  -- -------- --

This is similar to Chebyshev’s @xmath -function, though we have removed
the contribution owing to the powers of primes. Consider that

  -- -------- --
     @xmath   
  -- -------- --

is positive if and only if there is at least one prime in the interval
@xmath . Many questions involving the primes can be phrased in terms of
@xmath . For example, the twin prime conjecture – there are infinitely
many primes @xmath such that @xmath is also prime – is equivalent to
@xmath taking on a positive value infinitely often where @xmath is a
prime.

Clearly, we set @xmath to tackle the problem of primes between cubes.
Then, if @xmath for all @xmath , there is a prime in the interval @xmath
for all @xmath . If we then set @xmath , we have that there is a prime
in the interval @xmath for all integers @xmath . It is our intention to
determine explicitly a value for @xmath and thus @xmath .

We call on our explicit formula. Substituting @xmath and then @xmath
into Theorem 2.1 and taking the difference, we find that:

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

Whilst the above will tell us information about prime powers, we are
interested in primes. We thus require the following lemma, which is a
combination of Proposition 3.1 of Dusart [ dusart ] and Corollary 2 of
Platt and Trudgian [ platttrudgian ] .

###### Lemma 3.3.

Let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

An application of this lemma to ( 3.1 ) gives us that

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.2)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

It remains to estimate the sum in this inequality, choose @xmath
appropriately and then find @xmath such that @xmath is positive for all
@xmath . We define

  -- -------- --
     @xmath   
  -- -------- --

It follows that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, the identity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

can be reformulated as follows:

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

where @xmath and @xmath are as defined in Chapter 2.

We can estimate the above sum, and thus @xmath , with the assistance of
some explicit bounds. Firstly note, that by Corollary 1 of Trudgian [
trudgianargument ] we have that

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

for all @xmath . Explicit estimates for @xmath are rare, though have
come to light recently through the likes of Kadiri [ kadiri ] and Ramaré
[ ramare ] , who have produced zero-density estimates of rather
different shape to each other. Ramaré’s estimate, which is an explicit
and asymptotically better version of Ingham’s [ ingham ] original
density estimate, is required for the problem of primes between cubes.
We give the result here, which is a corollary of Theorem 1.1 of [ ramare
] .

###### Lemma 3.4.

Let @xmath and @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

There are some comments to make here. Firstly, it should be noted that
when @xmath , the zero-density estimate in Lemma 3.4 is stronger than
that of Kadiri’s for all sufficiently large @xmath . For the problem of
primes between cubes, this is precisely the range of @xmath we are most
concerned with, and @xmath will certainly be taken large enough so that
our choice of zero-density estimate is indeed the best one possible.

Also, consider a more general zero-density estimate of the form

  -- -------- --
     @xmath   
  -- -------- --

Note that we could apply some trivial bounds to Ramaré’s estimate so
that it takes such a form. The most important player here is the
constant @xmath , which (see Theorem 1 of Ingham [ ingham ] ) implies
that one can take @xmath , so long as we have the zero-free region ( 2.1
) or, rather, anything of greater order than the so-called Littlewood
zero-free region (see Theorem 5.17 of Titchmarsh [ titchmarsh1986theory
, Ch. 5] )

  -- -------- --
     @xmath   
  -- -------- --

For the proof of Theorem 3.1 , it would be useful to insert a completely
general zero-density estimate and zero-free region (with unspecified
constants). This would allow us to obtain a function which takes in the
important values and returns a result for the primes-between-cubes
problem. Really, this is how most mathematics is surely done, for it
allows one to see immediate changes without repeating the labours of
other mathematicians. However, keeping everything general disables a lot
of the freedom we require when working explicitly. It is very easy to
say something like

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath but, on the other hand, finding a suitable range so that

  -- -------- --
     @xmath   
  -- -------- --

is not as straightforward.

As such, for the zero-density theorem, we will only leave one constant
unspecified. We will conduct our working with @xmath in place of the
constant @xmath in Lemma 3.4 . The reason for this is simple: if one
were to sharpen up the numbers elsewhere in the estimate, it is always
straightforward enough to express this as a change in the
number-out-the-front.

The following zero-free region, an explicit form of the
Vinogradov–Korobov region as derived by Ford [ ford ] , will also be
required.

###### Lemma 3.5.

Let @xmath . Then there are no zeroes of @xmath in the region given by
@xmath where

  -- -------- --
     @xmath   
  -- -------- --

For the same reasons as with the zero-density estimate, we will leave
the scaling constant general, and so we work with @xmath in place of the
@xmath in the above lemma.

We split the integral in ( 3.3 ) into two parts, one over the interval
@xmath , where @xmath may as well be bounded by @xmath , and another
over @xmath . By applying the relevant estimates in the above two
lemmas, we get

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.5)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

The working out is routine, yet tedious. We give the qualitative details
to the extent that the reader can follow the process. We introduce the
parameter @xmath , which will play a part in the relationship between
@xmath and @xmath . The reasons for the range of values of @xmath will
become clear soon. We let @xmath be the solution to the equation

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

We then have that

  -- -------- --
     @xmath   
  -- -------- --

Upon performing the integration in ( 3.5 ), we directly apply the
equation ( 3.6 ), along with the bound for @xmath and the fact that
@xmath , to get

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.7)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

There is some cancellation in the above inequality. First, we need to
estimate one of the exponential terms involving @xmath . We have that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, upon expansion of ( 3.7 ) and using the above we can notice that

  -- -------- --
     @xmath   
  -- -------- --

This is clear if one looks at the dominant terms, but one can verify
this by dividing through by @xmath , stipulating that @xmath , @xmath ,
and taking @xmath . It follows that

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.8)
  -- -------- -------- -------- -- -------

The remaining exponential term involving @xmath is dealt with as before
to get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, we may write @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

First, we look to bound the error. Noting that @xmath and @xmath , we
use the fact that @xmath will give us the worst possible error to get

  -- -------- --
     @xmath   
  -- -------- --

Thus, one can show that positivity holds if the following two
inequalities are simultaneously satisfied:

1.  @xmath ,

2.  @xmath

This splitting simplifies our working greatly whilst perturbing the
solution negligibly. To be convinced of this, one could consider the
right hand side of each of the above inequalities as being equal to
@xmath , in some better-than-possible scenario. It turns out that the
improvements would hardly be noticeable.

Now, in the first inequality, we take the logarithm of both sides and
set @xmath to get

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

This is easy to solve using Mathematica , given knowledge of @xmath ,
@xmath and @xmath . There are some notes to make here first. We can see
that @xmath , the constant in front of Ramaré’s zero-density estimate
has little contribution, for being in the argument of the logarithm. On
the other hand, @xmath plays a much larger part from where it is
positioned. We can also see the reason for @xmath : this guarantees a
solution to the above inequality.

We deal with the second inequality in the same way, but first we notice
that

  -- -------- --
     @xmath   
  -- -------- --

This is obtained using the main result of Ramaré and Saouter [
ramaresaouter ] , namely that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath as given in their paper. Thus, using the same approach as
before we get

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

We notice here our reason for having @xmath . One can also see the
reason for leaving @xmath free to vary in @xmath . There should be an
optimal value of @xmath , where the solution range of the above two
inequalities are equal and their intersection is minimised.

No rigorous analysis needs to be conducted; we set @xmath , @xmath and
use the Manipulate function of Mathematica to “hunt” for a good value of
@xmath . It turns out that upon choosing @xmath , we have that both
inequalities are satisfied for @xmath , or @xmath , which proves our
main result.

### 3.2 Improvements and higher powers

In this short section, we will discuss how improvements to the
parameters @xmath and @xmath will affect our result for primes between
cubes. We will then consider the problem of primes between higher
integer powers.

Let us consider first improving the zero-density estimate given by
Ramaré. Say, for the sake of discussion, one could obtain a value of
@xmath . Then we would obtain our result instead with @xmath , an
improvement which would probably not be worth the efforts required to
obtain such a value of @xmath . On the other hand, reducing the exponent
of @xmath in Ramaré’s estimate would correspond to incredibly small
values of @xmath , seeing as we take @xmath to be arbitrarily large.
Therefore, it would be useful for a zero-density estimate of smaller
order to be made explicit for use in this problem. One can see
Titchmarsh [ titchmarsh1986theory , Ch. 9] for some discussion of these.

Changes in the constant @xmath are more effective, though seemingly much
more difficult to obtain. A value of @xmath would yield only @xmath ,
and @xmath would give @xmath . The removal of the @xmath would give a
similar result to this.

There are other parameters where one might wish to direct future
efforts. In Ramaré’s zero density estimate, one might consider the power
@xmath of the logarithm to be @xmath . The main difference in our
working would be @xmath in place of @xmath in the reduced form of our
second inequality. The following table summarises the improvements which
would follow, namely the existence of a prime between @xmath and @xmath
for all @xmath .

  -----------------------------------------------------------------------
  @xmath                              @xmath
  ----------------------------------- -----------------------------------
  5                                   33.217

  4                                   31.8

  3                                   29.8

  2                                   22.19

                                      
  -----------------------------------------------------------------------

Turning now to the error term of Theorem 2.1 one could also consider a
smaller constant in place of @xmath . This constant, however, would
appear in the logarithm of the right hand side of ( 3.10 ), and thus
make little difference. On this note, Wolke [ wolke ] has derived the
Riemann–von Mangoldt explicit formula with an error term which is

  -- -------- --
     @xmath   
  -- -------- --

and thus @xmath for the choice of @xmath used for our problem. One may
propose all sorts of “good” explicit constants for the above error term
and try them via the methods of this paper, but there will be no major
improvements.

Thus, really, one expects a major result, or perhaps the collaboration
of minor ones, to make significant progress on this problem.

In lieu of a complete result on the problem of primes between cubes, we
consider instead primes between @xmath th powers, where @xmath is some
positive integer. Appropriately, we choose @xmath , and we are able to
prove the following result.

###### Theorem 3.6.

Let @xmath . Then there is a prime between @xmath and @xmath for all
@xmath .

The result seems absurd on a first glance as the value of @xmath is
quite large. We shall leave it to others to attempt to bring the value
down. We prove the above theorem as follows: for our choice of @xmath ,
it follows that ( 3.10 ) becomes

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

whereas ( 3.9 ) remains the same. As before, we can, for some given
@xmath , choose @xmath and find @xmath such that there is a prime
between @xmath and @xmath for all @xmath by solving both inequalities.
Some results are given in the following table.

  @xmath   @xmath   @xmath
  -------- -------- --------
  4        0.9635   29.240
  5        0.9741   27.820
  6        0.9796   27.230
  7        0.983    26.427
  1000     0.9998   19.807

One can see that this method has its limitations, even in the case of
higher powers. In any case, we have that there is a prime in @xmath for
all @xmath . It follows that, for @xmath , there is a prime between
@xmath and @xmath for all

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

We could choose @xmath which is approximately @xmath to get primes
between @xmath and @xmath for all @xmath . Bertrand’s postulate then
improves this to all @xmath .

However, we can use Corollary 2 of Trudgian [ trudgianpomerance ] to
improve on this value of @xmath . This states that for all @xmath there
exists a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

If we set @xmath , we might ask when the above interval falls into
@xmath . One can rearrange the inequality

  -- -------- --
     @xmath   
  -- -------- --

to get

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

We wish to choose the lowest value of @xmath for which the solution sets
of ( 3.12 ) and ( 3.13 ) first coincide. It is not to hard to see that
this equates to solving simultaneously the equations

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

We do this by substituting the first equation directly into the second
to get

  -- -------- --
     @xmath   
  -- -------- --

which can easily be solved with Mathematica to prove Theorem 3.6 .

A gambit was suggested to the author, that he might consider the larger
interval @xmath in favour of @xmath . The improvements, however, are
negligible. Using the well-known bound

  -- -------- --
     @xmath   
  -- -------- --

we have from the binomial theorem that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Unfortunately, from ( 3.12 ) we have that @xmath is extremely small for
the values of @xmath which improve on Theorem 3.6 .

### 3.3 A result on the Riemann hypothesis

We have seen that without the Riemann hypothesis, explicit results are
obtainable using similar-natured zero-free regions and zero-density
estimates. If we assume this hypothesis, however, we replace such
estimates with the simple identity @xmath , and subsequently our working
and results become far neater.

On the assumption of the Riemann hypothesis, von Koch [ vonkoch ] proved
that there exists a constant @xmath such that the interval @xmath
contains a prime for all @xmath , where @xmath is sufficiently large.
This is often written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the @xmath th prime. Schoenfeld [ schoenfeld ] made
this result explicit, showing that one can take @xmath and @xmath .

Cramér [ cramer ] sharpened the result of von Koch by proving the
following theorem.

###### Theorem 3.7.

Suppose the Riemann hypothesis is true. Then it is possible to find a
positive constant @xmath such that

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

for @xmath . Thus if @xmath denotes the @xmath th prime, we have

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

Goldston [ goldston ] made the above result more precise by showing that
one could take @xmath in ( 3.14 ) for all sufficiently large values of
@xmath . He also showed that

  -- -------- --
     @xmath   
  -- -------- --

for all sufficiently large values of @xmath . It should be noted that
Goldston was not trying in any way to find the optimal constants; he was
providing a new proof of Cramér’s theorem. Ramaré and Saouter [
ramaresaouter ] furthered this line of research by showing that for all
@xmath there exists a prime in the interval @xmath .

The purpose of this section is to give the following improvement on the
work of Ramaré and Saouter.

###### Theorem 3.8.

Suppose the Riemann hypothesis is true. Then there is a prime in the
interval @xmath for all @xmath .

We prove this theorem using a weighted version of the Riemann–von
Mangoldt explicit formula and some standard explicit estimates for sums
over the zeroes of the Riemann zeta-function. It should be noted that
the constant @xmath appearing in Theorem 3.8 is not optimal. In fact, it
is unclear what the limitations of the method are, though we can compare
our result with Cramér’s conjecture [ cramerorder ] that

  -- -------- --
     @xmath   
  -- -------- --

We will show that with a bit more consideration, the constant @xmath can
be improved as follows.

###### Theorem 3.9.

Suppose the Riemann hypothesis is true and let @xmath . Then there is a
prime in the interval @xmath provided that @xmath is sufficiently large.

It is not clear to the author whether the optimal constant is @xmath or
something less, though it would be interesting to see whether any
improvements are readily forthcoming. In a paper with Grenié and Molteni
[ dudekmoltenigrenie ] , we show that a far more sophisticated method
yields the same result as Theorem 3.9 . Moreover, we actually make
Theorem 3.9 explicit in the following way.

###### Theorem 3.10.

Suppose the Riemann hypothesis is true. Let @xmath and

  -- -------- --
     @xmath   
  -- -------- --

Then there is a prime in the interval @xmath and at least @xmath primes
in @xmath .

We will not prove this result here, as the details are somewhat similar
to the proof of Theorem 3.9 . Notably, it follows from Theorem 3.9 that
Theorem 3.7 can be taken with @xmath for sufficiently large values of
@xmath . It is also clear from the Prime Number Theorem that @xmath .

Finally, the reader may wish to see the work of Heath-Brown and Goldston
[ goldstonheathbrown ] , for they show that one has an arbitrarily small
constant in place of the @xmath in Theorem 3.8 on the assumption of some
more sophisticated conjectures.

We will now prove Theorems 3.8 and 3.9 . In consideration of the von
Mangoldt function, we define the weighted sum (see Ingham [ inghambook ,
Ch. 4] for more details)

  -- -------- --
     @xmath   
  -- -------- --

and first prove an analogous explicit formula.

###### Lemma 3.11.

For @xmath and @xmath we have

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

where

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We integrate both sides of ( 2.2 ) over the interval @xmath to get

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Sending @xmath to infinity, the integral can be evaluated to yield
@xmath , and the sum over the zeroes can be estimated on the Riemann
hypothesis by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

The value of this sum is explicitly known. By comparing (10) and (11) of
Davenport [ davenport , Ch. 12] , we have that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is Euler’s constant. Thus,

  -- -------- --
     @xmath   
  -- -------- --

and the result follows. ∎

We now consider the existence of prime numbers in an interval of the
form @xmath . We do this by defining the weight function

  -- -------- --
     @xmath   
  -- -------- --

and considering the identity

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.17)
  -- -------- -------- -------- -- --------

One can verify this by expanding the weighted sum on the left hand side.
An application of Lemma 3.11 to the right side of the above gives us the
following result.

###### Lemma 3.12.

Let @xmath and @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

We use this lemma to prove our results. Our focus is estimating the sum
@xmath , which we consider in two parts: @xmath Here, @xmath ranges over
the zeroes @xmath with @xmath , where @xmath is to be chosen later, and
@xmath is the contribution from the remaining zeroes.

For @xmath , we notice that the summand may be written as

  -- -------- --
     @xmath   
  -- -------- --

the absolute value of which can be bounded above by

  -- -------- --
     @xmath   
  -- -------- --

It follows that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath is as before, and thus the bound ( 3.4 ) gives us that

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

when @xmath . We can estimate @xmath trivially on the Riemann hypothesis
by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where the last line follows from Lemma 1 (ii) of Skewes [ skewes ] . We
also note that Lehman [ lehman ] has explicit bounds for the sum @xmath
, which could be useful when working with explicit formulas for the
general sum (see Ingham [ ingham , Ch. 4] )

  -- -------- --
     @xmath   
  -- -------- --

Now, putting our estimates for @xmath and @xmath into Lemma 3.12 we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Notice that as we will choose @xmath to be @xmath , it follows that the
term in front of the logarithm is asymptotic to

  -- -------- --
     @xmath   
  -- -------- --

It is a straightforward exercise in differential calculus to show that
@xmath will minimise this term, and thus

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

or rather

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

As before, an application of Lemma 3.3 allows us to remove the
contribution from the higher prime powers viz.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

for all @xmath and @xmath . If we set @xmath , the leading term on the
right hand side can be shown to be asymptotic to

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

Thus, for @xmath we have that there is a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

and so we choose @xmath . Then, using a monotonicity argument we have
this for all @xmath . Replacing @xmath with @xmath , we have that there
is a prime in the interval

  -- -------- --
     @xmath   
  -- -------- --

for all

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . We complete the proof of Theorem 3.8 by using Mathematica
to verify the theorem for the remaining values of @xmath .

It now remains to prove Theorem 3.9 by showing that the constant @xmath
can be reduced to @xmath by a more detailed analysis of the sum @xmath .
Bounding trivially, we have that

  -- -------- --
     @xmath   
  -- -------- --

By noting the straightforward bound

  -- -------- --
     @xmath   
  -- -------- --

which holds for @xmath , we have that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as @xmath . Using this estimate and

  -- -------- --
     @xmath   
  -- -------- --

one obtains

  -- -------- --
     @xmath   
  -- -------- --

This sum can be estimated using Theorem A in Ingham’s book [ inghambook
, Pg. 18] and ( 3.4 ) to get that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the height of the first nontrivial zero of the
Riemann zeta-function. Employing the substitution @xmath and simplifying
shows that

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

Now, estimating @xmath as in the previous section, we have from Lemma
3.12 and ( 3.20 ) that

  -- -------- --
     @xmath   
  -- -------- --

If we set @xmath , and choose

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

then it follows that

  -- -------- --
     @xmath   
  -- -------- --

Note that the integral in ( 3.21 ) is equal to @xmath if one sends
@xmath to infinity. Therefore, we have @xmath provided that we take
@xmath to be sufficiently large. Of course, to avoid inflating the error
term @xmath , one finds that @xmath works fine. One can also remove the
contribution of prime powers to the sum to show that there is a prime in
the interval

  -- -------- --
     @xmath   
  -- -------- --

for all sufficiently large values of @xmath . This completes the proof
of Theorem 3.9 .

Finally, as mentioned in Section 1, we can also show that Theorem 3.7
can be taken with @xmath provided that @xmath is sufficiently large. For
if we take

  -- -------- --
     @xmath   
  -- -------- --

then again removing the contribution from prime powers, we have that

  -- -------- --
     @xmath   
  -- -------- --

The result then follows from using partial summation.

In the next chapter, we migrate from the problem of primes in short
intervals to that of additive problems in number theory. Our main
characters – the primes and the zeroes of @xmath – remain central to the
story.

## Chapter 4 Some Results in Additive Number Theory

  “Reeling and Writhing, of course, to begin with,” the Mock Turtle
  replied; “and then the different branches of Arithmetic – Ambition,
  Distraction, Uglification, and Derision.”

Additive number theory deals with the additive properties of numbers.
Specifically, we seek analogues to the fundamental theorem of arithmetic
where the operation is addition instead of multiplication. As mentioned
in Chapter 1, the following two conjectures of Goldbach form the
centrepiece of this theory.

###### Conjecture 1 (The Binary Goldbach Conjecture).

Every even integer greater than two can be written as the sum of two
primes.

###### Conjecture 2 (The Ternary Goldbach Conjecture).

Every odd integer greater than five can be written as the sum of three
primes.

The latter of these conjectures was recently proven by Helfgott [
helfgott2013 ] . Vinogradov [ vinogradov ] first proved in 1937 that
every odd integer @xmath can be written as the sum of three primes
(provided that @xmath is sufficiently large). Explicit results for
@xmath appeared soon after; Borodzin showed in 1939 that the one could
take @xmath . This was improved to @xmath by Chen and Wang [ chenwang ]
and to @xmath by Liu and Wang [ liuwanggoldbach ] . Helfgott finished
this line of work, showing that @xmath does the trick.

The binary conjecture, on the other hand, has not submitted itself as
gently as the ternary conjecture. We do not yet even know if every
sufficiently large even integer may be written as the sum of two primes.
However, by a result of Chen [ chen ] , we know that every sufficiently
large even integer can be written in the form @xmath , where @xmath is a
prime and @xmath is either a prime or a product of two primes. Another
impressive step in the right direction is the result of Linnik, that
every sufficiently large integer @xmath can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are primes, @xmath is a positive integer for all
@xmath , and @xmath where @xmath is an absolute constant. One can see
the paper of Heath-Brown and Puchta [ heathbrownpuchta ] for a short
history on the explicit bounds for @xmath . Both of these results are
weak forms of Goldbach’s binary conjecture, and it would be interesting
to see if one could make either of these explicit in the same style as
Helfgott’s theorem. That is, can we furnish an actual number @xmath such
that all even integers @xmath can be written in at least one of the
above two ways? Of course, as both of these are weak versions of
Goldbach’s binary conjecture, we would optimistically expect @xmath to
work.

In this chapter, we prove two explicit results in the additive theory of
numbers. Our first result is a weak form of Goldbach’s binary
conjecture; we prove that every integer greater than two can be written
as the sum of a prime and a square-free number. This completes a theorem
of Estermann [ estermann ] , who proved the same theorem but only for
sufficiently large integers.

We then examine the result of Erdős that every sufficiently large
integer @xmath such that @xmath can be written as the sum of the square
of a prime and a square-free number. We complete this result, showing
that this is true for all @xmath satisfying this congruence condition.
This is joint work with Dave Platt at the University of Bristol, and so
I will be clear in stating our individual contributions.

Importantly, the two results presented in this chapter serve to measure
the current state of play in the explicit theory of numbers. We exist in
a time where long-standing results may be revisited and sharpened, and
as such we provide a bounty of open problems for the interested reader
in Chapter 6.

### 4.1 On a theorem of Estermann

It was first shown by Estermann [ estermann ] in 1931 that every
sufficiently large positive integer @xmath can be written as the sum of
a prime and a square-free number, that is,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is prime for all @xmath and @xmath for @xmath . There is no
restriction on the size of @xmath here, however we already know by the
later work of Chen [ chen ] that one can take @xmath .

Moreover, Estermann proved that the number @xmath of such
representations satisfies the asymptotic formula

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

is a product over all prime numbers which is known as Artin’s constant
(see Wrench’s computation [ wrench ] for more details). Notably, it
follows that @xmath , and so we expect @xmath to be square-free for a
positive proportion of primes @xmath below @xmath .

In 1935, Page [ page ] improved Estermann’s result by giving a bound for
the order of the error term in ( 4.1 ), using estimates for the error in
the Prime Number Theorem for arithmetic progressions. Mirsky [ mirsky ]
extended these results in 1949 to count representations of an integer as
the sum of a prime and a @xmath -free number, that is, a number which is
not divisible by the @xmath -th power of any prime. More recently, in
2005, Languasco [ languasco ] treated the possibility of Siegel zeroes
(see Davenport [ davenport ] for a discussion on this) with more caution
so as to provide better bounds on the error.

The purpose of this section is to prove the following theorem,
completing the result of Estermann. This work has been accepted for
publication [ dudekestermann ] in The Ramanujan Journal .

###### Theorem 4.1.

Every integer greater than two is the sum of a prime and a square-free
number.

We prove this theorem by working in the same manner as Mirsky [ mirsky ]
, though we employ explicit estimates on the error term for the Prime
Number Theorem in arithmetic progressions. Specifically, if we let

  -- -------- --
     @xmath   
  -- -------- --

where the sum is over primes @xmath , we require estimates of the form

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

where @xmath is sufficiently small and @xmath and @xmath are suitably
ranged. Good estimates of this type are available due to Ramaré and
Rumely [ ramarerumely ] , but are only provided for finitely many moduli
@xmath . It turns out, however, that this is sufficient, as the
Brun–Titchmarsh theorem (which we will state soon) is enough for the
remaining cases. Later in the chapter – when we work on the result of
Erdős – Platt actually improves the Ramaré–Rumely estimates for the
Prime Number Theorem in arithmetic progressions. We delay this
improvement until then, as it is not required in the proof of Theorem
4.1 .

As with many of the proofs in this thesis, we will first employ analytic
methods to obtain explicit bounds. In this section, this will allow us
to prove the theorem in the range @xmath . Then we verify the remaining
cases computationally.

As such, we let @xmath be a positive integer and @xmath denote the
Möbius function, where @xmath is zero if @xmath is not square-free;
otherwise @xmath where @xmath denotes the number of distinct prime
factors of @xmath . We also stipulate that @xmath . For a positive
integer @xmath , it can be shown that the sum

  -- -------- --
     @xmath   
  -- -------- --

is equal to @xmath if @xmath is square-free and zero otherwise. Thus, it
follows that the expression

  -- -------- --
     @xmath   
  -- -------- --

counts the number of ways that @xmath may be expressed as the sum of a
prime and a square-free number. We will employ logarithmic weights so as
to use the known prime number estimates with more ease, and so we define

  -- -------- --
     @xmath   
  -- -------- --

We note that @xmath is the sum of a prime and a square-free number if
and only if @xmath . As such, the majority of this paper is dedicated to
finding a lower bound for @xmath . The expression for @xmath can be
rearranged so as to involve weighted sums over the prime numbers in
arithmetic progressions:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

We will split the range of this sum into three parts, for we shall use a
different technique to bound each of them. Thus, we may write

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

where

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

and @xmath is to be chosen later to minimise the value of @xmath such
that @xmath for all @xmath . We will use the estimates of Ramaré and
Rumely [ ramarerumely ] to bound @xmath ; this is the reason for the
specific range of @xmath in this sum. We will then use the
Brun–Titchmarsh theorem to bound @xmath . Finally, @xmath will be
bounded using trivial estimates.

Starting with the first sum, Theorem 1 of Ramaré and Rumely [
ramarerumely ] provides estimates of the form

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

In particular, by looking through the square moduli in Table 1 of their
paper, we have values of @xmath for all @xmath which are valid for all
@xmath . We therefore have that

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.6)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We now wish to estimate the three sums in the above parentheses. We note
that the leftmost sum is equal to Artin’s constant ( 4.2 ) viz.

  -- -- --
        
  -- -- --

Wrench [ wrench ] has computed this constant to high accuracy; it will
suffice for the purpose of Theorem 4.1 to note that @xmath .

We will, for the moment, neglect the middle sum in ( 4.6 ), for it shall
be considered jointly with a term in the estimation of @xmath . Thus, in
our estimation of @xmath , it remains to manually compute the upper
bound for the rightmost sum. This is a straightforward task which is
done in reference to Table 1 of Ramare and Rumely’s paper [ ramarerumely
] . We get that

  -- -------- --
     @xmath   
  -- -------- --

We now bring @xmath into the fray by calling on Montgomery and Vaughan’s
[ MV ] explicit version of the Brun–Titchmarsh theorem:

###### Theorem 4.2.

Let @xmath and @xmath be real numbers, and let @xmath and @xmath be
relatively prime positive integers with @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the number of prime numbers @xmath such that @xmath
.

A trivial application of Theorem 4.2 effects the bound

  -- -------- --
     @xmath   
  -- -------- --

Clearly, in the range @xmath we may bound

  -- -------- --
     @xmath   
  -- -------- --

and so we have the estimate that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . We may then bound @xmath from below by

  -- -------- --
     @xmath   
  -- -------- --

We can then add this to our estimate for @xmath to get

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.7)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We estimate the sum in the above inequality by writing it as follows:

  -- -------- --
     @xmath   
  -- -------- --

The infinite sum is less than 1.95 (see Ramaré [ ramare ] for example),
and the finite sum can be computed by hand to see that the sum in ( 4.7
) is bounded above by 0.086. Thus

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

For @xmath , we have trivially that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

This follows from the fact that there can be at most @xmath integers not
exceeding @xmath that are divisible by @xmath . Therefore, we have that

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.9)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We can now provide an explicit lower bound for @xmath . Combining our
explicit estimates ( 4.8 ) and ( 4.1 ) with ( 4.4 ) and dividing through
by @xmath we have that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

For sufficiently small @xmath and large @xmath , the right hand side
will be positive. For any @xmath , we have @xmath ; it is a simple
matter to choose @xmath and verify that the right hand side is positive
for all @xmath . That is, Theorem 4.1 is true for all integers @xmath .

It so remains to prove this result for all integers in the range @xmath
. If @xmath is even, we have the numerical verification by Oliviera e
Silva, Herzog and Pardi [ silva ] that all even integers up to @xmath
can be written as the sum of two primes. Thus, every even integer
greater than two may be written as the sum of a prime and a square-free
number.

Therefore, we need to check that every odd integer @xmath can be written
as the sum of a prime and a square-free number. Our algorithm is as
follows: we partition the range @xmath into intervals of size @xmath .
That is, we are considering the intervals @xmath for all integers @xmath
such that @xmath .

The interval @xmath is straightforward to check; in general, for the
interval @xmath , we use Mathematica to generate a decreasing list
@xmath of the 100 greatest primes which do not exceed @xmath . Then,
starting with the first odd number @xmath , we check to see first if
@xmath is square-free as @xmath ranges from 1 to 100, moving to @xmath
as soon as we have found a prime which works. The purpose of choosing
primes close to the interval is soon apparent, for the relatively small
value of @xmath makes it a simple exercise to check for square-freeness.
This is a straightforward computation; we ran this on Mathematica and it
took just under 3 days on a 2.6GHz laptop. This computation could no
doubt be optimised; for example, we could have first generated a list of
the square-free numbers up to some bound by employing the sieve of
Eratosthenes but with square moduli. Then, checking that @xmath is an
element of this list would be far quicker than running a square-free
test for each number.

### 4.2 On a theorem of Erdős

In 1935, quite soon after the aforementioned theorem of Estermann [
estermann ] , Erdős [ erdos ] proved that every sufficiently large
integer @xmath may be written as the sum of the square of a prime and a
square-free number. The congruence condition here is sensible: if @xmath
then @xmath for any odd prime @xmath , and so @xmath is clearly not
square-free. This only leaves the case @xmath , but @xmath fails to be
square-free infinitely often ¹ ¹ 1 For example, one can consider the
congruence class @xmath . .

It is the objective of this section to make explicit the proof provided
by Erdős, to the end of proving the following theorem.

###### Theorem 4.3.

Let @xmath be an integer such that @xmath . Then there exists a prime
@xmath and a square-free number @xmath such that @xmath .

The proof of this theorem, and thus the content of this section, was
completed jointly with Dave Platt at the University of Bristol. This
work has now been accepted by the LMS Journal of Computation and
Mathematics [ dudekplatt2 ] .

The reader should note that Theorem 4.3 is, in some sense, stronger than
Theorem 4.1 , for the sequence of squares of primes is far more sparse
than the sequence of primes. We prove Theorem 4.3 in a similar way, by
combining modern explicit results on primes in arithmetic progressions
and computation. We push both of these resources to their limits in
doing so, at least, a lot further than in the last section.

Specifically, we extend the results of Ramaré and Rumely [ ramarerumely
] , and our computational algorithm is far more involved than that of
the previous section. These last two important points were significant
contributions on Platt’s part, and before these were brought to the
table, I could only prove Theorem 4.3 for all @xmath . Therefore, whilst
the method of this section is my adaptation of Erdős’ original proof, it
was Platt’s contributions that allowed the proof to get over the line.

The proof may be roughly outlined as follows. For any integer @xmath
satisfying the conditions of the above theorem, we want to show that
there exists a prime @xmath such that @xmath is square-free. That is, we
require some prime @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

for all odd primes @xmath . The idea is to consider, for some large
@xmath and each odd prime @xmath , those mischievous primes @xmath that
satisfy the congruence

  -- -------- --
     @xmath   
  -- -------- --

Then, for each @xmath we explicitly bound from above (with logarithmic
weights) the number of such primes @xmath . Summing over all moduli
@xmath gives us an upper bound for the weighted count of the mischievous
primes viz.

  -- -------- --
     @xmath   
  -- -------- --

It is then straightforward to show that for large enough @xmath , the
above sum is less than the weighted count of all primes less than @xmath
, and therefore there must exist a prime @xmath such that @xmath is not
divisible by the square of any prime.

This method works well, and allows us first to prove Theorem 4.3 for all
integers @xmath which satisfy the congruence condition. We then
eliminate the remaining cases by direct computation to complete the
proof.

Note that from before, the paper of Ramaré–Rumely [ ramarerumely ]
provides us with bounds on the error term in the Prime Number Theorem in
arithmetic progressions. Specifically, these are of the form

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

for various ranges of @xmath and @xmath respectively. These computations
were in turn based on Rumely’s numerical verification of the generalised
Riemann hypothesis (GRH) [ Rumely1993 ] for various moduli and to
certain heights.

The GRH is a more general form of the Riemann hypothesis, and asserts
that a broad class of Dirichlet series (namely the Dirichlet @xmath
-functions) have all of their nontrivial zeroes on the line @xmath (see
Davenport [ davenport ] for further discussion). Since the computations
of Rumely, Platt has verified GRH for a wider range of moduli and to
greater heights [ Platt2013 ] . For our purposes, we rely only on the
following result.

###### Lemma 4.4.

Let @xmath be a prime satisfying @xmath . All nontrivial zeroes @xmath
of Dirichlet L -functions derived from characters of modulus @xmath with
@xmath have @xmath .

###### Proof.

See Theorem 10.1 of Platt’s paper [ Platt2013 ] . ∎

We can therefore extend the results of Ramaré–Rumely with the following
lemma.

###### Lemma 4.5.

For @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

for the values of @xmath and @xmath in Table 4.1 .

###### Proof.

We refer to Ramaré and Rumely [ ramarerumely ] . The values for @xmath
are from Table 1 of that paper. For the other entries, we use Theorem
5.1.1 with @xmath and @xmath (see display 4.2). We set @xmath for @xmath
, @xmath for @xmath and @xmath otherwise. We use @xmath and for @xmath
we use the upper bound of Lemma 4.2.1. Finally, for @xmath we rely on
Lemma 4.1.2 and we note that @xmath as required. ∎

###### Lemma 4.6.

We have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is a prime such that @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The results for @xmath are from Table 2 of [ ramarerumely ] with a
slight correction to the entry for @xmath . A short computation shows
that the maximum occurs for all of the other @xmath when @xmath and
@xmath . ∎

###### Lemma 4.7.

Let @xmath . Then for @xmath and @xmath an odd prime we have

  -- -------- --
     @xmath   
  -- -------- --

where the values of @xmath are given in Table 4.2 .

###### Proof.

Using @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

so for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

and so we can take

  -- -------- --
     @xmath   
  -- -------- --

∎

The reader should note that the above sharpening of Ramaré and Rumely’s
results could be extended so as to include all moduli in the given range
and not just the squares. This would then allow one to ease the
computation involved in proving Theorem 4.1 in the previous section.

Now, let @xmath be such that @xmath and consider the case where @xmath
is an odd prime such that @xmath . We want to bound from above the
number of primes @xmath satisfying

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

Clearly, @xmath can belong to at most two arithmetic progressions
moduluo @xmath . Therefore, by Lemma 4.7 , we can estimate the weighted
count of such primes as follows.

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are the possible congruence classes for @xmath
and @xmath is given in Table 4.2 . Summing this over all @xmath values
of @xmath gives us the contribution

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

We now consider the case where @xmath and @xmath is to be chosen later
to achieve an optimal result. As in the previous section, the
Brun–Titchmarsh Theorem gives us that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Trivially, one has that

  -- -------- --
     @xmath   
  -- -------- --

As @xmath , it follows that

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

We bound the sum as follows:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Substituting this into ( 4.12 ) gives us that

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

Now, let @xmath be an odd prime such that @xmath , where @xmath is to be
chosen later for optimisation. Since there are at most two possible
residue classes modulo @xmath for @xmath , the number of primes @xmath
such that @xmath is trivially less than

  -- -------- --
     @xmath   
  -- -------- --

Clearly, using our logarithmic weights one has that

  -- -------- --
     @xmath   
  -- -------- --

and so

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the number of primes not exceeding @xmath . The sum
can be estimated in a straightforward way by

  -- -------- --
     @xmath   
  -- -------- --

and by Theorem 6.9 of Dusart [ dusart ] , which gives us that

  -- -------- --
     @xmath   
  -- -------- --

Note that, for the eventual choice of @xmath and our range of @xmath ,
we will have @xmath and so this upper bound is valid. Therefore, putting
this all together we have

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

Finally, we consider the range @xmath . If @xmath is divisible by @xmath
, then

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

for some positive integer @xmath . We will need some preliminary results
here. First, it is known by the theory of quadratic forms (see Davenport
[ davenport , Ch. 6] ) that the equation

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are given positive integers, has at most @xmath
proper solutions, that is, solutions with @xmath . Note that @xmath
denotes the number of automorphs of the above form and @xmath denotes
the number of different prime factors of @xmath . The number of
automorphs is directly related to the discriminant of the form;
specifically, @xmath for the case @xmath and @xmath for @xmath .
Moreover, we are only interested in the case where @xmath and @xmath are
both positive, and so it follows that ( 4.15 ) has at most @xmath proper
solutions. Finally, noting that there will be at most 1 improper
solution to ( 4.15 ), namely @xmath , we can bound the overall number of
solutions to ( 4.15 ) by @xmath .

Furthermore, Theorem 11 of Robin [ robin ] gives us the explicit bound

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

for all @xmath . Robin also gives (Theorem 12) the stronger bound

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , which allows one to replace the value @xmath in ( 4.16
) with 1.1189 for all @xmath . It turns out that @xmath will be good
enough for our proof, however one should note that using the constant
@xmath would ease the computation slightly by allowing us to prove
Theorem 4.3 for a slightly larger range. This improvement, however, was
suggested to the author by Dr. Trudgian after the later computation had
been done, and so we do not need to implement this. It would be a useful
gambit to keep in mind for similar problems.

Thus, for fixed @xmath and @xmath , it is easy to bound explicitly from
above the number of solutions to ( 4.15 ). It remains to sum this bound
over all valid values of @xmath . However, we should note that given an
integer @xmath , there are not too many good choices of @xmath , and
this will allow us to make a further saving.

This comes from the observation that every prime @xmath satisfies @xmath
. For with @xmath and @xmath , it follows that ( 4.15 ) becomes

  -- -------- --
     @xmath   
  -- -------- --

and this confines @xmath to the integers in a single residue class
modulo 24.

Formally and explicitly, we argue as follows. Consider first the case
where @xmath is an integer in the range

  -- -------- --
     @xmath   
  -- -------- --

The leftmost inequality above keeps @xmath . Here, there are clearly at
most

  -- -------- --
     @xmath   
  -- -------- --

integer values for @xmath . We now consider the case where @xmath , and
it follows that @xmath . Clearly, then, there are at most

  -- -------- --
     @xmath   
  -- -------- --

values for @xmath in this range. Therefore, in total, there are at most

  -- -------- --
     @xmath   
  -- -------- --

values of @xmath for which we need to sum the solution counts to ( 4.15
). Also, we must also consider that @xmath for @xmath . Therefore, we
have that the number of solutions to ( 4.15 ) summed over @xmath is
bounded above by

  -- -------- --
     @xmath   
  -- -------- --

Therefore, the number of primes @xmath , each counted with weight @xmath
, which satisfy ( 4.15 ) is at most

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

Now, collecting together ( 4.11 ), ( 4.13 ), ( 4.14 ) and ( 4.17 ), we
have that the weighted count over all the so-called mischevious primes
can be bounded hideously thus

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

As expected, however, the weighted count over all primes exceeds this
for large enough @xmath and good choices of @xmath and @xmath . Dusart [
dusart ] gives us that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , and thus it follows that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . There are sharper bounds that one could use here (see
Trudgian [ trudgianpomerance ] and Faber–Kadiri [ faberkadiri ] for
modern results), however Dusart’s result is both easily stated and
suitable for the application.

Therefore, if we denote by @xmath the (weighted) count of primes @xmath
such that @xmath is square-free, it follows that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

It is now straightforward to check that choosing @xmath and @xmath gives
@xmath for all @xmath , that is, Theorem 4.3 is true for this range of
integers.

We will now describe Platt’s computation to confirm that all integers
@xmath satisfying @xmath and @xmath can be written as the sum of the
square of a prime and a square-free number. This is actually much
further than we needed to check, but we did not expect our analytic
approach to fare as well as it did. We will first describe the algorithm
used, and then say a few words about its implementation.

We aim to test @xmath different values of @xmath . We quickly conclude
that we cannot afford to individually test candidate numbers of the type
@xmath to see if they are square-free. We proceed instead by chosing a
largest prime @xmath and a sieve width @xmath . To check all the
integers in @xmath we first sieve all the integers in @xmath by crossing
out any that are divisible by a prime square @xmath with @xmath . Now,
for each @xmath such that @xmath , we look in our sieve to see if @xmath
is square-free ² ² 2 Unless @xmath . . If not, we try @xmath , then
@xmath , and so on until @xmath is square-free. If it fails all these
tests up to and including @xmath , we output @xmath for later checking.

Numbers of this size fit comfortably in the @xmath bit native word size
of modern CPUs and we implemented the algorithm in C++. We use a
character array for the sieve and chose a sieve width @xmath as this
allows us to run @xmath such sieves in parallel in the memory available.
We set the prime limit @xmath as this was found to reduce the number of
failures to a manageable level (see below). To generate the primes used
to sieve the character array, we used Kim Walisch’s primesieve [
Walisch2012 ] .

We were able to run @xmath threads on a node of the University of
Bristol’s Bluecrystal cluster [ ACRC2014 ] and in total we required
@xmath core hours of CPU time to check all @xmath . Here, @xmath values
of @xmath were rejected as none of @xmath with @xmath were square-free.
We checked these @xmath cases in seconds using PARI [ Batut2000 ] and
found that @xmath eliminated @xmath of them, @xmath does this for a
further @xmath , @xmath for @xmath more, @xmath for @xmath more values
of these @xmath , @xmath does not help, @xmath knocks off @xmath more
and the last one standing, @xmath falls away with @xmath . Finally, we
use PARI again to check @xmath with @xmath and we are done.

It is interesting to consider the efficiency of the main part of this
algorithm. The CPUs on the compute nodes of Phase III are @xmath GHz
Intel ^(®) Xeon ^(®) processors and we checked @xmath individual @xmath
in @xmath hours. This averages less than @xmath clock ticks per value of
@xmath which suggests that the implementation must have made good use of
cache.

This computation completes the proof of Theorem 4.3 . We note again
that, for the interested reader, there are plenty more open problems of
this flavour that may yield to similar techniques. We provide a
collection of these in Chapter 6.

## Chapter 5 Solving a Curious Inequality of Ramanujan

  “Curiouser and curiouser!” cried Alice (she was so much surprised that
  for the moment she quite forgot how to speak good English).

In this chapter, we detail another joint investigation, made by the
author and Platt, on @xmath , the number of primes which are less than
or equal to @xmath . The work of this chapter has now been published [
dudekplattem ] in Experimental Mathematics .

In one of his notebooks, Ramanujan (see the preservations by Berndt [
berndt , Ch. 24] ) proved that the inequality

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

holds for all sufficiently large values of @xmath . Berndt [ berndt ]
states that Wheeler, Keiper and Galway used Mathematica in an attempt to
determine an @xmath such that ( 5.1 ) holds for all @xmath . They were
unsuccessful, but independently Galway was able to establish that the
largest prime counterexample below @xmath occurs at @xmath .

Hassani [ Hassani ] looked at the problem in @xmath and established
inter alia the following theorem.

###### Theorem 5.1 (Hassani).

Assuming the Riemann Hypothesis, the inequality

  -- -------- --
     @xmath   
  -- -------- --

holds for all @xmath .

The first objective of this chapter is to provide an estimate for the
inequality ( 5.1 ) without the condition of the Riemann hypothesis.
Using standard estimates on the error term in the Prime Number Theorem,
we will prove the following theorem.

###### Theorem 5.2.

Without any condition, the inequality

  -- -------- --
     @xmath   
  -- -------- --

holds for all @xmath .

We then solve the problem completely on the assumption of the Riemann
hypothesis, showing that the counterexample found by Wheeler, Keiper and
Galway is the largest.

###### Theorem 5.3.

Assuming the Riemann Hypothesis, the largest integer counterexample to

  -- -------- --
     @xmath   
  -- -------- --

is that at @xmath .

We will look at the unconditional result first.

### 5.1 The unconditional result

We start by giving Ramanujan’s original and, we think, rather fetching
proof, which is based on de la Vallée Poussin’s rendition of the Prime
Number Theorem, or more specifically that

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

as @xmath . As such we have the two estimates

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Subtracting the above two expressions gives

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

which is negative for sufficiently large values of @xmath . This
completes the proof.

The proof itself should serve as a tribute to the workings of
Ramanujan’s mind, for surely one would not calculate the asymptotic
expansions of such functions without the inkling that doing so would be
fruitful.

Note that if one were to work through the above proof using explicit
estimates on the asymptotic expansion of the prime-counting function,
then one would be able to make precise what is meant by “sufficiently
large”. The following lemma shows how we do this.

###### Lemma 5.4.

Let @xmath and suppose that for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Then Ramanujan’s inequality is true if

  -- -------- --
     @xmath   
  -- -------- --

where a value for @xmath can be obtained in the proof and is completely
determined by @xmath and @xmath .

###### Proof.

Following along the lines of Ramanujan’s proof we have for @xmath

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

where

  -- -------- --
     @xmath   
  -- -------- --

The other term requires slightly more trickery; we have for @xmath

  -- -------- --
     @xmath   
  -- -------- --

We make use of the inequality

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
              @xmath   @xmath   
  -- -------- -------- -------- --

to get

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

where

  -- -------- --
     @xmath   
  -- -------- --

Now, subtracting @xmath from @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

The right hand side is negative if

  -- -------- --
     @xmath   
  -- -------- --

and so we can then choose @xmath to be some value @xmath which satisfies
this. ∎

The aim is to reduce @xmath so as to get the sharpest bound available
using this method and modern estimates involving the prime counting
function. We thus look at developing the explicit bounds on @xmath that
are required to invoke Lemma 5.4 . We need to call on Corollary 1 of
Mossinghoff and Trudgian [ trudgianmossinghoff ] , which bounds the
error in approximating the Chebyshev @xmath -function with @xmath .

###### Lemma 5.5.

Let

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -------- --
     @xmath   
  -- -------- --

This is another form of the Prime Number Theorem, and is able to give us
the estimates required to use Lemma 5.4 . For any choice of @xmath , it
is possible to use the Lemma 5.5 to find some @xmath such that

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

for all @xmath ; we simply need to find the range of @xmath for which

  -- -------- --
     @xmath   
  -- -------- --

As this may yield large values of @xmath , we write @xmath (also @xmath
) and take logarithms to get the equivalent inequality

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

Now, suppose that, for any @xmath and some corresponding @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . The technique of partial summation gives us that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
              @xmath   @xmath   
  -- -------- -------- -------- --

We can estimate the remaining integral here by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
              @xmath   @xmath   
                                
              @xmath   @xmath   
  -- -------- -------- -------- --

Putting it all together we have that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , where

  -- -- -- -------
           (5.8)
  -- -- -- -------

In an almost identical way, we can obtain for @xmath that

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

and

  -- -------- --
     @xmath   
  -- -------- --

Now that we have our estimates, we can launch directly into the proof of
Theorem 5.2 . Our method is as follows. We choose some @xmath such that
we wish for

  -- -------- --
     @xmath   
  -- -------- --

to hold for @xmath . We simply plug our desired value of @xmath into (
5.7 ) and use Mathematica to search for some value of @xmath , such that
the inequality holds for all @xmath . We then use ( 5.8 ) and ( 5.9 ) to
calculate two values @xmath and @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

holds for @xmath . Then, by Lemma 5.4 , we find some value @xmath
(dependent on @xmath , @xmath and @xmath , and thus really only on
@xmath ) such that Ramanujan’s inequality is true for @xmath .

One finds that small values of @xmath , give rise to large values of
@xmath , yet small values of @xmath . Similiarly, large values of @xmath
will yield small @xmath yet large values of @xmath . Of course, we want
@xmath and @xmath to be comparable, so that we might lower their maximum
as much as possible. Thus, the idea is to select @xmath so that @xmath
and @xmath are as close as possible.

It follows immediately from the above and Lemma 5.4 , upon choosing
@xmath , that @xmath and @xmath are suitable values. This gives us
Theorem 5.2 .

### 5.2 Estimates on the Riemann hypothesis

In this section, we prove Theorem 5.3 . We assume the Riemann Hypothesis
and can therefore rely on Schoenfeld’s [ schoenfeld ] conditional bound
for the prime counting function.

###### Theorem 5.6.

Assume the Riemann hypothesis. For @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

We now aim to improve on Theorem 5.1 to the extent that a numerical
computation to check the remaining cases become feasible. The following
result will bridge the gap by showing that Ramanujan’s inequality ( 5.1
) also holds in the range @xmath .

###### Lemma 5.7.

Assuming the Riemann Hypothesis, we have

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

###### Proof.

Due to the work of Hassani, we really only need to prove this for the
range @xmath . Platt and Trudgian [ platttrudgian ] have recently
confirmed that @xmath holds for @xmath . Together with Theorem 5.6 we
see that

  -- -------- --
     @xmath   
  -- -------- --

is bounded above by

  -- -- --
        
  -- -- --

for all @xmath . Berndt [ berndt , Pg. 114] uses some elementary
calculus to show that a similar function to the above is monotonically
increasing over some range. One can use that same technique here to show
that @xmath is monotonically decreasing for all @xmath , as the
derivative of @xmath is straightforward to compute. Then, Mathematica
can be used to show that

  -- -------- --
     @xmath   
  -- -------- --

and thus @xmath is negative for all @xmath . ∎

Finally, we wish to show by computation that there are no
counterexamples to ( 5.1 ) in the interval @xmath . As before, we write

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath is strictly decreasing between primes, so we could
simply check that @xmath for all primes @xmath in the required range.
However, there are roughly @xmath primes to consider ¹ ¹ 1 Or precisely
@xmath . and this many evaluations of @xmath would be computationally
too expensive. Instead, we employ a simple stepping argument.

###### Lemma 5.8.

Let @xmath be in the interval @xmath with @xmath . Set @xmath . Then
@xmath for all @xmath .

###### Proof.

We have for @xmath and @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Setting @xmath and solving the resulting quadratic in @xmath gives us
our lemma. ∎

Suppose we have access to a table containing values of @xmath with
@xmath for all @xmath . Then we can compute an interval containing
@xmath simply by looking up @xmath and @xmath where @xmath . Repeating
this for @xmath we can determine an interval @xmath for which @xmath
must lie. Assuming @xmath is negative, we can use Lemma 5.8 to step to
the next value of @xmath and repeat.

Oliviera e Silva has produced extensive tables of @xmath [ Oliviera2012
] . Unfortunately, these are not of a sufficiently fine granularity to
support the algorithm outlined above. In other words the estimates on
@xmath and @xmath we can derive from these tables alone are too
imprecise and do not determine the sign of @xmath uniquely. We looked at
the possibility of refining the coarse intervals provided by these
tables using Montgomery and Vaughan’s explicit version of the
Brun–Titchmarsh [ MV ] theorem but to no avail. Instead, we (or, more
specifically, Dave Platt) re-sieved the range @xmath to produce exact
values for @xmath where the @xmath were more closely spaced. Table 5.1
provides the details. ² ² 2 At the same time we double checked Oliviera
e Silva’s computations and, as expected, we found no discrepancies.

We used Kim Walisch’s primesieve package [ Walisch2012 ] to perform the
sieving and it required a total of about @xmath hours running on nodes
of the University of Bristol’s Bluecrystal cluster [ ACRC2014 ] . ³ ³ 3
Each node comprises two @xmath core Intel ^(®) Xeon ^(®) E5-2670 CPUs
running at @xmath GHz and we ran with one thread per core.

Using Lemma 5.8 with these tables, actually confirming that @xmath for
all @xmath took less than @xmath minutes on a single core. We had to
step (and therefore compute @xmath ) about @xmath times to span this
range. We sampled at every @xmath th step and Figure 5.1 shows a log/log
plot of @xmath against @xmath for these samples. ⁴ ⁴ 4 Actually, we use
the midpoint of the interval computed for @xmath .

No counterexamples to ( 5.1 ) where uncovered by this computation and so
we can now state that there are no counterexamples in the interval
@xmath . This concludes the proof of Theorem 5.3 , and so ends this
chapter of work. The next chapter contains a good assortment of open
problems for the reader to investigate, including a suggested
generalisation of the work contained in this chapter.

## Chapter 6 An Offering of Open Problems

  “I almost wish I hadn’t gone down that rabbit-hole – and yet – and yet
  – it’s rather curious, you know, this sort of life!”

Whilst solving the problems that made this thesis, the author came
across a suite of related problems. Within this chapter, we offer these
to the avid reader in the hope that interest in the area of explicit
methods in number theory burgeons.

Certainly, one should adopt the practice of searching for new problems
every once in a while. Besides the standard citation searches offered by
the likes of MathSciNet and Google Scholar, there is a lot to be gained
by sifting through the information on Wikipedia, Wolfram MathWorld,
StackExchange and MathOverflow. Of course, these latter sources offer
not peer-reviewed research, but a community dialogue for one to look
through, and it is surprising how much can be gained from this.

For example, the inequality of Ramanujan studied in Chapter 5 was first
found on the Wolfram MathWorld page [ mathworld ] for the prime counting
function. And similarly, it would be unwise for one working on the
Riemann hypothesis to avoid the Wikipedia page [ wiki ] on this topic
for reasons of scholarly lewdness.

The author also found Guy’s book of unsolved problems [ guy ] , Murty’s
book of exercises [ murty ] and the Mitrinović–Sándor–Crstici handbook [
sandor ] to be excellent companions to the working analytic number
theorist.

###### Problem 1.

Consider the explicit version of the truncated Riemann–von Mangoldt
explicit formula developed in Chapter 2. Wolke [ wolke ] has established
a (not explicit) version of this formula with an error term that is

  -- -------- --
     @xmath   
  -- -------- --

It would be interesting to make this explicit.

###### Problem 2.

Using an explicit version of Wolke’s formula, one could estimate the sum
over the zeroes using Ramaré’s explicit zero-density estimate [ ramare ]
and the Mossinghoff–Trudgian zero-free region [ trudgianmossinghoff ] .
This would give an explicit bound for @xmath that might improve that of
Mossinghoff and Trudgian.

###### Problem 3.

In his paper, Wolke [ wolke ] shows how his explicit formula can be used
to prove Cramér’s theorem that there is a prime in the interval @xmath
for some @xmath and sufficiently large @xmath . It would be interesting
to see if Wolke’s method, made explicit, would yield better estimates
for @xmath than those given in Chapter 3 of this thesis.

###### Problem 4.

It would be interesting to see the explicit version of the truncated
Riemann–von Mangoldt explicit formula proven in a faster way.
Specifically, can one write the sum over the zeroes as

  -- -------- --
     @xmath   
  -- -------- --

and directly bound the rightmost sum?

###### Problem 5.

The Riemann–von Mangoldt explicit formula has been used in various
applications. It would be interesting to see which of these applications
can now be reworked explicitly using Theorem 2.1 .

###### Problem 6.

It would be interesting to see if other explicit formulas can produce
better bounds on primes between cubes. The author attempted an
investigation of this using @xmath , but was not able to get primes
between cubes using Ford’s zero-free region and Ramaré’s zero-density
estimate (one can, however, still get short interval results).

###### Problem 7.

Although proving that there is a prime between any two consecutive cubes
seems out of reach (at least for this author), one could try to prove
the existence of almost-primes between cubes. There are some details on
this in Ivić’s book [ ivicbook , Ch. 12.7] .

###### Problem 8.

In Chapter 4, we make two theorems in additive number theory completely
explicit. There are many similar problems that one could look at. For
example, fix @xmath such that @xmath . One could attempt to show that
every large enough positive integer @xmath could be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a prime such that @xmath and @xmath is square-free.

###### Problem 9.

One could prove that every positive integer is the difference of a prime
and a square-free number.

###### Problem 10.

Given some positive integer @xmath , explicitly determine a constant
@xmath such that every even integer @xmath can be written in the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are primes, @xmath is a positive integer for all
@xmath and @xmath .

###### Problem 11.

In Erdős’ paper [ erdos ] , he also shows that, in the case where @xmath
and is sufficiently large, @xmath may be written in the form @xmath
where @xmath is a prime and @xmath is square-free. I am not sure why
Dave Platt and I walked around this problem, but one could surely
resolve it similarly to the case where @xmath .

###### Problem 12.

Prove that every integer (in the appropriate congruence classes and from
some number onwards) can be written as the sum of a @xmath -th power of
a prime and an @xmath -free number (see Rao [ rao ] for a proof that
every sufficiently large integer can be so written).

###### Problem 13.

In Chapter 4, we showed how Platt’s [ Platt2013 ] work on verifying GRH
up to certain heights could be used to improve the bounds on the Prime
Number Theorem in arithmetic progressions. It would be very useful if
one were to rework the entire paper of Ramaré and Rumely [ ramarerumely
] using this verification.

###### Problem 14.

It would be interesting to see if the inequality of Ramanujan that we
studied in Chapter 5 could be suitably generalised. For example,
Ramanujan considered two expressions involving @xmath that agreed for
the first four terms of their series expansions but not thereafter.
Given some integer @xmath , would it be possible to contrive two
expressions involving @xmath that agree for the first @xmath terms but
not thereafter?

Note that Hassani [ hassanigen ] has generalised the problem in a
different way, which might also be of interest.

The above problems are few in a field of many, but these are certainly
the ones of most interest to the author.