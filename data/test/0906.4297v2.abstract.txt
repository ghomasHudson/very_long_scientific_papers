This thesis consists of four chapters. The first two chapters pertain to
the design of stable quantization methods for analog to digital
conversion, while the third and fourth chapters concern problems related
to compressive sensing.
In the first chapter, we study the @xmath -encoder and golden ratio
encoder, and show that these quantization schemes are robust with
respect to uncertainty in the multiplication element of their
implementation, whereby @xmath . In particular, we use a result from
analytic number theory to show that the possibly unknown value of @xmath
can be reconstructed as the unique root of a power series with
coefficients in @xmath obtained from the quantization output of test
input @xmath and its negative, @xmath .
The focus of our attention in Chapter 2 is Sigma Delta ( @xmath )
modulation, a course quantization method in analog to digital conversion
that is widely used for its simplicity of implementation and robustness
to component imperfections. A persistent problem in @xmath quantization
of audio signals is the occurrence of undesirable tones arising from
periodicities in the bit output; these tones are particularly
intolerable in the space between successive audio tracks. As one of the
contributions of this thesis, we show that the standard second order
1-bit @xmath scheme can be modified so as to eliminate such
periodicities, and this modification can be achieved without sacrificing
accuracy or introducing significant complexity.
The emerging area of compressed sensing guarantees that sufficiently
sparse signals can be recovered from significantly fewer measurements
than their underlying dimension suggests, based on the observation that
an @xmath dimensional real-valued vector can be reconstructed
efficiently to within a factor of its best @xmath -term approximation by
taking @xmath measurements, or inner products. However, the quality of
such a reconstruction is not assured if the underlying sparsity level of
the signal is unknown. In Chapter 3, we show that sharp bounds on the
errors between a signal and @xmath estimates (corresponding to a
different sparsity hypotheses, say) can be achieved by reserving only
@xmath measurements of the total @xmath measurements for this purpose.
The proposed technique is reminiscent of cross validation in statistics
and learning theory, and theoretical justification in the context of
compressed sensing is provided by the Johnson Lindenstrauss lemma.
In Chapter 4, we study the relation between nonconvex minimization
problems arising in compressed sensing and those known as
free-discontinuity problems, which are often encountered in the areas of
image segmentation and edge detection. We adapt recent thresholding
techniques in the area of sparse recovery to a class of nonconvex
functionals that contains both compressed sensing and
free-discontinuity-type problems. Along the way, we establish a
connection between these two types of problems, using the notion of
gamma convergence, and gain new insights into the minimizing solutions
of such functionals.
