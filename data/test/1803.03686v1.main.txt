## Chapter 1 Introduction and Motivation

“Begin at the beginning,” the King said, gravely, “and go on till you
come to an end; then stop.”

– Lewis Carroll; Alice in Wonderland

### 1.1 The big bang and the early universe

The early universe has proven itself notoriously difficult and elusive
to physicists who seek to understand its beginning and evolution. The
current theory of universe formation begins with the big bang followed
by a period of rapid inflation, corresponding to about a few pico
seconds or an energy scale of @xmath @xmath [ 1 ] as shown in Fig 1.1 .
As the universe begins to expand and cool, elementary particles begin to
start forming from the high temperature vacuum leading to nucleons such
as protons/neutrons. These nucleons then start interacting with other
elementary particles (such as electrons) and start to form nuclei. At
this epoch, the photons are no longer in thermal equilibrium with normal
matter and the universe becomes photo-transparent leading to the famed
cosmic microwave background (CMB) [ 2 ] . Our conventional (microwave,
visible and radio) telescopes are limited in their ability to see beyond
the CMB and study the early formation of the universe [ 3 ] . Recent
results from LIGO [ 4 ] with gravitational wave astronomy has the
potential to see past the CMB and therefore generated a lot of
excitement in the general community but the field is in its infancy. One
way to recreate the conditions after the big bang, especially the
particle physics epoch, is by colliding heavy element nuclei at
relativistic speeds in particle colliders.

### 1.2 The little bang and relativistic heavy ion collisions

Relativistic heavy ion collisions at the CERN Large Hadron Collider
(LHC) in Geneva, Switzerland and the Relativistic Heavy Ion Collider
(RHIC) at Brookhaven National Laboratory (BNL), Long Island USA, provide
the necessary conditions to recreate the particle epoch in the early
universe. Studying how the collision remnants evolve using particle
detectors such as trackers, calorimeters, muon chambers, time of flight
counters etc. tantamount to understanding how fundamental particles
navigate the primordial universe.

A simulation of a single heavy ion collision in shown in Fig: 1.2 , with
the help of the MADAI framework [ 5 ] , split up into three panels;
before the collision (top), immediately after (middle) and 10-15
femtoseconds after the collision (bottom). Before the collision, we see
lorentz contracted nuclei in the direction of the beam (along the z axis
as shown in the bottom left of the panels). After the collision, we see
the formation of all kinds of particles and the whole system expanding
reminiscent of a blast wave type pattern. It is by the reconstruction of
these final state particles that we are able to extract the properties
of the state of matter immediately after the collision.

In the collisions of heavy ions at relativistic speeds, the immediate
aftermath can be composed of fundamental particles such as quarks or
gluons, deconfined and moving around in whats now know as the quark
gluon plasma (QGP) [ 6 ] . The path taken by the deconfined
quarks/gluons (henceforth referred to as partons) to color neutral
hadrons constitutes a quantum chromo dynamics (QCD) phase transition,
first proposed in the early 70s [ 7 ] as shown in Fig: 1.3 . In heavy
ion collisions at the LHC, the baryon density is very low and and the
temperature is high since the nucleons in the incoming beams at the LHC
go through each other with minimal billiard-ball like contact. The area
of the phase diagram being studied by the LHC is shown in the green
shaded region in Fig: 1.3 . On the other hand, RHIC has the capability
to collide different particle species at a variety of beam energies (the
lower the beam energy, the more probable it is to have direct collisions
between nucleons in the beam) leading to a wider coverage in the phase
diagram. A recent physics review of QCD phase diagram can be found here
[ 8 ] . The edges of the phase diagram correspond to different physical
states of matter (as mentioned below) with the yellow dot in the middle
representing a possible second order phase transition which is still the
matter of current research and an open question probed via the Beam
Energy Scan (BES) at RHIC (see ref. [ 9 ] for a recent review of the
physics from BES).

-   top left (high temperature and low baryon density): Early universe

-   top right (high temperature and high baryon density): QGP

-   bottom right (low temperature and high baryon density): Neutron
    stars

-   bottom left (low temperature and low baryon density): Hadron gas.

### 1.3 Jet quenching and thesis overview

Parton energy loss was one of the predicted signatures of the QGP [ 10 ,
11 , 12 ] with the amount of energy loss per distance travelled in the
medium being a direct inference on the QGP properties. With the QGP
being very short lived, it is not possible to study this particular
signature in a laboratory, wherein one can shoot particles at it and
study the energy loss. Rather, we use ultra-relativistic heavy ion
collisions since both the QGP and the hard scattered partons are created
around the same time with the parton traversing the medium in its path.
By comparing such heavy ion collisions with proton-proton collisions, in
similar parton kinematics, one can extract qualitative features of its
energy loss or quenching. Experimentally, one cannot measure or detect
individual partons, jets or collections of particles arising from a
parton are used as first order proxies. Jets are ideal probes of the QGP
since they are essentially involve both the hard scale (from the hard
scattering) and the soft scale (from the QGP interactions). While there
are other signatures of the QGP, jets are especially useful at the LHC
due to their high production cross section and relative abundance
leading to multiple interesting measurements to probe the effect of the
QGP on the jet energy and structure. Jets are the main actors in this
thesis and I will show measurements of the jet cross section from
different systems at the LHC such as proton-proton, proton-lead and
lead-lead aiding in supplementing our understanding of fundamental QCD
and physics of the QGP.

There are excellent review articles and seminal papers referenced
throughout the early chapters and the interested reader is encouraged to
look up these references and further references within. The necessary
theoretical framework/assumptions and background of QCD/jets is provided
to the reader in Chapter 2. In addition, a quick introduction to Monte
Carlo (MC) event generators and theoretical calculations is presented
following a discussion of the signatures of the QGP in a heavy ion
environment. The experimental point of view and technicalities of heavy
ion events and in measuring a jet spectra are presented in chapters 3
and 4. We move to the physics of jet spectra measurements in pp and pPb
collisions in chapter 5 and PbPb collisions in chapter 6. The heavy ion
MC generator JEWEL is introduced in chapter 7 and we discuss the physics
we can extract in comparing data to theoretical and MC models. We
finally summarize the current state of the art in heavy ion jet
measurements and ponder the future of the field in the coming years. The
appendices contain useful discussion of particle physics kinematics, the
technical details involving jet reconstruction algorithms, a list of
abbreviations commonly used in the field and a short review of recent
progress in jet structure measurements at the LHC.

## Chapter 2 Theoretical Overview

“We are all agreed that your theory is crazy. The question which divides
us is whether it is crazy enough to have a chance of being correct. My
own feeling is that it is not crazy enough.”

– Niels Bohr

### 2.1 Standard model of particle physics

There are four fundamental types of interactions or forces that are
present in nature; Gravity, Electromagnetism, Weak and the Strong force.
Of the four, strong and electro-weak forces can be described by one
theory, rather collection of theories called the Standard Model (SM) of
particle physics. There are two kinds of fundamental particles in the
SM, force mediators or gauge bosons and matter particles or fermions.
The matter particles (and their corresponding anti-matter particles)
shown in Fig: 2.1 in the pink and green boxes are the quarks and
leptons. These matter particles are fermions and they appear in nature
as couplets such as u, d and e, @xmath of which three subsequent
generations have so far been experimentally confirmed. Amongst the
bosons, shown in the red boxes, the photon mediates the electromagnetic
force, and its heavier cousins, the Z and W @xmath mediate the weak
force. The gluons facilitate interactions between quarks and thus
mediate the strong force. The most recent addition to the table is the
notable Higgs boson in the yellow box as the Higgs field being
responsible for the individual particle masses. There are several
textbooks and review papers to learn more about the standard model and
its intricacies and the reader can find a few of those here [ 13 , 14 ,
15 , 16 ] .

As mentioned above, the standard model only deals with the strong and
electroweak forces with Gravity as the notable exception. Theories that
include gravity are called Grand Unified Theories (GUT) (see [ 17 ] for
a recent review) and will not be discussed in this thesis. Our main
focus in this chapter is studying the formation and behaviors of the QGP
which involves the following; understanding the interaction of quarks
and gluons, jet production cross sections, technicalities involved in MC
event generation models and finally signatures of the QGP in heavy ion
collisions.

### 2.2 Fundamentals of QCD and jets

The interaction of quarks and gluons makes up the theory of QCD and we
will go over some of the fundamental properties of QCD from an
experimentalist’s point of view. Quarks were proposed in the early 60s
by Murray Gell-Mann and George Zweig [ 18 ] as a way of understanding
the fundamental particles that make up cosmic rays and their collision
products with the atmosphere. Since quarks are fermions, they are spin
one half and carry both electromagnetic (non integral) and color charge.
Color charge is unique to quarks and gluons with each quark capable of
carrying one of three possible options, which physicists in their
infinite wisdom have called red, blue and green (with anti-quarks
carrying either anti-red, anti-blue or anti-green charges). Gluons [ 19
] carry color charge composed of quark-anti-quark configurations,
leading to 8 varieties of gluons. The composite objects made up of
quarks such as Baryons (three or five quarks) and Mesons
(quark-antiquark) are by definition colorless (RBG = R @xmath = White).

#### 2.2.1 Asymptotic freedom and Confinement

The strength of an interaction is primarily characterized by its
coupling in the respective field. When you consider QED [ 20 ] , the
coupling constant is dependent on the beta function which is positive to
several orders in perturbative theory. At low energies, we find that
@xmath and around the Z mass (90 GeV/c) @xmath . Since it is small, the
overall sum across all orders in perturbative theory converges. In QCD
however, the beta function non zero and thus the coupling constant is a
function of the energy scale at which it is probed and is of order
@xmath at 100 GeV/c and increasing to @xmath as the energy scale
decreases to 1 GeV/c or the proton mass scale. This dependence on the
energy scale, referred to as asymptotic freedom [ 21 ] in literature,
has been extracted from several experimental measurements during the
past decades is shown in Fig: 2.2 . The markers correspond to
measurements and the shaded region are fits to the data showing the
characteristic dependence of the @xmath which is calculable in
perturbation theory.

The running of the coupling constant also leads to infra-red slavery
where quarks and gluons are bound to color singlet states [ 23 ] . This
is analogous to thinking about a quark-antiquark pair as two ends of a
string and as one pulls one side of the string apart, the tension
increases and at some point, the string breaks and multiple strings are
formed. In simpler terms, it is not possible to isolate an individual
quark or gluon and thus the QGP is a direct consequence of the
asymptotic freedom. The formation of hadrons from quarks/gluons is
called as hadronization. A theoretical and phenomenological review is
available here [ 24 ] . Thus, hadronization and infra-red slavery mean
that the QGP is not directly observable and experiments utilize jets as
internal hard probes to study the medium indirectly.

#### 2.2.2 Jets as evidence for quarks and gluons

Quarks were first experimentally discovered in high energy
electron-positron collisions in the PETRA (housed in DESY) accelerator
ring at the TASSO experiment [ 25 ] as shown in the left panel of Fig:
2.3 . The presence of back to back collimated streams of particles
confirmed the existence of the so-called quark “jets”. A more formal
definition of a jet is given in the next chapter and in Appendix: B . At
the moment, we shall only consider a jet as a collimated spray of
particles, limited by a given distance scale from a single parton. Three
jet or Mercedes style events (right panel of Fig: 2.3 ) again at TASSO,
were consistent with gluon bremmstrahlung from one of the quarks and
thus verified the existence of gluons. Since these were @xmath
collisions, background contamination was negligible and the signals were
very clean with almost all the tracks directly associated with the
collision products. When we move over to pp and heavy ion collisions, we
will soon see that the picture becomes quite complicated.

Jet studies at the LHC, due to the nature of the high energy beam, probe
the high @xmath , or momentum transfer region where perturbative theory
is mostly valid. This is an important point to note since we will be
focusing on understanding the behavior of QCD at high density and
temperature by comparing it to a baseline pp which we henceforth call
vacuum. In order to understand our vacuum production of jets, we will in
turn be comparing it with perturbative QCD (pQCD) calculations with the
use of the factorization theorem.

#### 2.2.3 Theoretical calculations of inclusive hadron cross section

To first order, a jet is a proxy for a hard parton and it has a
characteristic structure arising from the QCD radiation pattern which
can be calculated. Such calculations typically involves the factorized
or perturbative part (hard process) and the non perturbative corrections
(soft processes) including hadronization, multi-parton scattering and
the underlying event. The QCD factorization theorem [ 26 ] relies on the
ability to separate the calculable short scale quark gluon scattering
from the long-distance hadronization process. Thus essentially, a
factorized hadron cross section in hadron collisions is a direct
generalization of the deep-inelastic scattering outlined as follows for
the production of a hadron of type ‘H’

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath is the parton distribution function, followed by the
individual cross section of @xmath and the fragmentation function @xmath
which is the probability distribution of hadrons with the fractional
momentum z. In the above factorized formula, @xmath is the fraction of
the parton momentum compared to that of the proton, referred to as
Bjorken @xmath , and @xmath is the energy scale of the factorization
process. The factorization scale ( @xmath ) is introduced to separate
the long and short distance physics of the interaction and thus at best
arbitrary. Systematic uncertainties of theoretical cross section often
include variations on the factorization scale utilized in the
calculation.

##### Parton distribution functions

The make up of a proton is characterized by the parton distribution
functions (PDF) [ 27 ] , represented as a probability of finding a
certain constituent at a given Bjorken @xmath as shown in Fig: 2.4 based
on the NNPDF 2.3 PDF [ 28 , 29 ] for two particular @xmath scenarios
(left - low @xmath GeV @xmath , right - high @xmath GeV @xmath ). The
different curves are labeled to represent the contributions that make up
a proton such as the valence quarks, up (blue) as @xmath , down (green)
as @xmath and the strange quarks (teal/turquoise) as @xmath and the
gluon contribution in red, which is the largest and is divided by a
factor of 10 in the panels. This tells us that the proton is
predominantly ”seen as composed ” made up of gluons as we move to high
@xmath and low @xmath region (significant in our high @xmath jet
studies). PDFs are universal and its scale dependence is calculable in
QCD and thus only the x dependence is parameterized.

Experimentally, is not possible to measure the initial parton kinematics
such as @xmath and @xmath directly. Nevertheless by looking at a special
class of events with two high @xmath hard scattered jets called a di-jet
system we can extract strong correlations between the following;

-   average transverse momentum of the two jets and the @xmath

-   di-jet pseudorapidity and the @xmath .

There are several options for choosing a PDF since they are essentially
fits to data deep inelastic lepton+nucleus and hadron collisions
utilizing different methods of fitting and fit functions. The NNPDF
curves shown in Fig: 2.4 utilize a neural network to fit a variety of
functions and more than 250 individual parameters on different datasets
with a non linear activation function.

##### Splitting functions

In QCD, splitting details how quarks or gluons can radiate additional
quarks or gluons in vacuum. They are encompassed in the DGLAP evolution
equations for parton densities, named after Dokshitzer, Gribov, Lipatov,
Altarelli and Parisi [ 31 , 32 ] , which are essentially a matrix in
flavor space where the splitting functions are given as follows (as a
function of energy fraction in the splitting fraction)

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where the coefficients are the respective casimir color factors @xmath
and @xmath . It is important to note that the @xmath are symmetric with
@xmath and @xmath excluding virtual emissions. The divergence for @xmath
and @xmath are for the conditions @xmath implying soft gluon emission
and @xmath which has a direct consequence of the growth in the PDFs as
we go to small @xmath .

##### Non-Perturbative corrections

Experimentally Non-Perturbative (NP) effects are evaluated by using
models for the underlying event [ 33 ] , hadronization [ 34 ] , and
multi-parton interactions [ 35 ] in MC event generators. The underlying
event primarily consists of proton remnants concentrated along the beam
direction and multiple soft interactions between the nuclei [ 36 ] . The
ratio between a nominal event generation using a well performing tune,
including matrix element (either Leading Order or Next to Leading Order)
and the parton shower (PS) and a sample with hadronization (HAD) and
multi parton interactions (MPI) effects switched off is taken as
correction. Note that NP corrections, so defined, are used to correct
any available pQCD calculation at parton level to bring it to the jet
level for direct comparison with experiment. The NP correction factors
can be defined as:

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

where in the superscript, the components of the simulations are listed
and in the subscript the order of the matrix element is specified. These
correction factors are usually estimated with different tunes,
generators and PDF sets, and the envelope resulting from them is
considered as theoretical uncertainty of the correction factors as shown
in the left panel of Fig: 2.5 estimated for CMS measurement of jet
spectra with a given distance parameter or jet radius of R = 0.7, at 13
TeV [ 37 ] . More details about the clustering algorithm and jet radius
will be provided in the upcoming chapters.

As one goes to very high @xmath processes, electroweak corrections to
the jet spectra also become non-negligible. These are corrections due to
virtual exchanges of massive guage bosons such as Z and W especially at
central rapidity and high @xmath as shown in the right panel of Fig: 2.5
.

With the addition of these correction factors the factorized jet cross
section calculation at NLO in the matrix element and parton showers are
available in the fastNLO framework [ 38 ] for a variety of collisions
and center of mass energies. A comprehensive comparison of data with
fastNLO predictions are shown in Fig: 2.6 . This plot is quite
complicated but the main takeaway message is that across a large scale
of jet @xmath , clustering algorithms, center of mass energy and
rapidity regions, theoretical calculations can reproduce data at certain
kinematic regions, but have notable exceptions for example anti-k @xmath
small jet radii and low jet @xmath . There are several non trivial
effects that arise in this particular region and as physicists, our
sights now turn to study what causes this discrepancy and what is
missing in our calculations which we will look at in detail in the
upcoming chapters.

### 2.3 Standard particle physics MC generators

Ab-initio theoretical calculations for every observable in question are
very complicated and take a lot of time and person power to materialize.
Monte Carlo event generators employ the same fundamental rules of
particle production and interactions in a probabilistic approach and
asymptote to a general solution [ 39 , 40 ] . The term Monte Carlo is
honorary to the city in Europe famous for its gambling casinos and the
usage in physics tantamount to repeated random sampling from a given
probability distribution, for example, a proton PDF.

The state of the art simulation of a full proton-proton collision has to
deal with several processes such as

-   Matrix Element for the hard scattering [ 41 ]

-   Initial State Radiation from the incoming protons

-   Parton showers and evolution towards jets provided by the DGLAP
    equations (see [ 42 ] for a review)

-   Parton Fragmentation towards hadrons

-   Hadronization - model dependent since the process is fundamentally
    non perturbative

-   Underlying Event and MPI from the same proton-proton collision

-   Final State Radiation say from bremmstrahlung photons.

There are a lot of MC generators on the market and many of them have
parameters fitted to a particular datasets leading to a variety of
tunes. The most well known generator in particle physics is PYTHIA [ 43
, 44 ] , regularly utilized by all the experiments at the LHC for
comparisons and for removing detector resolution biases. Other commonly
used generators are HERWIG [ 45 , 46 ] , SHERPA [ 47 , 48 ] which
utilize an angular ordered parton shower stemming from the Seymor-Catani
splitting functions [ 49 , 50 ] .

### 2.4 Signatures of the QGP

Armed with a phenomenological introduction to QCD and pp collisions, we
can begin to comprehend heavy ion collisions and any experimental
signatures of the QGP. Since the QGP only exists in a very small time
frame, it is not straight forward to say if a particular collision
produced the deconfined state directly. It is also not possible to
experimentally study the state of matter via say spectroscopy or some
external probe. By analyzing the final state products, several possible
signatures have emerged during the last decades that are discussed in
Appendix: C .

The main evidence for the presence of the QGP in heavy ion collisions is
the concept of jet quenching. In relativistic heavy ion collisions,
there is a significantly large cross section for hard scattering of two
partons from the incoming beams. These hard scattered partons are
produced back-to-back in the transverse plane and thus by reconstructing
the jets arising from these partons, one expects them to be of roughly
equal momentum due to momentum conservation. A naive expectation of
medium induced modification is an asymmetric reduction in the jet energy
depending on distance from the center of the collision. This is
pictorially highlighted in Fig: 2.7 where one jet with transverse energy
@xmath is seen to escape the interaction region fairly easily where as
its recoil partner travels through much of the medium and loses
additional energy, ending up with @xmath [ 51 ] .

The STAR collaboration was able to directly measure this phenomenon in
its landmark result as shown in Fig: 2.8 where the azimuthal angular
correlation ( @xmath ) of all identified charged hadrons with the
leading charged hadron in the event [ 52 ] . The result shows this
correlation for minimum bias pp (proton-proton), head-on AuAu
(gold-gold) and dAu (deuteron-gold) collisions. The pp and dAu
correlations both show the near side peak ( @xmath ) and the away side
recoiling peak ( @xmath ). The disappearance of the away side peak in
AuAu collisions (shown in blue stars) confirms the presence of medium
(or QGP) interaction where the recoiling jet appears to be quenched.

At the LHC, both ATLAS and CMS measured this particular phenomenon with
fully reconstructed jets as opposed to charged tracks. The observable of
interest was the dijet asymmetry ( @xmath ) which is defined as the
difference between the leading and the subleading jet @xmath divided by
the sum of the two. Both ATLAS and CMS published the asymmetry
measurement as a function of centrality [ 53 ] and the jet @xmath [ 54 ]
respectively. The top panels of 2.9 show the asymmetry distribution
normalized to the number of events for head on collisions on the right
and peripheral, glancing collisions on the left for PbPb data with the
solid markers, pp data with the open markers and an MC sample without
quenching in the yellow histograms. A clear deviation from pp collisions
to PbPb is observed in the data with a significant fraction of dijet
events being more asymmetric than symmetric. The bottom panels in Fig:
2.9 also shows the angular correlation between the two leading jets
(ordered by their transverse momentum) showing very little deviation in
the away side region but small modification in the near side.

The corresponding CMS measurement for the @xmath is shown in Fig: 2.10
for head on collisions where the different panels correspond to varying
bins of leading jet momenta increasing from top left to bottom right.
The data is comparable with an embedded, unquenched MC at high @xmath
but the deviations are quite clear for the low leading jet @xmath bins
in the analysis.

While these results directly show evidence of jet quenching, both the
jets in the @xmath measurement can be quenched and thus one cannot get
an idea of how much energy loss is happening for a jet of a given @xmath
. In addition, the jets considered here are quite high in the @xmath and
that might constitute a selection bias in our events. Another
conceptually simple way to measure an effect of the QGP is to compare a
measurement in heavy ion collisions to proton proton collisions
multiplied by the equivalent number of binary collisions ( @xmath ).
Such measurements are know as nuclear modification factors or @xmath ,

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where the AA stands for Ion-Ion (including proton-Ion). The number of
binary collisions is estimated with the use of the Glauber model that
will be discussed in the coming sections. Thus, the @xmath provided
early clear signals indicating the presence of the QGP or medium
behavior when it is found to be less than or greater than 1 and this
will be primary measurement of this thesis.

### 2.5 Key features of heavy ion collisions

The complications in a heavy ion collision partly arises due to the
theoretical difficulty in describing the following

-   Initial state

-   Event Centrality

-   Hydrodynamic evolution

-   Parton energy loss

-   Hadronization

with the main question revolving around the symbiotic treatment of the
soft and the hard scale in the collision.

There are two groups of theories based on the description of nuclear
matter, right before or during the collision, described as the initial
state [ 55 , 56 , 57 ] . Firstly, one can assume that its entirely
composed of gluons with high coupling such as in the Color Glass
Condensate (CGC) approach [ 58 ] and secondly, weak coupling gluons
originating from a cascade of multiple splittings from the initial
valence quarks as described in the EKRT [ 59 , 60 , 61 ] or EPOS [ 62 ,
63 ] model. Both these approaches are able to reproduce the particle
production dependent on the multiplicity under a variety of assumptions
including a parameterized description of temperature and the entropy
density in the initial state.

In earlier sections, we discussed the proton PDFs and in heavy ion
collisions, one often talks about the use of nuclear PDFs [ 64 ] . This
approach is data driven where in one assumes the respective PDF is
modified and the nuclear modification factor is often obtained by global
fits to data from deep inelastic measurements [ 65 ] . A well used
example of such nPDFs are from the EPS09 [ 66 ] and nCTEQ [ 67 , 68 ]
collaborations with its fits for cold nuclear matter effects. These can
describe jet data reasonably well at the LHC for pPb collisions as we
shall seen in the upcoming chapters. One facet of a heavy ion event
which we will cover next is the question of event centrality and its
modeling.

In collisions of lorentz contracted nuclei, the impact parameter @xmath
(distance between the center of the nuclei) varies from event to event.
By looking at the simple geometry of the collision based on the event
multiplicity or the energy deposits in the forward calorimeters we can
identify events into several centrality or event activity classes. The
most central collisions are identified with the smallest @xmath and
peripheral collisions have the largest @xmath . The Glauber model (or a
variant thereof) is used to calculate the nuclear thickness function
@xmath (which we will use in our binary scaling of the pp reference).

The Glauber model [ 69 ] describes the interaction of two nuclei in
terms of the interaction of its constituent nucleons as shown
pictorially in Fig: 2.11 . The following assumptions are made to have a
model of the interaction.

-   nucleus moves in a straight line

-   classical scattering to find the number of interacting nucleons as a
    function of the given impact parameter

We start with the nuclear thickness function, @xmath defined as the
probability density of finding a nucleon at a given impact parameter

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

where @xmath is the nuclear density distribution of nucleus A. Now we
can talk about the thickness overlap function between two nucleus which
is the effective overlap area for which a specific nucleon in A can
interact with a given nucleon in B. This is defined as

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

When integrated over the nucleons in A, one can calculate the expected
number of hard collisions, @xmath with the nucleons from B at the same
two-dimensional position ( @xmath in coordinate from the center of B, as
shown in Fig: 2.12 ) where @xmath is the total inelastic nuclear nuclear
scattering. An accurate description of the @xmath variable is important
to extract useful physics from the @xmath .

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

Since a heavy ion collision is inherently a many-body QCD problem, it
involves microscopic non-equilibrium physics (as we realized in the
first chapter), and a full description or solution of its evolution is
an area of active research. What we can do as physicists, is to describe
a coarse grained collective motion of the system after thermal
equilibrium with a fluid-like treatment. Thus it is intuitive that
hydrodynamics is an integral part of the theoretical modeling [ 65 ] .
Almost all of the heavy ion MC models in market utilize some form of a
hydrodynamics transport model for its particles and the interested
reader can find an exhaustive review here [ 71 ] . As was mentioned in
the introductory chapter, the main focus of this thesis deals with jet
quenching and so we will take a brief look at how individual parton
energy loss is treated in both theory and MC generators.

#### 2.5.1 Jet Quenching

Since a jet is a composite object, understanding jet energy loss in the
medium entails first studying single parton energy loss as was done in
the early papers on QGP phenomenology [ 10 , 11 , 12 , 72 , 73 , 74 ] .
The primary idea revolved around how a single parton lost energy via a
variety of processes such as radiative (inelastic) and collisional
(elastic) as a function of its path length in the medium as shown in
Fig: 2.13 at leading order.

The direct calculation of these processes is not trivial since it
involves a hot and dense medium. The medium is also finite size and is
evolving and expanding in a non intuitive way. Such effects of the
medium to first order can be included as corrections on top of the
vacuum structure of jets since the soft interactions does not affect the
hard scatter or the production as soon on the bottom panels of Fig: 2.9
. Going back to our cross section for a single hadron from a hard
scattering, we can add an additional term to the cross section as
follows

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

with medium modification @xmath now dependent on the event geometry.
This new term is related to the transport properties of the QGP,
quantized via the @xmath variable defined as the momentum transfer
squared per elastic collision with the medium

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

where @xmath is the coherent length and @xmath is the emitted gluon upon
interaction with the QGP [ 75 ] . The coherence length is effectively
the threshold within which all scatterings count as a single scattering
within the medium. When the coherence length is larger than the mean
free path (the average maximal distance between scatterings), it implies
a suppression of coherent radiation i.e. gluon bremsstrahlung. This is
formally known as the Landau Pomeranchuck Migdal [ 76 ] effect and has
been very effective in MC implementation of parton energy loss [ 77 ] .
Phenomenologically, the @xmath variable is very interesting and a lot of
literature exists in that subject [ 78 , 79 ] . Briefly, it not only
plays an important role in describing medium induced radiative energy
loss (as we saw above), it also quantifies the transverse momentum
exchange between the propagating jet and the medium. The JET
collaboration utilized single hadron suppression data and extracted a
parametrized temperature dependence of the temperature scaled jet
transport parameter @xmath at both LHC and RHIC energies [ 80 ] . Their
main result is shown in Fig: 2.14 for a variety of jet energy loss
models and with the summary as follows, for a quark with an energy of 10
@xmath , it will lose around @xmath and @xmath of @xmath per fermi of
distance travelled in the plasma at RHIC and at the LHC with initial
temperatures of 370 and 470 MeV respectively.

It is interesting to note that the value of @xmath in LHC is larger
compared to RHIC, essentially meaning that the two mediums are
quantitatively different. While the overall effect is comparable, when
say estimated by the nuclear modification factors, the corresponding
energy loss is much larger at the LHC (and gets even larger when
increased center of mass energy of the collision).

The prescription for energy loss for a given jet builds on the
aforementioned hadron suppression, since a jet corresponds to its
leading constituent in the limiting case of infinitely small lateral
size of the jet. One intuitive picture is to take the vacuum branching
of a jet and run the individual constituents through the energy loss
prescription. The probabilistic nature of this branching causes several
issues qualitatively since the medium interactions inherently depend on
the nature of the splitting and the matter density in the path of the
jet and its constituents. There are several p-QCD MC approaches that
treat this prescription utilizing scattering centers and with either
elastic or inelastic scattering with such centers. For example, the AMY
[ 81 ] , ASW [ 82 ] model focusses on multiple soft scatterings and
averages over the path length to define transport coefficients. Such a
method excludes hard scatterings, whereas methods such as HT [ 83 ] or
DGLV [ 84 ] take into account one scattering with interference terms
calculated in multiple orders. The elastic scattering centers described
in the BDMPS-Z formalism often includes the LPM suppression as discussed
above for emitted gluons based on their formation times as given in [ 77
] . See [ 65 , 72 , 85 ] for detailed reviews on the theoretical aspect
of jet quenching in heavy ion collisions.

With all these questions and complexities involved in the theoretical
description of the QGP, any experimental measurement in heavy ions needs
to keep in mind a few of fundamental points such as understanding the
baseline behavior in pp (including at the NLO level) and
relevance/connection to QGP transport properties or nuclear effects.

### 2.6 Jet measurements in the different systems

With what we learnt so far about QGP signatures, Fig: 2.15 shows a few
of the standout measurements one can perform with the use of jets [ 86 ]
.

Jets in pp collisions are very useful to tune PDFs, cross check the hard
scattered cross-section and probe the fragmentation functions, with the
use of the charged hadrons. In pPb and PbPb collisions, we can study the
nuclear modifications of the aforementioned measurements when comparing
with pp, in addition to cold and hot nuclear matter effects
respectively. We will go through some of these measurements in more
detail in the upcoming chapters and see how we can extract physics and
understanding about fundamental QCD and QGP behaviors by comparing data
to theory.

## Chapter 3 Experiment Details

“A pretty experiment is in itself often more valuable than twenty
formulae extracted from our minds.”

– Albert Einstein

### 3.1 LHC and the CMS experiment

The accelerator complex at CERN ( Conseil Europ en pour la Recherche
Nucl aire or European Organization for Nuclear Research), located just
outside Geneva, Switzerland is uniquely capable of providing the most
energetic particle collisions thus far in the world. The facility, as
outlined in Fig: 3.1 has an impressive array of linear accelerators, ion
rings (for heavy ion beams), synchrotrons, boosters, leading to the LHC
ring with the ability to accelerate particles from gas cylinders to very
nearly the speed of light.

In addition to proton beams, the LHC provides accelerated lead ions
208Pb for the possibility of colliding PbPb and pPb (and Pbp, please see
Appendix A for CMS convention) with the use of the same dipole magnets.
The heavy ion collisions occur at a much smaller luminosity and the
bunches contain less particles with a reduced frequency of the bunch
crosses as shown in Table: 3.1 . This thesis deals primarily with data
collected during the heavy ion running period of 2011 and 2013 where pp
and PbPb were run at 2.76 TeV and pPb at 5 TeV respectively. One
advantage in the pp reference runs is their low pileup ¹ ¹ 1 Number of
additional primary vertices resulting from more than one hard scatter as
the bunches cross each other leading to a very clean data sample
requiring only the very rudimentary event cleaning setups. For more
details about the individual components and facilities at CERN and the
LHC ring, please refer the to the technical design report [ 87 , 88 ] .

The Compact Muon Solenoid (CMS) [ 91 ] is one of the four main
experiments on the LHC and is located in Annecy, France, farthest from
the main CERN campus. The reason to have several experiments is one of
fundamental necessity to all science i.e. reproducibility of results and
verification of data. With proton-proton data at 8 TeV, experiments have
discovered the Higgs particle (at both the CMS [ 92 ] and ATLAS
collaborations [ 93 ] ) along with an impressive array of results
excluding the existence of beyond the standard model theories and
particles, current status can be found in these reviews [ 94 , 95 ] .
The heavy ion running period is also an important time for CMS when
operations shift from the large pp crew to the small but substantial
heavy ion crew. We record, analyze and publish data leading to important
results in the field of relativistic heavy ions, and quite recently, in
pp collisions as well.

The CMS detector subsystems include the trackers, electromagnetic and
hadronic calorimeters offering almost @xmath hermetic coverage, magnets,
the muon systems and the forward calorimeters as shown in the 3D
rendition in Fig: 3.2 . The central feature of the CMS apparatus is a
superconducting solenoid providing a magnetic field of 3.8 T.
Charged-particle trajectories are measured with the silicon tracker that
allows a transverse impact parameter resolution of @xmath and a @xmath
(transverse momenta) resolution of @xmath for particles with @xmath =
100 GeV/c. A PbWO @xmath crystal electromagnetic calorimeter (ECAL) and
a brass and scintillator hadron calorimeter (HCAL) surround the tracking
volume. The forward regions are instrumented with an iron and
quartz-fiber Hadronic Forward calorimeters (HF), which are very
important for heavy ion events as we will see in the upcoming sections.
A set of beam scintillator counters (BSC), used for triggering and beam
halo rejection, is mounted on the inner side of the HF calorimeters. The
very forward angles are covered at both ends by zero-degree calorimeters
(ZDC).

Example event displays for a dijet event in pp and PbPb collisions at
CMS from Run1 and Run2 is shown in Fig: 3.3 . As we discussed in the
previous chapter, a dijet event is two back to back jets resulting from
a hard quark/gluon from one proton scattering of another quark/gluon
from the other proton, as shown on the left of Fig: 3.3 .
Correspondingly, a quenched dijet system is shown on the right of Fig:
3.3 in central PbPb collisions. Run1 at the LHC also had pPb collisions
at 5.02 TeV in early 2013 but a pp reference run was not performed
leading to an extrapolated reference which will be discussed in detail
in the upcoming chapters.

A separate suite of reconstructing software is installed in CMS to
efficiently take data in the heavy ion environment. In comparison to pp
events where the average track density in mid rapidity is around 16
tracks, heavy ion events average more than 1600 tracks for the most head
on collisions with the same kinematic cuts, necessitating dedicated data
operations.

### 3.2 Event selection and triggering

In order to clean our sample from background, beam gas, PKAM (Previously
Known As Monster) and ultra peripheral (no significant hard scatter in
the collision) events, the following cuts/filters are applied to select
events off-line (at the analysis level).

-   BSC halo filter: events where any of the BSC halo bits fired were
    excluded.

-   Requirement of a reconstructed 2-track primary vertex was imposed.
    In peripheral events, all tracks above 75 MeV/c transverse momentum
    were used to reconstruct the vertex. In central events, the minimum
    @xmath requirement was increased, and the tracking region was
    narrowed down, to keep the maximum number of fitted tracks stable
    around 40 or 60, ensuring time efficient reconstruction. This
    requirement removes non-inelastic-collision events (e.g. beam gas,
    UPC, calorimeter) with large HF energy deposits but very few pixel
    hits.

-   A cut to remove PKAM events, which is a requirement of pixel
    cluster-length compatibility with the vertex.

-   A requirement of an off-line HF coincidence, which requires at least
    3 towers on each side of the interaction point in the HF with at
    least 3 GeV total deposited energy per tower.

Noise cleaning in the experiment also extends to the different
reconstructed objects such as calorimeter clusters for example. Since
you always have electronic noise, it is important to only select events
with a calorimeter deposit due to particles from the collision (or
depending on the run, cosmic rays). Shower shape, signal profile (in
time and space) and, number of active channels are few of the most
important quantities for a calorimeter deposit enabling distinction
between signal and noise and these were specifically tuned and tested
for heavy ion events for the analysis performed in this thesis. Detailed
information about the calorimeter noise studies can be found here [ 96 ]
.

#### 3.2.1 CMS trigger architecture

Since the inelastic nucleon-nucleon scattering cross section is smaller
than the elastic one, a lot of the events in heavy ion (and pp as well)
collisions are not what we are interested in; high @xmath momentum
transfer. At the same time it is also not currently possible to write
down every single collision to tape due to limits on data transfer. Thus
one needs a workflow that makes a decision on a particular event as
interesting or not based on a user defined criteria as soon as it occurs
and store only those for analysis purposes. This selection process needs
to happen before the next event occurs and at CMS, we utilize very quick
hardware and software tools that have the physics details programmed in
them. The CMS triggering architecture is designed on two levels, the
Level 1 Trigger (L1) and High Level Trigger (HLT) as shown in the
diagrammatic representation in Fig: 3.4 .

There are several ways one can employ the use of L1 and HLTs in an
event, such as triggering on high energy photons, muons, jets, track
multiplicity and HF energy deposits etc. Due to the limit of writing
data, several of the triggers are prescaled, which means that those
events are only written a fraction of the time. A prescale of 2, means
that once every two events, that particular event is written down to
tape. As we go to lower @xmath jet triggers, the prescale value
increases due to the increased cross-section. More details on the
implementation and usage can be found in this recent extensive review [
98 ] .

#### 3.2.2 Collision centrality

The notion of event centrality was brought up and discussed in the last
chapter with respect to the glauber model. In reality, it is essential
to classify an event’s centrality using an experimental observable since
the impact parameter is not accessible directly. The centrality variable
also has to be de-correlated from the main observable of interest, to
avoid systematic biases in the measurement. For example, when the main
observable is say the average track density in a certain detector
region, the results would be biased if the events are split into
different centrality classes based on the multiplicity in the event. But
there are other measurements such as the flow Fourier harmonics, which
we looked at in the last chapter, where it is very interesting to study
the effect of system size for events with the same overall multiplicity.

In our published CMS papers, we have so far utilized two different
estimations of an event centrality; total energy deposited in the HF
calorimeters in PbPb [ 99 ] and the offline track multiplicity in pPb [
100 ] as shown in Fig: 3.5 . In both these methods, the distributions
are normalized to unity and bounds are chosen to represent a percentage
fraction of the events. For example, 0-10% represents events with the
highest HF energy deposited (or largest number of tracks) and these are
called as the most central collisions and similarly 80-100% refers to
peripheral collisions. Since the probability to have a central collision
is smaller compared to peripheral collisions, there is a general need
when studying hard probes to have maximal statistics possible.

### 3.3 Jets in the detector

Jets are the main actors in this thesis. The definition of a jet ² ² 2
Colloquially, one says that a jet is a jet is a jet and in practice, a
jet is whatever the fastjet algorithm returns. is primarily an agreement
between experimentalists and theorists on their cluster algorithms as
was done in the SNOWMASS accord [ 101 ] in June 25th 1990 (which
incidentally is only a couple of months after I was born indicating a
rather curious connection). A jet represents a collimated spray of
particles originating from a parton characterized by a lateral size
limit and lower momentum cutoff. The lateral size limit is often called
as the distance parameter or the jet radius and is described as a
physical distance, for example in the @xmath plane. To get an idea of
the jet radius, for a detector like CMS, a jet of R=4 would encompass
the full barrel and cluster all final state particles in the event. The
jet radii selection should be done carefully for a given analysis since
it enforces an inherent selection on the fragmentation pattern and could
also provide some handle on signal versus background in a very dense
heavy ion environment. For searches of new physics in pp collisions,
typically jets of a large size of R=0.7 or R=1.0 are used to fully
contain the decay products of boosted objects. On the other hand, in
heavy ion collisions, one seldom uses a radius larger than R=0.5 and we
will quantify the effect in the upcoming chapters.

There many different ways one chooses to cluster these particles as
outlined in App: B but the main algorithm that is currently widely
accepted and used is the anti-k @xmath algorithm due to its infrared,
collinear safety and rather pleasing overall shape. The algorithm
clusters two objects if the distance between them

  -- -------- --
     @xmath   
  -- -------- --

is less than the distance between the particle and the beam

  -- -------- --
     @xmath   
  -- -------- --

Since CMS has both tracker and calorimeter systems, we can choose a
variety of object collections for the jet clustering algorithms. Jets
that are made from only tracks/calo towers are called track/Calo jets.
There is also another option unique to CMS that uses all detector
components which we shall go over in more detail in the coming sections.

#### 3.3.1 Particle Flow

The CMS Particle Flow (PF) algorithm [ 102 ] (sometimes referred to as
Global Event Description) takes into account particle tracks,
corresponding spatially matched calorimeter deposits (both ECAL and
HCAL) and muon tracks and combines them into a single object
representing as close to the original particle as possible. In its
essence, it tries to follow the path of a given particle through the
detector, collecting its energy deposits and momenta in every step of
the way to globally identify the particle as one of the following types
mentioned below and as shown in Fig: 3.6

-   Photons ( @xmath ) : No tracks in the tracker but deposit in the
    ECAL

-   Electrons ( @xmath ) : Tracks matched with a ECAL deposit

-   Charged Hadrons ( @xmath ) : Tracks matched with a HCAL deposit

-   Neutral Hadrons ( @xmath ) : No tracks in the tracker but energy
    deposited in HCAL

-   Muons ( @xmath ) : Tracks in the inner tracker and the outer muon
    chambers (cleanest signal) and characteristic double bent signal due
    to the inner solenoid’s magnetic field and the return iron yoke
    holding the muon systems.

In addition to the above mentioned categories of PF objects, the
algorithm can also distinguish between hadronic style energy deposits in
the HF calorimeter from electromagnetic style energy deposits based on
the characteristic shower shape. The interested reader can also refer
Rishi Patel’s PhD thesis [ 103 ] to learn how PF photons crucially
helped in finding the Higgs boson.

#### 3.3.2 Jet Energy Corrections

Due to the finite and segmented detector response, it is imperative to
apply corrections to the jets once they are clustered from reconstructed
objects. The convention in CMS is outlined in Fig: 3.7 with several
levels of jet energy corrections for data and MC [ 104 ] . We briefly
explain what they are and why they are needed.

-   Pileup correction : This is the first correction applied to both
    data and MC jets based on the influence of pileup events. In the
    heavy ion samples we have very less pileup contribution and hence
    this correction is not applied in our case.

-   Response : Derived from MC samples and is the first major correction
    based on matching generator level (particle/gen) jets to
    reconstructed level (reco) jets. They are estimated as a function of
    the @xmath and @xmath and only correct the jet @xmath .

-   Residuals : Secondary correction factors to be only applied on data
    by comparing MC to data. These residuals come in two categories as
    residuals as a function of @xmath and residuals as a function of
    @xmath .

    -   Dijets : Utilizing the use of dijet even topologies where there
        is inherent momentum conservation in pp collisions. By
        identifying one of the dijets in a given detector @xmath region,
        we can measure the momentum asymmetry with the other dijet pair
        as they are found in different detector regions.

    -   @xmath +Jet : The @xmath in such events where a boson scatters
        of a jet can be used as a reference for the jet’s @xmath .

-   Flavor : Purely MC based correction factor to account for the
    difference in the jet flavor (such as quarks vs gluons).

The correction factors and their associated systematic uncertainty
bounds for anti-k @xmath PF jets with R=0.5 are shown in top panels of
Fig: 3.8 as a function of the jet @xmath and the bottom panels as a
function of the jet @xmath . We see that the correction factor is the
largest for CALO jets (in gray) and the least for PF jets (in red). The
JPT jets (in blue) are essentially calo jets including the associated
track information and have a better performance than just calo objects.

While this is the standard case for pp collisions, for heavy ions (as we
have begun to expect), things are not as straight forward. Since we have
jet quenching, we cannot estimate residuals of any sort and the flavor
dependent corrections are based on MC models which do not completely
describe heavy ion collisions as saw earlier. An additional step for
heavy ion jets involve background subtraction which we will look at in
detail in the upcoming chapters.

#### 3.3.3 Jet Energy Scale and Resolution

Once these correction factors are applied to the reconstructed jets, the
jet energy scale (JES) and jet energy resolution (JER) can be estimated
by plotting the ratio of the corrected jet @xmath with the spatially
matched particle level jet @xmath at the generator level [ 105 ] . The
mean (or @xmath ) of this distribution, as shown in Fig: 3.9 is the
overall jet energy scale or response and the width (or @xmath ) is known
as the resolution for a given jet @xmath window and @xmath selection.
The distributions are usually fitted with a gaussian or a crystal ball
function to extract these parameters.

The goal of the jet energy correction factors is to get the jet energy
scale or response as close to 1 as possible at the same time reducing
the resolution. The JES before and after the corrections is shown in
Fig: 3.10 . The left panel shows the response from MC without any
correction factors as a function of the jet @xmath for a variety of
@xmath selections represented by different markers. The plot also shows
the important detector regions covered such as the barrel, endcaps,
detector gap in @xmath and the forward calorimeters. After applying JECs
we can see the corrected response on the right panel of Fig: 3.10 as a
function of the particle jet @xmath and its within @xmath for all @xmath
and @xmath ranges.

## Chapter 4 Measuring the Jet Cross Section

Experiment is the sole source of truth. It alone can teach us something
new; it alone can give us certainty.

– Henri Poincare

The main observable we are trying to measure is the double differential
jet cross section defined as

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where @xmath is in the integrated luminosity and its measured in bins of
jet @xmath and @xmath .

In this chapter we shall go over the necessary analysis steps one has to
undergo in order to measure the jet spectra in different systems such as
pp, pPb and PbPb. We begin the chapter with event selection criteria and
discuss the influence of pileup events on our sample followed by studies
of the heavy ion background and the relevant background
subtraction/noise suppression techniques for jets.

### 4.1 Event selection and pileup rejection

In addition to the standard event selection criteria discussed in the
last chapter, for all three kinds of events, pp, pPb and PbPb, we choose
events where the primary vertex was situated in the barrel ( @xmath cm).
This selection ensured charged particles arising from the collision,
would be measured by the tracker and thus offer better reconstruction
performance. With regards to pileup, both the pp and pPb datasets were
collected with negligible pileup and thus did not cause any problems. On
the other hand, the PbPb dataset had a very small number of pileup
events (affecting roughly @xmath of the dataset) and for this particular
analysis, they were removed by applying a selection as follows. Firstly
we can isolate them via correlations between deposits in the ZDC and the
HF. Due to calibration issues of the ZDC-Plus during the entire run, we
only rely on the ZDC-Minus information which is shown as the number of
neutrons, assuming one neutron deposits 1.35 TeV of energy in Fig: 4.1 .
The ZDC Plus and Minus correspond to which side of the CMS detector the
ZDC sits, with Plus along the direction of the counter-clockwise beam
and Minus the opposite side.

Events that have two mid-central collisions instead of a single
ultra-central event, i.e pileup events, are expected to have more
spectator nucleons in the HF. Therefore we can isolate such events as
having very large HF energy deposit but not corresponding ZDC events.
Based on the band present in the minimum bias events shown on the left
of Fig: 4.1 we apply a straight line cut of shown in red and declare
events above the line as pileup.

Secondly we can also tag events with large number of jets by comparing
the number of pixel hits to the number of high @xmath @xmath
reconstructed jets as shown in Fig. 4.2 for Data in the left panel and
for MC simulations in the right panel for @xmath central collisions.
Area above the black dashed line represents the cut selection. As can be
seen in Fig: 4.2 , MC simulations and data differ for the large counts
of pixel hits. Events with a large pixel hit count (top of the black
dashed line) in data are removed.

We can see the effect of these two cuts on the HF Energy Sum (on the
left) and the pixel multiplicity (on the right) of Fig: 4.3 . The large
tail of pileup events extending to the higher energies and
multiplicities has indeed been removed by the application of both these
cuts.

### 4.2 Underlying event and background subtraction in heavy ion
collisions

In the context of heavy ion collisions, the underlying event is
fluctuating on an event by event basis as one would expect, but also
fluctuating inside a given event per centrality class since you can have
a variety of flow modulations. As we see in Fig: 4.4 , we have two
events that fall into the same central window, but end up having very
different structures; on the left we see an elliptical event but on the
right we see a more triangular structure. Any estimate of the background
needs to have a dependence, not only on the overall particle density but
take into account the flow behavior as well.

Since we are particularly interested in studying the impact of jets and
the medium, Fig: 4.5 shows a cartoon-like, but meaningful insight into
how a jet interacts with the background. In addition to sitting atop a
fluctuating uncorrelated background, jets bring with them a correlated
background.

#### 4.2.1 Embedded MC simulations

The most popular underlying event MC models are HYDJET (HYDrodynamics
plus JETs) which treats heavy ion collisions as a superposition of the
soft, hydro-type state and the hard state resulting from multi-parton
fragmentation [ 109 ] and HIJING (Heavy Ion Jet INteraction Generator)
which combines perturbative-QCD inspired models for multiple jet
production with low pT multistring phenomenology [ 110 ] . Both these
primarily deal with the underlying event in complementary ways and in
experiments at the LHC, we have utilized these for the study of jets by
embedding PYTHIA hard scattered events in them. A visual example of a
single event embedding is shown in Fig: 4.6 , the top panel a sample
PYTHIA dijet event and the bottom panel is the same event after
embedding a HYDJET background event.

The overall underlying density for a cone of R=0.4 in that event at 5.5
TeV, is around 100 GeV. Which means that, if we had a jet of say 150
GeV, it could be a 50 GeV jet sitting on top of the background and we
need to compare it to a 50 GeV pp jet once we perform background
subtraction.

#### 4.2.2 Background subtraction techniques

Fundamentally, the goal of any UE subtraction technique would be to
remove the uncorrelated background leaving the jet structure intact.
This is pretty hard in practice where there is no way to distinguish if
one final state particle belongs to the initial hard scattered parton or
just part of the UE. If we are just concerned about the jet’s momenta,
then a possible way would be employ what is known in the community as a
@xmath -subtraction meaning @xmath where @xmath is the UE density and
@xmath is the area of the jet given by fastjet. This method is fine for
first order estimations, but beyond that, there are several issues to
consider; how @xmath is estimated, lack of account for fluctuations,
insensitive to jet fragmentation etc.

For our analysis, we have utilized an algorithm designed to deal with
backgrounds and their fluctuations called iterative pileup subtraction [
113 ] . The algorithm as its implemented in CMS can be seen in Fig: 4.7
with 4 basic steps. It clusters the PF objects into pseudo-towers based
on the HCAL geometry ( @xmath ) for an event and divides an event into
strips of @xmath . For each strip in eta, we take the mean and the
standard deviation @xmath from the distributions of the pseudotower
energies and subtract from each tower the @xmath . All towers that go
negative are zeroed otherwise they would be unphysical during
clustering. Then we cluster the event into jets and the jets, above a
certain @xmath cutoff are removed from the event. After this step, we
essentially recompute the mean and sigma for each strip and do the
subtraction, following which the jets are put back into the event. This
way, for a given jet radii, the effect of the subtraction to the
correlated background is minimal.

The HYDJET used in our simulations is tuned to match the distributions
in data for particle/track density and the flow modulations. To study
the background in PbPb events, data and PYTHIA+HYDJET simulations are
compared. The correction to the jet @xmath obtained from this iterative
subtraction technique (called “raw subtracted @xmath ”), for a jet with
distance parameter @xmath is estimated by taking the difference between
the sum of all the PF candidate @xmath in a @xmath cone and the raw jet
@xmath . The @xmath is defined as the distance of the PF candidate from
the reconstructed jet axis in the @xmath plane

  -- -------- --
     @xmath   
  -- -------- --

The distributions of raw subtracted @xmath for @xmath jets, from
peripheral to central collisions are shown in Fig. 4.8 for two different
reconstructed jet @xmath selections. Data are shown with filled circles
and simulations with histograms. There is a good agreement between the
two in all centralities and jet @xmath bins. A similar level of
agreement is also seen for @xmath and @xmath .

The average raw subtracted @xmath and its root mean square (RMS) values
are shown in Fig. 4.9 as a function of the reconstructed jet @xmath ,
from central to the most peripheral collisions. Data are shown with
markers and are compared with the PYTHIA+HYDJET generated events shown
as histograms. The average raw subtracted @xmath decreases, from the
most central to peripheral events, as expected, and distributions show
reasonable agreement between data and PYTHIA+HYDJET .

### 4.3 Single jet triggers and the combined jet spectra

In the last chapter, we realized the need to collect data triggered on
physics objects such as high @xmath jets since its very inefficient and
sometimes impossible to collect all the data in a minimum bias way at
CMS. For this thesis, HLT single jet triggers were primarily utilized in
all three collision systems and the trigger efficiency for one such
trigger (HLT @xmath Jet80) in PbPb events is shown in Fig: 4.10 as a
function of the jet @xmath for different radii. The trigger HLT @xmath
Jet80 corresponds to a high level trigger that selects an event if the
corresponding reconstructed object, in this case a calo jet of R=0.5
clustered with the iterative cone algorithm, is greater than @xmath
@xmath . The jet spectra from such single jet triggered events are used
to stitch together a minimum bias jet spectra with the use of trigger
combination methods as described below.

#### 4.3.1 Primary method with three triggers

In order to extend the reach of the jet spectra, datasets from high-
@xmath single jet triggers with three different jet thresholds were
combined together in both pp and PbPb collisions. The jet triggers that
are used are: HLT_HIJet55, 65 and 80 for PbPb data and HLT_PAJet40, 60
and 80 for pp data.

The entire sample is split into three exclusive categories:

1.  JetC = “ @xmath ”

2.  JetB AND NOT JetC = “ @xmath ”

3.  JetA AND NOT JetB AND NOT JetC = “ @xmath ”

where A, B and C are the three thresholds, from smallest to largest.
Taking into account that threshold C is always unprescaled, the weight
factors applied to stitch the sample together are:

1.  @xmath

2.  @xmath

3.  @xmath

The run-averaged pre-scale factor for a given trigger X, denoted @xmath
, is determined by counting the fraction of events which fire the
unprescaled trigger (C), that also fire trigger X. The procedure can be
described by calling the three exclusive categories @xmath , @xmath ,
and @xmath , where the aim is to recover the original unprescaled
categories @xmath , @xmath , and @xmath . Since the JetC trigger is
unprescaled, this category is a trivial one: @xmath = @xmath . @xmath ,
however, is the most complicated category, due to the overlap between
triggers B and C, and the fact that trigger B is prescaled. Naively, one
may assume that the simplest method to obtain @xmath from @xmath is to
simply scale @xmath by the prescale factor @xmath . However, this then
leaves a difficult exercise for recovering @xmath from @xmath . Since
trigger A should fire for any events that fire trigger B, there will be
some “unlucky” events that should have fired trigger B and should be
counted in @xmath , but were prescaled away by trigger B and caught by
trigger A. Therefore, simply scaling up each category by the respective
trigger prescale factor will double-count events in @xmath . The method
described here essentially relies on the trigger A to recover the
majority of @xmath , by scaling up those events by @xmath . Then, the
remaining events in @xmath are recovered by trigger B. Finally, once
@xmath is taken care of, @xmath is obtained by simply scaling the @xmath
events by the prescale factor @xmath , since there is no other trigger
overlap. In other words, if we break @xmath into two pieces, namely the
events that should have only fired trigger A (“ @xmath ”) and events
that should have fired trigger B, but were prescaled away (“ @xmath ”),
we can say:

1.  @xmath

2.  @xmath

3.  @xmath

but then since @xmath , we can say:

1.  @xmath

2.  @xmath

and we recover the original algorithm. The trigger combined and
individual HLT jet spectra with the aforementioned method in pp data is
shown in Fig: 4.11 as a function of the jet @xmath .

#### 4.3.2 Extended approach with multiple triggers

Since we increased the number of jet triggers in pPb collisions, a new
different approach to combine the triggers was utilized. The events are
classified according to the HLT trigger path by using the effective
prescale value from each jet triggers, and then normalize to the
luminosity recorded in the last trigger bin since no pre-scale is done
in our highest HLT trigger path. The sample is categorized into five
groups according to its HLT trigger based on the trigger @xmath and then
divide into different @xmath bins:

1.  MAX(triggerPt) @xmath threshold @xmath = “ @xmath ”

2.  threshold @xmath @xmath MAX(triggerPt) @xmath threshold @xmath = “
    @xmath ”

3.  threshold @xmath @xmath MAX(triggerPt) @xmath threshold @xmath = “
    @xmath ”

4.  threshold @xmath @xmath MAX(triggerPt) @xmath threshold @xmath = “
    @xmath ”

5.  threshold @xmath @xmath MAX(triggerPt) @xmath threshold @xmath = “
    @xmath ”

where A through E are the five @xmath thresholds, from smallest to
largest, of the five triggers used and MAX(triggerPt) refers to the
maximum value of the online transverse momentum observed by the triggers
and used to calculate the trigger decisions. The weights applied to each
sample are simply:

1.  @xmath

2.  @xmath

3.  @xmath

4.  @xmath

5.  @xmath

where “PS” again refers to the prescale factor of a particular trigger.
The left panel of Fig. 4.12 shows the trigger combined spectra (open
black circles) as a function of the jet @xmath along with the different
colored markers as individual HLT spectra. The relative contribution of
the different triggers to the combined spectra is shown on the right
panel of Fig. 4.12 .

### 4.4 Jet finding efficiency

The performance of the jet reconstruction algorithm in the experiment is
characterized by comparing the reconstructed jets (RecoJets) in MC
simulations to the generator jets (GenJets). The RecoJets and GenJets
are matched by position within @xmath jet Radius. The @xmath of the
matched pairs is compared for different systems and in the case of PbPb,
different centrality selections. For each selection, the ratio of
RecoJet to GenJet @xmath is found. Fig: 4.13 - 4.14 show the jet finding
efficiency calculated in PbPb MC and pPb for different centralities and
we find it to be less than @xmath for @xmath @xmath . For the efficiency
as a function of generator level jet @xmath , the drop in efficiency are
covered by the statistical error bars and also includes lower @xmath
jets where the efficiency is a bit lower.

The same procedure is also performed for pPb collisions as shown in Fig:
4.14 where we see a similar performance compared to peripheral PbPb
events. The different markers represent different @xmath bins since the
system is asymmetric (more about that in the upcoming chapters when we
study the physics of pPb collisions).

### 4.5 Jet Energy Scale and Response

The jet energy resolution(JER) and scale (JES) were derived from pythia
and pythia+hydjet generated events. The JER and JES were studied in bins
of generated jets (GenJet) @xmath . The pp studies have no background
subtraction and the PbPb studies (Figs. 4.15 ) include the iterative
background subtraction. Jets from pp collisions are shown in red
(duplicated across all centralities), and for PbPb in black.

The same study was performed for pPb collisions with and without the
background subtraction procedure as shown in Fig: 4.16 for different
radii jets, except in this case, PYTHIA is embedded with HIJING events.
The left and right panels correspond to p going to negative and positive
direction respectively.

### 4.6 Residual correction from dijet balance

The dijet @xmath balance technique as described in the previous chapter
can be used to correct the jet relative response in pp collisions. Two
leading jets in the interval @xmath are selected followed by selection
of the reference jet within @xmath . The probe jet has to be within
@xmath . If both jets are within @xmath then one jet is chosen at random
to be the reference jet. If neither jets are within @xmath then the
event is not used. To study the detector relative response, dijet
balance for each event is calculated as:

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

where @xmath is the average @xmath of the two jets:

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

To suppress 3-jet event contributions, events were required to satisfy
@xmath and @xmath . Furthermore, events had to fall within one of the
following @xmath ranges to be used in the final analysis. The ranges
were 40 - 60 GeV/c, 60 - 80 GeV/c, 80 - 100 GeV/c, 100 - 140 GeV/c, and
140 - 200 GeV/c. These distributions were plotted for data and MC in
Fig. 4.17 and Fig. 4.18 for the 40 @xmath 60.

Taking the average value of B, @xmath , in a @xmath bin, the relative
response, @xmath , was computed:

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

The corrections are estimated for pp and pPb collisions, as a function
of jet @xmath and applied to the jet spectra. This particular procedure
(and other residuals such as @xmath + jet) cannot be performed in PbPb
events because of quenching. Thus the jet energy scale systematic
uncertainty is always larger for PbPb when compared with pp or pPb.

### 4.7 Dealing with mis-reconstructed low @xmath PbPb jets

As we saw in the previous sections, the background in heavy ion events
is quite large and for low @xmath jets, it becomes very hard to
distinguish between “real” jets and mis reconstructed jets. We use the
term real in quotes since it is not possible to accurately say in a
collision if a given final state object originated from the hard
scattering or not due to several non global effects. At the same time,
it is a given that the background will affect some fraction of jets at
that kinematic range and thus different experiments employ different
techniques to remove this contamination.

The commonly used method to remove this soft background contamination is
to require the presence of a hard final state object in the jet. A
method to remove this contamination, used in other experiments [ 114 ,
115 ] , is to select jets with a requirement on the leading
charged-particle track or calorimeter energy deposit among the
constituents of the jet. With this requirement, it is possible to remove
a lot of jets made up of uncorrelated soft components, but it also
introduces a fragmentation bias that is not negligible at low @xmath .
Some experiments try to correct for this bias by estimating its impact
with a MC but since gluon fragmentation is still an open question, even
in pp collisions, this correction comes with a large uncertainty that is
often not quoted.

#### 4.7.1 Data driven unbiased approach

In this analysis, a novel data-driven technique, based on control
regions in data, is introduced to derive the spectrum of
misreconstructed jets from the minimum bias sample. This spectrum is
then subtracted from the jet-triggered sample. Two methods, operating in
different kinematic regimes, are combined to get a correction factor.
The first method (labeled the trigger object method) selects all events
with a leading HLT jet @xmath of less than 60 @xmath as a control sample
potentially containing misreconstructed jets. This @xmath threshold is
chosen based on analysis of random cones in minimum bias events, with
the leading and subleading jets removed.

The second method (labeled the dijet method), performed in parallel with
the first method, selects minimum bias events with dijets, which can
originate either from a hard scattering or fluctuating background. There
are two thresholds defined in this method, one for the leading jet (
@xmath @xmath ) and another for the subleading jet ( @xmath @xmath ) in
the reconstructed event. If an event fails any of the following
selections, it is tagged as a background event. An event is tagged as a
signal if it passes all of the criteria: Leading jet @xmath @xmath
@xmath @xmath and @xmath and subleading jet @xmath @xmath @xmath @xmath
.

To choose the thresholds for the dijet selection, the mean and RMS of
the subtraction step in the iterative subtraction algorithm are mimicked
by applying a cutoff on the transverse energies of the PF towers used in
the random cone study as shown in Fig: 4.20 . The distribution plotted
is essentially the subtracted event and it is represented as the
difference between the amount of energy present in the region of the jet
and the amount of energy subtracted plus the jet’s momenta. The RMS of
the background subtracted event energy distribution is used as an
estimate of the fluctuation. The thresholds are set as follows: @xmath
@xmath for the leading jet, and @xmath @xmath for the subleading jet, to
allow for jet modification in the medium.

Since these two methods operate in different kinematic regimes, the
average of the two is used to estimate the data driven correction factor
for misreconstructed jet rates as can be seen in Fig. 4.21 , as a
function of the jet @xmath . These rates for different distance
parameters are shown in the different panels (left: @xmath , center:
@xmath , and right: @xmath ). The symbols correspond to the centrality
bins in the analysis. The minimum bias background jet spectra are then
normalized to a per-event yield and the background is removed from the
measured jet spectra, resulting in an inclusive jet spectrum without
fragmentation bias.

A thorough suite of systematic studies of the data driven method was
tested on heavy ion MC events. The correction, estimated in a similar
way from PYTHIA dijet events, where one does not expect any background,
is added as an additional systematic uncertainty, starting from 6% at 70
GeV to 1% at 100 GeV.

The data driven method was also applied to PYTHIA+HYDJET simulations
without quenching and, using the same @xmath threshold, this yielded a
recovery efficiency of greater than 98% for signal jets and background
acceptance of less than 3% as shown in Fig: 4.22 as a function of jet
@xmath The different markers point to different centrality bins and the
panels go from R=0.2 in the left to R=0.4 on the right. Both these
percentages are much smaller than the systematic uncertainty bounds of
the method and thus gives us confidence in the approach undertaken.

### 4.8 Unfolding the jet spectra

The term “unfolding” is used to describe a set of techniques which are
used to essentially “invert” the convolution of the spectra and the
resolution. This is a non-trivial mathematical problem because the jet
@xmath spectra are falling very steeply and the resolution is derived
from MC simulations and therefore is not known exactly. Even if the
transformation matrix due to the resolution were known exactly,
statistical fluctuations in the measured spectrum can be transformed
into unphysical large fluctuations in the unfolded spectra.

With binned histograms for the spectra, the unfolding problem can be
understood as the matrix inversion to solve

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

with the correspondence

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

The unfolding procedures use a response matrix with Monte Carlo
simulation (training), and then attempts to reconstruct the true
distribution from the measured distribution with this response matrix.
Figures 4.23 , 4.24 show the response matrix from MC that is used in the
analysis. The response matrix shows the distribution of reconstructed
jet @xmath (RecoJet) in comparison to generator level jet @xmath
(GenJet), finely binned in the actual bins used in the unfolding
analysis for PbPb and pp. All the MC samples used to construct the
matrix were weighted by the event cross section to properly merge
different @xmath samples. Additionally, the MC samples are weighted by
the jet triggered data centrality and primary vertex distribution.

The pPb response matrix built with embedded pythia+hijing events is
shown in Fig: 4.25 derived using the same procedure as described above.

#### 4.8.1 Kinematic efficiency

The data kinematic range based on the trigger efficiency is chosen to be
from @xmath GeV/c. Since the response matrix is built up by our MC
datasets which start from a @xmath GeV/c (where @xmath is the transverse
momentum of the subprocess in the 2-2 scattering) we need to apply a
reco level cutoff in the normalized response matrix corresponding to the
same kinematic range of our data spectra. This effectively reduces the
possible @xmath bins a given detector smeared jet can end up in the
generator side. This is estimated by looking at the normalized matrix’s
projection onto the generator axis before and after the reco level cut
and the correction factor (as shown in Figure 4.26 for @xmath jets in
PbPb and PP) is applied to the unfolded spectra.

#### 4.8.2 Bayesian and bin-by-bin unfolding

Bayesian unfolding [ 116 ] uses the input MC truth and reconstruction
information to create a smearing matrix. Using probability theory, the
physical quantity of the jet @xmath spectra is unfolded from the
detector effects which modify it. Apart from the provided implementation
of the root-based unfolding ( roounfold [ 117 ] ), we implemented the
standard Richardson–Lucy [ 118 , 119 , 120 ] method ourselves.
Correlated error propagation through the Bayesian unfolding is done by
taking (numerical) partial derivatives with respect to the input
spectrum, and then propagated through the entire Bayesian unfolding.
Bayesian unfolding here is performed with 4 iterations. The choice of 4
iterations is twofold: first it is the default and recommended number of
iterations for Bayesian unfolding, second, that four iterations provide
reasonable closure when tested in MC.

Unlike Bayesian unfolding, which allows for the migration of events
between bins, the bin-by-bin method assumes no migration, and thus
corrects for detector effects only in the height of each jet @xmath bin.
Bin-by-bin unfolding can be a valid technique in the case where
resolution is much smaller than bin size.

#### 4.8.3 Unfolding using SVD

For pp and pPb collisions, we show the main physics results with the
Singular Value Decomposition(SVD) unfolding methods. For the (additive)
LLS method, an “initial guess” @xmath is used to scale the problem such
that the unfolding does not have to exhaust its total degrees of freedom
(DOF) to purely reproduce the steeply falling spectrum shape. The
standard method to perform Phillips–Tikhonov regularization is the
generalized singular value decomposition (GSVD), which is available in
the RooUnfold program.

The correct value for the regularization parameter is determined by
looking at the Pearson coefficients and by studying the values of the
@xmath vector which is the data expressed in the basis vectors of the
response matrix. These @xmath are normalized by the error and
statistical fluctuations of unity and the values of @xmath where @xmath
are the statistically significant equations in the linear system. The
Pearson coefficients for @xmath and for the @xmath centrality bin (for
example) is shown in Fig: 4.27 . For all @xmath PbPb centrality classes
and pp, the @xmath vector is shown in Fig. 4.28 . The unfolded spectra
can then be re-folded to test the effectiveness of the unfolding. In
Fig. 4.29 , we see that the folded spectra is similar to the measured
spectra and is within the total uncertainties. Based on the studies for
the different centrality classes and jet radii, we find the
corresponding @xmath value where the @xmath vector gets to the value
@xmath . These values are collected in table 4.1 . Comparisons of folded
and unfolded spectra are shown in Fig. 4.29 for R=0.3.

Monte Carlo closure has been performed to verify the validity of the
unfolding methods. Fig. 4.30 - Fig. 4.31 show the closure test for the
Bayesian, bin-by-bin and SVD unfolding methods with pp, pPb and PbPb MC
samples. This is done by taking half of the MC sample as ”data”, and
utilizing the other half as the prior to unfold the ”data”. The jet
spectra for unfolded, reconstructed MC jets from the ”data” are compared
to the generator level jets. The ratio of unfolded jet spectra to
generator level jet spectra and the ratio of measured jet spectra by
generator level jet spectra are compared to show the closure of the
Bayesian and bin-by-bin methods.

#### 4.8.4 Statistical error propagation

While for SVD method we use the kCovToy option and propagate the
estimated statistics uncertainties, in Bayesian unfolding, the unfolded
jet spectra’s statistical error information is lost. We can perform a
data driven approach where we randomly generate a large set of jet
spectra using a gaussian distribution for each @xmath bin which upon
unfolding will give us another gaussian distribution (as shown in Figure
4.32 ) of the bin content per @xmath bin in our final spectra.

### 4.9 Estimating systematic uncertainties

An experimental measurement is incomplete without an estimate of
systematic uncertainties and how they affect the result. For a
measurement of the jet spectra, the systematic uncertainty due to a
particular sources is estimated as overall change in the final spectra
due to finite variations in the source.

The unfolded jet spectra for R=0.3 jets has an overall systematic
uncertainty of @xmath . We have clumped the unfolding with the JES
systematic uncertainty together since they both affect the overall
energy scale. A residual jet energy correction, using the dijet balance
method [ 104 ] , is derived and applied to the jets from pp collisions.
It corresponds to less than 1% correction to the jet @xmath . There is
an additional uncertainty on the integrated luminosity of @xmath which
is estimated by running van der merve scans during the same data
collection period. The systematic uncertainties from the different
sources are shown in Fig: 4.33 as a function of the jet @xmath for R=0.3
jets.

A summary of the systematic uncertainties in the jet spectra in pPb
collisions, the jet yield asymmetry measurements in pPb collisions, the
reference pp spectra, and the nuclear modification factors @xmath are
listed in Table 4.9 . The uncertainties depend on the jet @xmath and
pseudorapidity, and the table shows representative values in two jet
@xmath and @xmath ranges. The uncertainties vary smoothly between these
ranges. The total systematic uncertainties listed for the nuclear
modification factors @xmath do not include the scale uncertainty of 4.3%
from the integrated luminosity measurements in pPb (3.5%) and pp (2.4%)
collisions. The luminosity uncertainties cancel in the measurements of
the jet yield asymmetry. The remaining uncertainties are partially
correlated in jet @xmath , with the unfolding uncertainty dominating at
low jet @xmath and the JES uncertainty dominating at high jet @xmath .

The jet response matrix is smeared by 1%, at both the generator and
reconstructed levels to account for variations in the simulations.
Separately the regularization parameter used for the unfolding is varied
between 4 and 8 resulting in at most 8% systematic uncertainty for the
PbPb jet yield. The JER uncertainty is estimated for each @xmath bin in
the analysis and is found to be at most 3%, for both pp and PbPb.
Studies of the underlying event fluctuations in jet-triggered and
minimum bias events show a contribution of up to 5% to the uncertainty
of reconstructed jet yields based on differences between data and
PYTHIA+HYDJET quantified in the right side of Fig. 4.9 . The
contributions due to jet reconstruction efficiency, detector noise, and
unfolding response matrix smearing are about 1% each. Since in PbPb, the
per-event jet yield is being measured, there is a 3% uncertainty on the
number of minimum bias events and there is no uncertainty quoted for the
luminosity. The overall systematic uncertainties from the different
sources are shown in Fig: 4.34 for R=0.3 jets.

## Chapter 5 Baseline Measurements in p-p and p-Pb Collisions

“An experiment is a question which science poses to Nature, and a
measurement is the recording of Nature’s answer.”

– Max Planck

### 5.1 Baseline measurements

As we have introduced in the previous chapters, measuring the inclusive
jet cross section in an important fundamental test of QCD. In line with
excellent CMS jet measurements [ 121 , 122 , 37 ] , we focused on the
inclusive jet cross section at 2.76 TeV for small radii jets, such as
0.2, 0.3 and 0.4 so that we can highlight the maximal deviation from
present state of the art theory calculations. We then proceed to pPb
collisions at the LHC and look at measurements of the inclusive jet
cross sections and study any possible effects cold nuclear matter
effects by comparing with an extrapolated pp reference spectra at 5 TeV.

### 5.2 Jet spectra in pp collisions

The inclusive differential jet cross sections in pp collisions at 2.76
TeV are shown in Fig. 5.1 for three different distance parameters. A
comparison is made to NLO pQCD [ 38 ] calculations with the fastNLO
framework including non-perturbative (NP) corrections. These
calculations are shown for two parton distribution functions (PDF) sets:
NNPDF 2.1 [ 29 ] (red stars), and CT10N [ 123 ] (purple triangles)
including such as multi-parton interactions and hadronization. The
bottom panel of Fig. 5.1 shows the ratio of the data for jet cross
sections in pp collisions to theoretical calculations. The agreement
with data gets better at larger distance parameters. In Ref. [ 122 ] the
ratio tends closer to unity for jets with R = 0.7. The theoretical
uncertainties shown are due to variations of the strong coupling
constant and the parton shower, factorization scales involved in the NLO
calculations for the different PDF sets.

#### 5.2.1 Theoretical progress for small R jets

In our landmark result, we essentially showed an evolution of the jet
cross-section as a function of the jet radii and how theory calculations
at NLO+NP over estimated the data at small radii. There has been recent
interest in this field of small radii jets in p-p collisions since
phenomenologically, radii dependent corrections were always assumed to
be small at NLO but they turn out to be quite large at NNLO. We will
briefly go over two of the latest developments from our theory
colleagues including matching NNLO corrections with Leading Logarithmic
resummations (LL @xmath ) for small radii jets.

##### NNLO matched with LL@xmath

The overall jet cross section is sensitive to the perturbative series
involving terms such as @xmath and at high @xmath where @xmath is small,
the terms are under compensated by large logarithms in the @xmath when
we take the small radii limit. Calculations for the first order terms
are available in the literature [ 124 ] and NLL @xmath is still in
progress since it involves several additional complications that we will
not discuss here. At the leading log, there is an additional
contribution to the micro-jet cross section

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

where the micro-jet fragmentation function ( @xmath ) for micro jets
with a fraction of the parton’s energy. The additional term in the small
R limit is built into the @xmath and can be written as

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

where we have @xmath proportional to the casimir factor @xmath . There
is an angular scale @xmath which is set to 1 in this calculation and
when we set @xmath this functional @xmath turns into the regular
fragmentation function with a delta function at @xmath , where @xmath is
the fractional energy of the splitting.

This additional correction for small radii jets is actually large, up to
@xmath for R=0.2, in the framework. A matching procedure is also
introduced in this calculation to combine the cross section at the NLO
with LL @xmath

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where again, @xmath is the arbitrary radius of order 1, @xmath denotes
the pure NLO contribution, without the LO, to the inclusive jet spectra
and @xmath is the pure NLO within the LL @xmath resummation. This
matching procedure is conceptually handy when extending the calculation
to NNLO+LL @xmath as was done in Fig: 5.2 . Both NNLO @xmath and NNLO
@xmath LL @xmath very nicely match data for all the three jet radii
across the full @xmath range measured. An interesting feature to note is
that both data and theory systematic uncertainties are of a similar
magnitude. In order to estimate, which of NNLO @xmath vs NNLO @xmath LL
@xmath captures the data performance better, we need to reduce the
uncertainties in both data/theory and come up with novel observables
such as taking ratios of cross-sections in different kinematic ranges
etc.

##### Ll@xmath resummation in SCET

Within the soft collinear effective theory (SCET) framework, there has
also been recent work to estimate the radius dependence at fixed order [
125 ] . Similar to the resummation we saw above, a perturbatively
calculable function is introduced that describes the formation of an
observed jet coming from the fragmenting parent parton as a function of
the radii. In a recent paper, this function was outlined for a quark jet
as the sum of the leading order born diagram, modified splitting with
the AP and additional corrections including virtual partons, including
when the final state partons exists the jet. In this framework, the
inclusive differential jet cross section is compared with our CMS data
as shown in Fig: 5.3 . These theory curves do not have the NP
corrections added but still are able to perform much better than the NLO
calculation.

### 5.3 Asymmetric pPb collisions at the LHC

Proton lead collisions at the LHC offer an intermediary stage between pp
and PbPb. One does not expect the formation of the QGP in pPb collisions
and thus we can test any additional nuclear effects. We continue with
the same goal of studying inclusive jet production in the natively
asymmetric pPb collisions and comparing them with pp cross sections at
the same center of mass energy. Since there was no pp data at 5.02 TeV
in Run1, we compare it to an extrapolated reference spectra as will be
discussed in detail in the following sections.

#### 5.3.1 Jet Yields and asymmetries in production

The observation of inclusive charged hadron yield modification in pPb
collisions [ 126 ] resulted in the @xmath rises above unity in the high
@xmath region, which was explained by anti-shadowing. It is worthwhile
to repeat the same analysis with an independent observable to see if the
same effect can be observed in the jet production yield in pPb
collisions since jets can be better constrain our partonic kinematics in
the hard scattering process. We study the inclusive jet production in
different pseudorapidity ranges to measure possible modification of the
nPDF.

The unfolded inclusive jet spectra in pPb collisions at @xmath TeV are
shown in Fig. 5.4 for the following @xmath intervals: @xmath , @xmath ,
@xmath , @xmath , @xmath , @xmath and @xmath . The jet spectra from
different @xmath ranges are scaled by arbitrary factors described in the
legend to enhance visibility.

The pPb jet spectra are obtained in several pseudorapidity intervals.
The @xmath dependent jet cross section spectrum is studied by measuring
the jet yield asymmetry, @xmath , in various @xmath ranges, where @xmath
is defined as follows:

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

where @xmath , @xmath , @xmath and @xmath are the boundary of two
different @xmath intervals.

To study the @xmath dependent jet production, the backward-forward
asymmetry of the jet cross section ratio, @xmath , is calculated in Pb
going direction with respect to proton going direction in various @xmath
ranges. Figure 5.5 shows @xmath as a function of jet @xmath for @xmath ,
and @xmath intervals.

Figure 5.5 shows @xmath as a function of jet @xmath for @xmath , @xmath
, and @xmath regions.

Since the @xmath strongly fluctuates due to the statistics limitation at
large @xmath range, one can then study the @xmath dependence by dividing
the jet yields in different @xmath bins to the most central one ( @xmath
), Fig. 5.6 shows the jet production ratio in different @xmath bin to
the one in @xmath , it shows clearly @xmath dependent jet production
yield in pPb collisions.

Inclusive jet cross section ratios of various @xmath intervals to @xmath
for three selected jet @xmath ranges on the right panel of Fig: 5.6 .
The error bars on the data points are statistical uncertainties and open
boxes represent the systematic uncertainties in pPb collisions. The data
points are shifted in @xmath to enhance visibility of the uncertainty
boxes.

#### 5.3.2 Extrapolating a pp reference at 5 TeV

The pp reference at @xmath TeV is extrapolated from the published jet
cross section measurement in pp collisions at @xmath TeV [ 121 ] by
using the scaling factors calculated based on PYTHIA Z2 simulation. The
challenge of such an extrapolation is only one collision energy data is
available and also a difference cone size is used in pPb analysis
compared to pp published data.

A schematic of the extrapolation method used is given below:

1.  Compare data with PYTHIA and POWHEG for @xmath and @xmath

2.  Calculate scaling factor of collision energy dependence ( @xmath )
    by using PYTHIA and POWHEG calculation for @xmath and @xmath
    respectively

3.  Scaling the published data in pp collisions at @xmath TeV from
    @xmath or @xmath to obtain the inclusive jet spectrum for the same
    cone size at @xmath TeV

4.  Make the cone-size dependent cross section ratio at @xmath TeV using
    PYTHIA and POWHEG generators and available data points

5.  Calculate the cone-size dependent cross section ratio from PYTHIA
    and POWHEG

6.  Scale the jet spectra obtained in (3) in pp collisions at @xmath TeV
    from @xmath or @xmath to @xmath using the factors from (5) to obtain
    the jet spectra at @xmath

7.  Study the collision energy dependence for a fixed cone size jet from
    PYTHIA

8.  Estimate systematics during this extrapolation using NLO calculation
    as scaling factors

9.  Cross check with @xmath based interpolation using CMS published data
    [ 122 ] .

Figure 5.7 shows the extrapolated jet spectra in four absolute rapidity
intervals with an artificial scaling factor applied to enhance the
visibility.

#### 5.3.3 Nuclear modification factors - @xmath

These extrapolated pp spectra at @xmath TeV are then used to calculate
nuclear modification factor @xmath via:

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

where @xmath is the number of binary collisions, the @xmath nb @xmath is
the recorded luminosity in pPb collisions as determined in Ref. [ 128 ]
and @xmath is the mass number of the lead nucleus. The inclusive jet
nuclear modification factor @xmath as a function of jet @xmath for six
pseudorapidity bins are shown in Fig. 5.8 using PYTHIA based
extrapolated pp reference. No dependence on the jet @xmath is observed
in most of the rapidity bins, except the backward (Pb going direction)
ones where a weak decrease in the @xmath is observed. In the
mid-pseudorapidity bins, the nuclear modification is quite similar.
While at large rapidity, a clear separation of the @xmath between
forward and backward range, with proton beam direction has slightly
larger nuclear modification factors compared to Pb beam direction.

We also compared the CMS measurement with the ATLAS result except it was
for a larger jet radii ( @xmath vs @xmath ) in Fig: 5.9 with a different
method of extracting a pp reference. In both cases the results are
comparable and show the @xmath @xmath across the measured jet @xmath
range. The larger systematic uncertainties are mostly due to the pp
reference extrapolation.

Inclusive jets at high @xmath are predominantly composed of gluons and
light quarks, due to the low x region we end up probing. A natural
experimentalist question that follows is to ask if there is any
dependence on the mass of the quark that initiates the jet. To answer
this question, we measured the @xmath for jets that were selected as
b-jets.

### 5.4 Probing initial parton flavor dependence

The nuclear modification of jets in heavy ion collisions should depend
on the flavor of the fragmenting parton [ 74 ] . For example, under the
assumption that radiative energy loss is the dominant mechanism, gluon
jets are expected to quench more strongly than quark jets, owing to the
larger color factor for gluon emission from gluons than from quarks [
129 ] . There are also theoretical predictions that radiative energy
loss may not be dominant for heavy quarks, including models based on
collisional energy loss of quarks within the medium and models favoring
an interpretation based on mesonic recombination and disassociation
within the medium, e.g. Refs. [ 130 , 131 ] . It is expected that there
should be some mass-dependence of partonic energy loss at low momentum,
and therefore, b quark jet (b jet) energy loss might be different from
that of light quark jets [ 132 , 133 ] .

We will briefly go over the measurement of b-jet @xmath and please refer
to my friend and colleague Kurt Jung’s PhD thesis [ 134 ] for more
details regarding b-jets in CMS.

#### 5.4.1 Heavy flavor jet @xmath

When the b-jet @xmath is measured with respect to a PYTHIA based
reference, we see consistency between the pPb data and the PYTHIA pp
reference, indicating a lack of @xmath -dependent effects for each
@xmath selection. Fig: 5.10 shows the @xmath measurements for the same
four @xmath selections. The average values are consistent with unity
within uncertainties.

Fig: 5.11 shows the pseudorapidity-integrated @xmath . Fitting a
constant to this distribution returns a value of @xmath @xmath , which
indicates that the b jet yield in pPb is consistent with the pp PYTHIA
simulation, especially considering the 22% uncertainty on just the
PYTHIA reference. In addition, Fig. 5.11 shows the comparison of the
measured @xmath to predictions from a pQCD model that includes modest
initial-state energy-loss effects [ 136 ] . The model and data are
roughly consistent within the total systematic uncertainties from both
PYTHIA and the pPb data.

In this chapter we saw a selection of measurements in pp and pPb
collisions geared towards studying how well we can comprehend the
baseline from a theoretical standpoint. When we take into account the
latest theoretical developments at the NLO and LL @xmath , we find a
very good agreement for the inclusive jet cross sections. But that is
not the end of the story since the important parts of a jet measurement,
such as fragmentation and hadronization, are still model dependent and
we still do not understand them intuitively. There is a renewed effort
to go back to basic jet structure measurements, but this time, looking
at gluon jets ¹ ¹ 1 What is a gluon jet? Is it based on the originating
parton or the hardest fragmented object or the initial hard scattering.
This question is starting to take prominence in the literature again and
how to distinguish gluon from quark jets without a known/unknown bias.
at the LHC in order to tune our models and calculations.

## Chapter 6 Quantifying Jet Quenching In Pb-Pb Collisions

“If I have seen further it is by standing on the shoulders of Giants.”

– Sir Issac Newton

In the last chapter, we discussed the physics of the nuclear
modification factor in pPb offering evidence of no cold nuclear effects
on jet production and jet energy. In search of the hot nuclear effects
such as jet quenching, we report the measurement of the jet yield in
PbPb collisions for three jet radii and a variety of centrality classes.

### 6.1 Invariant jet yield

The unfolded jet cross sections for PbPb and pp events are shown in Fig.
6.1 for different distance parameters. The PbPb spectra are normalized
by the number of minimum bias events, and are scaled by @xmath , with
each centrality multiplied by a different factor, to separate the
spectra for better visualization. The pp reference data is normalized to
the integrated luminosity of the analyzed data set. The high @xmath
cutoffs for the spectra (hence also the @xmath ) are dictated by
statistical limitations.

The JES uncertainty ranges from 6–32% (from peripheral to central
events), varying due to the uncertainty in the heavy ion tracking and
the quark/gluon fragmentation. The fragmentation difference is extended
for PbPb jets due to expected asymmetric jet quenching effects for quark
and gluon jets. They are estimated in a MC sample by separating jet
collections as those originating from quarks or gluons and separately
estimating the JES and JER as shown in Fig: 6.2 . The pp is shown on the
top left panel and the other panels correspond to different centrality
classes. The black markers are for inclusive jets and the green and red
correspond to gluon and quark jet. Half of the spread between the quarks
and gluons is chosen as the additional JES systematic uncertainty on the
PbPb jet yield.

### 6.2 Inclusive jet nuclear modification factors

The jet @xmath , calculated from the PbPb and pp spectra after all
corrections including SVD unfolding, are shown for different distance
parameters in Fig. 6.3 . The jet @xmath decreases with increasing
collision centrality in the range of the measured jet @xmath . Within
the systematic uncertainty, the jet @xmath shows the same level of
suppression for the three distance parameters. Systematic uncertainties,
from different contributions to the jet @xmath from the individual
spectra in pp and PbPb collisions, are summed in quadrature with an
overall uncertainty of 19–40%, from peripheral to central collisions for
@xmath jets.

To focus on the centrality dependence of the jet @xmath , two ranges of
jet @xmath are selected and the corresponding jet @xmath values are
plotted as a function of the average number of participants ( @xmath )
in Fig. 6.4 , for jets of @xmath @xmath @xmath and @xmath @xmath @xmath
@xmath . The systematic uncertainty is shown in the three bounds of
lines for @xmath (dotted), 0.3 (solid), and 0.4 (dashed) jets. The jet
@xmath shows a clear trend of increasing suppression as the number of
participants in the PbPb collision increases. Overall, in the kinematic
range explored, the @xmath show the same level of suppression across the
three distance parameters.

### 6.3 Comparisons with theory

Comparing data with predictions is an important theme of my work so far
and thus in this section, we shall go over several different models of
jet energy loss and see if they can accurately predict the jet @xmath ,
a hallmark heavy ion measurement.

##### Toy Model of Energy Loss

Lets begin by understanding the impact of energy loss on the jet @xmath
. Fig: 6.5 shows the @xmath for inclusive jets with two different
methods for energy loss; losing an fixed amount of @xmath per jet on the
left and losing a fraction of the jet’s @xmath with different colored
markers pointing to different energy/fractions. The main difference
between the two emulations, as performed in PYTHIA for R=0.3 anti-k
@xmath jets, we see that when a jet loses a standard amount of energy
due to quenching regardless of the jet’s @xmath , the @xmath has a
increasing behavior as one would expect. On the other hand, the @xmath
has a slight decreasing tendency when one loses a fraction of the jet’s
@xmath and in both cases, when one increases the amount of
energy/fraction, the @xmath decreases. By looking at the trend in data,
one can naively estimate the behavior of energy loss.

##### Jewel

JEWEL [ 137 ] is a pQCD based model of energy loss and we will discuss
it in further detail in the next chapter. For now, all we need to know
is that for the jet @xmath observable, JEWEL does a good job of
reproducing the data as shown in Fig: 6.6 for the different radii.

##### SCET-g

The SCET-g framework [ 138 ] is a heavy ion extension of the framework
that was introduced in an earlier chapter for small radii pp jets. In
this framework, they estimate the effect of a single gluon coupling with
the medium in the different fragmentation legs and thus are able to
emulate energy loss with the medium. Their result for the inclusive jet
@xmath is shown in Fig: 6.7 for two different centrality bins (central
on the left and peripheral on the right) for three different radii. It
is important to note the radial ordering here with R = 0.4 jets having a
smaller quenching than R=0.3 jets followed by R=0.2. This picture is
consistent with energy loss at angles away from the jet axis with going
to larger radii tending to recover the energy lost rather quickly.

##### Hydro+Shower

This is one of the more recent models on the market and it uses both a
hydro component and a particle shower component in its energy loss
calculations [ 139 ] . It has certain parameters such as @xmath (which
was introduced earlier) and a soft radiation cutoff for emissions and
tracks to stay in the perturbative regime. Their calculations for the
@xmath as shown in Fig: 6.8 have solid lines for shower + hydro model
and the dotted lines for only the shower part. Within the data
systematic uncertainties, the model performs admirably and the
shower+hydro mode showcases the same radii dependence as with a certain
amount of energy lost from a jet independent of its momenta.

##### Holographic HYBRID

The HYBRID [ 140 ] model uses holographic techniques to perform parton
energy loss. The AdS dual of a parton losing energy is a string falling
into a black hole. For the inclusive jet @xmath , we can see their
comparison with the published data points in Fig: 6.9 which happens to
line up very nicely ableit with large theoretical systematic
uncertainties. It is called HYBRID since the jets are described at weak
coupling and the parton energy loss at strong coupling. It is
interesting to note the radii dependence in this theoretical calculation
is opposite to other models that we have seen for a given jet @xmath . A
physical interpretation for this particular ordering is partly due to
the medium kick being at quite large angles away from the jet axis with
the recovery happening beyond the @xmath limit.

### 6.4 What we learn from the jet @xmath

One can think of the @xmath as an ensemble observable elucidating
bulk/overall properties but failing for finer details. In the previous
section, we see that a whole host of theory calculations and models can
predict the jet @xmath with reasonable accuracy. The interesting point
is that even amongst experiments at the LHC, there is very good
consistency in the measurement as shown in Fig: 6.10 . The panels show
CMS compared with ALICE (left) for R = 0.2 jets and ATLAS (right) for R
= 0.4 jets and even though ALICE and ATLAS employ somewhat of a
fragmentation biased jet selection, overall the agreement is pretty
remarkable. This is why the CMS result is a legacy measurement and one
that bridges the gap between ALICE and ATLAS in terms of both kinematic
reach and with utilizing unbiased inclusive jets.

From the data, we see the following

-   Jet quenching is a final state effect - due to lack of modification
    in @xmath

-   Clear centrality dependence in PbPb - more overlap leads to larger
    quenching

-   slight dependence on the jet @xmath

-   independence on the jet radii within the measured systematic
    uncertainties

From our CMS measurement, the inclusive jet @xmath for the most central
collisions, ranges @xmath as a function of jet @xmath . Since these are
ratios of jet spectra, a quick back of the envelope calculation tells us
that an @xmath of 0.4 means a @xmath reduction in the spectra which in
turn corresponds to energy loss of @xmath GeV for a 70 GeV jet, assuming
a power law spectra with an exponent of 4. Similarly, @xmath of 0.6
corresponds to energy loss of @xmath GeV for a 300 GeV jet. With the
latest data from Run2 at the LHC, ATLAS and ALICE have both presented
their preliminary @xmath and this time even at 5.02 TeV, the results lie
in the same scale i.e the @xmath appears to be flat around @xmath even
for 1 TeV jets. The reasons for a 1 TeV jet to lose roughly @xmath GeV,
with our back of the envelope calculation are still unknown and thus
provides an exciting new question for both experiments to quantify this
energy loss and for theorists to model such a behavior. Thus, we need to
move towards more differential measurements on the jet structure/profile
compared to a jet quenching MC which we will look at in the next
chapter.

## Chapter 7 Jet Quenching with JEWEL

“ If you make a theory, for example, and advertise it, or put it out,
then you must also put down all the facts that disagree with it, as well
as those that agree with it.”

– Richard Feynman

### 7.1 Introducing Jewel

JEWEL or Jet Evolution With Energy Loss, is a fully dynamical
perturbative framework developed to simulate jet quenching in heavy ion
collisions. It includes a simultaneous scale evolution of hard partons
into jets and their subsequent re-scatterings with the medium. The
parton shower in JEWEL is virtuality ordered and all partons in the
shower in addition to the jet evolution, undergo re-scattering in the
background. These interactions are described by @xmath pQCD elastic or
inelastic matrix elements at LO+LL. When the we consider re-scattering
in the QGP, JEWEL goes beyond factorization theorems and relies on a few
assumptions,

-   re-scattering resolves the partonic structure of the QGP for
    sufficiently hard interactions

-   infra-red continuation to regularize the pQCD matrix elements and
    include the dominant effect of soft scattering

-   interplay of different sources of radiation governed by the
    formation times

-   the physical picture of the LPM interference via eikonal kinematics
    is also valid in the non-eikonal regime.

For a full discussion of the JEWEL framework and its implementation the
reader is referred to [ 137 ] . We begin this chapter, as is our
preferred style throughout, by summarizing the most important features.
The vacuum case of jet evolution in JEWEL reduces to a standard
virtuality ordered final state parton shower in based on PYTHIA 6.4 [ 43
] which generates the initial state parton showers, hard jet production
matrix elements, hadronization and hadron decays. The strong coupling
@xmath runs at one loop evaluated according to the standard perturbative
scale choices and @xmath is adjusted to fit LEP data and doesn’t change
for subsequent generations.

#### 7.1.1 MonteCarlo implementation of in-medium energy loss

In JEWEL the jet-medium interactions give rise to energy loss. The
knowledge about the energy-momentum transferred from the jet to the
medium can be used for detailed studies of the medium response to jets [
141 ] . JEWEL has the option to retain recoiling medium partons in the
event, but this requires special analysis techniques [ 142 , 143 ]
(paper in preparation). For inclusive jet observables like the jet
@xmath , dijet asymmetry, angular correlations etc. JEWEL can be run
without storing the recoils. To study jet-substructure observables and
their sensitivity to the medium response, JEWEL can store the recoiling
partons which requires a background subtraction procedure to be
discussed in detail in the upcoming sections.

All scattering processes within the formation time of a medium-induced
emission act coherently, which means that only the vectorial sum of the
momentum transfers matters for the gluon emission. This is the QCD
analogue of the Landau-Pomerantchuk-Migdal effect, which is implemented
according to a generalization of the algorithm derived in [ 144 ] . The
emissions due to the scale evolution of the jet get dynamically
interleaved with radiation associated to re-scatterings in such a way
that re-scattering can only induce radiation if its formation time is
shorter than the lifetime of the hard parton. This implies that only a
hard re-scattering can perturb the hard parton shower emissions related
to the initial jet production process, so that the hard jet structure is
protected from medium modifications. This principle shares important
features with color coherence (cf. e.g. [ 145 ] ), but is not a
dynamical implementation of color coherence. It is missing, for
instance, soft and large angle emissions from coherent sub-systems.

The full list of parameters are available in the JEWEL manual but the
main ones that change typically as the beam energy, initial temperature
and the formation time of the QGP, along with the weighted exponent in
the power law of jet spectra. The initial conditions are provided by
hydrodynamic calculations. There are also additional parameters which
involve the debye mass screening factor which was set based on pion
quenching at RHIC. This means that for a given collision system and
center of mass energy, JEWEL can provide predictions for several jet
observables simultaneously without additional tunings or including new
parameters. All one needs is to generated events in JEWEL and produce
predictions for observables which can then be directly compared to
measurements.

We generate events in the standard setup [ 146 ] at @xmath TeV and
@xmath TeV with the simple parametrisation of the background discussed
in detail in [ 147 ] . This background model describes a thermal
quark-gluon gas undergoing Bjorken expansion with a superimposed
transverse profile obtained from an optical Glauber model. The initial
conditions for the background model are initial time @xmath fm and
temperature @xmath MeV for @xmath TeV [ 148 ] and @xmath fm and @xmath
MeV for @xmath TeV [ 149 ] . They are taken from a hydrodynamic
calculation describing soft particle production. The proton PDF set is
Cteq6LL [ 150 ] and for the Pb+Pb sample the Eps09 [ 66 ] nuclear PDF
set is used in addition, both are provided by Lhapdf [ 151 ] . The only
parameter in JEWEL that can be fitted to jet quenching data is the
scaling factor of the Debye mass. It was adjusted once to describe the
single-inclusive hadron suppression at RHIC and has remained the same
since. We use the Rivet analysis framework [ 152 ] for all our studies.
Jets are reconstructed using the same jet algorithm as the experiments
(anti-k @xmath [ 153 ] ) from the fastjet package [ 154 ] .

### 7.2 Electroweak bosons and the QGP

Since the QGP interacts via the strong force, it is transparent to
electro-weak bosons which propagate without energy loss. Thus for events
where we have a quark scattering of a boson, say a photon in the final
state, reconstructing the photon’s energy can provide a handle on how
much the jet in the back to back direction got quenched. For this reason
such events are called as standard candles of the QGP by some
aficionados in the field. In general they are also used in pp collisions
to apply corrections to the jet energy since there is no jet quenching.
Thus for a heavy ion MC generator, it is important to have the ability
to generate such events to establish confidence in the implementation of
energy loss.

#### 7.2.1 Adding V+Jet to Jewel

We have included the lowest order processes with a jet recoiling against
a vector boson [ 155 ] with the corresponding diagrams shown in Fig. 7.1
. These correspond to either a quark scattering off a gluon (Compton
scattering) or a quark–anti-quark pair annihilating to produce a boson
and a gluon. For photons, the box diagram @xmath is also included. This
process is of higher order than the others, but is included as it can be
numerically important in certain phase space regions. The leptonic
decays of the heavy boson @xmath and @xmath are simulated as well.

Hard photons can also be radiated off quarks during jet evolution. These
fragmentation photons are typically accompanied by hadronic activity and
are suppressed by requiring the photon to be isolated. However, it is
still possible that fragmentation photons pass the isolation criterion.
The probability for this to happen is small and depends on the cuts. It
has to the best of our knowledge not been quantified in a heavy ion
environment in the presence of jet quenching. In the current JEWEL
version fragmentation photons are also not included. For the analyses
shown here the fragmentation component is expected to be small due to
the applied photon isolation.

As we mentioned before, JEWEL is a leading-order framework. While NLO
corrections to @xmath +jet processes can be sizable, in the observables
shown here corrections affecting only the cross section largely cancel
due to the normalization to number of bosons or number of boson-jet
pairs. The corrections to differential distributions remain, but are
typically smaller.

#### 7.2.2 Predictions and comparisons with data

In order to suppress the background from fragmentation and decay
photons, isolation cuts are applied by requiring the sum of energy in a
cone of radius @xmath (in the @xmath phase space) around the photon to
be less than @xmath of the photon’s energy. In addition, the photon has
to be within @xmath and have a transverse momentum @xmath @xmath @xmath
. The jets are reconstructed with the anti-k @xmath algorithm with a
resolution parameter of @xmath . Jets are required to have a @xmath
@xmath @xmath and to be in the barrel region ( @xmath ). Furthermore,
only jets that are back-to-back with the photon ( @xmath ) are selected.

Fig. 7.2 shows our results for the transverse momentum asymmetry in
@xmath jet pairs ( @xmath ) compared with preliminary CMS [ 156 ] data
points for p+p and central ( @xmath ) Pb+Pb collisions at @xmath TeV.
Fig 7.2 shows the average value of the @xmath as a function of the
photon transverse momenta in four @xmath bins, again for p+p and central
Pb+Pb collisions. JEWEL+PYTHIA is able to reproduce the effect of the
@xmath imbalance for @xmath jets events very nicely for both p+p and
Pb+Pb events. In central Pb+Pb collisions @xmath is slightly lower in
JEWEL+PYTHIA than in the data indicating stronger medium modifications
in JEWEL , particularly at relatively low photon @xmath . In Fig. 7.4
the azimuthal angle ( @xmath ) between the photon and the jet is shown.
We again find a very reasonable agreement with JEWEL+PYTHIA for pp
collisions slightly more peaked. In all three figures we also show the
JEWEL+PYTHIA predictions for @xmath TeV, which turn out to be very
similar to the @xmath TeV results. The agreement with the ATLAS
measurement [ 158 ] is of a very similar quality.

In the case of @xmath and @xmath production we utilize the muon decay
channel in our simulations (this is purely convenience, the electron
channel can be simulated as well). The @xmath candidate’s momentum is
reconstructed from the di-muon pairs. For comparison to the ATLAS
measurement we require its reconstructed mass in the window @xmath
@xmath and @xmath @xmath @xmath . The jets are reconstructed with the
same anti-k @xmath algorithm with resolution parameter @xmath , with the
kinematic cut on its @xmath @xmath @xmath and it is required to be found
in the barrel region @xmath . Similar to the @xmath jet case, we impose
@xmath to select the back to back pairs. Fig. 7.5 shows the ATLAS [ 159
] preliminary result for the @xmath imbalance compared to JEWEL+PYTHIA
for central (0-20%) Pb+Pb collisions at @xmath TeV. For comparison we
also show the JEWEL+PYTHIA result for p+p. In central Pb+Pb events we
observe a clear shift of the distribution towards smaller @xmath
compared to p+p and a reasonable agreement between the MC and data.

Reconstructing a @xmath boson candidate in the heavy ion environment is
difficult due to the ambiguous nature of the missing transverse energy
(MET) in the event. Due to in-medium energy loss, the MET in such events
does not accurately represent the neutrino, required to reconstruct the
@xmath . We therefore investigate the possibility of using the charged
decay lepton instead of a reconstructed @xmath . In both cases we
require the lepton to have a high @xmath @xmath @xmath and @xmath , for
reconstructed @xmath ’s the mass window is @xmath @xmath . Jets are
reconstructed with @xmath and kinematic cuts @xmath @xmath @xmath and
@xmath . We also impost a @xmath to ensure no overlap between our
reconstructed jet and lepton collections.

The left panel of Fig. 7.6 shows the @xmath distributions in central (
@xmath ) Pb+Pb events for the reconstructed jets with the generator
level @xmath in the red line and with the leading lepton ( @xmath ) in
the event in the blue dotted line. We see that the @xmath distribution
are similar for the @xmath and leading lepton and therefore we show the
transverse momentum imbalance with the leptons. This is shown in the
right panel of Fig. 7.6 for p+p and central Pb+Pb collisions. Again,
there is a clear shift towards larger asymmetries in central Pb+Pb
events.

It is also informative to look at the nuclear modification factors (
@xmath ) of jets in events recoiling against a @xmath or a @xmath . Due
to the large mass of the @xmath boson, the jet spectrum is harder than
for jets recoiling off a @xmath . This influences the @xmath for @xmath
+jets to be less suppressed at the low @xmath range as shown in Fig. 7.7
.

### 7.3 Background subtraction in Jewel

In JEWEL the background medium is assumed to consist of an ensemble of
partons, the phase space distribution and flavor composition of which
have to be provided by an external medium model. Partons belonging to a
jet may interact with these background partons through @xmath scattering
processes described by perturbative matrix elements, with associated
gluon emission generated by the parton shower. Further details of the
inner workings and Monte Carlo implementation of JEWEL are available in
[ 137 , 144 ] .

As mentioned in the introduction, there are two operational modes for
event generation with JEWEL concerning the treatment of background
partons recoiling against a scattering with the jet (so called “recoils”
or “recoiling partons”). Events can be generated with or without storing
the recoil information. When run without recoils, the recoiling partons
do not show up in the event. In this case no medium response is
considered and inclusive and inter-jet observables can be compared to
(background subtracted) experimental data. So far this was the
recommended mode for jet observables.

However, jet structure observables are sensitive to medium response and
hence it is desirable to include these effects in JEWEL by keeping the
recoiling partons in the event. After the scattering these recoiling
partons do not interact further with the medium and free-stream towards
hadronization. This represents a limiting case for the recoil behavior,
that can be regarded as being the limit opposite the assumption of
immediate thermalization of recoil energy and momentum made by
hydrodynamic frameworks. The truth is expected to be between these two
extreme cases, since one would expect that these partons interact
further with the medium, but do not necessarily fully thermalize.

So far the background partons could be either (anti-)quarks or gluons.
For hadronization, however, all recoiling partons are converted to
gluons. It is assumed that the recoiling parton is a color neighbor of
the hard parton it interacted with. The recoil gluons are thus inserted
in the strings connecting the partons forming the jet. Therefore, the
hadronic final state including recoiling partons is not an incoherent
superposition of jets and activity arising from recoils. At hadron
level, it is impossible to assign a certain hadron to the jet or medium
response.

The four-momentum of the recoiling partons has two components: the
thermal momentum it had before the interaction with the jet, and the
four-momentum transferred from the jet in the scattering process. Only
the latter is interesting for investigating medium response, the former
is part of the uncorrelated thermal background that is subtracted from
the jet. As JEWEL generates only the jets and not full heavy ions
events, it is not possible to use the experimental background
subtraction techniques for the Monte Carlo events. Instead, a dedicated
procedure for removing the thermal four-momentum components from the
jets when running with recoils has to be devised. Therefore, along with
the recoiling partons, we are also storing the thermal four-momenta,
which constitute our background ¹ ¹ 1 Technically, this is done by
adding one line labeled as comment for each thermal momentum to be
subtracted to the HepMC event record. . These will be systematically
removed from the jets during the analysis step, as detailed in the
following section.

### 7.4 Subtraction of the thermal component

As discussed in the previous section, in order to compare predictions
for jet observables with data, it is imperative to perform a background
subtraction, as shown diagrammatically in Fig: 7.8 on JEWEL events when
running with the recoils. This is to avoid a mismatch between the
prediction and data, since the jets in data have the fluctuating
underlying event subtracted. In this section, we present two independent
subtraction methods for JEWEL , that can be employed at the analysis
level ² ² 2 Example Rivet [ 152 ] analyses are available for download on
the JEWEL homepage http://jewel.hepforge.org/ .

#### 7.4.1 4MomSub

This method removes the thermal momenta exactly from the jet’s
four-momentum. In order to determine which thermal momenta should be
subtracted, an additional set of neutral particles with very small
energy and momenta and pointing in the direction of the thermal momenta
are added to the final state particles list. These “dummy” particles are
effectively the same as ghosts that FastJet [ 154 ] uses during its
clustering to determine the jet area. They can get clustered into jets
without affecting the jet’s momentum or structure. Thermal momenta, that
are matched to a dummy (in the azimuthal angle - pseudorapidity plane)
inside a jet, are subtracted from the jet’s momentum. The resulting four
vector constitutes the subtracted jet momentum. An algorithmic
implementation of the procedure is detailed below:

1.  Cluster the initial jet collection from the final state particles
    (including dummies).

2.  Compile a list of the thermal momenta (particles in the HepMC event
    record with status code 3).

3.  For each jet, get the list of thermal momenta that have @xmath with
    one of the jet constituents, i.e a dummy particle.

4.  Sum up the four-momenta of the matched thermal momenta. This
    constitutes the background.

5.  For each jet subtract the background four-momentum from the jet’s
    four momentum, this provides the corrected jet collection.

6.  Calculate jet observables from corrected jet four-momenta.

This method is easily generalized to subtraction of sub-systems of jets,
such as sub-jets or annuli used for the jet profile.

#### 7.4.2 GridSub

This is a generic, observable independent subtraction method. A finite
resolution grid (in the @xmath plane) is superimposed on the jet and its
constituents. The four-momenta of particles in each cell in the grid are
then vectorially summed and thermal momenta subtracted, yielding the
cell four-momentum. Finally, we re-cluster the jet with the cell
four-momenta as input to the jet clustering algorithm. This method does
not require dummy particles. It is also possible to first discretize the
entire event, subtract thermal four-momenta cell-by-cell, and then
cluster jets. The algorithms for the two variants are given below.

Jet clustering before discretization (GridSub1):

1.  Cluster the initial jet collection from the final state particles.

2.  Compile a list of the thermal momenta (particles in the HepMC event
    record with status code 3).

3.  Define the grid resolution and place grid over jets.

4.  Inside each cell sum the jet constituents’ four-momenta and subtract
    the thermal four-momenta that fall into the cell (note: no matching
    is required, thermal four-momenta with distance @xmath jet radius
    are considered ³ ³ 3 Alternatively, when dummy particles are written
    to the event record, one can also match thermal momenta and dummies
    to decide which momenta should be included. ), providing a single
    four momentum for each cell.

5.  In case a cell contains more thermal momentum than jet constituents,
    the cells is set to have zero four-momentum. This is deemed to be
    the case when the (scalar) @xmath of the thermal component is larger
    than the @xmath of the particle component.

6.  Re-cluster the jets with the cell four-momenta as input to get the
    final, subtracted jets.

7.  Calculate jet observables from re-clustered jets.

This version is the default.

Discretization before jet clustering (GridSub2):

1.  Compile a list of the thermal momenta (particles in the HepMC event
    record with status code 3).

2.  Define the grid resolution and place grid over the entire event.

3.  Inside each cell sum the final state particles’ four-momenta and
    subtract the thermal four-momenta that fall into the cell (note: no
    matching is required), providing a single four momentum for each
    cell.

4.  In case a cell contains more thermal momentum than particle
    momentum, the cells is set to have zero four-momentum. This is
    deemed to be the case when the (scalar) @xmath of the thermal
    component is larger than the @xmath of the particle component.

5.  Cluster the jets with the cell four-momenta as input to get the
    final, subtracted jet.

6.  Calculate jet observables.

Due to the finite size of the grid, it is possible to have certain cells
with more thermal momentum than particle momentum, resulting in a total
negative four-momentum, which in our case is set to zero before
clustering. Thus, the GridSub method systematically removes less
background from the jet than 4MomSub. The smearing introduced by the
GridSub method will be quantified systematically in the following
section.

The use of the 4MomSub method is recommended when possible, since it
does not introduce finite-resolution effects and is consequently more
accurate.

#### 7.4.3 Limitations of the subtraction and the issue of track jets

Since the subtraction techniques introduced above subtract the thermal
momenta, which are at parton level, from the hadronic final state, they
only yield meaningful results for observables that are insensitive to
hadronization effects. This is the case for most infra-red safe
observables based on calorimetric jets. Examples for observables that do
not fall into this category are fragmentation functions and charged jet
observables. In general, all cuts on the final state particles, also
@xmath cuts, are problematic.

A few of the recent experimental results involve the use of charged or
track jets [ 161 , 162 , 163 ] , i.e jets reconstructed using only
tracks. When the subtraction is naively applied, the techniques end up
overestimating the contribution of the four-momenta to subtract. Thus,
in order to compare with such experimental results, a heuristic
procedure is applied. The observable of interest is calculated for full
jets and re-scaled. The re-scaling between the full and the charged jet
distribution is extracted from the corresponding JEWEL simulation for
p+p collisions. If it is larger than the resolution of the observable,
it is applied to the full jet subtracted distribution in Pb+Pb. In this
way an estimate of the charged jet distribution is derived. For example,
a naive way of estimating the charged jet four-momentum is by re-scaling
the full jet quantity with the fraction of charged particles in the jet.
The charged jet mass distribution discussed in section 7.7 is estimated
using this technique and compared with data. In other cases, for
instance the jet radial moment girth (also shown in section 7.7 ), the
distributions for charged and full jets are the same in p+p collisions.
In this case we compute the observable for full jets in Pb+Pb collisions
as well and do not apply any re-scaling.

Obviously, this method comes with an additional uncontrolled systematic
uncertainty, since it is not guaranteed that the same relation between
full and charged jet distribution holds in Pb+Pb and p+p.

### 7.5 Systematic studies

The background subtraction techniques introduced in the previous section
and their effects on jets are studied henceforth in a systematic
fashion.

#### 7.5.1 Smearing due to finite resolution of the grid

An immediate consequence of the grid, before any subtraction is
introduced, is that both the jet @xmath and the position of the jet in
the @xmath plane are smeared. This effect is studied in JEWEL with p+p
events generated at hadron level to highlight the inherent behavior. All
our studies of the grid are shown for a nominal grid size of @xmath in
@xmath plane, which we find to be a good compromise between resolution
and under-subtraction (which is more severe for smaller cell sizes). The
systematic uncertainties are estimated by varying the grid size by a
factor of two and most final observables are shown to be quite
insensitive to the grid size within these limits.

In each event, jets are first reconstructed from the final state
hadrons. Then the event is discretized using a grid and jets are
reconstructed based on the grid cells. Finally, each jet of the smaller
of the two collections is matched to the one from the other set that is
closest in @xmath , with the constraint that @xmath is smaller than the
reconstruction radius (this is the standard CMS procedure for comparing
generator level jets to jets after detector simulation). The smearing is
quantified in Fig. 7.9 with the top panels showing the smearing in jet
@xmath (on the left) and jet axis (on the right) as a function of the
particle jet @xmath . The latter is broken down into the respective
shifts in @xmath and @xmath , which are shown in the bottom panels. The
deviations are observed to be small in the @xmath range studied here.
There is a clear trend for the grid jet @xmath to be larger than the
corresponding particle jet @xmath , which is due to the fact that the
effective area of the grid jets can be larger due to the discretization.
As one would expect, increasing the jet @xmath reduces the smearing
introduced by the grid.

In Fig. 7.10 the @xmath shift seen in Fig. 7.9 is quantified. The ratio
between grid jet @xmath and the particle jet @xmath is seen to be around
1.04 and thus reasonably close to unity, and largely independent of jet
@xmath and @xmath for @xmath @xmath @xmath . Such shifts usually are
corrected in experiments [ 104 , 164 ] by introducing detector level
correction factors as a function of the jet @xmath and @xmath . In this
paper, GridSub jets are not corrected for this shift in their @xmath ,
since it is reasonably small. Also, it partially cancels when looking at
ratios of Pb+Pb with p+p due to its independence on jet kinematics.
Furthermore, since the mismatch is related to nearby jets, increasing
the jet @xmath cut leads to a reduction of the effect.

#### 7.5.2 Under-subtraction due to cells with negative energy

As previously mentioned, the GridSub technique sets the cell’s four
momentum to zero if it contains more thermal than particle momentum.
This leads to a systematic under-subtraction, that increases with
decreasing cell size. We quantify this effect using the event sample
with medium response included. Jets are reconstructed and subtracted
using the default grid subtraction, but here we keep track of the energy
of cells whose four-momentum is set to zero. For each jet we then check
if it contains such cells and sum the (negative) energy that these cells
originally had. The sum of the negative energy per grid jet is shown in
Fig. 7.11 for different jet @xmath ranges. The contribution of negative
energy, i.e the amount of thermal energy that remains un-subtracted from
the jet, is largely independent of the jet @xmath (except for the lowest
@xmath bin) and small compared to the jet @xmath over most of the
covered @xmath range.

#### 7.5.3 Comparison of two GridSub versions

As discussed in section 7.4.2 we have implemented two versions of the
grid based subtraction, that differ in the order of jet clustering and
discretization. It is to be expected that the two versions yield
different results, as there is no reason why the two operations should
commute. Using again the hadron level event sample with medium response
included we quantify the differences between the versions. To this end,
we find and subtract jets with both versions and event-by-event match
the jets following the procedure detailed above. The relative difference
in jet @xmath and shift of the axis due to the different ordering of
operations is shown in Fig. 7.12 . Both these effects are determined to
be quite small, but the jet @xmath is consistently larger, when the
initial jet clustering is performed before the discretization of the
event.

#### 7.5.4 Effects on jet @xmath with 4MomSub and GridSub subtraction

A final check of the two subtraction methods (4MomSub and GridSub1) is
done at parton level, where the same jets can be reconstructed with and
without recoiling partons. The subtraction is performed with either of
the two methods and the matching procedure is again the same as before.

Fig. 7.13 shows the relative @xmath difference between jets
reconstructed with and without recoiling partons. As expected, the
4MomSub distribution is narrower compared to GridSub1, due to additional
jet smearing introduced by the discretization of the event into cells of
a finite size. Additionally, the 4MomSub distribution has a tail on the
positive side. This is a momentum conservation effect: the thermal
distribution is isotropic (except for the longitudinal boost), while the
recoiling partons have a net momentum in direction of the jet due to
momentum conservation. Therefore, when including medium response more
momentum is added to the jet than is subtracted. This is a physical
effect that is independent of the subtraction method, but for the
GridSub method the shoulder is towards the negative side. This is due to
the aforementioned nature of the GridSub to under-subtract the jets,
which overcompensates the momentum conservation effect.

### 7.6 Application to traditional jet quenching observables

Observables built from the jet @xmath and axis, such as jet @xmath or
the di-jet asymmetry @xmath , for smaller radii jets typically show a
rather mild sensitivity to medium response. The jet axis is dominated by
the hard jet components and for the jet @xmath the only effect of medium
response is a partial recovery of lost energy. For small reconstruction
radii, this is at best a moderate effect, while for very large radii,
such as @xmath , the effect becomes sizable. For such large radii also
the systematic uncertainties related to the subtraction become large.
Experimentally, the study of such large jets in a heavy ion environment
constitutes an almost impossible task of discriminating between
underlying event and the jets. For small radii jets at small momenta the
same problem persists, which is why different experiments utilize
different procedures to remove the effect of the underlying event in the
jet collection of interest [ 115 , 165 , 113 ] .

As our primary validation, Fig. 7.14 shows the nuclear modification
factor @xmath of jets, i.e the ratio of jet yield in Pb+Pb over binary
collisions scaled p+p, for a moderate radius of @xmath . As expected,
including medium response leads to a small increase of @xmath over the
entire jet @xmath range. The grid based subtraction leads to a
significantly larger increase. This reflects the under-subtraction of
the GridSub method discussed in section 7.5 . Increasing the cell size
leads to a reduction of @xmath . There is good agreement between the two
versions of the grid subtraction.

The jet radius dependence of @xmath is shown in Fig. 7.15 with medium
response and 4MomSub. The expected increase of @xmath with @xmath ,
because with increasing jet radius more and more of the lost energy is
recovered, is indeed observed ⁴ ⁴ 4 This is in contrast to the behaviour
observed in [ 166 ] , where @xmath decreases with increasing jet radius
because wider jets are more easily lost and medium response cannot
compensate this loss. .

Figs. 7.16 and 7.17 show the di-jet momentum asymmetry

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

and relative azimuthal angle @xmath , respectively. Here, the leading
jet is required to have @xmath @xmath and the cut on the sub-leading jet
is @xmath @xmath @xmath ⁵ ⁵ 5 Analysis cuts are always applied after
subtraction. . The momentum asymmetry @xmath is calculated without
@xmath cut. The jet axis and thus @xmath are unaffected by medium
response, while in the case of @xmath it leads to a mild reduction of
the medium modification obtained without medium response.

### 7.7 Application to jet shape observables

In contrast to the observables discussed in the previous section, that
aim at characterizing global properties of jet events, jet shape
observables are sensitive to the momentum distribution inside the jet.
The latter are thus more affected by medium response. The energy in QCD
jets is very much concentrated towards the jet axis, while medium
response leads to a much broader distribution of relatively soft
activity. Also the fluctuations of the two components are different. In
this section we discuss a number of jet shape observables and how they
are affected by medium response in JEWEL .

#### 7.7.1 Jet mass

The reconstructed jet mass is a good probe of medium induced jet
modifications and medium response, since it is sensitive to the soft
sector. Fig. 7.18 shows the JEWEL+PYTHIA results for the jet mass
distribution. The Monte Carlo shows a shift towards larger masses when
medium response is included, whilst for events generated without
recoils, a smaller jet mass is observed for jets belonging to the same
kinematic range. The latter is due to the known narrowing of the hard
jet core. The partial cancellation between two competing effects – the
narrowing due to energy loss and the broadening due to medium response –
is typical for this kind of observables and also seen in other jet
shapes (e.g. the jet profile and girth). We observe a large difference
between 4MomSub and GridSub subtraction in this observable, but good
agreement between the two versions GridSub1 and GridSub2. In fact, the
jet mass is very sensitive to the details of the grid subtraction. In
Fig. 7.19 we compare two different cell sizes and two ways of computing
the cell momentum. One is the default, which consists of summing the
four-momenta of the particles in the cell (and subtracting the thermal
momenta), and the other sums the particles’ energies and assumes the
cell four-momentum to be massless and to point in the direction defined
by the cell centre. Both variations lead to large differences in the jet
mass distribution (which is not observed in any other observable we
studied). We therefore strongly discourage the use of grid subtraction
for the jet mass and from here on show results only for 4MomSub
subtraction.

As discussed in section 7.4.3 , in order to be able to compare the
JEWEL+PYTHIA results to the ALICE data, the charged jet mass has to be
estimated from the full jet mass. We do this by re-scaling the full jet
mass with a constant factor 2/3 and the jet @xmath with a factor 3/4
(this is needed to match the @xmath cuts in the charged jet sample). The
scaling factors are extracted from the JEWEL+PYTHIA p+p sample. The left
panel of Fig. 7.20 shows the charged jet, full jet and re-scaled full
jet mass distributions in p+p and gives a lower bound on the related
systematic uncertainties. We would like to stress once more that this is
an ad hoc procedure and that there is no guarantee that it yields
meaningful results. The right panel of Fig. 7.20 shows the comparison of
the re-scaled full jet mass distribution from JEWEL+PYTHIA to a recent
ALICE measurement [ 163 ] . The Monte Carlo predicts significantly
larger jet masses, but given the uncertainties involved in obtaining the
charged jet distribution it is difficult to interpret this comparison
with data.

#### 7.7.2 Fragmentation functions

Intra-jet fragmentation function [ 167 , 169 , 168 ] in p+p and Pb+Pb
collisions are also an important jet sub-structure observable. However,
in JEWEL there is no way of doing the subtraction for individual hadrons
or, as in this case, tracks. In Fig. 7.21 , which shows the modification
of the fragmentation function in Pb+Pb collisions compared to p+p, we
therefore in the sample with medium response correct the jet @xmath ,
but all tracks enter the fragmentation function. It is thus expected
that JEWEL+PYTHIA overshoots the data in the low @xmath or @xmath ,
corresponding to high @xmath , region. The sample without medium
response in this region shows a suppression as opposed to the
enhancement seen in the data and the sample with recoiling partons,
confirming the interpretation that the low @xmath (high @xmath )
enhancement seen in the data is due to medium response. The enhancement
at high @xmath (low @xmath ) region is caused by the already mentioned
narrowing and hardening of the hard jet core, and is more pronounced in
JEWEL+PYTHIA than in data. It is stronger without medium response,
because the latter does not affect the hard fragments, but slightly
increases the jet @xmath .

#### 7.7.3 Jet profile

The differential jet shape or jet profile @xmath measures what fraction
of the jet @xmath is found at what distance from the jet axis. It is
defined as

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

where the sum runs over all particles in the jet. The CMS measurement [
170 ] was performed using the full jet @xmath , but @xmath was built
only from tracks. Therefore, as is the case of the fragmentation
function, we can do the subtraction for the jet @xmath , but not for the
charged particles. In this case, however, this is not a problem, since
the jet profile built from tracks and the one built form all particles
differ only by a constant factor. Assuming this factor to be the same in
p+p and Pb+Pb, it will cancel exactly in the ratio of the jet profiles.
We can therefore compare JEWEL+PYTHIA results for full jets directly to
the CMS data on the jet profile ratio. A more serious problem is that in
experimental analysis only tracks with @xmath @xmath GeV are included.
Since we can only subtract for the inclusive final state, this leads to
a small mismatch, that becomes visible only at large @xmath and reaches
up to 10% in the highest @xmath bin.

Fig. 7.22 shows the JEWEL+PYTHIA result compared with CMS data [ 170 ]
for the modification of the differential jet shape @xmath in Pb+Pb
collisions compared to p+p. Including medium response and after
performing the subtraction using the 4MomSub method, we are able to
reproduce the general trend of the data. JEWEL+PYTHIA with recoiling
partons describes the enhancement of the jet shape at large radii mostly
due to soft particles ( @xmath @xmath GeV), while without medium
response the enhancement is entirely absent.

#### 7.7.4 Girth

The first radial moment of the jet profile is called girth [ 171 ] and
is defined as

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

where the numerator sums the distance from the jet axis weighted with
@xmath @xmath of each constituent @xmath of the jet. It characterises
the width of the @xmath distribution inside the jet.

JEWEL+PYTHIA results for girth using GridSub1 subtraction for fully
reconstructed jets in central Pb+Pb collisions are shown in the left
panel of Fig. D.3 . We find a shift to smaller values of @xmath due to
narrowing of the hard component, which is partly compensated by a
broadening of the jet due to medium response. We also compare our
results with preliminary ALICE data [ 162 ] for charged jets in the
right panel of Fig. D.3 . Following the same argument as above for the
jet profile, the girth of full and charged jets should be the same,
provided the @xmath range is adjusted accordingly. We confirmed this in
the Monte Carlo for p+p collisions. We therefore in Fig. D.3 compare
JEWEL+PYTHIA results for fully reconstructed jets at a correspondingly
higher @xmath with the ALICE data. We find reasonable agreement, but the
JEWEL+PYTHIA distribution peaks at slightly higher values than the data.

#### 7.7.5 Groomed shared momentum fraction @xmath

The groomed shared momentum fraction @xmath is a measure for the
momentum asymmetry in the hardest, i.e. largest angle, two-prong
structure in the jet. In p+p collisions it is closely related to the
Altarelli-Parisi splitting function [ 173 ] . It is defined through the
Soft Drop procedure [ 174 , 175 ] detailed below and implemented in
FastJet [ 154 ] contrib. First, jets are clustered with the anti-k
@xmath algorithm and re-clustered with Cambridge/Aachen. Then the last
clustering step is undone, yielding the largest angle two-prong
structure in the jet. If this configuration satisfies the Soft Drop
condition

  -- -------- -- -------
     @xmath      (7.4)
  -- -------- -- -------

where @xmath and @xmath are parameters, it is kept. Otherwise, the
softer of the two prongs is discarded and the procedure of un-doing the
last clustering step is repeated for the harder prong. In this way soft
contaminations are systematically removed from the jet and the hardest
two-prong structure is identified. Soft Drop jet grooming thus takes an
inclusive jet collection and turns it into a different collection of
jets with two-prong structure of a minimum momentum symmetry provided by
@xmath . Varying @xmath up or down varies the degree of asymmetrical
splitting allowed in the parton’s fragmentation, while the @xmath
controls how collinear the configuration has to be.

In p+p collisions, this method is has been studied in some detail [ 175
, 173 ] , but in heavy ion collisions the exact meaning of the grooming
procedure is not obvious, due to the presence of the fluctuating
underlying heavy ion event and the increased soft sector, that the
procedure tries to remove. Recent analytical studies [ 176 ] have shown
that grooming increases the sensitivity to medium induced gluon
bremsstrahlung thus experimentally opening up different avenues to
directly probe the effect of the medium on a jet by jet basis. In JEWEL
, however, a different story unfolds.

As shown in the right panel of Fig. 7.24 , there is an increase in
asymmetrical splittings in Pb+Pb jets as opposed to p+p jets, which is
observed in recent preliminary CMS results and reproduced in
JEWEL+PYTHIA . The secondary feature observed in this measurement is an
apparent reduction of the effect for higher @xmath jets. JEWEL
reproduces this behavior qualitatively as well, with very high @xmath
jets showing very little difference in the momentum fraction of the
first splitting [ 172 ] . The left panel of Fig. 7.24 shows that in the
Monte Carlo the modification of the @xmath distribution in Pb+Pb
collisions is partly due to the narrowing of the jet, as seen in the
sample without medium response. The more important contribution,
however, comes from adding the recoiling partons ⁶ ⁶ 6 For a detailed
discussion of the origins of the effect in JEWEL cf. [ 177 ] . . In
JEWEL+PYTHIA we see no sign of medium induced bremsstrahlung
contributing to the effect, as advertised in [ 176 ] .

### 7.8 Discussion and conclusions

Studies of jet sub-structure modifications in heavy ions probe the
intricate interactions between the medium and jets. Due to their
sensitivity to medium response, they offer the power to discriminate
between several models and shed light on the underlying jet quenching
mechanisms as well as the thermalization of the deposited energy and
momentum.

In JEWEL it is possible to study medium response in detail by keeping
the partons recoiling against interaction with the jet in the event. One
has to keep in mind that this is only a limiting case, since these
partons do not undergo further interactions in the medium. In order to
be able to compare these results to experimental data, the thermal
component of the recoiling partons’ momenta has to be subtracted. In
this paper we introduced two methods for doing this, a four-momentum and
a grid based one. With these tools we can for the first time
quantitatively study jet shape observables.

We find that – at least in JEWEL+PYTHIA – a number of qualitative
feature in the data can only be explained by medium response. These are

-   the increase at low @xmath of the ratio of intra-jet fragmentation
    functions in Pb+Pb compared to p+p,

-   the increase of the jet profile at large distance from the jet axis
    in Pb+Pb compared to p+p,

-   and the enhancement of asymmetric two-prong structures in Pb+Pb
    compared to p+p as seen in the @xmath distribution.

This is in line with observations by other authors [ 166 , 139 ] . In
other observables, in particular the jet mass and girth, a non-trivial
cancellation between a narrowing of the jet core due to energy loss [
178 , 179 , 166 ] and a broadening due to medium response takes place.
Also in the case of girth, including medium response leads to an
improvement of the agreement between JEWEL+PYTHIA and ALICE data.

For the jet mass we find that the grid based subtraction does not yield
reliable results. The 4MomSub subtraction should be more robust, but
without grid subtraction we do not have an independent way of
cross-checking the results. We therefore recommend not to use GridSub
for the jet mass and to take the comparison of JEWEL+PYTHIA results to
the ALICE data with a grain of salt.

Jet shape observables open a new perspective on jet quenching and may
also help to address the question of thermalization, and it is important
to develop tools capable of quantitatively describing medium response.
The present study with JEWEL can only be a first step in this direction.
As emphasized above, the treatment of recoiling partons is still
schematic. The subtraction methods introduced in this paper are solid,
but have their limitations, in particular when it comes to the
description of charged jets. It is currently also impossible to perform
the subtraction for particles (for instance in the fragmentation
functions), due to the mix of parton and hadron level in the
subtraction. The grid method also introduces systematic uncertainties
related to the discretization, that can, however, be quantified (cf.
section 7.5 ). Nevertheless, the results for jet shapes obtained with
JEWEL+PYTHIA are very promising. In some cases this is the first time
that they can be studied quantitatively in a consistent jet quenching
model including medium response.

Upcoming measurements at the LHC will further advance the understanding
of jet shapes by utilizing the jet grooming tools, amongst others. This
ushers in a new era of sub-structure studies in heavy ion collisions,
where correlation between different observables could point the way to
the future in decoupling several of the physics features hidden in
individual observables.

## Chapter 8 Moving Towards a Quantitative Understanding

“Nothing in life is to be feared, it is only to be understood.
Now is the time to understand more, so that we may fear less.”

– Marie Curie

### 8.1 Improving current baseline jet measurements

Any experimental measurement can be improved by either extending the
kinematic reach or better understanding the systematic uncertainties or
increasing statistics. Especially jet observables need a lot of
statistics since the hard scattering cross section is small compared to
the minimum bias. Lets go over the results for each system in
consideration and briefly mention how each can be improved.

#### 8.1.1 Jets in pp collisions

Measuring the inclusive jet cross section is fundamental to any jet
program and we discussed the ability of theory calculations at NNLO and
LL to match data for small radii jets. Our result was only looking at
the mid rapidity region and thus the next obvious step forward is to
look at the Data/Theory comparison across a variety of rapidity windows
and radii. Especially studying the forward rapidity starts to go more
into the high x region of the PDFs and can expose inconsistencies in the
calculations. The overall systematic uncertainty in the jet cross
section is probably the smallest its ever been and with the current
method of deriving corrections (using MC in a detector simulation), it
is improbable that we can reduce it much further. With these
comparisons, the theoretical uncertainties will reduce facilitating an
improved understanding of the proton and the hard scattering.

#### 8.1.2 Any nuclear effects in pPb

In our inclusive and b-jet studies in pPb collisions in comparison with
an extrapolated pp reference, we saw no significant modification due to
initial state nuclear effects. This provided us with confidence that
@xmath is indeed a final state effect. But pPb has raised more questions
than it answered, especially related to the initial state and its
composition, accurate centrality determination and effect of
multiplicity on jet structure. The parton mass dependence would be
interesting upon extending the kinematic range to lower @xmath but at
the LHC that is very hard. The overall systematics do reduce when we
take into account pp data as the baseline but still it doesn’t point to
any significant modification. So for pPb collisions, we need to directly
push towards jet structure and sub-jet studies as we will discuss in the
coming sections.

#### 8.1.3 Jets in the QGP

We started this exploration with the goal of extracting QGP properties
by using jets as tomographical tools. Have we attained that goal? It is
safe to say that so far, that studying jets had proven to be more
complicated than assumed. It turns out that we must first understand the
baseline in order to use these tools in a heavy ion environment and due
to the multi-scale processes involved with jets, there are still several
questions that we need to answer when we start to move towards a
quantitative reasoning of the QGP interactions. In the coming sections,
we shall briefly summarize what we have learnt from existing
measurements and how they can be improved. We will finish the thesis
with what I call the new age of jet measurements in heavy ions and how
we can refine/upgrade our current measurements in all three systems that
we studied in this thesis.

### 8.2 Consensus on jet quenching

We have gone through a lot of pages regarding jets and
measurements/models so lets try to summarize what we have learnt so far.
It is very clear across experiments that jets are indeed quenched in
heavy ion collisions when compared with pp collisions. These
modifications appear to be final state interactions with the medium as
opposed to initial state or cold nuclear matter effects evident by the
lack of significant modifications in pPb collisions. These are all broad
stroke or rather qualitative features and are quite easily reproduced by
a wide spectra of models when taking into account medium induced energy
loss via elastic, inelastic and radiative processes. The @xmath turns
out to be a sledgehammer approach to the finer details and thus as a
natural evolution in jet studies, we also looked at jet structure and
even sub-structure measurements. From these jet shape, fragmentation
function, mass, moments and even the so-called splitting function
results, we start to collect consistent picture of jet structure
modification starting from a relatively unmodified core, reduction of
medium @xmath particles as we move away from the core and an enhancement
of low @xmath particles in the periphery of the jet. As we extend far
away from the jet axis, we are even able to recover the lost energy, if
we take into account the assumptions involved in the measurement. It is
safe to say that there have been many high impact results in the studies
of jets in heavy ion collisions in the past decade.

### 8.3 New age of jet measurements

Almost all the recent measurements on jet quenching highlight the
importance of understanding the correlation between the jet and the
medium. These correlations manifest in how jet structure is modified and
very recently, how the QGP itself is modified with the presence of the
jet. Any standard jet observable is dependent on two fundamental scales
in the problem; momentum and angular. This is what I call as the jet
phase space and the new age of jet measurements involves a systematic,
multifaceted study of this phase space.

#### 8.3.1 Systematic exploration of the phase space

In order to study sub-jet and jet structure observables efficiently in
heavy ion collisions, one must first understand their position on the
phase space of jet-medium interactions as shown in Fig: 8.1 .
Observables such as the radial moments and jet mass represent different
scales and provide information on different aspects of quenching, such
as parton energy loss and the kick away from the jet axis.

These observables could also be utilized in pPb and pp collisions since
they probe QCD properties which could be used to study several important
questions such as gluon jet fragmentation, parton shower modifications
and hadronization in high multiplicity events amongst others. Another
area of recent interest in the pp community is in the study of quark vs
gluon identification. If such an identification is possible in PbPb, one
can directly isolate the medium interaction properties such as coupling
to quarks and gluons and also study jet evolution in the dense medium. A
lot of such quark gluon identification is based on understanding the
observable and having a machine learning software framework provide
classifiers.

We are in a very exciting time for jet studies in pp and heavy ion
collisions wherein both experiment and theory are pushing the frontiers
of our current understanding. Within the next decade there are plans for
a new modular framework called JETSCAPE, which can incorporate multiple
models of the initial state, jets, energy loss all in one framework.
This would be very important to take the community forward with the
realistic goal of extracting the QGP’s inherent properties. In the near
future, one also expects a lot from the sPHENIX detector at RHIC, which
promises to kinematically overlap with experiments at the LHC, but at
the same time, offering an unique opportunity to probe the low @xmath
region with high sensitivity to medium-jet interactions. I am personally
very excited about all that i’ve mentioned above and each and every one
of these is important for us to elucidate the fundamental properties of
the QGP and thus systematically study the early universe within our
lifetimes.
