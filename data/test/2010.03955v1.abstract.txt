In this thesis, I explore the possibilities of conducting Bayesian
optimization techniques in high dimensional domains. Although high
dimensional domains can be defined to be between hundreds and thousands
of dimensions, we will primarily focus on problem settings that occur
between two and 20 dimensions. As such, we focus on solutions to
practical problems, such as tuning the parameters for an electron
accelerator, or for even simpler tasks that can be run and optimized
just in time with a standard laptop at hand.

Our main contributions is 1.) comparing how the log-likelihood affects
the angle-difference in the real projection matrix, and the found matrix
matrix, 2.) an extensive analysis of current popular methods including
strengths and shortcomings, 3.) a short analysis on how dimensionality
reduction techniques can be used for feature selection, and 4.) a novel
algorithm called "BORING", which allows for a simple fallback mechanism
if the matrix identification fails, as well as taking into consideration
"passive" subspaces which provide small perturbations of the function at
hand.

The main features of BORING are 1.) the possibility to identify the
subspace (unlike most other optimization algorithms), and 2.) to provide
a much lower penalty to identify the subspace if identification fails,
as optimization is still the primary goal.

LaTeX Bachelor Thesis Engineering ETH Zürich

\subtitle

Bachelor Thesis \dept Department of Computer Science \university Swiss
Federal Institute of Technology in Zurich \crest [] \supervisor Prof. A.
Krause
J. Kirschner
M. Mutný \degreetitle Bachelor of Science, Computer Science \degreedate
August 2018 \subject LaTeX
