More than a speculative technology, quantum computing seems to challenge
our most basic intuitions about how the physical world should behave.
 In this thesis I show that, while some intuitions from classical
computer science must be jettisoned in the light of modern physics, many
others emerge nearly unscathed; and I use powerful tools from
computational complexity theory to help determine which are which.

In the first part of the thesis, I attack the common belief that quantum
computing resembles classical exponential parallelism, by showing that
quantum computers would face serious limitations on a wider range of
problems than was previously known.  In particular, any quantum
algorithm that solves the collision problem —that of deciding whether a
sequence of @xmath integers is one-to-one or two-to-one—must query the
sequence @xmath times.  This resolves a question that was open for
years; previously no lower bound better than constant was known.  A
corollary is that there is no “black-box” quantum algorithm to break
cryptographic hash functions or solve the Graph Isomorphism problem in
polynomial time.  I also show that relative to an oracle, quantum
computers could not solve @xmath -complete problems in polynomial time,
even with the help of nonuniform “quantum advice states”; and that any
quantum algorithm needs @xmath queries to find a local minimum of a
black-box function on the @xmath -dimensional hypercube.  Surprisingly,
the latter result also leads to new classical lower bounds for the local
search problem.  Finally, I give new lower bounds on quantum one-way
communication complexity, and on the quantum query complexity of total
Boolean functions and recursive Fourier sampling.

The second part of the thesis studies the relationship of the quantum
computing model to physical reality.  I first examine the arguments of
Leonid Levin, Stephen Wolfram, and others who believe quantum computing
to be fundamentally impossible.  I find their arguments unconvincing
without a “Sure/Shor separator”—a criterion that separates the
already-verified quantum states from those that appear in Shor’s
factoring algorithm.  I argue that such a separator should be based on a
complexity classification of quantum states, and go on to create such a
classification.  Next I ask what happens to the quantum computing model
if we take into account that the speed of light is finite—and in
particular, whether Grover’s algorithm still yields a quadratic speedup
for searching a database.  Refuting a claim by Benioff, I show that the
surprising answer is yes.  Finally, I analyze hypothetical models of
computation that go even beyond quantum computing.  I show that many
such models would be as powerful as the complexity class @xmath , and
use this fact to give a simple, quantum computing based proof that
@xmath is closed under intersection.  On the other hand, I also present
one model—wherein we could sample the entire history of a hidden
variable—that appears to be more powerful than standard quantum
computing, but only slightly so.

\abstractsignature

\degreeyear

2004 \degreesemester Fall \degree Doctor of Philosophy \numberofmembers
3 \chair Professor Umesh Vazirani \othermembers Professor Luca Trevisan
Professor K. Birgitta Whaley \prevdegrees Bachelor of Science (Cornell
University) 2000 \field Computer Science \campus Berkeley \approvalpage

\copyrightpage
