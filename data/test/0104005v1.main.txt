##### Contents

-    1 A Short Review on Non-Perturbative Renormalization
    -    1.1 The General Setting
    -    1.2 Different Renormalization Schemes
        -    1.2.1 Infinite-Volume Schemes
        -    1.2.2 Finite-Volume Schemes
    -    1.3 The Scale Dependence of Renormalized Operators
    -    1.4 Renormalized Operators from the OPE
-    2 Perturbative Renormalization of the @xmath @xmath -Model
    -    2.1 Renormalization of the Model
    -    2.2 The Structure of Renormalized Operators
    -    2.3 Renormalization Constants
        -    2.3.1 @xmath Invariant Operators of Dimension 2
        -    2.3.2 Antisymmetric Rank 2 Operators
        -    2.3.3 Symmetric Rank 2 Operators
    -    2.4 Anomalous Dimensions
        -    2.4.1 @xmath Invariant Operators of Dimension 2
        -    2.4.2 Antisymmetric Rank 2 Operators
        -    2.4.3 Symmetric Rank 2 Operators
    -    2.5 Lattice Model and Lattice Composite Operators
        -    2.5.1 @xmath Invariant Operators of Dimension 2
        -    2.5.2 Antisymmetric Rank-2 Operators
        -    2.5.3 Symmetric Rank 2 Operators
    -    2.6 Lattice Anomalous Dimensions
    -    2.7 Renormalization-Group Equations
    -    2.8 On the Evaluation of the Running Coupling Constant
-    3 Operator Product Expansion for Conserved Currents
    -    3.1 Perturbative Calculation of the Wilson Coefficients
        -    3.1.1 Continuum
        -    3.1.2 Lattice
    -    3.2 Constraints on the OPE Coefficients
    -    3.3 Numerical Results
        -    3.3.1 The Observables
        -    3.3.2 One-Particle States
        -    3.3.3 Non-Perturbative Renormalization of the Lattice
            Energy-Momentum Tensor
        -    3.3.4 OPE for the Scalar Product of Currents
        -    3.3.5 OPE for the Antisymmetric Product of Currents
    -    3.4 First Answers
-    4 Operator Product Expansion for Elementary Fields
    -    4.1 Perturbative Expansions and OPE
        -    4.1.1 The Limits of Perturbative Expansions
        -    4.1.2 The Definition of Composite Operators
    -    4.2 Perturbative Calculation of the Wilson Coefficients
    -    4.3 Solution of the RG Equations
    -    4.4 Numerical Results
        -    4.4.1 The Observables
        -    4.4.2 One-Particle States
        -    4.4.3 Corrections to Scaling
        -    4.4.4 Field-Renormalization Constant
        -    4.4.5 Symmetric Operator
        -    4.4.6 Renormalization of the Symmetric Operator
        -    4.4.7 OPE in the Scalar Sector
        -    4.4.8 OPE in the Antisymmetric Sector
        -    4.4.9 OPE in the Symmetric Sector
    -    4.5 More Answers
-    Conclusions and Perspectives

## Chapter 1 A Short Review on Non-Perturbative Renormalization

Why do we need renormalization in lattice field theory? We can broadly
distinguish two types of needs: a “fundamental” one, and a
“phenomenological” one [ 1 ] .

By “fundamental” we mean the tuning of bare lattice parameters which is
necessary for recovering the correct continuum theory. In the case of
lattice QCD with Wilson fermions a “minimal” set of parameters to be
tuned is given by the gauge coupling and the quark masses. Since the
theory is asymptotically free, the bare gauge coupling must be sent to
zero. The bare masses can be obtained by fixing the masses of an
appropriate number of mesons in units of some reference scale, e.g., the
string tension. This type of renormalization is necessary no matter
which model we are studying. Generally speaking, physical predictions
can be extracted from the lattice regularized theory without further
renormalization. In fact physical quantities are given as matrix
elements of the @xmath matrix. Such matrix elements do not depend upon
the normalization of the interpolating fields.

This “first principles” point of view must be modified in many cases of
phenomenological interest. An important example is the study of QCD
corrections to weak interactions. Weak interactions cannot be
straightforwardly discretized and simulated on the lattice. This happens
for two types of reasons:

-   Practical ones: the masses of the weak bosons are much larger than
    the currently achievable lattice cutoffs.

-   Theoretical ones: preserving the chiral properties of fermions on
    the lattice is a difficult (and intensively studied) problem.

A widespread solution to the above problems consists in adopting the
effective hamiltonian approach. Heavy degrees of freedom are integrated
over treating weak interactions in perturbation theory. Non-perturbative
(low energy) QCD contributions are encoded in the hadronic matrix
elements of some basis of composite operators. Such operators must be
properly renormalized. This is what we referred to as the
“phenomenological” need for renormalization.

The renormalization of composite operators is a complex and important
problem. In this Chapter we shall review the renormalization techniques
which are used currently, having in mind the type of applications
sketched above.

The exposition is organized as follows. In Sec. 1.1 we add some feature
concerning the use of renormalized matrix elements in phenomenological
applications. In Sec. 1.2 we outline the two available approaches to
non-perturbative renormalization, broadly distinguishing between
infinite and finite volume schemes. In Sec. 1.3 we focus on a property
of renormalized operator (the dependence upon the renormalization scale)
which plays a special role in finite volume schemes. In Sec. 1.4 we
describe the new approach which will be tentatively investigated in this
Thesis.

### 1.1 The General Setting

The general context which we have in mind can be described schematically
as follows:

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

The “interesting quantity” on the left hand side of Eq. ( 1.1 ) depends
upon the application we are considering. If we are studying weak
interactions physics [ 2 , 3 ] , it can be the amplitude for a
non-leptonic decay as well as a meson mixing amplitude, etc. For deep
inelastic scattering applications [ 4 ] , it can be the moment of a
structure function. In both cases the aim is to include QCD effects in
electroweak processes. Widely separated energy scales play a role in
such processes. Among them a “large energy” scale @xmath can be usually
identified. We keep track of the @xmath dependence in Eq. ( 1.1 ). In
weak interactions physics this energy scale is, typically, the mass of
the weak vector bosons. In deep inelastic scattering the relevant scale
is determined by the exchanged four-momentum. The @xmath on the
right-hand side are local, gauge-invariant (under the colour @xmath
gauge group) operators ¹ ¹ 1 In general two other classes of operators
may appear [ 5 , 6 , 7 ] : (a) operators which are BRS-variations; (b)
operators which vanish by the equation of motions. However, as long as
@xmath and @xmath are on-shell, physical states, the matrix elements of
these two classes of operators vanish. , which are renormalized at the
scale @xmath . They are evaluated between the hadronic states @xmath and
@xmath . The series on the right-hand side is asymptotic in the
parameter @xmath . The exponent @xmath is fixed by naive power counting.
Usually the scale @xmath is much larger than the hadronic scales
involved in the matrix elements on the right-hand side of Eq. ( 1.1 ).
This allows to neglect all the terms of the series but a few ones.

The technical tool for obtaining the expansion given in Eq. ( 1.1 ) is
the Operator Product Expansion (OPE). The OPE has been postulated for
the first time by Wilson [ 8 ] thirty years ago, has been later proved
in perturbation theory by Zimmermann [ 9 ] , and is widely thought to
hold beyond perturbation theory. If the theory is asymptotically free
the Wilson coefficients @xmath can be computed in renormalization-group
(RG) improved perturbation theory. The result will be reliable as long
as @xmath is in the perturbative regime.

The general idea behind Eq. ( 1.1 ) is to divide the energy scales
involved in the process in two regimes. The perturbative regime from
@xmath to @xmath is well described by RG improved perturbation theory.
This contribution is kept into account by the Wilson coefficients @xmath
. The non-perturbative regime from @xmath to @xmath has to be treated
with some other method. This contribution is cast into the matrix
elements @xmath , whose computation is, in many cases, a still unsolved
problem.

For this approach to work the factorization scale @xmath must be chosen
large enough (i.e. in the perturbative regime). Can we give a
quantitative indication for the onset of the perturbative regime? The
answer to this question depends upon which observable is being studied
and which truncation in perturbation theory is used. As an example, let
us consider the running coupling @xmath and the running quark masses
@xmath in quenched QCD. These observables are very interesting since
their running has been computed non-perturbatively in [ 10 , 11 ] . The
perturbative expansions of the beta function and of the mass anomalous
dimensions are known up to four-loop order. We can then compare the
non-perturbative and the perturbative running of these quantities. Above
@xmath , two-loop perturbative expansions describe the non-perturbative
results with a systematic error of a few percent. We must be very
careful here because the systematic error is not well defined unless we
know the exact result. However, the large energy scale @xmath is, in all
practical applications, far in the perturbative regime. We can consider
it to be an infinite energy, for our purposes.

### 1.2 Different Renormalization Schemes

In this section we shall outline two general approaches to the
construction of renormalized operators. We shall refer to the simple
case of purely multiplicative renormalization (without mixing):

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath is a bare lattice operator, and @xmath is its renormalized
counterpart. In Eq. ( 1.2 ) we have emphasized the dependence of the
renormalization constant upon the various scales of the problem: the
lattice spacing @xmath , the renormalization scale @xmath and the
physical scale @xmath (the so called “lambda parameter”) which breaks
the scale invariance of the continuum theory. The renormalized operator
@xmath is required to have a finite continuum limit ( @xmath at @xmath
fixed).

In Eq. ( 1.2 ) we implicitly assumed an important simplifying feature:
the renormalization scheme is mass independent. Such a scheme can always
be defined for QCD. This is done by computing the renormalization
constants at zero quark masses [ 12 ] . Nevertheless it is often
difficult to implement such a scheme in numerical simulations.
Simulating QCD with very light quarks implies several complications:
finite volume effects, exceptional configurations, slowing down of the
computation of the quark propagator, etc. The way this problem is dealt
with depends upon the adopted renormalization method ² ² 2 This
discussion must be modified if we want to construct @xmath improved
operators [ 13 ] . In this case the @xmath includes terms which are
linear in @xmath , @xmath being the bare quark mass. .

Before discussing the various renormalization schemes, let us recall
that, if the operator @xmath in Eq. ( 1.2 ) is a Noether current, the
corresponding renormalization constant @xmath cannot depend upon @xmath
. The reason is that the values taken by the related conserved charges
are fixed algebraically. Examples of such operators are the vector and
axial flavour currents in QCD. There exists a well studied method for
renormalizing this type of operators using the Ward identities. We shall
not give more details on this type of operators and focus instead on the
“difficult” case of scale-dependent operators.

#### 1.2.1 Infinite-Volume Schemes

The use of infinite-volume non-perturbative renormalization schemes has
been suggested for the first time in Ref. [ 14 ] and intensively studied
since then ³ ³ 3 See, for instance, Refs. [ 15 , 16 , 1 , 17 ] .

The proposed procedure mimics what is often done in perturbation theory.
One determines the renormalization constants by requiring that some
well-chosen vertex function takes its tree-level value when the scale of
external momenta is equal to the renormalization scale. As an example,
let us consider the non-singlet pseudo-scalar density:

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

where @xmath is a generator of the flavour group @xmath . This is a case
of great physical relevance, since it gives access, through the PCAC
relation, to the quark mass renormalization [ 18 , 19 , 20 ] . We define
the following Green function with one @xmath insertion at zero momentum:

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

The indices @xmath and @xmath in the preceding expression are Dirac
indices and must not be summed over. Let us denote as @xmath the
corresponding vertex function. This is obtained from Eq. ( 1.4 ) by
amputating the external quark legs:

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

The renormalization condition reads:

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

where the trace @xmath has to be taken with respect to the Dirac indices
and @xmath is the tree-level value for the vertex function. The constant
@xmath on the right-hand side of Eq. ( 1.6 ) is needed in order to
renormalize the external quark legs. It can be computed by imposing a
condition analogous to Eq. ( 1.6 ) on the two-point quark function.

Notice that the correlation function ( 1.4 ) is not gauge invariant. In
order to avoid a trivial outcome of the above computation, a gauge must
be fixed. Usually the Landau gauge is chosen. Moreover, the condition (
1.6 ) is intended to be imposed at zero quark masses. In practice this
is done by extrapolating to the chiral limit the numerical result for
@xmath , obtained for a non-zero value @xmath of the quark masses. Apart
from this extrapolation, Eq. ( 1.6 ) yields the exact renormalization
constant at the scale @xmath up to lattice artifacts which are of order
@xmath (or @xmath if the theory is improved non-perturbatively).

In order to keep lattice artifacts and finite-size effect under control,
we must consider energy scales in the range:

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

and bare couplings such that

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

where @xmath is the linear lattice size in lattice units. Equations (
1.7 ) and ( 1.8 ) are the crucial limitations of infinite-volume
schemes. We shall reconsider them in the next Sections.

Equation ( 1.6 ), together with analogous conditions for other composite
operators and for the quark field, defines a particular renormalization
scheme. This is often referred to as the Regularization Independent (RI)
scheme.

Once the hadronic matrix elements have been computed and renormalized in
the RI scheme, we would like to use them in Eq. ( 1.1 ). Therefore, we
must “translate” them in the same scheme, usually minimal subtraction
(MS), used for the Wilson coefficients @xmath . This passage can be
accomplished by computing a finite renormalization constant. In our
example:

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

The constant @xmath can be reliably computed in perturbation theory as
long as

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

Notice that this condition follows from the simple fact that we compute
perturbatively ⁴ ⁴ 4 See Refs. [ 21 , 22 ] for an alternative proposal.
the Wilson coefficients @xmath in Eq. ( 1.1 ).

As discussed in the previous Section, Eq. ( 1.10 ) assures that the
separation between low-energy and high-energy contributions in Eq. ( 1.1
) is sensible, and that the result is @xmath independent. The
compatibility of the condition in Eq. ( 1.10 ) with the previous ones
given by Eq. ( 1.7 )-( 1.8 ) is a serious (and still not completely
solved) problem.

#### 1.2.2 Finite-Volume Schemes

Finite-volume schemes are the practical application of an important
observation due to Symanzik [ 23 ] : renormalizability is not spoiled
when a field theory is put on a finite space-time manifold. We can
define a finite volume renormalization scheme by using the linear size
@xmath of this space-time manifold as the renormalization scale.
Non-perturbative computations are made possible by discretizing this
space time on a lattice of spacing @xmath . The first advantage of this
approach, with respect to the infinite-volume one, is that the two
limitations in Eqs. ( 1.7 )-( 1.8 ) reduce to the much weaker:

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

These constraints correspond to working in the finite-size scaling (FSS)
regime. The second advantage is that a proper choice of the boundary
conditions produces a gap of order @xmath in the spectrum of the
Dirac-Wilson operator @xmath . This gap survives in the chiral limit
@xmath . One can safely work at @xmath avoiding chiral extrapolations.
Finally, a careful examination shows that nontrivial results can be
obtained without fixing a particular gauge.

How are finite-volume schemes implemented in practice? A popular
geometry is a @xmath lattice with twisted boundary conditions in the
space direction and Dirichelet boundary conditions in the time
direction. In order to have a unique scale in the problem the size of
the lattice in the time direction is proportional to the size in the
space direction: to be definite let us say @xmath . It is convenient to
think of the boundary conditions in the time direction as of “boundary
fields” (let us denote them @xmath or @xmath depending upon which of the
two boundaries we are considering) which must themselves be properly
renormalized. To be definite let us consider again the example of the
pseudoscalar density, already treated in the previous Section [ 11 ] .
The renormalization condition is

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

The ratio on the left-hand side of Eq. ( 1.12 ) is constructed so that
the uninteresting boundary-field renormalizations cancel. We shall not
describe the precise boundary conditions which are usually adopted,
although their careful choice is quite a relevant point.

The setting outlined above has been dubbed the ‘‘Schrödinger
functional’’ and has been much studied in the last years ⁵ ⁵ 5 An
incomplete list of references is [ 24 , 25 , 10 , 26 , 11 , 27 ] . See
also [ 28 , 29 , 30 ] for an earlier proposal. . It allows to compute
non-perturbatively the renormalization constants @xmath in the
interesting regime @xmath and @xmath with the minimum of computational
work.

The above handwaving description hides an important difficulty, and
leaves out the crucial step which is required for solving it. Let us in
fact consider the following trivial identity:

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

and recall that, in order to avoid lattice artifacts, we required @xmath
. In practical cases @xmath . At the end we would like to use our
renormalization constant @xmath for computing physical quantities from
lattice simulations. As stressed in the previous Sections
renormalization scale @xmath must then be safely in the perturbative
regime: let us say @xmath . For obtaining physical results we must
compute bare hadronic matrix elements near the infinite-volume limit.
This forces us to consider not too fine lattices: with current computing
capabilities we are restricted to @xmath . The last two conditions
imply, using the identity ( 1.13 ), @xmath , which contradicts the first
requirement in Eq. ( 1.11 ). There exists a clever solution to this
problem: we shall explain this solution in the next section.

### 1.3 The Scale Dependence of Renormalized Operators

In the previous Section we stressed the fundamental problems which arise
with two classes of non-perturbative renormalization schemes. The source
of these problems is the requirement of a large separation between the
different scales: @xmath . In infinite-volume schemes one tries to
realize all this scales on the same lattice, keeping all the length
scales much smaller than the size of the lattice, i.e. @xmath . This is
obviously difficult, since a very large lattice is required. In
finite-volume schemes one identifies the lattice size with the
renormalization scale. This produce however a separation between the
scales @xmath and @xmath which cannot be reproduced when hadronic,
infinite-volume, matrix elements are computed.

The first step to the solution of this dilemma consists in considering
the ratio:

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

The existence of the above limit is a scaling hypothesis, and is assured
by the existence of the continuum limit. The function @xmath is
universal ⁶ ⁶ 6 For a nice numerical verification of this universality
hypothesis, see Ref. [ 31 ] . , i.e. it does not depend upon the precise
definition of the lattice operator and of the lattice action, but only
upon the renormalization prescription. Finite lattice spacing
corrections to the limit defined by Eq. ( 1.14 ) are of order @xmath for
a general theory with fermions. They can be reduced to @xmath if the
lattice action and the operator @xmath are non-perturbatively improved.
The function @xmath is closely related to the anomalous dimensions of
the operator @xmath :

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

Let us suppose that we know @xmath . If we compute the renormalization
constant @xmath for some value of the lattice spacing @xmath and for
some scale @xmath , then we can use the function @xmath for computing it
at the same lattice spacing for any scale of the type @xmath (the most
common choice is @xmath ). In other words the function @xmath describes
the running of the renormalized operator @xmath . Its non-perturbative
determination allows to bypass the problems encountered in the previous
Section, both for finite and for infinite volume schemes.

Until now we did not specify any renormalization scheme. The second step
consists in noticing that, in a finite-volume scheme, it is quite simple
to compute the “step-scaling function” @xmath non-perturbatively. This
computation corresponds to the computation of a finite-size scaling
function. This is a remarkable feature of finite-size schemes. Their
peculiarity comes from the fact that they allow to consider very small
lattice spacings without using huge lattices.

### 1.4 Renormalized Operators from the OPE

In this Section we briefly discuss a recently proposed method [ 32 , 33
, 1 , 17 ] for constructing renormalized composite operators in
asymptotically free theories. This procedure shares many features of the
infinite-volume schemes described in Section 1.2 and in fact it is
defined in infinite volume. It has the advantage of being more direct
and allowing a simplified treatment of operator mixing. Moreover, it
avoids the evaluation of products of local operators at coincident
points. Such products must be taken into account with infinite-volume
schemes as the expression on the right-hand side of Eq. ( 1.4 ) shows.
Avoiding coincident points should reduce lattice artifacts and allow a
simpler implementation of operator improvement. Finally, the method we
will describe yields renormalized operators in a zero mass continuum
scheme without the necessity of taking the chiral limit.

We proceed now to describe the general context to which this method
apply:

-   Let us consider, for instance, the following simple example of
    Operator Product Expansion in the continuum:

      -- -------- -- --------
         @xmath      (1.16)
      -- -------- -- --------

    where the dots @xmath indicate terms of higher order in @xmath ,
    corresponding to operators of higher canonical dimension.

-   Let us suppose that we know how to construct the renormalized
    operators @xmath and @xmath non-perturbatively. This is the case if
    @xmath and @xmath are conserved Noether currents. If the lattice
    does not break the corresponding symmetry, then an exactly conserved
    discretized current can be constructed. Such a conserved lattice
    current does not renormalize. This happens, in lattice QCD, with the
    Noether currents of the vector flavour group.

-   Let us suppose that we are interested in computing some hadronic
    matrix element of @xmath . We denote this matrix element @xmath .

The proposed procedure works as follows:

1.  The Wilson coefficient @xmath in Eq. ( 1.16 ) is calculated using RG
    improved perturbation theory. Any renormalization scheme can be used
    in this step. Let us call @xmath the resulting ( @xmath -loop)
    approximation for the Wilson coefficient.

2.  The matrix element @xmath is computed in a numerical simulation for
    a properly chosen range of @xmath , let us say @xmath . This step
    gives a function @xmath .

3.  Finally @xmath is fitted using the form @xmath and keeping @xmath as
    the parameter of the fit.

The outcome of this third step, i.e. the parameter of the fit @xmath ,
is identified with the matrix element we are looking for, @xmath ,
renormalized in the same scheme and at the same scale at which we
computed the Wilson coefficient @xmath . This identification will be
correct in the limit @xmath keeping always @xmath . Of course in
practice @xmath and @xmath must be kept finite, because of the
finiteness of the lattice spacing. We can estimate the systematic errors
to be of the order of the neglected terms in the perturbative expansion
of the Wilson coefficient: @xmath , @xmath being the running coupling at
the scale @xmath .

Let us conclude by recalling the most important physical motivation for
the use of the above approach [ 32 ] . The study of weak decays through
the effective-hamiltonian formulation is often complicated by operator
mixings. The pattern of operator mixing is dictated by power counting
and is greatly restricted by the symmetries of the theory. In lattice
numerical computations, the Wilson discretization of the fermion action
is usually adopted. The explicit breaking of chiral symmetries in the
Wilson formulation makes operator mixing much more difficult to be
treated. In the OPE approach outlined above, the continuum OPE is
employed. As a consequence the right-hand side of Eq. ( 1.16 ) is
restricted by the symmetries of the continuum theory. Irrelevant terms
of the action, and, among them, the Wilson term, manifest themselves as
lattice artifacts and can be disregarded in the continuum limit.
Moreover chiral symmetry is completely restored at short distances: both
the spontaneous symmetry breaking and the fermion masses produce power
corrections to the leading behavior.

## Chapter 2 Perturbative Renormalization and Composite Operators in the
@xmath Non-Linear @xmath-Model

We aim at computing matrix elements of renormalized operators in the
@xmath non-linear @xmath model. In the next Chapters we shall adopt the
“OPE method”, sketched in Sec. 1.4 , for coping with this task. This
computation will constitute a non-trivial test of this newly proposed
approach.

Before proceeding, we shall study the renormalization of the model (and
in particular the renormalization of composite operators) in
perturbation theory. This is important for two reasons. First reason: it
is commonly supposed in non-perturbative renormalization studies, that
the structure of perturbative renormalization (which is dictated by the
symmetries and by power counting) holds beyond perturbation theory.
Second reason: in applying the OPE method we shall need some
perturbative inputs. A part of these inputs (the composite operators
anomalous dimensions) will be computed in this Chapter. Moreover it is
interesting to compare the outcomes of the OPE method to the
perturbatively renormalized operators. In order to allow this
comparison, we shall compute the lattice renormalization constants in
perturbation theory.

In Secs. 2.1 and 2.2 we present the model, its renormalization, and the
renormalization of composite operators in perturbation theory. In Sec.
2.3 we compute the continuum renormalization constants for some
interesting operators and in Sec. 2.4 we report the corresponding
anomalous dimensions. In Sec. 2.5 we repeat some of these computations
on the lattice. The basic definitions for lattice anomalous dimensions
are recalled in Sec. 2.6 . In Sec. 2.7 we recall how the renormalization
group (RG) can be used for improving the perturbative expressions of the
Wilson coefficients. A basic ingredient for evaluating RG improved
Wilson coefficients is the running coupling. In Sec. 2.8 we compare
various procedures for evaluating the running coupling.

### 2.1 Renormalization of the Model

The @xmath non-linear @xmath -model can be defined through the lattice
discretization. The standard lattice action reads:

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath is the forward lattice derivative, and the spin variables
@xmath are constrained to lie on the unit sphere: @xmath . The partition
function is obtained by specifying the measure:

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

The continuum counterpart of the above model is obtained, as usual in
perturbation theory, by writing down the naive continuum limit of the
action ( 2.1 ), and adopting a continuum regularization (we shall use
dimensional regularization). The naive continuum action reads @xmath .
In order to construct the perturbative expansion, the @xmath -vector
field @xmath is parametrized as follows:

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

and the fields @xmath are taken as the elementary (independent) degrees
of freedom of the theory. The perturbative expansion is obtained by
expanding the path integral for small fields @xmath . This perturbative
expansion is plagued by infra-red divergences. The problem can be
understood by noticing that the tree-level propagator of the @xmath
fields is @xmath and has no Fourier transform in two dimensions.

A possible approach for treating this problem is to introduce an
external magnetic field. The continuum action obtained in this approach
can be written as follows in terms of bare fields:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (2.4)
  -- -------- -------- -------- -- -------

with @xmath . The magnetic field @xmath acts as an infrared regulator
but breaks the @xmath symmetry. According to the Mermin-Wagner [ 34 , 35
] theorem, @xmath symmetry must be recovered in the @xmath limit. The
restoration of @xmath symmetry manifests itself in perturbation theory
in a rather peculiar way [ 36 , 37 , 38 ] . While the perturbative
expansion of @xmath invariant quantities is infrared finite in the
@xmath limit, infrared singularities do not cancel in the perturbative
expansion of non-invariant quantities. The latter can however be
re-expressed in terms of the former using @xmath symmetry.

The renormalizability of the perturbative expansion described above has
been investigated in Refs. [ 39 , 40 ] and proven in Ref. [ 41 ] . In
order to make the perturbative expansion ultraviolet finite, the
following renormalized quantities must be defined:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (2.5)
     @xmath   @xmath   @xmath      (2.6)
     @xmath   @xmath   @xmath      (2.7)
     @xmath   @xmath   @xmath      (2.8)
  -- -------- -------- -------- -- -------

The factor @xmath is introduced to implement naturally the @xmath
prescription. The two renormalization constants @xmath and @xmath
defined above are known to four-loop order in perturbation theory [ 42 ,
43 , 44 ] . The beta-function and the anomalous dimension of the field
@xmath are defined in terms of @xmath and @xmath as follows:

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

where we single out the dependence of these functions upon the
renormalization scheme. Within a different scheme we shall obtain
different RG functions @xmath and @xmath . For future use we fix the
notation of their perturbative expansion as follows:

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

The first coefficients of these expansions are listed below

  -- -------- -- --------
     @xmath      (2.11)
     @xmath      (2.12)
  -- -------- -- --------

where we dropped the superscript “scheme” since, as is well known, the
first coefficients @xmath , @xmath , and @xmath are scheme-independent.

In the following, we shall often refer to the schemes listed below:

-   The minimal subtraction @xmath renormalization scheme, already used
    in this Section, see also Secs. 2.3 and 2.4 . The corresponding
    beta-function and anomalous dimensions are @xmath and @xmath .

-   The bare lattice theory, see Secs. 2.5 and 2.6 . In this scheme the
    RG functions are denoted @xmath and @xmath .

-   The improved-coupling scheme, which differs from the lattice theory
    uniquely in the definition of the coupling constant, see Sec. 2.8
    and Eq. ( 2.201 ). We denote the corresponding functions as @xmath
    and @xmath .

-   The finite-size scheme, see Sec. 2.8 and Eq. 2.198 , whose RG
    functions are @xmath and @xmath .

### 2.2 The Structure of Renormalized Operators

In this Section we describe the structure of renormalization (and
mixing) for composite operators as it emerges in perturbation theory.
The basic task is to understand how @xmath symmetry restricts the
possible mixings among composite operators. This problem has been solved
in Refs. [ 41 , 45 ] . We recall here the results of these papers for
greater convenience of the reader.

The general form of a renormalized composite operator is

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

where the @xmath ’s are unrenormalized composite operators, that is
products of @xmath ’s, @xmath ’s (renormalized fields) and of their
derivatives. Which operators @xmath must appear on the r.h.s. of Eq. (
2.13 ) for a given @xmath on the l.h.s.? The naive answer would be: all
the operators which transform like @xmath under @xmath and have
canonical dimension @xmath . This answer is wrong because of the
magnetic field in Eq. ( 2.4 ) which breaks explicitly the @xmath
symmetry ¹ ¹ 1 A similar problem is encountered in non-abelian gauge
theories. In order to renormalize gauge-invariant operators, both gauge
non-invariant, and BRS non-invariant operators must be subtracted [ 5 ]
. .

In order to give the correct answer, let us start by considering the
non-linear realization of the @xmath symmetry on the independent degrees
of freedom:

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

In the following we shall use the convention @xmath . The transformation
rule defined above is a rotation on a sphere of renormalized radius
@xmath . In fact a rotation of radius one (i.e. Eq. ( 2.14 ) with the
substitution @xmath ) does not leave invariant the action ( 2.4 ) even
in the limit @xmath . We could say that renormalization changes the
transformation properties of the fields.

Let us now consider a composite operator @xmath and write down its
variation under the rotation ( 2.14 ). If we write @xmath as a function
of @xmath , and its derivatives @xmath , we can define the variation of
@xmath induced by Eq. ( 2.14 ) as follows:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.15)
  -- -------- -------- -------- -- --------

The variation @xmath can be written more explicitly as follows:

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

We consider now an irreducible multiplet @xmath of composite operators:

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

where the matrices @xmath define a linear irreducible representation of
(the Lie algebra of) @xmath . It easy to classify all the multiplets of
dimension zero [ 45 ] . They are the irreducible @xmath tensor of rank
@xmath :

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

where the “traces” term assures that @xmath is traceless and completely
symmetric in the indices @xmath . Another simple example is given by

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

which has dimension @xmath , and is a rank- @xmath @xmath tensor.

Let us call @xmath the renormalized counterparts of the multiplet ( 2.17
). The naive expectation would be that the renormalized operators
transform as follows

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

Equation ( 2.20 ) holds for operators of dimension zero, but it is wrong
in the general case. In order to give the correct answer in the general
case, we introduce the following composite operator:

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

which can be rewritten as follows:

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

The operator @xmath is not invariant under @xmath transformations, but
it is invariant under the unbroken subgroup @xmath .

A generic composite operator @xmath can be considered as a function of
@xmath , and of the derivatives of according to the following rule:

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

which is a simple change of variables. This allows us to define a new,
and somewhat artificial, transformation rule “at fixed @xmath ”:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.24)
  -- -------- -------- -------- -- --------

Analogously to Eq. ( 2.16 ), we can write explicitly the action of
@xmath , as follows:

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

Notice that the derivative with respect to @xmath on the r.h.s. of Eq. (
2.25 ) is taken at @xmath fixed. We can now formulate the correct
statement regarding the renormalization structure of a generic composite
operator. This is obtained by rewriting Eq. ( 2.20 ) with the
substitution @xmath :

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

Notice that, since @xmath is invariant under the unbroken @xmath
subgroup, @xmath if @xmath . This is what we expect, since the global
unbroken symmetries are preserved under renormalization.

An explicit form for the renormalized operators @xmath can be obtained
by noticing that the canonical dimension of @xmath is 2. To be definite
let us consider a renormalization scheme such that the renormalized
operators depend only logarithmically upon the renormalization scale.
Minimal subtraction is an example of such a scheme. If we call @xmath
the canonical dimension of @xmath we get

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

The @xmath are local functionals of @xmath of canonical dimension @xmath
. The @xmath are multiplets of composite operators of canonical
dimension @xmath , transforming like @xmath under @xmath . Moreover they
do not depend upon @xmath .

We shall now give a proof of the previous statement along the lines of
Refs. [ 41 , 46 ] . In the following it will be useful to consider
@xmath as an external space dependent field @xmath . Equation ( 2.21 )
will be modified accordingly with the prescription @xmath .

We shall prove Eq. ( 2.27 ) in perturbation theory by induction over the
perturbative order. Our first step will be formulating the thesis at
@xmath -loop order. Then we shall prove it for any @xmath by showing
that, assuming it as an inductive hypothesis for a given order @xmath ,
it holds also for the successive order @xmath .

Given a multiplet of composite operators @xmath , it is possible to
construct the @xmath -loop perturbatively renormalized operators @xmath
in such a way that:

1.  @xmath at tree level;

2.  the insertions of @xmath are ultraviolet finite up to terms of order
    @xmath ;

3.  @xmath if @xmath ;

4.  @xmath if @xmath .

Before proving the points 1 - 4 , let us make a few observations. The
statement 3 is trivial because, as we noticed above, global symmetries
are preserved under renormalization. The point 4 replaces the naive
expectation @xmath , see Eq. ( 2.20 ), which would be the simplest
extension of point 3 .

Let us now elaborate on point 4 . We want to rewrite it in a form which
can be easily obtained with the generating functional technique. More
precisely, we formulate it as follows:

  -- -------- -- --------
     @xmath      (2.28)
  -- -------- -- --------

where we define

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.29)
     @xmath   @xmath   @xmath      (2.30)
  -- -------- -------- -------- -- --------

The above definition of @xmath differs from the one given in Eq. ( 2.4 )
only in the fact that the magnetic field @xmath is taken to be position
dependent. Using Eqs. ( 2.29 ) and ( 2.30 ), it is easy to show that

  -- -------- --
     @xmath   
  -- -------- --

whence, using the chain rule:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.32)
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
  -- -------- -------- -------- -- --------

we finally obtain, using Eqs. ( 2.25 ) and ( 2.14 ):

  -- -------- -- --------
     @xmath      (2.34)
  -- -------- -- --------

Equation ( 2.28 ) is then equivalent to the point 4 of our thesis.

The proof of 1 - 4 proceeds by induction on @xmath . The thesis is
obviously true for @xmath by taking @xmath . Let us suppose the thesis
to be true for a generic integer @xmath . We want to construct new
renormalized operators @xmath which satisfy 1 - 4 with @xmath .
Equations ( 2.32 ) and ( 2.2 ) allow us to derive a relation between
@xmath and @xmath which will turn out to be useful in the following:

  -- -- -- --------
           (2.35)
  -- -- -- --------

We are interested in the behavior of the renormalized operators @xmath .
Because of the induction hypothesis 4 , we get

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

This identity characterize the behavior of the renormalized operators
under an @xmath rotation. Notice that the second term on the r.h.s. is a
quantum correction which receives contributions only from the @xmath
terms on the r.h.s. of Eq. ( 2.27 ).

Our next step will be to prove a Ward identity related to the explicitly
broken symmetries. We shall adopt the generating functional technique.
The final outcome is given by Eq. ( 2.48 ). In order to prove it, we
define the effective action @xmath as follows:

  -- -------- -- --------
     @xmath      (2.37)
     @xmath      
     @xmath      (2.38)
  -- -------- -- --------

where we added the sources @xmath coupled to the composite operators
@xmath . The @xmath invariant integration measure is formally defined
as:

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

The usual generating functional is recovered when the fields @xmath
vanish. The vertex functions without composite operators insertions are
obtained by taking the derivative with respect to @xmath at @xmath :

  -- -------- -- --------
     @xmath      (2.40)
  -- -------- -- --------

We are interested in renormalizing vertex functions with only one
inserted composite operator. This is enough for making finite all the
correlation functions with an arbitrary number of composite operators at
separate positions. The vertex functions with one composite operator
insertion are determined by the term of @xmath linear in @xmath :

  -- -------- -- --------
     @xmath      (2.41)
  -- -------- -- --------

Notice that the zeroth-order term of the above expansion @xmath is
finite to any order in perturbation theory. In fact the coupling
constant, the elementary fields @xmath , and the magnetic field have
been properly renormalized in Eq. ( 2.29 ). Because of the inductive
hypothesis 2 , the first order terms @xmath are finite up to divergences
of order @xmath .

Let us check the above definitions at tree level. The loop expansion
reads:

  -- -------- -- --------
     @xmath      (2.42)
  -- -------- -- --------

and, using the inductive hypothesis 1 , we obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

which yields the correct insertions of the operators @xmath at tree
level.

Now we have set up the effective functional formalism and we can proceed
to prove the relevant Ward identity. Let us consider the following
symmetry transformation:

  -- -------- -- --------
     @xmath      (2.44)
  -- -------- -- --------

This is a modification of Eq. ( 2.14 ) and can be thought as a “modified
rotation” on a sphere of radius:

  -- -------- -- --------
     @xmath      (2.45)
  -- -------- -- --------

The modification is required by the introduction of the source terms
@xmath in Eq. ( 2.37 ), just as the introduction of counterterms in the
action requires a modification of the radius @xmath . The symmetry
transformation ( 2.44 ) follows the general prescription of Ref. [ 41 ]
: if a term @xmath is added to the action ( 2.29 ), the modified
transformation rule will be

  -- -------- -- --------
     @xmath      (2.46)
  -- -------- -- --------

In the following we shall work at order @xmath . Using Eq. ( 2.36 ) it
is easy to obtain the identity:

  -- -------- -- --------
     @xmath      (2.47)
  -- -------- -- --------

The term linear in @xmath of the above identity reads

  -- -------- -- --------
     @xmath      (2.48)
  -- -------- -- --------

Equation ( 2.48 ) is the Ward identity related to the explicitly broken
@xmath symmetry. It gives a constraint on the insertions of composite
operators and, in particular, on their divergences.

We remark that @xmath diverges at order @xmath . Since Eq. ( 2.48 ) is
linear in @xmath and valid for any value of the cutoff we can choose a
decomposition

  -- -------- -- --------
     @xmath      (2.49)
  -- -------- -- --------

such that: (i) @xmath is finite; (ii) @xmath ; (iii) both @xmath and
@xmath satisfy Eq. ( 2.48 ). Moreover the decomposition ( 2.49 ) can be
chosen such that @xmath is local, i.e. a function of @xmath . This is a
general theorem on the renormalization of composite operators and it is
independent of the symmetry properties of the theory [ 9 ] .

Given such a decomposition we get, from Eq. ( 2.48 ):

  -- -------- -- --------
     @xmath      (2.50)
  -- -------- -- --------

where @xmath is the first term of the perturbative expansion of the
action ( 2.29 ): @xmath . Equation ( 2.50 ) is “almost” what we need. We
would like that @xmath appeared on the l.h.s. of Eq. ( 2.50 ), instead
of @xmath . However this problem can be overcome by adding @xmath terms
to @xmath . More precisely, it is possible to find a local functional

  -- -------- -- --------
     @xmath      (2.51)
  -- -------- -- --------

which satisfies Eq. ( 2.50 ) with the substitution @xmath . Such a
functional can be found by solving recursively

  -- -------- --
     @xmath   
  -- -------- --

for @xmath .

If is now easy to verify that the renormalized operators can be defined
at @xmath loops as follows

  -- -------- -- --------
     @xmath      (2.53)
  -- -------- -- --------

The definition ( 2.53 ) satisfies the inductive thesis, i.e. 1 - 4 with
the substitution @xmath .

### 2.3 Renormalization Constants

In this Section we apply the general results of Sec. 2.2 to a few
interesting cases. We describe the mixing structure for various
composite operators and give the corresponding renormalization
constants. In order to distinguish the various renormalization constants
we adopt the following convention. Given a basis @xmath of composite
operators, they can be characterized through their canonical dimension
@xmath , and their transformation properties under @xmath rotations. In
particular they will be @xmath tensors of rank @xmath . We shall denote
the corresponding renormalization constants as @xmath . Renormalized
operators are obtained as follows from bare ones: @xmath .

#### 2.3.1 @xmath Invariant Operators of Dimension 2

All the @xmath invariant operators of dimension 2 can be expressed as
linear combinations ² ² 2 Notice that @xmath is obtained from @xmath by
taking the trace over the space-time indices. They are not linearly
independent. However, as is well known, minimal subtraction does not
commute with taking the trace over the space-time indices. We must then
consider the two operators as distinct elements of the basis. of @xmath
and @xmath . Under renormalization they mix with the operator @xmath
defined in Eq. ( 2.21 ):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.54)
     @xmath   @xmath   @xmath      (2.55)
     @xmath   @xmath   @xmath      (2.56)
  -- -------- -------- -------- -- --------

The computation of the renormalization constants @xmath is pretty
simple. For this particular set of operators they can be expressed in
terms of the field and coupling constant renormalizations @xmath and
@xmath .

We start by noticing that a particular linear combination of @xmath and
@xmath yields the energy-momentum tensor ³ ³ 3 The reader will notice
that Eq. ( 2.57 ) gives the correct energy-momentum tensor only in the
limit @xmath , see Eq. ( 2.4 ). For nonzero magnetic field a term @xmath
must be added. However, since this term is finite, our discussion does
not need any modification.

  -- -------- -- --------
     @xmath      (2.57)
  -- -------- -- --------

From energy-momentum conservation it follows that @xmath is finite if we
replace the renormalized fields and the renormalized coupling constant
in Eq. ( 2.57 ) with the bare ones. It follows that:

  -- -------- -- --------
     @xmath      (2.58)
  -- -------- -- --------

Then we remark that differentiating the action ( 2.4 ) with respect to
renormalized parameters yields finite operators [ 47 ] . Upon
differentiation with respect to @xmath (keeping @xmath , @xmath and
constants), we obtain a linear combination of @xmath and @xmath as on
the right-hand side of ( 2.55 ), with the following coefficients:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.59)
     @xmath   @xmath   @xmath      (2.60)
  -- -------- -------- -------- -- --------

We can unambiguously identify the above coefficients with the correct
@xmath renormalization constants because they are series of poles in
@xmath .

The next useful observation is that the equations of motion, obtained by
varying the action ( 2.4 ) with respect to , do not need
renormalization. It follows that the combination

  -- -------- -- --------
     @xmath      (2.61)
  -- -------- -- --------

is finite, cf. Eq. ( 2.22 ). Combining this result with the previous
ones, we get

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.62)
     @xmath   @xmath   @xmath      (2.63)
  -- -------- -------- -------- -- --------

The remaining renormalization constants can be computed by using Eq. (
2.57 )–( 2.60 ):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.64)
     @xmath   @xmath   @xmath      (2.65)
  -- -------- -------- -------- -- --------

We finally notice that the identities derived above are true only if a
“consistent” renormalization scheme is adopted. In particular there must
be consistency between the prescriptions for renormalizing the action
and the composite operators. Examples of such schemes are minimal
subtraction or zero momentum (BPHZ) subtraction.

The above results allow us to rewrite Eq. ( 2.22 ) in terms of
renormalized operators:

  -- -------- -- --------
     @xmath      (2.66)
  -- -------- -- --------

In the following we shall be interested in on-shell matrix elements of
composite operators at zero magnetic field ( @xmath ). Equation ( 2.66 )
allows us to eliminate the contribution of “spurious” operator @xmath in
such matrix elements.

The renormalization constants computed in this Section can be used for
accomplishing a simple exercise: the computation of the trace of the
energy-momentum tensor. Using Eq. ( 2.57 ), we have

  -- -------- -- --------
     @xmath      (2.67)
  -- -------- -- --------

Then, using Eqs. ( 2.55 ) and ( 2.56 ), we can rewrite

  -- -------- -- --------
     @xmath      (2.68)
  -- -------- -- --------

where we have expressed @xmath and @xmath in terms of @xmath and @xmath
using Eqs. ( 2.9 ), and dropped the superscripts @xmath on @xmath and
@xmath . We finally obtain

  -- -------- -- --------
     @xmath      (2.69)
  -- -------- -- --------

#### 2.3.2 Antisymmetric Rank 2 Operators

We shall now consider operators which are tensors of @xmath of rank two
(i.e. they have two @xmath indices). Let us begin from operators which
are antisymmetric under the indices exchange. Obviously, there exists no
such operator of dimension zero. There exists a unique antisymmetric
operator of dimension @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.70)
  -- -------- -------- -------- -- --------

which is the Noether current associated to the @xmath symmetry
Conservation of @xmath implies

  -- -------- -- --------
     @xmath      (2.71)
  -- -------- -- --------

We can classify the antisymmetric, rank @xmath operators of dimension
@xmath according to their Lorentz ⁴ ⁴ 4 Here and in the following we
denote as Lorentz transformations the ordinary @xmath rotations of the
two-dimensional euclidean space-time. These must be distinguished from
the internal @xmath rotations of the fields . symmetry. Let us list them
in order of increasing spin (respectively 0, 1, 2):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.72)
     @xmath   @xmath   @xmath      (2.73)
     @xmath   @xmath   @xmath      (2.74)
  -- -------- -------- -------- -- --------

The three operators defined above can be written as linear functions of
@xmath . As a consequence they renormalize as the current itself and do
not mix.

#### 2.3.3 Symmetric Rank 2 Operators

Finally we shall consider rank-two @xmath tensors which are symmetric
and traceless in the two @xmath indices. The unique dimension @xmath
operator with this symmetry is:

  -- -- -------- -------- -- --------
        @xmath   @xmath      (2.75)
  -- -- -------- -------- -- --------

The corresponding renormalization constant has been calculated in Ref. [
43 , 44 ] up to four-loop order. We give below the first two terms of
the perturbative result:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.76)
  -- -------- -------- -------- -- --------

There are @xmath linearly independent operators of dimension @xmath . A
simple basis for these operators is the following:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.77)
     @xmath   @xmath   @xmath      (2.78)
     @xmath   @xmath   @xmath      (2.79)
     @xmath   @xmath   @xmath      (2.80)
     @xmath   @xmath               (2.81)
     @xmath   @xmath               (2.82)
     @xmath   @xmath               (2.83)
  -- -------- -------- -------- -- --------

We computed the corresponding renormalization matrix at two-loop order
in perturbation theory. In the @xmath scheme we get:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.84)
  -- -------- -------- -------- -- --------

with

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.85)
     @xmath   @xmath   @xmath      (2.86)
                                   
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

While the operators @xmath ,…, @xmath are ordinary rank two @xmath
tensors, @xmath is the product of the non @xmath invariant operator
@xmath times a rank two @xmath tensor. This mixing pattern agrees with
the general results of Sec. 2.2 .

Analogously to what we did in Sec. 2.3.1 , we can eliminate the non
@xmath covariant operator @xmath in the limit @xmath and on-shell. Let
us prove this statement in the general case. We consider Eq. ( 2.22 )
and multiply it by a generic finite local operator @xmath :

  -- -------- -- --------
     @xmath      (2.88)
  -- -------- -- --------

We would like to renormalize the previous Equation. We notice that, on
general grounds [ 47 ] , the last term on the r.h.s. of Eq. ( 2.88 ) is
finite. Applying minimal subtraction to both sides of Eq. ( 2.88 )
amounts to subtracting equal quantities from the left-hand and
right-hand sides. In fact Eq. ( 2.88 ) holds for any value of @xmath ,
and thus holds between the poles in @xmath . It follows that:

  -- -------- --
     @xmath   
  -- -------- --

Finally we remark that the last term on the r.h.s. of this Equation
vanishes on-shell. The contact term due to @xmath does not contribute in
dimensional regularization because of the well known identity @xmath .
Using Eq. ( LABEL:AlphaTimesSomething ) we can eliminate @xmath in
favour of @xmath (on-shell, in the limit @xmath ).

We have chosen the basis defined in Eqs. ( 2.77 ),…,( 2.83 ) for sake of
simplicity. However the structure of the mixing matrix ( 2.84 ) becomes
more transparent if we use the following new basis ⁵ ⁵ 5 This definition
holds for bare operators. If minimal subtraction is adopted, the
renormalized basis reads: @xmath , @xmath ; @xmath , @xmath , @xmath ,
@xmath , @xmath . : @xmath , @xmath ; @xmath , @xmath , @xmath , @xmath
, @xmath . Notice that @xmath and @xmath are space derivatives and
therefore their insertion at zero momentum vanishes. Moreover @xmath and
@xmath are proportional to @xmath up to contact terms:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.90)
     @xmath   @xmath   @xmath      (2.91)
  -- -------- -------- -------- -- --------

From the above observations we can deduce the following structure of the
mixing matrix:

  -- -------- -- --------
     @xmath      (2.92)
  -- -------- -- --------

where we used a block notation.

The structure ( 2.92 ) can be easily verified on the two-loop
expressions given in Eqs. ( 2.85 )-( LABEL:RenConst2.2.C ). In the new
basis the renormalization matrix of Eq. ( 2.84 ) becomes

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.93)
  -- -------- -------- -------- -- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (2.94)
     @xmath   @xmath   @xmath      (2.95)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

### 2.4 Anomalous Dimensions

In this Section we list the anomalous dimensions for some of the
composite operators treated in the previous one.

First of all we shall recall the basic definitions. This will be useful
in order to fix our notations. Let us consider a set of operators which
is “complete” under mixing:

  -- -------- -- --------
     @xmath      (2.97)
  -- -------- -- --------

We adopt the convention of Ref. [ 47 ] : the operators on the r.h.s. of
Eq. ( 2.97 ) are local functions of the renormalized fields , @xmath ,
and of the renormalized parameters @xmath and @xmath . We can rewrite
Eq. ( 2.97 ) in a matrix notation as follows:

  -- -------- -- --------
     @xmath      (2.98)
  -- -------- -- --------

where @xmath @xmath @xmath , and @xmath @xmath @xmath .

The anomalous dimension matrix of @xmath is defined implicitly by the
following relation:

  -- -------- -- --------
     @xmath      (2.99)
  -- -------- -- --------

Equation ( 2.99 ) is a shorthand for the RG equation:

  -- -------- -- ---------
     @xmath      (2.100)
  -- -------- -- ---------

where @xmath is the vertex function with one @xmath insertion and @xmath
-“legs”. The running of the magnetic field is given by the anomalous
dimensions defined below:

  -- -------- -- ---------
     @xmath      (2.101)
  -- -------- -- ---------

In Eq. ( 2.97 ) and in the previous Section we used the convention of
defining renormalized operators as products of renormalized fields times
an operator renormalization constant. This convention makes it clear the
origin of composite-operator renormalization. This is necessary because
of short-distance singularities which arise when we consider two or more
fields at the same space-time point. However, our convention is
unpractical for giving explicit formulae for the anomalous dimensions
defined in Eq. ( 2.99 ). The renormalization of the fields ( and @xmath
), which is implicit on the r.h.s. of Eq. ( 2.97 ), must be taken into
account. Let us consider the case of a set of operators @xmath which are
the product of @xmath fields ( , @xmath or their derivatives @xmath ,
@xmath , etc.). Schematically we could write @xmath . In this case the
following formula can be obtained from Eqs. ( 2.97 ) and ( 2.99 ):

  -- -------- --
     @xmath   
  -- -------- --

A simple example of Eq. ( LABEL:ExplicitAnomalous ) is the computation
of the anomalous dimension of the elementary field itself. In this case
@xmath , @xmath and @xmath . From Eq. ( LABEL:ExplicitAnomalous ) it
follows that

  -- -------- -- ---------
     @xmath      (2.103)
  -- -------- -- ---------

a well-known result which agrees with the definition Eq. ( 2.99 ), see
also Eq. ( 2.100 ).

Equation ( 2.99 ) can be solved by introducing the renormalization-group
invariant (RGI) operators @xmath as follows:

  -- -------- -- ---------
     @xmath      (2.104)
  -- -------- -- ---------

where we expanded @xmath , and @xmath denotes the @xmath -ordered
exponential:

  -- -------- -- ---------
     @xmath      (2.105)
  -- -------- -- ---------

If @xmath renormalizes multiplicatively, then @xmath is a scalar
function and Eq. ( 2.104 ) simplifies to:

  -- -------- -- ---------
     @xmath      (2.106)
  -- -------- -- ---------

The new operator @xmath is renormalization-group invariant, i.e. its
insertions satisfy:

  -- -------- -- ---------
     @xmath      (2.107)
  -- -------- -- ---------

Moreover, unlike @xmath , @xmath is scheme-independent.

Notice that, in general, we are not interested in the whole set of
operators which mix under renormalization, see Eq. ( 2.97 ). A part of
them is proportional to the non @xmath -covariant operator @xmath ,
defined in Eq. ( 2.21 ). In general we shall consider on-shell
correlation functions in the @xmath limit. In this case Eq. (
LABEL:AlphaTimesSomething ) can be used to eliminate the non-covariant
operators.

Does any RG equation hold for the “reduced” basis which is obtained
after the elimination of @xmath ? The answer is positive. First we
choose an operator basis such that the operator @xmath always appears in
the combination @xmath . Because of the general structure of composite
operators outlined in Sec. 2.2 , we can distinguish two classes of
operators: @xmath @xmath -covariant operators, let us denote them
collectively as @xmath ; @xmath products of @xmath -covariant operators
times some power of @xmath , let us denote them as @xmath . Because of
Eq. ( 2.88 ) the operators @xmath vanish on-shell, for @xmath .
Therefore the renormalization matrix has the following triangular form:

  -- -------- -- ---------
     @xmath      (2.108)
  -- -------- -- ---------

It follows that the operators @xmath satisfy the following RG equation
(in shorthand notation):

  -- -------- -- ---------
     @xmath      (2.109)
  -- -------- -- ---------

The anomalous dimension matrix @xmath to be used in Eq. ( 2.109 ) is the
same as if there were no mixing with the operators @xmath .

We come now to the compilation of our list of anomalous dimensions,
classifying them, as in the previous Section, according to their @xmath
symmetry and canonical dimension.

#### 2.4.1 @xmath Invariant Operators of Dimension 2

In this particular case, we were able to express the renormalization
matrix @xmath in terms of the field and the coupling constant
renormalizations, @xmath and @xmath . This allows us to write the
corresponding anomalous dimension matrix in terms of the beta function
and the field anomalous dimensions, @xmath and @xmath . The result is
given below:

  -- -------- -- ---------
     @xmath      (2.110)
  -- -------- -- ---------

In particular from Eqs. ( 2.57 ) and ( 2.58 ), we get the anomalous
dimensions of the energy-momentum tensor ⁶ ⁶ 6 This result cannot be
obtained by applying directly Eq. ( LABEL:ExplicitAnomalous ), since
this is valid only for operators which are products of renormalized
fields (and their derivatives) without explicit @xmath dependence.
Equation ( LABEL:ExplicitAnomalous ) can be applied, for instance, to
@xmath . @xmath . This is a well known fact: conserved currents are RGI,
see Eq. ( 2.107 ).

#### 2.4.2 Antisymmetric Rank 2 Operators

We can apply to the Noether current @xmath the same observations
concerning the energy-momentum tensor made in the previous Subsection.
We get @xmath .

The three operators @xmath , @xmath defined in Eqs. ( 2.72 )-( 2.74 )
have @xmath , and it is easy to see that this implies @xmath . This is a
trivial consequence of the fact that the @xmath are linear combinations
of @xmath .

#### 2.4.3 Symmetric Rank 2 Operators

The anomalous dimensions of the dimension-0 operator ( 2.75 ) have been
computed up to four-loop order in Refs. [ 43 , 44 ] . Using Eqs. ( 2.76
) and ( LABEL:ExplicitAnomalous ) with @xmath , we can write the first
two terms of the perturbative expansion:

  -- -------- -- ---------
     @xmath      (2.111)
  -- -------- -- ---------

Let us now consider the anomalous dimensions matrix of the dimension-2,
symmetric traceless rank-2 @xmath tensors. It is convenient to choose a
basis which simplifies the solution of the RG equations. Such a basis
can be constructed from the @xmath operators, defined in the text above
Eqs. ( 2.90 ) and ( 2.91 ). The new basis will contain operators of
definite spin (0 or 2) and is defined as follows:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.112)
     @xmath   @xmath   @xmath      (2.113)
     @xmath   @xmath   @xmath      (2.114)
     @xmath   @xmath   @xmath      (2.115)
     @xmath   @xmath   @xmath      (2.116)
     @xmath   @xmath   @xmath      (2.117)
     @xmath   @xmath   @xmath      (2.118)
  -- -------- -------- -------- -- ---------

Among the above operators, @xmath , @xmath , @xmath and @xmath are
Lorentz scalars (i.e. they have spin 0), while @xmath , @xmath and
@xmath are rank-2, symmetric, traceless Lorentz tensors (i.e. they have
spin 2). These two classes do not mix under renormalization. Notice
that, in the above definitions, we did not use the notation @xmath ,
since, for instance

  -- -------- -- ---------
     @xmath      (2.119)
  -- -------- -- ---------

Because of the observations made above and in Sec. 2.3.3 , the structure
of the anomalous dimension matrix is

  -- -------- -- ---------
     @xmath      (2.120)
  -- -------- -- ---------

Moreover, since both @xmath and @xmath are total space-time derivatives
of the dimension zero operator ( 2.75 ), we get

  -- -------- -- ---------
     @xmath      (2.121)
  -- -------- -- ---------

Both the statements ( 2.120 ), and ( 2.121 ), are easily verified on the
two-loop result:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.122)
  -- -------- -------- -------- -- ---------

where

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.123)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ---------

### 2.5 Lattice Model and Lattice Composite Operators

We shall now consider the non–perturbative lattice definition of the
theory which is formally described by Eq. ( 2.4 ). Moreover we shall
study some examples of lattice composite operators in order to
understand how renormalization must be adapted to the lattice
regularization. In perturbation theory, there are three main
modifications concerning this subject:

-   The lattice breaks the symmetry of the action ( 2.4 ) under
    space–time transformations. As a consequence the operators @xmath
    and @xmath on the left and right-hand sides of Eq. ( 2.13 ), may
    belong to different representations of the Lorentz group.

-   In general there exist different lattice counterparts of a given
    continuum operator. All of them differ by “irrelevant” terms. After
    renormalization, these lattice discretization are supposed to
    converge to the same continuum limit with corrections of order
    @xmath . Better convergence rates can be obtaining by applying the
    Symanzik improvement program. If, for instance, action and operator
    improvement is non–perturbatively implemented up to @xmath , then we
    expect an improved convergence rate @xmath .

-   As for any cutoff regularization (dimensional regularization is
    somehow an exception in this respect), correlation functions of
    composite operators may have power-like divergences of the type
    @xmath . This requires power subtractions. Considering again Eq. (
    2.13 ), it may happen that @xmath , and that @xmath as @xmath .

Examples of the above remarks can be given in perturbation theory.
Nevertheless they are widely believed to hold beyond perturbation
theory. The last one, in particular, implies severe difficulties in the
non–perturbative renormalization of some composite operators.

The simplest discretization of the action ( 2.4 ) is given by Eq. ( 2.1
). For a discussion of other equivalent choices we refer to [ 48 ] .

As in the continuum, lattice perturbation theory can be made infrared
finite by adding an external magnetic field:

  -- -------- -- ---------
     @xmath      (2.125)
  -- -------- -- ---------

Moreover, one must keep track of the measure contribution. This can be
done by adding a new term to the action ( 2.125 ), yielding:

  -- -------- -- ---------
     @xmath      (2.126)
  -- -------- -- ---------

The procedure outlined above is by no means unique. There exist
alternative possibilities for regularizing the infrared singularities
which plague perturbation theory. A theoretically appealing approach
consists in putting the model in a finite box [ 49 ] . The independence
of the perturbative series upon the infrared regularization has been
questioned in [ 50 ] .

The correlation functions of @xmath ’s and @xmath ’s fields, have a
finite continuum limit if the bare parameters and fields are properly
renormalized:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.127)
     @xmath   @xmath   @xmath      (2.128)
     @xmath   @xmath   @xmath      (2.129)
     @xmath   @xmath   @xmath      (2.130)
  -- -------- -------- -------- -- ---------

In general the constants @xmath and @xmath are fixed by imposing
appropriate renormalization conditions. As long as perturbation theory
is concerned, we may choose @xmath and @xmath in such a way that
renormalized lattice correlation functions match continuum @xmath ones.
We shall therefore consider the renormalized fields and parameters on
the r.h.s. of Eqs. ( 2.127 )–( 2.130 ), as @xmath quantities.

The perturbative expansion of lattice renormalization constants has the
general form:

  -- -------- -- ---------
     @xmath      (2.131)
  -- -------- -- ---------

The renormalization constants @xmath and @xmath have been computed up to
three-loop order in perturbation theory [ 51 , 52 , 53 ] . For greater
convenience of the reader we report here the one-loop result:

  -- -------- --
     @xmath   
  -- -------- --

The lattice beta-function @xmath and anomalous dimensions @xmath are
obtained from @xmath and @xmath as follows:

  -- -------- -- ---------
     @xmath      (2.133)
  -- -------- -- ---------

Let us now consider composite-operator renormalization. The role of the
@xmath symmetry in restricting operator mixing is the same as in the
continuum. The proof in Sec. 2.2 does not rely on any regularization
scheme as long as @xmath symmetry is broken uniquely by the external
magnetic field @xmath . On the r.h.s of Eq. ( 2.13 ) we must consider
products of operators transforming like @xmath , times powers of @xmath
. The form of @xmath , i.e. the lattice counterpart of @xmath , see Eq.
( 2.21 ), is dictated by the @xmath transformation properties of the
lattice action. For the discretization ( 2.125 ), we get

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.134)
  -- -------- -------- -------- -- ---------

where @xmath is the lattice laplacian. The last term in Eq. ( 2.134 ) is
not present in the continuum and arises because of the measure term, see
Eq. ( 2.126 ). As in the continuum renormalized theory, we can get rid
of the operators proportional to @xmath in the @xmath limit, as long as
on-shell matrix elements are considered. In particular, the following
identity follows from Eqs. ( 2.134 ) and ( 2.126 ):

  -- -------- -- ---------
     @xmath      (2.135)
  -- -------- -- ---------

We conclude this overview by a simple remark. In Sec. ( 2.2 ) we
discussed the construction of renormalized composite operators. This
construction renormalizes the correlation functions of @xmath and @xmath
fields with a single composite operator insertion. This is enough for
renormalizing correlation functions with multiple operator insertions as
long as the insertions are made at distinct physical positions. When
lattice correlation functions are studied, for instance a two-point
function @xmath , we must keep different composite operators at
distances @xmath . This implies that @xmath in the continuum limit
(recall that we set the lattice spacing @xmath ).

#### 2.5.1 @xmath Invariant Operators of Dimension 2

As we explained above, there is some freedom in choosing lattice
composite operators, if we are not interested in improving their
approach to the continuum limit. We make the choice of discretizing the
operators of Sec. 2.3.1 by substituting the space-time derivative @xmath
with the symmetric lattice derivative @xmath , where @xmath . Moreover,
we shall neglect contributions coming from the identity operator. Indeed
such terms cancels in connected correlation functions. The
renormalization structure is given below:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (2.136)
                                @xmath   
     @xmath   @xmath   @xmath            (2.137)
                                @xmath   
     @xmath   @xmath   @xmath            (2.138)
     @xmath   @xmath   @xmath            (2.139)
  -- -------- -------- -------- -------- ---------

Notice that the operator @xmath does not renormalize as @xmath because
of the lack of Lorentz invariance.

We now list the one-loop perturbative expressions for the constants
entering in Eqs. ( 2.136 )–( 2.139 ). Some of these constants have been
already computed in [ 54 ] . We give them here in order to correct a few
misprints.

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.140)
     @xmath   @xmath   @xmath      (2.141)
     @xmath   @xmath   @xmath      (2.142)
     @xmath   @xmath   @xmath      (2.143)
     @xmath   @xmath   @xmath      (2.144)
     @xmath   @xmath   @xmath      (2.145)
     @xmath   @xmath   @xmath      (2.146)
     @xmath   @xmath   @xmath      (2.147)
  -- -------- -------- -------- -- ---------

and @xmath . Notice that we were not able to express the above constants
in terms of the field and coupling renormalization constants @xmath and
@xmath , as we did in the continuum, see Sec. 2.3.1 . This happens
because of two reasons. In Eqs. ( 2.136 )–( 2.139 ) we used the
symmetric lattice derivative @xmath . As a consequence @xmath is not
directly related to the lattice action ( 2.1 ). The second reason is
that, since translation invariance explicitly broken, there exists no
exactly conserved energy-momentum tensor on the lattice.

A naive discretization of the energy-momentum tensor can be written in
terms of the operators appearing in Eqs. ( 2.136 )–( 2.139 ):

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.148)
  -- -------- -------- -------- -- ---------

We can write down an energy-momentum tensor which is conserved up to
lattice artifacts. This can be done by mixing the naively discretized
version ( 2.148 ) with the other operators appearing in Eqs. ( 2.136 )–(
2.139 ). We get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where @xmath is the continuum renormalized energy-momentum tensor, and
the relevant renormalization constant are

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.150)
     @xmath   @xmath   @xmath      (2.151)
     @xmath   @xmath   @xmath      (2.152)
     @xmath   @xmath   @xmath      (2.153)
  -- -------- -------- -------- -- ---------

Since the continuum energy-momentum tensor on the l.h.s. of Eq. ( 2.5.1
) is conserved, the corresponding renormalization constants satisfy:

  -- -------- -- ---------
     @xmath      (2.154)
  -- -------- -- ---------

Finally, notice that we can eliminate @xmath from Eqs. ( 2.136 )–( 2.139
) using Eq. ( 2.135 ). However, @xmath is different from @xmath , which
appears in Eqs. ( 2.136 )–( 2.139 ). The two operators are related by a
finite renormalization:

  -- -------- -- ---------
     @xmath      (2.155)
  -- -------- -- ---------

At one loop

  -- -------- -- ---------
     @xmath      (2.156)
  -- -------- -- ---------

Then, considering only connected correlation functions, on-shell and for
@xmath , we have

  -- -------- -- ---------
     @xmath      (2.157)
  -- -------- -- ---------

Using this relation, we can write the energy-momentum tensor ( 2.5.1 )
in terms of @xmath invariant operators (as always on-shell, and in the
@xmath limit) as follows:

  -- -------- -- ---------
     @xmath      (2.158)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.159)
  -- -------- -- ---------

#### 2.5.2 Antisymmetric Rank-2 Operators

Since @xmath symmetry is not broken by the lattice discretization,
renormalization is quite simple for these operators. One can explicitly
construct the lattice Noether currents. With the lattice action ( 2.1 )
we get the simple expression

  -- -------- -- ---------
     @xmath      (2.160)
  -- -------- -- ---------

The lattice current ( 2.160 ) satisfies (exactly) the following Ward
identity:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.161)
  -- -------- -------- -------- -- ---------

where @xmath is a generic composite operator (or a product of composite
operators), and @xmath is the variation of this operator induced by a
rotation of the spin @xmath :

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.162)
  -- -------- -------- -------- -- ---------

Equation ( 2.161 ) guarantees that the lattice current ( 2.160 ) has the
correct normalization, i.e. @xmath (up to lattice artifacts).

We can construct lattice discretizations of the rank-2 antisymmetric
operators ( 2.72 )–( 2.74 ) in terms of derivatives of the lattice
current @xmath .

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.163)
     @xmath   @xmath   @xmath      (2.164)
     @xmath   @xmath   @xmath      (2.165)
  -- -------- -------- -------- -- ---------

Since the lattice current @xmath does not need any renormalization, we
must renormalize only the coupling constant which explicitly appears in
front of the above definitions:

  -- -------- -- ---------
     @xmath      (2.166)
  -- -------- -- ---------

#### 2.5.3 Symmetric Rank 2 Operators

We limit ourselves to the symmetric rank 2 operator of dimension 0. We
consider the natural discretization appearing below:

  -- -- -------- -------- -- ---------
        @xmath   @xmath      (2.167)
  -- -- -------- -------- -- ---------

The relevant renormalization constant has been computed in Ref. [ 51 ]
up to two loops in perturbation theory:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

### 2.6 Lattice Anomalous Dimensions

In this Section we recall the basic definitions of the anomalous
dimensions for bare lattice composite operators.

Let us consider, once again, the general mixing pattern ( 2.97 ):

  -- -------- -- ---------
     @xmath      (2.169)
  -- -------- -- ---------

or its matrix formulation @xmath . In the previous formulae, we
specified the regularization scheme to be the lattice one.

As for renormalized operators, the anomalous dimensions of the lattice
operators @xmath can be implicitly defined through a RG equation:

  -- -------- -- ---------
     @xmath      (2.170)
  -- -------- -- ---------

The derivative with respect to the cutoff @xmath has to be taken keeping
the renormalized parameters (for instance the coupling @xmath , and the
scale @xmath ) fixed.

Equation ( 2.170 ) is a shorthand for

  -- -------- -- ---------
     @xmath      (2.171)
  -- -------- -- ---------

where @xmath is the vertex with one @xmath insertion, and @xmath .

An explicit formula for the anomalous dimensions @xmath is easily
obtained from the above definitions:

  -- -------- -- ---------
     @xmath      (2.172)
  -- -------- -- ---------

The knowledge of the continuum anomalous dimensions can be of great help
when computing their lattice cousins. Indeed the following relation
holds

  -- -------- -- ---------
     @xmath      (2.173)
  -- -------- -- ---------

This equation yields @xmath at @xmath -loop order, once @xmath is known
at @xmath loops. In particular, if we write the perturbative expansion
of @xmath as

  -- -------- -- ---------
     @xmath      (2.174)
  -- -------- -- ---------

Eq. ( 2.173 ) implies that @xmath .

### 2.7 Renormalization-Group Equations

Let us now discuss how RG can be used for “resumming” the perturbative
expansions of the Wilson coefficients. We consider here the OPE for
renormalized operators. The extension to the case of bare lattice
operators is straightforward.

The most general short-distance expansion has the form:

  -- -------- -- ---------
     @xmath      (2.175)
  -- -------- -- ---------

The operators @xmath appearing on the r.h.s. of Eq. ( 2.175 ) are the
same which would mix with the product @xmath under renormalization. Let
us assume, for sake of simplicity, that the operators @xmath and @xmath
renormalize multiplicatively. In general @xmath will have some
non-trivial Lorentz structure. However we can always factorize out one
(or more) homogeneous function of @xmath , carrying both the canonical
dimensions and the tensor structure of @xmath . We can therefore
restrict ourselves to the case of Wilson coefficients with zero
canonical dimension and depending upon @xmath only through its modulus
@xmath .

With a slight abuse of notation we denote these “reduced” Wilson
coefficients as @xmath . They satisfy the following RG equation

  -- -------- -- ---------
     @xmath      (2.176)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.177)
  -- -------- -- ---------

In the case of operator mixing, see Eq. ( 2.97 ), we must consider
@xmath as an @xmath matrix, and @xmath as a column vector of length
@xmath .

The perturbative expansion for @xmath has the usual structure:

  -- -------- -- ---------
     @xmath      (2.178)
  -- -------- -- ---------

where we dropped, for sake of simplicity, the superscript @xmath .
Equation ( 2.176 ) implies a recursive relation between the coefficients
@xmath :

  -- -------- -- ---------
     @xmath      (2.179)
  -- -------- -- ---------

We could use this relation for resumming the perturbative expansion.
Once @xmath (which is given by a tree-level calculation) is known, Eq. (
2.179 ) allows us to sum up all the terms @xmath ( leading-log
approximation ). The calculation of @xmath yields the sum of the terms
@xmath ( next-to-leading log ), and so on.

However, it is more convenient (both practically and conceptually) to
solve Eq. ( 2.176 ) and use the perturbative calculation as a “boundary
condition”. The solution has the well known form:

  -- -------- -- ---------
     @xmath      (2.180)
  -- -------- -- ---------

In the case of operator mixing @xmath has to be interpreted as an @xmath
matrix, and @xmath as a column vector of length @xmath .

@xmath satisfies the ordinary differential equation

  -- -------- -- ---------
     @xmath      (2.181)
  -- -------- -- ---------

Let us write the perturbative expansion of @xmath as @xmath . The
solution of Eq. ( 2.181 ) can be formally written as follows:

  -- -------- -- ---------
     @xmath      (2.182)
  -- -------- -- ---------

Here @xmath is the intrinsic scale of the model (the so-called
lambda-parameter ):

  -- -------- -- ---------
     @xmath      (2.183)
  -- -------- -- ---------

It is useful to define the dimensionless function @xmath through the
identity @xmath . The function @xmath clearly depends upon the
renormalization scheme through the beta-function. When necessary we
shall indicate the particular scheme through a subscript. Within the
four schemes listed in Sec. 2.1 , we shall write, respectively, @xmath ,
@xmath , @xmath , @xmath . The explicit definition in a generic scheme
is:

  -- -- -- ---------
           (2.184)
  -- -- -- ---------

In this Section we shall drop the subscript. The lambda-parameter depend
upon the scheme too. We have four lambda parameters corresponding to the
four schemes listed in Sec. 2.1 : @xmath , @xmath , @xmath , and @xmath
. In order to match two different schemes, the corresponding
lambda-parameters must be in a fixed ( @xmath -independent) ratio. This
ratio is easily obtained through a one-loop calculation.

Notice that the prefactor @xmath can be readsorbed with a redefinition
of the operators. In particular, we can get rid of it by replacing the
renormalized operators @xmath , @xmath , and @xmath in Eq. ( 2.175 )
with their RGI counterparts, see Eq. ( 2.104 ).

Using the perturbative expansion ( 2.178 ) and the solution ( 2.180 ), (
2.182 ) of the RG equation, we derive an expansion for @xmath :

  -- -------- -- ---------
     @xmath      (2.185)
  -- -------- -- ---------

The expansion is written in terms of @xmath (the coupling at the energy
scale @xmath ) which is implicitly defined as follows:

  -- -------- -- ---------
     @xmath      (2.186)
  -- -------- -- ---------

The definition of the coupling @xmath , and, consequently, of the
expansion ( 2.185 ), is by no means unique. If we knew the whole
expansion ( 2.185 ), the resulting @xmath would not depend upon the
particular choice. In practice we shall compute the expansion ( 2.185 )
in perturbation theory, truncating it to some finite order. We shall use
the dependence of the truncated Wilson coefficient @xmath upon the
definition of the coupling @xmath , in order to assess the reliability
of perturbation theory. We refer to Sec. 4.4 for further discussion on
this point. Hereafter we shall use both the notations @xmath and @xmath
.

As in any asymptotically free theory @xmath as @xmath . Is we define
@xmath , we can write down an expansion of @xmath in inverse powers of
@xmath :

  -- -------- -- ---------
     @xmath      (2.187)
  -- -------- -- ---------

We know the beta-function at four-loop order, both on the lattice [ 51 ,
52 , 53 ] , in continuum @xmath scheme [ 42 , 43 , 44 ] , and in the
Finite Volume (FV) [ 55 ] scheme. This allows to add one more term (of
order @xmath ) to the expansion ( 2.187 ). Equation ( 2.187 ) implies
that the expansion ( 2.185 ) is asymptotically good as @xmath . More
precisely @xmath -loop perturbation theory gives an estimation of Wilson
coefficients with a systematic error of order @xmath .

The coefficients @xmath are obtained by plugging Eqs. ( 2.182 ), ( 2.185
) and ( 2.183 ) in Eq. ( 2.180 ), expanding it in powers of @xmath and
matching this expansion with Eq. ( 2.178 ). The expressions for @xmath
are simple if @xmath renormalizes multiplicatively. In the case of
general operator mixing, they are quite involved.

For the general case, see Eq. ( 2.97 ), we give the expressions of the
first two coefficients of the expansion ( 2.185 ):

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.188)
     @xmath   @xmath   @xmath      (2.189)
  -- -------- -------- -------- -- ---------

In the next Chapters we shall not need higher-order coefficients. @xmath
is a @xmath matrix, determined by the following linear equation:

  -- -------- -- ---------
     @xmath      (2.190)
  -- -------- -- ---------

This is a rather implicit formula for @xmath . In order to obtain a more
explicit expression, let us consider a change of basis which
diagonalizes @xmath . If we define @xmath with @xmath , then we get:

  -- -------- -- ---------
     @xmath      (2.191)
  -- -------- -- ---------

Notice that the r.h.s. is not well defined if there exist two
eigenvalues @xmath and @xmath of @xmath which satisfy @xmath . Such an
unlucky case is called a resonance ⁷ ⁷ 7 More generally we would have a
resonance if @xmath , with @xmath a positive integer. in the theory of
ordinary differential equations [ 56 , 57 ] . We will encounter a
resonance in Sec. 4.3 . It turns out that, in such a case, non-analytic
terms of the type @xmath must be added to the expansion ( 2.185 ).

Things simplify if the operator @xmath , see Eq. ( 2.175 ), renormalizes
multiplicatively. In this case @xmath becomes a number:

  -- -------- -- ---------
     @xmath      (2.192)
  -- -------- -- ---------

and it is easy to write down the three-loop coefficient in the expansion
( 2.185 )

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.193)
     @xmath   @xmath   @xmath      (2.194)
  -- -------- -------- -------- -- ---------

### 2.8 On the Evaluation of the Running Coupling Constant

The determination of the running coupling constant is a key ingredient
in the application of RG-improved perturbation theory to any
asymptotically free theory. If we use the lattice OPE, the coupling is
@xmath , one of the input parameters of our numerical calculations.
However, perturbation theory in @xmath is poorly behaved, so that one
expects a poor agreement with the numerical data. It is known that it is
much more convenient to use perturbative expansions in the @xmath
scheme. Perturbative coefficients are smaller, so that truncations in
the number of loops give smaller systematic errors. For these reasons,
it is important to relate the @xmath coupling to the bare coupling
@xmath . Given @xmath , we fix the scale @xmath and then compute the
coupling @xmath . In principle, it is a function of @xmath and @xmath ,
but, because of the RG equations, it can be written as a function of the
single variable @xmath , where @xmath is the mass gap.

Here, we shall outline several different procedures—all of them are
exact in the continuum limit—and we shall compare their efficiency. We
consider the following methods:

1.  The naive perturbative method.

    In this approach, one computes the continuum coupling as a function
    of the lattice coupling by matching the continuum and the lattice
    perturbative expansion of some physical quantity, e.g., of the
    two-point correlation function. At @xmath -loops one obtains a
    truncated series of the form @xmath . We shall call @xmath the value
    obtained in this way. The relevant perturbative expansions are known
    to three loops [ 51 , 53 ] . Note that the @xmath -loop
    approximation does not satisfy the exact RG equations and thus this
    approximation is not a function of @xmath only.

2.  The RG improved perturbative method.

    The idea of this method—and also of those that will be presented
    below—is to compute @xmath starting from some quantity that can be
    computed numerically at the given value of the bare lattice coupling
    constant.

    In this case, we consider the RG prediction for the mass gap @xmath
    in the @xmath scheme:

      -- -------- -------- -------- -- ---------
         @xmath   @xmath   @xmath      (2.195)
      -- -------- -------- -------- -- ---------

    see Eqs. ( 2.183 ) and ( 2.184 ). The constant @xmath is not known
    for a general theory. For the two-dimensional @xmath -model it has
    been computed [ 58 , 59 ] using the thermodynamic Bethe ansatz. The
    result, in the @xmath scheme, reads:

      -- -------- -- ---------
         @xmath      (2.196)
      -- -------- -- ---------

    The method works as follows: For a given value of the lattice
    coupling @xmath , compute numerically (for instance, by means of a
    Monte Carlo simulation) the mass gap @xmath . Then, fix @xmath and
    solve numerically Eq. ( 2.195 ), obtaining @xmath , which is a
    function of @xmath only. Note that, since the @xmath -function is
    known only to a finite order in perturbation theory, we have to
    substitute the function @xmath with its truncated perturbative
    expansion. There is some arbitrariness in this truncation. We shall
    make the simplest choice

      -- -------- -- ---------
         @xmath      (2.197)
      -- -------- -- ---------

    where the coefficients @xmath are obtained by expanding
    perturbatively Eq. ( 2.184 ). Equation ( 2.197 ) gives the @xmath
    -loop approximation of the @xmath -parameter. The solution of the
    corresponding Eq. ( 2.195 ) will be denoted as @xmath . The
    perturbative expansion of the @xmath @xmath -function is known to
    four loops [ 43 ] .

3.  The finite-size non-perturbative method.

    This method, due to Lüscher [ 60 ] , was initially tested in the
    two-dimensional @xmath @xmath -model [ 61 ] . Recently, it has been
    successfully employed in the computation of the @xmath -parameter in
    quenched QCD [ 10 ] . The idea is to consider the theory in a finite
    box and to define a “finite-size scheme” in which the
    renormalization scale is the size of the box. For the @xmath -model,
    Ref. [ 61 ] introduces a coupling @xmath defined as follows: ⁸ ⁸ 8
    This definition is by no means unique. For instance, one could also
    use @xmath , where @xmath is the inverse of the second-moment
    correlation length on a square lattice of size @xmath . The
    corresponding universal finite-size scaling function—i.e. the
    function that gives the correspondence between @xmath and @xmath
    —has been determined numerically in [ 62 ] .

      -- -------- -- ---------
         @xmath      (2.198)
      -- -------- -- ---------

    where @xmath is the mass gap in a strip of width @xmath . Standard
    finite-size scaling theory indicates that @xmath is a universal
    function of @xmath , where @xmath is the infinite-volume mass gap:
    @xmath . Such a function can be computed non-perturbatively by means
    of Monte Carlo simulations with a good control of the systematic
    errors. If we set ⁹ ⁹ 9 The constant @xmath is arbitrary. In Ref. [
    61 ] @xmath was used together with the minimal subtraction scheme.
    Here we will use the @xmath scheme, and, in order to be consistent
    with previous results, we set @xmath . @xmath , @xmath defines a
    running coupling constant that is a function of @xmath . The
    function @xmath can also be computed in perturbation theory in a
    different perturbative scheme. This provides the connection between
    @xmath and any other perturbative scheme.

    We will now present two different methods of computing @xmath .
    First, we will compute the @xmath -loop approximation to the @xmath
    coupling @xmath by using its perturbative expansion in terms of
    @xmath at the same scale @xmath : @xmath . The perturbative
    expansion of @xmath is known to three-loop order [ 55 ] .

    A different method (see, e.g., [ 11 , 27 ] ) works as follows. First
    we compute @xmath , using its expression truncated at @xmath -loops
    (see Eq. ( 2.197 )) and @xmath . Then, we derive @xmath using

      -- -------- -- ---------
         @xmath      (2.199)
      -- -------- -- ---------

    and finally we solve Eq. ( 2.197 ), obtaining @xmath .

    As we will discuss below, the two methods are essentially
    equivalent, and therefore in our numerical work we have always used
    @xmath because of its simplicity.

    The finite-size scaling method does not provide—at least in the
    implementation of Ref. [ 61 ] —the coupling @xmath for any @xmath ,
    but only on a properly chosen mesh of values, say @xmath .
    Therefore, the methods described above provide @xmath only for
    selected values of @xmath . We want now to explain how to determine
    the coupling for generic values of the scale. In principle, one
    could use perturbation theory, generalizing the definition @xmath .
    Indeed, we could simply define @xmath . However, this definition
    does not work well, because of the presence of logarithms of @xmath
    . A RG-improved version can be obtain using the RG equations. Since
    the mass gap is a RG-invariant quantity, at order @xmath , we may
    require

      -- -------- -- ---------
         @xmath      (2.200)
      -- -------- -- ---------

    Using @xmath , one can then obtain @xmath for any given @xmath . We
    shall call @xmath the running coupling obtained by this procedure.

4.  The improved-coupling method.

    Method 1 does not work well because lattice perturbation theory is
    not “well behaved”: Perturbative coefficients are large, giving rise
    to large truncation errors. Parisi [ 63 , 64 ] noticed that much
    smaller coefficients are obtained if one expands in terms of
    “improved” (or “boosted”) couplings defined using “short-distance”
    observables. In the @xmath -model one can define a new coupling in
    terms of the energy density

      -- -------- -- ---------
         @xmath      (2.201)
      -- -------- -- ---------

    which is then related to @xmath perturbatively. At order @xmath , we
    can write @xmath . In practice the method works as follows: Given
    @xmath , one computes numerically @xmath ; then, given @xmath , one
    uses the previous perturbative expansion to determine the @xmath
    coupling constant. This method is expected to be better than the
    naive one. Indeed, one expects @xmath , so that truncation errors
    should be less important. The perturbative coefficients @xmath can
    be computed up to @xmath using the results of [ 51 , 53 , 65 ] .
    Notice that the @xmath -loop approximation is not a function of
    @xmath only at variance with methods (B) and (C).

Notice that the list above is by no means exhaustive. For instance, an
alternative non-perturbative coupling may be defined using off-shell
correlation functions:

  -- -------- -- ---------
     @xmath      (2.202)
  -- -------- -- ---------

Something similar has been proposed in Refs. [ 66 , 67 , 68 ] , with the
purpose of computing the QCD @xmath -parameter. This approach opens the
Pandora box of possible definitions of the running coupling in
substitution of Eq. ( 2.202 ). A scheme that has been intensively
studied in the context of QCD employs the three-gluon vertex (see Refs.
[ 69 , 67 , 70 , 71 , 72 , 73 , 74 ] ).

Let us compare the different methods. In Tab. 2.1 we compare the
procedures 1 , 2 , 3 , and 4 . In the first column we report a
collection of values of @xmath . A subset of the values given in the
table have been considered for the first time in Ref. [ 61 ] . Later,
the mesh was enlarged by Hasenbusch [ 75 ] . For these values of @xmath
, Hasenbusch computed the corresponding value of @xmath which is
reported in the second column. Note a peculiarity of the finite-size
approach: usually, one fixes @xmath and then determines the running
coupling constant. Here, the running coupling constant is fixed at the
beginning and the value of the scale is determined numerically. In the
third column we report the scale in lattice units for @xmath , the value
of the lattice coupling at which we have done most of our simulations.
The results are obtained by using @xmath . The error reported there
corresponds to the error on @xmath , the error on @xmath being
negligible. In column 4 we report the estimate of @xmath obtained by
using @xmath and three-loop perturbation theory [ 55 ] . In brackets we
report the difference @xmath . In the next column we report the
four-loop coupling @xmath obtained by using the value of @xmath given in
the second column. Again, in brackets we report @xmath . In the last two
columns we report the results obtained by using three-loop lattice
perturbation theory [ 51 , 53 , 65 ] . In the fifth column we use @xmath
as the expansion parameter. In the sixth column the improved coupling
defined by Eq. ( 2.201 ) is used. The connection with the bare coupling
is obtained by using the perturbative expressions given in Ref. [ 65 ] .
The relevant expectation value has been evaluated in a Monte Carlo
simulation at @xmath on a lattice @xmath with statistics @xmath ,
yielding @xmath .

In Table 2.1 we have used the first definition for the finite-size
coupling, @xmath , but completely equivalent results are obtained
adopting the second procedure. For instance, for @xmath (resp. 0.2092)
we obtain @xmath (resp. 1.5864[258]). Clearly, the two procedures are
equivalent for @xmath .

In Tab. 2.2 we compare, on a broad range of scales, the outcome of
RG-improved perturbation theory and the interpolation procedure ( 2.200
). In both cases four-loop perturbation theory is used. The couplings
differ in the “boundary condition” for the RG interpolation, that is in
the value used in the left hand side of Eq. ( 2.200 ). The couplings A1
and A2 have been obtained using @xmath . The coupling A1 was determined
using @xmath , while A2 was computed starting from @xmath . Analogously
the couplings B1 and B2 have been obtained using @xmath for @xmath . In
all cases we fixed @xmath .

What do we learn from this comparison? First of all, lattice (naive)
perturbation theory (sixth column of Tab. 2.1 ) is a very bad tool. Even
at energies as high as @xmath times the mass gap @xmath is affected by a
@xmath systematic error. However, it is reassuring that the expansion
tells us its own unreliability. Indeed, the observed discrepancy is of
the order (at most twice as large) of the difference between the
two-loop and the three-loop result. The perturbative expansion in terms
of the improved coupling is much better. The results are quite precise
up to @xmath . For smaller values of @xmath the discrepancy increases,
but it is nice that it is again of the order of the difference between
the two- and the three-loop result. Perturbative RG supplemented with
the prediction ( 2.196 ) gives results which are in agreement with the
non-perturbative ones obtained using the finite-size scaling method
within a few percent for all the energy scales given in Tab. 2.1 . The
accuracy remains good (if the comparison is made with the
“interpolation” procedure ( 2.200 )) also for scales of the order of the
mass gap.

Up to now we have discussed the @xmath scheme and how to obtain the
value of the @xmath coupling. However, as we already mentioned above,
reasonably good results can also be obtained if we use the coupling
@xmath . In this scheme we introduce the @xmath parameter as follows

  -- -------- -- ---------
     @xmath      (2.203)
  -- -------- -- ---------

where @xmath is defined by Eq. ( 2.184 ) in terms of the corresponding
beta-function @xmath . The beta-function @xmath is related to the
lattice one through a simple change of variables: if @xmath , then
@xmath . The mass gap is invariant and thus @xmath , where

  -- -------- -- ---------
     @xmath      (2.204)
  -- -------- -- ---------

Finally, to be exhaustive, we give the formulae for the lambda-parameter
and for the mass gap in the bare lattice theory. Analogously to the
previous case, we have @xmath , and

  -- -------- -- ---------
     @xmath      (2.205)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.206)
  -- -------- -- ---------

## Chapter 3 Operator Product Expansion for Conserved Currents

In this Chapter we present our perturbative and numerical results
concerning the OPE of @xmath Noether currents in the non-linear @xmath
-model. Since @xmath currents are exactly conserved on the lattice, they
do not need to be renormalized. This makes it simpler to verify the
validity of the OPE on the lattice.

We consider one-particle matrix elements of the current product.
Moreover, we keep only the leading term of the OPE. In brief, we shall
study the following example of OPE:

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath and @xmath are one-particle states with spatial momentum
@xmath and @xmath (respectively). We shall compute the left-hand side of
Eq. ( 3.1 ) for @xmath . In the above equation we adopted a loose
notation, omitting both @xmath and Lorentz indices. The particular
choices of these indices will be specified in Sec. 3.3 . Finally, we
often consider the angular average of Eq. ( 3.1 ), i.e. the average over
@xmath at fixed @xmath . Moreover, we shall compute the renormalized
matrix elements @xmath without relying on the OPE approach. This makes
it possible to compare the two sides of Eq. ( 3.1 ), yielding a
stringent test of the validity of the OPE.

The procedure outlined above is quite different from what would be done
in more physical (QCD) applications. In this case the matrix element on
the r.h.s. of Eq. ( 3.1 ) would be unknown. In this Chapter we focus
mostly on the validity of the OPE, and on the reliability of the
perturbative calculation of the Wilson coefficients. We would like to
get an idea of the window of @xmath for which the OPE works. Moreover,
we will investigate different procedures resumming perturbation theory
using the RG. We will try to assess the goodness of the various
procedures.

A preliminary account of this work has been presented at the Lattice
conference in 1998 [ 76 ] .

The organization of this Chapter is quite simple. In Sec. 3.1 we write
down the structure of the OPE for two different products of Noether
currents, and we list the one-loop results for the Wilson coefficients.
In Sec. 3.3 we gives the details of our Monte Carlo simulations and
compare the results withe the OPE prediction. Finally, we summarize the
outcomes of our investigation in Sec. 3.4

### 3.1 Perturbative Calculation of the Wilson Coefficients

A general product of two @xmath currents reads @xmath . This is a
reducible rank-4 @xmath -tensor. We shall decompose it into irreducible
parts and consider uniquely the two simplest sectors, namely the @xmath
-scalar, and the antisymmetric rank 2 @xmath -tensor. According to the
general considerations of Sec. 2.2 , the operators appearing in the OPE
will be either @xmath -tensors in the same representation or products of
such tensors times some power of @xmath (see Eq. ( 2.21 ) for the
definition of @xmath ).

We shall present the results both in the continuum @xmath
renormalization scheme and for the lattice bare theory. We recall that
the OPE holds on the lattice (and in particular in lattice perturbation
theory) as long as we keep distinct lattice operators at non-zero
physical separations in the continuum limit. This means taking @xmath
and @xmath at @xmath fixed. Next one can consider the short-distance
regime @xmath . The OPE will be valid up to scaling corrections of
relative order @xmath (such corrections cannot be seen in perturbation
theory), @xmath , etc. The only difference between lattice and continuum
OPE is related to space-time symmetries. In fact, while the Lorentz
invariance strongly restricts the OPE in the continuum, it is lost on
the lattice.

#### 3.1.1 Continuum

##### Scalar Sector

We begin by considering the OPE for the product of two currents in the
scalar sector. There exists an unique manner of combining two currents
to make a scalar. The general form of the OPE, neglecting @xmath terms,
is:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.2)
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

where @xmath and @xmath are functions of @xmath , of the @xmath coupling
@xmath , and of the renormalization scale @xmath . Explicit one-loop
expressions are reported below, see Eqs. ( 3.8 )–( 3.16 ).

We are interested in the @xmath -symmetric limit @xmath . Moreover we
shall consider on-shell matrix elements of the operator product on the
left-hand side of Eq. ( 3.2 ). In this case, as we explained in Sec.
2.3.1 , we can express the non @xmath -invariant operator @xmath ,
appearing in the right-hand side of Eq. ( 3.2 ), in terms of @xmath
invariant operators. After eliminating @xmath through Eq. ( 2.66 ), we
recover an @xmath -invariant expansion:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.3)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

with

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

The Wilson coefficients satisfy the following RG equations:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.5)
     @xmath   @xmath   @xmath      (3.6)
     @xmath   @xmath   @xmath      (3.7)
  -- -------- -------- -------- -- -------

where @xmath is the @xmath @xmath -function. These equations can be
derived from the general formulae of Sec. 2.7 , using the
anomalous-dimension matrix given in Sec. 2.4.1 . Notice that, as we
explained in Sec. 2.4 , we can write RG equations for the “reduced”
@xmath -invariant expansion ( 3.3 ), without taking care of on-shell
vanishing terms.

The explicit one-loop expression for the Wilson coefficients @xmath and
@xmath appearing in Eq. ( 3.2 ) are given below:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.8)
                                @xmath   
     @xmath   @xmath   @xmath            (3.9)
     @xmath   @xmath   @xmath            (3.10)
     @xmath   @xmath   @xmath            (3.11)
     @xmath   @xmath   @xmath            (3.12)
     @xmath   @xmath   @xmath            (3.13)
     @xmath   @xmath   @xmath            (3.14)
     @xmath   @xmath   @xmath            (3.15)
     @xmath   @xmath   @xmath            (3.16)
  -- -------- -------- -------- -------- --------

##### Antisymmetric Sector

We consider now the OPE of the antisymmetric product of currents. As in
the previous case, there exists a unique manner of constructing a rank-2
antisymmetric @xmath -tensor from the product of two Noether currents.
Neglecting terms of order @xmath , we have ¹ ¹ 1 Note that one could
also add a contribution proportional to @xmath . However, in two
dimensions, @xmath , and thus this term is equivalent to that
proportional to @xmath .

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (3.17)
  -- -------- -- --------

The coefficients @xmath and @xmath satisfy the RG equations:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.18)
  -- -------- -------- -------- -- --------

The meaning of this equation is very simple: @xmath is RG invariant,
i.e. @xmath . This could be easily understood from Eq. ( 3.17 ), since
neither @xmath , nor its space-time derivatives must be renormalized.

The coefficients appearing in Eq. ( 3.17 ) are given by:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.19)
     @xmath   @xmath   @xmath      (3.20)
     @xmath   @xmath   @xmath      (3.21)
     @xmath   @xmath   @xmath      (3.22)
     @xmath   @xmath   @xmath      (3.23)
  -- -------- -------- -------- -- --------

#### 3.1.2 Lattice

##### Scalar Sector

If we write Eq. ( 3.2 ) in terms of lattice operators we get:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.24)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

where @xmath is the naive lattice energy momentum tensor, see Eq. (
2.148 ). Notice the appearance of the non-Lorentz covariant operator
@xmath . The Wilson coefficient of this operator is of order @xmath
(i.e. non vanishing) in the continuum limit. One could suspect that
Lorentz invariance is lost even in the continuum limit. Of course this
is not the case since the terms proportional to @xmath are readsorbed in
the renormalization of the energy-momentum tensor @xmath , see Sec.
2.5.1 .

The one-loop expressions for the Wilson coefficients are easily obtained
by writing the @xmath renormalized operators appearing in Eq. ( 3.2 ) in
terms of bare lattice operators. The formulae of Sec. 2.5.1 for the
renormalization constants can be used. Alternatively one can use
directly lattice perturbation theory and proceed as in the continuum.
The result is:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.25)
                                @xmath   
     @xmath   @xmath   @xmath            (3.26)
     @xmath   @xmath   @xmath            (3.27)
     @xmath   @xmath   @xmath            (3.28)
     @xmath   @xmath   @xmath            (3.29)
     @xmath   @xmath   @xmath            (3.30)
     @xmath   @xmath   @xmath            (3.31)
     @xmath   @xmath   @xmath            (3.32)
     @xmath   @xmath   @xmath            (3.33)
     @xmath   @xmath   @xmath            (3.34)
     @xmath   @xmath   @xmath            (3.35)
     @xmath   @xmath   @xmath            (3.36)
     @xmath   @xmath   @xmath            (3.37)
  -- -------- -------- -------- -------- --------

We shall need the RG equations uniquely for the terms proportional to
the energy-momentum, cf. Eq. ( 3.24 ):

  -- -------- --
     @xmath   
  -- -------- --

Notice that these equations decouple from the ones for the other Wilson
coefficients because of the block triangular form of the renormalization
matrix @xmath , see Eqs. ( 2.136 )–( 2.136 ). Moreover, @xmath is
determined by the following simple formula:

  -- -------- -- --------
     @xmath      (3.39)
  -- -------- -- --------

Using the one-loop result for @xmath , see Eq. ( 2.140 ), we get

  -- -------- -- --------
     @xmath      (3.40)
  -- -------- -- --------

##### Antisymmetric Sector

The OPE in the antisymmetric sector has an even simpler structure:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (3.41)
  -- -------- -- --------

It is easy to write th RG equations which hold for the Wilson
coefficients @xmath and @xmath . It is easier to guess the solution of
these equations without writing them. Since @xmath does not renormalize,
we have @xmath .

The one-loop results for the Wilson coefficients are

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.42)
     @xmath   @xmath   @xmath      (3.43)
     @xmath   @xmath   @xmath      (3.44)
     @xmath   @xmath   @xmath      (3.45)
     @xmath   @xmath   @xmath      (3.46)
  -- -------- -------- -------- -- --------

### 3.2 Constraints on the OPE Coefficients

In this Section we want to derive the constraints on the coefficients of
the OPE due to the current conservation. First, we need the Ward
identity related to the @xmath invariance in the presence of a magnetic
term @xmath . A simple calculation gives:

  -- -------- -- --------
     @xmath      (3.47)
  -- -------- -- --------

Then, we need the OPE of @xmath . The leading term for @xmath has the
form

  -- -------- -- --------
     @xmath      (3.48)
  -- -------- -- --------

Using Eq. ( 3.47 ) and noticing that @xmath for @xmath , we have @xmath
. Thus, @xmath is a function of @xmath only. But the Wilson coefficient
satisfies the RG equation

  -- -------- -- --------
     @xmath      (3.49)
  -- -------- -- --------

Thus, if it is independent of @xmath , and therefore of @xmath , it is
also independent of @xmath . A simple calculation at tree level gives
then

  -- -------- -- --------
     @xmath      (3.50)
  -- -------- -- --------

The same result has been obtained in [ 77 ] using the canonical
formalism.

We now consider the OPE of the scalar product of currents. Using the
Ward identity ( 3.47 ) and Eq. ( 3.50 ) we have for @xmath

  -- -------- -- --------
     @xmath      (3.51)
  -- -------- -- --------

where we have discarded contact terms. Then, using Eq. ( 2.66 ) and
discarding again contact terms, we obtain for @xmath

  -- -------- -- --------
     @xmath      (3.52)
  -- -------- -- --------

This equation implies the following relations on the Wilson
coefficients:

  -- -------- -- --------
     @xmath      (3.53)
     @xmath      (3.54)
     @xmath      (3.55)
                 (3.56)
                 (3.57)
  -- -------- -- --------

In the derivation we used Eq. ( 2.69 ) for the trace of the
energy-momentum tensor.

Now let us consider the antisymmetric case. Using the Ward identity (
3.47 ) and Eq. ( 3.50 ), we obtain for @xmath

  -- -------- -- --------
     @xmath      (3.58)
  -- -------- -- --------

Again, contact terms have been discarded in the derivation. Using this
relation, we obtain the following constraints on the Wilson coefficients
² ² 2 Equations ( 3.59 )–( 3.63 ) have been derived in Ref. [ 77 ] . Eq.
( 3.64 ) is due to the matching of the terms proportional to @xmath . It
is also a simple consequence of Eqs. ( 3.60 ) and ( 3.62 ) and of the RG
equations.

  -- -------- -- --------
     @xmath      (3.59)
     @xmath      (3.60)
                 (3.61)
                 (3.62)
     @xmath      
     @xmath      (3.63)
     @xmath      (3.64)
  -- -------- -- --------

Using Eqs. ( 3.59 ) and ( 3.60 ) we obtain immediately

  -- -------- -- --------
     @xmath      (3.65)
  -- -------- -- --------

which implies that this combination is @xmath and @xmath independent. By
making use of the RG equations ( 3.18 ) one proves that this combination
is determined uniquely by its one-loop value. Then, using the results of
the previous Section, we obtain:

  -- -------- -- --------
     @xmath      (3.66)
  -- -------- -- --------

Thus, using ( 3.66 ) and ( 3.60 ), @xmath and @xmath are uniquely
determined by @xmath . Moreover, using Eqs. ( 3.66 ) and ( 3.64 ) one
immediately verifies that Eqs. ( 3.62 ) and ( 3.63 ) are equivalent to
Eq. ( 3.60 ).

Finally, consider ( 3.61 ). We will now show that this equation provides
the two-loop estimate of @xmath . Indeed, since

  -- -------- -- --------
     @xmath      (3.67)
  -- -------- -- --------

and @xmath , cf. previous Section, we have

  -- -------- -- --------
     @xmath      (3.68)
  -- -------- -- --------

where @xmath , and @xmath , @xmath are constants that are not fixed by
the RG equation. Plugging this expression into ( 3.61 ), we obtain

  -- -------- -- --------
     @xmath      (3.69)
  -- -------- -- --------

Of course, the result at order @xmath agrees with the expression
reported in Sec. 3.1.1 . Correspondingly we obtain

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.70)
     @xmath   @xmath   @xmath      (3.71)
     @xmath   @xmath   @xmath      (3.72)
  -- -------- -------- -------- -- --------

Let us finally mention that in Ref. [ 77 ] it was argued that the
functions @xmath are one-loop exact, in the sense that there are no
corrections of order @xmath , @xmath . As we have shown above and it has
also been recognized by the author, ³ ³ 3 In Ref. [ 78 ] it was also
shown that, even though the expressions for the Wilson coefficients were
incorrect, one could still modify the argument so that the main result
(existence of a conserved charge) of Ref. [ 77 ] remains true. this is
inconsistent with the RG equations.

### 3.3 Numerical Results

In this Section we present our numerical computations. We evaluated
short-distance products of the type ( 3.1 ) through Monte Carlo
simulations. We considered several different specifications of the
Lorentz and @xmath indices, omitted in Eq. ( 3.1 ), as well as of the
external one-particle states @xmath and @xmath .

The typical procedure we adopt is the following, see Eq. ( 3.1 ):

1.  We compute a matrix element @xmath by measuring a suitable lattice
    correlation function in Monte Carlo simulations, and taking the
    on-shell limit for the one-particle states.

2.  We compute the renormalized matrix element @xmath appearing in the
    short distance expansion either exactly (this is possible in most of
    the cases), or numerically by means of some different numerical
    non-perturbative technique.

3.  We divide @xmath by the OPE prediction @xmath . If more than one
    operator appears on the r.h.s. of Eq. ( 3.1 ), we of course sum over
    them.

The goal is to see if there is a window of values of @xmath in which the
OPE works, i.e. the result of step 3 is 1 independently of @xmath . For
the cases we will consider here, the OPE gives an accurate description
(at the level of 5-10%) of correlation functions for distances @xmath
(remember that, when not explicitly stated, we take @xmath ). This
result is quite encouraging for future applications of this method.

#### 3.3.1 The Observables

We have simulated the @xmath @xmath -model with action ( 2.1 ) using a
Swendsen-Wang cluster algorithm with Wolff embedding [ 79 , 80 , 81 , 82
] . We did not try to optimize the updating procedure: Most of the CPU
time was employed in evaluating the relevant observables (four-point
functions) on the spin configurations of the ensemble. In order to
estimate the scaling corrections, we simulated three different lattices,
of size @xmath , using in all cases periodic boundary conditions:

1.  Lattice of size @xmath with @xmath .

2.  Lattice of size @xmath with @xmath .

3.  Lattice of size @xmath with @xmath .

The algorithm is extremely efficient—the dynamic critical exponent
@xmath is approximately 0—and the autocorrelation time is very small.

We performed a preliminary study in order to determine how many
iterations are needed to obtain independent configurations. For this
purpose we measured the normalized autocorrelation function

  -- -------- -- --------
     @xmath      (3.73)
  -- -------- -- --------

for different observables @xmath . Here @xmath is the number of Monte
Carlo iterations, @xmath is the value of @xmath at the @xmath -th
iteration, and @xmath the sample mean of @xmath : @xmath . In Fig. 3.1
we report @xmath for the observable

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.74)
  -- -------- -------- -------- -- --------

where @xmath and @xmath . We have considered @xmath —a short-distance
observable—and @xmath (more precisely @xmath , on lattices (A) , (B) and
(C) , respectively). As expected, local observables have a slower
dynamics—this is due to the fact that the dynamics is nonlocal—than
long-distance ones. In any case, for all observables the autocorrelation
function shows a fast decay: indeed, for @xmath we have @xmath , while
for @xmath we have @xmath . Moreover, @xmath is independent of the
lattice used, confirming the fact that @xmath (as we shall report below,
all lattices have the same @xmath ).

Since the measurement of the observables is quite CPU-time consuming, we
evaluated the observables listed in the next paragraphs, and in
particular the short-distance products of Noether currents, only every
15 iterations. This should be enough to make the measurements
independent. Nonetheless, most of the CPU time is employed in evaluating
the observables on each spin configuration of the ensemble. The updating
time is a small fraction of the total computing time. We computed the
product @xmath of two Noether currents for distances @xmath smaller than
some fixed fraction of the correlation length: @xmath . If the physical
size @xmath of the lattice is kept constant (as we did) we expect the
CPU time to scale as @xmath . The CPU time per iteration turns out to be
roughly independent of the particular product considered. As an example
we give the CPU time per measurement for the simulation in which we
compute the antisymmetric product of two currents between states with
opposite momentum, see Sec. 3.3.5 . For the three different lattices, on
an SGI Origin2000, we have: @xmath , @xmath , @xmath .

We measure several different observables. First, we measure the
two-point function @xmath (here and in the following the “temporal”
direction is the first one, of extent @xmath )

  -- -------- -- --------
     @xmath      (3.75)
  -- -------- -- --------

We computed the correlation function @xmath on the lattices (B) and (C)
for momenta @xmath and times separations @xmath ; on lattice (A) we
considered the same set of momenta and time separations @xmath . The
number of independent configurations we generated is: @xmath for lattice
(A) ; @xmath for lattice (B) ; @xmath for lattice (C) and @xmath ;
finally @xmath for lattice (C) and @xmath .

A check of our simulation is provided by the results of Ref. [ 83 ] ,
who computed, among other things, the mass gap for lattices (A) and (B)
. For the exponential correlation length @xmath we obtain

  -- -------- -- --------
     @xmath      (3.76)
  -- -------- -- --------

for lattices (A) , (B) , (C) respectively. They are in good agreement
with the results of Ref. [ 83 ] : they obtain @xmath and @xmath for the
first two lattices. The three lattices we simulate have approximately
the same physical size, @xmath , which is large enough to make
finite-size effects much smaller than our statistical errors.
Finite-size corrections are indeed supposed to be exponentially small in
the physical size (i.e. of order @xmath ). This is consistent with the
analysis of [ 84 ] . In Ref. [ 83 ] the authors verified the smallness
of finite-size effects on lattices (A) and (B) .

In order to verify the OPE, we need the values of the matrix elements
which appear in the r.h.s. of Eq. ( 3.1 ). Matrix elements of lattice
operators can be computed from properly defined three-point correlation
functions. If @xmath is a lattice operator, we define the correlation
function

  -- -------- -- --------
     @xmath      (3.77)
  -- -------- -- --------

and the corresponding normalized correlation

  -- -------- -- --------
     @xmath      (3.78)
  -- -------- -- --------

The function @xmath has a finite limit for @xmath . This limit gives
access to the one-particle matrix elements of @xmath , see Sec. 3.3.3 .
For this reason, we shall look for a plateau in the large- @xmath
behavior of @xmath .

In this Chapter we will only need the matrix elements of the naive
lattice energy-momentum tensor ( 2.148 ). For this reason, we have
computed @xmath with @xmath . Such a correlation function has been
computed on lattice (B) , using @xmath configurations, for @xmath and
@xmath , @xmath . For these observables @xmath is independent of @xmath
, within the statistical errors, already at @xmath . The results
obtained for @xmath are reported in Table 3.1 . For @xmath , statistical
errors are dominated by the error on the evaluation of @xmath . On the
other hand, for @xmath , the statistical error of the numerator in Eq. (
3.78 ) is roughly equal to that of the denominator. The reason is clear:
since in the continuum limit @xmath is proportional to the identity
operator, we are computing essentially (up to @xmath corrections) the
same quantity in the numerator and in the denominator, with
approximately the same statistics. The reported errors on the ratios are
obtained using the independent error formula. For @xmath smaller error
bars could have been obtained by taking into account the statistical
correlations between numerator and denominator.

We also measured @xmath for the same operators on lattice (B) , using
@xmath independent configurations, for @xmath with @xmath and @xmath .
The normalized three-point function shows a plateau for @xmath when
@xmath and for @xmath when @xmath . The results obtained for @xmath are
reported in Tab. 3.2 . In this case the statistical errors are dominated
by the uncertainty on @xmath .

In order to obtain one-particle matrix elements of products of Noether
currents, we proceed in the same manner as above. The only difference is
that we must consider four-point (instead of three-point) functions. In
particular, let us define:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.79)
     @xmath   @xmath   @xmath      (3.80)
  -- -------- -------- -------- -- --------

where @xmath is the lattice Noether current defined in Eq. ( 2.160 ). Of
course, we averaged over lattice translations.

Here is a list of the quantities we measured in our Monte Carlo
simulations:

-   @xmath using @xmath configurations on lattice (A) and using @xmath
    independent configurations on lattice (B) .

-   @xmath using @xmath independent configurations on lattice (B) .

-   @xmath using @xmath configurations on lattice (A) , @xmath
    independent configurations on lattice (B) , and @xmath
    configurations on lattice (C) .

-   @xmath using @xmath independent configurations on lattice (B) .

In all cases we consider @xmath , @xmath ; @xmath and @xmath on lattice
(A) , @xmath and @xmath on lattice (B) , and @xmath and @xmath on
lattice (C) .

Using the four-point correlation function determined above, we
constructed the normalized ratios

  -- -------- -- --------
     @xmath      (3.81)
  -- -------- -- --------

which have a finite limit for @xmath . We verified that @xmath is
independent of @xmath in the range considered, and thus we have taken
the result obtained at the lowest considered value of @xmath as an
estimate of @xmath .

In the paper we will usually consider averages over two-dimensional
rotations, i.e., given a function @xmath , we consider

  -- -------- -- --------
     @xmath      (3.82)
  -- -------- -- --------

with @xmath and @xmath , @xmath integer.

#### 3.3.2 One-Particle States

In the conventional picture the lowest states of the model are
one-particle states transforming as @xmath vectors. On a lattice of
finite spatial extent @xmath , we normalize the states and the fields as
follows:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.83)
     @xmath   @xmath   @xmath      (3.84)
  -- -------- -------- -------- -- --------

The function @xmath , which is the energy of the state @xmath , and the
field renormalization @xmath can be determined from the large- @xmath
behavior of the two-point function @xmath :

  -- -------- -- --------
     @xmath      (3.85)
  -- -------- -- --------

In the continuum (scaling) limit we have @xmath independent of @xmath
and @xmath . In Table 3.3 we report our results for the three lattices.
In order to evaluate @xmath and @xmath , we determined effective values
at time @xmath by solving the equations

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.86)
     @xmath   @xmath   @xmath      (3.87)
  -- -------- -------- -------- -- --------

Then we looked for a plateau in the plot of @xmath and @xmath versus
@xmath . Both functions become independent of @xmath for @xmath . The
values reported in Table 3.3 correspond to one particular value of
@xmath of order @xmath : @xmath respectively for lattice (A) , (B) , (C)
.

In principle we should take the limit: @xmath , and @xmath . Our
procedure consists in using one particular value of @xmath rather than
trying an extrapolation. This gives good results as long as the
systematic error (due to the finiteness of @xmath ) is of the same order
as the statistical one. The expected large- @xmath behavior of @xmath is

  -- -------- -- --------
     @xmath      (3.88)
  -- -------- -- --------

where we neglected terms of order @xmath and multi-particle states
involving more than three particles. The “standard wisdom” prediction
for the gap @xmath is:

  -- -------- -- --------
     @xmath      (3.89)
  -- -------- -- --------

In the thermodynamic ( @xmath ) limit, the coefficient @xmath is a
slowly varying (power-like) function of @xmath .

In Fig. 3.2 we plot @xmath , versus @xmath . together with best fitting
(least squares) curves of the form:

  -- -------- -- --------
     @xmath      (3.90)
  -- -------- -- --------

There is rough agreement between this form and the numerical data. The
@xmath dependence of @xmath cannot be appreciated due to the statistical
errors. From the fit ( 3.90 ) we get an idea of the systematic error on
@xmath , namely @xmath . The estimated systematic error, corresponding
to the curves in Fig. 3.2 , is about @xmath , which is of the same order
as the statistical error. The above analysis can be easily extended to
@xmath .

Let us now look at scaling corrections in the one-particle spectrum. In
the continuum limit we expect @xmath , and @xmath . In Fig. 3.3 we plot
the ratios @xmath (graph (A)), and @xmath (graph (B)). Both this
quantities all well described by the same form, see Ref. [ 83 ] :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.91)
     @xmath   @xmath   @xmath      (3.92)
  -- -------- -------- -------- -- --------

The fitting lines in Fig. 3.3 have been obtained using @xmath and @xmath
. The fitting form in Eqs. ( 3.91 ) and ( 3.92 ) follows from the
general behavior of scaling corrections. Let us consider, for instance,
the ratio @xmath . Since the continuum limit of this quantity is equal
to one, it behaves as follows:

  -- -------- -- --------
     @xmath      (3.93)
  -- -------- -- --------

with @xmath weakly (logarithmically) depending upon @xmath , at @xmath
and @xmath fixed. Since @xmath and @xmath is even in @xmath , it follows
that @xmath , whence

  -- -------- -- --------
     @xmath      (3.94)
  -- -------- -- --------

which coincides with Eq. ( 3.92 ). Our three lattices (A) , (B) and (C)
have approximatively the same physical size @xmath . Because of the
logarithmic dependence of @xmath upon @xmath , the fitting coefficients
@xmath and @xmath should not be independent of the lattice at @xmath
fixed. However our statistical errors are too large to detect this weak
dependence. Finally, let us notice that the behavior described in Eqs. (
3.91 ) and ( 3.92 ) can be recovered in lattice perturbation theory [ 48
] . It is easy to obtain @xmath (one-loop perturbation theory) and
@xmath (tree-level perturbation theory). Both these results are in rough
agreement with our numerical data. We conclude that for the two largest
lattices the spectrum scales at the error-bar level. Instead, for
lattice (A) there are tiny (and essentially under control) scaling
corrections. These corrections are so small (at most 1%) that we can
neglect them in the following discussion.

One can also investigate asymptotic scaling, i.e. the dependence of
@xmath and @xmath on @xmath . The dependence of @xmath can be determined
from Eq. ( 2.205 ). There exists also an exact prediction for @xmath ,
including the non-perturbative constant [ 85 , 86 ] . However, as is
well known, lattice perturbation theory is not predictive at these
values of the correlation length, and indeed, the perturbative four-loop
predictions show large discrepancies compared to the numerical data. The
agreement is instead quite good [ 87 , 86 ] if one uses the improved
coupling @xmath defined in Eq. ( 2.201 ).

#### 3.3.3 Non-Perturbative Renormalization of the Lattice
Energy-Momentum Tensor

In this Section we want to compute non-perturbatively the
renormalization constant @xmath of the lattice energy-momentum tensor,
see Eq. ( 2.5.1 ). In general, given an operator @xmath on the lattice,
we define its matrix element by

  -- -------- -- --------
     @xmath      (3.95)
  -- -------- -- --------

For @xmath the matrix elements can be obtained from the results given in
Tables 3.1 and 3.2 . The matrix elements of @xmath are dominated by the
mixing with the identity operator and thus, in order to define the
renormalized operator for @xmath , we should perform a non-perturbative
subtraction of the large @xmath term, which is practically impossible. ⁴
⁴ 4 In general we expect @xmath and @xmath . The quantity we are
interested in is @xmath . However, from Table 3.1 we immediately realize
that much smaller errors are required to really observe the momentum
dependence of the matrix elements and thus to determine the constant
@xmath . Therefore, we only compute the renormalized operator for @xmath
, which amounts to determining the constant @xmath . This constant is
obtained by requiring

  -- -------- -- --------
     @xmath      (3.96)
  -- -------- -- --------

In practice, we first compute an effective (momentum-dependent)
renormalization constant

  -- -------- -- --------
     @xmath      (3.97)
  -- -------- -- --------

which, in the continuum limit, becomes independent of @xmath and
converges to @xmath . Using the data of Table 3.1 , on lattice (B) , we
obtain @xmath , @xmath , @xmath for @xmath , @xmath , @xmath
respectively.

Corrections to scaling are expected to produce the following dependence
upon the external momentum: @xmath . In Fig. 3.4 we report the numerical
results for @xmath , together with the best fitting curve of the form
@xmath . Clearly the scaling corrections are small: we can estimate
@xmath on this lattice. This compares very well with the result of
one-loop lattice perturbation theory given in Eq. ( 2.150 ), which
yields @xmath , and with the result of “improved” (sometimes called
“boosted”) perturbation theory in terms of the coupling @xmath , cf. Eq.
( 2.201 ), @xmath (the error is due to the error on @xmath ).

#### 3.3.4 OPE for the Scalar Product of Currents

In this Section we consider the product @xmath averaged over rotations.
Using Eq. ( 3.2 ), we have in the continuum scheme

  -- -------- -- --------
     @xmath      (3.98)
  -- -------- -- --------

Notice that, since the currents are exactly conserved, both on the
lattice and in the continuum, there is no need to make a distinction
between lattice and @xmath -renormalized operators. All other
contributions vanish after the angular average. Using the results of
Sec. 3.1.1 we have at one loop in the @xmath scheme

  -- -- -- --------
           (3.99)
  -- -- -- --------

where @xmath is the renormalization scale and @xmath Euler’s constant.
We will not use this form of the OPE expansion, but instead the
RG-improved Wilson coefficients. Thus, cf. Sec. 2.7 , we write

  -- -------- -- ---------
     @xmath      (3.100)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (3.101)
  -- -------- -- ---------

and @xmath is the running coupling constant defined by

  -- -------- -- ---------
     @xmath      (3.102)
  -- -------- -- ---------

This expression coincides with the one of Sec. 2.7 , see Eq. ( 2.186 ),
apart from the factor @xmath which has been inserted for future
convenience. Using the perturbative expression ( 2.187 ), we can also
rewrite ( 3.101 ) as

  -- -------- -- ---------
     @xmath      (3.103)
  -- -------- -- ---------

where @xmath .

We will also use the lattice Wilson coefficients, see Sec. 3.1.2 . Using
the one-loop results of Sec. 3.1.2 and the general expressions reported
in Sec. 2.7 , proceeding as before, we obtain the prediction

  -- -------- -- ---------
     @xmath      (3.104)
  -- -------- -- ---------

where, at one loop,

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (3.105)
     @xmath   @xmath   @xmath      (3.106)
  -- -------- -------- -------- -- ---------

and @xmath is the running coupling constant defined by

  -- -------- -- ---------
     @xmath      (3.107)
  -- -------- -- ---------

where @xmath is the lattice @xmath -parameter, see Sec. 2.7 .

Finally we shall test perturbation theory in the “improved” expansion
parameter @xmath defined in Eq. ( 2.201 ). The OPE becomes:

  -- -------- -- ---------
     @xmath      (3.108)
  -- -------- -- ---------

where

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (3.109)
  -- -------- -------- -------- -- ---------

@xmath is the same as in Eq. ( 3.106 ), and @xmath is the running
coupling constant defined by

  -- -------- -- ---------
     @xmath      (3.110)
  -- -------- -- ---------

where @xmath is the @xmath -parameter ( 2.203 ).

We have tested the validity of the OPE by considering matrix elements
between one-particle states. The matrix elements of the product of the
currents can be determined in terms of @xmath , since

  -- -------- -- ---------
     @xmath      (3.111)
  -- -------- -- ---------

In Fig. 3.5 we report ⁵ ⁵ 5 On lattice (B) @xmath has only been measured
in @xmath . The points with @xmath appearing in the figure correspond to
“partial” angular averages, i.e. they have been obtained using Eq. (
3.82 ) and restricting @xmath to @xmath . The same comment applies also
to the subsequent figures. the angular average of @xmath for lattices
(A) and (B) : here @xmath , @xmath for the two lattices respectively. In
Figs. 3.6 , 3.7 , and 3.8 we compare these numerical data with the
predictions of perturbation theory.

In Fig. 3.6 we use continuum RG-improved perturbation theory in the
@xmath scheme. In this case, the matrix element of the energy-momentum
tensor is immediately computed: @xmath . Therefore, we consider the
ratio

  -- -------- -- ---------
     @xmath      (3.112)
  -- -------- -- ---------

which should approach 1 in the short-distance limit. In Fig. 3.6 we
present several determinations of @xmath that differ in the way in which
the running coupling constant @xmath and the @xmath coupling @xmath are
determined.

There are several different methods that can be used to compute the
@xmath coupling @xmath and the strictly related @xmath . They have been
compared in detail in Sec. 2.8 . It turned out that the finite-size
scaling method proposed by Lüscher [ 60 , 61 ] and what we call “the
RG-improved perturbative method” are essentially equivalent, see, e.g.,
Table 2.1 . Therefore, we can use either of them, ⁶ ⁶ 6 In QCD the
RG-improved perturbative method cannot be used since no exact prediction
for the mass gap exists. In this case the finite-size scaling method
would be the method of choice. Note that for large values of the scale
also the improved-coupling method [ 63 , 64 ] , which can be generalized
to QCD [ 88 ] , works well, see Sec. 2.8 . obtaining completely
equivalent results. In Fig. 3.6 we have used the finite-size scaling
method to be consistent with what we would do in QCD. Elsewhere, we have
used the RG improved perturbative method because of its simplicity.

The first step in the computation of @xmath is the determination of
@xmath . This is obtained as follows: we fix @xmath , and using the
finite-size scaling results reported in Table 2.1 , we compute @xmath .
Then, using Eq. ( 2.197 ) we determine @xmath at @xmath -loops. Finally,
@xmath is obtained either by solving Eq. ( 3.102 ), again using Eq. (
2.197 ) for @xmath appearing in the right-hand side, or by using Eq. (
2.187 ). As we discussed in Sec. 2.8 , the final result should be
independent of the chosen value of @xmath and therefore we can evaluate
the systematic error on @xmath by considering different values of @xmath
. If we fix @xmath , cf. first row of Table 2.1 , we have @xmath ,
@xmath , @xmath respectively for @xmath , @xmath , @xmath , while if we
fix @xmath , cf. 10th row of Table 2.1 in App. 2.8 , we have @xmath ,
@xmath , @xmath at the same distances. The dependence is tiny and, as
expected, it increases for larger values of @xmath . In practice, it
does not play any role, the main source of error being instead the
truncation of the OPE coefficients. Notice that the independence on
@xmath is obvious if we use the RG-improved perturbative method.

Let us now describe the various graphs appearing in Fig. 3.6 . In graphs
(A) and (B) we fix @xmath and then, using the results presented in Table
2.1 , cf. first row, we obtain @xmath . We then compute @xmath using the
four-loop expression ( 2.197 ) with @xmath . Finally, the Wilson
coefficient is given by ( 3.103 ): in graph (A) we use the leading term
only, while in graph (B) we include the next-to-leading one.

In graphs (C) and (D) we compute @xmath as in (A) and (B), choosing a
different scale, @xmath , cf. @xmath row of Table 2.1 . Then we compute
@xmath by solving numerically Eq. ( 3.102 ) using the four-loop
expression ( 2.197 ) with @xmath . Finally, the Wilson coefficient is
obtained using Eq. ( 3.101 ). While in graph (C) we keep only the
leading term @xmath , in graph (D) we use the complete expression.

Finally, graphs (E) and (F) are identical to graph (D) except that
@xmath and @xmath are computed using the two-loop expression ( 2.197 )
with @xmath . The two graphs correspond to different choices of @xmath :
@xmath (graph (E)) and @xmath (graph (F)).

Comparing the different graphs, we immediately see that the choice of
scale @xmath and the order of perturbation theory used for @xmath (two
loops or four loops) are not relevant with the present statistical
errors. Much more important is the role of the Wilson coefficients. If
one considers only the leading term (graphs (A) and (C)) there are
indeed large discrepancies and in the present case one would obtain
estimates of the matrix elements with an error of 50–100%. Inclusion of
the next-to-leading term—this amounts to considering one-loop Wilson
coefficients and two-loop anomalous dimensions—considerably improves the
results, and now the discrepancy is of the order of the statistical
errors, approximately 10%. For the practical application of the method,
it is important to have criteria for estimating the error on the
results. It is evident that the flatness of the ratio of the matrix
element by the OPE prediction is not, in this case, a good criterion:
The points in graph (A) show a plateau—and for a quite large set of
values of @xmath —even if the result is wrong by a factor of two.
However, this may just be a peculiarity of the case we consider, in
which the @xmath -dependence of the data and of the OPE coefficients is
very weak. On the other hand, the comparison of the results obtained
using different methods for determining @xmath seems to provide
reasonable estimates of the error bars. For instance, if only the
leading term of the Wilson coefficients were available, we could have
obtained a reasonable estimate of the error by comparing graphs (A) and
(C).

In Fig. 3.7 we consider lattice RG-improved perturbation theory,
computing

  -- -------- -- ---------
     @xmath      (3.113)
  -- -------- -- ---------

In graph (A) we use @xmath as an expansion parameter. We compute @xmath
using the value of the mass gap @xmath and Eq. ( 2.205 ), with the
non-perturbative constant ( 2.206 ). Then, we determine @xmath by
solving numerically ( 3.107 ) and using for @xmath appearing in the
left-hand side its truncated four-loop expression ( 2.197 ). Finally, we
use Eq. ( 3.105 ) for the Wilson coefficient. The results are quite
poor: there is a downward trend as a function of @xmath and the data are
far too low. Naive lattice perturbation theory is unable to provide a
good description of the numerical data.

The results improve significantly if we use the improved coupling @xmath
: The estimates obtained using this coupling, graphs (B), (C), (D), are
not very different from those obtained using @xmath continuum
perturbation theory. Graph (B) has been obtained exactly as graph (A),
except that in this case we used @xmath as an expansion parameter. The
@xmath -parameter is defined in ( 2.203 ), @xmath in ( 2.204 ), and the
relevant Wilson coefficient is given in Eq. ( 3.109 ). Graphs (C) and
(D) are analogous to graph (B). The difference is in the determination
of @xmath . We do not compute it non-perturbatively by using the mass
gap but we determine it directly from the perturbative expression (
2.203 ). In this case we use the perturbative expression truncated at
four loops (C) and two loops (D).

In Figs. 3.6 and 3.7 we have checked the validity of the OPE on lattice
(B) . If one has in mind QCD applications this is quite a large lattice
since @xmath . For this reason, we have tried to understand if the nice
agreement we have found survives on a smaller lattice, by repeating the
computation on lattice (A) . The results are reported in Fig. 3.8 .
Graphs (A) and (B) should be compared with graph (D) of Fig. 3.6 . In
(A) we compute @xmath from Eq. ( 2.195 ), with the non-perturbative
constant ( 2.196 ) and @xmath . Then, we compute @xmath solving
numerically Eq. ( 3.102 ) using the four-loop expression ( 2.197 ) with
@xmath . The Wilson coefficient is obtained from Eq. ( 3.101 ). In (B)
we repeat the same calculation as in Fig. 3.6 graph (D) at the scale
@xmath . In (C) and (D) we repeat the calculation of graph (B) using the
two-loop and the three-loop @xmath -function for the determination of
the coupling @xmath . In all graphs (B), (C), (D) we use the result
@xmath .

Graphs (A) and (B) show a nice flat behavior and for @xmath , the ratio
@xmath is approximately 1 with 2–3% corrections (notice that the
vertical scale in Figs. 3.6 and 3.8 is different): The OPE works nicely
even on this small lattice. (A) and (B) differ in the method used in the
determination of the @xmath coupling. As we explained in App. 2.8 and it
appears clearly from the two graphs, the effect is very small. Graph
(C)—and to a lesser extent graph (D)—shows instead significant
deviations: Clearly, @xmath must be determined using four-loop
perturbative expansions in order to reduce the systematic error to a few
percent. Notice that such discrepancies are probably present also for
lattice (B) : however, in this case, the statistical errors on @xmath
are large—approximately 5-6% (for @xmath and @xmath ) and 9% (for @xmath
)—and thus they do not allow to observe this effect.

As a further check we considered matrix elements between states of
different momentum. In Fig. 3.9 we report the angular average of @xmath
for lattice (B) . In Fig. 3.10 we compare the numerical data with the
OPE prediction, by considering

  -- -------- -- ---------
     @xmath      (3.114)
  -- -------- -- ---------

where @xmath is defined in Eq. ( 2.5.1 ) and @xmath is computed in Sec.
3.3.3 . In Fig. 3.10 we report @xmath for lattice (B) . The Wilson
coefficients are computed as in graph (A) of Fig. 3.8 , using @xmath .
The numerical data are again well described by the OPE prediction for a
quite large set of values of @xmath .

#### 3.3.5 OPE for the Antisymmetric Product of Currents

In this Section we consider the antisymmetric product of two currents
and compare our numerical results with the perturbative predictions.
With respect to the previous case, we have here a better knowledge of
the perturbative Wilson coefficients—some of them are known to two
loops—and moreover we have an exact expression for the one-particle
matrix elements of the current @xmath . Indeed, we have [ 89 , 83 ] :

  -- -------- -- ---------
     @xmath      (3.115)
  -- -------- -- ---------

where @xmath , @xmath , @xmath , and, for @xmath ,

  -- -------- -- ---------
     @xmath      (3.116)
  -- -------- -- ---------

where the rapidity variable @xmath is defined by @xmath .

We first consider the product @xmath for @xmath and @xmath . The OPE of
such a product can be determined from Eq. ( 3.17 ). Using the results of
App. 3.2 , we have for @xmath ,

  -- -------- -- ---------
     @xmath      (3.117)
  -- -------- -- ---------

where, at two loops,

  -- -------- -- ---------
     @xmath      (3.118)
  -- -------- -- ---------

and @xmath is defined in Eq. ( 3.102 ). We also consider the angular
average of the product of the currents for @xmath and @xmath . Using the
results of Sec. 3.1.1 , we have for @xmath

  -- -------- -- ---------
     @xmath      (3.119)
     @xmath      
  -- -------- -- ---------

Again, we have tested the validity of the OPE by considering matrix
elements between one-particle states. The matrix elements of the product
of the currents are obtained from

  -- -------- -- ---------
     @xmath      (3.120)
  -- -------- -- ---------

In Fig. 3.11 we show a plot of @xmath obtained on lattice (B) for @xmath
and @xmath , and in Fig. 3.12 we show the angular average of @xmath on
the same lattice and again for @xmath . Comparing these graphs with
those for the scalar product of the currents, one sees that the matrix
elements show here a larger variation with distance, and thus this
should provide a stronger test of the validity of the OPE.

In Fig. 3.13 we compare the results for @xmath with the OPE perturbative
predictions. Here, as always in this Section, we use the RG-improved
perturbative method to compute @xmath , using the four-loop expression
for the @xmath function. As we explained at length in the previous
Section, no significant difference is observed if one uses the
finite-size scaling method, or improved lattice perturbation theory.

In graphs (A) and (B) we show the combination

  -- -------- -- ---------
     @xmath      (3.121)
  -- -------- -- ---------

for two different values of @xmath . In the scaling limit @xmath is a
function of @xmath and of @xmath . As it can be seen from the graphs our
results show a very nice scaling: The data corresponding to the three
different lattices clearly fall on a single curve. In the same graphs we
also report the OPE prediction ( 3.117 ), i.e.

  -- -------- -- ---------
     @xmath      (3.122)
  -- -------- -- ---------

Note that @xmath , so that the corrections due to higher-order terms in
the OPE expansion are of order @xmath . In graph (A) and (B) we use only
the one-loop Wilson coefficient for @xmath . There is a good agreement
between the OPE prediction and the numerical data: quite surprisingly
the agreement extends up to 2 lattice spacings.

To better understand the discrepancies, in graphs (C) and (D) we report
@xmath . In graphs (C1) and (C2) we use the one-loop Wilson coefficient,
and in (D1) and (D2) the two-loop Wilson coefficient given in Eq. (
3.118 ). The numerical data refer to lattice (A) for (C1) and (D1) and
to lattice (B) for (C2) and (D2). There is clearly agreement, although
here deviations are quantitatively somewhat large, since @xmath is
strongly varying. Let us consider for instance the data obtained on
lattice (B) for @xmath . If we evaluate the matrix element of the
Noether current using the numerical estimate of @xmath with @xmath we
obtain the result with a systematic error of @xmath respectively.

In Fig. 3.14 we compare the angular average of @xmath (cf. Fig. 3.12 )
with the OPE prediction, by defining

  -- -------- -- ---------
     @xmath      (3.123)
  -- -------- -- ---------

where @xmath is the OPE one-loop prediction ( 3.3.5 ). Here we use the
form-factor prediction ( 3.115 ) for the matrix elements of the
currents, but no significant difference would have been observed if the
matrix elements of the currents had been determined numerically. Use of
the form-factor prediction allows only a reduction of the statistical
errors and thus gives the opportunity for a stronger check of the OPE.
Again we observe a nice agreement and a very large window in which the
data are well described by perturbative OPE. The systematic error is
below the statistical one (which is approximately @xmath ) as soon as
@xmath .

### 3.4 First Answers

From the examples of short-distance products studied in this Chapter we
can draw some first conclusions.

We considered products of the type @xmath . In most of the cases the
leading term of the OPE was of order @xmath (with @xmath ), and the
first correction, after averaging over rotations, was of order @xmath .
In these cases, we can make the following statements, which are valid
within the statistical accuracy of our numerical simulations (about
@xmath , depending upon the particular example):

-   We extracted one-particle matrix elements of the type @xmath from
    well chosen four-point correlation functions. These correlation
    functions show a nice scaling behavior as soon as @xmath . On
    general grounds we would expect scaling corrections of order @xmath
    (among the others). Such scaling corrections cannot be seen in our
    data. The only relevant lattice artifacts occur at @xmath . This is
    easily understood if we remember that the lattice currents @xmath
    and @xmath have a spatial extension of one lattice spacing, see Eq.
    ( 2.160 ). The lattice artifacts at @xmath are due to contacts
    between the two operators @xmath and @xmath .

    Such a good scaling behavior allows to use the OPE on rather coarse
    lattices, e.g. on lattice (A) which has a correlation length @xmath
    .

-   Power corrections (i.e. terms of order @xmath ) are negligible for
    @xmath . Indeed we did not find evidence for them in our numerical
    results.

-   The running coupling @xmath can be accurately determined. This
    determination makes use of the four-loop beta function, and of the
    lambda parameter. In the @xmath non-linear @xmath -model, the lambda
    parameter can be computed either with the finite-size method, or by
    using the exact prediction for the mass gap. In QCD there exists no
    exact prediction fixing the lambda parameter in terms of some
    low-energy quantity. However, the finite-size method has already
    given a precise determination of @xmath for the quenched theory.

    In our case we can compute @xmath with a few percent accuracy, over
    all the range @xmath .

-   The perturbative computation of the Wilson coefficients seems to be
    the weakest point of the whole procedure. The use of the leading-log
    approximation gives grossly inexact (by more than @xmath ) results
    in most of the cases considered. The next-to-leading-log
    approximation (which requires the computation of one-loop Wilson
    coefficients and two-loop anomalous dimensions) yields results with
    about a @xmath accuracy. These statements are valid if a
    “well-behaved” renormalization scheme (e.g. @xmath ) is adopted.
    They seem to hold also if improved lattice perturbation theory is
    used. Naive lattice perturbation theory gives much worser results.

-   The use of different resummation methods for the Wilson coefficients
    seems to give a realistic idea of the systematic error involved in
    their perturbative calculation.

These conclusions should be perhaps modified if the leading Wilson
coefficient has a power-like diverging behavior ( @xmath ). We studied a
single case of this type, see Sec. 3.3.5 . In this case we were able to
compute the relevant Wilson coefficient up to two-loop order.
Nevertheless, the agreement between the OPE prediction and the numerical
results was not good as in the other examples.

## Chapter 4 Operator Product Expansion for Elementary Fields

In this Chapter we shall consider the short-distance expansion of the
product of two elementary fields for the @xmath non-linear @xmath
-model. The motivation for such a study is twofold.

From a numerical point of view, the task is simpler than in the previous
Chapter. Computing the product of two fields implies fewer operations
than computing the product of two Noether currents. This implies a
significative speed up in the algorithms and, as a consequence, much
better numerical data. We will be able to discuss finer issues than in
the previous Chapter, such as lattice artifacts and next-to-leading
terms in the OPE.

Unlike Noether currents, elementary fields require a non-trivial
renormalization. This makes the exercise slightly more complicated from
a conceptual point of view. We shall be forced to consider the
intricacies of renormalization and to compare various (perturbative and
non-perturbative) renormalization methods.

As in the previous Chapter, we shall focus on matrix elements between
one-particle states. Generally speaking, we shall consider the following
OPE:

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where, once more, we neglected @xmath indices. They will be specified in
Sec. 4.4 . In the above equation @xmath is the leading term of the OPE.
The corresponding Wilson coefficient @xmath is of order @xmath or @xmath
(we recall that @xmath ), depending upon the specific example. In the
cases we considered, @xmath does not mix with any other operator (it
renormalizes multiplicatively). The other terms, denoted generically as
@xmath , are power corrections of relative order @xmath . The operators
@xmath have a non-trivial mixing structure.

We evaluated the left-hand side of Eq. ( 4.1 ) in lattice simulations
for @xmath . Notice that the separation between the two field operators
on the left-hand side of Eq. ( 4.1 ) is @xmath . This means that, in
this Chapter, we are probing larger distances than in the previous one.
We expect that power corrections, i.e. the @xmath terms in Eq. ( 4.1 ),
will not be negligible on such distances.

In this Chapter we mimic what would be done in a physical (QCD)
application of the OPE method. We fit the numerical results for the
l.h.s. of Eq. ( 4.1 ), using the r.h.s. as fitting form, and keep the
matrix elements @xmath and @xmath as fitting parameters. Finally we
compare the results for @xmath with some independent prediction, either
numerical or analytical, for the same quantity.

We restrict the fit to the window @xmath , and study the dependence of
the results upon the window. In particular we shall focus on the outer
limit @xmath . We learned in the previous Chapter that the principal
source of error, in comparing the OPE with lattice simulations, is the
perturbative truncation of the Wilson coefficients. This systematic
error depends upon @xmath , and in particular vanishes as @xmath because
of asymptotic freedom. The crucial point is that we cannot easily take
the limit @xmath because of lattice artifacts (which force us to
consider @xmath ) and of finite-size effects (for avoiding them, we must
take @xmath , @xmath being the linear size of the lattice).

We shall also consider the evaluation of the matrix elements @xmath of
the non-leading operators in the OPE. It turns out that a distinction
must be made among these operators. Those which do not mix with the
leading one ( @xmath ) can be fixed through Eq. ( 4.1 ), adopting a
perturbative determination of the Wilson coefficients. Nevertheless the
computation is, in practice, quite difficult. The determination of the
other operators, those that mix with @xmath , is instead impossible,
even from a theoretical point of view. Such a calculation would require
a non-perturbative knowledge of the leading Wilson coefficient @xmath .

This Chapter is organized as follows. In Sec. 4.1 we recall some
well-known properties of perturbative expansions in quantum field
theory. We discuss the consequences of these properties on our
non-perturbative renormalization method. In Sec. 4.2 we write the
structure of the OPE for two elementary fields, including @xmath terms,
and we list the perturbative results for the Wilson coefficients. In
Sec. 4.3 we show how to solve the RG equation if a resonance occurs in
the anomalous dimensions matrix, cf Sec. 2.7 . In Sec. 4.4 we explain
the details of the fitting procedure, and we present our numerical
results. Finally we summarize our conclusions in Sec. 4.5 .

### 4.1 Perturbative Expansions and OPE

As we explained above, in this Chapter we shall keep track of the
next-to-leading terms in the OPE. Our interest is twofold. First of all
this may improve the determination of the leading operator. Moreover we
want to understand if it is possible to estimate next-to-leading
operators.

It turns out that there is some theoretical difficulty in estimating
next-to-leading operators in the OPE when they mix with the leading one.
This theoretical difficulties are related to the diseases of
perturbative expansions, namely to renormalons . In this Section we try
to describe these difficulties.

The Section is divided in two parts. In the first one we review some
well-known facts concerning the perturbative series of renormalizable
asymptotically-free theories. The intent is mainly pedagogical. Rather
than making general statements, we look at simple examples taken from
the @xmath non-linear @xmath -model at large @xmath . This has been an
important toy model for the study of such problems. For a complete
review on renormalons we refer to [ 90 ] . In the second part of this
Section we discuss the possibility of evaluating the matrix elements of
next-to-leading operators which mix with the leading one.

#### 4.1.1 The Limits of Perturbative Expansions

For our discussion it is convenient to introduce the widespread language
of Borel transforms. Perturbation theory yields physical quantities in
the form of asymptotic series:

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

In order to recover @xmath from the r.h.s. of Eq. ( 4.2 ) one needs, in
general, additional informations beyond (all) the coefficients @xmath .
These informations usually concern the analyticity properties of @xmath
. A simple example is the case in which @xmath is analytic in a
neighborhood of @xmath . Then, @xmath is obtained by summing the r.h.s.
of Eq. ( 4.2 ) for @xmath smaller than the convergence radius and by
analytic continuation outside.

Unfortunately this case is not realized in any non-trivial
field-theoretical example.

The next simpler situation is realized in several interesting cases
(e.g. @xmath theory with @xmath ) and is described by the hypothesis of
the Nevalinna-Sokal theorem [ 91 ] :

-   @xmath is analytic inside a disc @xmath of radius @xmath and center
    @xmath with @xmath and @xmath .

-   The remainder @xmath satisfies the bound

      -- -------- -- -------
         @xmath      (4.3)
      -- -------- -- -------

When the previous hypothesis are realized, the function @xmath is
uniquely determined by the coefficients @xmath through the following
construction. One defines the Borel transform of the series ( 4.2 ) as
the formal series given below

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

Under the hypotheses I and II it can be proved that the sum on the
r.h.s. of Eq. ( 4.4 ) converges for @xmath , @xmath . We can promote
@xmath to the status of an analytic function. Moreover it can be proved
that @xmath is analytic inside the strip @xmath and that the integral

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

is finite and equal to @xmath for @xmath .

The physically interesting case of four-dimensional non-abelian gauge
theories does not fit in the above picture. In this case there is no
exact result about the properties of perturbative expansions. Here we
recall the standard picture, which is based on heuristic calculations.
The large-order behavior of the perturbative coefficients is @xmath ,
where @xmath and @xmath are the first two coefficients of the
beta-function, see Eq. ( 2.10 ). This behaviour is compatible with the
hypothesis II. However, the analiticity region of @xmath is a wedge of
zero opening angle with the tip at the origin. The essential ingredients
for the above picture are renormalizability and asymptotic freedom. As a
consequence similar statements hold for the two-dimensional @xmath
non-linear @xmath -model.

In order to study the concepts outlined above in a simple model we shall
consider the @xmath nonlinear @xmath -model in the limit @xmath . In
this Section we fix the field and coupling-constant renormalizations by
requiring:

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

where @xmath is the two-point vertex function. It is moreover convenient
to define the running coupling at the scale @xmath by using the
renormalization-group equation @xmath . At leading order in @xmath ,
@xmath , whence

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

We start with a simple example of physical observable, and consider its
perturbative expansion. We define the effective coupling @xmath as
follows in terms of the four-point vertex function @xmath :

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (4.8)
  -- -------- -------- -------- -- -------

Being a renormalization group invariant quantity, @xmath will be a
function of @xmath . It can be rewritten as a function of the the
running coupling @xmath at the scale @xmath , see Eq. ( 4.7 ). The
leading term in the @xmath expansion of @xmath is given by

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

Let us make a few observation concerning this very simple result:

1.  For small positive @xmath we have @xmath . The “perturbative” part
    of this expansion is trivial; it is obviously analytic in the whole
    complex plane. Nevertheless it does not determine @xmath uniquely.
    The next terms are of order @xmath . These are the so-called “power
    corrections”.

2.  The singularity structure of @xmath is nontrivial, including:

    1.  Simple poles at @xmath with @xmath . These poles are of
        “kinematical” origin: they appear because we factored out the
        term @xmath in the definition ( 4.1.1 ) of @xmath .

    2.  Branching points at @xmath , @xmath . These singularities were
        predicted on general grounds by ’t Hooft in Ref. [ 92 ] . They
        are the traces of the two-particle threshold at @xmath .

3.  The function on the r.h.s. of Eq. ( 4.9 ) does not satisfies the
    hypotheses of the Nevalinna-Sokal theorem. If they were satisfied,
    we could sum the perturbative series using the Borel procedure
    obtaining the wrong result @xmath . Indeed, although the function is
    analytic in any disc @xmath with @xmath , it does not satisfy the
    bound in Eq. ( 4.3 ) for any @xmath . In fact, for @xmath , we get
    @xmath and we remark that @xmath is periodic ¹ ¹ 1 More precisely,
    @xmath if @xmath . along the circles @xmath with @xmath These
    circles pass through the origin @xmath and belong to the disc @xmath
    for @xmath . Therefore, we can approach the origin through one of
    these circles. The bound ( 4.3 ) is violated because of the
    periodicity of @xmath .

Let us now consider a less straightforward computation. The self-energy
is defined as follows:

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

The leading term in the @xmath expansion of @xmath is given by

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

where @xmath denotes zero momentum subtraction up to the @xmath order in
the external momentum @xmath . The integral in Eq. ( 4.11 ) has been
considered in Ref. [ 93 ] . One obtains, as a byproduct of its
computation, the whole perturbative series for @xmath which reads:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where @xmath is the Riemann zeta function. Let us quote some simple
remarks:

1.  The series on the r.h.s. of Eq. ( 4.1.1 ) has zero radius of
    convergence. The coefficients have the general large order behavior
    @xmath .

2.  The function @xmath does not satisfy the hypothesis of the
    Nevalinna-Sokal theorem. If they were satisfied the Borel transform
    of the series in Eq. ( 4.1.1 ) would be analytic on the real axis.
    Indeed we obtain (neglecting the @xmath and the constant):

      -- -------- -- --------
         @xmath      (4.13)
      -- -------- -- --------

    which has simple poles at @xmath with @xmath , @xmath .
    Singularities occurring within this pattern are usually denoted as
    “renormalons”.

3.  One can “resum” the series ( 4.1.1 ) through the integral ( 4.5 ) by
    assigning a prescription on each singularities of @xmath . Examples
    of such prescriptions are: take the Cauchy principal value at each
    pole; move slightly upward (downward) in the complex planes all the
    poles; move the pole at @xmath to @xmath , and so on. Notice that,
    since the first pole is at @xmath these prescriptions yield
    resummations which differ by terms of relative order @xmath .

The last of these observations is often rephrased by saying that the
perturbative expansion fixes physical quantities up to an ambiguity of
order @xmath . This is the “standard wisdom” on the problem and is by no
means self-evident. Indeed we could add to a given resummation a term of
the type @xmath without modifying its asymptotic expansion.

However it is commonly believed that the correct physical quantity can
be recovered by assigning a prescription at the renormalon
singularities. We could associate to any perturbative expansion a family
of “minimally ambiguous” resummations, each one corresponding to a
well-defined prescription at renormalon singularities. Any two of these
resummed expansions differ by terms of order @xmath . The correct
resummation lies among them but, in order to recover it, some
non-perturbative input is required.

#### 4.1.2 The Definition of Composite Operators

Let us now consider a simple example of OPE:

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

For sake of simplicity we considered the Wilson coefficients to be
rotationally invariant, i.e. to depend upon @xmath uniquely through its
modulus @xmath . Such a behavior can be enforced by averaging over
rotations. Moreover we made explicit the power-like @xmath dependence of
the Wilson coefficients. Both @xmath and @xmath are of order @xmath .
Finally let @xmath and @xmath have the same (internal and Lorentz)
symmetries. As a consequence they will mix under renormalization.

We suppose the renormalized operators @xmath and @xmath on the l.h.s. of
Eq. ( 4.14 ) to be non-perturbatively known. Hereafter we shall focus on
the RGI operators @xmath , @xmath , @xmath , @xmath , and the
corresponding Wilson coefficients @xmath , @xmath . With a slight abuse
of notation we shall drop the subscripts @xmath in this Subsection.

As usual, everything we know about the Wilson coefficients @xmath (
@xmath ) is their @xmath -loop (respectively, @xmath -loop) perturbative
expansions. If we resum the perturbative series using the
renormalization group, see Sec. 2.7 , we obtain:

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

and an analogous formula for @xmath .

Notice that Eq. ( 4.14 ) allows to define the composite operator @xmath
regardless of the precise value of @xmath :

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

Both the left-hand and right-hand sides of the above equation must be
interpreted as inserted in a correlation function. This correlation
function must be taken with elementary fields @xmath at space-time
points @xmath distinct from @xmath : @xmath ( @xmath ). Apart from this
specification Eq. ( 4.16 ) is an exact definition because of asymptotic
freedom. The @xmath limit is approached with corrections of relative
order @xmath . Equation ( 4.16 ) is the theoretical basis of the
non-perturbative renormalization method studied in this thesis.

Let us now take a step further and see whether Eq. ( 4.14 ) can be used
to define the next-lo-leading operator @xmath . The naive approach would
be to fix @xmath from Eq. ( 4.16 ), and then subtract its contribution
from the OPE ( 4.14 ). In other words one would define @xmath through
the following short distance limit:

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

This procedure is equivalent to using Eq. ( 4.14 ) as a fitting form,
restricting the fit to the window @xmath and considering the @xmath
regime. This is what we do in Sec. 4.4 .

The problem with Eq. ( 4.17 ) is evident: the @xmath limit diverges. The
@xmath behavior of the ratio in Eq. ( 4.17 ) is easily obtained using
Eq. ( 4.14 ):

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

where @xmath .

The problem we encountered do not disappear if we push the perturbative
calculation of Wilson coefficients to high orders. Let us suppose, for
instance, that we know the coefficients @xmath for any @xmath , see Eq.
( 4.15 ). The series ( 4.15 ) with @xmath will diverge, as explained in
Sec. 4.1.1 . Nevertheless we can try to sum it, i.e. to find a function
@xmath whose asymptotic expansion for @xmath coincides with the
perturbative one. We can moreover require @xmath to have the minimum
possible ambiguity. This prescription should be understood in the sense
explained in the previous Subsection.

Even if we have such a minimally ambiguous Wilson coefficient @xmath ,
we are left with a great freedom. This freedom correspond to the choice
of the prescription at the renormalon singularities. It produces an
ambiguity of order @xmath .

Let us now repeat the construction outlined in Eq. ( 4.17 ) using the
new Wilson coefficient @xmath . We get:

  -- -------- --
     @xmath   
  -- -------- --

According to a conjecture due to Parisi [ 94 , 95 , 96 ] , the
ambiguities in the perturbative series are strictly related to the power
corrections in the OPE. In our case we get:

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

Using this formula we can further elaborate Eq. ( LABEL:NewWilson ),
obtaining

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

Even if we know the whole perturbative series for the leading Wilson
coefficient, we cannot fix the next-to-leading operator from the OPE (
4.14 ). The renormalon ambiguity in the leading Wilson coefficient is
accompanied by the ambiguity of the additive renormalization of the
next-to-leading operator. David [ 97 , 98 , 99 ] studied this phenomenon
in the @xmath nonlinear @xmath -model at large @xmath .

Our discussion does not exclude the possibility of estimating the
next-to-leading operator @xmath from the OPE ( 4.14 ). Nevertheless such
a calculation cannot be accomplished by naively substituting the
coefficients @xmath and @xmath by their perturbative truncation. A
clever and accurate definition of the Wilson coefficients is required.
This definition should be matched with the appropriate definition for
the composite operator @xmath .

### 4.2 Perturbative Calculation of the Wilson Coefficients

In order to apply the OPE renormalization method, we have to compute the
OPE of two elementary fields in perturbation theory.

The product of two fields can be decomposed in terms of irreducible
representations of @xmath . We get a scalar, an antisymmetric rank-2
tensor, and a symmetric traceless rank-2 tensor:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.22)
                                @xmath   
  -- -------- -------- -------- -------- --------

It is convenient to introduce the following notation for the symmetrized
and antisymmetrized products: @xmath , and @xmath . As we explained in
the previous Chapter, the form of OPE is dictated by @xmath symmetry and
Lorentz invariance. Let us write it explicitly up to @xmath terms:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.23)
                                @xmath   
     @xmath   @xmath   @xmath            (4.24)
     @xmath                              (4.25)
     @xmath   @xmath   @xmath            
  -- -------- -------- -------- -------- --------

where we defined

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

The symmmetric traceless dimension 2 operators @xmath are defined in
Eqs. ( 2.77 )–( 2.83 ). All the operators on the right-hand sides of
Eqs. ( 4.23 )–( 4.25 ) are understood at the space-time position @xmath
. For sake of simplicity we dropped the Lorentz indices of the Wilson
coefficients in Eqs. ( 4.23 )–( 4.25 ). In Eq. ( 4.25 ) we neglected the
Lorentz indices also on the operators @xmath , @xmath and @xmath . The
indices can be restored without ambiguity. Summation over repeated
indices is understood.

The Wilson coefficients @xmath can be computed in perturbation theory.
We computed the leading coefficient @xmath at two-loop order, and the
next-to-leading coefficients @xmath , @xmath at one-loop order. Using
the results for the anomalous dimensions given in Sec. 2.4 , we are able
to resum the @xmath at next-to-next-to-leading log, and the @xmath ,
@xmath at next-to-leading log order. The outcomes of the resummation
procedure are given in Secs. 4.3 and 4.4 .

Let us begin from the scalar sector, see Eq. ( 4.23 ). In this case the
leading Wilson coefficient is known at three-loop order [ 100 , 101 ] .
Since the field anomalous dimensions are known at four-loop order [ 43 ,
44 ] , see Sec. 2.1 , we can resum this coefficient at (next-to-) @xmath
leading log order, cf. Eq. ( 4.92 ). For greater convenience of the
reader, we give below a complete list of the perturbative results:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (4.28)
     @xmath   @xmath   @xmath      (4.29)
     @xmath   @xmath   @xmath      (4.30)
  -- -------- -------- -------- -- --------

Next we consider the antisymmetric sector, see Eq. ( 4.24 ). Here we
limit ourselves to the leading term of the OPE:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

In Sec. 4.4.8 we shall also consider the power corrections (of relative
order @xmath ) to this leading behavior. Since we did not compute them
in perturbation theory, even in leading-log approximation, we shall
adopt a “phenomenological” point of view. We shall add all the terms
with the correct dimension and Lorentz symmetry, neglecting any
logarithmic @xmath dependence ² ² 2 Something similar is done in Ref. [
102 ] . . This gives the feeling of how power corrections do affect the
estimates on the leading operator @xmath .

Finally we must consider rank-2 symmetric traceless @xmath -tensors, see
Eq. ( 4.24 ). The list of Wilson coefficients is given below:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.32)
     @xmath   @xmath   @xmath      (4.33)
     @xmath   @xmath   @xmath      (4.34)
     @xmath   @xmath   @xmath      (4.35)
     @xmath   @xmath   @xmath      (4.36)
     @xmath   @xmath   @xmath      (4.37)
     @xmath   @xmath   @xmath      (4.38)
     @xmath   @xmath   @xmath      (4.39)
  -- -------- -------- -------- -- --------

In Sec. 4.4 we shall compute, among the other things, the
renormalization constant for the dimension zero symmetric traceless
operator @xmath , see Eq. ( 4.26 ). In order to obtain a
non-perturbative estimate, we shall consider its two-point function, and
apply an “OPE-inspired” procedure. The first step in this procedure
consists in computing perturbatively the OPE for two operators @xmath .
The structure of the OPE is the following

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

We computed this Wilson coefficient at three-loop order in perturbation
theory:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

### 4.3 Solution of the RG Equations

Solving the RG equations for the Wilson coefficients @xmath of the
dimension 2 symmetric traceless operators, see Eq. ( 4.25 ), deserves
some unexpected technical difficulty. We anticipated this difficulty,
namely a resonance in the RG equations, already in Sec. 2.7 . Here we
describe in detail how to proceed if such a case occurs. In fact, we did
not find any reference to this problem in textbooks. We study the
concrete example we encountered, and refer to [ 57 ] for a general
treatment of the subject.

The first step consists in choosing the most convenient basis of
operators. We shall adopt the basis of operators of definite spin @xmath
defined in Section 2.4.3 , see Eqs. ( 2.112 )–( 2.118 ). The
corresponding Wilson coefficients @xmath are easily computed using the
results of Section 4.2 , see Eqs. ( 4.32 )–( 4.39 ). In order to avoid
the complications due to the tensor structure of the Wilson
coefficients, we shall adopt the following convention. Among the
mentioned composite operators, @xmath , @xmath and @xmath have spin 2,
while @xmath , @xmath , @xmath and @xmath are Lorentz scalars. We give
to the last ones two Lorentz indices in the obvious way: @xmath for
@xmath . We can now write all the Wilson coefficients in the form @xmath
. Dropping the common factor @xmath , we get:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.42)
     @xmath   @xmath   @xmath      (4.43)
     @xmath   @xmath   @xmath      (4.44)
     @xmath   @xmath   @xmath      (4.45)
     @xmath   @xmath   @xmath      (4.46)
     @xmath   @xmath   @xmath      (4.47)
     @xmath   @xmath   @xmath      (4.48)
  -- -------- -------- -------- -- --------

The anomalous dimension matrix for the Wilson coefficients @xmath is
@xmath , where @xmath is given at two-loop order by Eqs. ( 2.122 )–(
LABEL:Gamma22g2 ). Because of the form ( 2.120 ) of @xmath , we obtain
the following structure for @xmath :

  -- -------- -- --------
     @xmath      (4.49)
  -- -------- -- --------

where we splitted the seven dimensional matrix as @xmath (in other words
@xmath is a @xmath matrix, while both @xmath and @xmath are @xmath ).

From Eq. ( 4.49 ) it follows that the Wilson coefficients @xmath ,
@xmath , and @xmath satisfy a “reduced” RG equation with anomalous
dimensions matrix @xmath . Recall that all the operators of our basis
except @xmath have vanishing matrix element between on-shell states of
equal momentum. As we shall see in the next Section, we focused on such
matrix elements in our numerical simulations. We can therefore limit
ourselves to considering the “reduced” RG equation for @xmath , @xmath ,
and @xmath .

We can further simplify the task, noticing that, while @xmath and @xmath
are spin 2 operators, @xmath is a scalar and thus renormalizes
multiplicatively. This observation was already made in Sec. 2.4.3 , see
Eq. ( 2.120 ). The computation of the RG improved Wilson coefficient for
@xmath is straightforward, and is accomplished along the lines of Sec.
2.7 . The final result for the renormalization group invariant Wilson
coefficient reads

  -- -------- -- --------
     @xmath      (4.50)
  -- -------- -- --------

Let us consider now the calculation of the Wilson coefficients of @xmath
and @xmath . It is convenient to write these two coefficients as a
column vector: @xmath @xmath @xmath . Since this vector satisfies a RG
equation, see Sec. 2.7 , we can write it as follows:

  -- -------- -- --------
     @xmath      (4.51)
  -- -------- -- --------

The @xmath matrix @xmath satisfies the equation:

  -- -------- -- --------
     @xmath      (4.52)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (4.53)
  -- -------- -- --------

We are interested in calculating @xmath . This can be done by solving
Eq. ( 4.52 ) for @xmath , and by using Eq. ( 4.51 ), where @xmath is
substituted by its perturbative expansion, see Eqs. ( 4.42 ) and ( 4.44
).

Thanks to the perturbative results presented in Sec. 2.4.3 , we can
write the first two terms of the asymptotic expansion @xmath :

  -- -- -- --------
           (4.54)
  -- -- -- --------

In Section 2.7 we wrote the solution of Eq. ( 4.52 ) as:

  -- -------- -- --------
     @xmath      (4.55)
  -- -------- -- --------

In computing @xmath the eigenvalues of @xmath are needed. In the case at
hand a simple calculation yields:

  -- -------- -- --------
     @xmath      (4.56)
  -- -------- -- --------

For @xmath , the solution of Eq. ( 4.52 ) admits indeed the asymptotic
expansion ( 4.55 ). The coefficients @xmath are obtained by plugging the
expansion ( 4.55 ) into Eq. ( 4.52 ) and matching the terms on the two
sides order-by-order in @xmath . The relevant formulae at one-loop order
have been given in Section 2.7 . In general we obtain the following
recursive equation for the coefficients @xmath :

  -- -------- -- --------
     @xmath      (4.57)
  -- -------- -- --------

This equation can be easily solved with respect to @xmath if we adopt
the basis which diagonalizes @xmath . Let us take @xmath , with @xmath .
In other words, @xmath is the change of basis which diagonalizes @xmath
, and @xmath , @xmath are the eigenvalues. In this basis we get

  -- -------- -- --------
     @xmath      (4.58)
  -- -------- -- --------

For @xmath the solution cannot be written in the form ( 4.55 ). The two
eigenvalues @xmath and @xmath differ by a non-zero integer, and Eq. (
4.58 ) becomes meaningless for @xmath (the denominator vanishes). The
novel feature of the correct solution is that it contains terms of the
type @xmath , rather than simply @xmath as prescribed by Eq. ( 4.55 ).
Since we carried out our simulations for the @xmath model, hereafter we
shall focus on the particular case @xmath .

Since the vanishing denominator appears in Eq. ( 4.58 ) only for @xmath
, we expect that one-loop calculations will not be affected by the
resonance. Nevertheless, it is instructive to proceed as in the general
case. The idea [ 57 ] is to transform Eq. ( 4.52 ) into an equivalent
one without a resonance. In the new equations we will have two
degenerate eigenvalues, rather than two eigenvalues differing by a
non-zero integer. The transformation is accomplished through appropriate
changes of variables (the so-called shearing transformations).

We start by writing the matrix @xmath as

  -- -------- -- --------
     @xmath      (4.59)
  -- -------- -- --------

with @xmath , and apply the following transformation

  -- -- -- --------
           (4.60)
  -- -- -- --------

The newly defined matrix @xmath satisfies the equation:

  -- -------- -- --------
     @xmath      (4.61)
  -- -------- -- --------

which looks quite similar to our starting point Eq. ( 4.52 ), but now
the resonance has disappeared. In fact

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.62)
     @xmath   @xmath   @xmath      (4.63)
  -- -------- -------- -------- -- --------

and, as promised, the two eigenvalues are now degenerate. The
“miraculous” matrix @xmath given in Eq. ( 4.60 ) can be constructed
through a step-by-step procedure described in [ 57 ] . Alternatively it
can be obtained by imposing the degeneracy of eigenvalues in the new
differential equation ( 4.61 ).

Notice that, since we know @xmath only to @xmath , see Eq. ( 4.54 ), we
cannot compute @xmath . Using in Eq. ( 4.63 ) the known values of @xmath
, see Eq. ( 4.54 ), we get @xmath .

The solution of Eq. ( 4.61 ) has the form

  -- -------- -- --------
     @xmath      (4.64)
  -- -------- -- --------

The coefficients @xmath can be computed by plugging this expression into
Eq. ( 4.61 ). Using the boundary condition @xmath we get

  -- -------- -- --------
     @xmath      (4.65)
  -- -------- -- --------

where we marked with a star ( @xmath ) the entries which cannot be
computed using our two-loop perturbative results, see Eq. ( 4.54 ).

The RG invariant Wilson coefficient @xmath is obtained by using Eq. (
4.51 ) and the perturbative prediction for @xmath , see Eqs. ( 4.42 )
and ( 4.44 ). The final result is (for greater convenience of the reader
we write here also the coefficient ( 4.50 ) for @xmath ):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.66)
     @xmath   @xmath   @xmath      (4.67)
     @xmath   @xmath   @xmath      (4.68)
  -- -------- -------- -------- -- --------

Notice that, as expected, the non-analytic term @xmath appears only in a
two-loop calculation. Moreover, this term is present only in the
coefficient @xmath .

### 4.4 Numerical Results

In this Chapter we shall face a more involved task than in the previous
one. We do not know the renormalized matrix elements on the right-hand
side of Eq. ( 4.1 ), and we would like to compute them using the OPE
method.

We shall proceed as follows:

1.  We compute numerically a matrix element of the type @xmath from
    properly chosen lattice correlation functions. This step yields a
    function @xmath .

2.  We compute the field-renormalization constant @xmath .

3.  We fit the function @xmath using the form @xmath and keeping the
    numbers @xmath as parameters of the fit. The function @xmath is an
    @xmath -loop truncation of the Wilson coefficient @xmath . We
    restrict the fit to the region @xmath , with @xmath . The outcomes
    of this step are the best fitting parameters @xmath together with an
    estimate of the statistical and systematic uncertainties.

4.  We look for some range of @xmath and @xmath (in the regime @xmath )
    such that @xmath remains constant within the above-mentioned
    uncertainties: @xmath .

5.  The @xmath matrix element of the renormalized operator @xmath is
    obtained by taking into account the renormalization of the bare
    lattice fields @xmath and @xmath : @xmath .

The above procedure is quite general. Let us now specify some of the
details. In step 3 we use a minimum-squares fit. As it stands, step 2 is
rather undefined and could be accomplished using different methods. The
calculation of @xmath will be the object of Sec. 4.4.4 . We shall use
once more the OPE. This will provide us with a further check of our
approach.

There is some ambiguity in choosing the perturbative truncation of the
Wilson coefficients in step 3 . We shall proceed as follows. We can
define a one-parameter family of running couplings @xmath , through the
following equation ³ ³ 3 The factor @xmath is introduced for future
convenience. We shall in fact write down the RGI Wilson coefficients for
@xmath . The factor @xmath avoids the proliferation of @xmath ’s in
these expressions.

  -- -------- -- --------
     @xmath      (4.69)
  -- -------- -- --------

where @xmath is defined as in Eq. ( 2.184 ). @xmath is a positive real
number which parametrizes the family of couplings. The solution of Eq. (
4.69 ) can be written as a series in inverse powers of @xmath . The
knowledge of the beta function at four-loop order [ 42 , 43 , 44 ]
allows us to write this series up to the order @xmath (cf. Eq. ( 2.187 )
for the first three terms of this expansion). This truncated series
defines the coupling @xmath . In the step 3 of our procedure we shall
use the RGI coefficients (see Sec. 2.7 ) expanded in terms of @xmath .
They have, in general, the form

  -- -------- -- --------
     @xmath      (4.70)
  -- -------- -- --------

Moreover, we shall substitute the coupling @xmath with its four-loop
approximation @xmath defined above. This completely specifies our
truncation of the Wilson coefficients for a given @xmath .

The perturbative coefficients @xmath depend upon @xmath . They can be
expressed, for a generic @xmath , in terms their values at @xmath . The
connection is obtained, up to three-loop order, using the following
formulae

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.71)
     @xmath   @xmath   @xmath            (4.72)
     @xmath   @xmath   @xmath            (4.73)
     @xmath   @xmath   @xmath            (4.74)
                                @xmath   
  -- -------- -------- -------- -------- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.75)
     @xmath   @xmath   @xmath      (4.76)
     @xmath   @xmath   @xmath      (4.77)
  -- -------- -------- -------- -- --------

The @xmath are the coefficients of the perturbative expansion of the
beta-function, see Eq. ( 2.10 ).

Notice that we use RGI Wilson coefficients. Therefore the outcomes of
the fit at step 3 will be the matrix element of RGI operators.

We defined a whole family of running couplings parametrized by @xmath .
Which value of @xmath do we choose? If we knew exactly the Wilson
coefficient @xmath and the beta function, then this choice would not
matter. By definition @xmath is independent of @xmath . However we must
truncate the beta function to four-loop order and, in most cases, @xmath
to two-loop order (for leading terms of the OPE), or one-loop order (for
next-to-leading terms). This introduces a dependence upon @xmath (mainly
because of the truncation of @xmath ). Clearly, we must take @xmath of
order one for avoiding “large logarithms”. In order to have a more
precise idea, we plot in Fig. 4.1 @xmath and @xmath for the Wilson
coefficients @xmath , @xmath , and @xmath . The perturbative expansions
for the Wilson coefficients are given in Eqs. ( 4.2 ), ( 4.2 ) and (
4.32 ). Their RGI counterparts are given by the general formulae of Sec.
2.7 . In all the cases considered in Fig. 4.1 , the coefficients @xmath
and @xmath attain their minimum absolute value around @xmath . This is a
rather natural choice. We shall compute our perturbative Wilson
coefficients (and, consequently, our estimates @xmath for the matrix
elements) using the running coupling defined by @xmath . In Tab. 4.1 we
give the numerical values (for @xmath and @xmath ) of the first few
perturbative coefficients @xmath corresponding to @xmath , @xmath , and
@xmath . This gives a feeling of the range of validity of perturbation
theory.

The above remarks suggest the following approach to the estimation of
the systematic uncertainty on @xmath . We shall repeat the calculation
of @xmath for @xmath varying in the range @xmath . This yields a @xmath
-dependent result @xmath . We estimate the systematic error with the
maximum deviation of @xmath from the value taken at @xmath .

Again, the choice of @xmath is rather arbitrary. In the following we
take @xmath . The consistency of this choice can be checked by
monitoring our estimates when the number of loops in the computation of
the Wilson coefficients is varied, see in particular Sec. 4.4.4 . A
further check is obtained by studying cases where an alternative
evaluation of the matrix element @xmath is available.

We conclude these introductory remarks by explaining some notations
which will be used in this Section. We shall attribute to any best
fitting parameter @xmath two types of errors: a systematic error (as
defined above) and a statistical one (one standard deviation). In order
to present both of them we shall use the following convention. When
writing a result we shall indicate in parentheses the statistical error,
and in brackets the systematic one. For instance @xmath means @xmath
with a statistical error of @xmath , and a systematic error of @xmath .
In the graphs we shall often indicate by a vertical bar the systematic
error, and by horizontal ticks on the bar the statistical one. We
finally notice that statistical errors will be typically smaller than
systematic ones.

#### 4.4.1 The Observables

Most of the simulations where done on the same lattices (A) , (B) and
(C) employed in the previous Chapter. We shall be mainly concerned with
the short-distance limit of (normalized) four-point functions. In order
to study their scaling behavior, we added two more lattices to the ones
already considered (also in these cases we use periodic boundary
conditions):

1.  Lattice of size @xmath with @xmath .

2.  Lattice of size @xmath with @xmath .

We used the same cluster algorithm as in the previous Chapter. In order
to obtain well decorrelated spin configurations, we evaluated the
observables every 15 or (for the majority of the observables considered)
30 updatings.

In all our simulations we evaluated the standard energy per link

  -- -------- -- --------
     @xmath      (4.78)
  -- -------- -- --------

for each generated configuration. This quantity can be used for
reweighting the Monte Carlo results at a different bare coupling.
Moreover in applying improved (“boosted”) perturbation theory, we shall
need the value of the improved coupling @xmath . We obtain the results
@xmath , @xmath , @xmath , respectively on lattices (A) , (B) , (C) ,
averaging over @xmath , @xmath , @xmath independent configurations. On
lattices (A’) and (C’) we obtained, respectively, @xmath and @xmath
using @xmath and @xmath configurations. The precision of these
computations can be easily increased but this is useless for our
purposes.

On lattices (A’) and (C’) we computed the “wall-to-wall” correlation
function @xmath , see Eq. ( 3.75 ) for momenta @xmath , @xmath , and
time separations @xmath on lattice (A’) and @xmath on lattice (C’). We
generated @xmath independent configurations on lattice (A’), and @xmath
independent configurations on lattice (C’).

Among the other things, we shall employ the OPE method for evaluating
the renormalized matrix element of the symmetric traceless operator
@xmath , see Eq. ( 4.26 ). In order to verify the result, we repeated
this calculation using a different method. We computed the lattice
matrix element and renormalized it in a successive step. In particular
we evaluated the three point function (obviously we averaged over
translations)

  -- -------- -- --------
     @xmath      (4.79)
  -- -------- -- --------

on lattices (A) , (B) and (C) for @xmath , @xmath . We used @xmath
configurations and @xmath on lattice (A) , @xmath configurations and
@xmath on lattice (B) , @xmath configurations and @xmath on lattice (C)
. The corresponding normalized function @xmath is defined analogously to
Eq. ( 3.78 )

One possible approach to the computation of the renormalization constant
@xmath for a lattice operator @xmath , consists in applying the OPE
method to the corresponding two point function. We applied this strategy
to the elementary field ( @xmath ), and to the symmetric traceless
operator of dimension zero ( @xmath ). We evaluated numerically the
corresponding two-point functions:

  -- -------- -- --------
     @xmath      (4.80)
  -- -------- -- --------

We evaluated @xmath ( @xmath ) from @xmath ( @xmath resp.) independent
configurations on lattice (A) , @xmath ( @xmath resp.) configurations on
lattice (B) , and @xmath ( @xmath resp.) configurations on lattice (C) .
For @xmath ( @xmath ) we considered @xmath , @xmath , @xmath ( @xmath ,
@xmath , @xmath resp.) on lattices (A) , (B) and (C) .

In order to study the OPE of the product of two fields, we considered
the following four-point correlation functions:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.81)
     @xmath   @xmath   @xmath      (4.82)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

We computed the above functions in Monte Carlo simulations as follows:

-   @xmath using @xmath configurations on lattice (A) , @xmath on
    lattice (B) and @xmath on lattice (C) .

-   @xmath using @xmath configurations on lattice (A) , @xmath
    configurations on lattice (B) , and @xmath configurations on lattice
    (C) and .

-   @xmath using @xmath independent configurations on lattice (A) ,
    @xmath configurations on lattice (B) , @xmath configurations on
    lattice (C) . In order to verify the relevance of scaling
    corrections we computed the same function also on lattices (A’) (
    @xmath ) and (C’) ( @xmath ).

In all the cases we consider @xmath with @xmath . Moreover @xmath and
@xmath on lattice (A) , @xmath and @xmath on lattice (B) @xmath and
@xmath on lattice (C) . Analogously to what is done in the previous
Chapter, see Eq. ( 3.81 ), we define the normalized functions @xmath
with @xmath , which have a finite limit for @xmath .

#### 4.4.2 One-Particle States

The one-particle spectrum @xmath and the field normalization @xmath have
been extracted from @xmath on lattices (A’) and (C’) as explained in
Sec. 3.3.2 . For the relevant definitions see Eq. ( 3.85 ). The results
of this computation are shown in Tab. 4.2 . We verified that the
effective quantities @xmath and @xmath do not depend upon @xmath for
@xmath . The values reported in Tab. 4.2 correspond to @xmath
respectively on lattices (A’) and (C’).

In order to estimate the systematic error due to the fact that we use a
finite value of @xmath we fitted @xmath and @xmath , taking into account
the first correction to the @xmath behavior. The procedure has been
explained in the previous Chapter, see Sec. 3.3.2 . The fitting form was
of the type ( 3.90 ). The results of this fit are shown in Fig. 4.2 .
The corresponding estimates for the systematic errors on the values of
@xmath quoted in Tab. 4.2 are about @xmath , on both lattices (A’) and
(C’). In general we verified the systematic error to be of the same
order as (or smaller than) the statistical one.

The exponential correlation length @xmath obtained from the data of Tab.
4.2 is

  -- -------- -- --------
     @xmath      (4.84)
  -- -------- -- --------

respectively for lattices (A’) and (C’). Notice that @xmath and @xmath
with deviations of (relative) order @xmath . Comparing the numerical
results obtained on these three lattices, we can carefully verify the
scaling of correlation functions.

#### 4.4.3 Corrections to Scaling

Let us consider the normalized functions @xmath , where the on-shell
limit @xmath has been taken. We expect the quantity

  -- -------- -- --------
     @xmath      (4.85)
  -- -------- -- --------

to have a finite continuum limit, i.e. @xmath with @xmath , @xmath ,
@xmath and @xmath fixed. This limit is approached with @xmath
corrections [ 103 , 104 , 105 ] . Renormalization group implies the
following scaling form in the continuum limit:

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- --------
     @xmath      (4.87)
  -- -------- -- --------

Let us now fix @xmath and @xmath in such a way that @xmath is kept
fixed. From Eq. ( LABEL:ScalingForm ), and using the fact that @xmath in
the continuum limit, we get:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.88)
     @xmath   @xmath   @xmath      (4.89)
  -- -------- -------- -------- -- --------

The r.h.s. of Eq. ( 4.88 ) is independent of @xmath , @xmath , @xmath ,
@xmath , and even of the particular ( @xmath ) correlation function, up
to @xmath lattice artifacts. Since we adopted lattice regularization,
Eq. ( 4.88 ) is meaningful for some @xmath only if @xmath is a rational
number ⁴ ⁴ 4 For a generic value of @xmath we can give a meaning to Eq.
( 4.88 ) as follows. Let us, for sake of simplicity, drop all the
indices and arguments but the space-time ones, and consider the lattice
function @xmath , with @xmath . Let us consider a “smooth” test function
@xmath on @xmath , and form the “scalar product” @xmath , @xmath being
the lattice spacing. The ratio on the l.h.s. of Eq. ( 4.88 ) can be
substituted, for a generic @xmath , by @xmath . However, in the
following we shall not pursue this strategy. .

Let us now turn to the numerical results, which are shown in Fig. 4.3 .
We considered the ratio on the l.h.s. of Eq. ( 4.88 ) for @xmath and
@xmath . In the left column we use lattices (A’) and (B) (i.e. @xmath
and @xmath ); in the right column lattices (B) and (C’) (i.e. @xmath and
@xmath ). We used @xmath , @xmath . In Eq. ( 4.88 ) we have to
extrapolate the normalized correlation function @xmath for @xmath . We
verified that the ratio on the left-hand side of Eq. ( 4.88 ) does not
depend upon the chosen value of @xmath among the ones for which @xmath
was computed, see Sec. 4.4.1 . The data presented refer to @xmath
respectively for lattices (A’), (B) , (C’). In Fig. 4.3 we plot our
numerical results for the ratio ( 4.88 ) along the directions @xmath and
@xmath .

The plots obtained with lattices (B) and (C’) (right column) show clear
evidence of scaling at error bars level (about @xmath depending upon the
chosen @xmath and @xmath ) as soon as @xmath . From Eq. ( 4.88 ),
neglecting corrections to scaling we obtain the estimate @xmath .
Four-loop (three-loop, two-loop) lattice perturbation theory yields
@xmath ( @xmath , @xmath ). Improved perturbation theory yields @xmath (
@xmath , @xmath ).

Lattices (A’) (B) (Fig. 4.3 left column) show approximate scaling for
@xmath . The horizontal lines would imply @xmath (we report the
statistical error which is roughly independent of the particular @xmath
point, rather than the systematic error due to scaling corrections).
Four-loop (three-loop, two-loop) lattice perturbation theory yields
@xmath ( @xmath , @xmath ). With improved perturbation theory we get
@xmath ( @xmath , @xmath ). Small scaling corrections could be suggested
by the points around @xmath or @xmath . This discrepancies are not
completely significant from a statistical point of view (about @xmath ,
while statistical errors are approximatively @xmath ).

Moreover, we remark that lattice perturbation theory gives unexpectedly
good estimates for the constant @xmath on lattices (B) -(C’). This is
probably due to the fact that @xmath is finite (indeed @xmath ) in the
continuum limit ( @xmath at @xmath fixed).

Notice that both using lattices (A’) and (B) , and using lattices (B)
and (C’), the relation @xmath is not exactly satisfied, the discrepancy
being of order @xmath . In order to check whether our conclusion could
be changed by a better tuning of the bare lattice couplings, we
reweighted our numerical data on lattice (A’) at @xmath . At this
coupling we get @xmath . The results for the scaling ratio ( 4.88 )
cannot be distinguished from the ones shown in Fig. 4.3 .

In the following Subsections we shall use the OPE method for computing
renormalization constants and renormalized matrix elements from lattice
data. The results of the present Subsection give us a rough idea of the
relevance of lattice artifacts in these computations. As soon as we
avoid products of lattice fields at coincident points, we expect these
errors to be about @xmath on lattice (A) , and to be compatible with
statistical uncertainties on lattices (B) and (C) . We shall see that
these effects are negligible with respect to other sources of error (in
particular the systematic error due to the perturbative truncation of
the Wilson coefficients). As explained at the beginning of this Section,
we shall put a short distance cutoff @xmath on our fitting region (i.e.
we take @xmath ). In order to avoid fields products at coincident
points, we shall always consider @xmath . Varying @xmath (in particular
we considered @xmath and @xmath , keeping @xmath fixed) does not change
much the results of the fits. These small changes (always much smaller
than estimated systematic errors) can be ascribed to asymptotic scaling
corrections, rather than to scaling corrections. In particular,
increasing @xmath produce an effect of the same sign as increasing
@xmath .

Motivated by this discussion, we shall present, in the following
Subsections, the results obtained fixing @xmath .

#### 4.4.4 Field-Renormalization Constant

We can apply the OPE approach to the computation of the
field-renormalization constant. The method can be easily extended to any
other composite operator @xmath . In Sec. 4.4.6 we shall apply it to the
symmetric traceless operator @xmath , see Eq. ( 4.26 ). The idea is to
compute numerically a short distance product of the type

  -- -------- -- --------
     @xmath      (4.90)
  -- -------- -- --------

such that the matrix element on the right-hand side is known. Enforcing
the validity of the OPE allows to compute the renormalization constant
of @xmath .

In this Subsection we want to compute the field-renormalization constant
@xmath . We will apply the method described above with @xmath . The
simplest choice is to consider the two-point function. This is
equivalent to choosing the states @xmath and @xmath in Eq. ( 4.90 ) to
be the vacuum state. From Eq. ( 4.23 ) we obtain

  -- -------- --
     @xmath   
  -- -------- --

where we used Eq. ( 2.69 ) to express the vacuum expectation value of
the energy-momentum tensor in terms of @xmath , and Eq. ( 2.66 ) to
eliminate the non-invariant operator @xmath . The RGI Wilson
coefficients are obtained from Eqs. ( 4.2 )–( 4.30 ) using the formulae
of Sec. 2.7 :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.92)
                                @xmath   
                                @xmath   
     @xmath   @xmath   @xmath            (4.93)
  -- -------- -------- -------- -------- --------

The lattice fields renormalize as follows, see Sec. 2.5 ,

  -- -------- -- --------
     @xmath      (4.94)
  -- -------- -- --------

where we emphasized the dependence of @xmath upon @xmath and @xmath ,
i.e., in more physical terms, upon @xmath and @xmath . This dependence
can be predicted using RG. In fact the following equations hold:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.95)
     @xmath   @xmath   @xmath      (4.96)
  -- -------- -------- -------- -- --------

These are simply the definitions of the continuum and lattice anomalous
dimensions @xmath and @xmath . The general solution of the above
equations reads

  -- -------- --
     @xmath   
  -- -------- --

The constant @xmath is easily fixed. Noticing that @xmath and @xmath ,
we obtain

  -- -------- -- --------
     @xmath      (4.98)
  -- -------- -- --------

As in the rest of this Chapter we have different attitudes towards
different terms in Eq. ( LABEL:RGZfield ). The lattice factor @xmath can
be computed in perturbation theory. However, since lattice perturbation
theory is not well behaved, we are interested in computing it
non-perturbatively. The continuum factor @xmath can be computed in
perturbation theory too. In this case, we assume that we are interested
in an energy scale @xmath which is high enough for making the
perturbative calculation reliable (recall that @xmath as @xmath ).

Notice that adsorbing the continuum factor @xmath in the definition of
yields the (finite) RGI field operator @xmath . Motivated by the above
discussion, we shall compute the renormalization constant @xmath ,
defined by: @xmath . Its explicit RG expression is easily obtained from
Eq. ( LABEL:RGZfield ):

  -- -------- -- --------
     @xmath      (4.99)
  -- -------- -- --------

Being written in terms of RGI fields, Eq. ( LABEL:TwoPointOPE ) gives
access to @xmath . We use the following fitting form for the two point
function:

  -- -------- -- ---------
     @xmath      (4.100)
  -- -------- -- ---------

As always we restrict the fit to the region @xmath . The parameter
@xmath gives an estimate of @xmath . The parameter @xmath could be
called a “spin-wave” condensate. However we do not expect to be able to
determine the value of @xmath from it. In fact @xmath mixes with the
identity operator and the remarks of Sec. 4.1.2 apply to this case. We
should determine the Wilson coefficient @xmath up to terms of order
@xmath for Eq. ( LABEL:TwoPointOPE ) to define @xmath unambiguously.

For each case we repeated the fit with and without the power-correction
term @xmath . This gives a feeling of how good is the truncation of the
OPE in Eq. ( LABEL:TwoPointOPE ).

In Fig. 4.4 we present a scaling plot of Monte Carlo data for @xmath
together with the best fitting curves with and without power
corrections. For sake of clarity we plotted only the values of @xmath
obtained along the time direction @xmath , and along the diagonal @xmath
. We rescaled the data using the estimated values of @xmath , i.e.
@xmath , see Tab. 4.3 and discussion below. The data collapse on a
single curve showing a clear evidence of scaling. The dotted curve (no
power corrections) simply reports @xmath . In the continuous curve we
add the power correction @xmath , with @xmath and @xmath obtained on
lattice (C) .

In Fig. 4.5 we show the best fitting parameters @xmath and @xmath on
lattices (A) , (B) and (C) . In all the cases we kept @xmath fixed (this
excludes only the point @xmath from the fit), and we varied @xmath .
Statistical errors are negligible in these plots and we do not report
them.

The estimates @xmath are reported in frames (A’), (B’), (C’). These
graphs do not allow any reliable evaluation of the expectation value
@xmath . For @xmath systematic errors are of the same order as the
estimate itself. For @xmath systematic errors begin to shrink but @xmath
shows a strong @xmath dependence. Indeed @xmath seems to diverge as
@xmath . This can be easily understood if we assume that we are
effectively fitting higher loops (which go as @xmath as @xmath ) with a
term of the type @xmath .

In graphs (A), (B), (C) we report the results for @xmath . The estimates
obtained including the power-correction term in Eq. ( 4.100 ) show a
quite mild @xmath dependence and very small systematic errors which are
roughly @xmath -independent. These values of @xmath are not constant
within systematic error bars. The reason is probably that the fitting
parameter @xmath mimics the effects of higher loops in @xmath and
reduces the scheme dependence of the result. The estimates obtained
without power corrections show larger systematic errors and are flat
within the systematic error bars. Systematic errors ⁵ ⁵ 5 Notice that
relative systematic errors are approximatively independent of @xmath at
@xmath fixed. decrease as @xmath .

In the same graphs we reported the analogous estimates (obtained without
power corrections) with @xmath computed in one-loop and two-loop
perturbation theory. Our method to assess systematic errors seems to be
consistent. Finally the difference between the results for @xmath
obtained with or without power corrections are quite small.

We summarize our results for @xmath in Tab. 4.3 . The values of @xmath
correspond to @xmath at @xmath , @xmath , @xmath on lattices (A) , (B)
and (C) . In the third column we compute the constant @xmath , see Eq. (
LABEL:RGZfield ), using the relation

  -- -------- -- ---------
     @xmath      (4.101)
  -- -------- -- ---------

and four-loop (three-loop, two-loop) perturbation theory. In the last
column we repeat the same calculation using improved perturbation
theory. The results for @xmath seem to scale well (i.e. they are
approximatively @xmath -independent) for the lattices (B) and (C) . A
little discrepancy remains for lattice (A) . Nevertheless, even at four
loops, the outcome of bare perturbation theory is about @xmath away from
the correct value @xmath . Improved perturbation theory yields a better
agreement. For the largest lattice the discrepancy is about the @xmath ,
which is not too far from the estimated systematic error
(approximatively the @xmath ).

Let us now try to judge our determination of systematic errors and in
particular our choice of @xmath . We shall concentrate on lattice (C) ,
since it allows to investigate a larger range of distances. In Tab. 4.4
we report the results for @xmath and the corresponding systematic error
for several values of @xmath and @xmath . The fitting form ( 4.100 )
without power correction was adopted. The Wilson coefficient was
computed in three-loop, two-loop, and one-loop perturbation theory. If
we look at a fixed value of @xmath in this table it seems that
perturbation theory converges very well and that, fixing @xmath , we are
overestimating the systematic errors: @xmath could appear a more
realistic choice. However if we vary @xmath and consider the systematic
error obtained with @xmath we realize that @xmath is by no means flat.
We deduce that @xmath is not too cautious and gives a good (very rough)
idea of the systematic errors.

#### 4.4.5 Symmetric Operator

As we explained in Sec. 4.4.1 , we are interested in computing the
matrix elements of the bare lattice operator @xmath between one-particle
states. In order to accomplish this task, we considered the three-point
function @xmath defined in Eq. ( 4.79 ). The matrix element can be
extracted from the corresponding normalized function @xmath as follows:

  -- -------- -- ---------
     @xmath      (4.102)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (4.103)
  -- -------- -- ---------

The numerical results for @xmath are constant (within statistical
errors) for @xmath .

In Tab. we report the numerical estimates for @xmath obtained on
lattices (A) , (B) and (C) , respectively for @xmath ( @xmath for @xmath
), @xmath ( @xmath for @xmath ) and @xmath ( @xmath for @xmath ).

In order to verify the “contamination” due to higher states, we adopt
the same method we used in the computation of the one-particle spectrum,
see Sec. 3.3.2 . The expected behaviour of @xmath in the large @xmath
limit is

  -- -------- -- ---------
     @xmath      (4.104)
  -- -------- -- ---------

where we made the same approximations as for the spectrum, namely we
neglected terms of order @xmath , and multi-particle states involving
more than three particles. The gap @xmath is given by Eq. ( 3.89 ). In
the thermodynamic ( @xmath ) limit, the coefficients @xmath are slowly
varying (power-like) functions of @xmath . Analogously to what we did in
Sec. 3.3.2 , we shall neglect the @xmath -dependence of the coefficients
@xmath . We fitted our data using the form

  -- -------- -- ---------
     @xmath      (4.105)
  -- -------- -- ---------

In Fig. 4.6 we plot @xmath versus @xmath on lattices (A) and (C) for
@xmath , @xmath . The estimated systematic error on the results of Tab.
4.5 is about @xmath , @xmath , @xmath , @xmath , respectively for @xmath
.

Notice that, for kinematical reasons, in the continuum limit @xmath does
not depend upon @xmath . The results of Tab. 4.5 verify this prediction
within the statistical errors. The only statistically significant
discrepancy occurs at @xmath on lattice (A) . It is plausible to explain
this discrepancy as a scaling correction.

#### 4.4.6 Renormalization of the Symmetric Operator

Let us now come to the problem of renormalizing the lattice results
obtained in the previous Section. This is a necessary step in order to
check the results of Sec. 4.4.9 , where we shall adopt the OPE method to
compute the matrix elements of the renormalized operator @xmath , see
Eq. ( 4.26 ).

We have seen in Sec. 4.4.4 that improved (boosted) perturbation theory
yields the field-renormalization constant with @xmath of systematic
error on lattice (C) . Now we have to compute the renormalization
constant for the symmetric operator @xmath . We shall use perturbation
theory at first. Next, we shall switch to the OPE non-perturbative
method, see Sec. 4.4.4 , in order to have more reliable results. We
shall see that, in this case, lattice perturbation theory (even if
improved) does not give an approximation as good as it does for the
field-renormalization constant.

We proceed as in Sec. 4.4.4 . Let us consider an operator @xmath
renormalizing multiplicatively: @xmath . The corresponding RGI operator
@xmath is easily given in terms of its lattice counterpart: @xmath . RG
considerations yield:

  -- -------- -- ---------
     @xmath      (4.106)
  -- -------- -- ---------

where @xmath are the lattice anomalous dimensions of the operator @xmath
, see Sec. 2.6 .

In Tab. 4.6 we report the results for

  -- -------- -- ---------
     @xmath      (4.107)
  -- -------- -- ---------

obtained from the data of Tab. 4.5 using Eqs. ( 4.102 ) and ( 4.106 ).
The lattice anomalous dimensions are known in three-loop perturbation
theory [ 106 ] . The bare matrix element has been obtained from the
@xmath data at of Tab. 4.5 .

The renormalized matrix elements of Tab. 4.6 seem to scale quite well.
The results obtained with improved perturbation theory change by @xmath
when passing from lattice (B) to lattice (C) . They converge well when
the order of the perturbative calculation is increased from two to three
loops.

However, we would like to have a nonperturbative control over the
renormalization constant of @xmath . We shall consider the two-point
function of this operator and proceed as in Sec. 4.4.4 . We shall limit
ourselves to the first term of the OPE:

  -- -------- -- ---------
     @xmath      (4.108)
  -- -------- -- ---------

Using the perturbative result of Eq. ( 4.2 ), and the general formulae
of Sec. 2.7 , we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Let us recall our notation for the renormalization constants, focusing
on the case at hand:

  -- -- -- ---------
           (4.110)
  -- -- -- ---------

Equations ( 4.108 ) and ( 4.110 ) motivate the following fitting form
for the isotensor correlation function, see Eq. ( 4.80 ):

  -- -------- -- ---------
     @xmath      (4.111)
  -- -------- -- ---------

The fitting parameter @xmath gives an estimate of @xmath . As in the
other cases we use a fitting window @xmath to extract the best fitting
parameter @xmath .

In Fig. 4.7 we show our Monte Carlo data for @xmath in a scaling plot.
The numerical results for @xmath have been rescaled using the estimated
renormalization constant @xmath , see Tab. 4.7 and discussion below. For
sake of clarity we limit ourselves to showing the results obtained along
the directions @xmath and @xmath . Scaling is well verified on the three
lattices. The continuous line corresponds to the leading OPE prediction
@xmath , with @xmath .

In Fig. 4.8 we show the @xmath dependence of the best fitting parameter
@xmath on lattices (A) , (B) and (C) . As in Sec. 4.4.4 , we kept @xmath
constant. In all the cases examined, the estimates @xmath are flat
within the systematic error bars as soon as @xmath . Notice that the
estimated systematic errors on @xmath are larger than in Sec. 4.4.4 .
This is not unexpected. In fact, in the present case, the Wilson
coefficient is more strongly varying: as @xmath , @xmath , while @xmath
(these formulae hold for @xmath ). As a consequence, the parameter
@xmath is more strongly dependent upon the perturbative truncation than
its counterpart @xmath .

In Tab. 4.7 we present our results for @xmath , and the corresponding
renormalized matrix elements for the symmetric operator, see Eq. ( 4.107
). The values of @xmath correspond to @xmath at @xmath , @xmath , and
@xmath , respectively on lattices (A) , (B) and (C) . The renormalized
matrix elements @xmath are obtained computing the renormalization
constant from @xmath , and using the bare lattice matrix elements of
Tab. 4.5 , @xmath . These results scale, i.e. they are @xmath
independent, within systematic errors. Systematic errors get reduced as
the lattice becomes finer. They are about the @xmath on lattice (C) .

The results of Tab. 4.7 should be compared with the ones of Tab. 4.6 (we
refer here to improved perturbation theory, i.e. to the rightmost
column). In both cases we present the matrix element @xmath , defined in
Eq. ( 4.107 ), and we use the bare lattice data of Tab. 4.5 , obtained
at @xmath . The only difference consists in the estimate of the
renormalization constant. In both cases, looking at the two larger
lattices, (B) and (C) , the values of @xmath show scaling (i.e. they are
independent of @xmath ) at percent level. There is, however, a
discrepancy between the determinations of Tab. 4.6 and of Tab. 4.7 .
This discrepancy is about the @xmath on lattice (C) , and is not
compatible with the systematic error of the OPE method.

A @xmath disagreement between improved perturbation theory and
non-perturbative results is not unfrequent at these correlation lengths,
see for instance Refs. [ 62 , 87 , 65 ] . Moreover the results of Tab.
4.7 agree with the ones obtained by applying the OPE method to the
computation of the matrix element, see Sec. 4.4.9 and Tab. 4.10 . This
provides a strong check of the whole approach.

#### 4.4.7 OPE in the Scalar Sector

In this Subsection we study the short-distance product of two elementary
fields in the @xmath -scalar sector.

As a preliminary step, we rewrite the general form of the OPE, see Eq. (
4.23 ), with two changes: we use RGI operators instead of @xmath ones;
we use operators with definite spin. Moreover,we focus on the @xmath
limit of on-shell matrix elements. Using Eq. ( 2.69 ) for the trace of
the energy-momentum tensor, we get (neglecting terms of order @xmath ):

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where @xmath is the traceless energy-momentum tensor:

  -- -------- -- ---------
     @xmath      (4.113)
  -- -------- -- ---------

The expressions for @xmath and @xmath have been already given in Sec.
4.4.4 , see Eqs. ( 4.92 ) and ( 4.93 ). The last Wilson coefficient is
easily obtained from Eq. ( 4.28 ):

  -- -------- -- ---------
     @xmath      (4.114)
  -- -------- -- ---------

We shall consider one-particle matrix elements of Eq. ( 4.4.7 ).
Space-time symmetries impose several constraints on the matrix elements
of the operators on the right-hand side. This yields a further check of
our calculation. We adopt the following parametrization:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (4.115)
     @xmath   @xmath   @xmath      (4.116)
  -- -------- -------- -------- -- ---------

where @xmath and @xmath . Because of kinematical considerations both
@xmath and @xmath do not depend upon @xmath . Moreover,invariance under
space and time inversions implies that @xmath and @xmath are both real.
Finally, e know the exact value of the expectation value of the
energy-momentum tensor. Recalling the normalization ( 3.83 ) for
one-particle states, we get @xmath .

Let us make a few elementary remarks concerning the status of the
different terms appearing in Eq. ( 4.4.7 ). The operator @xmath has spin
0 and dimension 2. In the context of deep-inelastic scattering it would
be called a ‘‘higher twist’’ ⁶ ⁶ 6 Recall the definition twist =
dimension - spin. . It mixes under renormalization with the identity
operator. The Lorentz structure of the corresponding Wilson coefficients
is the same: they are rotationally invariant. The remarks of Sec. 4.1.2
apply to this case. The matrix elements of @xmath cannot be determined
from the expansion ( 4.4.7 ) unless we fix the coefficient @xmath up to
@xmath . As a consequence, we do not expect to be able to compute the
matrix elements of @xmath , i.e. the parameter @xmath , see Eq. ( 4.116
), with our method ⁷ ⁷ 7 Notice, however, that the @xmath matrix
elements of the identity operator and of @xmath have a different scaling
with respect to the external momentum @xmath . In the continuum limit,
on a strip of spatial extent @xmath , we know that @xmath , while @xmath
is @xmath -independent. This gives a clue to distinguish the two
contributions. We shall not pursue this strategy in this Section, since
it would require a statistical accuracy beyond the one of our Monte
Carlo data. .

The traceless energy-momentum tensor @xmath is instead a leading twist
(spin 2, dimension 2) and can be determined from the expansion ( 4.4.7
), although it is only a power correction. We could, for instance,
consider the quantity:

  -- -------- -- ---------
     @xmath      (4.117)
  -- -------- -- ---------

From Eq. ( 4.4.7 ), it is easy to derive the following OPE:

  -- -------- -- ---------
     @xmath      (4.118)
  -- -------- -- ---------

where @xmath appears as the leading contribution. In this particular
case, however, we can use a more direct approach. Since the leading term
of the expansion ( 4.4.7 ) is proportional to the identity operator, it
cancels when considering connected correlation functions. In particular
we could consider, see Eq. ( 4.81 ),

  -- -------- -- ---------
     @xmath      (4.119)
  -- -------- -- ---------

From Eq. ( 4.4.7 ), it follows that @xmath is of order @xmath as @xmath
(here @xmath ). Nevertheless, in the following we shall study the whole
OPE ( 4.4.7 ), without eliminating the leading contribution.

The one-particle matrix elements of the product on the l.h.s. of Eq. (
4.4.7 ) can be obtained from the function @xmath , see Eq. ( 4.81 ).
Indeed we know that

  -- -------- -- ---------
     @xmath      (4.120)
  -- -------- -- ---------

We computed @xmath for different values of @xmath (with @xmath , see
Sec. 4.4.1 ) and verified it to be independent of @xmath in that range.
This is compatible with the findings of Secs. 4.4.2 and 4.4.5 : the
on-shell limit for one-particle states is reached, with a good
approximation, at time separations @xmath . We evaluated the limit on
the r.h.s. of Eq. ( 4.120 ) using the lowest value of @xmath in the
range considered in our Monte Carlo calculations. In particular we use
@xmath on lattice (A) , @xmath on lattice (B) and @xmath on lattice (C)
. The same procedure will be applied in the next Sections. In Fig. 4.9
we compare the numerical results obtained in this manner with the OPE
fit.

The parametrization in Eqs. ( 4.115 ), ( 4.116 ), and the OPE ( 4.4.7 )
imply the following fitting form:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

The renormalized parameters @xmath and @xmath are related to their
unrenormalized counterparts @xmath and @xmath through the
renormalization of the fields @xmath on te l.h.s. of Eq. ( 4.4.7 ). In
particular we can estimate @xmath and @xmath using, respectively, @xmath
and @xmath . The parameter @xmath give access to the
field-renormalization constant @xmath , analogously to the parameter
@xmath in Sec. 4.4.4 .

In Fig. 4.9 we plot @xmath on lattice (A) ( @xmath ), (B) ( @xmath ) and
(C) ( @xmath ), versus the separation between @xmath and @xmath in
physical units: @xmath . This function should have a finite @xmath limit
(at @xmath fixed). We used the values of @xmath estimated with the OPE
method in Sec. 4.4.4 , see Tab. 4.3 , second column, and the results for
@xmath of the previous Chapter, see Eq. ( 3.76 ). The results obtained
on lattices (A) , (B) and (C) collapse except for @xmath , as expected.
This fact indicates that we are in the scaling regime.

The best fitting curves shown in Fig. 4.9 have been obtained on lattice
(C) . We used a fitting window @xmath , with @xmath and @xmath . The fit
is quite good for @xmath . We used the fitting form ( 4.4.7 ) both with
@xmath , @xmath , @xmath free, and with @xmath free and @xmath (i.e. in
this case we kept only the leading term of Eq. ( 4.4.7 )). The
difference between the two fitting procedure is hardly visible. The
reason is that the first term in Eq. ( 4.4.7 ) is of order @xmath with
respect to the other ones in the thermodynamic limit ( @xmath at fixed
@xmath ).

In Figs. 4.10 and 4.11 we study the dependence of the fit parameters
upon @xmath . Our aim is to understand whether a window for asymptotic
scaling exists. We plot the best fitting values obtained with @xmath
together with the statistical and systematic uncertainties. For sake of
clarity we limit ourselves to showing the results obtained with @xmath
(the results for @xmath have larger statistical errors). In graphs (A),
(B), (C) we used the fitting form ( 4.100 ) including power corrections.
In (A’) we kept only the leading term of Eq. ( 4.100 ), i.e. @xmath .

The remarks formulated in Sec. 4.4.4 can be repeated here. Statistical
errors on our numerical data are, also in this case, quite small.
Systematic errors on the leading operator are strongly reduced if
power-correction terms are included in the fitting form. Nevertheless,
as we already discussed in Sec. 4.4.4 , this is a somewhat “spurious”
effect.

#### 4.4.8 OPE in the Antisymmetric Sector

We consider now the antisymmetric product of two elementary fields at
short distances.

We start by rewriting the form of the OPE in terms of RGI operators, cf.
Eq. ( 4.24 ):

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (4.122)
  -- -------- -------- -------- -- ---------

where we neglected @xmath terms. Notice that the Noether current @xmath
is RGI (this happens for any regularization and any renormalization
scheme). As a consequence we did not add any subscript to it. The Wilson
coefficient is easily obtained from Eq. ( 4.2 ) using the formulae of
Sec. 2.7 :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Before continuing we remark that the @xmath symmetry fixes the
normalization of the Noether current. This can be seen by considering
the @xmath charges @xmath , and requiring that @xmath generates the
@xmath transformations:

  -- -------- -- ---------
     @xmath      (4.124)
  -- -------- -- ---------

Using Lorentz invariance and the above condition we have:

  -- -------- -- ---------
     @xmath      (4.125)
  -- -------- -- ---------

This identity allows a tight check of the expansion ( 4.122 ).

The OPE ( 4.122 ) is quite different from the other examples studied in
this Chapter. Since there exists no dimension-zero antisymmetric
operator, the leading term is of order @xmath . In the other cases we
have a much weaker @xmath dependence: @xmath .

The one-particle matrix elements have been extracted as explained in the
previous Subsection, see Eq. ( 4.120 ). We rewrite here the relevant
equation in order to specify the correct normalization

  -- -------- -- ---------
     @xmath      (4.126)
  -- -------- -- ---------

In Fig. 4.12 we show the numerical results for the @xmath matrix
elements. We plot the function @xmath along the directions @xmath and
@xmath . In this case a plot along the direction @xmath would be
trivial, since @xmath . The non-perturbative results of Sec. 4.4.4 , see
Tab. 4.3 , have been used to estimate @xmath .

The OPE ( 4.122 ) and the identity ( 4.125 ) imply the following fitting
form

  -- -------- -- ---------
     @xmath      (4.127)
  -- -------- -- ---------

where @xmath is an estimate of the field-renormalization constant
(analogously to @xmath in Sec. 4.4.4 , and @xmath in Sec. 4.4.7 ). In
Fig. 4.12 we show the best fitting curves of the form ( 4.127 ), as
determined on lattice (C) . We used a fitting window @xmath with @xmath
and @xmath . The collapse of the data obtained on different lattices
indicates that scaling is well verified by our numerical results for
@xmath . Moreover, the fitting curves are in good agreement with
numerical data up to @xmath .

In Fig. 4.13 we study the @xmath dependence of the best fitting
parameter @xmath , keeping @xmath fixed. In graphs (A) and (B) we
present the results obtained with the one-loop Wilson coefficient, which
is given by dropping out the @xmath term in Eq. (
LABEL:WilsonAntiSymmetric ). In graphs (A’) and (B’) we use the two-loop
Wilson coefficient ( LABEL:WilsonAntiSymmetric ). The continuous lines
refer to the field renormalization constant as computed in Sec. 4.4.4 .

One-loop results, i.e. graphs (A) and (B), are almost flat within the
systematic errors and agree with the prediction of Sec. 4.4.4 for the
field-renormalization constant. Our estimate of the systematic errors
seems to be quite good in this case.

Two-loop results, i.e. graphs (A’) and (B’) do not differ much from
their one-loop counterparts, as far as the central value for @xmath
(corresponding to @xmath ) is concerned. However systematic errors are
greatly reduced. They are much smaller than systematic errors obtained
in the scalar or symmetric sectors with the same number of loops, at the
same values of @xmath . As a consequence the two-loop results for @xmath
are no longer flat. Looking at Fig. 4.13 , graphs (A’) and (B’), we
cannot find any “scaling window”. Nevertheless, for small @xmath ,
@xmath seems to converge to the field-renormalization constant computed
in Sec. 4.4.4 . In Tab. 4.8 we report the values of @xmath obtained with
@xmath on lattices (A) and (B) , and @xmath on lattice (C) .

The discrepancy at larger values of @xmath can be attributed either to
an imperfect evaluation of systematic errors (an unlucky numerical
coincidence which makes them so small in this case), or to
power-correction effects. In order to better understand the problem, we
tried to fit the numerical data using the following “phenomenological”
form:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.128)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

This fitting form is obtained as follows. We write down the @xmath terms
of the OPE ( 4.122 ), and single out the Lorentz structure of the Wilson
coefficients. The “reduced” Wilson coefficients depend logarithmically
upon @xmath and are rotationally invariant. We make the crude
approximation of neglecting this logarithmic @xmath dependence. Next, we
single out the @xmath dependence of the @xmath matrix elements of the
composite operators of dimension 3. The @xmath dependence can be easily
deduced by using the space-time symmetries. It depends uniquely upon the
spin of the composite operator. The result of this procedure has the
form 4.128 .

The functions multiplying @xmath and @xmath have the same dimension and
Lorentz structure as the Wilson coefficients of the next-to-leading
terms in the OPE ( 4.122 ). The parameters @xmath and @xmath correspond,
respectively, to dimension 3, spin 3 operators, and to dimension 3, spin
1 operators.

Equation ( 4.128 ) can be considered, for what concerns power
corrections, as a “naive” (i.e. not RG improved) tree-level
approximation. Since power corrections in Eq. ( 4.128 ) do not have the
correct @xmath limit, the parameters @xmath and @xmath do not give
access to well-defined matrix elements. Anyway, by adopting the fitting
form ( 4.128 ), we gain some insight into the role of power corrections
for the determination of @xmath .

The results obtained on lattice (C) are shown in Fig. 4.14 . Notice that
@xmath is much flatter than in Fig. 4.14 . The estimation at small
@xmath does not change much and is compatible with the one of Sec. 4.4.4
. For instance at @xmath on lattice (C) we get @xmath (here we quote the
result at @xmath ), cf. Tab. 4.8 .

#### 4.4.9 OPE in the Symmetric Sector

Our last example concerns the symmetric traceless product of two
elementary fields at short distances.

We shall keep track of the @xmath power corrections in the OPE. As a
consequence, we must take care of the non-trivial mixing between
dimension-2 symmetric traceless operators, see Sec. 2.3.3 . For this
task, it is convenient to adopt the basis of operators with definite
spin, see Eqs. ( 2.112 )–( 2.118 ).

For sake of clarity we shall restrict ourselves to the case of on-shell
external states of equal total momentum. This allows two
simplifications. We can eliminate the operators @xmath and @xmath since
they vanish on shell, see Eqs. ( 2.90 ) and ( 2.90 ). We can eliminate
@xmath and @xmath , which are total space-time derivatives. With these
assumptions we get from Eq. ( 4.25 )

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.129)
                                @xmath   
  -- -------- -------- -------- -------- ---------

where we used, once more, renormalization-group invariant operators. The
coefficients @xmath for @xmath are given in Eqs. ( 4.66 )-( 4.68 ) for
@xmath . The coefficient of the leading term can be calculated from Eq.
( 4.32 ):

  -- -------- -- ---------
     @xmath      (4.130)
  -- -------- -- ---------

We shall be interested in the @xmath matrix elements of Eq. ( 4.129 ).
Analogously to Sec. 4.4.7 , space-time symmetries constrain the matrix
elements of the composite operators on the right-hand side of Eq. (
4.129 ). Here we adopt the following parametrization:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (4.131)
     @xmath   @xmath   @xmath      (4.132)
     @xmath   @xmath   @xmath      (4.133)
     @xmath   @xmath   @xmath      (4.134)
  -- -------- -------- -------- -- ---------

The parameters @xmath are real numbers and do not depend upon the
external momentum @xmath .

Let us make some remarks concerning the expansion ( 4.129 ). The
operator @xmath is a higher-twist operator and mixes under
renormalization with the dimension-zero operator @xmath . The warnings
expressed in Sec. 4.1.2 apply also to this case ⁸ ⁸ 8 In the analogous
case of @xmath , see Sec. 4.4.7 , it was possible to single out (at
least in theory) the higher-twist contribution by looking at the @xmath
dependence, cf. footnote 7 on page 7 . In the present case no analogous
trick is available. .

Let us now consider the operators @xmath and @xmath . Since their
canonical dimension is equal to their spin (dimension @xmath spin @xmath
), they are leading twists. As a consequence, they can be determined
unambiguously from the expansion ( 4.129 ). This can be done analogously
to what we explained in Sec. 4.4.7 for @xmath , cf. Eq. ( 4.117 ).

There is, however, a practical difficulty in the determination of @xmath
and @xmath . For sake of clarity we refer to the case @xmath . In this
case @xmath (which is of order @xmath ) is strongly suppressed with
respect to @xmath (of order 1). In order to disentangle the two
contributions in Eq. ( 4.129 ), we should compute @xmath at least to
order @xmath . Since we have computed @xmath and @xmath to one-loop
order, we do not expect to obtain a good determination of @xmath . The
best fitting @xmath (see Eq. ( 4.133 )) will mimic the higher-loop
contributions in @xmath .

This difficulty is however quite different from the one described in
Sec. 4.1.2 . In the present case it would be “sufficient” to push
forward the perturbative calculation of @xmath , and to perform
numerical simulations at large enough correlation lengths, in order to
solve the problem.

One-particle matrix elements have been extracted from the function
@xmath as explained in Secs. 4.4.7 and 4.4.8 . The relation between
one-particle matrix elements and the @xmath limit of @xmath is given by:

  -- -------- --
     @xmath   
  -- -------- --

In Fig. 4.15 we present the results of this computation. We plot the
function @xmath along the directions @xmath and @xmath . We used the
non-perturbative estimates of @xmath given in Sec. 4.4.4 , see Tab. 4.3
. Together with the numerical data we show the best fitting curves. The
form of the fit is easily obtained from Eqs. ( 4.129 ) and ( 4.131 )–(
4.134 ):

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

The curves in Fig. 4.15 are the best fitting curves obtained on lattice
(C) . For these curves we use a fitting window @xmath , with @xmath and
@xmath . As usual we try two types of fit: with (continuous line) and
without (dashed line) power corrections.

The fitting form which includes power corrections (i.e. the parameters
@xmath , @xmath , @xmath , see Eq. ( 4.4.9 )) describes very well the
numerical data for @xmath . At distances @xmath we expect both the OPE
and the perturbative expansion to break down.

The fit without power corrections (which amounts to dropping the
parameters @xmath , @xmath and @xmath in Eq. ( 4.4.9 )) correctly
captures the small- @xmath behaviour of @xmath @xmath . The deviations
from the numerical data become quite large as soon as @xmath and depend
upon the direction. These deviations are mainly due to spin @xmath
operators in the OPE ( 4.129 ). Such terms are effectively averaged out
when considering a rotationally invariant fitting form (like the one
without power corrections). As a consequence the best fitting value of
@xmath does not change very much whether or not power correction terms
are included in the fitting form.

In Figs. 4.16 and 4.17 we report the best fitting parameters as a
function of the fitting window @xmath . We keep @xmath fixed and vary
@xmath . The kinematic scaling (independence of the parameters upon
@xmath ) is verified within the statistical error. The only exception is
given by parameter @xmath on lattice (A) . However this effect is very
small (about the @xmath ) and can be ascribed to scaling corrections ⁹ ⁹
9 Notice that neither higher-order power corrections, e.g., @xmath
terms, nor the approximate knowledge of the Wilson coefficients can be
the cause of this effect. .

In the majority of the cases, statistical errors on the fitting
parameters are by far smaller than systematic ones. There are some
exceptions to this rule. Consider for instance parameters @xmath and
@xmath on lattices (B) and (C) , see Figs. 4.16 and 4.17 , graphs (B)
and (C). As @xmath statistical errors become larger than systematic
ones. The reason of this fact is quite simple. At small @xmath the
contribution of power corrections vanishes. The corresponding fitting
parameters are fixed essentially by statistical fluctuations.

Let us now come to the cautious remarks concerning the evaluation of
@xmath and @xmath (i.e., respectively, the parameters @xmath and @xmath
) formulated at the beginning of this Section.

It is clear from Figs. 4.16 and 4.17 , graphs (D), that any sound
estimate of @xmath is hopeless. The central value @xmath (obtained with
@xmath ) is approximatively zero (namely it is of order @xmath ), with
systematic errors of order 1. This is true on all the lattices and for
all the values of @xmath considered. Let us suppose to repeat the
calculation by fixing a particular perturbative truncation of the Wilson
coefficients. We shall obtain, in general, values of @xmath of order
one. Nevertheless the results will depend strongly upon the chosen
truncation. In our approach we can look at @xmath , which depends
depends upon @xmath . As @xmath is varied the neglected higher-loops
contributions to @xmath vary. The value of @xmath determined by the fit
mimics these higher-order terms.

A subtle point in the computation of @xmath is the following. Suppose to
choose a particular value of @xmath and a particular perturbative
truncation of the Wilson coefficients, i.e., in our approach, a
particular value of @xmath . Then compute @xmath for several values of
the bare coupling @xmath . This amounts to choosing several values of
the lattice spacing. It is not unlikely that the matrix elements of
@xmath obtained in this way will have (roughly) the correct scaling with
the lattice spacing. In other words one obtains @xmath which is
approximatively independent of @xmath , instead of having a power-like
dependence upon the lattice spacing. For example on lattices (A) , (B)
and (C) at @xmath and @xmath we get, respectively, @xmath , @xmath and
@xmath (the quoted values refer to @xmath and the corresponding
statistical error). This fact could led to the conclusion that a genuine
physical (continuum) quantity has been estimated despite the theoretical
warnings. The analysis in the previous paragraphs shows, however, that
this estimate is unreliable.

Let us now consider the parameter @xmath , i.e. the operator @xmath ,
whose @xmath dependence is shown in Figs. 4.16 , 4.17 , graphs (C). In
the general discussion above, we stressed that, for a sound estimate of
@xmath , a two-loop calculation of the Wilson coefficient @xmath is
needed. Here, we shall “guess” the two-loop result. This will provide us
with an “instructive” estimate of @xmath .

From Tab. 4.1 we learn that (if @xmath and @xmath ) one-loop
coefficients are of order @xmath , while two-loop coefficients are of
order @xmath . Let us suppose the same to be true for the unknown
two-loop coefficient of @xmath . We can look at the values of @xmath
presented in Figs. 4.16 and 4.17 , graphs (C), as the sum of two
contributions: the genuine matrix element of @xmath , and a spurious
contribution coming from the two-loop term of @xmath . Using the value
of @xmath given below ( @xmath ), we can estimate the spurious
contribution to be about @xmath . We can now subtract this contribution
from the best fitting values @xmath reported in Figs. 4.16 , 4.17 ,
graphs (C). We obtain @xmath of order @xmath : a conservative estimate
is then @xmath . It is interesting to notice that the systematic errors
in Figs. 4.16 , 4.17 , graphs (C) are about @xmath for intermediate
values of @xmath . They correctly signal the effects due to the
perturbative truncation of the Wilson coefficients.

We shall now consider the leading operator @xmath (and the corresponding
parameter @xmath ). In Figs. 4.16 and 4.17 , graphs (A), we report the
values of @xmath obtained with the fitting form ( 4.4.9 ). In the graphs
(A’) of the same figures, we repeat the fit using only the leading term
of the OPE, i.e. we drop out the terms @xmath , @xmath and @xmath in Eq.
( 4.4.9 ).

The results for @xmath obtained including power corrections, reported in
graphs (A), are flat within statistical errors (approximatively @xmath )
as soon as @xmath . The estimates obtained without power corrections ,
see graphs (A’), coincide with the previous ones within systematic
errors. Systematic errors are strikingly different between graphs (A)
and (A’). This phenomenon was already remarked in Sec. 4.4.4 . Here we
limit ourselves to underline a consequence of this fact. The systematic
error on the final evaluation of the parameter @xmath (i.e. on @xmath )
strongly depends upon the lattice spacing, i.e. upon the bare coupling
@xmath . For instance if we fix @xmath and @xmath we get @xmath , @xmath
and @xmath respectively on lattices (A) , (B) and (C) . Obviously
systematic errors can be reduced on coarser lattices by taking smaller
values of @xmath , but one cannot reduce @xmath below the lattice
spacing.

As we did in the previous Subsections, we estimate the systematic error
from the fit without power corrections. Our final results for parameter
@xmath are given in Tab. 4.9 . Here we used @xmath on lattices (A) and
(B) while @xmath on lattice (C) .

Finally we consider the evaluation of the parameter @xmath (i.e. of the
matrix element of @xmath ). Here we cannot apply the same strategy as
for @xmath , that is taking smaller values of @xmath as @xmath gets
larger (ideally @xmath and @xmath ). As we explained above, if @xmath is
small, the statistical error on @xmath becomes large. We shall keep
@xmath roughly fixed. Moreover @xmath must be taken in the perturbative
regime. In Tab. 4.9 we present the corresponding estimates of @xmath
obtained with @xmath , @xmath and @xmath , respectively on lattices (A)
, (B) and (C) .

We want to have an idea of the soundness of the systematic error bars
quoted in Tab. 4.9 . A possible check consists in looking at the results
for the parameter @xmath when the corresponding Wilson coefficient
@xmath is truncated to one-loop order. Using the fitting form ( 4.4.9 )
without power corrections, @xmath , and the same values of @xmath as the
ones used for Tab. 4.9 , we obtain @xmath , @xmath and @xmath ,
respectively on lattices (A) , (B) and (C) .

Finally, in Tab. 4.10 , we report the renormalized parameters
corresponding to the matrix elements of @xmath and @xmath . The bare
values are taken from the @xmath columns of Tab. 4.9 . They have been
renormalized using the field renormalization constant computed in Sec.
4.4.4 , cf. Tab. 4.3 . The results for @xmath can be compared with the
ones of Secs. 4.4.5 and 4.4.6 , reported in the rightmost column of Tab.
4.7 . We recall that in Secs. 4.4.5 and 4.4.6 , we adopted a completely
different method for the computation of the renormalized matrix elements
of @xmath . The two calculations agree very well, yielding a strong
consistency check of the OPE method.

### 4.5 More Answers

The investigations described in this Chapter allow us to complete the
partial conclusions of Sec. 3.4 .

In this Chapter we considered short distance products of the form @xmath
. As in the previous Chapter, the leading behaviour of this product was
of the type @xmath (where @xmath ) in most of our examples (the only
exception being the antisymmetric sector, see Sec. 4.4.8 ). It seems
that such a situation is more favorable and we shall focus on it at
first. Here we can make tighter statements than in Sec. 3.4 , thanks to
the smaller statistical errors (a fraction of percent) reached in this
Chapter.

-   Corrections to scaling determine the ultimate accuracy achievable at
    a given value of the bare coupling. The product of two elementary
    fields scales quite well, as long as the field operators are kept on
    different lattice sites. We were not able to reveal unambiguously
    corrections to scaling on these observables. We obtained some
    indications of scaling corrections (at the level of @xmath ) on
    lattice (A’), at @xmath .

-   Higher-twist operators, i.e. operators which require power
    subtractions to be renormalized, cannot be determined from the OPE
    (at least in our simple approach). There are strong theoretical
    reasons pointing to this conclusion, see Sec. 4.1.2 . The results
    obtained with the OPE method give a concrete support to these
    theoretical reasons.

-   Leading-twist operator can be determined (at least in theory) from
    the OPE. They can be classified according to their canonical
    dimension. Those with the lowest dimension yield the leading
    contribution to the OPE. In all our examples there was a unique
    leading operator. We were able to determine its matrix elements with
    a few percent accuracy. We used (next-to-) @xmath leading-log Wilson
    coefficients and products @xmath at distances @xmath ( @xmath ).

-   Higher-dimensional (leading-twist) operators appear as power
    corrections in the OPE. They can be determined from the OPE, but
    this task presents some technical difficulties. As the dimension of
    the operators increases, their mixings become more and more
    complicated. Moreover, at small distances (where perturbation theory
    is well behaved), their contribution to the OPE decreases quickly
    and statistical noise hides it.

-   Including or not power corrections in the OPE fitting form seems not
    to be an important issue.

-   As we already said in Sec. 3.4 , the main problem is related to the
    need for asymptotic scaling. Usually asymptotic scaling is judged
    with respect statistical errors. If the perturbative prediction lies
    within statistical error bars, asymptotic scaling is considered to
    be reached. This point of view is not completely satisfactory. Among
    the other things it heavily depends upon the statistical accuracy.
    We proposed to estimate the convergence of perturbation theory by
    assigning a systematic error to it. There exists (to date) no proved
    good way to assign this systematic error. However, our “empirical”
    definition was in rough agreement with all our observations.

The example studied in Sec. 4.4.8 , i.e. the antisymmetric product of
two elementary fields, is somehow an exception to these remarks. This is
perhaps related to the fact that the leading term of the OPE is, in this
case, of order @xmath , instead of @xmath . In this case we were not
able to find a scaling window without adding power corrections to the
OPE fitting form. Taking care of power corrections at tree level allowed
to improve the scaling behaviour. The final result was in good agreement
with an alternative calculation. Nevertheless the situation is not fully
satisfactory for what concerns this example.

## Conclusions and Perspectives

Renormalization of lattice composite operators is a central problem for
applications of lattice QCD. The structure of hadrons can be, for many
purposes, encoded in matrix elements, which cannot be computed in
perturbation theory. Lattice computations are a non-perturbative, widely
applicable tool for such problems. Perturbation theory seems not to be
the good method for translating the lattice results in the continuum
language. This leads to the problem of designing well-chosen
non-perturbative renormalization methods.

The authors of Ref. [ 32 ] proposed to define renormalized composite
operators by “splitting” them into simpler operators (e.g., conserved
currents). Operator Product Expansion must then be used for recovering
the operator we were interested in. This is essentially an
“infinite-volume scheme” (see Chapter 1 ) and has the disadvantage that
many scales must be separated on the same lattice. However it has some
advantages.

-   Renormalized operators are obtained in a massless scheme without any
    extrapolation to the chiral limit.

-   It is more direct: renormalization and computation of matrix
    elements are accomplished in the same step.

-   A simpler approach to operator mixing is possible. In particular
    “lattice-induced” mixings can be disregarded since unrenormalized
    lattice operators are never used.

Moreover the idea itself is quite appealing. It is however far from
obvious that it can applied in practice.

We completed a detailed feasibility study of this method on a simple
two-dimensional model which can be simulated with very fast algorithms.
We gave here a thorough account of this work. The main result is that
the new method outlined above and in Section 1.4 really works. We refer
to Secs. 3.4 and 4.5 for some technical highlights.

Here we recall the principal suggestions which come out from this work
and could be of help in a QCD application of the new method:

-   The model studied in this thesis is affected by @xmath lattice
    artifacts. The same type of corrections to scaling occurs in @xmath
    -improved QCD. We found the systematic errors due to these effects
    to be under control even on quite coarse lattices. The largest
    lattice artifacts occur in fact at contact points, and can be easily
    avoided in the OPE approach. On the coarsest lattice considered, the
    correlation length (inverse mass gap) was @xmath .

-   The principal source of systematic error is the perturbative
    truncation of the Wilson coefficients. We resummed the Wilson
    coefficients using RG up to next-to-next-to-leading-log order. We
    estimated the systematic error by varying the resummation procedure
    and the perturbative order. Moreover, we recomputed the same
    renormalized matrix elements using different approaches. The various
    estimates of the systematic error were roughly consistent. The
    achievable precision depends upon the lattice spacing, which control
    the shortest distance that can be reached on the lattice considered.

-   Obviously, it is much simpler to estimate the leading operator of
    the OPE. The best situation occur when the corresponding Wilson
    coefficient behaves logarithmically in the short distance limit.

Let us conclude by listing a few lines for further investigation:

-   In QCD chiral symmetries are broken both spontaneously, and “softly”
    by the quark-mass terms. These breakings manifest themselves as
    power corrections in the OPE. The role of these power corrections
    deserves some accurate investigation.

-   What is the effect of improvement? One of the advantages of the
    method exposed here is that improvement of composite operators is
    straightforward. It would be interesting to study the efficiency of
    the method with an improved action and improved operators.

-   The principal feature of the method studied in this thesis is that
    it allows to employ continuum symmetries, rather than lattice ones.
    This is an advantage both on the “standard” infinite-volume methods,
    and on the finite-volume ones. Therefore it would be very
    interesting to find a finite-volume version of the OPE method.