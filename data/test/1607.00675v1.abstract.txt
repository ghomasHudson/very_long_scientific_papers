The recent development of compressed sensing has led to spectacular
advances in the understanding of sparse linear estimation problems as
well as in algorithms to solve them. It has also triggered a new wave of
developments in the related fields of generalized linear and bilinear
inference problems, that have very diverse applications in signal
processing and are furthermore a building block of deep neural networks.
These problems have in common that they combine a linear mixing step and
a nonlinear, probabilistic sensing step, producing indirect measurements
of a signal of interest. Such a setting arises in problems as different
as medical or astronomical imaging, clustering, matrix completion or
blind source separation.

The aim of this thesis is to propose efficient algorithms for this class
of problems and to perform their theoretical analysis. To this end, it
uses belief propagation, thanks to which high-dimensional distributions
can be sampled efficiently, thus making a Bayesian approach to inference
tractable. The resulting algorithms undergo phase transitions just as
physical systems do. These phase transitions can be analyzed using the
replica method, initially developed in statistical physics of disordered
systems. The analysis reveals phases in which inference is easy, hard or
impossible. These phases correspond to different energy landscapes of
the problem.

The main contributions of this thesis can be divided into three
categories. First, the application of known algorithms to concrete
problems: community detection, superposition codes and an innovative
imaging system. Second, a new, efficient message-passing algorithm for a
class of problems called blind sensor calibration. It could be used in
signal processing for a large class of measurement systems that use
arrays of physical sensors. Third, a theoretical analysis of achievable
performances in matrix compressed sensing and of instabilities in
Bayesian bilinear inference algorithms.
