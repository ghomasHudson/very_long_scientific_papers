# Acknowledgments

I would like to thank my advisor, professor Eilon Solan, for the time,
effort and goodwill he invested helping me with my research. I would
also like to thank professor Dov Samet and proffesor Ehud Lehrer, whose
remarks helped to improve this work. Many thanks to my fellow graduate
students Roee Teper, Yuval Heller and Ya’arit Even. Last but not least,
I thank Yuval Elhanati for his support and good advices.

###### Contents

-    1 Introduction
-    2 The Model
-    3 Main Result: Characterization of the Cooperation Events
    -    3.1 The Complete Information Case
    -    3.2 The Incomplete Information Case
    -    3.3 Proof of Theorem 3.3
-    4 Constructing the Cooperation Events
    -    4.1 Preliminaries — Belief Operators
    -    4.2 Constructing the Cooperation Events
-    5 Prisoner’s Dilemma
-    6 Examples
-    7 @xmath -Equilibria
-    8 “Almost” Complete Information
    -    8.1 Knowing Approximately the Discount Factors
    -    8.2 The True Discount Factors are Common- @xmath -Belief in
        Most States of the World
    -    8.3 Each Player @xmath -Believes that a State of Nature is
        Common- @xmath -Belief
-    9 Generalizations
    -    9.1 The Results when One’s Own Discount Factor is Unknown
    -    9.2 General games
    -    9.3 More than Two Players

## 1 Introduction

In the repeated Prisoner’s Dilemma, when every player has a different
discount factor, the grim-trigger strategy is an equilibrium if and only
if the discount factor of each player is sufficiently close to 1. A
similar situation holds for other repeated two-player games in which
there is a pair of pure actions @xmath such that under @xmath the payoff
for each player is strictly higher than some equilibrium payoff: there
are two thresholds @xmath such that the grim-trigger course of action
@xmath , under which the players follows @xmath until a deviation occur,
and then they switch to the equilibrium action that punishes the other
player, is an equilibrium if and only if @xmath for @xmath . In a
symmetric game, like the Prisoner’s Dilemma, these thresholds are the
same for both players. ¹ ¹ 1 Note that when the players have different
discount factors, there may exist equilibria which yield payoffs that
are higher than the payoffs under any such @xmath . Such cooperative
equilibria are not in the scope of this work. See Lehrer and Pauzner
(1999).

In this work we look at repeated games in which each player has
incomplete information regarding the other player’s discount factor, and
ask when a pair of grim-trigger strategies is an equilibrium. A strategy
in the incomplete information game is information-dependent: a strategy
assigns a “course of action”, which is a strategy in the repeated game
(with complete information), to each state of the world. A pair of
strategies will be called “conditional-grim-trigger” if it is composed
of two action pairs @xmath and @xmath , where (a) @xmath is an
equilibrium of the one-shot game, (b) the payoff under @xmath is higher
than the payoff under @xmath for both players, and (c) in any state of
the world @xmath , player @xmath either plays repeatedly @xmath , or
plays @xmath until a deviation from @xmath is detected, and then he
switches to playing @xmath forever, for @xmath . ² ² 2 This is a
narrower sense of the concept of grim-trigger strategy, since we demand
that the pair of punishing strategies will define an equilibrium,
instead of any pair @xmath under which @xmath (Here and below, @xmath is
an arbitrary player and @xmath is the player which is not @xmath ).
Because of this assumption, a conditional-grim-trigger strategy pair
Bayesian equilibrium is a perfect Bayesian equilibrium.

In order for a player to cooperate (assuming his own discount factor is
sufficiently high), he needs to ascribe high enough probability that the
other player’s discount factor is higher than his threshold. But he also
needs to ascribe high enough probability that the other player ascribes
high enough probability that his own discount factor is higher than his
own threshold, and so on. We thus get that infinitely many conditions
need to hold in order for the conditional-grim-trigger strategy pair to
be an equilibrium, one for each level of belief for each player. Note
that the “high enough” probability in each level depends on the player’s
own discount factor, since the higher his discount factor is, the player
will lose more if the grim-trigger course of action is triggered.
Therefore, a player with high discount factor will cooperate in
situations where he wouldn’t have cooperated if his discount factor was
lower.

We show that this is not the case, and only two conditions for each
player are necessary and sufficient to characterize when the
conditional-grim-trigger strategy is a Bayesian equilibrium. In this
strategy, each player plays the grim-trigger course of action in some
states of the world, which is called his “cooperation event”, and the
punishing strategy in the others. We show that this strategy is a
Bayesian equilibrium if and only if (a) each player plays the
grim-trigger course of action only when his discount factor is above his
threshold; and (b) each player ascribes sufficiently high probability to
the other player’s cooperation event whenever he plays the grim-trigger
course of action, and a sufficiently low probability to the other
player’s cooperation event whenever he does not play this course of
action. This result holds for all belief structures, whether they are
derived from a common prior or not.

We describe the sets of states of the world that satisfy these
conditions, and relate them to the concept of @xmath -belief and common-
@xmath -belief. These two concepts generalize the concepts of @xmath
-belief and common- @xmath -belief defined by Samet and Mondrer (1989).
In particular, we show that for the repeated Prisoner’s Dilemma, the
strategy profile above is an equilibrium whenever each player plays the
cooperation strategy if he @xmath -believes that it is a common- @xmath
-belief that both players’ discount factors are above a given threshold.
For games with more then two actions for each player, an additional
condition is needed.

We also show that these conditions are sufficient, though not necessary,
for this kind of strategy to be a Bayesian equilibrium even if each
player does not know his own discount factor, and also in a larger class
of two-player games with incomplete information, in which there is an
equilibrium which holds in all states of the nature (equivalent to the
“punishment” equilibrium) and an equilibrium which holds only in some
states of nature (equivalent to the “cooperation” grim-trigger
equilibrium, which holds only for high discount factors). We also show
that similar conditions are sufficient, though not necessary, in
repeated games with incomplete information with more than two players.

Last, we look at belief spaces in which the information is “almost”
complete, in several senses, and see that in some senses, when the
information is almost complete, there is a conditional-grim-trigger
@xmath -equilibrium in which the players cooperate in all states of the
world where they could have cooperated under equilibrium in the complete
information case, but for a set of small probability, while in other
senses, there may be no conditional-grim-trigger @xmath -equilibrium at
all.

## 2 The Model

Let @xmath be a two-player one-shot game: @xmath is the set of players,
and for every player @xmath , @xmath is the set of pure actions of
player @xmath , and @xmath is his utility function (extended
multilinearly to mixed strategies). Let @xmath be a Nash equilibrium in
mixed-strategies in @xmath . Assume that the payments in another
non-equilibrium pure action profile @xmath , which we call a cooperation
profile , are higher than the equilibrium payments, that is @xmath for
@xmath . Also, assume that for @xmath , @xmath is not a best response to
@xmath , and, in particular, not in the support ³ ³ 3 We discuss this
assumption in 3.5 below. of @xmath .

Let @xmath be the repeated game based on @xmath , with incomplete
information regarding the discount factors:

-   @xmath is the set of players.

-   @xmath is a measurable space of the states of nature, that is,
    @xmath is the set of possible pairs of discount factors of the
    players. @xmath is the @xmath -algebra that is induced on @xmath by
    the Borel @xmath -algebra on @xmath .

-   @xmath is the players’ belief space:

    -   @xmath is a measurable space of states of the world.

    -   @xmath is a measurable function between the states of the world
        and the states of nature, i.e., the players’ discount factors
        are @xmath , where @xmath is player @xmath ’s discount factor in
        the state of the world @xmath . The definition of @xmath implies
        that @xmath , for every open @xmath .

    -   @xmath is a measurable function that assigns a belief for player
        @xmath to each state of the world @xmath . We denote by @xmath
        the probability that player @xmath ascribes to the event @xmath
        at the state of the world @xmath , and by @xmath the
        corresponding expectation operator. @xmath is measurable in the
        sense that for every @xmath , @xmath is a measurable function.
        @xmath is consistent, in the sense that each player knows his
        belief: @xmath , for every @xmath . We assume that @xmath is
        such that each player knows his own discount factor in every
        state of the world @xmath : @xmath for every @xmath . In Section
        9.1 we drop this assumption.

    Because @xmath is consistent, it divides @xmath into disjoint
    “types” of player @xmath ; that is, into the sets @xmath . Denote by
    @xmath the @xmath -algebra generated by these sets, and by the sets
    @xmath , for every open set @xmath (since each player knows his own
    discount factor, these sets are unions of his types). We will call a
    subset of @xmath or a function from @xmath @xmath -measurable if it
    is measurable with respect to @xmath .

-   @xmath and @xmath are the same as in @xmath : the set of pure
    actions of player @xmath , and his utility function (in each stage
    of the game), which are independent of the state of the world.

A course of action of player @xmath is function that assigns a mixed
action of player @xmath to each finite history of actions in the game.
This function is independent of the state of the world. A strategy of
player @xmath is an @xmath -measurable function @xmath that assigns a
course of action @xmath to each state of the world @xmath . The payoff
of player @xmath when the profile @xmath is played, conditional on the
state of the world @xmath , is @xmath , where @xmath is the utility in
stage @xmath . The expectation ⁴ ⁴ 4 Note that this is actually the
expected subjective payoff of player @xmath , because the expectation is
taken with respect to his belief @xmath . This is the relevant payoff
for the player’s decision making. One could define the payoff as @xmath
. Most of our results remain unchanged with this payoff function.
depends on @xmath , since player @xmath ’s actions and player @xmath ’s
belief may depend on @xmath . As mentioned, we assume that the discount
factor @xmath is known to player @xmath .

Recall that @xmath is a cooperative profile, and @xmath is a Nash
equilibrium with payoffs lower than those under @xmath .

###### Definition 2.1

A grim-trigger course of action for player @xmath , based on @xmath and
@xmath , is the course of action @xmath under which player @xmath plays
@xmath until player @xmath deviates from @xmath , and from that stage on
plays @xmath .

In the complete information case, there are thresholds @xmath such that
@xmath is an equilibrium if and only if @xmath :

  -- -------- --
     @xmath   
  -- -------- --

Denote @xmath , which is the set of states in which player @xmath cannot
profit by deviating from the profile @xmath . Note that player @xmath
always knows whether @xmath or not: @xmath is an @xmath -measurable
event.

We are interested only in “conditional-grim-trigger” strategies:

###### Definition 2.2

A strategy @xmath of player @xmath is called conditional-grim-trigger
strategy (with respect to @xmath and @xmath ) if there is an @xmath
-measurable set @xmath such that:

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath is the course of action where player @xmath always plays
@xmath . We denote this strategy by @xmath .

Note that if a pair of grim-trigger strategies @xmath is played, then,
because @xmath is not in @xmath ’s support, after the first stage both
players learn if the other player “cooperates”. From that point on they
do not learn anything else.

###### Definition 2.3

If @xmath is a Bayesian equilibrium, the pair of events @xmath is called
cooperation events .

The existence of non-empty cooperation events guarantees that the
players may cooperate in some states of the world.

Note that @xmath is a Bayesian equilibrium in which the players always
follow @xmath . Also note that if @xmath is a Bayesian equilibrium and
@xmath , then @xmath , since we assumed that @xmath is not a best
response to @xmath .

## 3 Main Result: Characterization of the Cooperation Events

### 3.1 The Complete Information Case

When the game has complete information we can identify @xmath and @xmath
, and each player knows the true state of the world.

###### Theorem 3.1

When the game @xmath has complete information, @xmath is a Bayesian
equilibrium if and only if @xmath where @xmath .

Proof: Assume @xmath . Then for every @xmath , the profile @xmath is
played, and both players know it. Since @xmath , both @xmath and @xmath
, so neither player can profit by deviating. For every @xmath , the
profile @xmath is played, and both players know it. Since @xmath is a
Nash equilibrium in @xmath , neither player can profit by deviating. For
the opposite direction, there are two cases: @xmath and @xmath . Assume
first that @xmath , and let @xmath . Without loss of generality assume
that @xmath in the state of the world @xmath . In the state of the world
@xmath the profile @xmath is played, but since @xmath , player 1 can
profit by deviating, so @xmath is not a Bayesian equilibrium. Assume Now
that @xmath . Then in the state of the world @xmath , player 1 knows
that player 2 plays @xmath , and since @xmath is not a best response to
@xmath , it is profitable for him to deviate from @xmath to @xmath , and
therefore @xmath is not a Bayesian equilibrium. @xmath

###### Example 3.2

Prisoner’s Dilemma with complete information.
[]
Here @xmath and @xmath . It can be easily calculated that @xmath , and
that @xmath is a Bayesian equilibrium if and only if @xmath .

### 3.2 The Incomplete Information Case

Our main result is the following:

###### Theorem 3.3

Let @xmath be an @xmath measurable event for @xmath , then the strategy
profile @xmath is a Bayesian equilibrium if and only if ,for @xmath ,
@xmath and

1.  @xmath for every @xmath ,

2.  @xmath for every @xmath ,

for the @xmath -measurable functions ⁵ ⁵ 5 By definition, the infimum
over an empty set is 1 and the supremum over an empty set is 0.

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an action of player @xmath , and @xmath . @xmath ,
@xmath and @xmath are derived from different kinds of deviations, and
are defined by:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

whenever @xmath , and @xmath otherwise, and

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

We now present an equivalent formulation of Theorem 3.3 , using the
concept of @xmath -belief and common- @xmath -belief, which we define
now.

###### Definition 3.4

Let @xmath be a set of players and @xmath be a general belief space on a
measurable space of states of nature @xmath . Let @xmath be a measurable
function, where @xmath is @xmath -measurable for every @xmath . Let
@xmath be an event. We say that player @xmath @xmath -believes in the
event @xmath at @xmath if @xmath . We say that the event @xmath is an
common- @xmath -belief at @xmath if in the state of the world @xmath
each player @xmath -believes in @xmath , @xmath -believes that each
other player @xmath -believes in @xmath , @xmath -believes that each
other player @xmath -believes that each player @xmath -believes in
@xmath , etc.

These two concepts generalize the concepts of @xmath -belief and common-
@xmath -belief described by Samet and Mondrer (1989). These concepts are
discussed in detail in Section 4 .

The definitions imply that the conditions in Theorem 3.3 are equivalent
to the following:

1.  @xmath is an @xmath -belief in @xmath .

2.  @xmath is an @xmath -belief in @xmath .

In Section 4 we prove that these conditions are also equivalent to the
following condition: each player either @xmath -believes that @xmath is
a common- @xmath -belief or @xmath -believes that the event “ @xmath is
not a common- @xmath -belief” is a common- @xmath -belief (Theorem 4.6
).

### 3.3 Proof of Theorem 3.3

Player @xmath ’s payoff under the strategy profile @xmath is @xmath . As
mentioned before, the strategy profile @xmath is not an equilibrium in
the one-shot game, whereas @xmath is. If player @xmath deviates from the
profile @xmath and plays @xmath in the first stage, then from the second
stage on player @xmath will play @xmath , to which @xmath will be player
@xmath ’s best response. The expected payoff for player @xmath will then
be @xmath . If there is a profitable deviation from @xmath for player
@xmath , there is such a profitable deviation in the first stage.
Therefore @xmath , is the minimal discount factor @xmath such that
player @xmath cannot gain by deviating from the profile @xmath .

We will now check player @xmath ’s options to deviate from the profile
@xmath .
Case 1: @xmath .

Note that, because @xmath is @xmath -measurable, in this case @xmath .

Player @xmath ’s payoff under the strategy profile @xmath is

  -- -------- --
     @xmath   
  -- -------- --

Indeed, according to player @xmath ’s belief, with probability @xmath
player @xmath plays @xmath , so they will play @xmath at every stage and
his payoff will be @xmath , and with probability @xmath player @xmath
plays @xmath so in the first stage the profile played will be @xmath and
afterwards the players will play @xmath , so that player @xmath ’s
payoff will be @xmath .

We now check the conditions that guarantee that player @xmath cannot
profit by deviating:

-   Because @xmath is an equilibrium, deviation after the first stage
    can be profitable for player @xmath only if player @xmath played
    @xmath in the first stage. Also, in that case, if it’s profitable to
    deviate in stage @xmath , it is also profitable to deviate in stage
    @xmath , because when @xmath is played, the players do not learn
    anything from the second stage onwards. After the first deviation
    the best response to @xmath is to play @xmath in all stages, because
    player @xmath will play @xmath . Denote by @xmath the course of
    action in which player @xmath plays @xmath in the first stage, an if
    player @xmath played @xmath in the first stage, player @xmath plays
    a pure action @xmath in stage @xmath and @xmath afterwards. If
    player @xmath played @xmath in the first stage, player @xmath plays
    @xmath from the second stage onwards. The payoff is:

      -- -------- --
         @xmath   
      -- -------- --

    So that @xmath is an equilibrium we should have @xmath for all
    @xmath , and therefore,

      -- -------- --
         @xmath   
      -- -------- --

    for every @xmath . Because @xmath , either @xmath or @xmath .

-   Player @xmath can also deviate in the first stage to a pure strategy
    @xmath . As before, after the deviation his best response to @xmath
    is to play @xmath in all stages. His payoff in this case is (denote
    by @xmath the course of action of player @xmath that plays @xmath at
    stage 1 and @xmath thereafter):

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

    In order for @xmath to be an equilibrium we should have

    @xmath , and therefore, for every @xmath :

      -- -------- -- -----
         @xmath      
         @xmath      (1)
      -- -------- -- -----

    Because @xmath is not a best response to @xmath , @xmath , otherwise
    inequality ( 3.3 ) becomes @xmath for every @xmath in contradiction.
    As above we deduce, that @xmath , or @xmath . Therefore we get that
    @xmath . Therefore, if @xmath inequality 3.3 trivially holds.
    Otherwise we obtain:

      -- -------- --
         @xmath   
      -- -------- --

    or @xmath where @xmath is defined by:

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath .

Case 2: @xmath .

Player @xmath ’s payoff under the strategy profile @xmath is

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

-   Player @xmath can deviate to the strategy @xmath described above (
    @xmath may be in the support of @xmath . See remark 3.6 (1)). His
    payoff in this case is:

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

    So that @xmath is a Bayesian equilibrium, we should have

    @xmath , that is

      -- -------- -- -----
         @xmath      
         @xmath      (2)
      -- -------- -- -----

    The last term on the left side of inequality ( 3.3 ) is non-negative
    since @xmath is an equilibrium. Therefore, if @xmath inequality 3.3
    trivially holds. Inequality ( 3.3 ) is equivalent to @xmath , where

      -- -------- --
         @xmath   
      -- -------- --

    and @xmath . Note that @xmath is independent of @xmath and the
    inequality is independent of @xmath .

-   Player @xmath can deviate to @xmath . In this case his payoff is:

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

    Because @xmath :

      -- -------- -- -----
         @xmath      
         @xmath      (3)
      -- -------- -- -----

    As before, @xmath . Unless @xmath inequality ( 3.3 ) trivially
    holds. Therefore inequality ( 3.3 ) is equivalent to @xmath , where

      -- -------- --
         @xmath   
      -- -------- --

    whenever @xmath , and @xmath otherwise.

-   Player @xmath can play the following strategy @xmath :

    -   Play @xmath in the first stage.

    -   If @xmath played @xmath in the first stage, play @xmath until
        stage @xmath and then play a pure @xmath , and afterwards @xmath
        .

    -   If @xmath played @xmath in the first stage, player @xmath ’s
        best response is @xmath from stage @xmath onwards.

    The payoff is:

      -- -------- --
         @xmath   
      -- -------- --

    Note that @xmath for some constants @xmath and @xmath , independent
    of @xmath . Therefore, as a function of @xmath , @xmath is
    monotonic. If it is increasing, it is smaller than the payoff in the
    previous case (playing @xmath ). If it is decreasing, @xmath if and
    only if the inequality holds for @xmath . Therefore, we only need to
    consider the case of @xmath :

      -- -------- -------- -------- -- -----
         @xmath                        
         @xmath   @xmath   @xmath      (4)
      -- -------- -------- -------- -- -----

    If @xmath inequality ( 3.3 ) trivially holds. Therefore inequality (
    3.3 ) is equivalent to @xmath , where

      -- -------- --
         @xmath   
      -- -------- --

    and

      -- -------- --
         @xmath   
      -- -------- --

Then @xmath . Last, we need to prove that @xmath and @xmath are @xmath
measurable. Both of them are rational functions (or segment-wise
rational functions) of @xmath , and therefore, as functions of @xmath ,
they are Borel functions. Since @xmath contains @xmath , for every open
set @xmath , @xmath and @xmath , as functions of @xmath , are @xmath
-measurable. @xmath

###### Remark 3.5

1.   If @xmath is in the support of @xmath , player @xmath cannot lose
    by playing @xmath in every @xmath : @xmath is a best response to
    @xmath in this case, and player @xmath cannot (in this mechanism)
    discern the deviation and punish. Therefore, in this case, in order
    for @xmath to be an equilibrium, it is necessary that @xmath for
    every @xmath . Also, in this case @xmath is not necessarily a subset
    of @xmath — see next remark.

2.   If @xmath is a best response to @xmath , @xmath may not be a subset
    of @xmath since we cannot conclude from inequality ( 3.3 ) that
    @xmath , and therefore we only get that @xmath . Moreover, in this
    case (and this case only) inequality ( 3.3 ) trivially holds for
    every @xmath — there is no non-trivial condition on @xmath that
    needs to hold for @xmath . Also, in this case @xmath may be 0 even
    if @xmath isn’t in the support of @xmath because @xmath and @xmath
    are either @xmath or @xmath (this follows from their definition
    because @xmath ). See Example 3.7 .

###### Remark 3.6

1.   If there is a best response @xmath to @xmath which is a better
    response to @xmath than @xmath , then @xmath (and then we need
    @xmath for every @xmath ), even if @xmath is a best response to
    @xmath , because then @xmath . Note that this condition depends only
    on the structure of @xmath , and not on the information structure.
    From this we deduce that if @xmath is not pure, then @xmath unless
    @xmath for every @xmath in the support of @xmath .

2.   Under the assumption that @xmath , we have @xmath . Note that
    @xmath for @xmath , and it can be defined as needed outside this
    set, see the following remark.

3.   Note that the definition of @xmath outside @xmath and the
    definition of @xmath inside @xmath for @xmath is irrelevant for
    Theorem 3.3 .

In the following example we show that if @xmath is a best response to
@xmath , @xmath may be an equilibrium even if @xmath (a strict
inclusion). In particular, the assumption that @xmath is not a best
response to @xmath is necessary for Theorem 3.3 .

###### Example 3.7

Consider the following game:
[]
As in Example 3.2 , @xmath , @xmath , and @xmath (the payoff of player
@xmath when he plays @xmath and player @xmath plays @xmath is irrelevant
for the calculation of @xmath , as long as @xmath remains a Nash
equilibrium). Let @xmath , with @xmath . In any state of the world
@xmath , player @xmath knows only the coordinate @xmath of @xmath (his
own discount factor). If @xmath , player @xmath believes that @xmath
(i.e., that both discount factors are 1/4). If @xmath , player @xmath
believes that @xmath or @xmath with equal probability. From @xmath we
have that @xmath and @xmath . We now show that @xmath is a Bayesian
equilibrium: Player 1 plays @xmath in every state of the world, and
player 2 plays @xmath if @xmath , and always defects otherwise.
Therefore, if @xmath , player 1 believes that @xmath , so that player 2
always plays @xmath , and in this case player 1 gains 1 in each stage
regardless of his actions. If @xmath , player 1 believes that in
probability @xmath player 2 always plays @xmath , so the same argument
as before holds, and in probability @xmath player 2 plays @xmath .
Because @xmath , player 1 cannot profit from deviating from @xmath .
Therefore, player 1 cannot profit by deviation. Player 2 knows that
player 1 plays @xmath . If @xmath he plays @xmath , and since @xmath he
cannot profit from deviating. If @xmath , player 2 plays @xmath in every
stage. He cannot profit from playing @xmath , since @xmath . Last, as
shown in the proof to Theorem 3.3 , we need to check that he cannot
profit by deviating to @xmath , and indeed inequality ( 3.3 ) holds in
this case (for @xmath ). Therefore, @xmath is indeed a Bayesian
equilibrium.

## 4 Constructing the Cooperation Events

In this section we construct the cooperation events @xmath and @xmath so
they will satisfy the conditions of Theorem 3.3 .

### 4.1 Preliminaries — Belief Operators

In this section we study the concepts @xmath -belief and common- @xmath
-belief, as defined in Definition 3.4 . This subsection is valid for
general belief spaces, not only regarding the model of incomplete
information regarding the discount factors (see definition 10.1 in
Zamir-Maschler-Solan for a formal definition of a general belief space).

###### Definition 4.1

The @xmath -belief operator of player @xmath is the operator @xmath that
assigns to each event the states of the world at which player @xmath
@xmath -believes in the event: @xmath .

If @xmath is a constant function, and @xmath for every @xmath and @xmath
, then the concept of @xmath -belief reduces to the concept of @xmath
-belief of Mondrer and Samet (1989). If @xmath is a constant function
@xmath , but not necessarily @xmath for every @xmath and @xmath , then
the concept of @xmath -belief reduces to the concept of -belief of
Morris and Kajii (1997). Similar to the analysis of Mondrer and Samet,
we prove the following:

###### Proposition 4.2

Let @xmath be an @xmath -belief operator. The following hold:

1.   If @xmath and @xmath , then @xmath .

2.   If @xmath then @xmath .

3.   If @xmath is a decreasing sequence of events then @xmath .

4.   If @xmath is an @xmath -measurable event, then @xmath .

5.   If @xmath or @xmath then @xmath for every event @xmath and @xmath
    -measurable event @xmath .

Proof: The proof of parts 1 and 3 is similar to the proof for
Proposition 2 in Mondrer and Samet (for @xmath -belief operators). To
prove part 4, observe that for every @xmath , @xmath and for every
@xmath , @xmath . Part 2 follows from part 4, because for every @xmath ,
@xmath is an @xmath -measurable event (since @xmath and @xmath are
@xmath -measurable), which contains @xmath . To prove part 5, assume
@xmath . In this case @xmath . Assume @xmath . From part 1 we have
@xmath and @xmath . For the opposite direction, assume @xmath . Then
@xmath and @xmath and therefore @xmath , that is, @xmath . @xmath

We say that @xmath is a common- @xmath -belief at a state of the world
@xmath if in the state of the world @xmath each player @xmath -believes
@xmath , @xmath -believes that the other players @xmath -believe @xmath
, @xmath -believes that they @xmath -believe that he @xmath -believes
@xmath , etc. Therefore, @xmath is a common- @xmath -belief at @xmath ,
then @xmath , @xmath , and so on. In particular, if we define @xmath ,
@xmath for every @xmath , and @xmath we get that “ @xmath is a common-
@xmath -belief is @xmath ” is equivalent to @xmath . The event @xmath is
called @xmath is a common- @xmath -belief .

By Proposition 4.2 , @xmath is a belief operator as defined by Mondrer
and Samet (1989), and therefore we get:

###### Proposition 4.3

Let @xmath , @xmath . The following definition of “ @xmath is an common-
@xmath -belief at a state of the world @xmath ” is equivalent to the
Definition 3.4 : @xmath is a common- @xmath -belief at @xmath if and
only if there exist an event @xmath such that @xmath , and @xmath and
@xmath for every @xmath .

### 4.2 Constructing the Cooperation Events

Now we go back to the incomplete information structure as defined in
Section 2 .

###### Definition 4.4

For every two events @xmath , @xmath , define @xmath . For @xmath ,
define

@xmath , and

@xmath .

The definition of @xmath is similar (though not identical) to the
definition of iterated @xmath -belief of player @xmath in Morris (1999).

As the next Lemma states, @xmath and @xmath are the largest subsets of
@xmath and @xmath (respectively), such that the first inequality in
Theorem 3.3 holds:

###### Lemma 4.5

1.   For every @xmath , one has @xmath for @xmath . @xmath and @xmath
    are the largest subsets of @xmath and @xmath (respectively) such
    that this property holds. ⁶ ⁶ 6 They are the largest in the
    following (strong) sense: if @xmath and @xmath fulfill @xmath for
    @xmath then @xmath .

2.   If @xmath is @xmath -measurable so is @xmath , for every @xmath .

3.   If @xmath is @xmath -measurable and @xmath for @xmath , then @xmath
    and @xmath depend only on the intersection of @xmath and @xmath . In
    this case, @xmath , the event containing all state of the world
    @xmath such that @xmath is a common- @xmath -belief at @xmath , and
    @xmath , the event event containing all state of the world @xmath
    such that player @xmath @xmath -believes that @xmath is a common-
    @xmath -belief.

Note that part 3 holds when @xmath and @xmath , and in particular to
@xmath -belief for @xmath .

Proof:

1.  We first argue that @xmath . Indeed, by Proposition 4.2 (3), and
    since @xmath is a decreasing sequence of events,

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

    Here @xmath and @xmath . For the maximality property, assume that
    that @xmath and @xmath fulfill @xmath for every @xmath and @xmath .
    Therefore @xmath from which follows @xmath and therefore @xmath .
    Because @xmath it follows, from Proposition 4.2  (1) that @xmath .

2.  This follows from the fact that @xmath is @xmath -measurable for
    every @xmath , and because the intersection of countably many @xmath
    -measurable sets is @xmath -measurable.

3.  Denote @xmath . By Proposition 4.2  (5) one has @xmath . This proves
    the first claim. Because @xmath , it can be verified from the
    definition of that for @xmath , @xmath and therefore @xmath . The
    event “player @xmath @xmath -believes that @xmath is a common-
    @xmath -belief” is the event

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

    The second equality follows from the second part of this lemma and
    Proposition 4.2 (5), and the last one from the first part of this
    lemma.

@xmath

Using Lemma 4.5 and Proposition 3.3 we get the following result:

###### Theorem 4.6

For every two events @xmath and @xmath , such that @xmath , for @xmath ,
and @xmath is measurable according to the information of player @xmath ,
the strategy profile @xmath is a Bayesian equilibrium if and only if
@xmath . Moreover, @xmath are the maximal subsets of @xmath with this
property - if there is @xmath such that @xmath , then @xmath is not an
equilibrium.

The opposite is also true: if @xmath is an equilibrium, then @xmath and
@xmath .

In other words, @xmath is an equilibrium if and only if each player
either @xmath -believes at @xmath that @xmath is a common- @xmath
-belief at @xmath or @xmath -believes at @xmath that the event “ @xmath
is not a common- @xmath -belief” is a common- @xmath -belief at @xmath ,
for every state of the world @xmath .

Also, if @xmath ( @xmath ) for some @xmath , then each player either
@xmath -believes at @xmath that @xmath is a common- @xmath -belief at
@xmath or @xmath -believes at @xmath that the event “ @xmath is not a
common- @xmath -belief” is a common- @xmath -belief at @xmath , for
every state of the world @xmath .

This theorem shows that the argument that infinite number of conditions
of the type “each player needs to ascribe high enough probability that
the other player ascribes high enough probability that his own discount
factor is higher than…” are needed, as was discussed in the
introduction, holds. It is equivalent to the condition that in @xmath
player @xmath @xmath -believes @xmath at @xmath for every @xmath for
both @xmath and @xmath . Also, as the theorem states, a similar
condition is required for every @xmath .

Proof: Denote @xmath . From Remark 3.6 (3), we can assure that @xmath
and @xmath . Therefore, Lemma 4.5 (3) holds, so @xmath and @xmath .
Because @xmath , we know from Lemma 4.5 (1) that the first condition in
Proposition 3.3 holds, and that there are no larger subsets of @xmath
such that it holds. Therefore, @xmath is an equilibrium if and only if
the second condition holds. That is, for every @xmath one has @xmath
which is equivalent to @xmath for every @xmath or @xmath . From that we
get

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , which implies that

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

For the second part, observe that @xmath follows from Lemma 4.5 (1):
@xmath is the biggest subset of @xmath such the first condition in
Proposition 3.3 holds. But since @xmath is an equilibrium it holds for
@xmath . Similarly, @xmath is the biggest subset of @xmath such that the
second condition in Proposition 3.3 holds, and therefore @xmath . @xmath

###### Example 4.7

Recall that @xmath . So, if we take @xmath , then @xmath is an
equilibrium if and only if whenever a player does not @xmath -believe
that ” @xmath and @xmath are high enough” is a common- @xmath -belief,
he @xmath -believes that the fact that this is not a common- @xmath
-belief is a common- @xmath -belief.

## 5 Prisoner’s Dilemma

We now apply the results from previous chapters to the Prisoner’s
Dilemma, thus expanding Example 3.2 .

First we will observe the following regarding a larger class of games:

###### Lemma 5.1

Assume player @xmath has only two actions @xmath and @xmath . Then
@xmath , for @xmath , @xmath , and for @xmath , @xmath .

Proof: @xmath , and therefore @xmath . Because there are only two
actions, @xmath , and therefore if @xmath then from the definition of
@xmath it follows that @xmath . If @xmath , it follows that @xmath . In
this case the inequality @xmath can be checked arithmetically, but one
can observe that if @xmath then player @xmath does not profit by
deviating when the profile @xmath is played, therefore the deviation
that leads to @xmath is more profitable for him then the deviation that
leads to @xmath .

Because @xmath , if @xmath we have @xmath or @xmath , which implies that
@xmath . @xmath

###### Corollary 5.2

1.   Let @xmath for @xmath . If both players have only two actions, then
    to verify that @xmath is a Bayesian equilibrium, one only needs to
    verify that @xmath for every @xmath for @xmath .

2.  @xmath is an equilibrium.

Note that in the last case both players cooperate whenever the fact that
both players have high enough discount factor is a common- @xmath
-belief.

Proof:

1.  This follows from Theorem 3.3 , Lemma 4.5  (1) and Lemma 5.1 .

2.  Assume there exists @xmath such that @xmath . Denote @xmath and
    @xmath . From the assumption, @xmath for every @xmath for @xmath ,
    in contradiction to the maximality property of @xmath as shown in
    Lemma 4.5 (1). @xmath

###### Remark 5.3

If we define @xmath to be at least 1 outside @xmath (see Remark 3.6
(3)), Corrolary 5.2 holds for every game which satisfies @xmath for
@xmath .

It is easy to calculate that for Prisoner’s Dilemma with the payoffs as
in Example 3.2 , @xmath . Therefore, from the last corollary we have:

###### Corollary 5.4

Let @xmath be the repeated Prisoner’s Dilemma where each player has
incomplete information regarding the other player’s discount factor.
Define @xmath . Then the pair of strategies where each player plays as
follows: If you @xmath -believe that it is a common- @xmath -belief that
@xmath , play the grim-trigger course of action. Otherwise, always
defect, is an equilibrium.

Therefore, both players will cooperate when @xmath is a common- @xmath
-belief.

Note that there cannot be larger events than @xmath such that the
strategy profile @xmath is an equilibrium, but it may be an equilibrium
with smaller ones. See next section for examples.

## 6 Examples

In all the examples in this section, @xmath , and we interpret the
coordinates of @xmath as the players’ discount factors, i.e. @xmath . In
all the examples each player knows his own discount factor (i.e., player
@xmath knows coordinate @xmath of @xmath ), and their belief regarding
the other player’s discount factor depends only on their own discount
factor.

In examples 6.1 - 6.4 , @xmath is the repeated Prisoner’s Dilemma, with
different information structures. In these examples corollaries 5.2 and
5.4 hold.

In the following example @xmath , and therefore we get the equilibrium
of Corollary 5.4 , but we can also get an equilibrium with smaller sets.

###### Example 6.1

Let @xmath , and each player assumes a uniform distribution on the other
player’s discount factor (regardless of his own discount factor).
Equivalently, there is a common-prior of uniform distribution on @xmath
.

Because @xmath , it follows that @xmath and @xmath . Therefore we get
that for every @xmath , @xmath . Since @xmath we get @xmath . Similarly,
@xmath , and therefore @xmath . From Corollary 5.4 we get that

  -- -------- --
     @xmath   
  -- -------- --

defines a Bayesian equilibrium.

Set @xmath and @xmath , then @xmath for every @xmath . Since @xmath , we
get @xmath . Similarly, @xmath ,and therefore @xmath . To use Corollary
5.1 (1) we need to verify that @xmath for every @xmath . If @xmath then
@xmath , and indeed in @xmath . Therefore,

  -- -------- --
     @xmath   
  -- -------- --

also defines a Bayesian equilibrium.

In the following example @xmath , and therefore we get the equilibrium
of Corollary 5.4 , but there are no smaller non-empty sets that define a
Bayesian equilibrium.

###### Example 6.2

Let @xmath and @xmath be as in the Example 6.1 , but change the beliefs
as follows for @xmath : If @xmath , player @xmath believes that @xmath ,
if @xmath he believes that @xmath with probability @xmath and that
@xmath with probability @xmath , and if @xmath he believes that @xmath
is uniform distributed over @xmath . Thus, each player believes that the
other player has a discount factor at least as high as his own.

@xmath is the same as in Example 6.1 , and @xmath so that

  -- -------- --
     @xmath   
  -- -------- --

defines a Bayesian equilibrium.

If we take @xmath as in Example 6.1 we still get @xmath , but now @xmath
for @xmath . Therefore

  -- -------- --
     @xmath   
  -- -------- --

does not define a Bayesian equilibrium. Similarly, @xmath is not a
Bayesian equilibrium for any non-empty @xmath -measurable events @xmath
(a strict subset), @xmath .

In the following example @xmath , and therefore there is no Bayesian
equilibrium with cooperation of the type described here.

###### Example 6.3

Let @xmath , and @xmath . Each player knows his own discount factor, and
if @xmath player @xmath believes that @xmath with probability higher
than @xmath (the rest of the beliefs are irrelevant). Here @xmath , and
so @xmath for @xmath . Therefore @xmath and @xmath , so that we do not
get an equilibrium with cooperation of the type @xmath (because @xmath
is the largest set where such an equilibrium is possible, and here it is
empty, we cannot get it for any set). Note that according to Corollary
5.2 @xmath is an equilibrium, but in this case, because @xmath , it’s
the trivial equilibrium in which the players always defect in every
state of the world @xmath .

In the following example @xmath but @xmath , as was in the previous
examples whenever @xmath was non-empty.

###### Example 6.4

Let @xmath , and assume that each player believes that the other
player’s discount factor is uniformly distributed, regardless of his own
discount factor. @xmath is the Borel @xmath -algebra over @xmath .
@xmath contains the sets @xmath , for every Borel set @xmath , and
@xmath contains the sets @xmath , for every Borel set @xmath .

Here @xmath and @xmath . We will see that @xmath , i.e., a strict subset
of @xmath (and an analog statement holds for player 2): because @xmath
for every @xmath , and @xmath we deduce that @xmath . Therefore @xmath
for every @xmath , and because @xmath we deduce that @xmath . We
continue the same way and deduce that for every @xmath there is @xmath
such that @xmath : @xmath for every @xmath , and because @xmath we
deduce that @xmath . Therefore @xmath . One can easily check that indeed
@xmath for every @xmath for @xmath . Note that here the construction of
@xmath requires an infinite number of steps - for every @xmath we have
@xmath .

From Corollary 5.4 we deduce that

  -- -------- --
     @xmath   
  -- -------- --

defines a Bayesian equilibrium.

In examples 6.5 - 6.6 , @xmath is the following repeated game:
[]
with @xmath (payoffs not indicated can be arbitrary). Here @xmath ,
@xmath , and @xmath . In these examples Theorem 4.6 holds, with @xmath ,
@xmath and @xmath .

In the following example @xmath for @xmath but these sets does not
satisfy the conditions in Theorem 4.6 (or equivalently those in Theorem
3.3 ). Moreover, we prove that in this example there are no non-empty
@xmath such that @xmath is a Bayesian equilibrium.

###### Example 6.5

Let @xmath , the belief space as in Example 6.4 . Here @xmath and @xmath
, and because @xmath for every @xmath , @xmath and therefore @xmath .
But, for @xmath , @xmath and therefore the second condition of
Proposition 3.3 does not hold, and @xmath does not define a Bayesian
equilibrium, unlike previous examples.

Now we prove that there are no non-empty @xmath such that @xmath is a
Bayesian equilibrium. Suppose that @xmath is a Bayesian equilibrium, and
that @xmath are non-empty cooperation events. Denote, for @xmath ,
@xmath . Since @xmath , @xmath . Note that since the beliefs are derived
from the uniform distribution, @xmath is independent of the state of the
world @xmath , so we denote it by @xmath . From the first inequality of
Theorem 3.3 , we have @xmath for every @xmath , and since @xmath is
continuous, @xmath . We now argue that if @xmath , then @xmath .
Otherwise we have, from the second inequality of Theorem 3.3 , that
@xmath . But @xmath , since @xmath , in contradiction. Therefore we have
that @xmath . Next, we argue that @xmath . Otherwise @xmath , and there
is a state of the world @xmath such that @xmath . From the definition of
@xmath , we have @xmath , but then we should have @xmath in
contradiction. We conclude that @xmath for @xmath . Because @xmath , we
have that @xmath , or equivalently, @xmath , in contradiction to @xmath
for @xmath .

In the following example @xmath and does not satisfy the condition in
Theorem 4.6 , but for a smaller non-empty set, the conditions hold, and
therefore define a Bayesian equilibrium.

###### Example 6.6

Let @xmath , and @xmath with a common-prior of uniform distribution.
Here @xmath and therefore @xmath . As in the Example 6.5 , @xmath but
the second condition of Proposition 3.3 does not hold because of @xmath
: @xmath .

For @xmath , we get @xmath and the second condition of Proposition 3.3
does hold (this can easily be verified by calculation). Therefore

  -- -------- --
     @xmath   
  -- -------- --

defines a Bayesian equilibrium.

## 7 @xmath-Equilibria

In this section, we generalize the results from the previous chapters,
for the case of @xmath -equilibria.

First, we prove the following conditions for Bayesian @xmath
-equilibrium with cooperation, similar to Theorem 3.3 :

###### Theorem 7.1

Let @xmath . In the game @xmath , the strategy profile @xmath , such
that @xmath and @xmath , is an @xmath -equilibrium for every @xmath if
and only if, for @xmath ,

1.  @xmath for every @xmath ,

2.  @xmath for every @xmath .

@xmath and @xmath are @xmath -measurable functions that will be
described in the proof, and they tend to @xmath and @xmath when @xmath
tends to 0.

Proof: The proof is similar to the proof of Theorem 3.3 , with the same
options for deviation in each case, and the payoffs are the same, only
here we assume @xmath instead of @xmath .
Case 1: @xmath .

-   Deviation to @xmath — in this case @xmath trivially holds since
    @xmath for every @xmath .

-   Deviation to @xmath — here instead of inequality ( 3.3 ) we get

      -- -------- -------- -- -- -----
         @xmath                  
         @xmath   @xmath         (5)
      -- -------- -------- -- -- -----

    or equivalently @xmath where @xmath is defined by:

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath .

Case 2: @xmath .

-   Deviation to @xmath — here instead of inequality ( 3.3 ) we get

      -- -------- -------- -- --
         @xmath               
         @xmath   @xmath      
      -- -------- -------- -- --

    or equivalently @xmath , where

      -- -------- --
         @xmath   
      -- -------- --

    and @xmath .

-   Deviation to @xmath — here instead of inequality ( 3.3 ) we get

      -- -------- -------- -- --
         @xmath               
         @xmath   @xmath      
      -- -------- -------- -- --

    or equivalently @xmath where

      -- -------- --
         @xmath   
      -- -------- --

    whenever @xmath and @xmath otherwise.

-   Deviation to @xmath — here instead of inequality ( 3.3 ) we get

      -- -------- -------- -- --
         @xmath               
         @xmath   @xmath      
      -- -------- -------- -- --

    or equivalently @xmath where

      -- -- --
            
      -- -- --

    and

      -- -------- --
         @xmath   
      -- -------- --

Set @xmath . The proof that @xmath and @xmath are @xmath -measurable is
the same as in the proof of Theorem 3.3 . @xmath

###### Remark 7.2

Note that the conditions given in this theorem are under the assumption
that @xmath and @xmath , and therefore the theorem does not describe
necessary conditions for @xmath to be an @xmath -equilibrium. For
example, define @xmath and @xmath . Then, when the information regarding
the discount factors is complete, @xmath is an @xmath -equilibrium, but
generally @xmath for @xmath .

###### Corollary 7.3

Theorem 4.6 holds for @xmath -equilibrium with the following
adjustments: First, instead of @xmath and @xmath there should be @xmath
and @xmath ; and second, in the second part of the theorem, the
assumption that @xmath for @xmath should be added.

Proof: The proof is exactly like the proof of Theorem 4.6 . @xmath

The following lemma shows that to @xmath -believe in an event or to
@xmath -believe in an event are weaker demands than to @xmath -believe
in an event, for @xmath sufficiently large. This property will be used
in Section 8 .

###### Lemma 7.4

Let @xmath for @xmath . For @xmath small enough, there exist constants
@xmath such that @xmath for every @xmath and @xmath for every @xmath .

Proof: Let @xmath be player @xmath ’s best response to @xmath in @xmath
, and @xmath the worst response. It follows, from the definition of
@xmath , that

  -- -------- --
     @xmath   
  -- -------- --

Denote @xmath . There exist @xmath such that, for every @xmath , @xmath
. Therefore, for every @xmath such that @xmath , @xmath . If @xmath , we
get that

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

and therefore @xmath . For @xmath small enough we will get @xmath for
every @xmath . @xmath for every @xmath if @xmath . From the definitions
of @xmath , @xmath and @xmath we get that, for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Therefore @xmath for every @xmath . @xmath

Next, we generalize the results of Section 5 to @xmath -equilibria in
games where both players have only two actions.

The following lemma is the @xmath -equilibrium equivalent of Lemma 5.1 :

###### Lemma 7.5

Assume player @xmath has only two actions @xmath and @xmath . Then, for
every @xmath , @xmath , for @xmath , @xmath , and for @xmath , @xmath
and @xmath .

Proof: All the results, except @xmath for @xmath , follow from Lemma 5.1
, since @xmath for @xmath and @xmath . The same reasoning that shows
@xmath for @xmath , @xmath . @xmath

The following corollary is the @xmath -equilibrium equivalent of
Corollary 5.2 :

###### Corollary 7.6

1.   Let @xmath for @xmath . If both players have only two actions, then
    to verify that @xmath is a Bayesian @xmath -equilibrium, it is
    sufficient to verify that @xmath for every @xmath for @xmath .

2.  @xmath is an @xmath -equilibrium.

Proof:

1.  This follows from Theorem 7.1 , Lemma 4.5  (1) and Lemma 7.5 .

2.  The proof is similar to the proof of Corollary 5.2 (2), only now it
    follows from Corollary 7.6  (1) instead from Corollary 5.2 (1).
    @xmath

## 8 “Almost” Complete Information

In this section we look at belief spaces that are “almost” complete, in
several senses, and see whether the cooperation events when the
information is almost complete are close to the cooperation events when
the information is complete.

### 8.1 Knowing Approximately the Discount Factors

The first sense of “almost” complete information we consider, is when
each player knows the other’s discount factor, up to a range of @xmath .
That is, player @xmath knows his own discount factor, and is given a
signal @xmath so he knows that player @xmath ’s discount factor is
between @xmath and @xmath . As the following example shows, in this case
the cooperation events are significantly different from the complete
information cooperation events, even in the repeated Prisoner’s Dilemma,
regardless of @xmath , and even if we consider only @xmath -equilibrium
for some @xmath .

###### Example 8.1

Let @xmath be the repeated Prisoner’s Dilemma. Let @xmath , @xmath is
the Borel @xmath -algebra, and as in previous examples, @xmath for every
@xmath . Each player knows his own discount factor, and believes that
the other’s discount factor is within @xmath of his own; if @xmath ,
then player @xmath believes that @xmath is uniformly distributed in
@xmath (with cutoffs if one side exceeds @xmath or @xmath ). Again,
@xmath and @xmath . We will show that @xmath regardless of @xmath (for
@xmath small enough):

Let @xmath . Because @xmath is a continuous monotonically-decreasing
function, and because @xmath , there exists @xmath such that @xmath .
Therefore, any state of the world @xmath such that @xmath is not in
@xmath . That is because for such states of the world @xmath , one has
@xmath . Therefore, for some @xmath , @xmath , and similarly for player
2. Therefore, any state of the world @xmath such that @xmath is not in
@xmath by the same reasoning, and @xmath for @xmath . We continue until
we get that any state of the world @xmath such that @xmath is not in
@xmath . This is true for every @xmath . Because @xmath tends to @xmath
as @xmath tends to @xmath , @xmath (similarly for player 2). The
equality follows from Lemma 4.5 (1), because @xmath and @xmath fulfill
the inequality.

We get from Corollary 5.4 that

  -- -------- --
     @xmath   
  -- -------- --

defines a Bayesian equilibrium and that there is not such an equilibrium
with larger sets of cooperation, regardless of @xmath . Therefore, under
this profile the players cooperate when both discount factors are no
less than @xmath , regardless of @xmath , whereas is the complete
information case they can cooperate whenever both discount factors are
no less than @xmath (see Example 3.2 ).

Note that this analysis does not change if @xmath , which verifies that
the true state of the world is within the support of the beliefs of the
players. Also, if for every state of the world @xmath player @xmath
believes that @xmath is distributed in any non-atomic symmetric way
around @xmath , the result still holds.

For a Bayesian @xmath -equilibrium we follow the same route, with @xmath
instead of @xmath (see Corollary 7.6 (2)). Instead of a threshold of
@xmath , we show that @xmath . That is because @xmath . We get a lower
threshold, which is still independent of @xmath , and, for low enough
@xmath , higher than @xmath .

### 8.2 The True Discount Factors are Common-@xmath-Belief in Most
States of the World

In this section we assume a common prior @xmath over the states of the
world.

###### Definition 8.2

Let @xmath . We say that the discount factors are almost complete
information with respect to @xmath and @xmath , if the set of states of
the world in which the true discount factors are common- @xmath -belief
has probability at least @xmath .

From Theorem B in Mondrer and Samet (1989), we have that if the number
of states of the world is finite, then in this case there are a strategy
profile @xmath and an event @xmath with probability at least @xmath ,
such that: (a) @xmath for every @xmath ; and (b) @xmath is an @xmath
-equilibrium for @xmath ( @xmath is the maximum of the absolute value of
the payoffs in the repeated game, taken over all the discount factors).
In other words, there is an @xmath -equilibrium profile that coincides
over a large set with the conditional-grim-trigger equilibrium of
maximum cooperation in the complete information case.

However, as Example 8.3 shows, this profile @xmath may not be a
conditional-grim-trigger profile. It shows that there may be no
conditional-grim-trigger @xmath -equilibria whatsoever, unless there are
only two actions for each player (see Corollary 8.5 ).

###### Example 8.3

Let @xmath be the game as in Example 6.6 . Let the information structure
be as follows: each player has two possible discount factors. That is,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the higher discount factor of player @xmath , and @xmath
the lower one. Assume @xmath for @xmath . In every state of nature, each
player gets a signal regarding the other player’s discount factor, which
may be either @xmath or @xmath , that is @xmath , the first two
coordinates are the discount factors, and the last two are the signals.
Each player knows only his discount factor and his signal.
The common prior on @xmath is as follows: the state of nature is chosen
according to the distribution

  -- -------- --
     @xmath   
  -- -------- --

In every state of nature, there is a probability @xmath that both the
signals are correct, and the other three states of the world that
correspond to this state of nature have equal probability @xmath . For
example, if @xmath is chosen, the distribution over the states of the
world is

  -- -------- --
     @xmath   
  -- -------- --

Assume that @xmath .
We now calculate the beliefs of player 1, up to normalization, that is,
the sum of the coefficients in the following equations may not be 1.
From symmetry, the beliefs of player 2 are similar.

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Note that for @xmath , which happens with probability @xmath , the true
state of nature is a common- @xmath -belief, and therefore the discount
factors are almost complete information with respect to @xmath and
@xmath , according to Definition 8.2 .

We now prove that there is no conditional-grim-trigger @xmath
-equilibrium for small enough @xmath , independent of @xmath and @xmath
. Let @xmath be such that @xmath and @xmath for @xmath . These
inequalities are satisfied by @xmath low enough, since (a) @xmath ,
@xmath , and (b) @xmath and @xmath because @xmath . Note that since
@xmath for @xmath , we have @xmath and @xmath . Assume also that for
@xmath , @xmath (we assumed @xmath so @xmath ). In this case Inequality
( 7 ) does not hold for @xmath , for any @xmath . Suppose @xmath is an
@xmath -equilibrium profile with non-trivial cooperation events. Since
In this case Inequality ( 7 ) does not hold for player @xmath when his
discount factor is @xmath , we have @xmath for @xmath , and so the
conditions of Theorem 7.1 holds. Suppose that @xmath . Then @xmath for
@xmath low enough, which is a contradiction since @xmath . Therefore
@xmath , an by a similar argument @xmath . But then we have @xmath for
low enough @xmath , in contradiction to @xmath being an @xmath
-equilibrium. Therefore there is no conditional-grim-trigger @xmath
-equilibrium profile with non-trivial cooperation events.

The following lemma is a result of this concept of almost complete
information:

###### Lemma 8.4

Set @xmath and @xmath , and assume that the discount factors are almost
complete information with respect to @xmath and @xmath . Then @xmath .

Proof: Denote @xmath . From our assumption @xmath . Since @xmath , we
have @xmath . @xmath

In the case where each player has two actions, Lemma 8.4 implies that
there is an @xmath -equilibrium with cooperation events close to @xmath
:

###### Corollary 8.5

Suppose each player has two actions. Let @xmath and @xmath and @xmath .
Assume that the discount factors are almost complete information with
respect to @xmath and @xmath . Then, for every @xmath , the strategy
profile @xmath is an @xmath -equilibrium, and @xmath .

Proof: From Corollary 7.5 (2) we have that @xmath is an @xmath
-equilibrium. From Lemma 7.4 we have that @xmath for every @xmath .
Therefore @xmath , so from Lemma 8.4 we have that @xmath . @xmath

### 8.3 Each Player @xmath-Believes that a State of Nature is
Common-@xmath-Belief

In this section we assume that the information is almost complete in a
different sense:

###### Definition 8.6

Let @xmath . We say that the discount factors are almost complete
information with respect to @xmath , if for every state of the world
@xmath , each player @xmath -believes in @xmath that some state of
nature is common- @xmath -belief in @xmath .

We show that when the discount factors are almost complete information
with respect to @xmath , according to Definition 8.6 , there is a simple
conditional-grim-trigger profile, which is an @xmath -equilibrium for
@xmath ( @xmath is a constant which depends only on the game and not on
the information structure). While this assumption can hold without the
information structure derived from a common prior on the state of the
world, we show that if it does, this concept of almost complete
information is stronger than the concept in Definition 8.2 . Also, under
this assumption (with the common prior), in the simple
conditional-grim-trigger @xmath -equilibrium mentioned above the players
cooperate in all the states of the world in which there is a cooperation
under the conditional-grim-trigger equilibrium of maximum cooperation in
the complete information case, @xmath , but for a set with small
probability. In other words, under a stronger concept of almost complete
information, we have a result which is quite similar to the one in
Theorem B of Mondrer and Samet (1989), but with a
conditional-grim-trigger profile which is defined explicitly for every
state of the world.

###### Proposition 8.7

Let @xmath . Assume that the discount factors are almost complete
information with respect to @xmath , according to Definition 8.6 . Then,
the strategy profile @xmath is an @xmath -equilibrium, for every @xmath
, where @xmath is a constant, independent of the information structure
and of @xmath .

Proof: Denote @xmath . Note that @xmath for @xmath . From Lemma 7.4 ,
there is an @xmath such that for every @xmath and @xmath , we have
@xmath for every @xmath and @xmath for every @xmath .

For every @xmath , we have @xmath . For every @xmath , we have from our
assumption that player @xmath @xmath -believes in @xmath that some state
of nature is a common- @xmath -belief in @xmath , but this state of
nature is not in @xmath . Therefore, @xmath . Therefore we have

  -- -------- --
     @xmath   
  -- -------- --

From Theorem 7.1 we have that @xmath is an @xmath -equilibrium. @xmath

###### Remark 8.8

1.   Under this strategy profile, both players will cooperate if and
    only if @xmath , since @xmath .

2.  @xmath may be empty, and then @xmath a trivial profile with no
    cooperation.

###### Proposition 8.9

Let @xmath . Assume that (a) the information structure is derived from a
common prior @xmath ; (b) the discount factors are almost complete
information with respect to @xmath , according to Definition 8.6 ; and
(c) the number of state of nature is finite or countable. Then the
discount factors are almost complete information with respect to @xmath
and @xmath according to Definition 8.2 .

Proof: Denote by @xmath the set of states of the world @xmath such that
there is a state of nature which is a common- @xmath -belief in @xmath .
From assumption (b) we have that for every state of the world @xmath ,
@xmath . Therefore @xmath . For every state of nature @xmath , denote
@xmath , and @xmath . Our goal is to show that @xmath . This is shown in
the proof of Theorem B of Mondrer and Samet (1989). @xmath

From Propositions 8.7 and 8.4 , Remark 8.8 and Lemma 8.4 we conclude the
following, which is the generalization of Corollary 8.5 for games with
more than two actions for each player:

###### Corollary 8.10

Let @xmath . Assume that (a) the information structure is derived from a
common prior @xmath ; (b) the discount factors are almost complete
information with respect to @xmath , according to Definition 8.6 ; and
(c) the number of state of nature is finite or countable. Then (A) the
strategy profile @xmath is an @xmath -equilibrium, for every @xmath ,
where @xmath is a constant, independent of the information structure and
of @xmath ; (B) under this strategy profile, both players will cooperate
if and only if @xmath ; and (C) @xmath .

###### Example 8.11

Let @xmath , @xmath and @xmath be as in Example 8.3 . The common prior
is as follows: the state of nature is chosen uniformly. In every state
of nature, there is a probability @xmath that both the signals are
correct, and the other three states of the world that correspond to this
state of nature have equal probability @xmath . For example, if @xmath
was chosen, the distribution over the states of the world is

  -- -------- --
     @xmath   
  -- -------- --

We now calculate the beliefs of player 1. From symmetry, the beliefs of
player 2 are similar.

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Note that indeed, for every state of the world @xmath , each player
@xmath -believes in @xmath that some state of nature is a common- @xmath
-belief in @xmath , so the discount factors are almost complete
information with respect to @xmath , according to definition 8.6 .

As in Example 8.3 , @xmath and @xmath , and so @xmath . Therefore @xmath
, and so @xmath and @xmath . Therefore, from Corollary 8.10 we conclude
that @xmath is an @xmath -equilibrium for every @xmath . Under this
strategy profile each player cooperates if both his discount factor and
his signal are high, and both players cooperate if the state of the
world is @xmath . Indeed, as in Corollary 8.10 , we have that @xmath .

Note that if @xmath and @xmath are high enough, we have @xmath for every
@xmath , and therefore @xmath for @xmath , and @xmath . This implies
that @xmath may be an equilibrium or an @xmath -equilibrium with larger
cooperation events. But, if @xmath is small enough, we have @xmath , so
the second condition of Theorem 7.1 does not hold and @xmath in not an
@xmath -equilibrium.

## 9 Generalizations

In this section we generalize the results of the previous sections in
several ways. First, we see that the main result (Theorem 3.3 ) holds,
with some adjustments, even when each player does not know his own
discount factor. Second, we generalize Theorem 3.3 for general games
with incomplete information, with respect to a course of action that is
an equilibrium in every state of the world (equivalent to @xmath ), and
a course of action that is an equilibrium only in some states of the
world (equivalent to @xmath ). Last, we analyze the case of repeated
games with incomplete information on the discount factor with more than
two players.

### 9.1 The Results when One’s Own Discount Factor is Unknown

In this section we assume that each player does not know his own
discount factor in every state of the world. In this case, most of the
arguments in the proof of Theorem 3.3 still hold, with the following
adjustments. In order to avoid measurability problems, we assume in this
section that @xmath is finite or countable, @xmath is the power set of
@xmath , and @xmath is generated by the “types” of player @xmath .

When calculating the expected payoffs, we cannot take @xmath out of the
expectation, since @xmath is no longer known to player @xmath given
@xmath . For example, instead of:

  -- -------- --
     @xmath   
  -- -------- --

when @xmath , the expected payoff is:

  -- -- --
        
  -- -- --

Similarly, @xmath is no longer the set @xmath , which is no longer
necessarily an @xmath -measurable set.
Rather @xmath . That is the set of states of the world in which player
@xmath believes he cannot profit by deviating from the profile @xmath .

The main adjustment in Theorem 3.3 itself is that it is not necessary
that @xmath . Indeed, this requirement was derived from the inequality:

  -- -------- --
     @xmath   
  -- -------- --

and because @xmath , it follows that either @xmath or @xmath .

When one’s own discount factor is unknown, this inequality becomes

  -- -------- --
     @xmath   
  -- -------- --

but here @xmath is weaker than @xmath . Therefore, there may be games
such that there are events @xmath such that @xmath is a Bayesian
equilibrium, but then the conditions are different from these of Theorem
3.3 — if @xmath , player @xmath may have to @xmath -believe in @xmath in
the state of the world @xmath , for a certain function @xmath , since he
has a profitable deviation from @xmath in @xmath . This may be in in
addition to @xmath -believing in @xmath in the state of the world @xmath
. See Example 9.3 .

Under the assumption that @xmath for @xmath , the rest of the proof does
not change, and so we get the following result.

###### Theorem 9.1

In the game @xmath , the strategy profile @xmath , such that @xmath and
@xmath , is a Bayesian equilibrium, if and only if, for @xmath ,

1.  @xmath for every @xmath ,

2.  @xmath for every @xmath .

The functions @xmath and @xmath are the same as before, with the natural
adjustments; for example, instead of:

  -- -------- --
     @xmath   
  -- -------- --

now we have:

  -- -------- --
     @xmath   
  -- -------- --

Note also that the sets over which the maxima and minima are taken when
calculating @xmath and @xmath may change according to the same
adjustments.

###### Remark 9.2

-    Note that because now we assume that @xmath for @xmath , we can
    omit the assumption that @xmath is not a best response to @xmath ,
    retaining only the weaker assumption that @xmath is not in the
    support of @xmath .

-    Because of that, as mentioned in Remark 3.5 (2), we may get that
    @xmath . This may also be the case even if @xmath is not a best
    response to @xmath (which was not the case in the original theorem,
    see Remark 3.6 (2)). That happens if and only if the distribution
    @xmath such that @xmath .

-    In this case, the functions @xmath and @xmath have a slightly
    different form if we take the payoffs as @xmath (with the @xmath in
    the expectation). The only significant difference is that in this
    case the payoffs are bounded and therefore Remark 3.6  (2) still
    holds.

The following example shows that the assumption @xmath for @xmath in
Theorem 9.1 cannot be omitted — @xmath may be a Bayesian equilibrium
without this assumption, but then the conditions are quite different.

###### Example 9.3

Consider the following game:
[]
(payoffs not indicated can be arbitrary). Here @xmath , @xmath . Both
players have the same discount factor, that can be either @xmath or
@xmath , so that @xmath . Let the information structure be the
following: @xmath , where @xmath are the possible signals of player
@xmath . Denote the signal that player @xmath receives by @xmath . The
first coordinate is the common discount factor in each state of the
world, that is @xmath . Each player knows only his own signal, and his
beliefs are as follows: If player @xmath gets the signal @xmath he
believes that the state of the world is @xmath : the discount factor is
@xmath and this fact is common belief. If player @xmath gets the signal
@xmath he believes that the state of the world is @xmath : the discount
factor is @xmath and this fact is common belief. If player @xmath gets
the signal @xmath , he believes that the state of the world is @xmath
with probability @xmath , and @xmath with probability @xmath , where
@xmath .

The best deviation from @xmath is to play @xmath in the first stage and
from the second stage on to play @xmath . This deviation is profitable
for player @xmath if and only if @xmath , that is if @xmath . Since
@xmath , it follows that @xmath .

Denote @xmath . We prove that @xmath is a Bayesian equilibrium, even
though @xmath . Because the game, the information structure and @xmath
are symmetric, it is sufficient to show that there is no profitable
deviation for player 1. If player 1’s signal is @xmath , he believes
that it is a common belief that @xmath , and that player 2 plays @xmath
. Since in this case @xmath , there is no profitable deviation from
@xmath for player 1. If player 1’s signal is @xmath , he believes that
player 2 always plays @xmath , and therefore player 1 cannot profit from
deviating from @xmath (which in this case is “always play @xmath ”). If
player 1’s signal is @xmath , he plays @xmath . Similar to the proof of
Theorem 3.3 , to prove that there is no profitable deviation, two
inequalities have to be satisfied:

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -- --
        
  -- -- --

for @xmath or @xmath . For @xmath , the first inequality holds since
@xmath with probability 1 (it is the same inequality as in the
prisoner’s dilemma, where @xmath ). The second inequality is equivalent
to @xmath . For @xmath , the first inequality holds since @xmath . The
second inequality is equivalent to @xmath . Therefore, we have that
@xmath is a Bayesian equilibrium if and only if @xmath and @xmath . The
first inequality holds for high enough @xmath , which is similar to the
first condition in Theorem 9.1 , but the second inequality only holds
for low enough @xmath , which is a significantly different condition (it
is @xmath -believing in @xmath in addition to @xmath -believing in
@xmath ).

To complete the proof that @xmath , observe that when @xmath , we have
@xmath . Therefore @xmath is equivalent to @xmath . Since @xmath , we
have @xmath , so @xmath , and @xmath for every @xmath . Similarly,
@xmath is equivalent to @xmath , which holds for every @xmath .

Our results regarding games with only two actions for each player does
not hold in this more general case. Lemma 5.1 does not hold in this
case: @xmath , @xmath for every @xmath , and @xmath for every @xmath
still hold, but @xmath needs not be 1 for every @xmath . Therefore,
Corollary 5.2 does not hold in this case.

### 9.2 General games

In this subsection we expand Theorem 3.3 to a broader class of
two-players Bayesian games (not only repeated games with incomplete
information regarding the discount factors). While up till now we
assumed that the sets of actions @xmath and the payoff functions @xmath
are independent in the state of the world, now it is not the case: for
every @xmath , @xmath is the set of the actions of player @xmath in the
state of the world @xmath , and @xmath is his payoff.

Let @xmath be a general two-player Bayesian game. To avoid measurability
problems, assume that the states of the world are finite or countable.
Assume that there is a course of action profile @xmath such that, when
the information is complete, is an equilibrium for all states of nature,
and that there is another course of action profile, @xmath which is an
equilibrium in only some states of nature. Suppose that the supports of
@xmath and @xmath are disjoint in all states of the world, that is, it
is discernable whether player @xmath plays @xmath or @xmath . A strategy
of player @xmath is an @xmath -measurable function that assigns each
state of the world a course of action of player @xmath .

Let @xmath be the event “player @xmath believes that he cannot benefit
by deviating from the profile @xmath ”. That is, for every @xmath and
every course of action @xmath of player @xmath , @xmath .

###### Theorem 9.4

In the game @xmath , there exist @xmath -measurable functions @xmath ,
@xmath , such that if @xmath and @xmath , the strategy profile @xmath ,
is a Bayesian equilibrium, if and only if, for @xmath ,

1.  @xmath for every @xmath ,

2.  @xmath for every @xmath .

###### Remark 9.5

There are several differences between the results of this theorem and
Theorem 3.3 :

-    Here we assume that @xmath and @xmath whereas in Theorem 3.3 we
    showed it was necessary for @xmath to be a Bayesian equilibrium.
    This weakened result allows us to drop the assumption that @xmath is
    not a best response to @xmath , and only requires that it is
    discernable whether player @xmath plays @xmath or @xmath (disjoint
    supports). ⁷ ⁷ 7 Still, as before, if we do assume that @xmath is
    not a best response to @xmath , we get @xmath , assuming that the
    payoffs in @xmath are bounded.

-    We do not assume that the realized payoffs are observed, so that
    all a player knows is his an expected payoff based on his
    information on the states of nature.

-    We do not assume that the payoffs when @xmath is played are higher
    than when @xmath is played.

Proof of Theorem 9.4 : Similar to the proof of Theorem 3.3 , we have two
cases.

Case 1 : @xmath .

The payoff of player @xmath when @xmath is played is

  -- -------- --
     @xmath   
  -- -------- --

If player @xmath deviates to a course of action @xmath , then his payoff
is

  -- -------- --
     @xmath   
  -- -------- --

Because @xmath is a Bayesian equilibrium, @xmath for every @xmath , or

  -- -------- -- -----
     @xmath      
     @xmath      (6)
  -- -------- -- -----

for every @xmath . By assumption @xmath , so that @xmath . If @xmath ,
then inequality ( 9.2 ) trivially holds. Otherwise, inequality ( 9.2 )
is equivalent to @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

and @xmath .

Case 2 : @xmath .

The payoff of player @xmath under @xmath is

  -- -------- --
     @xmath   
  -- -------- --

If player @xmath deviates to a course of action @xmath , then his payoff
is

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is a Bayesian equilibrium,

@xmath for every @xmath , or equivalently

  -- -------- -- -----
     @xmath      
     @xmath      (7)
  -- -------- -- -----

for every @xmath . Because @xmath is an equilibrium in every state of
nature, @xmath . Therefore, if @xmath , inequality ( 9.2 ) trivially
holds. Otherwise, inequality ( 9.2 ) is equivalent to @xmath where

  -- -------- --
     @xmath   
  -- -------- --

and @xmath . @xmath

### 9.3 More than Two Players

In this section we show that while the same analysis can be used to
derive necessary and sufficient conditions for conditional-grim-trigger
equilibria in repeated games with incomplete information on the discount
factors with more than two players, these conditions are much more
complex than in two player games. We provide simple conditions, similar
to those in previous sections (i.e., @xmath -believing in an event at a
state of the world), which are sufficient for a conditional-grim-trigger
strategy profile to be a Bayesian equilibrium, but are not necessary
(Theorem 9.6 ).

Let @xmath be a one-shot game, with @xmath the set of players. Let
@xmath be a mixed-strategies Nash equilibrium in @xmath . Assume that
the payments in another non-equilibrium pure action profile @xmath , are
higher than the equilibrium payments, that is @xmath for every @xmath .
Also, assume that for every @xmath , @xmath is not in the support of
@xmath .

Let @xmath be the repeated game based on @xmath , with incomplete
information regarding the discount factors, similar to the one described
in Section 2 , where each player knows his own discount factor.

Let @xmath and @xmath be defined as in the two-player case. ⁸ ⁸ 8 When
there are more than two players, @xmath is triggered whenever there is
at least one player that deviate from @xmath . Again, @xmath is an
equilibrium course of action regardless of the discount factors. Player
@xmath does not have a profitable deviation from @xmath if and only if
@xmath , where

  -- -------- --
     @xmath   
  -- -------- --

As before, denote @xmath .

The conditional-grim-trigger strategy is defined in the same way as in
the two-player case, only now there is a cooperation event for eack
player in @xmath , so the strategy profile is @xmath . The following
theorem gives sufficient conditions that guarantee that the profile
@xmath is a Bayesian equilibrium.

###### Theorem 9.6

Suppose that @xmath , for every @xmath . The strategy profile @xmath is
a Bayesian equilibrium in the game @xmath , if, for every @xmath ,

1.  @xmath for every @xmath ,

2.  @xmath for every @xmath .

Where the functions @xmath and @xmath are defined by:

  -- -------- --
     @xmath   
  -- -------- --

and @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and @xmath .

These conditions mean that in order for @xmath to be a Bayesian
equilibrium, player @xmath needs to @xmath -believe in a the event
@xmath whenever he plays @xmath , and to @xmath -believe in the event
@xmath , whenever he plays @xmath . Note that when there are more then
two players, these two events may not be the same.

Proof: The proof follows the same lines as the proof of Theorem 3.3 .
For simplicity, we assume that @xmath . The analysis for games with more
than three players is similar. Without loss of generality, it is
sufficient to prove that player 1 does not have a profitable deviation.

Case 1: @xmath .

Player 1’s payoff under the strategy profile @xmath is

  -- -- --
        
  -- -- --

As in the proof of Theorem 3.3 , we need to consider the following
deviations:

-   Let @xmath , and define the course of action @xmath by: Player 1
    plays @xmath in the first stage, an if the action profile @xmath was
    played in the first stage, player 1 plays a pure action @xmath in
    stage @xmath and @xmath afterwards. If the action profile @xmath was
    not played in the first stage, player 1 plays @xmath from the second
    stage onwards. If player 1 plays @xmath , his payoff is:

      -- -- --
            
      -- -- --

    Since @xmath is a Bayesian equilibrium, @xmath , or equivalently,

      -- -------- --
         @xmath   
      -- -------- --

    for every @xmath . Because @xmath , either @xmath or @xmath , which
    is a similar result to the two-player case.

-   Let @xmath , and define the course of action @xmath by: Player 1
    plays @xmath in the first stage and @xmath afterwards. If player 1
    plays @xmath , his payoff is:

      -- -------- --
         @xmath   
      -- -------- --

    Since @xmath is a Bayesian equilibrium, @xmath , or equivalently,

      -- -------- -- -----
         @xmath      
         @xmath      
         @xmath      
         @xmath      (8)
      -- -------- -- -----

    This is the analogue of inequality ( 3.3 ) in the two-players game,
    only here this condition is not equivalent to a simple @xmath
    -belief type condition.
    However, the left hand side of inequality ( 9.3 ) is no less than

      -- -------- --
         @xmath   
      -- -------- --

    and so it is a sufficient condition that

      -- -------- --
         @xmath   
      -- -------- --

    for every @xmath , which is equivalent to @xmath and @xmath .

Case 2: @xmath .

Player 1’s payoff under the strategy profile @xmath is

  -- -------- --
     @xmath   
  -- -------- --

As in the proof of Theorem 3.3 , we need to consider the following
deviations:

-   Deviation to @xmath , for @xmath ( @xmath may be in the support of
    @xmath , if @xmath is not a pure action). The payoff is:

      -- -------- --
         @xmath   
      -- -------- --

    Since @xmath is a Bayesian equilibrium, @xmath , or equivalently,

      -- -------- -- -----
         @xmath      
         @xmath      
         @xmath      
         @xmath      (9)
      -- -------- -- -----

    This is the analogue of inequality ( 3.3 ) in the two-players game,
    only here this condition is not equivalent to a simple @xmath
    -belief type condition.
    However, the left hand side of inequality ( 9.3 ) is no less than

      -- -------- --
         @xmath   
      -- -------- --

    and so it is a sufficient condition that

      -- -------- --
         @xmath   
      -- -------- --

    for every @xmath , which is equivalent to @xmath .

-   Deviation to @xmath . The payoff is:

      -- -- --
            
      -- -- --

    Since @xmath is a Bayesian equilibrium, @xmath , or equivalently,

      -- -------- -- ------
         @xmath      
         @xmath      
         @xmath      
         @xmath      (10)
      -- -------- -- ------

    This is the analogue of inequality ( 3.3 ) in the two-players game,
    only here this condition is not equivalent to a simple @xmath
    -belief type condition.
    However, the left hand side of inequality ( 9.3 ), multiplied by
    @xmath , is no less than

      -- -------- --
         @xmath   
      -- -------- --

    and so it is a sufficient condition that

      -- -------- --
         @xmath   
      -- -------- --

    which is equivalent to @xmath .

-   Deviation to @xmath , defined by:

    -   Play @xmath in the first stage.

    -   If the profile @xmath was played in the first stage, play a pure
        @xmath , and afterwards @xmath .

    -   If the profile @xmath was not played in the first stage, play
        @xmath from the second stage onwards.

    The payoff is:

      -- -- --
            
      -- -- --

    Since @xmath is a Bayesian equilibrium, @xmath , or equivalently,

      -- -------- -- ------
         @xmath      
         @xmath      
         @xmath      
         @xmath      (11)
      -- -------- -- ------

    This is the analogue of inequality ( 3.3 ) in the two-players game,
    only here this condition is not equivalent to a simple @xmath
    -belief type condition.
    However, the left hand side of inequality ( 9.3 ) is no less than

      -- -------- --
         @xmath   
      -- -------- --

    and so it is a sufficient condition that

      -- -------- --
         @xmath   
      -- -------- --

    which is a weaker condition than @xmath .

The proof that @xmath and @xmath are @xmath -measurable is the same as
in the proof of Theorem 3.3 . @xmath