###### Contents

-    1 Introduction
    -    1.1 History of the averaging problem
        -    1.1.1 The “Special Observer” assumption
-    2 Averaging schemes : Buchert’s spatial averaging
    -    2.1 Buchert’s spatial averaging of scalars
    -    2.2 Acceleration from averaging
        -    2.2.1 Late time and curvature dominated unbound models
-    3 Averaging schemes : Zalaletdinov’s covariant Macroscopic Gravity
    -    3.1 A covariant averaging scheme
    -    3.2 The averaged manifold
    -    3.3 Averaging Einstein’s equations
    -    3.4 A @xmath spacetime splitting and the spatial averaging
        limit
    -    3.5 The correlation @xmath -form and the averaged field
        equations
        -    3.5.1 Results for the Volume Preserving Gauge
        -    3.5.2 Results for an arbitrary gauge choice
    -    3.6 Comparing the approaches of Buchert and Zalaletdinov
-    4 Backreaction in linear perturbation theory
    -    4.1 Metric perturbations in cosmology
        -    4.1.1 Gauge transformations
    -    4.2 The Averaging Operation and Gauge Related Issues
        -    4.2.1 Volume Preserving (VP) Gauges and the Correlation
            Scalars
        -    4.2.2 Choice of VP Gauge
    -    4.3 The Correlation Scalars
    -    4.4 Worked out examples
        -    4.4.1 EdS background and non-evolving potentials
        -    4.4.2 Radiation and CDM without baryons
-    5 Nonlinear structure formation and backreaction
    -    5.1 Spherical Collapse : Setting up the model
        -    5.1.1 Initial conditions
        -    5.1.2 Mass function @xmath and curvature function @xmath
        -    5.1.3 The solution in the region @xmath
        -    5.1.4 Behaviour of the model
        -    5.1.5 Aside : Acceleration from initial conditions
    -    5.2 Transforming to Perturbed FLRW form
        -    5.2.1 The transformation in region 1
        -    5.2.2 The transformation in regions 2 and 3
        -    5.2.3 The magnitude of the backreaction
    -    5.3 Backreaction during nonlinear growth of structure
-    6 Conclusions
-    A Basics of FLRW cosmology
-    B The Lemaître-Tolman-Bondi solution
    -    B.1 Regularity conditions
-    C Cosmology in MG
    -    C.1 Analysis of @xmath
    -    C.2 Analysis of the condition @xmath

## Synopsis

### Introduction

A central assumption in modern cosmology is that the universe on large
scales is homogeneous and isotropic [ 3 ] . This assumption leads to
tremendous simplifications in the application of general relativity (GR)
to cosmology, since it reduces the ten independent components of the
metric of spacetime @xmath to essentially a single function of time
@xmath known as the scale factor. In the early days of modern cosmology,
beginning with stalwarts such as Einstein and deSitter, the assumption
of homogeneity and isotropy was largely motivated on grounds of
simplicity and aesthetic appeal. In recent times however, it has become
possible to confront this assumption with observations, which remarkably
appears to be justified to a large extent (based on observations of the
cosmic microwave background (CMB) radiation [ 5 ] , and on analyses of
galaxy surveys [ 6 , 7 ] ). This indicates that a model based on
essentially a single function of time might in fact go a long way in
furthering our understanding of the behaviour of the universe.

Of course the real universe is not homogeneous; we see a rich variety of
structure around us from stellar systems to galaxies to clusters of
galaxies and even larger structures. The study of the large scale
structure (LSS) in the universe has a long history going back several
decades [ 10 ] . Perhaps one of the biggest successes of cosmological
theory based on GR, has been the explanation of how statistical
properties of the LSS arise [ 11 ] . The relevant calculations are
largely based on linear perturbation theory, in which one describes
inhomogeneities in the universe as perturbations around the smooth
solution characterised by the scale factor @xmath and expands the
Einstein equations as a series in these small perturbations. While such
a treatment has met with great success in the description of the
statistical properties of the tiny fluctuations (anisotropies) in the
temperature of the CMB, there are two causes for concern.

The first is a purely theoretical issue, and is the basis of this work.
The idea that the large scale universe is homogeneous and isotropic
necessarily entails an implicit notion of averaging on these large
scales. In other words, what one is really saying is, ‘‘When the
spatially fluctuating parts of the solution of GR describing our
universe are averaged out, what is left is the homogeneous and isotropic
solution of Einstein’s equations’’ ¹ ¹ 1 This solution is known as the
Friedmann-Lemaître-Robertson-Walker (FLRW) solution after those who
first studied it. . The immediately obvious problem with this statement
is that the details of the averaging operation are not at all clear, and
indeed are usually never specified. A bigger problem is one noted by
Ellis [ 17 ] , and can be stated in the following symbolic way. If
@xmath denotes the metric, @xmath the Christoffel connection and @xmath
the Einstein tensor for the metric @xmath , then we have the relations

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

with @xmath denoting spacetime derivatives. The Einstein equations are
therefore

  -- -------- -- -----
     @xmath      (2)
  -- -------- -- -----

with @xmath denoting the energy-momentum tensor of the matter
components. Now, irrespective of any details of the averaging operation,
one notes that

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

with the angular brackets denoting the averaging. The FLRW solution
would amount to solving the equations @xmath . In general therefore, it
is not true that averaging out the fluctuating inhomogeneities leaves
behind the FLRW solution, since what we are actually left with is

  -- -------- -- -----
     @xmath      (4)
  -- -------- -- -----

and the homogeneous solution that we are looking for will depend on the
details of the correction terms @xmath .

The second cause for concern comes from observations. It has now been
established beyond a reasonable doubt, that the FLRW metric confronted
with observations indicates an accelerating scale factor [ 18 ] .
Conventional sources of energy such as radiation and nonrelativistic
matter cannot explain the acceleration, and it is now common to
attribute this effect to a hitherto unknown “Dark Energy”, which in its
simplest form is a cosmological constant. The true nature of this
additional component in the cosmological equations, is perhaps the most
challenging puzzle facing both theorists and observers today. A huge
amount of research has gone into (a) explaining the value that a
cosmological constant term must take to explain data or (b) assuming a
zero cosmological constant, constructing models of a dynamical dark
energy which explains the observed acceleration [ 19 ] . It is fair to
say however that there is no theoretical consensus on what the origin of
Dark Energy is.

Since we have seen above that the effects of averaging lead to some
extra, as yet unknown terms in the equations, it is natural to ask
whether these two issues are connected. Could the acceleration of the
universe be explained by the effects of averaging inhomogeneities
(“backreaction”) in the universe? Regardless of the answer to this
question, what is the nature and magnitude of this backreaction? The
purpose of this thesis is to answer these questions as rigorously as
possible.

### The conventional wisdom, and loopholes

One should note that the conventional wisdom on the issue of
backreaction in the sense described in the previous section, is that
this effect can never be significant. It is of importance therefore to
understand this argument and its shortcomings. The argument goes as
follows [ 27 ] . One starts by assuming that inhomogeneities in the
universe can be described in the Newtonian approximation of GR, by the
gravitational potential @xmath with @xmath , which satisfies the Poisson
equation @xmath where @xmath is the fluctuation of matter density about
the mean homogeneous value @xmath , and can in general have a large
value. (E.g., in clusters of galaxies one finds @xmath , and the ratio
increases on smaller length scales). One then argues that the universe
we observe does seem to be very well-described by the above model, and
effects of averaging this model can only arise at second order in @xmath
and should hence be extremely small.

There is a loophole in this argument though. The catch is that the
background expansion @xmath is defined completely ignoring the
backreaction, which is an integrated effect with contributions from a
large range of length scales. This means that the following possibility
cannot be a priori ruled out : Initial conditions are specified as a
perturbation around a specific FLRW solution, but the integrated effect
of the backreaction grows (with time) in such a manner as to effectively
yield a late time solution which is a perturbation around a different
FLRW model. Indeed, there are calculations in the literature that do
indicate such a possibility being realised [ 28 , 31 , 34 ] . We
therefore see the need to actually perform a rigorous calculation that
will describe the time evolution of the backreaction, and thereby either
confirm or overthrow the conventional wisdom.

### Averaging schemes

A major hurdle in computing the effects of averaging has been the lack
of reliable averaging procedures which can be used in GR, mainly because
defining and physically interpreting averaging operations suitable for
tensors, is a challenging prospect. A number of authors have attempted
to solve this problem, both in the specific context of cosmology and
also as a more general problem of the mathematics of GR (see, e.g. Refs.
[ 22 , 23 , 24 , 25 , 26 ] ). To date, the most promising averaging
schemes have been the spatial averaging of scalars due to Buchert [ 40 ,
41 ] , and the fully covariant tensor averaging due to Zalaletdinov [ 43
] .

Buchert’s scalar averaging deals with a chosen @xmath splitting of
spacetime, and only averages two of the Einstein equations. This
averaging scheme is simple to implement and intuitively easy to grasp,
however it is ultimately difficult to interpret its physical
significance. Zalaletdinov’s scheme on the other hand, is technically
challenging to handle, since its averaging operation can deal with
full-fledged tensors at the cost of introducing some new mathematical
structures into the problem. The appeal of this scheme lies in the fact
that ultimately one has in hand an object which can legitimately be
called the “averaged metric” on an “averaged manifold”.

In this thesis we use both these schemes to address certain specific
questions concerning the backreaction problem. As we discuss below
however, ultimately we rely upon Zalaletdinov’s scheme to make realistic
statements regarding the nature of cosmological backreaction.

#### Can backreaction ever be large? A Paranjape and T P Singh, Class.
Quant. Grav. 23, 6955 (2006).

One question to ask in the context of the conventional wisdom presented
above, is whether it is technically possible within GR to have a
situation in which the backreaction dominates the averaged expansion. We
answer this in the affirmative by studying a toy model. We use the
exact, spherically symmetric Lemaître-Tolman-Bondi (LTB) solution of GR,
to construct a parametrized toy model for a curvature dominated universe
, i.e. – a spacetime in which the spatial curvature of the 3-dimensional
slices dominates over the contribution of the (nonrelativistic) matter.
Using Buchert’s averaging scheme we find that the effective scale factor
obtained in this toy model, does in fact accelerate for a wide class of
parameter values. Now one needs to ask whether this can happen in the
real universe, for which we turn to Zalaletdinov’s approach.

#### Simplifying Zalaletdinov’s framework A Paranjape and T P Singh,
Phys. Rev. D76, 044006 (2007).

As it stands, Zalaletdinov’s averaging framework deals with averaging an
arbitrary spacetime, and due to its generality it is technically
challenging and difficult to work with. By restricting its application
to cosmology and requiring consistency with basic cosmological
assumptions, we find that we can simplify this framework and bring it to
a form which can be readily applied to perform calculations. Doing this
also clarifies the nature of the backreaction as being a physically
relevant quantity on the same footing as the scale factor of the FLRW
spacetime. An important point is that for cosmology one must necessarily
consider the spatial averaging limit of Zalaletdinov’s 4-dimensional
spacetime averaging. In this limit we further highlight the similarities
and differences between Zalaletdinov’s and Buchert’s approaches, and the
fact that the structure of the correction terms in both approaches is
very similar, being essentially the same as expected from the heuristic
arguments of Ellis discussed earlier.

There is a significant difference between the original philosophy of the
averaging formalism, common to both the Buchert and Zalaletdinov
schemes, and the manner in which we employ Zalaletdinov’s averaging. The
original idea as developed by these authors was to construct a framework
which would independently describe a suitably defined averaged dynamics,
with no reference to the inhomogeneous spacetime whose average leads to
this dynamics. So, for example, Zalaletdinov formulates a new theory of
gravity (named Macroscopic Gravity or MG) which attempts to describe the
dynamics of an averaged manifold, with no recourse to the underlying
manifold which is described by the usual Einstein equations. The
backreaction in this approach is actually a new field in the problem
which satisfies its own equations and whose dynamics must be solved for
simultaneously with that of other fields such as the averaged metric and
the averaged energy-momentum tensor for matter.

Our approach to the backreaction issue is different : We consider it
central to be able to self-consistently describe both the inhomogeneous
geometry as well as its averaged counterpart. We find this necessary
since modern cosmology crucially relies on observations of
inhomogeneities around us, and ignoring the evolution of inhomogeneities
when solving for the averaged dynamics does not appear to be
satisfactory. Put another way, when faced with a solution of the
averaged dynamics, we find it essential to answer the question “which
(if any) inhomogeneous solution could lead to this averaged homogeneous
solution?” All our calculations therefore focus on solving for the
averaged dynamics of specific inhomogeneities, which we attempt to keep
as realistic as possible.

### Backreaction in (linear) perturbation theory A Paranjape, Phys. Rev.
D78, 063522 (2008).

We apply the simplified version of Zalaletdinov’s scheme to the problem
of calculating the backreaction in the perturbative framework and
determining its evolution. We discuss the issue of a possible gauge
dependence of the backreaction, which is essentially the problem that in
the perturbative framework one must be careful to distinguish physical
effects from artifacts of choosing a specific coordinate system. We show
how the backreaction can be calculated in a gauge independent manner,
although one is forced to make certain choices concerning the averaging
operation itself, which are not fixed by Zalaletdinov’s formalism. Once
the formalism is developed, we are left with expressions for the
backreaction that are valid whenever the metric of spacetime can be
described as a perturbation around its FLRW form, regardless of the
magnitude of matter density fluctuations.

To deal with the issue of self-consistency, we propose an iterative
procedure to compute the backreaction. Since order-of-magnitude
estimates of the backreaction indicate that the effect is expected to be
small in the early universe (around the epoch of last scattering say),
we begin with a “zeroth iteration” in which the backreaction is assumed
to vanish entirely. This of course is simply the setup for the standard
treatment of cosmology, in which the evolution of inhomogeneities can be
numerically evaluated. We do this and consequently obtain a first
estimate for the backreaction using the formalism developed earlier. We
find that the magnitude of the backreaction in this first estimate
remains negligible ( @xmath at present epoch in dimensionless units)
compared to the background contribution at all times, and its evolution
indicates that continuing to further iterations would not lead to any
instability; the final answer is expected to converge to a form very
close to the original “zeroth order” choice for the background.

### The nonlinear regime

The preceding arguments however are valid in the linear regime of
perturbation theory where matter fluctuations are small. However, the
structure of the integrands of the backreaction functions indicate that
the contribution from length scales where matter fluctuations have
become nonlinear, should in fact also remain negligible. Yet one would
like to see this in an actual nonlinear calculation rather than relying
on heuristic arguments. Specifically, in the nonlinear regime when
matter fluctuations are large, one needs needs to address two issues :
(a) Is a perturbative expansion in the metric still valid? (b) If so,
then is the contribution to the backreaction from nonlinear scales in
fact negligible?

#### A toy model for structure formation A Paranjape and T P Singh,
JCAP03(2008)023;

It has been claimed in the literature [ 37 ] that perturbation theory
does not give correct insight into the problem of structure formation in
the late universe, and that when one studies simple but nonperturbative
examples of structure formation, the contribution of backreaction to the
averaged dynamics is in fact large. These claims are clearly
contradictory to the conventional wisdom and to the arguments presented
earlier. We attempt to sort out this debate by studying a toy model of
structure formation, using the spherically symmetric LTB solution.

The matter source in the LTB solution is pressureless “dust”, which is
sufficient for our purposes since we wish to enquire whether a universe
dominated by nonrelativistic matter can have a large backreaction
component in realistic situations. We assume initial conditions to be a
perturbation around an FLRW model without dark energy. Our model
contains an inner spherical overdense ball surrounded by an underdense
shell, outside which we take the matter density to be homogeneous. The
overdense ball initially expands but eventually turns around and begins
collapsing, mimicking for example the infalling region outside clusters
of galaxies. This happens because this inner region satisfies equations
which are identical to those of a “closed” FLRW model in which the
universe eventually recollapses. Naively one would expect that the
underdense region behaves like the “open” FLRW models which expand
forever, however the situation is more involved. It turns out that
imposing appropriate matching conditions at the boundary of the over-
and underdense regions, implies that a section of the underdense region
immediately surrounding the overdense ball, will in fact eventually
collapse.

This result has interesting consequences. By simply ignoring this part
of the underdense shell that eventually turns around, we can show using
our model that arguments such as in Ref. [ 37 ] which ignore matching
conditions across boundaries can lead to an accelerating effective scale
factor. However, as soon as this region is correctly accounted for, the
acceleration disappears.

Consistently with this result, we show that one can rewrite the
nonperturbative LTB solution as a perturbation around the same FLRW
model we started with, provided the peculiar velocity of the dust
remains nonrelativistic ² ² 2 The peculiar velocity is defined as the
difference between the physical velocity and the Hubble flow of the dust
element. . This is exactly what one expects from standard textbook
results concerning cosmology in the Newtonian limit of GR. The small
parameter governing the linear perturbation theory valid in the early
universe is the magnitude of the matter density contrast @xmath , while
the small parameter relevant for the late time Newtonian limit is the
nonrelativistic peculiar velocity @xmath . Our calculation is an
explicit demonstration in a physically clear and simple setting, of how
the perturbation theory in @xmath becomes a perturbation theory in
@xmath .

#### Backreaction in the nonlinear regime A Paranjape and T P Singh,
Phys. Rev. Lett. 101, 181101 (2008).

As a final step, for completeness we compute the backreaction in our
model of structure formation described above. The formalism described in
the preceding sections can be applied to this model since we can bring
the metric of this model to the perturbed FLRW form. There are some
subtleties regarding the numerical calculations, since the coordinates
that are natural to the model are not natural to the backreaction
formalism, but these can be handled in a straightforward manner. As
expected, we find that the backreaction for such a model of structure
formation is in fact negligible. The significance of this calculation is
that it is the first one in which the backreaction has been calculated
as a physically meaningful quantity even in the late time nonlinear
phase of the cosmological evolution.

### Conclusions and Outlook

The question of whether backreaction from averaging of inhomogeneities
can lead to significant effects, has generated a heated debate in the
literature. There have been conflicting results on issues such as the
stability of perturbation theory in the presence of these corrections.
Our calculations using Zalaletdinov’s covariant averaging scheme applied
to both linear perturbation theory and toy models of nonlinear structure
formation, form the first systematic demonstration that perturbation
theory is in fact stable against corrections due to backreaction, and
that backreaction cannot explain the late time acceleration of the
universe. In principle such calculations can be extended to numerical
simulations of structure formation, however that is beyond the scope of
this work.

Given that cosmological data is rapidly increasing in quantity and
improving in quality, it will soon become possible to determine
cosmological parameters with percent level accuracy [ 59 ] , and even
perform tests of fundamental assumptions such as the Copernican
principle [ 60 ] . In this context, it becomes interesting to ask
whether the contribution of the backreaction, while very small compared
to the background, could be tested or used to improve parameter
estimation. This remains a subject for future work.

List of publications

-   Publications contributing to this thesis

         I. “The Possibility of Cosmic Acceleration via Spatial
        Averaging in Lemaitre-Tolman-Bondi Models” , Aseem Paranjape
        and T. P. Singh, Class. Quant. Grav. 23 , 6955 (2006)
        [arXiv:astro-ph/0605195].

         II. “The Spatial Averaging Limit of Covariant Macroscopic
        Gravity – Scalar Corrections to the Cosmological Equations” ,
        Aseem Paranjape and T. P. Singh, Phys. Rev. D76 , 044006 (2007)
        [arXiv:gr-qc/0703106].

         III. “Backreaction of Cosmological Perturbations in Covariant
        Macroscopic Gravity” , Aseem Paranjape, Phys. Rev. D78 ,
        063522 (2008) [arXiv:0806.2755].

         IV. “Structure Formation, Backreaction and Weak Gravitational
        Fields” , Aseem Paranjape and T. P. Singh, JCAP 03 (2008)023
        [arXiv:0801.1546].

         V. “Cosmic Inhomogeneities and the Average Cosmological
        Dynamics” , Aseem Paranjape and T. P. Singh, Phys. Rev. Lett.
        101 , 181101 (2008) [arXiv:0806.3497].

-   Other publications

    1.   “Nonlinear Structure Formation, Backreaction and Weak
        Gravitational Fields” , Aseem Paranjape, arXiv:0811.2619 (2008),
        talk presented at CRAL-IPNL Conference on Dark Energy and Dark
        Matter, Observations, Experiments and Theories , July, 2008,
        Lyon Center for Astrophysics Research (CRAL), Lyon, France; to
        appear in the Conference Proceedings.

    2.   “A Covariant Road to Spatial Averaging in Cosmology – Scalar
        Corrections to the Cosmological Equations” , Aseem Paranjape,
        Int. J. Mod. Phys. D17 , 597 (2008) [arXiv:0705.2380]. (This
        essay received an Honourable Mention in the Gravity Research
        Foundation’s Essay Competition, 2007.)

    3.   “Entropy of Null Surfaces and Dynamics of Spacetime” , T.
        Padmanabhan and Aseem Paranjape, Phys. Rev. D75 , 064004 (2007)
        [arXiv:gr-qc/0701003].

    4.   “Explicit Cosmological Coarse Graining via Spatial Averaging” ,
        Aseem Paranjape and T. P. Singh, Gen. Rel. Grav. 40 , 139 (2008)
        [arXiv:astro-ph/0609481].

    5.   “Thermodynamic route to field equations in Lanczos-Lovelock
        gravity” , Aseem Paranjape, Sudipta Sarkar and T. Padmanabhan,
        Phys. Rev. D74 , 104015 (2006) [arXiv:hep-th/0607240].

    6.   “Embedding diagrams for the Reissner-Nordstrom space-time” ,
        Aseem Paranjape and Naresh Dadhich, Gen. Rel. Grav. 36 ,
        1189 (2004) [arXiv:gr-qc/0307056]. (This paper was the result of
        part of the work done under the JNCASR Summer Research
        Fellowship, April – June 2003.)

###### List of Figures

-    2.1 The models described by @xmath . (a) The scaled function @xmath
    . (b) @xmath plotted against @xmath for specific values of @xmath .
-    2.2 Evolution of @xmath in the models with @xmath , plotted against
    @xmath for (a) three values of @xmath with @xmath , and (b) three
    values of @xmath with @xmath .
-    4.1 Numerical results for the transfer function.
-    4.2 Backreaction and nonlinearity.
-    4.3 The correlation scalars (“backreaction”) for the sCDM model,
    normalised by @xmath . @xmath , @xmath and @xmath are negative
    definite and their magnitudes have been plotted. The vertical line
    marks the epoch of matter radiation equality @xmath .
-    5.1 The evolution of the density contrast @xmath , using parameter
    values from Table 5.1 evaluated at (a) @xmath in region 1 and (b)
    @xmath in region 3.
-    5.2 The deceleration parameters for a range of parameter values.
    The dashed lines correspond to @xmath and the solid lines to @xmath
    . The @xmath -axis shows @xmath , where @xmath is the time at which
    region 1 turns around, and is different for each plot. The values
    for @xmath , @xmath and @xmath are the same as those listed in Table
    5.1 . [Both curves in Fig. 5.2(d) begin at @xmath at @xmath .]
-    5.3 The quantity @xmath in region 1, plotted using parameter values
    from Table 5.1 . Since @xmath , the peculiar velocity @xmath remains
    small.
-    5.4 The peculiar velocity @xmath in regions 2 and 3 using parameter
    values from Table 5.1 .
-    5.5 The metric function @xmath in regions 2 and 3 using parameter
    values from Table 5.1 . The time axis begins at @xmath .
-    5.6 The evolution of @xmath , normalised by @xmath . Also shown is
    a hypothetical curvature-like correction, evolving like @xmath .
-    5.7 The normalised evolution of the backreaction functions other
    than @xmath . To enhance contrast, a strongly decaying early time
    mode for @xmath has not been shown.

## Chapter 1 Introduction

Our understanding of the universe has undergone dramatic changes in the
last century. Edwin Hubble’s discovery in 1924 that stars known as
Cepheid variables could be found in the Andromeda nebula and appeared
fainter than Cepheids in the Milky Way, established that such nebulae
were not part of the Milky Way but were in fact distant galaxies
themselves. And his demonstration 5 years later that these galaxies
appear to be receding from the Milky Way at speeds proportional to their
distances, has found its way into popular consciousness as the maxim
“the universe is expanding” [ 1 ] . On the theoretical front, Einstein’s
general relativity had at this time quickly gained acceptance as a
fundamental theory of gravity, and its application to cosmology was
being studied by several workers including Einstein himself, deSitter,
Lemaître, Friedmann among others. The simple models of a universe
described by the homogeneous and isotropic geometries characterised by
the Friedmann-Lemaître-Robertson-Walker (FLRW) metric, were very
successful at describing the then limited amount of cosmological
observations. The decades since have seen the emergence of the highly
successful Big Bang model of cosmology, which posits that the universe
went through a very hot dense phase at early times and cooled as it
expanded, with tiny fluctuating inhomogeneities in the past that have
grown to form structures such as galaxies today [ 2 ] .

A central assumption in this (widely accepted) model of cosmology is
that the universe on large scales is homogeneous and isotropic [ 3 ] .
This assumption leads to tremendous simplifications in the application
of general relativity (GR) to cosmology, since it reduces the ten
independent components of the metric of spacetime @xmath to essentially
a single function of time @xmath known as the scale factor. In the early
days of @xmath century cosmology, the assumption of homogeneity and
isotropy was largely motivated on grounds of simplicity and aesthetic
appeal. In recent times however, it has become possible to confront this
assumption with observations, which remarkably appears to be justified
to a large extent (based on observations of the CMB radiation [ 4 , 5 ]
, and on analyses of galaxy surveys [ 6 , 7 , 8 ] , although see Ref. [
9 ] ). This indicates that a model based on essentially a single
function of time might in fact go a long way in furthering our
understanding of the behaviour of the universe.

Of course the real universe is not homogeneous; we see a rich variety of
structure around us from stellar systems to galaxies to clusters of
galaxies and even larger structures [ 10 ] . Perhaps one of the biggest
successes of cosmological theory based on GR, has been the explanation
of how statistical properties of the large scale structure arise [ 11 ]
. The relevant calculations are largely based on linear perturbation
theory (i.e. linearizing Einstein’s equations around the smooth FLRW
solution) which is valid at all length scales of interest at early times
and on large scales at late times [ 12 , 13 ] . Dynamics on small scales
at late times involves nonlinear theory, and is dealt with using
approximation schemes such as the Press-Schechter formalism and its
extensions [ 14 ] , “Newtonian” nonlinear perturbation analyses [ 15 ]
and numerical simulations [ 16 ] . While such treatments have met with
great success in the description of the statistical properties of the
anisotropies in the temperature of the CMB, as well as of the
inhomogeneous distribution of galaxies, there are two causes for
concern.

The first is a purely theoretical issue, and is the basis of this work.
The idea that the large scale universe is homogeneous and isotropic
necessarily entails an implicit notion of averaging on these large
scales. In other words, what one is really saying is, “When the
spatially fluctuating parts of the solution of GR describing our
universe are averaged out, what is left is the homogeneous and isotropic
FLRW solution of Einstein’s equations”. The immediately obvious problem
with this statement is that the details of the averaging operation are
not at all clear, and indeed are usually never specified. A bigger
problem is one noted by Ellis [ 17 ] , and can be stated in the
following symbolic way. If @xmath denotes the metric, @xmath the
Christoffel connection and @xmath the Einstein tensor for the metric
@xmath , then we have the relations

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

with @xmath denoting spacetime derivatives. The Einstein equations are
therefore

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

with @xmath denoting the energy-momentum tensor of the matter
components. Now, irrespective of any details of the averaging operation,
one notes that

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

with the angular brackets denoting the averaging. The FLRW solution
would amount to solving the equations @xmath . In general therefore, it
is not true that averaging out the fluctuating inhomogeneities leaves
behind the FLRW solution, since what we are actually left with is

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

and the homogeneous solution that we are looking for will depend on the
details of the correction terms @xmath .

The second cause for concern comes from observations. It has now been
established beyond a reasonable doubt, that the FLRW metric confronted
with observations indicates an accelerating scale factor [ 18 ] .
Conventional sources of energy such as radiation and nonrelativistic
matter cannot explain the acceleration, and it is now common to
attribute this effect to a hitherto unknown “dark energy”, which in its
simplest form is a cosmological constant. The true nature of this
additional component in the cosmological equations, is perhaps the most
challenging puzzle facing both theorists and observers today. A huge
amount of research has gone into (a) explaining the value that a
cosmological constant term must take to explain data or (b) assuming a
zero cosmological constant, constructing models of a dynamical dark
energy which explains the observed acceleration [ 19 ] . It is fair to
say however that there is no theoretical consensus on what the origin of
dark energy is. Since we have seen above that the effects of averaging
lead to some extra, as yet unknown terms in the equations, it is natural
to ask whether these two issues are connected. Could the acceleration of
the universe be explained by the effects of averaging inhomogeneities
(“backreaction”) in the universe? Regardless of the answer to this
question, what is the nature and magnitude of this backreaction? The
purpose of this thesis is to answer these questions as rigorously as
possible.

### 1.1 History of the averaging problem

The problem of averaging in general relativity has a history going back
even further than Ellis’ work of 1984. In the context of gravitational
radiation, the problem of second order effects of gravity waves on the
large scale background metric of spacetime was studied by Isaacson in
the 1960’s [ 20 ] in the “short-wavelength” approximation. Isaacson used
an averaging operation which he called the “BH assumption” after Brill
and Hartle [ 21 ] , which was suited to studying the effects of
perturbative gravity waves in a spacetime region encompassing many
wavelengths. An attempt to generalize Isaacson’s results was made by
Noonan [ 22 ] , who introduced a different averaging procedure which was
also constructed for situations where inhomogeneities were perturbative
in nature. Interest in the cosmological consequences of such an
averaging picked up only after Ellis very clearly laid down the problems
and possibilities that open up when the idea of averaging in general
relativity is taken seriously. An example is the work of Futamase [ 23 ]
, who introduced a spatial averaging procedure after performing a @xmath
splitting of spacetime, and computed backreaction terms arising from
averaging second order perturbations, finding them to be negligibly
small (see also Ref. [ 24 ] ). Another example is the work of Boersma [
25 ] , who attempted to construct a gauge-invariant (i.e. coordinate
independent) averaging procedure in perturbation theory, and also
estimated that backreaction effects remain negligibly small at the
present epoch. (For other work on the averaging problem, see Ref. [ 26 ]
.)

It may seem intuitively obvious that perturbatively small
inhomogeneities can only lead to negligibly small backreaction effects.
Indeed, this has been the conventional wisdom on this subject, and has
recently been spelt out by Ishibashi and Wald [ 27 ] . One starts by
assuming that inhomogeneities in the universe can be described in the
Newtonian approximation of GR, by the gravitational potential @xmath
with @xmath , which satisfies the Poisson equation @xmath where @xmath
is the fluctuation of matter density about the mean homogeneous value
@xmath , and can in general have a large value. (E.g., in clusters of
galaxies one finds @xmath , and the ratio increases on smaller length
scales). One then argues that the universe we observe does seem to be
very well-described by the above model, and effects of averaging this
model can only arise at second order in @xmath and should hence be
extremely small.

There is a loophole in this argument though. The catch is that the
background expansion @xmath is defined completely ignoring the
backreaction, which is an integrated effect with contributions from a
large range of length scales. This means that the following possibility
cannot be a priori ruled out : Initial conditions are specified as a
perturbation around a specific FLRW solution, but the integrated effect
of the backreaction grows (with time) in such a manner as to effectively
yield a late time solution which is a perturbation around a different
FLRW model. Indeed, there are calculations in the literature that do
indicate that this may happen. For example, Martineau and Brandenberger
[ 28 ] showed in a toy model that long wavelength fluctuations can give
rise to a backreaction contribution which has a late-time effective
equation of state similar to a cosmological constant. Their calculations
were based on the averaging procedure developed by Abramo et al. [ 29 ]
in the context of backreaction in inflationary cosmology. Other claims
to solving the dark energy problem using backreaction from long
wavelength fluctuations were made by Barausse et al. [ 30 ] and Kolb et
al. [ 31 ] . It is fair to say however, that such claims have been
controversial. A number of authors have argued that when effects of long
wavelength fluctuations are suitably “renormalized” and the background
suitably redefined, the backreaction cannot lead to acceleration of the
scale factor [ 32 ] . Nevertheless, what is definitely true is that the
idea of backreaction of cosmological fluctuations has generated a lively
debate in the community [ 27 , 33 , 34 , 35 ] .

In this thesis we will not deal with the effects of long wavelength
fluctuations, although we will see that certain assumptions need to be
made in order to define a self-consistent perturbation theory in the
presence of an averaging operation. A separate and equally interesting
question, which will be the main focus of this work, is whether
cosmological perturbation theory is stable in the presence of the
backreaction contribution. There are results in the literature which
indicate that this might not be the case, and that the backreaction can
grow with time in such a manner that at late times (when matter
fluctuations have become nonlinear) perturbation theory in the metric
also no longer holds [ 34 ] (see also Ref. [ 36 ] ). In the same vein,
there are arguments using nonperturbative toy models of gravitational
collapse and nonlinear structure formation, which suggest that
perturbation theory may not give correct insight into gravitational
dynamics at late times in cosmology [ 37 ] . If these results are
relevant for the real world, then it not only means that the
conventional wisdom is badly failing, but in fact implies that all of
late-time cosmology must be reworked from scratch (see, e.g. Ref. [ 38 ]
; also see however Ref. [ 39 ] ). On the other hand, if these results
are for some reason or other not realistic, then it is important ask
what is wrong with such arguments, and further what the correct approach
to the problem is.

Clearly, to make any headway in this problem, it is first essential to
have a reliable averaging scheme at hand. Since the questions one is
asking deal with the stability of cosmological perturbation theory, this
averaging scheme needs to be inherently nonperturbative , i.e. the
validity of perturbation theory should not be a prerequisite to defining
the averaging prescription. This thesis will deal with two averaging
schemes present in the literature : the spatial averaging of scalars
defined by Buchert [ 40 , 41 , 42 ] , and the fully covariant tensor
averaging defined by Zalaletdinov [ 43 , 44 , 45 ] . Some very
interesting early work on possible nonperturbative effects of averaging
was by Buchert and Ehlers [ 46 ] , followed up by Ref. [ 47 ] , in the
context of spatial averaging in Newtonian cosmology. Buchert’s averaging
operation in general relativity has since been used by several authors
to explore the effects of backreaction in various situations [ 38 , 48 ,
49 , 50 , 51 ] , including the perturbative contexts mentioned above [
34 , 36 ] , and has also been compared against observations [ 52 ] . As
we shall see later, this averaging scheme has an appealing simplicity of
implementation, which could be a reason for the amount of attention it
has received. In contrast, Zalaletdinov’s averaging scheme (which was
developed earlier than Buchert’s work) is technically rather challenging
to handle and involves a fair amount of complicated algebra. Its
strength however lies in the fact that it is a fully covariant
prescription which, at the end of the day, yields an object which can be
legitimately called the “averaged metric” on an “averaged manifold”.
This ultimately allows us to make physically clear statements regarding
the backreaction, which is difficult to do in Buchert’s scheme as it
stands. While Zalaletdinov’s scheme has not received the same amount of
attention as Buchert’s, there has been a series of very interesting
results derived in this framework by Zalaletdinov and coworkers [ 53 ] .

#### 1.1.1 The “Special Observer” assumption

The idea of using inhomogeneities to explain the dark energy problem has
generated a flurry of research in the backreaction problem in recent
years, as we saw above (see also Ref. [ 54 ] ). It is important to also
mention another approach which has gained popularity in this context,
namely that of ascribing the dark energy phenomenon to light propagation
effects in an inhomogeneous universe [ 55 ] . The central idea here is
that light propagation through an inhomogeneous underdensity or “void”
can be significantly different from that in a homogeneous space. In
fact, it is possible to show that luminosity distance data from
supernovae can always be fit by modelling ourselves as observers in a
void with a suitable density profile. Typically however, the (usually
spherical) voids invoked for this purpose are very large (in the range
of @xmath Mpc to @xmath Gpc in diameter), and are difficult to reconcile
with the typical sizes of voids seen in galaxy surveys, which are in the
range of @xmath - @xmath Mpc, with some “supervoids” reaching @xmath Mpc
[ 56 ] . Nevertheless, this idea has been rather vigorously investigated
in the last several years. Since this thesis will not directly deal with
this approach to the dark energy problem, we will simply point the
reader to a list of references [ 57 ] dealing with the study of light
propagation in an inhomogeneous universe and of supernovae data and the
CMB from the point of view of void-based observers. Unlike the
backreaction issue which requires mainly theoretical work, a detailed
description of the inhomogeneous universe belongs squarely in the regime
of observational cosmology [ 58 ] . Due to the obvious observational
difficulties involved in such a program (for example due to the lack of
homogeneous samples of galaxy data), this approach at present is largely
restricted to being an exercise in building toy models of the local
large scale structure [ 57 ] . As a final comment on this topic, we note
that this “non-Copernican” approach (even at the level of building toy
models) is amenable to observational verification or disproof in the
coming generation of surveys, as pointed out by Ref. [ 60 ] .

With this introduction, our main results (the thesis of the thesis!) are
:

-    Although technically possible, in the real world backreaction does
    not significantly affect the expansion history of the universe.

-    Cosmological perturbation theory is stable against backreaction
    effects, well into the nonlinear regime.

-    Dark energy cannot therefore be an effect of the backreaction of
    inhomogeneities.

The outline of this thesis is as follows :

Chapters 2 and 3 will deal respectively with Buchert’s and
Zalaletdinov’s averaging schemes. We will first describe Buchert’s
scheme in chapter 2 and show using a toy model of a spherically
symmetric inhomogeneous spacetime (the Lemaître-Tolman-Bondi or LTB
solution [ 61 ] ), how an averaged effective description of the
spacetime can have an accelerating scale factor even when the underlying
exact solution has no exotic elements. This calculation will be based on
Paranjape and Singh, CQG (2006) (henceforth Paper 1). We will then turn
to Zalaletdinov’s formalism in chapter 3 and give a pedagogical
introduction to his 4-dimensional covariant averaging scheme and the
derivation of the equations in his effective theory of Macroscopic
Gravity (MG). We will then specialize this formalism for use in
cosmology and emphasize the need for a spatial averaging limit of this
averaging. By explicitly writing out the backreaction terms in a @xmath
-splitting of spacetime, we will also be in a position to give a
detailed comparison between Zalaletdinov’s formalism and Buchert’s
spatial averaging, and to demonstrate the physical relevance of the
backreaction terms. This part will be based on Paranjape and Singh, PRD
(2007) (henceforth Paper 2).

In chapter 4 we will use the spatial averaging limit of Zalaletdinov’s
scheme in the setting of cosmological perturbation theory. We will show
how the leading order contribution to the backreaction can be calculated
in a gauge invariant manner, and derive expressions for the backreaction
which are valid whenever the metric of spacetime can be written as a
perturbation around the FLRW form. We will also discuss the issue of
self-consistency of the backreaction calculation, and propose an
iterative scheme to calculate the backreaction. As concrete examples we
will perform the first iteration in such a process, for some
well-studied models of perturbative inhomogeneities in the linear
regime. This set of calculations will be based on Paranjape, PRD (2008)
(henceforth Paper 3).

Chapter 5 will deal with the regime when matter fluctuations have become
large, so that linear perturbation theory no longer holds. We will use
the LTB solution once more to describe a semi-realistic situation of
spherical collapse, which we will follow well into the nonlinear regime.
Initially working in the Buchert formalism, we will emphasize the
importance of correctly accounting for boundary conditions when building
models, by showing how spurious results can be obtained for the averaged
expansion, by ignoring boundary conditions. We will also show how the
late time nonperturbative behaviour in our LTB model can be recast in
the perturbed FLRW form, by a straightforward coordinate transformation,
provided matter velocities remain non-relativistic. This will
demonstrate in a clear and unambiguous manner, how a perturbation theory
in the density contrast @xmath at early times becomes a perturbation
theory in peculiar velocity @xmath at late times. These results will be
based on Paranjape and Singh, JCAP (2008) (henceforth Paper 4). Finally,
to complete the picture, we will apply the formalism developed in
chapter 3, to the toy model described above, and explicitly show that
the backreaction in the nonlinear regime of structure formation does
remain small in this model. This calculation will be based on Paranjape
and Singh, PRL (2008) (henceforth Paper 5).

We will conclude in chapter 6 with a summary and a brief comparison with
other work in the literature. Additionally, in the Appendices we have
collected some results which will be used in the main text. Appendix A
describes the homogeneous and isotropic FLRW cosmology and serves to fix
notation. Appendix B describes the LTB metric which is a solution of the
Einstein equations sourced by a spherically symmetric pressureless
fluid. Appendix C contains proofs of some results quoted in chapter 2.
Throughout this work we shall set the speed of light @xmath to unity,
and use the metric signature @xmath . Lowercase Latin indices @xmath
will take values @xmath , while uppercase indices @xmath will take
spatial values @xmath . The Hubble constant @xmath is parametrized when
necessary in usual astronomers’ units as @xmath .

## Chapter 2 Averaging schemes : Buchert’s spatial averaging

This chapter and the next describe the averaging schemes we will use for
the backreaction calculations. In this chapter we deal with Buchert’s
spatial averaging scheme and show in a toy example how a large,
acceleration-inducing backreaction can arise even in the absence of any
exotic dark energy.

### 2.1 Buchert’s spatial averaging of scalars

The most straightforward and intuitively clear application of Buchert’s
spatial averaging is in the case when the matter source is a
pressureless “dust” with an energy-momentum tensor @xmath , with @xmath
the dust 4-velocity which satisfies @xmath . Assuming further that the
dust is irrotational, the 4-velocity will be orthogonal to 3-dimensional
spatial sections and the metric can be written in “synchronous and
comoving” coordinates (in which @xmath ) [ 62 ] as,

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

The expansion tensor @xmath is given by @xmath where the dot refers to a
derivative with respect to time @xmath . The traceless symmetric shear
tensor is defined as @xmath where @xmath is the expansion scalar. The
Einstein equations can be split into a set of scalar equations and a set
of vector and traceless tensor equations. The scalar equations are the
Hamiltonian constraint ( 2.2a ) and the evolution equation for @xmath (
2.2b ),

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (2.2a)
     @xmath   @xmath      (2.2b)
  -- -------- -------- -- --------

where @xmath is the Ricci scalar of the 3-dimensional hypersurface of
constant @xmath and @xmath is the rate of shear defined by @xmath .
Eqns. ( 2.2a ) and ( 2.2b ) can be combined to give Raychaudhuri’s
equation

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

The continuity equation @xmath which gives the evolution of @xmath , is
consistent with Eqns. ( 2.2a ), ( 2.2b ). We only consider the scalar
equations, since the spatial average of a scalar quantity can be defined
in a gauge covariant manner within a given foliation of spacetime. For
the spacetime described by ( 2.1 ), the spatial average of a scalar
@xmath over a comoving domain @xmath at time @xmath is defined by

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where @xmath is the determinant of the 3-metric @xmath and @xmath is the
volume of the comoving domain given by @xmath . The following
commutation relation then holds [ 40 ]

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

which yields for the expansion scalar @xmath

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

Introducing the dimensionless scale factor @xmath normalized by the
volume of the domain @xmath at some initial time @xmath , we can average
the scalar Einstein equations ( 2.2a ), ( 2.2b ) and the continuity
equation to obtain [ 40 ]

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (2.7a)
     @xmath   @xmath      (2.7b)
     @xmath   @xmath      (2.7c)
  -- -------- -------- -- --------

Here @xmath , the average of the spatial Ricci scalar @xmath , is a
domain dependent spatial constant. The ‘backreaction’ @xmath is given by

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

and is also a spatial constant. The last equation ( 2.7c ) simply
reflects the fact that the mass contained in a comoving domain is
constant by construction : since @xmath , the local continuity equation
@xmath can be solved to give @xmath where the subscript @xmath refers to
some arbitrary reference time @xmath . The mass @xmath contained in a
comoving domain @xmath is then @xmath constant. Hence

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

which is precisely what is implied by Eqn. ( 2.7c ). Equations ( 2.7a ),
( 2.7b ) can be thought of as “modified Friedmann equations” (compare
Eqns. ( A.3b )), with the modifications arising due to the presence of
the backreaction @xmath and the fact that the averaged Ricci curvature
in general need not evolve like @xmath as in the FLRW case.

A necessary condition for ( 2.7b ) to integrate to ( 2.7a ) takes the
form of the following differential equation involving @xmath and @xmath

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

which is a very interesting equation because it shows that the evolution
of the backreaction is intimately tied to that of the average spatial
curvature. Scaling solutions for this equation have been explored by
Buchert, Larena and Alimi [ 50 ] , a simple example being @xmath ,
@xmath . Clearly the FLRW solution with @xmath is a special case. In
this thesis we will mainly be concerned with the behaviour of the
backreaction arising from explicitly averaging an inhomogeneous
spacetime, and will therefore not discuss these scaling solutions which
make no reference to the underlying inhomogeneous geometry. We note that
the criterion to be met in order for the effective scale factor @xmath
to accelerate, is

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

Equations ( 2.7 ) and ( 2.10 ) describe the essence of Buchert’s
averaging formalism, for the simplest case of irrotational dust. We note
that the remaining eight Einstein equations for the inhomogeneous
geometry, which are not scalar equations, are not averaged. These are
the five evolution equations for the trace-free part of the shear,

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

and the three equations relating the spatial variation of the shear and
the expansion,

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

Here, @xmath is the spatial Ricci tensor and a @xmath denotes covariant
derivative with respect to the @xmath -metric. Later, when we apply
Zalaletdinov’s formalism to cosmology, we will see that accounting for
the full set of Einstein’s equations when performing the averaging,
leads to additional constraints on the inhomogeneous geometry, which are
not present in Buchert’s formalism.

For completeness, and to enable a fuller comparison with Zalaletdinov’s
formalism, we also display the results of applying Buchert’s averaging
to the case of a perfect fluid with energy-momentum tensor @xmath [ 41 ]
. In this case comoving coordinates are not in general synchronous, and
for an irrotational perfect fluid in comoving coordinates, the metric
takes the form

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

The averaged scalar Einstein equations for the scale factor @xmath are

  -- -------- -------- -- --------
     @xmath   @xmath      (2.15)
     @xmath   @xmath      (2.16)
  -- -------- -------- -- --------

where the kinematical backreaction @xmath is given by

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

and the dynamical backreaction @xmath is given by

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

where @xmath is the @xmath -divergence of the @xmath -acceleration of
the fluid. Eqn. ( 2.16 ) follows as an integral from Eqn. ( 2.15 ) if
and only if the relation

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (2.19)
  -- -------- -------- -- --------

is satisfied. There are also the unaveraged equations (which we do not
display here) for the shear, analogous to the shear equations ( 2.12 )
and ( 2.13 ) for dust.

### 2.2 Acceleration from averaging

In this section we use the spherically symmetric dust solution of
Einstein’s equations (the Lemaître-Tolman-Bondi or LTB solution
described in Appendix B) to construct an explicit example where
Buchert’s effective scale factor accelerates even though the underlying
model has no cosmological constant or dark energy. Our model contains a
single underdense and “curvature-dominated” region (in a sense to be
described below), whose evolution we study at late times.

#### 2.2.1 Late time and curvature dominated unbound models

Consider the LTB metric ( B.1 )

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

which satisfies

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

for the specific case @xmath in the region of interest, so that the
solution is ( B.4a )

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

Although it is straightforward to numerically evaluate @xmath for any
given choice of the free functions, we would like to try and
analytically simplify these expressions as far as possible. Since @xmath
in the unbound case is an increasing function of time for arbitrary
@xmath , Eqn. ( 2.21 ) shows that the late time solution (after
neglecting the @xmath term in the equation) can be expressed as

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

[This leading order solution can also be derived from an asymptotic
expansion of the solution ( 2.22 ) for large @xmath , see below.] The
function @xmath can be obtained using the closed form expression for
@xmath obtained by integrating Eqn. ( 2.22 ) [ 65 ] and the scaling
@xmath , as

  -- -- -- --------
           (2.24)
  -- -- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

If we further assume that the matter contribution encoded in @xmath is
negligible compared to that of the spatial curvature as encoded in
@xmath , i.e. if @xmath , then the expression for @xmath also simplifies
at the leading order to ¹ ¹ 1 We are assuming that @xmath remains finite
at all @xmath . In particular as @xmath this implies @xmath ; @xmath
(see Eqn. ( B.6 )).

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

The leading order unbound LTB solution in this late time, negligible
matter limit is then given by

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

where we have introduced two placeholders @xmath and @xmath (ultimately
set to unity) which will remind us that we are working with a late time
solution with large @xmath . Note that Eqn. ( 2.27 ) (with @xmath ), is
the exact solution Eqn. ( 2.21 ) in the special case @xmath for all
@xmath . This actually corresponds to Minkowski spacetime, with the
corresponding Riemann tensor being exactly zero. The constant time
@xmath -spaces are hypersurfaces of negative curvature, with the @xmath
-curvature being determined by the function @xmath . The ‘FLRW’ limit of
this solution is in fact the Milne universe; the solution ( 2.27 ) could
hence be thought of as the ‘LTB’ type generalization of the Milne
universe. Although we will use this form of the solution to draw
conclusions regarding acceleration of Buchert’s @xmath , we will later
argue that these conclusions are not altered by the presence of a
nonzero but small amount of matter. Although it may appear at this stage
that requiring @xmath renders the late time approximation redundant, we
will see below that additionally imposing the late time approximation
allows us to write down a fairly straightforward sufficient condition
for acceleration of @xmath , which would not be possible with only the
@xmath condition.

For the metric ( 2.20 ), the volume of a spherical comoving domain of
radius @xmath is

  -- -------- -- --------
     @xmath      (2.28)
  -- -------- -- --------

Substituting the solution ( 2.27 ) in this expression, we find

  -- -------- -- --------
     @xmath      (2.29)
  -- -------- -- --------

where we have defined the domain dependent integrals

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.30)
  -- -------- -------- -- --------

The sum of the exponents of @xmath and @xmath in each term in ( 2.29 )
indicates the relative order of that term with respect to the leading
@xmath term. This approach of treating some terms as small compared to
others is valid since the various integrals which multiply the powers of
@xmath , are all finite and non-zero. Expanding @xmath in powers of
@xmath , we find for the effective scale factor,

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

where @xmath represents terms involving @xmath (i.e. containing @xmath )
with @xmath .

We see that the generic late time (i.e. @xmath ) behaviour of the
unbound models under consideration is @xmath , and that deviations from
zero are small, being a second order effect. Whether the approach to
@xmath is via an accelerating or decelerating phase, depends upon the
relative magnitudes of the domain integrals involved. A sufficient
condition for an unbound model with negligible matter to accelerate at
late times, is

  -- -- -- --------
           (2.32)
  -- -- -- --------

As an explicit example, consider a model with @xmath given by

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

in arbitrary units. The condition @xmath ensures that the regularity
conditions of Appendix B are satisfied. The function @xmath for these
models, which controls the magnitude of the late time acceleration (see
Eqn. ( 2.31 )) is shown in Fig. 2.1 , against @xmath and @xmath . For
clarity, in the second panel we have shown @xmath against @xmath for
specific values of @xmath . We find that @xmath is positive everywhere
in the region shown. To explicitly demonstrate acceleration, we plot the
evolution of the dimensionless quantity @xmath defined by

  -- -------- -- --------
     @xmath      (2.34)
  -- -------- -- --------

for various fixed values of @xmath and @xmath , using the full
expression for @xmath in ( 2.29 ). The results are shown in Fig. 2.2 .
We have used units in which @xmath , and have displayed the evolution
for times @xmath .

Even though the acceleration condition ( 2.32 ) is strictly derived for
the case @xmath , one can easily see that it remains valid at late
enough times even in the presence of a small amount of matter.
Introducing another place holder @xmath to keep track of the smallness
of the function @xmath defined in Eqn. ( 2.25 ), one sees that by
waiting long enough, the solution for @xmath will be approximately given
by Eqn. ( 2.23 ), with @xmath given by Eqn. ( 2.24 ). The expression for
the volume @xmath will have the same form as Eqn. ( 2.29 ), but the
integrals involved will be different due to the presence of terms
involving @xmath . A condition similar to ( 2.32 ), say @xmath , will
then be obtained for late time acceleration, with different integrals
involved in the definition of the functional @xmath . The point to note
is that @xmath terms containing @xmath with @xmath defined as in Eqn. (
2.32 ), and for small enough @xmath , @xmath will be positive whenever
@xmath is positive ² ² 2 More precisely, we will have @xmath . . Hence
the acceleration condition is robust against adding a small but nonzero
amount of matter.

Chapter summary and discussion: This chapter dealt with details of
Buchert’s scheme for spatially averaging scalar quantities, and the
effective cosmological equations it leads to. Using exactly solvable toy
models of inhomogeneities, which were explicitly averaged using this
scheme, we saw how an accelerating effective scale factor can arise even
in situations where there is no exotic matter component.

However, the fact that Buchert’s scheme deals with only two of the ten
Einstein equations, makes it difficult to relate the effective scale
factor @xmath with observations. In particular, it is not clear whether
or not @xmath should replace the usual scale factor in the FLRW metric.
We see this difficulty of interpretation as arising from the inherent
non-covariant structure of Buchert’s averaging scheme. To get around
this problem we will study a different averaging scheme in the next
chapter, namely Zalaletdinov’s fully covariant Macroscopic Gravity. This
scheme will allow us to deal with objects which are structurally similar
to Buchert’s scale factor and backreaction, while being easier to
interpret in a physically clear manner.

## Chapter 3 Averaging schemes : Zalaletdinov’s covariant Macroscopic
Gravity

In this chapter we turn to the averaging defined by Zalaletdinov [ 43 ]
, which is a @xmath -dimensional generally covariant procedure. This
averaging is used on the Einstein equations and, together with some
additional assumptions, leads to what Zalaletdinov has called
Macroscopic Gravity (henceforth MG). After introducing MG, we will
describe its spatial averaging limit as discussed in Paper 2.

### 3.1 A covariant averaging scheme

The starting point in any covariant averaging scheme has to be the
question : “How does one average tensors while retaining their
transformation properties under coordinate changes?” If the averaging
operation is to involve an integral over a spacetime region, then
clearly only scalar objects can be averaged, since they change only
trivially under coordinate transformations. To define a scheme for
general tensors then, it is essential to introduce some additional
structure in the formalism. The most convenient option is to introduce a
bivector @xmath which transforms as a vector at event @xmath and as a
co-vector at event @xmath . In Zalaletdinov’s scheme one postulates the
existence of such a bivector, requires it to have certain desirable
properties, and then explicitly constructs an object which has all these
properties. We will see how this is done in what follows. [Throughout
this chapter primed indices (e.g. @xmath ) will refer to “primed events”
( @xmath ) and unprimed indices to unprimed events.]

To begin with, we require that this bivector be idempotent (i.e. “square
to itself”)

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

and have the coincidence limit

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

This ensures that @xmath has the inverse operator @xmath (which is
easily seen by taking the @xmath limit in Eqn. ( 3.1 ) and using the
condition ( 3.2 )). The bivector is then used to define the “bilocal
extension” of a general tensorial object (denoted by an overtilde) : for
a vector @xmath this takes the form

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

with the obvious generalisation to higher rank objects. Notice that the
bilocal extension as defined above transforms like the original tensor
at the event @xmath , but as a scalar at the event @xmath . This allows
us to define the “average” of @xmath over a 4-dimensional spacetime
region @xmath with a supporting point @xmath , as

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

the subscript @xmath standing for ‘spacetime’. While this averaged
tensor has the correct transformation properties at the event @xmath ,
in order to be a local function of its argument, one needs to ensure
that @xmath has appropriate differential properties. Since the @xmath
dependence of this object arises not only from the explicit appearance
of @xmath but also through the dependence of the domain @xmath on the
support point, in order to correctly calculate the derivative of @xmath
we need to specify how neighbouring domains are related to each other.

This is done as follows : The same bivector @xmath is used to specify a
Lie dragging of the averaging region @xmath , ensuring that the volumes
of the averaging regions constructed at nearby supporting points are
coordinated in a well defined manner (which motivates the terminology
“coordination bivector” for @xmath , which we will follow henceforth).
Suppose @xmath and @xmath are the coordinates of two support points,
where @xmath is a small change in the parameter along the integral curve
of a given vector field @xmath . Symbolically denote the two points as
@xmath and @xmath . Then the averaging region at @xmath is defined in
terms of the averaging region @xmath at @xmath , by transporting every
point @xmath around @xmath along the appropriate integral curve of a new
bilocal vector field @xmath defined as @xmath , thereby constructing the
averaging region @xmath with support point @xmath .

We can now evaluate the Lie derivative of @xmath along the vector field
@xmath , by first noting that the Lie derivative of the volume @xmath is

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

where the semicolon denotes a covariant derivative. An easy way to see
this is to note that since

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

or symbolically @xmath , we will have

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

and the result ( 3.5 ) follows from writing

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

and using @xmath . For the derivative of @xmath , we need @xmath .
Explicitly we have

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

which after writing @xmath with @xmath and using ( 3.7 ), finally gives

  -- -------- -------- -- --------
     @xmath   @xmath      
                          
              @xmath      (3.10)
  -- -------- -------- -- --------

where we have defined the “bilocal partial derivative”

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Since the vector field @xmath is arbitrary, Eqn. ( 3.10 ) gives us an
expression for the partial derivative @xmath (recalling that @xmath ).
Requiring that partial derivatives of @xmath commute, leads to the
following condition

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

Straightforward algebra shows that

  -- -------- -------- -- --------
     @xmath   @xmath      (3.13)
     @xmath   @xmath      (3.14)
  -- -------- -------- -- --------

and hence the necessary and sufficient condition for ( 3.12 ) to hold,
is

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

where underlined indices are not antisymmetrized.

At this stage it is convenient to re-express results in the language of
differential forms, since it will make the algebra that follows concise
and readable. The original papers by Zalaletdinov introduce a
full-fledged bilocal exterior calculus, involving @xmath -forms which
are @xmath -forms at @xmath and @xmath -forms at @xmath . In what
follows however, we will almost exclusively only need to deal with
@xmath -forms that are differential forms at a single event @xmath ,
although they may be bilocal in their functional dependence on events
@xmath and @xmath . This is because we will only deal with bilocal
extensions of local @xmath -forms, which are defined to be @xmath
-forms. For example, the bilocal extension of a @xmath -form @xmath is
defined as

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

which is a @xmath -form. We define the bilocal exterior derivative as

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

where d is the usual exterior derivative which “differentiates and
antisymmetrizes at @xmath ”, and the “shifted” exterior derivative
@xmath “differentiates at @xmath but antisymmetrizes at @xmath ” so
that, say for the @xmath -form @xmath , we have

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

For a bilocal function @xmath we will have @xmath . In this language,
the preceding results for differential conditions on the coordination
bivector can be generalised to arbitrary tensor-valued @xmath -forms. In
particular for a vector-valued @xmath -form @xmath whose bilocal
extension is the @xmath -form @xmath , we have

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

where we have defined,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.20)
  -- -------- -------- -- --------

The condition ( 3.15 ) for the averaged object to be a local function of
its argument, reduces to

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

Eqn. ( 3.19 ) shows that it is desirable to choose a coordination
bivector which satisfies

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

since firstly, this allows us to commute the exterior derivative with
the averaging according to

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

and secondly, it implies that the volume of the averaging region is held
constant during the coordination (see Eqn. ( 3.5 )), and is therefore a
free parameter in the formalism.

Mars and Zalaletdinov [ 44 ] show in their Theorems 1, 3 and 4, that
firstly, the general solution of Eqn. ( 3.21 ) for an idempotent
coordination bivector is given by

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

where @xmath is any vector basis satisfying the commutation relations

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

and secondly, that Eqn. ( 3.22 ) with the coordination bivector given by
Eqn. ( 3.24 ) is always integrable on a differentiable manifold with a
given volume @xmath -form. The proofs given in Ref. [ 44 ] are very
clear, although somewhat lengthy, and we will hence omit them here.
Further, these authors also show that for the special class of bivectors
for which @xmath , the vectors @xmath form a coordinate basis, with
‘proper’ coordinate functions @xmath say, so that

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

and satisfying Eqn. ( 3.22 ) makes this proper coordinate system volume
preserving, with @xmath constant. When expressed in terms of such a
volume preserving coordinate (VPC) system, the coordination bivector
takes its most simple form, namely

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

Volume preserving coordinates in fact form a large class in themselves,
generalizing the Cartesian coordinate system of Minkowski spacetime. For
a discussion on the properties of VPCs and the associated bivectors
@xmath , see Sec. 8 of Ref. [ 44 ] . The problem of defining an
averaging operator has now been reduced to the far simpler problem of
choosing a specific VPC system which then fixes the coordination
bivector. We emphasize that the averaging is still fully covariant;
choosing a coordination bivector is distinct from choosing a coordinate
system to perform calculations in. This freedom in defining the
coordination bivector leads to a lack of uniqueness of the average in
the formalism as it stands. We will return to this issue when we study
the backreaction arising from perturbative inhomogeneities in chapter 4.

### 3.2 The averaged manifold

With the averaging operation in place, we can turn to the description of
an averaged geometry . Let us begin by recalling some standard results
from differential geometry. Given a differentiable manifold @xmath
endowed with a metric @xmath of Lorentzian signature @xmath , the
connection @xmath -forms @xmath are defined by the action of the
exterior derivative on the basis vectors @xmath [ 66 ] :

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

where @xmath are the Christoffel symbols and the parentheses represent
the inner product with @xmath . We define the “exterior covariant
derivative” @xmath associated with the connection @xmath , as follows :
for a @xmath -form @xmath ,

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

with an obvious generalisation to higher rank objects. The compatibility
between the metric and the connection on @xmath is expressed by the
condition

  -- -------- -- --------
     @xmath      (3.30)
  -- -------- -- --------

with a similar condition for the inverse metric @xmath . The Cartan
structure equations are given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.31a)
     @xmath   @xmath      (3.31b)
  -- -------- -------- -- ---------

where Eqn. ( 3.31a ) expresses the symmetry of the connection @xmath and
@xmath is the curvature @xmath -form on @xmath which defines the Riemann
curvature tensor via @xmath . Finally, the structure equations ( 3.31 )
and the metric compatibility condition ( 3.30 ) are supplemented by
their respective integrability conditions, given by equations ( 3.32a ),
( 3.32b ) and ( 3.32c )

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.32a)
     @xmath   @xmath      (3.32b)
     @xmath   @xmath      (3.32c)
  -- -------- -------- -- ---------

Note that Eqn. ( 3.32a ) corresponds to the cyclic identity @xmath and
Eqn. ( 3.32b ) to the Bianchi identity @xmath .

Consider now the bilocal version of the basis vector @xmath , given by
@xmath , which is a scalar at @xmath and a vector at @xmath , and whose
inverse is the @xmath -form @xmath . The construction of an averaged
manifold begins with the observation that the @xmath -form defined by

  -- -------- -- --------
     @xmath      (3.33)
  -- -------- -- --------

transforms like a connection under coordinate transformations at @xmath
and, equally importantly, as a scalar at @xmath , and further has the
coincidence limit

  -- -------- -- --------
     @xmath      (3.34)
  -- -------- -- --------

Explicitly, we have

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.35)
  -- -------- -------- -- --------

where @xmath is symmetric in @xmath due to the condition ( 3.21 ) or (
3.15 ). This explicit form can be used to directly check the
transformation properties at @xmath and @xmath , and @xmath can
therefore be considered as the bilocal extension of the connection
@xmath .

The transformation properties of @xmath imply that its average @xmath ,

  -- -------- -- --------
     @xmath      (3.36)
  -- -------- -- --------

has the transformation properties of a local connection, and the
coincidence limit ( 3.34 ) implies the limit @xmath . This leads to the
key idea of MG, which is that @xmath , is defined as the connection
@xmath -form on a new, averaged manifold @xmath . As a set, @xmath is
identical to @xmath ; however for consistency in the definition of
averaged quantities, the guiding principle one adopts is that each
averaging domain @xmath is effectively treated as a single point on
@xmath . This ensures, for example, that the averaging operation is
idempotent [ 44 ] .

The goal now is to average out the bilocal extensions of the structure
equations ( 3.31 ) and the compatibility condition ( 3.30 ) and their
integrability conditions ( 3.32 ), and to express them in terms of
appropriate differential forms defined on @xmath . The bilocal
extensions of Eqns. ( 3.31 ) and ( 3.30 ), are respectively given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.37a)
     @xmath   @xmath      (3.37b)
     @xmath   @xmath      (3.37c)
  -- -------- -------- -- ---------

where, in the last equation, @xmath is the bilocal covariant exterior
derivative associated with the bilocal connection @xmath . The
integrability conditions of Eqns. ( 3.37 ) are given by the bilocal
extensions of Eqns. ( 3.32 ),

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.38a)
     @xmath   @xmath      (3.38b)
     @xmath   @xmath      (3.38c)
  -- -------- -------- -- ---------

In the above equations, the @xmath -form @xmath is the bilocal extension
of the curvature @xmath -form constructed according to the rules set out
in Eqns. ( 3.16 ) and ( 3.3 ). Similarly the @xmath -form @xmath is the
bilocal extension of the metric. To proceed with the averaging, a
correlation @xmath -form is defined

  -- -------- -- --------
     @xmath      (3.39)
  -- -------- -- --------

The average of the curvature @xmath -form @xmath on @xmath is denoted
@xmath , and the curvature @xmath -form on the averaged manifold @xmath
is denoted @xmath ,

  -- -------- -- --------
     @xmath      (3.40)
  -- -------- -- --------

Equations ( 3.37a ) and ( 3.37b ) then average out to give

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.41a)
     @xmath   @xmath      (3.41b)
  -- -------- -------- -- ---------

The averages of Eqn. ( 3.38a ) and the identity @xmath give us

  -- -------- -- --------
     @xmath      (3.42)
  -- -------- -- --------

and the symmetry of @xmath and hence of @xmath give us

  -- -------- -- --------
     @xmath      (3.43)
  -- -------- -- --------

This ensures that the curvature @xmath -form @xmath satisfies the
correct algebraic identities

  -- -------- -- --------
     @xmath      (3.44)
  -- -------- -- --------

The formalism at this stage becomes somewhat complicated. The reason is
that there is no simple way of averaging out equations ( 3.37c ), (
3.38b ) and ( 3.38c ), which become

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.45a)
     @xmath   @xmath      (3.45b)
     @xmath   @xmath      (3.45c)
  -- -------- -------- -- ---------

where @xmath . What we need are “splitting rules” for the various
products appearing inside the averager in these equations. Of these,
Eqn. ( 3.45b ) can be split by noting that the exterior covariant
derivative of the correlation @xmath -form becomes

  -- -------- -- --------
     @xmath      (3.46)
  -- -------- -- --------

where the symbol @xmath permutes the free indices in, say @xmath
pairwise according to @xmath , and any summed indices are ignored, and
the correlation 3-form is defined as

  -- -------- -- --------
     @xmath      (3.47)
  -- -------- -- --------

Tracing Eqn. ( 3.46 ) on the indices @xmath and @xmath kills the term
involving the correlation @xmath -form due to the presence of the
permutation symbol, leaving behind

  -- -------- -- --------
     @xmath      (3.48)
  -- -------- -- --------

which averages out Eqn. ( 3.45b ) to give the Bianchi identity for the
curvature @xmath -form @xmath ,

  -- -------- -- --------
     @xmath      (3.49)
  -- -------- -- --------

This was achieved at the cost of introducing a new object, the
correlation @xmath -form @xmath , which fixes the differential
properties of the correlation @xmath -form @xmath and hence of the
@xmath -form @xmath . The differential properties of this @xmath -form
are in turn fixed by introducing a correlation 4-form in an analogous
manner. Due to the @xmath -dimensionality of spacetime there are no
higher correlation @xmath -forms that need to be defined.

In practice, it is cumbersome to keep track of the correlation @xmath
-form and @xmath -form, and furthermore it is only the correlation
@xmath -form which will appear in the averaged Einstein equations. We
will ultimately be interested in explicit calculations of the
correlation objects in a perturbative setting at leading order, and will
hence ignore the @xmath -form and @xmath -form. Remarkably, it is also
possible to self-consistently ignore these forms in the nonperturbative
setting [ 43 ] as follows : We set the @xmath -form and @xmath -form to
zero and impose the conditions

  -- -------- -- --------
     @xmath      (3.50)
  -- -------- -- --------

with the second equality required since Eqn. ( 3.49 ) holds. It can be
shown [ 43 ] that requiring the @xmath -form to vanish also imposes the
condition

  -- -------- -- --------
     @xmath      (3.51)
  -- -------- -- --------

The integrability condition for @xmath is

  -- -------- -- --------
     @xmath      (3.52)
  -- -------- -- --------

which also contains the integrability condition for @xmath .

So far we have only managed to average out Eqn. ( 3.45b ). To make
progress with Eqns. ( 3.45a ) and ( 3.45c ) we need additional
assumptions. Zalaletdinov argues [ 43 ] that for a class of slowly
varying tensor fields (tensor-valued @xmath -forms) @xmath on @xmath
such as the metric and other covariantly constant tensors, and Killing
tensors, etc., the following assumptions may be reasonable

  -- -------- -- ---------
     @xmath      (3.53a)
     @xmath      (3.53b)
  -- -------- -- ---------

Then Eqn. ( 3.45a ) and its analogue for @xmath average out to give

  -- -------- -- --------
     @xmath      (3.54)
  -- -------- -- --------

Further, for a general slowly varying object @xmath , the following
identity holds

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.55)
  -- -------- -------- -- --------

which follows from differentiating Eqn. ( 3.53a ), and which averages
out Eqn. ( 3.45c ) (and its analogue for @xmath ) to give

  -- -------- -- --------
     @xmath      (3.56)
  -- -------- -- --------

Eqn. ( 3.54 ) allows one to choose @xmath , where @xmath is the metric
on the averaged manifold @xmath . In general however, we have @xmath ,
and one defines the tensor @xmath to keep track of this difference.
However, we shall see later that when the averaged manifold is highly
symmetric, as in the case of a manifold with homogeneous and isotropic
spatial sections which we will consider, one finds that @xmath .

### 3.3 Averaging Einstein’s equations

In the general case, it turns out that Eqn. ( 3.55 ) is all that is
needed to average out the Einstein equations

  -- -------- -- --------
     @xmath      (3.57)
  -- -------- -- --------

where @xmath , @xmath is the microscopic energy momentum tensor of the
matter distribution, and the Ricci tensor @xmath on @xmath is defined
according to the sign convention @xmath . The averaging leads to the
equations

  -- -------- -- --------
     @xmath      (3.58)
  -- -------- -- --------

where @xmath is the Ricci tensor on @xmath and we have defined

  -- -------- -- --------
     @xmath      (3.59)
  -- -------- -- --------

The averaged equations ( 3.58 ) differ from the usual Einstein equations
by the correlation tensor which we define as

  -- -------- -- --------
     @xmath      (3.60)
  -- -------- -- --------

Hence, denoting the Einstein tensor on @xmath as @xmath , and defining
the tensor @xmath via

  -- -------- -- --------
     @xmath      (3.61)
  -- -------- -- --------

the averaged Einstein equations read

  -- -------- -- --------
     @xmath      (3.62)
  -- -------- -- --------

Since the left hand side of Eqn. ( 3.62 ) is covariantly conserved by
construction ( @xmath ), where the semicolon denotes covariant
differentiation with respect to the connection on @xmath , in general
one has

  -- -------- -- --------
     @xmath      (3.63)
  -- -------- -- --------

with no condition on @xmath and @xmath separately. If, however, we
assume that @xmath , it follows that

  -- -------- -- --------
     @xmath      (3.64)
  -- -------- -- --------

which implies that the averaged energy-momentum tensor @xmath is also
covariantly conserved. In our explicit calculations in the perturbative
setting in chapter 4, we will see that this condition does not hold in
general.

It can also be shown that in 4 dimensions, the 720 a priori independent
components of @xmath are subject to 680 constraints arising from Eqns. (
3.52 ) and ( 3.51 ). This leaves 40 independent components which combine
to give the 10 independent components of the correlation tensor @xmath .
The conditions in Eqns. ( 3.52 ) and ( 3.51 ) do not constrain the
components of @xmath , which follows from considering the structure of
those equations.

### 3.4 A @xmath spacetime splitting and the spatial averaging limit

We are now in a position to apply the MG formalism to the problem of
cosmology. The main idea we wish to emphasize is that in the
cosmological context, it is essential to consider a spatial averaging
limit of the covariant averaging used in MG. The simplest way to see
this is to note that the homogeneous and isotropic FLRW spacetime ¹ ¹ 1
Appendix A describes the main features of the FLRW spacetime. must be
left invariant under the averaging operation, and this is only possible
if the averaging is tuned to the uniquely defined spatial slices of
constant curvature in the FLRW spacetime. We will elaborate on this
below. Our main motivation here is to spell out all the assumptions
usually made in the standard approach to cosmology, and ask what they
imply in the context of the averaging paradigm. It has been suggested
that the observationally relevant averaging must necessarily be
performed on the light cone [ 67 ] . This would not preserve the
symmetries of the FLRW spacetime. Our point of view is that one needs a
theoretically self-consistent mathematical framework in which to study
cosmological expansion, structure formation, etc. We will be
conservative in our approach and only make the minimum assumptions
necessary in order to make standard cosmology compatible with the
averaging paradigm.

We start with the assumption that Einstein’s equations are to be imposed
on length scales @xmath where stars are pointlike objects, and that
there exists a length scale @xmath such that averaging on this length
scale yields a geometry which has homogeneous and isotropic spatial
sections. We expect @xmath Mpc and we assume @xmath where @xmath is the
length scale of the observable universe. In other words, we will assume
that the averaged manifold @xmath admits a preferred,
hypersurface-orthogonal unit timelike vector field @xmath , which
defines @xmath -dimensional spacelike hypersurfaces of constant
curvature, and that @xmath is tangent to the trajectories of observers
who see an isotropic cosmic background radiation. For simplicity we will
work with the special case where these spatial sections on @xmath are
flat. One can then choose coordinates @xmath , @xmath , on @xmath such
that the spatial line element takes the form

  -- -------- -- --------
     @xmath      (3.65)
  -- -------- -- --------

where @xmath for @xmath , and @xmath otherwise, and we have @xmath so
that the spatial coordinates are comoving with the preferred observers.
The vector field @xmath also defines a proper time (the cosmic time)
@xmath such that @xmath . We will further assume that the averaged
energy-momentum tensor @xmath can be written in the form of a perfect
fluid, as

  -- -------- -- --------
     @xmath      (3.66)
  -- -------- -- --------

where the projection operator @xmath is defined as

  -- -------- -- --------
     @xmath      (3.67)
  -- -------- -- --------

and satisfies @xmath , @xmath , and @xmath and @xmath are the
homogeneous energy density and pressure respectively, as measured by
observers moving on trajectories (in @xmath ) with the tangent vector
field @xmath ,

  -- -------- -- --------
     @xmath      (3.68)
  -- -------- -- --------

An important consequence of the above assumptions is that the
correlation tensor @xmath , when expressed in terms of the natural
coordinates adapted to the spatial sections defined by the vector field
@xmath , is homogeneous and depends only on the time coordinate. This is
clear when the modified Einstein equations ( 3.62 ) are written in these
natural coordinates.

Using the vector field @xmath , the (FLRW) Einstein tensor @xmath can be
written as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.69)
  -- -------- -------- -- --------

where @xmath and @xmath are scalar functions whose form depends upon the
coordinates used. The remaining components given by @xmath and the
traceless part of @xmath , vanish identically. Since the energy-momentum
tensor @xmath in Eqn. ( 3.66 ) also has an identical structure, this
structure is therefore also imposed on the correlation tensor @xmath .
Namely, only the components @xmath and the trace @xmath are relevant to
the dynamics of the averaged metric. The remaining components, namely
@xmath and the traceless part of @xmath , must vanish . This is a
condition on the underlying inhomogeneous geometry, irrespective of the
coordinates used to describe the geometry on either @xmath or @xmath ,
and is clearly a consequence of demanding that the averaged geometry
have the symmetries of the FLRW spacetime.

This leads us to the crucial question of the choice of gauge for the
underlying geometry : namely, what choice of spatial sections for the
inhomogeneous geometry, will lead to the spatial sections of the FLRW
metric in the comoving coordinates defined in Eqn. ( 3.65 )? Since the
matter distribution at scale @xmath need not be pressure-free (or,
indeed, even of the perfect fluid form), there is clearly no natural
choice of gauge available, although locally, a synchronous reference can
always be chosen. We note that there must be at least one choice of
gauge in which the averaged metric has spatial sections in the form (
3.65 ) – this is simply a refinement of the Cosmological Principle, and
of the Weyl postulate, according to which the universe is homogeneous
and isotropic on large scales, and individual galaxies are considered as
the “observers” travelling on trajectories with tangent @xmath . In the
averaging approach, it makes more sense to replace “individual galaxies”
with the averaging domains considered as physically infinitesimal cells
– the “points” of the averaged manifold @xmath . This is physically
reasonable since we know after all, that individual galaxies exhibit
peculiar motions, undergo mergers and so on. This idea is also more in
keeping with the notion that the universe is homogeneous and isotropic
only on the largest scales , which are much larger than the scale of
individual galaxies.

Consider any @xmath spacetime splitting in the form of a lapse function
@xmath , a shift vector @xmath , and a metric for the @xmath -geometry
@xmath , so that the line element on @xmath can be written as

  -- -------- -- --------
     @xmath      (3.70)
  -- -------- -- --------

where @xmath . At first sight, it might seem reasonable to leave the
choice of gauge arbitrary. One could then formally consider a
coordination bivector given by the Eqns. ( 3.24 ) and ( 3.26 ), with
@xmath denoting the coordinates in the chosen gauge and @xmath the VPCs;
and demand for example, that the metric ( 3.70 ) (with say @xmath )
average out to the FLRW form (with a nonsynchronous time coordinate in
general). This would imply

  -- -------- -- --------
     @xmath      (3.71)
  -- -------- -- --------

Note that the condition on the bilocal extension @xmath is in general
nontrivial even when the components @xmath are chosen to be zero. In the
Appendix ( C.1 ) we show that with the above assumptions, for a general
lapse function @xmath , the conditions @xmath (Eqn. ( 3.54 )) also allow
us to choose

  -- -------- -- --------
     @xmath      (3.72)
  -- -------- -- --------

However, it turns out that if we make the assumption that the spatial
sections on @xmath leading to the spatial metric ( 3.65 ) on @xmath ,
are spatial sections in a volume preserving gauge , then the correlation
terms simplify greatly. This is not surprising since the MG formalism is
nicely adapted to the choice of volume preserving coordinates. Moreover,
as we will see in chapter 4, at least in the perturbative context a
modified version of this “VP gauge assumption” in fact becomes a
necessity in order to consistently set up the formalism. We will
therefore introduce spatial averaging in MG by making the VP gauge
assumption, and will then calculate the correlation terms and display
the modified equations resulting from this choice of gauge. Following
that calculation we will also show how the correlation terms can be
generalized to the case where the gauge in the inhomogeneous metric is
(formally) left unspecified.

To begin our first calculation, we perform a coordinate transformation
and shift to the gauge wherein the new lapse function @xmath is given by
@xmath where @xmath is the determinant of the new @xmath -metric,
denoted @xmath . In general, one will now be left with a non-zero shift
vector @xmath ; however, the condition @xmath ensures that the
coordinates we are now using are volume preserving, since the metric
determinant is given by @xmath . We denote these volume preserving
coordinates (VPCs) by @xmath , and will assume that the spatial
coordinates are noncompact. For simplicity, we make the added assumption
that @xmath in the inhomogenous geometry ² ² 2 We are making the
assumption @xmath in the volume preserving gauge for algebraic
convenience only – in our case this assumption cannot be justified by
the absence of vorticity. A more detailed (and complicated) analysis
should retain an arbitrary @xmath in the inhomogeneous geometry, and
make assumptions about its average – such as @xmath for example. , so
that @xmath and @xmath . The line element for the inhomogenous manifold
@xmath becomes

  -- -------- -- --------
     @xmath      (3.73)
  -- -------- -- --------

Note that in this gauge, the average takes on a particularly simple form
: for a tensor @xmath , with a spacetime averaging domain given by the
“cuboid” @xmath defined by

  -- -------- -- --------
     @xmath      (3.74)
  -- -------- -- --------

where @xmath and @xmath are averaging time and length scales
respectively, the average is given by

  -- -------- -- --------
     @xmath      (3.75)
  -- -------- -- --------

We define the “spatial averaging limit” as the limit @xmath (or @xmath )
which is interpreted as providing a definition of the average on a
spatial domain corresponding to a “thin” time slice, the averaging
operation now being given by

  -- -------- -- --------
     @xmath      (3.76)
  -- -------- -- --------

(Note the time dependence of the integrand.) Henceforth, averaging will
refer to spatial averaging, and will be denoted by @xmath , in contrast
to the spacetime averaging considered thus far (denoted by @xmath ) ³ ³
3 The choice of a cube with sides of length @xmath as the spatial
averaging domain was arbitrary, and is in fact not essential for any of
the calculations to follow. In particular, all calculations can be
performed with a spatial domain of arbitrary shape. We will only use the
cube for definiteness and simplicity in displaying equations. . The
significance of introducing a spatial averaging in this manner is that
the construction of spatial averaging is not isolated from spacetime
averaging, but is a special limiting case of the latter and is, in fact,
still a fully covariant operation.

For the volume preserving gauge, the averaging assumption ( 3.71 )
reduces to

  -- -------- -- --------
     @xmath      (3.77)
  -- -------- -- --------

where @xmath and @xmath are some functions of the time coordinate alone.
A few remarks are in order on this particular choice of assumptions.
Apart from the fact that the spacetime averaging operation takes on its
simplest possible form ( 3.75 ) in this gauge and allows a transparent
definition of the spatial averaging limit, it can also be shown that the
assumptions in Eqn. ( 3.77 ) are sufficient to establish the following
relations :

  -- -------- -- --------
     @xmath      (3.78)
  -- -------- -- --------

Here the second equality arises from the condition @xmath which can be
assumed whenever the averaged metric is of the FLRW form (see Appendix (
C.1 )). The last equality follows on considering the conditions @xmath
in obvious notation, (the basic assumption of the MG averaging scheme),
details of which can be found in the Appendix ( C.2 ). Eqn. ( 3.78 )
reduces the line element on @xmath to the form

  -- -------- -- --------
     @xmath      (3.79)
  -- -------- -- --------

The line element in Eqn. ( 3.79 ) clearly corresponds to the FLRW metric
in a volume preserving gauge which differs from the standard synchronous
and comoving gauge, only by a redefinition of the time coordinate. The
vector field @xmath introduced at the beginning of this section and
which defines the FLRW spatial sections, is now given by

  -- -------- -- --------
     @xmath      (3.80)
  -- -------- -- --------

Note that @xmath is not in general the average of the vector field
@xmath which defines the @xmath splitting on @xmath , but (at least in
the volume preserving gauge) is related to it by

  -- -------- -- --------
     @xmath      (3.81)
  -- -------- -- --------

(A simple relation such as ( 3.81 ) cannot in general be written for an
arbitrary gauge.)

As mentioned earlier, the spatial averaging limit of the covariant MG
averaging is important because we want the homogeneous and isotropic
FLRW geometry to average to itself. Since the FLRW geometry has a
preferred set of spatial sections, one therefore needs to average over
these sections. Further, since the FLRW metric adapted to its preferred
spatial sections depends on the time coordinate, it is also essential
that the spacetime average involve a time range that is short compared
to the scale over which say the scale factor changes significantly.
Clearly then, averaging the FLRW metric (denoted @xmath ) given in Eqn.
( 3.79 ) will strictly yield the same metric only in the limit @xmath .
Namely, for the cuboid @xmath defined in Eqn. ( 3.74 )

  -- -------- -- --------
     @xmath      (3.82)
  -- -------- -- --------

which should be clear from the definition of the metric. The result
@xmath in the spatial averaging limit can also be shown to hold for the
FLRW metric in synchronous gauge, where the coordination bivector @xmath
can be easily computed using the transformation from the VPCs @xmath to
the synchronous coordinates @xmath given by

  -- -------- -- --------
     @xmath      (3.83)
  -- -------- -- --------

The transformation ( 3.83 ) will also later allow us to write the
averaged equations in the synchronous gauge for the averaged geometry.

### 3.5 The correlation @xmath-form and the averaged field equations

#### 3.5.1 Results for the Volume Preserving Gauge

In any gauge with @xmath , the expansion tensor @xmath is given by

  -- -------- -- --------
     @xmath      (3.84)
  -- -------- -- --------

The notation is the same as used in chapter 2, and the expansion scalar
@xmath , shear tensor @xmath and shear scalar @xmath are defined as
before. Note that

  -- -------- -- --------
     @xmath      (3.85)
  -- -------- -- --------

The connection @xmath -forms @xmath in terms of the expansion tensor,
are listed below for an arbitrary lapse function @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.86)
  -- -------- -------- -- --------

where @xmath is the Christoffel symbol built from the @xmath -metric
@xmath and its inverse. Specializing now to the volume preserving gauge
( @xmath ), the bilocal extensions @xmath of the connection @xmath
-forms are trivial and are simply given by

  -- -------- -- --------
     @xmath      (3.87)
  -- -------- -- --------

Since @xmath , the connection @xmath -forms @xmath for the averaged
manifold @xmath are constructed using the FLRW metric in volume
preserving gauge given in Eqn. ( 3.79 ), and are given by

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.88)
  -- -------- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (3.89)
  -- -------- -- --------

Using Eqns. ( 3.86 ) with @xmath , Eqn. ( 3.87 ) and Eqns. ( 3.88 ), we
can now easily construct the correlation @xmath -form @xmath defined in
Eqn. ( 3.39 ). For completeness, we will display all the nontrivial
components @xmath , although not all of them will be relevant for the
final equations. The condition @xmath has the effect that several of the
Christoffel symbols (which can be read off from Eqn. ( 3.86 )) become
related to each other. For example, we have @xmath , and so on. Denoting
the spatial average of some quantity @xmath as simply @xmath , we have

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      
              @xmath      
              @xmath      (3.90a)
     @xmath   @xmath      
              @xmath      
              @xmath      (3.90b)
     @xmath   @xmath      
              @xmath      (3.90c)
     @xmath   @xmath      (3.90d)
     @xmath   @xmath      
              @xmath      
              @xmath      (3.90e)
     @xmath   @xmath      
              @xmath      (3.90f)
     @xmath   @xmath      (3.90g)
     @xmath   @xmath      
              @xmath      
              @xmath      (3.90h)
     @xmath   @xmath      (3.90i)
  -- -------- -------- -- ---------

where we have used the relation @xmath .

It is now straightforward to use the relations in Eqn. ( 3.59 ) (note
the unconventional normalization of the @xmath -form) to read off the
components @xmath and hence perform the required summations to construct
@xmath . This, together with the fact that @xmath (see Appendix ( C.1
)), allows us to construct the correlation tensor @xmath defined in Eqn.
( 3.60 )

  -- -------- -- --------
     @xmath      (3.91)
  -- -------- -- --------

Now, the components of the Einstein tensor @xmath for the averaged
spacetime with metric ( 3.79 ) are given by

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.92)
  -- -------- -------- -- --------

where the peculiar splitting of terms in the last equation is for later
convenience. Recall that the overdot denotes a derivative with respect
to the VPC time @xmath , not synchronous time. In terms of the
coordinate independent objects introduced in Eqn. ( 3.69 ), we have

  -- -------- -- --------
     @xmath      (3.93)
  -- -------- -- --------

From the averaged Einstein equations in ( 3.62 ) we next construct the
scalar equations which in the standard case would correspond to the
Friedmann equation and the Raychaudhuri equation. These correspond to
the Einstein tensor components,

  -- -------- -- --------
     @xmath      (3.94)
  -- -------- -- --------

and are given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.95a)
     @xmath   @xmath      (3.95b)
  -- -------- -------- -- ---------

Here Eqn. ( 3.95a ) is the modified Friedmann equation and Eqn. ( 3.95b
) the modified Raychaudhuri equation (in the volume preserving gauge on
@xmath ). We have used Eqn. ( 3.68 ), with the overbar on @xmath and
@xmath reminding us that they are expressed in terms of the
nonsynchronous time @xmath , and we have defined the correlation terms

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (3.96a)
                          
     @xmath   @xmath      (3.96b)
                          
     @xmath   @xmath      (3.96c)
                          
     @xmath   @xmath      (3.96d)
  -- -------- -------- -- ---------

We have used the second relation in Eqn. ( 3.85 ) in defining @xmath .
@xmath and @xmath are correlations of the extrinsic curvature, whereas
@xmath and @xmath are correlations restricted to the intrinsic @xmath
-geometry of the spatial slices of @xmath . Since the components of
@xmath are not explicitly constrained by Eqns. ( 3.51 ) and ( 3.52 ), we
can treat the combinations @xmath and @xmath as independent, subject
only to the differential constraints ( 3.64 ) which follow if we assume
@xmath . We will return to these below.

As discussed earlier, the remaining components of @xmath must be set to
zero, giving constraints on the underlying inhomogeneous geometry. In
coordinate independent language, these constraints read

  -- -------- -- --------
     @xmath      (3.97)
  -- -------- -- --------

Eqns. ( 3.97 ) reduce to the following for our specific choice of volume
preserving coordinates,

  -- -------- -- --------
     @xmath      (3.98)
  -- -------- -- --------

or, in full detail,

  -- -------- -- ---------
                 
     @xmath      
     @xmath      (3.99a)
     @xmath      
     @xmath      (3.99b)
     @xmath      
     @xmath      (3.99c)
  -- -------- -- ---------

where @xmath . Eqns. ( 3.86 ) with the choice @xmath show that all the
terms paired within square brackets in Eqns. ( 3.99 ) above, as also the
correlations @xmath and @xmath defined in Eqns. ( 3.96c ) and ( 3.96d ),
are of the form

  -- -------- -- ---------
     @xmath      (3.100)
  -- -------- -- ---------

The assumption in Eqn. ( 3.53b ) shows that one can write

  -- -------- -- ---------
     @xmath      (3.101)
  -- -------- -- ---------

An interesting point is that the VPC assumption @xmath also allows us to
assume @xmath consistently with the formalism (details in Appendix ( C.2
)). Using Eqn. ( 3.78 ) this gives us

  -- -------- -- ---------
     @xmath      (3.102)
  -- -------- -- ---------

This leads to some remarkable cancellations in Eqns. ( 3.99 ), and also
shows that the correlation terms @xmath and @xmath in fact vanish,

  -- -------- -- ---------
     @xmath      (3.103)
  -- -------- -- ---------

Eqns. ( 3.99 ) simplify to give

  -- -------- -- ----------
                 
     @xmath      (3.104a)
     @xmath      (3.104b)
     @xmath      (3.104c)
  -- -------- -- ----------

These simplifications are solely a consequence of assuming that the
inhomogeneous metric in the volume preserving gauge averages out to give
the FLRW metric in standard form. In general, these simplifications will
not occur when the standard FLRW metric arises from an arbitrary choice
of gauge for the inhomogeneous metric.

In order to come as close as possible to the standard approach in
cosmology, we will now rewrite the scalar equations ( 3.95 ) (which are
the cosmologically relevant ones) after performing the transformation
given in Eqn. ( 3.83 ) in order to get the FLRW metric to the form

  -- -------- -- ---------
     @xmath      (3.105)
  -- -------- -- ---------

Since Eqns. ( 3.95 ) are scalar equations, this transformation only has
the effect of re-expressing all the terms as functions of the
synchronous time @xmath . Although the transformation will change the
explicit form of the coordination bivector @xmath , this change involves
only the time coordinate, and in the spatial averaging limit there is no
difference between averages computed in the VPCs and those computed
after the time redefinition. This again emphasizes the importance of the
spatial averaging limit of spacetime averaging, if we are to succeed
operationally in explicitly displaying the correlations as corrections
to the standard cosmological equations. The correlation terms in Eqns. (
3.96 ) are therefore still interpreted with respect to the volume
preserving gauge, but are treated as functions of @xmath . For the scale
factor on the other hand, we have

  -- -------- -- ---------
     @xmath      (3.106)
  -- -------- -- ---------

Further writing

  -- -------- -- ---------
     @xmath      (3.107)
  -- -------- -- ---------

equations ( 3.95 ) become

  -- -------- -------- -- ----------
                          
     @xmath   @xmath      (3.108a)
                          
     @xmath   @xmath      (3.108b)
  -- -------- -------- -- ----------

We emphasize that the quantities @xmath and @xmath , defined in Eqns. (
3.96a ) and ( 3.96b ) as correlations in the volume preserving gauge,
are to be thought of as functions of the synchronous time @xmath , where
the synchronous time coordinate itself was defined after the spatial
averaging. Such an identification is justified since we are dealing with
scalar combinations of these quantities. Note that @xmath and @xmath can
be treated independently, apart from the constraints imposed by Eqn. (
3.64 ), which we turn to next. These conservation conditions can be
decomposed into a scalar part and a @xmath -vector part, given
respectively by

  -- -------- -- ---------
     @xmath      (3.109)
  -- -------- -- ---------

In the synchronous gauge ( 3.105 ) for the FLRW metric, the scalar
equation reads

  -- -------- -- ---------
     @xmath      (3.110)
  -- -------- -- ---------

We recall that this equation is a consequence of setting the correlation
3-form and the correlation 4-form to zero, and it relates the evolution
of @xmath and @xmath . The @xmath -vector equation (on imposing the
first set of conditions in Eqn. ( 3.97 )) simply gives @xmath , so that
@xmath constant, which also implies that @xmath constant and hence this
equation gives nothing new. (We have used the relations @xmath , @xmath
and @xmath where @xmath denotes the nonsynchronous time coordinate
@xmath .)

The cosmological equations ( 3.108 ), along with the constraint
equations ( 3.104 ) and ( 3.110 ) are the key results of this section.
Subject to the acceptance of the volume preserving gauge on the
underlying manifold @xmath they can in principle be used to study the
role of the correction terms resulting from spatial averaging.

#### 3.5.2 Results for an arbitrary gauge choice

In this subsection, we will display the results obtained on assuming
that the metric

  -- -------- -- ---------
     @xmath      (3.111)
  -- -------- -- ---------

averages out to the FLRW metric in standard form with a nonsynchronous
time coordinate @xmath in general, to give

  -- -------- -- ---------
     @xmath      (3.112)
  -- -------- -- ---------

In other words, we are assuming that the relations in Eqn. ( 3.71 )
hold. Note that the averaging operation is no longer trivial, although
we are still assuming an averaging on domains corresponding to “thin”
time slices. We again split the averaged Einstein equations into scalar
equations, and @xmath -vector and traceless @xmath -tensor equations.
After transforming to the synchronous time coordinate @xmath , now
defined by

  -- -------- -- ---------
     @xmath      (3.113)
  -- -------- -- ---------

and again defining @xmath and @xmath with @xmath , the modified
Friedmann and Raychaudhuri equations read

  -- -------- -------- -- ----------
                          
     @xmath   @xmath      (3.114a)
                          
     @xmath   @xmath      (3.114b)
  -- -------- -------- -- ----------

where the correlation terms are now defined using the relations,

  -- -------- -------- -- ----------
                          
     @xmath   @xmath      (3.115a)
                          
     @xmath   @xmath      (3.115b)
                          
     @xmath   @xmath      (3.115c)
                          
     @xmath   @xmath      (3.115d)
  -- -------- -------- -- ----------

We emphasize that averaging here refers to spatial averaging. Also
@xmath , and the index @xmath refers to the nonsynchronous time @xmath .
It is easy to check using Eqn. ( 3.86 ), that @xmath and @xmath
correspond to correlations of (the bilocal extensions of) the extrinsic
curvature with itself and with the time derivative of the lapse
function. @xmath corresponds to correlations between the Christoffel
symbols of the @xmath -geometry, and @xmath to correlations of the
spatial derivative of the lapse function with itself and with the
Christoffel symbols of the @xmath -geometry. Due to the way we have
defined these correlations, one can also check that when the lapse
function satisfies @xmath (so that the averaging becomes trivial), we
have @xmath , @xmath , and @xmath , where @xmath and @xmath were defined
in Eqns. ( 3.96 ). The @xmath -vector and traceless @xmath -tensor
equations become

  -- -------- -- ----------
                 
     @xmath      (3.116a)
     @xmath      (3.116b)
     @xmath      
     @xmath      (3.116c)
  -- -------- -- ----------

where the lower case index @xmath in the last equation runs over all
spacetime indices @xmath , with the index @xmath referring to the
nonsynchronous time @xmath . It is easy to check that Eqns. ( 3.116 )
reduce to Eqns. ( 3.104 ) with the choice @xmath . The condition @xmath
has the scalar part,

  -- -------- -- ---------
     @xmath      (3.117)
  -- -------- -- ---------

while the @xmath -vector part, as before, gives nothing new and simply
states @xmath .

We can now state the main result of this section as follows : Having
assumed that the FLRW spatial sections arise as the average of some
gauge choice with lapse function @xmath , spatial @xmath -metric @xmath
and shift vector @xmath set to zero for convenience, we can construct
the scalar quantities @xmath and @xmath which, in coordinates natural to
the FLRW metric take the form,

  -- -------- -- ---------
     @xmath      (3.118)
  -- -------- -- ---------

with the various quantities being defined in Eqns. ( 3.115 ). These
scalars modify the usual cosmological equations as shown in Eqns. (
3.114 ), and are themselves subject to the differential conditions (
3.117 ). In addition, for consistency of our assumptions with the
formalism, the underlying inhomogeneous metric is also subject to the
conditions ( 3.116 ).

The combinations on the right hand sides of the relations ( 3.118 ) can
clearly be treated independently, apart from the conditions ( 3.117 ).
Further, since the correlation @xmath -form has 40 independent
components @xmath after imposing all algebraic constraints, and since
none of the four quantities @xmath , @xmath , @xmath and @xmath are
trivially related by these constraints, one can always treat these four
functions independently of each other, subject only to the constraint in
Eqn. ( 3.117 ). In general this constraint may also not be satisfied,
and the correlation tensor may not be independently covariantly
conserved. In chapter 4 we will see the explicit time dependence of
these correlation objects in the perturbative setting in cosmology.

### 3.6 Comparing the approaches of Buchert and Zalaletdinov

An important motivation in studying the spatial averaging limit of MG
was to be able to compare its results with those of Buchert’s spatial
averaging. Buchert’s averaging is the only approach apart from
Zalaletdinov’s MG, which is capable of treating inhomogeneities in a
nonperturbative manner, although it is limited to using only scalar
quantities within a chosen @xmath splitting of spacetime. Buchert takes
the trace of the Einstein equations in the inhomogeneous geometry, and
averages these inhomogeneous scalar equations. In the context of
Zalaletdinov’s MG however, we have used the existence of the vector
field @xmath in the FLRW spacetime to construct scalar equations after
averaging the full Einstein equations. As far as observations are
concerned, it has been noted by Buchert and Carfora [ 42 ] , that the
spatially averaged matter density @xmath defined by Buchert is not the
appropriate observationally relevant quantity – the “observed” matter
density (and pressure) is actually defined in a homogeneous space. Since
we have done precisely this in Eqn. ( 3.68 ), we are directly dealing
with the appropriate observationally relevant quantity in the MG
framework.

Another important difference between the two approaches is the averaging
operation itself. Buchert’s spatial average, given by ( 2.4 ), is
different from the averaging operation we have been using (given by Eqn.
( 3.76 ) using the volume preserving gauge), which is a limit of a
spacetime averaging defined using the coordination bivector @xmath .
Further, since Buchert only averages two of the Einstein equations, a
major difference between the two schemes is the presence of the
constraints ( 3.104 ) on the underlying geometry. These are in general
nontrivial and hence indicate that it is not sufficient to assume that
the metric of the inhomogeneous manifold averages out to the FLRW form.

Most importantly though, Buchert’s averaging scheme by itself does not
incorporate the concept of an averaged manifold @xmath (although the
work of Buchert and Carfora [ 42 ] does deal with @xmath -spaces of
constant curvature). The question then arises as to how one should
interpret Buchert’s @xmath . If one does not wish to identify @xmath
with the scale factor in FLRW cosmology, one is compelled to develop a
whole new set of ideas in order to try and compare theory with
observation. On the other hand, if one does (naively) identify @xmath
with the scale factor, comparison with standard cosmology becomes more
convenient, but this introduces a possible inconsistency since we know
from Zalaletdinov’s approach that additional constraints need to be
satisfied. It is not clear how one should account for these constraints
since the non-scalar Einstein equations are not averaged in Buchert’s
approach.

It is our understanding that the MG approach is a complete and
self-consistent scheme which allows us to meaningfully pose questions in
the averaging paradigm, which are directly interpretable in terms of
standard cosmological ideas. The Buchert approach on the other hand, is
harder to interpret. In the MG approach, there are no unaveraged shear
equations, because the trace of the Einstein equations has been taken
after performing the averaging on the underlying geometry. Since the
averaged geometry is FLRW, its shear is zero by definition. There is a
natural metric on the averaged manifold by construction, the FLRW
metric. The correlations satisfy additional constraints, given by Eqns.
( 3.104 ). Thus, once a gauge has been chosen and if one can overcome
the computational complexity of the averaging operation, the
cosmological equations derived by us in the MG approach are complete and
ready for application, without any further caveats.

In spite of these differences, our equations ( 3.108 ) and ( 3.110 ) for
the volume preserving gauge are strikingly similar to Buchert’s
effective FLRW equations and their integrability condition in the dust
case; and in the case of general @xmath , the role of Buchert’s
dynamical backreaction @xmath in Eqns. ( 2.15 ) and ( 2.19 ) is
identical to that of our combination of @xmath in Eqns. ( 3.114b ) and (
3.117 ). Concentrating on the volume preserving case, the structure of
the correlation @xmath is identical to Buchert’s kinematical
backreaction @xmath (or @xmath in the general case). The correlation
@xmath appears in place of the averaged @xmath -Ricci scalar @xmath in
Buchert’s dust equations. This is not unreasonable since Buchert’s
@xmath can be thought of as @xmath corrections, where @xmath represents
the @xmath -Ricci scalar on the averaged manifold which in our case is
zero, and hence @xmath represents the corrections due to averaging.
Further, these similarities are in spite of the fact that our
correlations were defined assuming that a volume preserving gauge
averages out to the FLRW @xmath -metric in standard form, whereas
Buchert’s averaging is most naturally adapted to beginning with a
synchronous gauge. This remarkable feature, at least to our
understanding, does not seem to have any deeper meaning – it simply
seems to arise from the structure of the Einstein equations themselves,
together with our assumption @xmath . In the absence of this latter
condition, one would have to consider the correlation @xmath - and
@xmath -forms mentioned earlier, and the structure of the correlation
terms and their ‘‘conservation’’ equations would be far more
complicated. In the rest of this thesis we will restrict our
calculations to Zalaletdinov’s approach ⁴ ⁴ 4 An entirely different
outlook towards his approach has been emphasized to us by Buchert [ 68 ]
. According to Buchert, the absence of an averaged manifold @xmath is
not to be thought of as a ‘caveat’, but as a feature deliberately
retained ‘on purpose’. The actual inhomogeneous universe is regarded by
Buchert as the only fundamental entity, and the introduction of an
averaged universe is in fact regarded as an unphysical and unnecessary
approximation. As we mentioned earlier, this is probably the most
important difference between MG and Buchert’s approach. In the latter,
contact with observations is to be made by constructing averaged
quantities, such as the scalars defined earlier in this section, and by
introducing the expansion factor @xmath . The assertion here is that the
averaging of geometry , as discussed in MG or in the Renormalization
Group approach of Buchert and Carfora [ 42 ] is not an indispensable
step in comparing the inhomogeneous universe with actual observations.
The need for averaging of geometry is to be physically separated from
simply looking at effective properties (such as the constructed scalars)
which can be defined for any inhomogeneous metric. Averaging of geometry
becomes relevant if (i) an observer insists on interpreting the data in
a FLRW template model, so that (s)he needs a mapping from the actual
inhomogeneous slice and its average properties to the corresponding
properties in this template, or (ii) one desires a mock metric, to sort
of have a thermodynamic effective metric to approximate the real one. .

Chapter summary and discussion: This chapter dealt with Zalaletdinov’s
fully covariant framework for averaging Einstein’s equations, named
Macroscopic Gravity (MG). Although the details of this approach are
rather involved, its strength lies in the fact that one can speak in
terms of a physically relevant “averaged metric” whose behaviour is
governed by a set of modified Einstein equations. We argued that in the
context of cosmology, the standard assumptions regarding the large scale
homogeneity and isotropy of the universe, translate to the requirement
of taking a spatial averaging limit of the four-dimensional averaging in
MG. The resulting modified cosmological equations were then compared
with the effective equations derived by Buchert, which we discussed in
the previous chapter.

We wish to emphasize an issue which is of importance in understanding
the approach we will take in subsequent chapters, which will deal with
Zalaletdinov’s averaging. There is a significant difference between the
original philosophy of the averaging formalism, common to both the
Buchert and Zalaletdinov schemes, and the manner in which we employ
Zalaletdinov’s averaging. The original idea as developed by these
authors was to construct a framework which would independently describe
a suitably defined averaged dynamics, with no reference to the
inhomogeneous spacetime whose average leads to this dynamics.
Zalaletdinov’s MG is therefore a new theory of gravity describing the
dynamics of an averaged manifold, with no recourse to the underlying
manifold which is described by the usual Einstein equations. The
backreaction @xmath in this approach is actually a new field in the
problem which satisfies its own equations and whose dynamics must be
solved for simultaneously with that of other fields such as the averaged
metric and the averaged energy-momentum tensor for matter.

Our approach to the backreaction issue is different : We consider it
central to be able to self-consistently describe both the inhomogeneous
geometry as well as its averaged counterpart. We find this necessary
since modern cosmology crucially relies on observations of
inhomogeneities around us, and ignoring the evolution of inhomogeneities
when solving for the averaged dynamics does not appear to be
satisfactory. Put another way, when faced with a solution of the
averaged dynamics, we find it essential to answer the question “which
(if any) inhomogeneous solution could lead to this averaged homogeneous
solution?” All our subsequent calculations will therefore focus on
solving for the averaged dynamics of specific inhomogeneities, which we
attempt to keep as realistic as possible. We will start with an
application of the spatial averaging limit of MG, to linear perturbation
theory in cosmology, in the next chapter. The reader is referred to
papers by Zalaletdinov and co-workers in Ref. [ 53 ] , for applications
of MG as a stand-alone theory for an averaged manifold.

## Chapter 4 Backreaction in linear perturbation theory

In this chapter we will adapt the MG formalism and its spatial averaging
limit to the specific case of linear cosmological perturbation theory
(PT). The motivation behind this excercise is to verify the
self-consistency of cosmological PT in the presence of a backreaction
due to averaging. In other words, we wish to ask whether cosmological PT
is stable against the inclusion of dynamical backreaction terms, or
whether a runaway process can render the PT invalid.

This chapter is organised as follows : In Sec. 4.1 we collect some
useful results from linear cosmological perturbation theory. Sec. 4.2
presents details of the MG averaging procedure adapted to cosmological
PT, including general expressions for the leading order backreaction
terms, with a discussion of gauge related issues and the definition of
the averaging operator. The main results are in Sec. 4.3 , where we
derive final expressions for the backreaction, both in real space and
Fourier space, which can be directly utilised in model calculations.
These expressions use a few simplifying restrictions which can be lifted
if necessary in a completely straightforward manner. Sec. 4.4 contains
example calculations in first order PT, which show that the magnitude of
the backreaction is, as expected, negligible compared to the homogeneous
energy density of matter in the radiation dominated era and for a
significant part of the matter dominated era. Throughout the chapter, a
prime refers to a derivative with respect to conformal time unless
stated otherwise, and we will assume that the metric of the universe is
a perturbation around the FLRW metric given by

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

Here @xmath is the scale factor and @xmath is the conformal time
coordinate related to cosmic time @xmath by the differential relation

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

In Eqn. ( 4.1 ) we have allowed the spatial metric to have the general
form @xmath where @xmath is the metric of a @xmath -space of constant
curvature. For the calculations in this chapter we will assume a flat
FLRW background in coordinates such that @xmath ; however for future
reference we shall present certain expressions in terms of the more
general spatial metric. Defining

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

and setting @xmath in Eqns. ( 3.115 ), the correction terms in the
modified Friedmann and Raychaudhuri equations ( 3.114 ) now read

  -- -------- -------- -- --------
                          
     @xmath   @xmath      (4.4a)
                          
     @xmath   @xmath      (4.4b)
                          
     @xmath   @xmath      (4.4c)
                          
     @xmath   @xmath      (4.4d)
  -- -------- -------- -- --------

where we have dropped the tildes for convenience. The averaging in Eqns.
( 4.4 ) is assumed to be a spatial averaging in an unspecified spatial
slicing in the inhomogeneous manifold @xmath ; in Sec. 4.2 we will
specify the averaging procedure more exactly. In addition, the
“cross-correlation” constraints ( 3.116 ) with @xmath , @xmath and
@xmath must also be satisfied by the inhomogeneities. Note that we are
not imposing the conservation condition ( 3.64 ).

Before we move on to deriving formulae for the correlation terms ( 4.4 )
in terms of perturbation functions in the metric, there is one issue
which merits discussion. The cosmological perturbation setting, together
with the paradigm of averaging, presents us with a rather peculiar
situation. On the one hand, the time evolution of the scale factor is
needed in order to solve the equations satisfied by the perturbations.
Indeed, the standard practice is to fix the time evolution of the
background once and for all, and to use this in solving for the
evolution of the perturbations. On the other hand, the evolution of the
perturbations (i.e. – the inhomogeneities) is needed to compute the
correlation terms appearing in Eqns. ( 3.114 ). Until these terms are
known, the behaviour with time of the scale factor cannot be determined;
and until we know the scale factor as a function of time, we cannot
solve for the perturbations. Note that this is a generic feature
independent of all details of the averaging procedure.

It would appear therefore, that we have reached an impasse. To clear
this hurdle, one can try the following iterative approach : Symbolically
denote the background as @xmath , the inhomogeneities as @xmath , and
the correlation objects as @xmath . Note that @xmath , @xmath and @xmath
all refer to functions of time. We start with a chosen background, say a
standard flat FLRW background with radiation, baryons and cold dark
matter (CDM), and solve for the perturbations in the usual way, without
accounting for the correlation terms @xmath . In other words, for this
“zeroth iteration”, we artificially set @xmath to zero and obtain @xmath
and @xmath using the standard approach (see e.g. Ref. [ 12 ] ). Clearly,
since the “true” background (say @xmath ) satisfies Eqns. ( 3.114 ) with
a nonzero @xmath , we have in general @xmath . Now, using the solution
@xmath , we can calculate the zeroth iteration correlation objects
@xmath by applying the prescription to be developed later in this
chapter. As a first correction to the solution @xmath , we now solve for
a new background @xmath , with the known functions @xmath acting as
sources in Eqns. ( 3.114 ). This first iteration will then yield a
solution @xmath for the inhomogeneities, and hence a new set of
correlation terms @xmath , and this procedure can be repeatedly applied.
Pictorially,

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

As for convergence, if perturbation theory is in fact a good
approximation to the real universe, then one can expect that the
correlation terms will tend to be small compared to other background
objects, and will therefore not affect the background significantly at
each iteration, leading to rapid convergence. On the other hand, if the
correlation terms are large, this procedure may not converge and one
might expect a breakdown of the perturbative picture itself. We will see
that in the linear regime of cosmological perturbation theory, the
correlation terms do in fact remain negligibly small.

### 4.1 Metric perturbations in cosmology

For ready reference, in this subsection we present expressions for the
metric, its inverse, and the Christoffel connection in first order
cosmological PT, in an arbitrary, unfixed gauge. The notation we use is
similar to that used in Ref. [ 63 ] . We will also give expressions for
the first order gauge transformations of the perturbation functions (see
e.g. Ref. [ 64 ] ). The first order perturbed FLRW metric in an
arbitrary gauge and in terms of conformal time @xmath , can be written
as

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

The functions @xmath and @xmath are scalars under spatial coordinate
transformations. The functions @xmath and @xmath can be decomposed as
follows

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

where the parentheses indicate symmetrization; @xmath is the tracefree
second derivative defined by

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

with @xmath the covariant spatial derivative compatible with @xmath ;
and @xmath , @xmath and @xmath satisfy

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

where spatial indices are raised and lowered using @xmath and its
inverse @xmath . From their definitions it is clear that @xmath , @xmath
, @xmath and @xmath each correspond to one scalar degree of freedom, the
transverse @xmath -vectors @xmath and @xmath each correspond to two
functional degrees of freedom, and the transverse tracefree @xmath
-tensor @xmath corresponds also to two functional degrees of freedom.
This totals to @xmath degrees of freedom, of which @xmath are coordinate
degrees of freedom which can be arbitrarily fixed, which is what one
means by a gauge choice. For example, the conformal Newtonian or
longitudinal or Poisson gauge [ 13 , 64 ] is defined by the conditions

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

For the metric ( 4.6 ) we have at first order,

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

The inverse of metric ( 4.6 ), correct to first order, has the
components

  -- -------- -- --------
     @xmath      
                 (4.12)
  -- -------- -- --------

With @xmath , the first order accurate Christoffel symbols are

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (4.13)
  -- -------- -- --------

where @xmath denotes the Christoffel connection associated with the
homogeneous @xmath -metric @xmath .

#### 4.1.1 Gauge transformations

While the concept of gauge transformations can be described in a rather
sophisticated language using pullback operators between manifolds [ 64 ]
, for our purposes it suffices to implement a gauge transformation using
the simpler notion of an infinitesimal coordinate transformation (also
known as the “passive” point of view). Hence, denoting the coordinates
and perturbation functions in the new gauge with a tilde (i.e. @xmath ,
@xmath , @xmath , and so on), we have

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

where the infinitesimal @xmath -vector @xmath can be decomposed as

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

where @xmath and @xmath are scalars and @xmath is a transverse @xmath
-vector satisfying @xmath .

It is then easy to show that if this transformation is assumed to change
the metric ( 4.6 ) by changing only the perturbation functions but
leaving the background intact (a so-called “steady” coordinate
transformation), then the old perturbations and the new are related by [
64 ]

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (4.16)
  -- -------- -- --------

The last equality shows that the transverse tracefree tensor
perturbations are gauge invariant. They correspond to gravitational
waves.

### 4.2 The Averaging Operation and Gauge Related Issues

In this section, we will describe the details of the MG (spatial)
averaging procedure adapted to the setting of cosmological PT.

#### 4.2.1 Volume Preserving (VP) Gauges and the Correlation Scalars

It will greatly simplify the discussion if we start with symbolic
calculations which allow us to see the broad structure of the objects we
are after. Since the correlation objects in Eqns. ( 3.114 ) depend only
on derivatives of the metric, we will primarily deal with metric
fluctuations; matter perturbations will only come into play when solving
for the actual dynamics of the system. Before dealing with the issue of
which gauge to choose in order to set the condition ( 3.36 ) with the
average connection taken to be the FLRW one, we will show that
irrespective of this choice, the leading order contribution to the
correlations requires knowledge of only first order perturbation
functions.

We will use the following symbolic notation :

-   Inhomogeneous connection: @xmath

-   FLRW connection: @xmath

-   Perturbation in the connection : @xmath

-   Coordination bivector : @xmath

-   Bilocal extension of the connection : @xmath

-   Inhomogeneous part of the bilocal extension of the connection :
    @xmath

-   Correlation object : @xmath

The integer superscripts denote the order of perturbation. The form of
the coordination bivector arises from the fact that in perturbation
theory, in the spatial averaging limit , a transformation from an
arbitrary gauge to a VP one can be achieved by an infinitesimal
coordinate transformation. By a VP gauge we mean a gauge in which the
metric determinant is independent of the spatial coordinates to the
relevant order in PT, but may be a function of time. It can be shown
that such a function of time (which will typically be some power of the
scale factor), is completely consistent with all definitions and
requirements of MG in the spatial averaging limit. An easy way of seeing
this is to note that in any averaged quantity, the metric determinant
appears in two integrals, one in the numerator and the other in the
denominator (which gives the normalising volume). In the “thin time
slicing” approximation we are using to define the averaging, any overall
time dependent factor in the metric determinant therefore cancels out.
Also, a fully volume preserving coordinate system can clearly be
obtained from any VP gauge as defined above, by a suitable rescaling of
the time coordinate. It is not hard to show that in the thin time
slicing approximation, this gives the same coordination bivector @xmath
as the VP gauge definition above.

To see that first order perturbations are sufficient to calculate @xmath
to leading order, we only have to note that the background connection
@xmath satisfies

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

and that the structure of the correlation is @xmath , which then leads
to

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

which is exact. Clearly, the correlation is quadratic in the
perturbation as expected, and hence to leading order, @xmath above can
be replaced by @xmath .

Eqns. ( 4.17 ) and ( 4.18 ) treat the averaging operation at a
conceptual level only. To make progress however, we also need to
prescribe how to practically impose the averaging assumption

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

in any given perturbative context. This requires some discussion since,
for example, the bilocal extension of the connection @xmath has the
structure

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

where @xmath is a derivative at @xmath and @xmath a derivative at @xmath
(see Eqn. ( 3.35 )). The actual MG averaging operation in general is
therefore a rather involved procedure. Additionally, it is also
necessary to address certain gauge related issues.

To clarify the situation, let us start with a fictitious setting in
which the geometry has exactly the flat FLRW form, with no physical
perturbations. Clearly, if we work in the standard comoving coordinates
in which the metric @xmath of Eqn. ( 4.1 ) is simply @xmath , then since
these coordinates are volume preserving in the sense described above,
the coordination bivector becomes trivial. The averaging involves a
simple integration over @xmath -space, and we can easily see that Eqn. (
4.17 ) is explicitly recovered.

Now suppose that we perform an infinitesimal coordinate transformation,
after imposing Eqn. ( 4.17 ). Since the averaging operation is
covariant, then from the point of view of a general coordinate
transformation, both sides of Eqn. ( 4.17 ) will be affected in the same
way. However, suppose that we had performed the transformation before
imposing Eqn. ( 4.17 ). In the language of cosmological PT, we would
then be dealing with some “pure gauge” perturbations around the fixed,
spatially homogeneous background. If we did not know that these
perturbations were pure gauge, we might naively construct the nontrivial
coordination bivector for this metric, compute the bilocal extension of
the connection according to Eqn. ( 4.20 ) and try to impose Eqn. ( 4.19
). This would be incorrect since these perturbations were arbitrarily
generated and need not average to zero (for example they could be
positive definite functions). In order to maintain consistency, it is
then necessary to ensure in practice that the averaging condition ( 4.19
) is applied only to gauge invariant fluctuations (which is rather
obvious in hindsight).

There is another problem associated with the structure of the
coordination bivector, even when there are real, gauge invariant
inhomogeneities present. Note from Eqns. ( 3.24 ) and ( 3.26 ) that the
coordination bivector has the structure

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

where @xmath denotes the coordinates we are working in and @xmath a set
of VPCs. In perturbation theory (in the spatial averaging limit) we will
have, at leading order,

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

where @xmath symbolically denotes an infinitesimal @xmath -vector
defining the transformation, and hence

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

and so on, which gives us

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Now when we compute a quantity such as @xmath which appears in the
expression ( 4.20 ) for @xmath , we will be left with a fluctuating (
@xmath -dependent) term of the form @xmath , where @xmath denotes the
@xmath spatial coordinates. Hence if we try to impose Eqn. ( 4.19 ) we
will ultimately be left with equations of the type

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

for some functions derived from the inhomogeneities which we have
collectively denoted @xmath . In other words, consistency would seem to
demand that the inhomogeneities vanish in this coordinate system, which
is of course not desirable.

It therefore appears that we are forced to impose Eqn. ( 4.19 ) in a
volume preserving gauge , since by definition, only in such a gauge will
we have @xmath exactly. We emphasize that this is a purely practical
aspect related to defining the averaging operation, and is completely
decoupled from, e.g. the choice of gauge made when studying the time
evolution of perturbations. We are in no way breaking the usual notion
of gauge invariance by choosing an averaging operator. The conditions
Eqn. ( 4.25 ) now reduce to the form

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

which are far more natural than Eqn. ( 4.25 ). The averaging condition
is now unambiguous, but depends on a choice of the VP gauge which
defines the averaging operation , an issue we shall discuss in the next
subsection. For now, all we can assert is that this VP gauge must be
such that in the absence of gauge invariant fluctuations, it must reduce
to the standard comoving (volume preserving) coordinates of the
background geometry as in Eqn. ( 4.1 ). This of course is simply the
statement that the VP gauge must be well defined and must not contain
any residual degrees of freedom.

The averaging operation now takes on an almost trivial form as we have
seen in chapter 3 – to leading order, for any quantity @xmath (with or
without indices), the spatial average of @xmath in a VP gauge is given
by

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

where the integral is over a spatial domain @xmath with a constant
volume @xmath . The spatial coordinates are the comoving coordinates of
the background metric, and at leading order the boundaries of @xmath can
be specified in a straightforward manner as, e.g.,

  -- -------- -- --------
     @xmath      (4.28)
  -- -------- -- --------

where @xmath is a comoving scale over which the averaging is performed
(in which case @xmath ). The averaging definition can be written more
compactly in terms of a window function @xmath as

  -- -------- -- --------
     @xmath      (4.29)
  -- -------- -- --------

where @xmath vanishes everywhere except in the region @xmath , with the
integrals now being over all space. This expression will come in handy
when working in Fourier space, as we shall do in later sections.

A couple of comments are in order at this stage. Firstly, we have not
specified the magnitude of the averaging scale @xmath . The general
philosophy is that this scale must be large enough that a single
averaging domain encompasses several realisations of the random
inhomogeneous fluctuations, and small enough that the observable
universe contains a large number of averaging domains. However, as we
will show later in Sec. 4.3 , if one is ultimately interested in
quantities which are formally averaged over an ensemble of realisations
of the universe (as is usually done in interpreting observations), then
the actual value of the averaging scale becomes irrelevant.

This brings us to the second issue. The above discussion is valid only
in the situation where there are no fluctuations at arbitrarily large
length scales, since in the presence of such fluctuations the averaging
condition ( 4.19 ) loses meaning (in such a situation it would be
impossible to isolate the background from the perturbation by an
averaging operation on any finite length scale). Indeed, we shall see a
manifestation of this restriction in Sec. 4.3 , where the correlation
scalars will be seen to diverge in the presence of a nonzero amplitude
at arbitrarily large scales, of the power spectrum of metric
fluctuations.

We will end this subsection by explicitly writing out the averaging
condition in an “unfixed VP” gauge, to be defined below, and also
writing the correlation terms appearing in Eqn. ( 3.114 ), in this
gauge. As we can see from Eqn. ( 4.11 ), the basic condition to be
satisfied by a VP gauge is

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

Hereafter, all VP gauge quantities will be denoted using a tilde. This
should not be confused with the similar notation that was used so far
for the bilocal extension, which will not be needed in the rest of the
chapter. @xmath and @xmath are the scalar potentials appearing in the
perturbed FLRW metric ( 4.6 ). The single condition ( 4.30 ) leaves
@xmath degrees of freedom to be fixed, in order to completely specify
the VP gauge one is working with. The MG formalism by itself does not
prescribe a method to choose a particular VPC system; in fact this
freedom of choice of VPCs is an inherent part of the formalism. We shall
return to this issue in the next subsection. For now we define the
“unfixed VP (uVP) gauge” by the single requirement ( 4.30 ), with @xmath
unfixed degrees of freedom, and present the expressions for the
averaging condition and the correlation scalars, with this choice.

It is straightforward to determine the consequences of requiring Eqn. (
3.36 ) to hold, with the right hand side corresponding to the FLRW
connection in conformal coordinates, and remembering that the
coordination bivector (in the spatial averaging limit) is now simply a
Kronecker delta. Together with some additional reasonable requirements,
namely

  -- -------- -- --------
     @xmath      (4.31)
  -- -------- -- --------

for any scalar @xmath , the averaging condition in the uVP gauge reduces
to

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (4.32)
  -- -------- -- --------

where we have used the expressions in Eqn. ( 4.13 ) with the uVP
condition ( 4.30 ). We will also make the additional reasonable
requirement that

  -- -------- -- --------
     @xmath      (4.33)
  -- -------- -- --------

using which it is easy to see that the perturbed FLRW metric ( 4.6 ) and
its inverse ( 4.12 ), in the uVP gauge, both on averaging reduce to
their respective homogeneous counterparts, namely

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

Using these results, the expressions ( 4.4 ) simplify to give, in the
uVP gauge,

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (4.35a)
                          
     @xmath   @xmath      (4.35b)
                          
     @xmath   @xmath      (4.35c)
     @xmath   @xmath      (4.35d)
  -- -------- -------- -- ---------

where square brackets denote antisymmetrization.

#### 4.2.2 Choice of VP Gauge

In this subsection we will prescribe a choice for the VP gauge which
defines the averaging operation. In general, the class of volume
preserving coordinate systems for any spacetime, is very large (see Ref.
[ 44 ] for a detailed characterisation). We have so far managed to pare
it down by requiring that the VP gauge we choose should reduce to the
standard FLRW coordinates in the absence of fluctuations. It turns out
to be somewhat difficult to go beyond this step, since there does not
appear to be any unambiguously clear guiding principle governing this
choice. We will therefore motivate a choice for the VP gauge based on
certain details of cosmological PT which one knows from the standard
treatments of the subject.

In particular, we shall make use of certain nice properties of the
conformal Newtonian or longitudinal or Poisson gauge, which is defined
by the conditions ( 4.10 ) [ 64 ] (henceforth we shall refer to this
gauge as the cN gauge for short). Since this gauge is well defined and
has no residual degrees of freedom, all the nonzero perturbation
functions in the cN gauge, namely @xmath , @xmath , @xmath and @xmath in
the notation of Appendix C, are equal to gauge invariant objects. This
is trivially true for @xmath , as seen in the last equation in ( 4.16 ).
For the rest, note that in any arbitrary unfixed gauge, the following
combinations are gauge invariant at first order

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      (4.36)
  -- -------- -- --------

which can be easily checked using Eqns. ( 4.16 ), and in the cN gauge,
@xmath , @xmath and @xmath all vanish. Here @xmath and @xmath are the
Bardeen potentials [ 69 ] (upto a sign), and @xmath in particular has
the physical interpretation of giving the gauge invariant curvature
perturbation , which is the quantity on which initial conditions are
imposed post inflation [ 70 ] .

Additionally, it is also known that the cN gauge for the metric remains
stable even during structure formation, when matter inhomogeneities have
become completely nonlinear ¹ ¹ 1 See Ref. [ 27 ] for an intuitive
description of why this is so. We will also see an explicit
demonstration in a toy model of structure formation in chapter 5. . We
believe that this is a strong argument in favour of using the cN gauge
to define a VP gauge which will then define the averaging operation in
the perturbative context. This will ensure that this “truncated”
averaging operation, defined for first order PT, will remain valid at
leading order even during the nonlinear epochs of structure formation.

To implement this in practice, consider a transformation from the cN
gauge to the uVP gauge defined by Eqn. ( 4.30 ). The transformation
equations ( 4.16 ) reduce to

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (4.37)
  -- -------- -- --------

Recall that to completely specify a VP gauge, we need to fix @xmath
degrees of freedom in the uVP gauge. Our requirement regarding the “well
defined”-ness of the VP gauge, forces us to set @xmath , and to choose
@xmath and @xmath such that they vanish in the case where @xmath .

This has fixed @xmath degrees of freedom, in addition to the condition (
4.30 ) which is just the definition of the uVP gauge, and has hence not
yielded a uniquely specified VP gauge. To do this, we shall make the
following additional requirement. Since we are dealing with a spatial
averaging, it seems reasonable to require that the VP gauge being used
to define the averaging, should be “as close as possible” to the cN
gauge in terms of time slicing , and for this reason we shall set the
function @xmath to zero. To summarize, the VP gauge chosen is defined in
terms of the gauge transformation functions @xmath between the cN gauge
and the VP gauge, by the following relations

  -- -------- -- --------
     @xmath      (4.38)
  -- -------- -- --------

and

  -- -------- -- ---------
                 
     @xmath      (4.39a)
     @xmath      (4.39b)
     @xmath      (4.39c)
     @xmath      (4.39d)
     @xmath      (4.39e)
  -- -------- -- ---------

where the function @xmath is restricted not to contain any nontrivial
solution of the homogeneous (Laplace) equation @xmath .

Having made this choice for the VP gauge, we are now assured that all
averaged quantities which we compute are gauge invariant : our choice
ensures that the averaging procedure does not introduce any pure gauge
modes, and the philosophy of “steady” coordinate transformations ensures
that all background objects are, by assumption, unaffected by gauge
transformations. In particular, the correlation objects in Eqns. ( 4.4 )
are all gauge invariant ² ² 2 Note that all these arguments are valid at
first order in PT, which is sufficient for our present purposes. A
consistent treatment at second order would require more work, although
as long as one is interested only in the leading order effect, these
arguments are expected to go through. . This is different from the gauge
invariance conditions derived in Ref. [ 29 ] , where the background was
also taken to change under gauge transformations at second order in the
perturbations. It is at present not clear how these results are related
to ours.

### 4.3 The Correlation Scalars

With the VP gauge choice defined by Eqns. ( 4.39 ), it is
straightforward to rewrite the correlation objects in Eqns. ( 4.35 )
(which are in the uVP gauge) in terms of the perturbation functions in
the cN gauge. We will restrict the subsequent calculations in this
chapter to the case where there are no transverse vector perturbations,
i.e.,

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

in the cN gauge. This is a reasonable choice since such vector
perturbations, even if they are excited in the initial conditions, decay
rapidly and do not source the other perturbations at first order [ 12 ]
. In addition, for simplicity we will choose to ignore the gauge
invariant tensor perturbations as well,

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

In terms of the scalar perturbations in the cN gauge, for a flat FLRW
background, the correlation objects ( 4.35 ) reduce to

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (4.42a)
                          
     @xmath   @xmath      (4.42b)
                          
     @xmath   @xmath      
              @xmath      (4.42c)
     @xmath   @xmath      (4.42d)
  -- -------- -------- -- ---------

where @xmath is defined in Eqn. ( 4.39b ).

Since we are working with a flat FLRW background, it becomes convenient
to transform our expressions in terms of Fourier space variables. This
will also highlight the problem with large scale fluctuations which was
mentioned in Sec. 4.2 . We will use the following Fourier transform
conventions : For any scalar function @xmath , its Fourier transform
@xmath satisfies

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (4.43)
  -- -------- -------- -- --------

Consider an average of a generic quadratic product of two scalars @xmath
and @xmath where we have suppressed the time dependence since it simply
goes along for a ride. Using the definition ( 4.29 ), and keeping in
mind that the scalars are real, it is easy to show that we have

  -- -------- -- --------
     @xmath      (4.44)
  -- -------- -- --------

where @xmath is the Fourier transform of the window function @xmath on
the variable @xmath , and the asterisk denotes a complex conjugate.

In the present context, the functions @xmath and @xmath will typically
be derived in terms of the initial random fluctuations in the metric
@xmath which are assumed to be drawn from a statistically homogeneous
and isotropic Gaussian distribution with some given power spectrum. In
order to ultimately make contact with observations, it seems necessary
to perform a formal ensemble average over all possible realisations of
this initial distribution of fluctuations. The statistical homogeneity
and isotropy of the initial distribution implies that the functions
@xmath and @xmath will satisfy a relation of the type

  -- -------- -- --------
     @xmath      (4.45)
  -- -------- -- --------

for some function @xmath which is derivable in terms of the initial
power spectrum of metric fluctuations, and where @xmath denotes an
ensemble average and @xmath is the Dirac delta distribution.

Applying an ensemble average to Eqn. ( 4.44 ) introduces a Dirac delta
which forces @xmath . Further, the normalisation condition on the window
function in Eqn. ( 4.29 ) implies that we have

  -- -------- -- --------
     @xmath      (4.46)
  -- -------- -- --------

which means that all dependence on the averaging scale and domain drops
out, and we are left with

  -- -------- -- --------
     @xmath      (4.47)
  -- -------- -- --------

Note however, that the right hand side of Eqn. ( 4.47 ) is precisely
what we would have obtained, had we treated the spatial average @xmath
to be the ensemble average @xmath to begin with. Therefore for all
practical purposes, we are justified in replacing all the spatial
averages in the expressions for the correlation scalars ( 4.42 ), by
ensemble averages.

It is convenient to define the transfer function @xmath via the relation

  -- -------- -- --------
     @xmath      (4.48)
  -- -------- -- --------

For the calculations in this chapter, we shall assume that the cN gauge
scalars @xmath and @xmath are equal

  -- -------- -- --------
     @xmath      (4.49)
  -- -------- -- --------

a choice which is valid in first order PT when anisotropic stresses are
negligible (see Ref. [ 12 ] ). This simplifies many of the expressions
we are dealing with. The Fourier transform of @xmath can be written,
using Eqns. ( 4.39b ) and ( 4.49 ), as

  -- -------- -- --------
     @xmath      (4.50)
  -- -------- -- --------

Finally, in terms of the transfer function @xmath and the initial power
spectrum of metric fluctuations defined by

  -- -------- -- --------
     @xmath      (4.51)
  -- -------- -- --------

the correlation scalars ( 4.42 ) can be written as

  -- -------- -------- -- ---------
                          
                          
     @xmath   @xmath      (4.52a)
                          
     @xmath   @xmath      (4.52b)
                          
     @xmath   @xmath      (4.52c)
                          
     @xmath   @xmath      (4.52d)
  -- -------- -------- -- ---------

These expressions highlight the problem of having a finite amplitude for
fluctuations at arbitrarily large length scales ( @xmath ), which was
mentioned in Sec. 4.2 . As a concrete example, consider the frequently
discussed Harrison-Zel’dovich scale invariant spectrum [ 71 ] which
satisfies the condition

  -- -------- -- --------
     @xmath      (4.53)
  -- -------- -- --------

Eqns. ( 4.52 ) now show that if the transfer function @xmath has a
finite time derivative at large scales (as it does in the standard
scenarios – see the next section), then the correlation objects @xmath ,
@xmath and @xmath all diverge due to contributions from the @xmath
regime. This demonstrates the importance of having an initial power
spectrum in which the amplitude dies down sufficiently rapidly on large
length scales (which is a known issue, see Ref. [ 70 ] ). Keeping this
in mind, we shall concentrate on initial power spectra which display a
long wavelength cutoff. Models of inflation leading to such power
spectra have been discussed in the literature [ 72 ] , and more
encouragingly, analyses of WMAP data seem to indicate that such a cutoff
in the initial power spectrum is in fact realised in the universe [ 73 ]
.

A final comment before proceeding to explicit calculations : In addition
to picking up nontrivial correlation corrections in the cosmological
equations, the averaging formalism also requires that the
“cross-correlation” constraints in Eqns. ( 3.116 ) be satisfied. It is
straightforward to show that the statistical homogeneity and isotropy of
the metric fluctuations implies that these constraints are identically
satisfied, for all types of perturbations (scalar, vector and tensor).
At the lowest order therefore, these constraints do not impose any
additional conditions on the perturbation theory, which is reassuring.

### 4.4 Worked out examples

We will now turn to some explicit calculations of the backreaction,
which will show that the magnitude of the effect remains negligibly
small for most of the evolution duration in which linear PT is valid. At
early times, linear PT is valid at practically all scales including the
smallest scales at which we wish to apply general relativity. As matter
fluctuations grow, the small length scales progressively approach
nonlinearity, and linear PT breaks down at these scales. As we will see,
however, by the time a particular length scale becomes nonlinear, its
contribution to the amplitude of the metric fluctuations correspondingly
becomes negligible. In practice therefore, one can extend the linear
calculation well into the matter dominated era, with the expectation
that the order of magnitude of the various integrals will not change
significantly due to nonlinear effects.

The model we will use is the standard Cold Dark Matter (sCDM) model
consisting of radiation and CDM [ 12 ] . We will neglect the
contribution of baryons, and at the end we shall discuss the effects
this may have on the final results. We shall also discuss, without
explicit calculation, the effects which the introduction of a
cosmological constant is likely to have. In the following, @xmath and
@xmath denote the density parameters of radiation and CDM respectively
at the present epoch @xmath , with @xmath denoting cosmic time. @xmath
is assumed to contain contributions from photons and @xmath species of
massless, out-of-equilibrium neutrinos. At the “zeroth iteration” we
have

  -- -------- -- --------
     @xmath      (4.54)
  -- -------- -- --------

where @xmath is the standard Hubble constant, the scale factor is
normalised so that @xmath , and @xmath and @xmath are related by

  -- -------- -- --------
     @xmath      (4.55)
  -- -------- -- --------

The comoving wavenumber corresponding to the scale which enters at the
matter radiation equality epoch, is given by

  -- -------- -- --------
     @xmath      (4.56)
  -- -------- -- --------

where we have set (see Refs. [ 74 , 12 ] for details)

  -- -------- -------- -- --------
     @xmath   @xmath      
                          
              @xmath      (4.57)
  -- -------- -------- -- --------

where @xmath is the dimensionless Hubble parameter defined by @xmath
km/s/Mpc. For all calculations we shall set @xmath [ 75 ] .

#### 4.4.1 EdS background and non-evolving potentials

Before dealing with the full model (which requires a numerical
evolution) let us consider the simpler situation, described by an
Einstein-deSitter (EdS) background, with negligible radiation and a
nonevolving potential @xmath (which is a consistent solution of the
Einstein equations in the sCDM model at least at subhorizon scales at
late times [ 12 ] ). Although not fully accurate, this example requires
some very simple integrals and will help to give us a feel for the
structure and magnitude of the backreaction.

With a constant potential, the only correlation object which survives is
@xmath , which evolves like @xmath , where the scale factor refers to
the “zeroth iteration”. The constant of proportionality can be written
in terms of the BBKS transfer function @xmath [ 76 , 12 ] , to give

  -- -------- -- --------
     @xmath      (4.58)
  -- -------- -- --------

where we have [ 76 ]

  -- -------- -------- -- --------
     @xmath   @xmath      (4.59)
  -- -------- -------- -- --------

where @xmath .

The integral in Eqn. ( 4.58 ) is well-behaved even in the presence of
power at arbitrarily large scales, for a (nearly) scale invariant
spectrum. Since we are only looking for an estimate, we shall evaluate
the integral in the absence of a large scale cutoff, and leave a more
accurate calculation for the next subsection. For the initial spectrum
given by

  -- -------- -- --------
     @xmath      (4.60)
  -- -------- -- --------

where the scalar spectral index @xmath is close to unity, the integral
in Eqn. ( 4.58 ) can be easily performed numerically and has the order
of magnitude

  -- -------- -- --------
     @xmath      (4.61)
  -- -------- -- --------

upto a numerical prefactor of order @xmath . Since the amplitude of the
power spectrum is @xmath [ 77 ] , the overall contribution of the
backreaction is

  -- -------- -- --------
     @xmath      (4.62)
  -- -------- -- --------

Now, as long as the correlation objects give a negligible backreaction
to the usual background quantities, when we proceed with the next
iteration, the effect of the backreaction on the evolution of the
perturbations will also remain negligible (at least at the leading
order). Hence in practice there will be essentially no difference
between the zeroth iteration and first iteration perturbation functions.
This amounts to saying that when the backreaction is negligible,
convergence to the “true” solution for the scale factor at the leading
order , is essentially achieved in a single calculation. We will discuss
the issue of convergence in somewhat more detail at the end of the
chapter.

#### 4.4.2 Radiation and CDM without baryons

Let us now turn to the full sCDM model (without baryons). An analytical
discussion of this model in various regions of @xmath -space, can be
found e.g. in Ref. [ 12 ] . Since we are interested in integrals over
@xmath across a range of epochs @xmath , it is most convenient to solve
this model numerically. It is further convenient to use @xmath in place
of @xmath , as the variable with which to advance the solution. Also, it
is useful to introduce transfer functions like @xmath for all the
relevant perturbation functions in exactly the same manner (see Eqn. (
4.48 )), namely by pulling out a factor of @xmath , since the initial
conditions are completely specified by the initial metric perturbation.
For a generic perturbation function @xmath (other than the metric
fluctuation @xmath ) the transfer function corresponding to @xmath will
be denoted by a caret, so that

  -- -------- -- --------
     @xmath      (4.63)
  -- -------- -- --------

The relevant Einstein equations can be brought to the following closed
set of first order ordinary differential equations (adapted from Eqns.
(7.11)-(7.15) of Ref. [ 12 ] ),

  -- -------- -- ---------
                 
     @xmath      (4.64a)
     @xmath      (4.64b)
     @xmath      (4.64c)
     @xmath      (4.64d)
     @xmath      (4.64e)
  -- -------- -- ---------

Here we have introduced the dimensionless variables

  -- -------- -- --------
     @xmath      (4.65)
  -- -------- -- --------

and the various perturbation functions are defined as follows : @xmath
is the @xmath -space density contrast of CDM, @xmath and @xmath are the
monopole and dipole moments respectively of the @xmath -space
temperature fluctuation of radiation, and @xmath is the @xmath -space
peculiar velocity scalar potential of CDM (i.e., the real space peculiar
velocity is @xmath where @xmath is the Fourier transform of @xmath ).

Assuming adiabatic perturbations, the initial conditions satisfied by
the transfer functions at @xmath are (adapted from Ch. 6 of Ref. [ 12 ]
)

  -- -------- -- --------
     @xmath      (4.66)
  -- -------- -- --------

We choose @xmath , which corresponds to an initial background radiation
temperature of @xmath GeV. While this is not as far back in the past as
the energy scale of inflation (which is closer to @xmath Gev), it is on
the edge of the energy scale where known physics begins [ 70 ] . This
makes Eqn. ( 4.57 ) unrealistic since we have ignored all of Big Bang
nucleosynthesis and also the fact that neutrinos were in equilibrium
with other species at temperatures higher than about @xmath Mev. However
the modifications due to these additional details are not expected to
drastically change the final results, and these assumptions lead to some
simplifications in the code used. The goal here is only to demonstrate
an application of the formalism; more realistic calculations accounting
for the effects of baryons can also be performed (see, e.g. Behrend et
al. [ 49 ] who incorporate these effects for the post-recombination era,
albeit in the Buchert formalism).

In order to partially account for the fact that inflationary initial
conditions are actually set much earlier than @xmath , we impose an
absolute small wavelength cutoff at the scale which enters the horizon
at the initial epoch which we have chosen. In the above notation this
corresponds to setting @xmath . This makes sense since scales satisfying
@xmath have already entered the horizon and decayed considerably by the
epoch @xmath . There is a source of error due to ignoring scales @xmath
which have not yet decayed significantly, but this error rapidly
decreases with time as progressively larger length scales enter the
horizon and decay. [In fact, in practice to compute the integrals at any
given epoch @xmath , one only needs to have followed the evolution of
modes with @xmath : more on this in the next subsection.] More important
is the cutoff at long wavelengths, which we set at @xmath (corresponding
to @xmath ), which is firstly a natural choice given that @xmath is the
only large scale in the system, and is secondly also guided by analyses
of CMB data which have detected such a cutoff [ 73 ] . We will see that
reducing @xmath even by a few orders of magnitude, does not affect the
final qualitative results significantly.

##### Numerical Results

Equations ( 4.64 ) with initial conditions ( 4.66 ) were solved with a
standard @xmath th order Runge-Kutta integrator with adaptive stepsize
control (based on the algorithm given in Ref. [ 78 ] ). For the
integrals in Eqns. ( 4.52 ), only the function @xmath needs to be
tracked accurately. Hence, although @xmath and @xmath are difficult to
follow accurately beyond the matter radiation equality @xmath due to
rapid oscillations, the integrals can still be reliably computed since
@xmath and @xmath do not significantly affect the evolution of @xmath in
the matter dominated era (as seen in Eqn. ( 4.64a )).

To see that known results are being reproduced by the code, consider
Figs. 4.1(a) and 4.1(b) as examples. Fig. 4.1(a) shows the evolution of
two scales corresponding to @xmath ( @xmath ) and @xmath . The first
enters the horizon at the present epoch, while the second remains
superhorizon for the entire evolution, satisfying @xmath . In this limit
an analytical solution exists in the sCDM model, due to Kodama and
Sasaki [ 79 , 12 ] , given by

  -- -------- -- --------
     @xmath      (4.67)
  -- -------- -- --------

where @xmath , and this function is also shown. Clearly all the curves
in Fig. 4.1(a) are practically identical. Fig. 4.1(b) shows the function
@xmath normalised by its (constant) value at large scales, at the epoch
@xmath , (which is well into the matter dominated era). The dotted line
is the BBKS fitting form given in Eqn. ( 4.59 ) with @xmath given by
Eqn. ( 4.56 ).

To numerically estimate the integrals in Eqns. ( 4.52 ), the values of
@xmath and its first and second derivatives with respect to @xmath are
needed across a range of @xmath values. For reference, note that the
following relations hold for a generic function of time @xmath ,

  -- -------- -- --------
     @xmath      (4.68)
  -- -------- -- --------

Based on the earlier discussion, the initial power spectrum @xmath is
taken to satisfy

  -- -------- -- --------
     @xmath      (4.69)
  -- -------- -- --------

and zero otherwise, and we set

  -- -------- -- --------
     @xmath      (4.70)
  -- -------- -- --------

which, for the sCDM model follows from the convention (see Eqn.(6.100)
of Ref. [ 12 ] ) @xmath with @xmath (see, e.g. Ref. [ 77 ] ).

Consider Figs. 4.2(a) and 4.2(b) , which highlight two issues discussed
earlier. Fig. 4.2(a) shows the integrand of @xmath at three sample
epochs, and we see that the integrand dies down rapidly at increasingly
smaller @xmath values for progressively later epochs. (The other
integrands, not displayed here, also show this rapid decline for large
@xmath .) [We have not shown the integrand at the later two epochs for
all values of @xmath since this was computationally expensive, but the
declining trend of the curves can be extrapolated to large @xmath ,
which is well understood analytically [ 12 ] .] This justifies the
statement in the beginning of this section, that at any epoch @xmath it
is sufficient to have followed the evolution of scales satisfying @xmath
for computing the integrals. Secondly, Fig. 4.2(b) shows the behaviour
of @xmath at the same three epochs, and comparing with Fig. 4.2(a) we
see that at any epoch, the region of @xmath -space where linear PT has
broken down, does not contribute significantly to the integrals. This is
in line with the conjecture in Ref. [ 80 ] that the effects of the
backreaction should remain small since the mass contained in the
nonlinear scales is subdominant. We will return to this issue in chapter
5.

Due to the structure of the integrals and the chosen initial power
spectrum, it is convenient to compute the integrands in Eqns. ( 4.52 )
equally spaced in @xmath , and then perform the integrals using the
extended Simpson’s rule [ 78 ] . If @xmath points are used to evaluate a
given integral, resulting in a value @xmath say, then the error can be
estimated by computing the integral with @xmath points to get @xmath ,
and estimating the relative error as @xmath . With @xmath , the
estimated errors in all the integrals at all epochs were typically less
than @xmath . A bigger error is incurred in computing the integrand
itself at any given epoch, leading to estimated errors of order @xmath
in @xmath , @xmath and @xmath , with a larger error in @xmath as
explained below.

The second derivative @xmath proves to be difficult to track
numerically. At early times, when most scales are superhorizon, the
Kodama-Sasaki analytical solution ( 4.67 ) is a good approximation for
most values of @xmath . Using this one can see that at early times the
value of the derivative is numerically very small, and is difficult to
reliably estimate due to roundoff errors. For this reason the integral
@xmath could not be accurately estimated at early times. However, the
structure of the integrand of @xmath ( 4.52d ) shows that the largest
contribution comes from large (superhorizon) scales (the small scales
being subdominant due to the presence of @xmath and @xmath ). An
analysis using the Kodama-Sasaki solution then shows in a fairly
straightforward manner that the behaviour of the backreaction term is
@xmath for our choices of parameters, where @xmath . At intermediate
times around @xmath and later, although it becomes computationally
expensive to obtain convergent values for the second derivative at all
relevant scales ³ ³ 3 Convergence was tested by varying a global
parameter which dynamically controls the stepsize during evolution (by
stepsize doubling/halving, see Ref. [ 78 ] ). The integrals other than
@xmath show convergence at @xmath or more significant digits for all
epochs, whereas convergence can be obtained for @xmath only at epochs
sufficiently close to matter radiation equality, and there only for
@xmath - @xmath significant digits, by setting stringent conditions on
stepsize doubling. , moderately good accuracy ( @xmath - @xmath ) can be
achieved.

The results are shown in Fig. 4.3 , in which the magnitudes of the
correlation integrals of Eqn. ( 4.52 ), normalised by the Hubble
parameter squared @xmath are plotted as a function of the scale factor
in a log-log plot. The values for @xmath are shown only for epochs later
than @xmath . We see that at all epochs, the correlation terms remain
negligible compared to the chosen zeroth iteration background. Also, in
the radiation dominated epoch all the correlation scalars (except @xmath
whose evolution couldn’t be accurately obtained) track the @xmath
behaviour of the background radiation density (see also Ref. [ 28 ] ).
The discussion above shows however that the magnitude of @xmath is far
smaller than the other backreaction functions at early times, for a
cutoff at @xmath . On the other hand, in the matter dominated epoch
@xmath dominates the backreaction and settles into a curvature-like
@xmath behaviour (note that in the matter dominated epoch we have @xmath
). As for the signs of the correlations, @xmath , @xmath , and @xmath
are negative throughout the evolution while @xmath is positive
throughout.

Finally, a few comments regarding the effects of ignoring baryons,
nonlinear corrections, etc. Including baryons in the problem (with a
background density parameter of @xmath ) will lead to a significant
suppression of small scale power (by introducing pressure terms which
will tend to wipe out inhomogeneities) and also a small suppression of
large scale power. This effect causes a (downward) change in the late
time transfer function of roughly @xmath - @xmath [ 12 ] , and therefore
cannot increase the contribution of the backreaction. Quasi-linear
corrections can lead to significant changes in the transfer function,
but do not cause shifts by several orders of magnitude (see Ref. [ 81 ]
and references therein). Hence accounting for changes due to
quasi-linear behaviour will also not increase the magnitude of the
backreaction by a large amount. As for effects from fully nonlinear
scales, we have seen that these can be expected to remain small (see
also chapter 5).

Adding a cosmological constant (and retaining a flat background
geometry) will change the qualitative features of the correlation
functions by shifting the scale @xmath (due to a reduced @xmath , which
will also increase the power spectrum amplitude [ 12 ] , but again not
by orders of magnitude). Also, the late time behaviour of the
correlation scalars will be affected since the potential @xmath will
decay at late times instead of remaining constant (see also below).
Regardless, the backreaction is expected to remain small even in this
case (which is also indicated by the calculations of Behrend et al. [ 49
] in the Buchert framework).

Chapter summary and discussion: This chapter showed how the spatial
averaging limit of MG can be adapted to the case of linear perturbation
theory (PT) in cosmology, to calculate the backreaction in gauge
invariant manner. In doing so we also saw the significance of volume
preserving gauges in defining self-consistent averaging operators. The
formalism leaves some freedom in the choice of the averaging operator
(via a choice of a volume preserving gauge), and therefore we cannot
claim that our results are unique down to all numerical factors.
However, since the final explicit form of the late time backreaction in
Fig. 4.3 matches closely with the (essentially order of magnitude)
estimate of Eqn. ( 4.62 ) which is actually independent of any details
of the averaging procedure, we do expect our results to be qualitatively
robust.

Fig. 4.3 also shows that in the absence of a cosmological constant, the
backreaction after a single iteration of the procedure outlined in
section 4.1, tracks the radiation density in the radiation dominated
era, and essentially behaves like a curvature term in the matter
dominated era. Two issues arise from this behaviour. Denote the
corrections to the Friedmann equation ( A.3a ) and the acceleration
equation ( A.3b ) as @xmath and @xmath respectively. Then firstly, we
find that in the radiation dominated era, although both @xmath and
@xmath behave like @xmath , their numerical coefficients do not combine
so as to preserve the conservation criterion ( 3.64 ) separately. Since
the backreaction must now necessarily couple to the background radiation
density, this points to a very tiny gravitationally induced correction
in the equation of state for radiation. This effect can be traced back
essentially to the presence of a small but non-zero correlation 3-form
and 4-form, arising from higher order perturbative effects. In the
matter dominated era, at least in the “zeroth” iteration, this effect
seems to be highly suppressed since we now have @xmath and @xmath ,
which is approximately consistent with ( 3.64 ).

The second issue concerns what happens at higher iterations, and is
important from the point of view of obtaining a convergent answer for
the backreaction. The basic cycle that one needs to keep in mind is that
the backreaction affects @xmath , which affects the equations for the
density and metric perturbations, which in turn define the backreaction.
Consider the situation in the matter dominated era, which is easier to
handle since firstly only one term @xmath contributes to the
backreaction and secondly the linear PT solution has a simple analytic
form. The estimate in Eqn. ( 4.62 ) shows that most of the contribution
comes from (quasi)linear subhorizon scales @xmath for which the Poisson
equation holds, so that if the density contrast behaves like @xmath then
the metric transfer function behaves like @xmath . Standard linear PT [
12 ] tells us that @xmath is the so-called growth function which can be
written as @xmath upto some numerical coefficient, where @xmath . An
analysis similar to the one leading to Eqn. ( 4.62 ) then shows that we
should expect @xmath at late times. For a flat universe without a
cosmological constant, @xmath and we recover the single iteration result
that we have been discussing so far.

The crucial thing to note is that since the backreaction affects only
the background equations and not the perturbation equations, @xmath is
completely determined by the Hubble parameter @xmath , so that at any
iteration @xmath we will have

  -- -------- -- --------
     @xmath      (4.71)
  -- -------- -- --------

where we expect @xmath . This immediately suggests that the limit of
this series is the solution of the integral equation

  -- -------- -- --------
     @xmath      (4.72)
  -- -------- -- --------

This equation can in principle be solved perturbatively by exploiting
the smallness of the parameter @xmath , and we expect the solution to be
close to the “zeroth” iteration answer @xmath . To understand why,
notice that at the zeroth iteration we found @xmath to be negative, so
that the first iteration Hubble parameter @xmath is effectively that of
an open universe with a small negative curvature. Standard analysis
shows that the growth factor in an open universe is suppressed compared
to that in a flat matter dominated one, and hence the Hubble parameter
at the second iteration @xmath will have a slightly smaller contribution
from the backreaction than @xmath . This will correspondingly slightly
enhance the contribution of the backreaction to @xmath over the
contribution to @xmath , and so on until the solution converges.

This convergent solution will, like the radiation dominated case, mildly
violate the conservation criterion Eqn. ( 4.62 ). Further, the analysis
above generalises to the case when the cosmological constant is nonzero.
In this case the late time growth factor is suppressed compared to the
EdS case even at the zeroth iteration [ 12 ] , and the convergent
solution will violate the conservation criterion by an amount comparable
to the backreaction itself. What is important however is that in all
cases, the backreaction as well as the violation of matter conservation
remain negligibly small, approximately at the level of one part in
@xmath . This analysis ignored all contributions from scales which have
become fully nonlinear in the matter density contrast at late times. The
reasoning was that these scales are not expected to contribute
significantly to the backreaction due to a suppression in the transfer
function @xmath . In the next chapter, we will confirm this expectation
in the context of a toy model of nonlinear structure formation.

## Chapter 5 Nonlinear structure formation and backreaction

We have seen so far that applying the averaging framework during epochs
when linear perturbation theory (PT) is expected to be valid, leads to
only negligible modifications in the standard cosmological equations.
This is not unexpected, since the estimate in e.g. Eqn. ( 4.62 ) does
not depend crucially on the details of the averaging procedure, and is
therefore robust. Most of the interest in the backreaction issue
however, has been from the point of view of late time cosmology when
matter fluctuations at least have become nonlinear on small scales. It
has been claimed using some simple models of structure formation [ 37 ]
that using the perturbed FLRW ansatz for the metric is no longer a good
approximation in this regime, and that one should expect backreaction
effects to grow large at these times. We will investigate this issue in
this chapter, in the framework of an exact toy model of structure
formation based on the LTB solutions of general relativity (see Appendix
B).

We have already seen in our linear PT calculation that if the metric at
late times continues to be of the perturbed FLRW form ( 4.6 ), then
backreaction effects of the nonlinear scales are in fact likely to be
small, which follows from studying the structure of the integrands of
the various backreaction functionals (see the discussion of Figs. 4.2(a)
and 4.2(b) ). Order of magnitude arguments such as those in Ref. [ 27 ]
suggest that the perturbed FLRW metric does remain a good approximation
at late times. In this chapter we will see an explicit demonstration
that a fully relativistic, highly nonlinear collapsing system can be
described by a perturbed FLRW metric, provided peculiar velocities of
the matter remain nonrelativistic. Further, in our model (which will
satisfy this condition) we can then use the formalism developed in
chapter 4 to explicitly compute the backreaction. We will see that the
backreaction in this case does remain small.

### 5.1 Spherical Collapse : Setting up the model

Our model is based on the LTB solution described in Appendix B, and is
completely determined once the initial conditions are specified.

#### 5.1.1 Initial conditions

While choosing the initial density, velocity and coordinate scaling
profiles, we make the important assumption that at initial time, a
well-defined global background FLRW solution can be identified, with
scale factor @xmath , Hubble parameter @xmath and density @xmath . This
is reasonable since the CMB data (combined with the Copernican
principle) assure us that inhomogeneities at the last scattering epoch
were at the level of 10 parts per million. This assumption plays a
crucial role in deciding which regions are overdense and will eventually
collapse, and which regions will keep expanding.

-    Initial density profile @xmath :
    The initial density is chosen to be

      -- -------- -- -------
         @xmath      (5.1)
      -- -------- -- -------

    where @xmath . Initially, the region @xmath is assumed to contain a
    tiny overdensity and the region @xmath , an underdensity. In other
    words,

      -- -------- -- -------
         @xmath      (5.2)
      -- -------- -- -------

    The discontinuities in the initial density profile can be smoothed
    out by replacing the step functions appropriately. We will not do
    this here, since the step functions make calculations very simple.
    This is not expected to affect the qualitative features of our final
    results.

-    Initial conditions on scaling and velocities :
    We match the initial velocity and coordinate scaling to the global
    background solution, by requiring

      -- -------- -------- -- -------
         @xmath   @xmath      (5.3)
         @xmath   @xmath      (5.4)
      -- -------- -------- -- -------

    with @xmath and @xmath denoting the initial values of the scale
    factor and Hubble parameter respectively of the global background.
    This amounts to setting the initial velocities to match the Hubble
    flow, ignoring initial peculiar velocities. This is only a
    convenient choice and the introduction of initial peculiar
    velocities is not expected to modify our final results
    qualitatively.

For the FLRW background we consider an Einstein-deSitter (EdS) solution
with scale factor and Hubble parameter given by

  -- -------- -- -------
     @xmath      (5.5)
     @xmath      (5.6)
  -- -------- -- -------

with @xmath denoting the present epoch. @xmath fixes the initial time as

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

We will always use @xmath , so that the initial conditions are being set
around the CMB last scattering epoch; in general @xmath must be treated
as one of the parameters in the problem. The initial EdS background
density is given in terms of @xmath and @xmath as

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

#### 5.1.2 Mass function @xmath and curvature function @xmath

We now have enough information to fix @xmath and @xmath . Using Eqn. (
B.2b ) at initial time together with the scaling in Eqn. ( 5.3 ) gives
us

  -- -- -- -------
           (5.9)
  -- -- -- -------

where we have defined a “critical” radius @xmath by the equation

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

The significance of @xmath will become apparent shortly. Using the
initial conditions Eqns. ( 5.3 ) and ( 5.4 ) in the evolution equation (
B.2a ) at initial time, gives

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

with @xmath , and hence

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

The significance of @xmath is now clarified. Since @xmath , we have
@xmath by definition (Eqn. ( 5.10 )). The following possibilities arise
:

-   If @xmath , then @xmath for all @xmath , and every shell will
    ultimately collapse, including the “void” region @xmath .

-   If @xmath , then @xmath for @xmath and changes sign at @xmath .
    Hence, the region @xmath will collapse even though it is underdense,
    while the region @xmath will expand forever.

-   If @xmath , then the “void” exactly compensates for the overdensity,
    and the universe is exactly EdS for @xmath . [ @xmath and @xmath .]
    Also the “void” will eventually collapse.

Clearly the most interesting case for us is the one with @xmath , and we
will hence make this choice for our model. We realize that the model as
it stands is not a very realistic depiction of the (nearly spherical)
voids we see in our Universe [ 56 ] , since these voids are seen to be
surrounded by “walls” of matter. However, our goal is to describe two
regions, one of which collapses while the other expands ever more
rapidly, and our model is capable of doing so while retaining its fully
relativistic character.

Although we have set up the model for all values of the radial
coordinate @xmath , hereon we will concentrate on the region @xmath .
One reason is that most of the interesting dynamics takes place in this
region. Another is that the region @xmath develops shell-crossing
singularities due to the sharp rise in density across @xmath . A more
realistic model would be able to incorporate the pressures that are
expected to build up when a shell-crossing occurs [ 82 ] , but the LTB
model is limited in this respect due to its pressureless character. We
will therefore ignore the region @xmath .

#### 5.1.3 The solution in the region @xmath

The region of interest can be split into three parts : region 1 @xmath ,
region 2 @xmath and region 3 @xmath . The solution in the three regions
is as follows :

-    region 1 ( @xmath ) :

      -- -------- -- ---------
                     
         @xmath      (5.13a)
         @xmath      (5.13b)
         @xmath      (5.13c)
         @xmath      (5.13d)
      -- -------- -- ---------

For regions @xmath and @xmath , it is convenient to define a function
@xmath as

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

-    region 2 ( @xmath ) :

      -- -------- -- ---------
                     
         @xmath      (5.15a)
         @xmath      (5.15b)
         @xmath      (5.15c)
         @xmath      
         @xmath      (5.15d)
      -- -------- -- ---------

-    region 3 ( @xmath ) :

      -- -------- -- ---------
                     
         @xmath      (5.16a)
         @xmath      (5.16b)
         @xmath      (5.16c)
         @xmath      
         @xmath      (5.16d)
      -- -------- -- ---------

The crossover from region 1 to region 2 is discontinuous in @xmath (but
not in @xmath ) due to our discontinuous choice of initial density.
Smoothing out the density will also smooth out @xmath . The crossover
from region 2 to region 3 can be shown to be smooth, by considering the
limits @xmath and @xmath or equivalently @xmath and @xmath . Note that
the results in Eqns. ( 5.13 ), ( 5.15 ) and ( 5.16 ) are exact, and do
not involve any perturbative expansions in @xmath or @xmath , even
though these parameters are small.

#### 5.1.4 Behaviour of the model

Each shell in the inner, homogeneous and overdense region 1 behaves as a
closed FLRW universe, expanding out to a maximum radius @xmath given by

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

All the inner shells reach their maximum radius and turn around at the
same time @xmath given by

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

where we have used the smallness of @xmath and @xmath to make the last
approximation. By appropriately choosing a value of @xmath , we can
arrange for the turnaround of region 1 to occur either before or after
the present epoch.

In Table 5.1 we have listed the parameter values which we will use
frequently in displaying plots. Along with the parameter set @xmath , we
have also listed the values of the derived quantities @xmath and speed
of light @xmath in units of @xmath . We have also shown the values of
the present day physical area radius @xmath at @xmath and @xmath . The
density contrasts are to be understood to reflect the inhomogeneities in
the dark matter density close to last scattering, and not the
inhomogeneities of the baryons which were much smaller [ 12 ] . In Fig.
5.1 we have shown the evolution of the density contrast @xmath defined
in the usual way by

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

for the parameter choices of Table 5.1 , for which one has @xmath , so
that the collapse is well under way in region 1 at the present epoch.
The two panels show the contrast for two representative values of @xmath
, one in region 1 and the other in region 3.

#### 5.1.5 Aside : Acceleration from initial conditions

It is interesting to note that our model is capable of qualitatively
reproducing results derived by earlier by Räsänen [ 37 ] in the context
of a very simple model of structure formation. Räsänen’s model can be
summarized as follows : one considers two disjoint regions, one
overdense and the other completely empty, each evolving according to the
FLRW evolution equations. (The embedding of these regions in an FLRW
background, and the behaviour of the region between these two regions,
is not considered.) The scale factor in the overdense region therefore
behaves as @xmath with @xmath , and the scale factor in the empty region
behaves as @xmath . It is then straightforward to show that if one
defines a volume averaged scale factor by @xmath , then the effective
deceleration parameter given by @xmath becomes negative (indicating
acceleration) around the time that the overdense region turns around and
starts collapsing.

If we define the volume of each of our three comoving regions
separately, as

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

then the total volume of the region can be used to define a
“Buchert-style” volume averaged scale factor as

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

and hence an effective deceleration parameter @xmath given by

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

whereas Räsänen’s model can be mimicked more closely by ours, if we
simply remove the region 2, by hand. By doing so we are left with two
disjoint regions, each spherically symmetric, one of which is collapsing
and the other expanding ever rapidly and becoming ever emptier. There is
no physical reason to throw away region 2 in this manner, but for the
sake of comparison we will define a “modified” scale factor @xmath and
it’s corresponding deceleration parameter @xmath by

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

In Fig. 5.2 we plot @xmath and @xmath , for several sets of initial
conditions which are close to our “base set” listed in Table 5.1 (except
for Fig. 5.2(d) which has a large value for @xmath ) ¹ ¹ 1 Both curves
in Fig. 5.2(d) begin at @xmath at @xmath . To enhance the contrast
between the curves, we have plotted them for times @xmath . The
remaining plots (Figs. 5.2(a) – 5.2(c) ) are plotted starting from
@xmath . . The various initial conditions correspond to turnaround times
that are slightly greater than, or slightly less than, or significantly
less than the present epoch. The results are therefore valid regardless
of whether the collapse has just begun or is well under way at the
present epoch.

We see that while the modified scale factor does accelerate as in
Räsänen’s model, the scale factor @xmath does not show this effect. The
reason for this can be understood as follows. The region 2 is of a
rather peculiar nature – it is underdense initially and becomes emptier
with time, however its evolution is closely linked to that of the
overdense region 1. Namely, the whole of region 2 (except its boundary
at @xmath ), is dragged along with region 1 and eventually turns around,
instead of expanding away to infinity like its counterpart region 3.
Now, if one ignores region 2, then Räsänen’s arguments about the
remaining two regions stand – one region is contracting and the other is
expanding faster than the global mean, and this stand-off leads to an
acceleration of the effective scale factor @xmath , as we see in the
plots of Fig. 5.2 . But if we account for region 2 as well, then we
bring in a counter-balancing influence of a large underdense volume
which is expanding slower than average, and this reduces the
accelerating influence of region 3 to the point of making the effect
completely disappear. Note that at late times, the volume of region 1
contributes negligibly to the total volume, and the volumes of regions 2
and 3 are comparable.

We wish to highlight two points. First, it is very important to note the
role played by the initial conditions in this entire excercise. The
function @xmath is defined in a continuous fashion once the initial
density, velocity and coordinate scaling are given, and @xmath then
decides which shells will eventually collapse and which will not. The
continuity of @xmath assures us that in models such as ours, with an
overdensity surrounded by an underdensity, the underdense region will
always contain a subregion in which @xmath . We see therefore that the
existence of region 2, is a generic feature not restricted to our
specific choice of discontinuous initial density or vanishing initial
peculiar velocities. Further, as we see in Fig. 5.2(d) , it is possible
to make @xmath deviate even more significantly from the EdS value than
the @xmath effect of the first three figures, but this requires an
unnaturally high value of @xmath (the figure has @xmath ), which
contradicts CMB data. Secondly, one may argue about the “naturalness” of
choosing one set of regions over another set, in order to compute
volumes. But this itself places the physicality of the acceleration
effect into question – if one has to judiciously choose a specific set
of averaging domains in order to obtain acceleration on average, then
the effect would appear to be an artifact of this choice rather than
something which observers would see.

### 5.2 Transforming to Perturbed FLRW form

We now turn to the main calculation of this section. We ask whether the
LTB metric ( B.1 ) for our model can be brought to the perturbed FLRW
form with scalar perturbations, at any arbitrary stage of the collapse.
Namely, we want a coordinate transformation @xmath such that the metric
in the new coordinates is

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

with at least the conditions

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

being satisfied. We will ignore conditions on the derivatives of @xmath
and @xmath for now (see the end of Section 3.2). The scale factor is the
EdS solution, with @xmath as the argument. The coordinate @xmath is
comoving with the (fictitious) background Hubble flow, but not with the
matter itself. On physical grounds we expect that this transformation
should be possible as long as the gravitational field is weak and matter
velocity is small. We will see below that this is exactly what happens.
In the new coordinates, all matter shells labelled by @xmath expand with
the Hubble flow, with a superimposed peculiar velocity.

Since we want @xmath to be comoving with the background, the natural
choice for this coordinate would be @xmath , at least at early times.
Also, we need to account for the local spatial curvature induced by the
initial conditions. As an ansatz for the coordinate transformation
therefore, we consider the equations

  -- -------- -- ---------
     @xmath      (5.26a)
     @xmath      (5.26b)
  -- -------- -- ---------

where @xmath and @xmath are expected to satisfy

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

This form of the transformation keeps us close to the standard gauge
transformation of cosmological perturbation theory, while still
accounting for the deviations in the evolution from the background FLRW,
caused by structure formation. We will show that a self-consistent
transformation exists, which preserves the conditions ( 5.25 ) and (
5.27 ) for most of the evolution. We will use the metric transformation
rule given by

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

and expand to leading order in the small functions @xmath , @xmath ,
@xmath , @xmath and also @xmath which, as we see from Eqn. ( 5.12 ),
remains small in the entire region of interest. The relations in Eqn. (
5.28 ) must be analysed for t he cases @xmath , in each of the three
regions. (The remaining cases can be shown to lead to trivial or
non-independent relations.) The analysis is similar to the standard
gauge transformation analysis in relativistic perturbation theory [ 12 ]
. Since the calculations involved are straightforward but tedious, we
will only present an outline of the calculation and highlight certain
issues. At the end we will present equations for all three regions and
numerically show that the transformation is well-behaved in the regime
of interest.

The case @xmath is easily analysed and leads to

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

The cases @xmath and @xmath both require @xmath for consistency (since
the RHS of Eqn. ( 5.28 ) in these cases has no zero order term to
balance a large @xmath ). Note that since @xmath is the proper time of
each matter shell, the quantity @xmath is simply the velocity of matter
in the @xmath frame (which is comoving with the Hubble flow). In other
words,

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

is the radial comoving peculiar velocity of the matter shells in the
@xmath frame. We will soon see that whereas the quantities @xmath and
@xmath behave roughly as @xmath , the peculiar velocity @xmath behaves
roughly as @xmath . We will therefore treat @xmath as a small quantity
of the same order as @xmath , etc. The case @xmath then leads to

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

the case @xmath gives

  -- -------- -- --------
     @xmath      (5.32)
  -- -------- -- --------

and the case @xmath gives ² ² 2 This corrects an error in Eqn. 35 of
Paper 4. I am grateful to Karel Van Acoleyen for pointing this out to
me.

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

The equations ( 5.29 ), ( 5.33 ), ( 5.31 ), and ( 5.32 ) are valid in
the entire range @xmath , provided the peculiar velocity remains small
in magnitude. The comoving peculiar velocity is given by

  -- -------- -- --------
     @xmath      (5.34)
  -- -------- -- --------

where we have assumed for consistency that @xmath and have dropped the
term @xmath since it is expected to be of higher order than @xmath .
(This can be seen from simple dimensional considerations – we have
@xmath , and since, from Eqns. ( 5.33 ) and ( 5.12 ), @xmath , we also
have @xmath .) We will see that these conditions do indeed hold for most
of the evolution, throughout the region of interest.

#### 5.2.1 The transformation in region 1

Since region 1 corresponds to a homogeneous solution, the integrals in
Eqns. ( 5.31 ) and ( 5.33 ) can be analytically performed. Since @xmath
has the structure @xmath , we have @xmath and Eqn. ( 5.31 ) then leads
to

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

after setting an arbitrary function of time to zero, while Eqn. ( 5.33 )
gives

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

after setting another arbitrary function of time to zero ³ ³ 3 Note that
it might be more meaningful to fix the two arbitrary functions of time
@xmath and @xmath , by requiring that @xmath and @xmath vanish. This
would be in line with the shell @xmath expanding like the flat EdS
background. However, this complicates some of the expressions we
evaluate, and does not change the order of magnitude of any of the final
results. Hence we will continue to assume that the transformation
functions @xmath and @xmath vanish at @xmath rather than at @xmath . .
The peculiar velocity can be explicitly calculated to be

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

where the various functions are defined in Eqns. ( 5.13 ), and we have
defined the constant @xmath by

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

In the rest of this section we will use the parameter values listed in
Table 5.1 . In Fig. 5.3 we have plotted @xmath in region 1. We see that
this dimensionless quantity remains of order @xmath throughout the
evolution. For our choice of @xmath , which corresponds to an
overdensity spanning a few Mpc today, the peculiar velocity is of order
@xmath in region 1.

Direct calculation shows that @xmath and @xmath are equal and given by

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

It is not hard to see that for our parameter choices, @xmath and @xmath
remain of order @xmath for most of the evolution (the @xmath factor will
start becoming significant only at very late times which are larger than
@xmath for our parameter choices). The fact that @xmath is in fact a
general result which follows from the absence of anisotropic stresses in
the problem. It can be shown (see e.g. Refs. [ 35 , 12 ] ) that the
difference between @xmath and @xmath is governed by the stress-tensor
component @xmath which vanishes for the spherically symmetric dust we
are considering ⁴ ⁴ 4 This is independent of whether we use @xmath or
@xmath , since the angular coordinates are not affected by this
transformation. . This is fortunate, since the form of @xmath in regions
2 and 3 is complicated, and is cumbersome to evaluate numerically. All
we need however is @xmath which can be directly evaluated, and @xmath
which can be found after one integration in ( 5.31 ). These are
sufficient to determine @xmath and the form for @xmath immediately
follows, assuming that @xmath and @xmath vanish at the same radius
@xmath (which in our case is @xmath ).

#### 5.2.2 The transformation in regions 2 and 3

For the calculation in regions 2 and 3, the integrals involved cannot be
computed analytically. We will therefore display the expressions we
obtain for @xmath and @xmath , and plot the results of numerically
computing @xmath from these quantities.

-    region 2 ( @xmath ):
    In region 2 we have

      -- -------- -- --------
         @xmath      (5.40)
         @xmath      (5.41)
      -- -------- -- --------

    where @xmath is computed from Eqn. ( 5.35 ) at @xmath , and we have
    defined

      -- -------- -- --------
         @xmath      (5.42)
      -- -------- -- --------

    @xmath must now be computed using ( 5.32 ).

-    region 3 ( @xmath ) :
    The analysis is very similar to that in region 2. We find

      -- -------- -- --------
         @xmath      (5.43)
         @xmath      (5.44)
      -- -------- -- --------

    where @xmath is obtained from ( 5.41 ), evaluated in the limit
    @xmath , and we have defined

      -- -------- -- --------
         @xmath      (5.45)
      -- -------- -- --------

In Fig. 5.4 , we have plotted the velocity @xmath in regions 2 and 3 for
a range of time. It can be shown that at the order of approximation we
are working at, @xmath changes sign at @xmath ⁵ ⁵ 5 Recall @xmath and
hence this shell expands exactly like the EdS background. The metric in
the @xmath coordinates will not be exactly EdS at @xmath , due to our
unusual choice of normalisation for @xmath and @xmath at @xmath . This
does not pose any problem for our conclusions. . In Fig. 5.5 we plot
@xmath . We see that this function is well behaved and remains small for
the entire region of interest (in space and time). Hence the perturbed
FLRW picture is indeed valid for this system, even though each region by
itself appears to be very different from FLRW in the synchronous
coordinates comoving with the matter. Due to numerical difficulties
close to the initial time @xmath , we have plotted the time axis
starting from @xmath . Note that the magnitude of @xmath is sensitive to
the overall size of the region, determined by the value of @xmath . For
our parameter choices given in Table 5.1 , the size of the region at the
present epoch is @xmath , which is a typical size for observed voids.
The dependence is roughly @xmath , and hence a void which is about 10
times larger in length scale than the above value, would have metric
functions about 100 times larger.

We end this subsection by noting the following. It is known that simply
having a metric of the form ( 5.24 ) with only the magnitude of the
perturbations being small, is not enough to guarantee consistency with
Einstein’s equations written as a perturbation series; additional
constraints on the derivatives of these functions must be satisfied.
These constraints, given in e.g. Ref. [ 27 ] , take the form (for the
metric ( 5.24 ) with @xmath ),

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

where @xmath , and @xmath is the spatial covariant derivative associated
with the flat 3-space metric. On dimensional grounds, treating @xmath ,
@xmath and @xmath , it is easy to see that these constraints will be
satisfied by our solution. This should also be expected since we started
from an exact solution of the Einstein equations and performed a
self-consistent coordinate transformation.

#### 5.2.3 The magnitude of the backreaction

One can now legitimately ask the question, “How large is the effect of
the small metric inhomogeneities?” Naively, one would argue that small
inhomogeneities must lead to small effects. Indeed, the question of the
magnitude of the backreaction in the Newtonianly perturbed FLRW setting
has been investigated by Behrend, et al. [ 49 ] in the linear and
quasilinear regimes, and they find that corrections to the FLRW
equations remain at the level of one part in @xmath . However, what we
are dealing with is a situation in which the matter perturbations are
completely nonlinear, and it is not a priori clear that the same
arguments would carry through. Indeed, we saw in section 2 that the
deceleration parameter @xmath deviated from its EdS value by about
@xmath . Here we give an argument based on dimensional considerations
supplemented with realistic numbers, which will show that this effect is
scale dependent, and is not expected to be present if a sufficiently
large averaging scale is chosen.

In the following we will work at the present epoch @xmath . Consider a
model situation similar to the one we have been considering so far, such
that at present epoch the physical extent of the overdense region is
@xmath , and that of the underdense is @xmath . For order of magnitude
estimates, we assume that in the perturbed FLRW metric ( 5.24 ) (which
is valid for this system provided @xmath ), @xmath . Also assume that
the density contrast in the overdense region is @xmath and that in the
underdense region is @xmath , where we take @xmath and @xmath to be
constant in space, which is fine for an order of magnitude estimate. The
backreaction in the Buchert approach contains, among other terms, the
spatial average of the quantity @xmath which appears in the spatial
curvature [ 40 , 49 ] , where @xmath is the Laplacian operator for the
flat @xmath -space metric. The spatial curvature has the structure

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

where @xmath are constants whose values are irrelevant for this order of
magnitude argument. Due to the Einstein equations in the small scale
Newtonian approximation, the leading order effect in the nonlinear
regime, comes from @xmath which satisfies

  -- -------- -- --------
     @xmath      (5.48)
  -- -------- -- --------

Consider the situation when, at present epoch, @xmath Mpc, @xmath Mpc,
@xmath and @xmath . These are typical numbers for clusters of galaxies
and voids. It is straightforward to now show that the spatial average of
@xmath over a domain comprising the overdense and underdense region,
works out to be

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.49)
  -- -------- -------- -- --------

It would appear therefore, that this spatial average of @xmath (which is
usually neglected) thus turns out to be a significant contributor to the
backreaction. (In fact it is the most significant contributor, since the
other terms are clearly of at least one higher order in the small
quantity @xmath , for such a model.)

As we now argue, however, the above effect can be deceptive, and is
really scale dependent. Let the initial density contrasts in the
overdense and underdense regions be @xmath and @xmath respectively, so
that @xmath . If @xmath , @xmath , @xmath and @xmath are the masses at
initial time and today, in the overdense and underdense region
respectively, and @xmath and @xmath are the values of the background
density at initial time and today, then at initial time

  -- -------- -- --------
     @xmath      (5.50)
  -- -------- -- --------

and at present time,

  -- -------- -- --------
     @xmath      (5.51)
  -- -------- -- --------

We now make the crucial observation that if the averaging scale is large
enough , and we are counting several such “pairs” of overdense and
underdense regions, then the mass ejected from the underdense region
must have all gone into the overdense region. It is then easy to show,
that

  -- -------- -- --------
     @xmath      (5.52)
  -- -------- -- --------

which means that, just like in the linear theory, the average of @xmath
is expected to be negligible on such a scale. In the real universe, we
do expect that the averaging scale must be at least of the order of the
homogeneity scale, and on such a scale we will be sampling several pairs
of overdense and underdense regions. The only cumulative effects that
may arise with such a choice of scale are from terms such as @xmath ,
which as we mentioned earlier, are of one higher order in the
perturbation and will give effects of the size @xmath . (For a
demonstration of the scale dependence of the effect, see e.g. the work
of Li and Schwarz, the first paper in Ref. [ 52 ] .)

### 5.3 Backreaction during nonlinear growth of structure

We can do better than the estimates for the magnitude of the
backreaction during late stages of structure formation. In chapter 4 we
have already developed a formalism in place to calculate the
backreaction whenever the metric has the perturbed FLRW form
(irrespective of matter inhomogeneities). We can use this procedure on
our LTB model in the @xmath coordinates to explicitly evaluate the
backreaction functions.

The expressions for the backreaction in Eqns. ( 4.42 ) were derived
under the requirement that the averaging operation be free of gauge
related ambiguities, in linear perturbation theory. However, the actual
conditions used to derive Eqns. ( 4.42 ) only depended on the fact that
one is working with leading order effects in the metric perturbations.
In particular, a key step was the transformation ( 4.39 ) between the
metric in the conformal Newtonian gauge (in Cartesian spatial
coordinates) and the corresponding volume preserving form. In the
present context, the same transformation remains valid at the leading
order , and hence the expressions ( 4.42 ) for the backreaction are
physically relevant here as well. We emphasize that this truncated
averaging operation remains valid even at late times since the weak
field approximation for gravity works well during the nonlinear phase of
structure formation.

Since our numerical results are in terms of the LTB variables @xmath ,
where @xmath “comoves” with the matter but not with the FLRW background,
we need to reexpress the averaging operation ( 4.27 ) in terms of these
variables. It is easy to show that, at the leading order, the average of
a scalar @xmath defined in Eqn. ( 4.27 ) can be written as

  -- -------- -- --------
     @xmath      (5.53)
  -- -------- -- --------

where the function @xmath solves the equation

  -- -------- -- --------
     @xmath      (5.54)
  -- -------- -- --------

Eqn. ( 5.53 ) gives the average of @xmath over a single domain centered
at the origin, which is what we will restrict ourselves to in this
section. There are two reasons behind this choice : firstly this is the
most natural choice given the symmetry of the system, and secondly since
our model is constructed as a “typical representative” of nonlinear
inhomogeneities, it makes sense to use averages over the single central
region as representative of more general averages. As discussed in
section 5.1, we are constrained to consider values @xmath , due to
unphysical shell crossing singularities in the region beyond. For this
reason the largest value of @xmath which we can choose is @xmath , which
then ensures @xmath since @xmath is a decreasing function for this
choice. This gives us an averaging scale of @xmath Mpc (comoving with
the FLRW background), which is smaller than the more realistic expected
value of @xmath Mpc. One consequence is that our model does not strictly
satisfy the condition that the potentials @xmath and @xmath and their
spatial and time derivatives should average to zero, as was assumed in
chapter 4. One can check that the actual average values of the form
@xmath are small ( @xmath ) compared to terms like @xmath which are
needed in the backreaction calculations, for all times, although it
turns out that the time derivatives satisfy @xmath , throughout the
evolution. However, since the averaging scale chosen here is large
enough to encompass all the inhomogeneity of this system, we expect that
our estimates for the backreaction functions in Eqns. ( 4.42 ) are
fairly representative.

Consider now the function @xmath . Since @xmath satisfies the Poisson
equation @xmath on a flat @xmath -space background, with no nontrivial
solutions of the corresponding homogeneous equation allowed, we can
directly write the solution for @xmath in terms of the background radial
coordinate @xmath as,

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.55)
  -- -------- -------- -- --------

where @xmath (we have set @xmath at leading order) and the integration
is over the spatial coordinates comoving with the background . The
following relations turn out to be useful in the calculations,

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.56a)
     @xmath   @xmath      (5.56b)
     @xmath   @xmath      (5.56c)
  -- -------- -------- -- ---------

We will need the quantities @xmath , @xmath and @xmath as functions of
the LTB variables @xmath , which can be done by replacing @xmath and
@xmath at leading order by @xmath and @xmath respectively. This gives us
(treating @xmath as a function of @xmath and @xmath ),

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.57a)
     @xmath   @xmath      (5.57b)
     @xmath   @xmath      (5.57c)
  -- -------- -------- -- ---------

where in the last equation we have used the fact that, at leading order,
@xmath .

Also, noting that the time derivatives in Eqns. ( 4.42 ) are taken
keeping the coordinate @xmath fixed, we have at the leading order, and
in terms of @xmath

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (5.58a)
     @xmath   @xmath      (5.58b)
     @xmath   @xmath      (5.58c)
  -- -------- -------- -- ---------

which follow from Eqns. ( 5.56 ). The expressions in Eqns. ( 4.42 ),
rewritten in terms of the LTB proper time @xmath and valid at leading
order in the various small quantities, reduce to

  -- -------- -- --------
                 
     @xmath      
     @xmath      
     @xmath      (5.59)
  -- -------- -- --------

where the angular brackets are now defined by Eqn. ( 5.53 ) and the
various integrands can be read off using Eqns. ( 5.57 ), ( 5.58 ) and
the results @xmath and @xmath , at leading order.

Figs. 5.6 and 5.7 show results of numerical calculations performed with
Mathematica . Fig. 5.6 shows the evolution of @xmath , the dominant
correction, as a function of the scale factor. The dotted line shows a
hypothetical curvature like correction. Clearly the evolution of the
actual backreaction is more complicated, due to significant evolution of
@xmath . Note that the largest value of @xmath computed here is @xmath ,
whereas estimates using linear theory in chapter 4 suggested that this
value should be around @xmath . This discrepancy highlights an issue we
noticed earlier in chapter 4, namely that nonlinear inhomogeneities on
small scales do not contribute significantly to the backreaction. Our
model has no large scale inhomogeneities and underestimates the
backreaction. Reassuringly, accounting for the deficit only requires a
calculation in linear theory, such as the one in chapter 4. Fig. 5.7
shows the evolution of the remaining integrals, also normalised by
@xmath . An initial rapid decay of @xmath starting from values of @xmath
has not been shown, in order to enhance the contrast in the late time
behaviour of the three functions. The other functions remain subdominant
compared to @xmath at the early times not shown.

This completes the picture of the effects of backreaction in the cosmic
expansion history. Our covariant and self-consistent calculation of the
backreaction in this spherical collapse model establishes that
inhomogeneities have an insignificant impact on the average cosmological
dynamics. In particular, the observed cosmic acceleration cannot be
explained by the averaging of inhomogeneities. Our nonlinear dust model
can be regarded as representing a realistic situation, because it has a
overdensity-void structure, and departure from sphericity, tidal
interactions, and second order corrections are not expected to introduce
any significant change in the results. What appears true in general is
that as long as peculiar velocities remain small, as seems to be the
case in the real universe, a description as a perturbed FLRW model is
valid, and this keeps the backreaction small.

Chapter summary and discussion: In this chapter we addressed the
question of whether or not the perturbed FLRW form for the metric
remains a valid approximation at late times in the cosmological history.
Heuristic arguments such as those presented by Ishibashi and Wald [ 27 ]
indicate that this should in fact be the case. We have studied this
issue in the context of an exactly solvable, fully relativistic toy
model which allows us to track the behaviour of both the metric and
matter perturbations unambiguously, well into the regime where the
matter perturbations have become completely nonlinear.

In these late stages of structure formation, a perturbation theory in
the density contrast @xmath is no longer valid. As expected from
standard Newtonian analyses however [ 11 ] , we found that a
perturbative expansion in peculiar velocities remains valid until fairly
late times. Our model parameters were chosen to reflect typical
inhomogeneities on scales of tens of Mpc. While the perturbative
description of our model eventually breaks down (see e.g. the @xmath
factor in the expression ( 5.39 ) for @xmath ), the model itself is not
expected to reflect realistic conditions at very late times. For
example, real clusters of galaxies eventually achieve virial equilibrium
due to random motions of the galaxies, rather than collapsing to a
singularity. Our pressureless model cannot accomodate such a behaviour
and must be abandoned beyond the point where virialisation is expected
to occur. Heuristic reasoning further suggests that in the virial phase,
the peculiar velocity with respect to the Hubble flow will essentially
be @xmath where @xmath is the virial radius, and the backreaction which
is controlled by @xmath should therefore decrease with time in this
phase. Our model parameters were chosen so that the physical radius of
the overdensity at @xmath is close to typical virial radii for
corresponding realistic clusters, and it is therefore meaningful to stop
the model evolution at @xmath .

Additionally we also computed the backreaction in our model using the
formalism developed in chapter 4. We emphasize that this formalism is
fully covariant, and is guaranteed to yield results which are coordinate
invariant at the leading order. The metric perturbation function @xmath
does not satisfy the equations of linear perturbation theory at late
times, and neither is it expected to. This is reflected in the
complicated behaviour of @xmath seen in Fig. 5.6 . However it is still
true that the metric can be brought to the perturbed FLRW form, which is
all that is required for a reliable calculation of the backreaction. And
finally, since the nonlinear inhomogeneities do not contribute as much
to the backreaction as those on scales @xmath , our entire discussion
regarding convergence of the iterative calculation (see chapter 4
summary and discussion) is expected to remain approximately valid even
after accounting for nonlinearity. This is important since it
establishes that cosmological perturbation theory is stable against
including the effects of the backreaction from averaging
inhomogeneities.

## Chapter 6 Conclusions

Backreaction as an explanation for the late time cosmic acceleration
would have truly been the most conservative solution to the dark energy
problem. Not only would it have resolved the discrepancy between
observed data and what is generally considered to be ‘‘ordinary
physics’’, but more importantly it would have obviated the need for
statements such as ‘‘We do not understand what 70% of the universe is
made of’’ ¹ ¹ 1 Including dark matter would take this number up to
approximately 95%. If we further take into account the fact that the
only component which we directly measure with great precision is the CMB
radiation, then one might say that we truly understand only @xmath of
the universe! . Needless to say, this approach has captured the
imagination of many cosmologists, and the (possibly incomplete) list of
references cited in the Introduction is testimony to this fact. Due to
the technically challenging nature of the problem however, it is very
important to proceed systematically and rigorously while determining the
size and nature of the effects of backreaction. This is especially true
since order of magnitude estimates on the one hand indicate that the
effect can never be large [ 27 ] , while simple toy models indicate
exactly the opposite [ 37 ] . It has been our goal in this thesis to
provide a reliable and self-consistent calculation to estimate the
nature of the backreaction.

We have used a fully covariant averaging formalism, adapted to the
specific needs of cosmology, and developed it further to allow estimates
of the effects of perturbative metric inhomogeneities in a gauge
invariant manner. We have used this formalism in the linear regime of
cosmological perturbations and have shown that linear PT is stable
against the inclusion of backreaction effects. We have also demonstrated
using simple but realistic toy models of nonlinear structure formation,
that (a) a description of the universe in terms of the perturbed FLRW
metric is indeed valid at late times as order of magnitude estimates
suggest, and (b) the backreaction due to these perturbative metric
inhomogeneities remains small, irrespective of whether the matter
inhomogeneities are in the linear or nonlinear regime. One might argue
that more precise nonlinear calculations, e.g. in numerical simulations,
might enhance the effect. While this might be true, this enhancement is
not expected to be by orders of magnitude, since the transfer functions
routinely found in nonlinear calculations do not deviate drastically
enough from the linear theory ones [ 15 ] , to lead to an order unity
backreaction. The cosmological expansion history therefore appears to be
largely insensitive to the presence of the backreaction terms.

Of course, this means that backreaction from averaging cannot solve the
dark energy problem. There have been claims in the literature which
suggest otherwise; we will comment on a few of these in what follows.
Kolb et al. [ 51 ] study a model with very large nonlinear
inhomogeneities (a @xmath Gpc sized void) to claim that in such a case
the perturbed FLRW form for the metric cannot be recovered at all times,
and that backreaction effects can be large. Our results do not
contradict this, since we have seen that the quantity @xmath controls
the late time perturbative expansion, and a @xmath Gpc size
inhomogeneity with a density contrast of order unity today will imply a
breakdown in the perturbation theory. What is important to bear in mind
however, is whether such large inhomogeneities are generic . If the
universe is dominated by Gpc sized voids then our analysis will indeed
break down; but this does not appear to be the case observationally.

Wiltshire [ 38 ] models the scale dependence of inhomogeneities in a
nonperturbative manner using Buchert’s formalism. The assumption is that
the clocks of observers in voids run at very different rates from those
of observers in the “walls” surrounding voids. The argument then is that
since the universe today is dominated by voids (of sizes ranging from
@xmath - @xmath Mpc [ 56 ] ), “wall” observers such as ourselves are
atypical. The difference in clock rates between average observers and
wall-observers is then fitted to data and can account for several sets
of observations. This was a rather simplistic picture of Wiltshire’s
model, which is actually far more involved in its construction. However,
Wiltshire’s basic final result, the clock rate difference mentioned
above, at least superficially does not agree with our results, since in
our toy model we explicitly see that clock rate differences for any pair
of observers are governed by the metric potential @xmath which remains
perturbatively small. It is not clear where this discrepancy arises
from, and this matter is further complicated by the fact that
Wiltshire’s model does not have a concrete setup in which to follow the
evolution of inhomogeneities.

To date, perhaps the most physically clear attempts to explain e.g.
supernova data without invoking dark energy, have involved the
“non-Copernican” models which place us at a special location in the
universe [ 57 ] . At the risk of some repetition, we will briefly
discuss a few issues that arise in this context. As we discussed in the
Introduction, a lot of attention has been focused on studying light
propagation in the inhomogeneous spacetime of a void modelled by the LTB
metric. These calculations involve standard GR, without any averaging
and the associated complications. As far as supernova data are
concerned, the calculations involve light propagation in a known metric,
and the two functional degrees of freedom in LTB models can be suitably
employed to construct a void geometry (which will typically span several
hundred @xmath Mpc) which fits the supernova data without any dark
energy/cosmological constant. This apparently straightforward result
leads to a host of questions. Do such “super”-voids exist in the
universe? Galaxy surveys at least do not show any evidence of this,
although some analyses of CMB data, specifically using the integrated
Sachs-Wolfe effect, have thrown up some interesting results [ 83 ] .
Even if such voids exist, is there any independent evidence that we
reside close to the center of one? (Were we not close to the center, the
CMB dipole would have been much higher.) Current data is not sufficient
to answer this question, although future surveys are likely to make some
headway in this issue [ 60 ] . On the theoretical front, how does one
analyse the growth of structure in a geometry which contains a
nonperturbative void? This question has begun to receive some attention
only recently (see the papers by Zibin, Moss and Scott, and Clifton,
Ferreira and Zuntz, in Ref. [ 57 ] ). The jury is therefore still out on
whether or not “dark energy” is simply a consequence of our being in a
special location. The most encouraging aspect of the “void instead of
dark energy” scenario is that it is amenable to observational testing,
which is very likely to occur in the foreseeable future.

To conclude, backreaction from inhomogeneities cannot solve the dark
energy problem. Void-like inhomogeneities, while having the potential to
solve this problem, await further observational evidence. And for now,
we still do not understand what (at least) 70% of the universe is made
of. The future continues to hold significant challenges for cosmology
and theoretical physics.

## Appendix A Basics of FLRW cosmology

The unique line element for a spacetime which admits homogeneous and
isotropic spatial sections (i.e. @xmath -surfaces of constant curvature)
is given by [ 3 ]

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

Here @xmath is a parameter related to the spatial curvature of @xmath
-space ( @xmath ) and @xmath is the single dynamical function - the
scale factor - which describes the evolution of the universe. This
thesis will mostly deal with the case @xmath corresponding to spatially
flat sections. The line element is written in coordinates which are
comoving with those observers who see a homogeneous and isotropic @xmath
-space. The coordinate @xmath is called cosmic time. The subscript
@xmath will refer to the present epoch @xmath and the scale factor is
always normalized so that @xmath .

The energy-momentum tensor of matter is taken to describe a perfect
fluid, which is homogeneous and isotropic in its rest frame (which
therefore coincides with the comoving reference frame of Eqn. ( A.1 )).
This has the form

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

with @xmath the energy density and @xmath the pressure as measured in
the fluid rest frame.

The Einstein equations @xmath , with @xmath the Einstein tensor
constructed using ( A.1 ) and @xmath as given above, reduce to ¹ ¹ 1
Eqn.( A.3b ) is actually obtained after substituting ( A.3a ) in the
Einstein equation for @xmath .

  -- -------- -- --------
     @xmath      (A.3a)
     @xmath      (A.3b)
  -- -------- -- --------

with the overdot referring to a time derivative @xmath . We will refer
to Eqns. ( A.3a ) and ( A.3b ) as the Friedmann equation and the
acceleration equation respectively. Together with an equation of state
@xmath , these equations can be solved to get an expression for @xmath
and @xmath . (One could also use the Friedmann equation ( A.3a ) in
conjunction with the continuity equation @xmath which follows from
@xmath , to solve for @xmath and @xmath .) For example, with the simple
assumption @xmath for constant @xmath , it can be shown that @xmath ,
and further if @xmath then

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (A.4)
  -- -------- -------- -- -------

where @xmath is constant. Some commonly occurring values of the equation
of state parameter @xmath are @xmath (pressureless matter or dust) and
@xmath (radiation). The case @xmath corresponds to the cosmological
constant @xmath , which gives rise to a constant energy density @xmath ,
and consequently a value of @xmath in Eqn. ( A.4 ) above.

In general we define @xmath , called the Hubble parameter. Its value at
the present epoch ( @xmath ) is called the Hubble constant, and is
usually parametrized as @xmath , with the current consensus on its
numerical value being @xmath . Define the critical density @xmath at the
present epoch as @xmath , and also the quantities @xmath where @xmath is
the value of the density of the @xmath matter component, at the present
epoch. Here @xmath labels the components radiation ( @xmath ), baryons (
@xmath ), dark matter ( @xmath ) and an additional “dark energy”
represented by the cosmological constant ( @xmath ). The total energy
density is simply @xmath and we can write @xmath , with the value of
@xmath at the present epoch being @xmath . The Friedmann equation ( A.3a
) can be written as

  -- -------- -------- -- -------
     @xmath   @xmath      (A.5)
  -- -------- -------- -- -------

where the cases @xmath correspond respectively to @xmath , @xmath ,
@xmath , and in general one would have @xmath . The cosmological
redshift @xmath of a source which emits light of wavelength @xmath at
time @xmath and is observed “here-and-now” at time @xmath with
wavelength @xmath , is

  -- -------- -- -------
     @xmath      (A.6)
  -- -------- -- -------

Using this in ( A.5 ) gives an expression for @xmath . Often it is
useful to work in terms of conformal time @xmath defined by

  -- -------- -- -------
     @xmath      (A.7)
  -- -------- -- -------

with the corresponding Hubble parameter

  -- -------- -- -------
     @xmath      (A.8)
  -- -------- -- -------

## Appendix B The Lemaître-Tolman-Bondi solution

In this appendix we describe the spherically symmetric
Lemaître-Tolman-Bondi (LTB) solution of the Einstein equations for
matter comprising a pressureless “dust” [ 61 ] . For an arbitrary dust
configuration, the metric can always be expressed in coordinates which
are “synchronous” ( @xmath ; @xmath ) and “comoving” (world lines of the
fluid elements are orthogonal to @xmath -space) [ 62 ] . Specifically,
the LTB metric is given in the synchronous and comoving gauge, by

  -- -------- -- -------
     @xmath      (B.1)
  -- -------- -- -------

Throughout this appendix, a prime and a dot will refer to partial
derivatives with respect to @xmath and @xmath respectively. The Einstein
equations simplify to

  -- -------- -- --------
     @xmath      (B.2a)
     @xmath      (B.2b)
  -- -------- -- --------

Surfaces of constant @xmath are @xmath spheres having area @xmath .
@xmath is the energy density of dust, while @xmath and @xmath are
arbitrary functions that arise on integrating the dynamical equations.
Solutions can be found for three cases @xmath , @xmath and @xmath . The
solution for @xmath (the marginally bound case) has the particularly
simple form

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

Here @xmath is another arbitrary function arising from integration. The
solution describes an expanding region, with the initial time @xmath
chosen such that @xmath for all @xmath . For the other two cases, the
solutions can be written in parametric form

  -- -------- -- --------
     @xmath      (B.4a)
     @xmath      (B.4b)
  -- -------- -- --------

In the unbound case ( @xmath ), @xmath increases monotonically with
@xmath , for every shell with label @xmath . In the bound case ( @xmath
), @xmath increases to a maximum value @xmath for each shell @xmath and
then decreases back to @xmath in a finite time.

In all cases, there are two physically different free functions,
although three arbitrary functions @xmath , @xmath and @xmath appear.
One of the three represents the freedom to rescale the coordinate @xmath
. We use this freedom to set ¹ ¹ 1 In the main text we also use a
slightly modified rescaling when convenient. @xmath . To completely
specify the solution, we specify the initial density @xmath and the
function @xmath (which can be related to the initial velocity profile
@xmath using Eqn. ( B.2a ) evaluated at initial time). This specifies
@xmath (which in the marginally bound case is interpreted as the mass
contained in a comoving shell), and @xmath can be solved for using Eqns.
( B.3 ), ( B.4a ) or ( B.4b ) as the case may be, at time @xmath . The
FLRW solution is a special case and is recovered by setting @xmath
constant, @xmath constant.

### b.1 Regularity conditions

It is useful to keep in mind certain regularity conditions when
constructing LTB models. In any LTB model, the functions @xmath and
@xmath are to be specified by initial conditions at @xmath , and the
choice of scaling @xmath fixes @xmath as

  -- -------- -- -------
     @xmath      (B.5)
  -- -------- -- -------

where @xmath and @xmath for @xmath ; @xmath and @xmath for @xmath . The
regularity conditions imposed on this model, and their consequences, are
as follows

-    No evolution at the symmetry centre :
    This is required in order to maintain spherical symmetry about the
    same point at all times, and translates as @xmath for all @xmath .
    The right hand side of Eqn. ( B.2a ) must therefore vanish in the
    limit @xmath . Since the functions involved are non-negative, we
    assume that we can write

      -- -------- -- -------
         @xmath      (B.6)
      -- -------- -- -------

    Consistency requires @xmath to be constant, and our scaling choice
    further requires @xmath . We do not require the exponents @xmath and
    @xmath to necessarily be integers.

-    No shell-crossing singularities :
    Physically, we demand that an outer shell (labelled by a larger
    value of @xmath ) have a larger area radius @xmath than an inner
    shell, at any time @xmath . Unphysical shell-crossing singularities
    arise when this condition is not met. Mathematically, this requires

      -- -------- -- -------
         @xmath      (B.7)
      -- -------- -- -------

-    Regularity of energy density :
    We demand that the energy density @xmath remain finite and strictly
    positive for all values of @xmath and @xmath . Combining this with
    Eqns. ( B.2b ) and ( B.7 ) gives (assuming that @xmath is finite for
    all @xmath and since @xmath )

      -- -------- -- -------
         @xmath      (B.8)
      -- -------- -- -------

-    No trapped shells :
    In order for an expanding shell to not be trapped initially, it must
    satisfy the condition @xmath . Near the regular center, this
    condition is automatically satisfied independent of the exact form
    of @xmath , since there @xmath .

## Appendix C Cosmology in MG

In this appendix we give proofs of several results that were used in
chapter 2.

### c.1 Analysis of @xmath

We start with the metric

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

on @xmath and assume that it averages out to the FLRW form (Eqn. ( 3.71
)):

  -- -------- -- -------
     @xmath      (C.2)
  -- -------- -- -------

We will analyze the second relation of Eqn. ( 3.54 ) and show that it
leads to the result @xmath , where @xmath refers to the connection
@xmath -forms associated with @xmath given by

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (C.3)
  -- -------- -------- -- -------

where @xmath for this section. We have

  -- -------- -- -------
     @xmath      (C.4)
  -- -------- -- -------

Consider the three cases ( @xmath ), ( @xmath ) and ( @xmath ) in turn.
The first case gives

  -- -------- -- -------
     @xmath      (C.5)
  -- -------- -- -------

which reduces to

  -- -------- -- -------
     @xmath      (C.6)
  -- -------- -- -------

We can conclude that

  -- -------- -- --------
     @xmath      (C.7a)
     @xmath      (C.7b)
  -- -------- -- --------

where @xmath is a positive definite function (so that the metric
signature is preserved) which arises as an integration constant and is
constrained by Eqn. ( C.7b ). The second case ( @xmath ) leads to

  -- -------- -- -------
     @xmath      (C.8)
  -- -------- -- -------

which gives us

  -- -------- -- --------
     @xmath      (C.9a)
     @xmath      (C.9b)
  -- -------- -- --------

where @xmath is a @xmath -vector that arises as a constant of
integration like @xmath , and is constrained by Eqn. ( C.9b ). Finally,
the last case ( @xmath ) leads to

  -- -------- -- --------
     @xmath      (C.10)
  -- -------- -- --------

which gives us

  -- -------- -- ---------
     @xmath      (C.11a)
     @xmath      (C.11b)
  -- -------- -- ---------

Here @xmath is another constant of integration, a symmetric @xmath
-tensor. Now, since the left hand side of Eqn. ( C.7b ) is independent
of time, either the time dependence of the right hand side must cancel,
or both sides must vanish. For the time dependence to cancel, we need
@xmath which is not expected a priori . Therefore both sides of Eqn. (
C.7b ) must vanish, which immediately tells us that the vector @xmath
must vanish, and the function @xmath must be a constant,

  -- -------- -- --------
     @xmath      (C.12)
  -- -------- -- --------

Equations ( C.9b ) and ( C.11b ) then give us

  -- -------- -- --------
     @xmath      (C.13)
  -- -------- -- --------

with the same constant @xmath as in Eqn. ( C.12 ). Finally, putting
everything together we find

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath               (C.14)
  -- -------- -------- -- --------

The constant @xmath is not constrained by any of the equations and
appears to be a free parameter in the theory. The modified Einstein
equations ( 3.58 ) show that @xmath can be absorbed into the averaged
energy momentum tensor. We will for simplicity assume @xmath to be unity
thereby obtaining, as required

  -- -------- -- --------
     @xmath      (C.15)
  -- -------- -- --------

### c.2 Analysis of the condition @xmath

Here we will assume that the line element on @xmath is in the volume
preserving gauge

  -- -------- -- --------
     @xmath      (C.16)
  -- -------- -- --------

so that the averaging is trivial, and the metric and averages out to the
FLRW line element on @xmath given by

  -- -------- -- --------
     @xmath      (C.17)
  -- -------- -- --------

where we used the condition @xmath that follows from @xmath . The
conditions @xmath then result in the following :

  -- -------- -- ---------
                 
     @xmath      (C.18a)
     @xmath      (C.18b)
     @xmath      (C.18c)
     @xmath      (C.18d)
     @xmath      (C.18e)
     @xmath      (C.18f)
  -- -------- -- ---------

Eqns. ( C.18b ) and ( C.18f ) are consistent with each other since
@xmath , and Eqn. ( C.18c ) is consistent with the assumption Eqn. (
3.53a ). The trace of Eqn. ( C.18d ) gives @xmath . However we have
@xmath , and combined with Eqn. ( C.18a ) this gives

  -- -------- -- --------
     @xmath      (C.19)
  -- -------- -- --------

where we have set an arbitrary proportionality constant (representing
rescaling of the time coordinate by a constant) to unity. This
establishes the last equality in Eqn. ( 3.78 ).

Finally, consider the trace @xmath : using the condition @xmath , Eqn. (
C.18e ) and the trace of Eqn. ( C.18d ), this gives us

  -- -------- -- --------
     @xmath      (C.20)
  -- -------- -- --------

On using the condition ( 3.53a ) this leads to

  -- -------- -- --------
     @xmath      (C.21)
  -- -------- -- --------

which is consistent with the assumption

  -- -------- -- --------
     @xmath      (C.22)
  -- -------- -- --------
