###### Contents

-    Abstract
-    Comments
-    Dedication
-    Acknowledgements
-    1 Coxeter groups and fully commutative elements
    -    1.1 Coxeter groups
    -    1.2 Fully commutative elements of Coxeter groups
    -    1.3 Star and weak star reductions
-    2 Heaps
    -    2.1 Heaps for elements of Coxeter groups
    -    2.2 Representations of heaps for elements of @xmath
    -    2.3 Saturated and convex subheaps
    -    2.4 Heaps for fully commutative elements in @xmath
    -    2.5 Weak star operations on heaps for fully commutative
        elements
-    3 The type I and type II elements of @xmath
    -    3.1 The type I elements
    -    3.2 The type II elements
-    4 Classification of the weak star irreducible elements in @xmath
    -    4.1 Statement of theorem
    -    4.2 Preparatory lemmas
    -    4.3 Proof of the classification of the irreducible elements in
        @xmath
-    5 Classification of the weak star irreducible elements in @xmath
    -    5.1 Statement of theorem
    -    5.2 More preparatory lemmas
    -    5.3 Proof of the classification of the irreducible elements in
        @xmath
-    6 Hecke algebras and Temperley–Lieb algebras
    -    6.1 Hecke algebras
    -    6.2 Temperley–Lieb algebras
    -    6.3 A presentation for @xmath
    -    6.4 Weak star reducibility and the monomial basis
    -    6.5 A characterization for an arbitrary product of monomials
-    7 Free products of associative algebras
    -    7.1 Bergman’s diamond lemma
    -    7.2 Free product of associative algebras
    -    7.3 Free product of two Verlinde algebras
-    8 Diagram algebras
    -    8.1 Summary of notation
    -    8.2 Ordinary Temperley–Lieb pseudo diagrams
    -    8.3 Decorated pseudo diagrams
    -    8.4 The @xmath -decorated diagram algebra @xmath and admissible
        diagrams
    -    8.5 Temperley–Lieb diagram algebras of type @xmath
-    9 A basis for @xmath
    -    9.1 Preparatory lemmas
    -    9.2 The admissible diagrams are generated by the simple
        diagrams
    -    9.3 More preparatory lemmas
    -    9.4 The set of admissible diagrams form a basis for @xmath
-    10 Main results
    -    10.1 The homomorphism @xmath from @xmath to @xmath
    -    10.2 Preparatory lemmas
    -    10.3 Each monomial maps to a single admissible diagram
    -    10.4 Proof of main result

## Chapter 1 Coxeter groups and fully commutative elements

In this first chapter, we will set up our notation and review some of
the necessary background material. For a reader unfamiliar with Coxeter
groups, we recommend either the classic text by Humphreys [ 16 ] or the
recent text by Björner and Brenti [ 3 ] for a more combinatorial
treatment.

### 1.1 Coxeter groups

A Coxeter group is a group @xmath with together with a distinguished set
of generating involutions @xmath subject to relations of the form @xmath
, where @xmath and @xmath . In other words, @xmath is given by the
presentation

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath . It turns out that the elements of @xmath are
distinct as group elements, and that @xmath is the order of @xmath . We
will only be interested in Coxeter groups in which the generating set
@xmath is finite. We call the pair @xmath a Coxeter system . Given a
Coxeter system @xmath , the associated Coxeter graph is the graph @xmath
on the generating set @xmath with edges connecting @xmath and @xmath ,
labeled @xmath , for all pairs @xmath with @xmath . If @xmath , it is
customary to leave the corresponding edge unlabeled. Given a Coxeter
graph @xmath , we can uniquely reconstruct the corresponding Coxeter
system @xmath . When we have a particular Coxeter graph @xmath in mind,
we will denote the underlying Coxeter group and distinguished generating
set by @xmath and @xmath , respectively.

###### Example 1.1.1.

In this example, we introduce three specific Coxeter groups that will
turn up frequently throughout this thesis.

-   The Coxeter graph of type @xmath ( @xmath ) is as follows.

    []

    Then @xmath is generated by @xmath and is subject only to the
    relations

    1.  [label=(0)]

    2.  @xmath for all @xmath ;

    3.  @xmath if @xmath ;

    4.  @xmath if @xmath .

    It is well-known (see [ 16 , Chapter 1] ) that @xmath is isomorphic
    to the symmetric group, @xmath , under the correspondence

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath is the adjacent transposition exchanging @xmath and
    @xmath .

-   The Coxeter graph of type @xmath ( @xmath ) is as follows.

    []

    In this case, @xmath is generated by @xmath and is subject only to
    the relations

    1.  [label=(0)]

    2.  @xmath for all @xmath ;

    3.  @xmath if @xmath ;

    4.  @xmath if @xmath and @xmath ;

    5.  @xmath .

-   The Coxeter graph of type @xmath ( @xmath ), pronounced “affine
    @xmath ”, is as follows.

    []

    Here, we see that @xmath is generated by @xmath and is subject only
    to the relations

    1.  [label=(0)]

    2.  @xmath for all @xmath ;

    3.  @xmath if @xmath ;

    4.  @xmath if @xmath and @xmath ;

    5.  @xmath if @xmath or @xmath .

Let @xmath be an arbitrary Coxeter graph. An expression is any product
of generators from @xmath . The length @xmath of an element @xmath is
the minimum number of generators appearing in any expression for the
element @xmath . Such a minimum length expression is called a reduced
expression . (Any two reduced expressions for @xmath have the same
length.) A product @xmath with @xmath is called reduced if @xmath . Each
element @xmath can have several different reduced expressions that
represent it. Given @xmath , if we wish to emphasize a fixed, possibly
reduced, expression for @xmath , we represent it in sans serif font, say
@xmath , where each @xmath . Note that if we write @xmath without the
sans serif font, then we are referring to a group element that is not
necessarily a generator. The context should also clarify any potential
confusion.

###### Example 1.1.2.

Let @xmath with expression @xmath . Since @xmath , @xmath , and @xmath
in @xmath , we see that

  -- -------- --
     @xmath   
  -- -------- --

This shows that @xmath is not reduced. However, it is true (but not
immediately obvious) that @xmath is a reduced expression for @xmath , so
that @xmath .

The following theorem is a well-known result, attributed variously to
Matsumoto [ 6 , Theorem 1.2.2] , [ 24 ] and Tits [ 29 ] .

###### Theorem 1.1.3 (Matsumoto’s Theorem).

Let @xmath be an arbitrary Coxeter graph and let @xmath . Then every
reduced expression for @xmath can be obtained from any other by applying
a sequence of braid moves of the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , and each factor in the move has @xmath letters. @xmath

Let the support of an element @xmath , denoted @xmath , be the set of
all generators appearing in any reduced expression for @xmath , which is
well-defined by Matsumoto’s Theorem.

Given a reduced expression @xmath for @xmath , we define a subexpression
of @xmath to be any expression obtained by deleting some subsequence of
generators in the expression for @xmath . If @xmath has an expression
that is equal to a subexpression of @xmath , then we write @xmath . This
is a well-defined partial order [ 16 , Chapter 5] on @xmath and is
called the (strong) Bruhat order . We will refer to a consecutive
subexpression of @xmath as a subword .

###### Example 1.1.4.

Let @xmath have reduced expressions @xmath , @xmath , and @xmath ,
respectively. Then @xmath and @xmath are both subexpressions for @xmath
, while only @xmath is a subword of @xmath . Then we have @xmath .

Let @xmath . We write

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

The set @xmath (respectively, @xmath ) is called the left (respectively,
right ) descent set of @xmath . It turns out that @xmath (respectively,
@xmath ) if and only if @xmath has a reduced expression beginning
(respectively, ending) with @xmath .

###### Example 1.1.5.

Let @xmath have reduced expression @xmath . Since @xmath and @xmath
commute, but @xmath commutes with neither @xmath nor @xmath , it follows
from Matsumoto’s Theorem (Theorem 1.1.3 ) that @xmath and @xmath .

It is known to be true (see [ 16 , Chapter 5] ) that we can obtain
@xmath from @xmath by removing the generator @xmath and the
corresponding relations. We also obtain a Coxeter group of type @xmath
if we remove the generator @xmath and the corresponding relations. To
distinguish these two cases, we let @xmath denote the subgroup of @xmath
generated by @xmath and we let @xmath denote the subgroup of @xmath
generated by @xmath .

It is well-known that @xmath is an infinite Coxeter group while @xmath
and @xmath are both finite. For a proof of this fact, see [ 16 ,
Chapters 2 and 6] .

### 1.2 Fully commutative elements of Coxeter groups

Let @xmath be an arbitrary Coxeter graph and let @xmath . Following
Stembridge [ 27 ] , we define a relation @xmath on the set of reduced
expressions for @xmath . Let @xmath and @xmath be two reduced
expressions for @xmath . We define @xmath if we can obtain @xmath from
@xmath by applying a single commutation move of the form @xmath , where
@xmath . Now, define the equivalence relation @xmath by taking the
reflexive transitive closure of @xmath . We refer to each equivalence
class under @xmath as a commutation class . Note that @xmath if and only
if we can obtain @xmath from @xmath by a sequence of commutation moves.
If @xmath has a single commutation class, then we say that @xmath is
fully commutative . According to [ 27 , Proposition 2.1] , an element
@xmath is fully commutative if and only if no reduced expression for
@xmath contains a subword of the form @xmath of length @xmath . This
also follows from Matsumoto’s Theorem (Theorem 1.1.3 ). We will denote
the set of all fully commutative elements of @xmath by @xmath .

###### Remark 1.2.1.

The fully commutative elements of @xmath are precisely those such that
all reduced expressions avoid subwords of the following types:

1.  [label=(0)]

2.  @xmath for @xmath and @xmath ;

3.  @xmath for @xmath or @xmath .

Note that the fully commutative elements of @xmath and @xmath avoid the
respective subwords above.

###### Example 1.2.2.

Let @xmath have reduced expressions @xmath and @xmath , respectively.
Since @xmath and @xmath commute, we can write

  -- -------- --
     @xmath   
  -- -------- --

This shows that @xmath has a reduced expression containing @xmath as a
subword, which implies that @xmath is not fully commutative. On the
other hand, we will never be able to rewrite @xmath to produce an
illegal subword, since the only relation we can apply is @xmath and this
does not provide an opportunity to apply any additional relations. So,
@xmath is fully commutative.

In [ 27 ] , Stembridge classified the Coxeter groups that contain a
finite number of fully commutative elements. According to [ 27 , Theorem
5.1] , @xmath contains an infinite number of fully commutative elements.
Since @xmath is a finite group, @xmath , and hence @xmath , contains
only finitely many fully commutative elements. There are examples of
infinite Coxeter groups that contain a finite number of fully
commutative elements.

### 1.3 Star and weak star reductions

The notion of star operation was originally defined by Kazhdan and
Lusztig in [ 20 , §4.1] for simply laced Coxeter groups (i.e., @xmath
for all @xmath and @xmath that are adjacent in the Coxeter graph) and
was later generalized to arbitrary Coxeter groups in [ 21 , §10.2] . If
@xmath is a pair of noncommuting generators for @xmath , then @xmath
induces four partially defined maps from @xmath to itself, known as star
operations. A star operation, when it is defined, respects the partition
@xmath of the Coxeter group, and increases or decreases the length of
the element to which it is applied by 1. For our purposes, it is enough
to define star operations that decrease length by 1, and so we will not
develop the full generality.

Let @xmath be an arbitrary Coxeter graph and let @xmath . Suppose that
@xmath . Then we define @xmath to be left star reducible by @xmath to
@xmath if there exists @xmath with @xmath . In this case, we say that
@xmath is left star reducible by @xmath with respect to @xmath , and we
define

  -- -------- --
     @xmath   
  -- -------- --

and refer to @xmath as a left star reduction . We analogously define
right star reducible and right star reduction . If @xmath is right star
reducible by @xmath with respect to @xmath , then we define

  -- -------- --
     @xmath   
  -- -------- --

If @xmath is not left (respectively, right) star reducible by @xmath
with respect to @xmath , then @xmath (respectively, @xmath ) is
undefined. Observe that if @xmath , then @xmath is left (respectively,
right) star reducible by @xmath with respect to @xmath if and only if
@xmath (respectively, @xmath ), where the product is reduced.

###### Example 1.3.1.

Let @xmath (for any @xmath ) have reduced expression @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

If @xmath has reduced expression @xmath , then @xmath and @xmath are
undefined for any noncommuting @xmath and @xmath .

If there is a (possibly trivial) sequence

  -- -------- --
     @xmath   
  -- -------- --

where, for each @xmath , @xmath is left or right star reducible to
@xmath , we say that @xmath is star reducible to @xmath . If @xmath is
star reducible to some @xmath , then we say that @xmath is star
reducible .

We say that a Coxeter group @xmath , or its Coxeter graph @xmath , is
star reducible if every element of @xmath is star reducible to a product
of commuting generators from @xmath . In [ 12 ] , Green classified the
star reducible Coxeter groups. It turns out that @xmath is star
reducible if and only if @xmath is odd (recall that @xmath has @xmath
generators). However, both @xmath and @xmath are star reducible,
regardless of the parity of @xmath (see [ 12 , Theorem 6.3] ).

###### Example 1.3.2.

Let @xmath have reduced expression @xmath . Then @xmath and @xmath are
undefined for all pairs of noncommuting generators @xmath and @xmath .
To see that this is true, first observe that @xmath . Then for @xmath ,
we have @xmath , where we obtain @xmath (respectively, @xmath ) by
removing the leftmost (respectively, rightmost) occurrence of @xmath in
@xmath . Then we see that @xmath (respectively, @xmath ) does not
contain a generator not commuting with @xmath . So, @xmath is neither
left nor right star reducible to a product of commuting generators.
Therefore, @xmath is not star reducible. We can construct similar
examples for @xmath for any even @xmath .

We now introduce the concept of weak star reducible, which is related to
Fan’s notion of cancellable in [ 5 ] . Similar to ordinary star
reductions, if @xmath is a pair of noncommuting generators for @xmath ,
then @xmath induces four partially defined maps, called weak star
reductions, from @xmath to itself. (Note our restriction to the set of
fully commutative elements.)

###### Definition 1.3.3.

Let @xmath be a Coxeter graph and let @xmath . Then @xmath is left weak
star reducible by @xmath with respect to @xmath to @xmath if

1.  [label=(0)]

2.  @xmath is left star reducible by @xmath with respect to @xmath ;

and

1.  [label=(0), resume]

2.  @xmath .

Observe that (1) implies that @xmath and that @xmath . Furthermore, (2)
implies that @xmath . We analogously define right weak star reducible .
If @xmath is left weak star reducible by @xmath with respect to @xmath ,
then we define

  -- -------- --
     @xmath   
  -- -------- --

and refer to @xmath as a left weak star reduction . Similarly, if @xmath
is right weak star reducible by @xmath with respect to @xmath , we
define

  -- -------- --
     @xmath   
  -- -------- --

and refer to @xmath as a right weak star reduction . If there is a
(possibly trivial) sequence

  -- -------- --
     @xmath   
  -- -------- --

where, for each @xmath , @xmath is left weak star reducible or right
weak star reducible to @xmath , we say that @xmath is weak star
reducible to @xmath . If @xmath is weak star reducible to some @xmath ,
then we say that @xmath is weak star reducible . If @xmath is not weak
star reducible, then we say that @xmath is weak star irreducible , or
simply irreducible .

###### Example 1.3.4.

Let @xmath have reduced expressions @xmath and @xmath , respectively. We
see that @xmath is left (and right) weak star reducible by @xmath with
respect to @xmath , and so @xmath is not irreducible. However, @xmath is
irreducible.

###### Remark 1.3.5.

We make several comments about weak star reducibility.

1.  [label=(0)]

2.  Note the similarity in notation for star reductions versus weak star
    reductions. We use @xmath for ordinary star reductions and @xmath
    for weak star reductions. There should be no confusion because we
    will only use weak star reductions in the remainder of this thesis.

3.  Observe that we restrict the definition of weak star reducible to
    fully commutative elements. It follows from the subword
    characterization of full commutativity [ 27 , Proposition 2.1] that
    if @xmath is left or right weak star reducible to @xmath , then
    @xmath is also fully commutative.

4.  As the terminology suggests, if @xmath is weak star reducible to
    @xmath , then @xmath is also star reducible to @xmath . However,
    there are examples of fully commutative elements that are star
    reducible, but not weak star reducible. For example, consider @xmath
    . We see that @xmath is star reducible, but not weak star reducible
    since @xmath and @xmath are still fully commutative for any @xmath .
    Moreover, observe that if @xmath , then the definition of a weak
    star reduction agrees with the definition of a star reduction. In
    particular, weak star reductions are equivalent to ordinary star
    reductions in a Coxeter group of type @xmath .

If @xmath , then @xmath is left weak star reducible by @xmath with
respect to @xmath if and only if @xmath (reduced) when @xmath , or
@xmath (reduced) when @xmath . In this case, we have

  -- -------- --
     @xmath   
  -- -------- --

Again, observe that the characterization above applies to @xmath and
@xmath . In Chapter 4 , we will classify the irreducible elements of
@xmath and @xmath , which verifies Fan’s unproved claim in [ 5 , §7.1]
about the set of @xmath having no element of @xmath or @xmath that can
be left or right cancelled, respectively. We will then use the
classification of the type @xmath and @xmath irreducible elements to
classify the irreducible elements in @xmath (see Chapter 5 ).

## Chapter 2 Heaps

Every reduced expression can be associated with a partially ordered set
called a heap that we define below. This partially ordered set allows us
to visualize a reduced expression as a set of lattice points while
preserving the necessary information about the relations among the
generators. Cartier and Foata [ 4 ] were among the first to study heaps
of dimers, and these were generalized to other settings by Viennot [ 31
] . Later, Stembridge studied enumerative aspects of heaps [ 27 , 28 ]
in the context of fully commutative elements, which is our motivation
here. In this chapter, we mimic the development found in [ 2 ] , [ 17 ]
, and [ 27 ] .

### 2.1 Heaps for elements of Coxeter groups

Let @xmath be a Coxeter graph. Suppose @xmath is a fixed reduced
expression for @xmath . As in [ 27 ] , we define a partial ordering on
the indices @xmath by the transitive closure of the relation @xmath
defined via @xmath if @xmath and @xmath and @xmath do not commute. In
particular, @xmath if @xmath and @xmath (since we took the transitive
closure). It follows from [ 27 , Proposition 2.2] that if @xmath and
@xmath are two reduced expressions for @xmath that are in the same
commutativity class, then the labeled posets of @xmath and @xmath are
isomorphic, where @xmath is labeled by @xmath . This isomorphism class
of labeled posets is called the heap of @xmath . In particular, if
@xmath is fully commutative then it has a single commutativity class,
and so there is a unique heap associated to @xmath .

###### Example 2.1.1.

Let @xmath be a reduced expression for @xmath . We see that @xmath is
indexed by @xmath . As an example, we see that @xmath since @xmath and
the second and third generators do not commute. In general, the labeled
Hasse diagram for the unique heap poset of @xmath is shown below.

[]

###### Remark 2.1.2.

We remark that some authors define the heap of @xmath to be the labeled
poset that results from reversing the partial order. That is, some
authors draw their heaps upside-down relative to ours. Our convention is
appropriate because it more naturally aligns with the construction of
our desired diagram algebra.

### 2.2 Representations of heaps for elements of @xmath

Now, consider @xmath and let @xmath . (Note that @xmath is simply the
index set for @xmath .) Let @xmath be a fixed reduced expression for
@xmath . As in [ 2 ] and [ 17 ] , we will represent a heap as a set of
lattice points embedded in @xmath . To do so, we assign coordinates (not
unique) @xmath to each entry of the labeled Hasse diagram for the heap
of @xmath in such a way that:

1.  [label=(0)]

2.  if an entry represented by @xmath is labeled @xmath in the heap,
    then @xmath ;

and

1.  [label=(0), resume]

2.  if an entry represented by @xmath is greater than an entry
    represented by @xmath in the heap, then @xmath .

Recall that a finite poset is determined by its covering relations. In
the case of @xmath , it follows from the definition that @xmath covers
@xmath in the heap if and only if @xmath , @xmath , and there are no
entries @xmath such that @xmath and @xmath . Hence, we can completely
reconstruct the edges of the Hasse diagram and the corresponding heap
poset from a lattice point representation. This representation enables
us to make arguments “by picture” that are otherwise cumbersome.

###### Definition 2.2.1.

Let @xmath be a reduced expression for @xmath . We let @xmath denote a
lattice representation of the heap poset in @xmath constructed as
described in the preceding paragraph.

If @xmath is fully commutative, then the choice of reduced expression
for @xmath is irrelevant. In this case, we may write @xmath (note the
absence of sans serif font) and we will refer to @xmath as the heap of
@xmath .

Although there are many possible coordinate assignments for a given
heap, the @xmath -coordinates of each entry are fixed for all of them,
and the coordinate assignments of any two entries only differ in the
amount of vertical space between them. We will say that all entries
having the same @xmath -coordinate lie in the same column , where two
columns are adjacent if they correspond to adjacent vertices in the
Coxeter graph.

Let @xmath be a reduced expression for @xmath . If @xmath and @xmath are
adjacent generators in the Coxeter graph with @xmath , then we must
place the point labeled by @xmath at a level that is above the level of
the point labeled by @xmath . Because generators that are not adjacent
in the Coxeter graph do commute, points that lie in non-adjacent columns
can slide past each other or land at the same level. To emphasize the
covering relations of the lattice representation we will enclose each
entry of the heap in a rectangle in such a way that if one entry covers
another, the rectangles overlap halfway.

###### Example 2.2.2.

Let @xmath be as in Example 2.1.1 . Then one possible representation for
@xmath is as follows.

[]

Here is another possible representation for @xmath .

[]

As in [ 2 ] , when @xmath is fully commutative, we wish to make a
canonical choice for the representation @xmath by “coalescing” the
entries in a particular way. To do this, we give all entries
corresponding to elements in @xmath the same vertical position; all
other entries in the heap should have vertical position as high as
possible. One possible interpretation of this canonical choice is that
adjacent columns represent overlapping stacks of cafeteria trays, where
there are springs under each column of trays that maintain the height of
the top row. In Example 2.2.2 , the first representation of @xmath that
we provided is the canonical representation. When illustrating heaps, we
will adhere to this canonical choice, but our arguments should always be
viewed as referring to the underlying heap poset. In particular, when we
consider the heaps of arbitrary reduced expressions, we will only allude
to the relative vertical positions of the entries, and never their
absolute coordinates.

Given a canonical representation of a heap, it makes sense to refer to
the @xmath th row of the heap, and we will occasionally do this when no
confusion will arise. (The first row of the heap corresponds to the left
descent set.) If @xmath , let @xmath denote the @xmath th row of the
canonical representation for @xmath . We will write @xmath to denote
that there is an entry occurring in the @xmath th row labeled by @xmath
. If @xmath consists entirely of entries labeled by @xmath , where
@xmath , then we will write @xmath . For example, consider the canonical
representation of @xmath in Example 2.2.2 . Then @xmath and @xmath .

###### Remark 2.2.3.

Our canonical representation of heaps of fully commutative elements
corresponds exactly to the Cartier–Foata normal form for monomials [ 4 ,
12 ] .

Let @xmath have reduced expression @xmath and suppose @xmath and @xmath
are a pair of entries in the heap of @xmath that correspond to the same
generator @xmath , so that they lie in the same column @xmath of the
heap. We say that @xmath and @xmath are consecutive if there is no other
occurrence of @xmath occurring between them in @xmath . In this case,
@xmath and @xmath are consecutive in @xmath , as well. For example the
two occurrences of the generator @xmath in the heaps given in Example
2.2.2 are consecutive. In general, for @xmath to be reduced, there must
exist at least one generator not commuting with @xmath that occurs
between @xmath and @xmath .

###### Remark 2.2.4.

Since @xmath and @xmath are both subgroups of @xmath , we naturally have
heap representations of elements from these groups, where the
appropriate entries never appear. That is, the heap for a fully
commutative element @xmath from @xmath (respectively, @xmath ) is the
same as the heap for @xmath when considered as an element of @xmath .

### 2.3 Saturated and convex subheaps

Let @xmath be a reduced expression for @xmath . Then @xmath is a
representation of the heap poset on the set @xmath , where @xmath is
labeled by the generator @xmath . We define a heap @xmath to be a
subheap of @xmath if @xmath , where @xmath is a subexpression of @xmath
. The subheap @xmath is a representation of the heap poset of the set
@xmath . We emphasize that the subexpression need not be a subword
(i.e., a consecutive subexpression).

A subheap @xmath of @xmath is called a saturated subheap if whenever
@xmath and @xmath occur in @xmath such that there exists a saturated
chain from @xmath to @xmath in the underlying poset for @xmath , there
also exists a saturated chain @xmath in the underlying poset for @xmath
such that @xmath is also a saturated chain in the underlying poset for
@xmath . (Note that, to the best of our knowledge, the notion of
saturated subheap has not appeared in the literature before.)

###### Example 2.3.1.

Let @xmath as in Example 2.1.1 . Also, let @xmath be the subexpression
of @xmath that results from deleting all but the first, third, and last
generators of @xmath . Then @xmath equals

[]

and is a subheap of @xmath . However, @xmath is not a saturated subheap
of @xmath since there is a saturated chain in @xmath from the lower
occurrence of @xmath to the occurrence of @xmath , but there is not a
chain between the corresponding entries in @xmath . Note that we could
obtain a heap with an identical representation by considering the
subexpression that results from deleting all but the first, third, and
fifth generators of @xmath . Now, let @xmath be the subexpression of
@xmath that results from deleting all but fifth, sixth, and last
generators of @xmath . Then @xmath equals

[]

and is a saturated subheap of @xmath .

Recall that a subposet @xmath of @xmath is called convex if @xmath
whenever @xmath in @xmath and @xmath . We will refer to a subheap as a
convex subheap if the underlying subposet is convex. (Note that all
convex subheaps are saturated, but not all saturated subheaps are
convex.)

###### Example 2.3.2.

Let @xmath and @xmath be as in Example 2.3.1 . Then @xmath is not a
convex subheap since there is an entry in @xmath labeled by @xmath
occurring between the two consecutive occurrences of @xmath that does
not occur in @xmath . However, if we do include the entry labeled by
@xmath , then

[]

is a convex subheap of @xmath . Let @xmath be the subexpression that
results from deleting all but the second, third, and fourth generators
of @xmath . Then @xmath is equal to

[]

and is a convex subheap of @xmath .

From this point on, if there can be no confusion, we will not specify
the exact subexpression that a subheap arises from.

The following fact is implicit in the literature (in particular, see the
proof of Proposition 3.3 in [ 27 ] ) and follows easily from the
definitions.

###### Proposition 2.3.3.

Let @xmath . Then @xmath is a convex subheap of @xmath if and only if
@xmath is the heap for some subword of some reduced expression for
@xmath . @xmath

### 2.4 Heaps for fully commutative elements in @xmath

It will be extremely useful for us to be able to recognize when a heap
corresponds to a fully commutative element in @xmath . The following
lemma follows immediately from Remark 1.2.1 and is also a special case
of [ 27 , Proposition 3.3] .

###### Lemma 2.4.1.

Let @xmath . Then @xmath cannot contain any of the following convex
subheaps, where we use @xmath to emphasize that no element of the heap
occupies that position.

1.   [label= ()]

2.  +-----------------------+-----------------------+-----------------------+
    |   ----                |   -----               |   ----                |
    |   []                  |   and                 |   []                  |
    |   ----                |   -----               |   ----                |
    +-----------------------+-----------------------+-----------------------+

    ;

3.  +-----------------------+-----------------------+-----------------------+
    |   ----                |   -----               |   ----                |
    |   []                  |   and                 |   []                  |
    |   ----                |   -----               |   ----                |
    +-----------------------+-----------------------+-----------------------+

    ;

4.  +-----------------+-----------------+-----------------+-----------------+
    |   ----          |   -----         |   ----          |   -             |
    |   []            |   and           |   []            | --------------- |
    |   ----          |   -----         |   ----          |                 |
    |                 |                 |                 |  where @xmath . |
    |                 |                 | ,               |   -             |
    |                 |                 |                 | --------------- |
    +-----------------+-----------------+-----------------+-----------------+

@xmath

###### Remark 2.4.2.

It is important to note that since @xmath in @xmath , the heap of a
fully commutative element may contain the following convex chains:

+-----------------------+-----------------------+-----------------------+
|   ----                | and                   |   ----                |
|   []                  |                       |   []                  |
|   ----                |                       |   ----                |
|                       |                       |                       |
|                       |                       | .                     |
+-----------------------+-----------------------+-----------------------+

###### Definition 2.4.3.

Let @xmath . We define @xmath to be the maximum integer @xmath such that
@xmath has a reduced expression of the form @xmath (reduced), where
@xmath , @xmath , and @xmath is a product of commuting generators.

Note that @xmath may be greater than the size of any row in the
canonical representation of @xmath . Also, it is known that @xmath is
equal to the size of a maximal antichain in the heap poset for @xmath .

###### Example 2.4.4.

Let @xmath be a reduced expression for @xmath . Then

  -- -- --
        
  -- -- --

and @xmath , where @xmath from Definition 2.4.3 equals @xmath .

### 2.5 Weak star operations on heaps for fully commutative elements

We conclude this chapter with a few observations regarding heaps and
weak star reductions. Let @xmath be a reduced expression for @xmath .
Then @xmath is left weak star reducible by @xmath with respect to @xmath
if and only if

1.  [label=(0)]

2.  there is an entry in @xmath labeled by @xmath that is not covered by
    any other entry;

and

1.  [label=(0), resume]

2.  the heap @xmath contains one of the convex subheaps of Lemma 2.4.1 .

Of course, we have an analogous statement for right weak star
reducibility.

###### Example 2.5.1.

Let @xmath be a reduced expression for @xmath . Then

  -- -- --
        
  -- -- --

and we see that @xmath is only left weak star reducible by @xmath with
respect to @xmath and only right weak star reducible by @xmath with
respect to @xmath . That is,

  -- -- --
        
  -- -- --

and

  -- -- --
        
  -- -- --

All other weak star reductions on @xmath are undefined.

## Chapter 3 The type I and type II elements of @xmath

In this chapter, we study the combinatorics of Coxeter groups of types
@xmath and @xmath . Our immediate goal is to define two classes of fully
commutative elements of @xmath that play a central role in the remainder
of this thesis. Some of these elements will turn out to be on our list
of irreducible elements which appears in Chapter 5 .

### 3.1 The type I elements

###### Definition 3.1.1.

Define the following elements of @xmath .

1.  [label=(0)]

2.  If @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

    and

      -- -------- --
         @xmath   
      -- -------- --

    We also let @xmath .

3.  If @xmath and @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

4.  If @xmath and @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

5.  If @xmath and @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

6.  If @xmath and @xmath , let

      -- -------- --
         @xmath   
      -- -------- --

We will refer to the elements in (1)–(5) as the type I elements.

###### Remark 3.1.2.

The heaps (which motivated the notation above) corresponding to the type
I elements are as follows.

1.  [label=(0)]

2.  If @xmath , then

      -- -- --
            
      -- -- --

3.  If @xmath and @xmath , then

      -- -- --
            
      -- -- --

    where we encounter an entry labeled by either @xmath or @xmath a
    combined total of @xmath times if @xmath and @xmath times if @xmath
    .

4.  If @xmath and @xmath , then

      -- -- --
            
      -- -- --

    where we encounter an entry labeled by either @xmath or @xmath a
    combined total of @xmath times if @xmath and @xmath times if @xmath
    .

5.  If @xmath and @xmath , then

      -- -- --
            
      -- -- --

    where we encounter an entry labeled by either @xmath or @xmath a
    combined total of @xmath times if @xmath and @xmath times if @xmath
    .

6.  If @xmath and @xmath , then

      -- -- --
            
      -- -- --

    where we encounter an entry labeled by either @xmath or @xmath a
    combined total of @xmath times if @xmath and @xmath times if @xmath
    .

###### Remark 3.1.3.

We gather a few remarks about the type I elements.

1.  [label=(0)]

2.  Every type I element is rigid, in the sense that each has a unique
    reduced expression. This implies that every type I element is fully
    commutative (there are no relations of any kind to apply).

3.  The index @xmath (respectively, @xmath ) tells us which generator is
    in the left (respectively, right) descent set. These are the unique
    elements occurring in the left and right descent sets since each
    element is rigid. The @xmath (respectively, @xmath ) in the notation
    means that we begin multiplying @xmath by @xmath (respectively,
    @xmath ). Also, @xmath (respectively, @xmath ) indicates the number
    of times we should encounter an end generator (i.e., @xmath or
    @xmath ) after the first occurrence of @xmath as we zigzag through
    the generators. If @xmath is an end generator, it is not included in
    this count. However, if @xmath is an end generator, it is included.

4.  It is clear from looking at the heaps for the type I elements that
    if @xmath is of type I, then @xmath (see Definition 2.4.3 ).
    Conversely, it follows by induction on @xmath that if @xmath for
    some @xmath , then @xmath must be of type I.

5.  Lastly, note that there is an infinite number of type I elements
    (there is no limit to the zigzagging that the heaps of the type I
    elements can do).

###### Example 3.1.4.

Consider @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -- --
        
  -- -- --

Also, we have

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -- --
        
  -- -- --

The next proposition follows immediately from the discussion above.

###### Proposition 3.1.5.

If @xmath is of type I, then @xmath is fully commutative with @xmath .
Conversely, if @xmath , then @xmath is one of the elements on the list
in Definition 3.1.1 . @xmath

###### Remark 3.1.6.

It is easily seen that if @xmath is of type I beginning (respectively,
ending) with @xmath , then @xmath is left (respectively, right) weak
star reducible by @xmath if and only if @xmath . That is, @xmath ,
@xmath , @xmath , and @xmath are the only type I elements that are
irreducible. We will see these elements appearing on our list of
irreducible elements in Chapter 5 .

### 3.2 The type II elements

It will be helpful for us to define @xmath . Then regardless of whether
@xmath is odd or even, @xmath will always be the largest even number in
@xmath . Similarly, @xmath will always be the largest odd number in
@xmath .

###### Definition 3.2.1.

Define @xmath and @xmath . Note that @xmath consists of all of the odd
indices and @xmath consists of all of the even indices amongst @xmath .

1.  [label=(0)]

2.  Let @xmath and @xmath be of the same parity with @xmath . Then we
    define

      -- -------- --
         @xmath   
      -- -------- --

    Also, define

      -- -------- --
         @xmath   
      -- -------- --

    and

      -- -------- --
         @xmath   
      -- -------- --

3.  Let @xmath . Define

      -- -------- --
         @xmath   
      -- -------- --

We will refer to finite alternating products of @xmath and @xmath as
type II elements. That is, the type II elements are

1.  [label=(0)]

2.  @xmath ;

3.  @xmath ;

4.  @xmath ;

5.  @xmath ;

6.  @xmath ;

7.  @xmath .

Note that @xmath and @xmath are products of commuting generators, and so
the order of the multiplication is immaterial. The heaps corresponding
to the type II elements are as follows.

1.  [label=(0)]

2.  @xmath

3.  @xmath

4.  If @xmath is even, then

      -- -- --
            
      -- -- --

    If @xmath is odd, then

      -- -- --
            
      -- -- --

    In each case, the canonical representation of @xmath has @xmath
    rows.

5.  If @xmath is even, then

      -- -- --
            
      -- -- --

    If @xmath is odd, then

      -- -- --
            
      -- -- --

    In each case, the canonical representation of @xmath has @xmath
    rows.

6.  If @xmath is even, then

      -- -- --
            
      -- -- --

    If @xmath is odd, then

      -- -- --
            
      -- -- --

    In each case, the canonical representation of @xmath has @xmath
    rows.

7.  If @xmath is even, then

      -- -- --
            
      -- -- --

    If @xmath is odd, then

      -- -- --
            
      -- -- --

    In each case, the canonical representation of @xmath has @xmath
    rows.

The next proposition follows immediately from looking at the heaps
above.

###### Proposition 3.2.2.

If @xmath is of type II, then @xmath is fully commutative with @xmath .

@xmath

###### Remark 3.2.3.

It is easily seen by inspecting the heaps for the type II elements that
if @xmath is of type II, then @xmath is irreducible. We will see these
elements appearing on our list of irreducible elements in the next
chapter.

Note that if @xmath , then @xmath is the maximum value that @xmath can
take. There are fully commutative elements with @xmath that are not of
type II. For example, if @xmath , then @xmath , but @xmath is not of
type II. Note, however, that there is an infinite number of type II
elements.

In [ 12 ] , Green proved that when @xmath is odd, @xmath is a star
reducible Coxeter group. Note that if @xmath is even, then every @xmath
from (5) above is not star reducible. This fact is implicit in [ 12 ]
and is easily verified. We conjecture that these elements are the only
non-star reducible elements in @xmath (with @xmath even) other than
products of commuting generators. This conjecture will be a topic of
future research.

## Chapter 4 Classification of the weak star irreducible elements in
@xmath

The goal of this chapter is to classify the irreducible elements of
@xmath . We will use this classification to prove the classification of
the irreducible elements of @xmath , which plays a pivotal role in the
proof of our main result in the final chapter.

### 4.1 Statement of theorem

As mentioned in Chapter 1, our definition of weak star reducible is
related to Fan’s notion of cancellable in [ 5 ] . In addition, the next
theorem verifies Fan’s unproved claim in [ 5 , §7.1] about the set of
@xmath having no element of @xmath or @xmath that can be left or right
cancelled, respectively.

###### Theorem 4.1.1.

Let @xmath . Then @xmath is irreducible if and only if @xmath is equal
to one of the elements on the following list.

1.   [label= ()]

2.  @xmath ;

3.  @xmath , where @xmath ;

4.  @xmath , where @xmath ;

where in each case @xmath is equal to a product of commuting generators
in @xmath .

We have an analogous statement for @xmath , where @xmath and @xmath are
replaced with @xmath and @xmath , respectively.

To prove this theorem, we require several lemmas.

### 4.2 Preparatory lemmas

In this section, we state and prove several technical lemmas that will
be used to prove Theorem 4.1.1 . A few of these lemmas will also be
useful in later chapters. Note that all statements about @xmath also
apply to @xmath and @xmath .

All of the results in this section are new.

Before proceeding, we make a comment on notation. Let @xmath . When
representing saturated and convex subheaps of @xmath , we will use the
symbol @xmath to emphasize the absence of an entry in this location in
@xmath . It is important to note that the occurrence of the symbol
@xmath implies that an entry from @xmath cannot be shifted vertically
from above or below to occupy the location of the symbol @xmath .

###### Example 4.2.1.

In the following heap, the region enclosed by the dotted line and
labeled with @xmath indicates that no entry of the heap may occupy this
region.

[]

In this example, if the heap is a saturated subheap of some larger heap,
then the subheap is convex.

###### Lemma 4.2.2.

Let @xmath . Suppose that @xmath has a reduced expression having one of
the following fully commutative elements as a subword:

1.   [label= ()]

2.  @xmath ,

3.  @xmath ,

4.  @xmath ,

5.  @xmath .

Then @xmath is of type I.

###### Proof.

First, we prove (i); (ii) follows by a symmetric argument. Assume that
@xmath is a subword of @xmath . Then

[]

is a convex subheap of @xmath . Since @xmath is a subword of @xmath , we
can write @xmath (reduced). If @xmath and @xmath are empty, we are done.
Without loss of generality, assume that @xmath is nonempty. If the
higher occurrence of @xmath in the heap for @xmath is covered by an
entry in the heap for @xmath labeled by @xmath , we would obtain one of
the impermissible convex chains of Lemma 2.4.1 , which would contradict
@xmath . This implies that the entry in the heap for @xmath labeled by
@xmath may only be covered by the entry labeled by @xmath . Iterating,
we see that each entry in the heap for @xmath labeled by @xmath , for
@xmath , may only be covered by an entry labeled by @xmath . Then

[]

must be a convex subheap of @xmath for some @xmath , where each of the
entries labeled by the same generator are consecutive occurrences.
Choose the largest such @xmath . By repeating similar arguments, we
quickly see that @xmath must be of type I; otherwise, at some point, we
contradict @xmath . A similar argument shows that @xmath must also be of
type I. Therefore, @xmath is of type I.

Now, we prove (iii); (iv) follows by a symmetric argument. Assume that
@xmath is a subword of @xmath . Then

[]

is a convex subheap of @xmath , where each of the entries labeled by the
same generator are consecutive occurrences. We can write @xmath
(reduced). If @xmath and @xmath are empty, there is nothing to prove.
Without loss of generality, assume that @xmath is nonempty. An argument
identical to the above shows that the higher occurrence of the entry in
the heap for @xmath labeled by @xmath , for @xmath , can only be covered
by @xmath . Since @xmath is nonempty, the higher occurrence of the entry
in the heap for @xmath labeled by @xmath must be covered by an entry in
the heap of @xmath labeled by @xmath . But this implies that

[]

is a convex subheap of @xmath . So, @xmath is a subword of @xmath . In
particular, @xmath is then a subword of @xmath . By case (i), @xmath
must be of type I. ∎

The purpose of the next three lemmas (Lemmas 4.2.3 , 4.2.5 , and 4.2.6 )
is to prove Lemma 4.2.8 .

###### Lemma 4.2.3.

Let @xmath . If

[]

is a saturated subheap of @xmath , where @xmath , then

[]

is a convex subheap of @xmath , where the shaded triangle labeled by
@xmath means that every possible entry occurs in this region (i.e.,
convex closure) of the subheap.

###### Proof.

This follows quickly from Lemma 2.4.1 ; all other configurations will
violate @xmath being fully commutative. ∎

###### Example 4.2.4.

Let @xmath for @xmath , so that @xmath . If

[]

is a saturated subheap of @xmath , then

[]

is also a saturated subheap of @xmath and

  -- -------- --
     @xmath   
  -- -------- --

is a subword of some reduced expression for @xmath .

###### Lemma 4.2.5.

Let @xmath . Suppose that there exists @xmath with @xmath such that
@xmath does not occur between two consecutive occurrences of @xmath in
@xmath . Then @xmath is a subword of some reduced expression for @xmath
. In terms of heaps, if @xmath has two consecutive occurrences of
entries labeled by @xmath such that there is no entry labeled by @xmath
occurring between them, then

[]

is a convex subheap of @xmath .

###### Proof.

We proceed by induction on @xmath . For the base case, let @xmath and
suppose that there exist two consecutive occurrences of @xmath such that
@xmath does not occur between them. Then

[]

must be a convex subheap of @xmath , which implies that @xmath is a
subword of @xmath , as desired. For the inductive step, assume that for
@xmath , whenever the hypotheses are met for @xmath , @xmath is a
subword of @xmath . Now, assume that hypotheses are true for @xmath .
Consider the entries in @xmath corresponding to the two consecutive
occurrences of @xmath . Since there is no entry labeled by @xmath
occurring between these entries and @xmath is fully commutative, there
must be at least two entries labeled by @xmath occurring between the
consecutive occurrences of @xmath . For sake of a contradiction, assume
that there are three or more entries in @xmath labeled by @xmath
occurring between the minimal pair of entries labeled by @xmath . By
induction (on @xmath ),

[]

is a saturated subheap of @xmath . But by Lemma 4.2.3 , the convex
closure of the saturated subheap occurring between the top two
occurrences of @xmath must be completely filled in. This produces a
convex chain that corresponds to the subword @xmath , which contradicts
@xmath . Therefore, between the consecutive occurrences of entries
labeled by @xmath , there must be exactly two occurrences of an entry
labeled by @xmath . That is, by induction,

[]

is a convex subheap of @xmath and hence @xmath is a subword of some
reduced expression for @xmath . ∎

###### Lemma 4.2.6.

Let @xmath such that @xmath is a subword of some reduced expression for
@xmath and let @xmath be the largest index such that

[]

is a saturated subheap of @xmath . Then one or both of the following
must be true about @xmath :

1.   [label= ()]

2.  @xmath is of type I;

3.  the following subheap is the northwest corner of @xmath .

    []

    In particular, the entry labeled by @xmath in the heap above is not
    covered.

###### Proof.

The higher entry labeled by @xmath cannot be covered by an entry labeled
by @xmath ; otherwise, we produce one of the impermissible
configurations of Lemma 2.4.1 and violate @xmath being fully
commutative. Then the entry labeled by @xmath cannot be covered by an
entry labeled by @xmath ; again, we would contradict Lemma 2.4.1 .
Iterating, we see that each entry on the diagonal of the subheap labeled
by @xmath , for @xmath , can only be covered by an entry labeled by
@xmath . If @xmath , we are done since the entry labeled by @xmath
cannot be covered by an entry labeled by @xmath . Assume that @xmath .
If the entry labeled by @xmath at the top of the diagonal in the subheap
is covered by an entry labeled by @xmath , then by Lemma 4.2.2 , @xmath
is of type I. If the entry labeled by @xmath is not covered, then we are
done, as well. ∎

###### Remark 4.2.7.

The previous lemma has versions corresponding to the southwest,
northeast, and southeast corners of @xmath .

As stated above, the purpose of the previous three lemmas was to aid in
the proof of the next important lemma.

###### Lemma 4.2.8.

Let @xmath . Suppose that there exists @xmath with @xmath such that
@xmath does not occur between two consecutive occurrences of @xmath in
@xmath . Then one or both of the following must be true about @xmath :

1.   [label= ()]

2.  @xmath is of type I;

3.  @xmath is of the form

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath .

In terms of heaps, if @xmath has two consecutive occurrences of entries
labeled by @xmath such that there is no entry labeled by @xmath
occurring between them, then either @xmath is of type I or

[]

is a convex subheap of @xmath and there are no other occurrences of
entries labeled by @xmath in @xmath .

###### Proof.

Choose the largest index @xmath with @xmath such that @xmath does not
occur between two consecutive occurrences of @xmath in @xmath . By Lemma
4.2.5 , @xmath is a subword of some reduced expression for @xmath and

[]

is a convex subheap of @xmath . Let @xmath be largest index with @xmath
such that each entry labeled by @xmath on the upper diagonal in the
above subheap covers an entry labeled by @xmath for @xmath . Similarly,
let @xmath be the largest index with @xmath such that each entry on the
lower diagonal in the above subheap labeled by @xmath is covered by an
entry labeled by @xmath for @xmath . Then

[]

is a convex subheap of @xmath . By the northwest and southwest versions
of Lemma 4.2.6 ,

[]

must be a convex subheap of @xmath . If neither of @xmath or @xmath are
equal to @xmath , then we are done since the entry labeled by @xmath
(respectively, @xmath ) cannot be covered by (respectively, cover) an
entry labeled by @xmath (respectively, @xmath ); otherwise, we
contradict @xmath . Assume that @xmath ; the case @xmath follows by a
symmetric argument. If the entry labeled by @xmath is covered, it must
be covered by an entry labeled by @xmath . But by Lemma 4.2.2 , @xmath
would then be of type I. ∎

###### Remark 4.2.9.

Note that all of the previous lemmas of this section have analogous
statements where @xmath and @xmath are replaced with @xmath and @xmath ,
respectively.

The next three lemmas are generalizations of Lemma 5.3 in [ 12 ] . In
both of these lemmas, we assume that @xmath is irreducible.

###### Lemma 4.2.10.

Let @xmath for @xmath and suppose that @xmath is irreducible and not of
type I. Consider the canonical representation of @xmath . If @xmath with
@xmath , then the entry labeled by @xmath is covered by entries labeled
by @xmath and @xmath , where at least one of these occurs in @xmath .

###### Proof.

We proceed by induction on @xmath . For the base case, assume that
@xmath , so that @xmath . Then this entry is covered by at least one of
@xmath or @xmath . Note that our restrictions on @xmath and @xmath force
@xmath . This implies that both @xmath and @xmath occur in @xmath ;
otherwise, @xmath is left weak star reducible. For the inductive step,
assume that the theorem is true for @xmath for some @xmath . Now,
suppose that @xmath with @xmath . Then at least one of @xmath or @xmath
occur in @xmath . We consider two cases: (1) @xmath and (2) @xmath .

Case (1): Assume that @xmath . Observe that this forces @xmath . Without
loss of generality, assume that @xmath . The case with @xmath is
symmetric since the restrictions on @xmath imply that we may apply the
induction hypothesis to either @xmath or @xmath . By induction, the
entry labeled by @xmath occurring in @xmath is covered by an entry
labeled by @xmath and an entry labeled by @xmath . This implies that the
entry labeled by @xmath occurring in @xmath must be covered by an entry
labeled by @xmath ; otherwise, we produce a convex chain corresponding
to the subword @xmath . This yields our desired result.

Case (2): For the second case, assume that @xmath . Without loss of
generality, assume that @xmath , the other case being similar. Then
@xmath . This entry is covered by either (a) an entry labeled by @xmath
, (b) an entry labeled by @xmath , or (c) both. If we are in situation
(c), then we are done. For sake of a contradiction, assume that exactly
one of (a) or (b) occurs.

First, assume that (a) occurs, but (b) does not. That is, an entry
labeled by @xmath covers the entry labeled by @xmath that occurs in
@xmath . Meanwhile, the entry labeled by @xmath that occurs in @xmath is
not covered by an entry labeled by @xmath . This implies that @xmath .
Since @xmath , the entry labeled by @xmath occurring in @xmath is
covered by at least one of @xmath or @xmath . Since @xmath is fully
commutative, the entry labeled by @xmath occurring in @xmath cannot be
covered by an entry labeled by @xmath . Thus, @xmath .

For sake of a contradiction, assume that @xmath , so that @xmath is not
the top row of the canonical representation for @xmath . Then we must
have @xmath . Since @xmath is not left weak star reducible, we cannot
have @xmath ; otherwise, @xmath is left weak star reducible by @xmath
with respect to @xmath . So, @xmath , which implies that the entry
labeled by @xmath occurring in @xmath is covered. This entry cannot be
covered by @xmath since @xmath is fully commutative. Therefore, we have
@xmath . But by induction, this entry is covered by an entry labeled by
@xmath and an entry labeled by @xmath . But this produces a convex chain
that corresponds to the subword @xmath , which contradicts @xmath being
fully commutative. We have just shown that @xmath .

Thus far, we have @xmath , @xmath , and @xmath , while @xmath does not
cover the entry labeled by @xmath occurring in @xmath and @xmath does
not cover the entry labeled by @xmath occurring in @xmath . Since @xmath
is not left weak star reducible, @xmath . Since @xmath is not right weak
star reducible, the entry labeled by @xmath occurring in @xmath must
cover an entry. However, since @xmath is fully commutative, we cannot
have @xmath , and so, we must have @xmath . Continuing with similar
reasoning, we see that

[]

is a saturated subheap of @xmath , where @xmath occurs in @xmath .

For sake of a contradiction, assume that the occurrence of @xmath in
@xmath is covered by an entry labeled by @xmath . In this case, the
occurrence of @xmath cannot cover any other entry, namely one labeled by
@xmath , since @xmath is fully commutative; otherwise, we produce a
convex chain that corresponds to the subword @xmath . But then @xmath is
right weak star reducible by @xmath with respect to @xmath , which
contradicts @xmath being irreducible. Therefore, the entry labeled by
@xmath occurring in @xmath is only covered by the entry labeled by
@xmath occurring in @xmath .

Since @xmath is fully commutative and we must avoid the convex chains of
Lemma 2.4.1 , we can quickly conclude that

[]

is the top @xmath rows of the canonical representation of @xmath . Since
@xmath is not of type I, this cannot be all of @xmath . The only
possibility is that @xmath . Since @xmath is not right weak star
reducible, this cannot be all of @xmath either. So, at least one of
@xmath or @xmath occur in @xmath . We cannot have @xmath because @xmath
is fully commutative. Thus, @xmath while @xmath is not. Again, since
@xmath is not right weak star reducible, we must have @xmath while
@xmath . Continuing with similar reasoning, we quickly see that

[]

is a convex subheap of @xmath . But then by Lemma 4.2.2 , @xmath is of
type I, which is a contradiction. Therefore, we cannot have possibility
(a) occurring while (b) does not.

The only remaining possibility is that (b) occurs, but (a) does not.
That is, @xmath and @xmath , while the entry labeled by @xmath occurring
in @xmath is not covered by an entry labeled by @xmath . Observe that
the case @xmath is covered by an argument that is symmetric to the
argument made above when we assumed that (a) occurs, but (b) does not,
where we take @xmath instead of @xmath . So, assume that @xmath . Then
by induction, we must have the entry labeled by @xmath occurring in
@xmath covered by an entry labeled by @xmath (and by an entry labeled by
@xmath ). But then we produce a convex chain corresponding to the
subword @xmath , which contradicts @xmath being fully commutative.
Therefore, if @xmath , then the entry labeled by @xmath occurring in
@xmath is covered by an entry labeled by @xmath and by an entry labeled
by @xmath , as desired.

We have exhausted all possibilities, and hence we have our desired
result. ∎

###### Lemma 4.2.11.

Let @xmath and suppose that @xmath is irreducible and not of type I.
Consider the canonical representation of @xmath . Then

1.   [label= ()]

2.  if @xmath is covered by an entry labeled by @xmath , then an entry
    labeled by @xmath covers the entry labeled by @xmath ;

3.  if @xmath is covered by an entry labeled by @xmath , then an entry
    labeled by @xmath covers the entry labeled by @xmath .

###### Proof.

We prove (i); (ii) follows by a symmetric argument. Note that since
@xmath , @xmath and @xmath . If @xmath , then @xmath and @xmath . This
implies that @xmath must occur in @xmath , otherwise, @xmath is left
weak star reducible by @xmath with respect to @xmath . So, assume that
@xmath . For sake of a contradiction, assume that the entry labeled by
@xmath occurring in @xmath is not covered by an entry labeled by @xmath
. This forces @xmath . Then at least one of @xmath or @xmath must cover
the entry labeled by @xmath occurring in @xmath . Since @xmath does not
cover the occurrence of @xmath and @xmath is fully commutative, it must
be the case that @xmath , while the entries labeled by @xmath and @xmath
occurring in @xmath and @xmath , respectively, are not covered by
entries labeled by @xmath and @xmath , respectively. Then

[]

is a convex subheap of @xmath . We consider two cases: (1) @xmath and
(2) @xmath .

Case (1): First, assume that @xmath , so that @xmath , @xmath , @xmath ,
and neither @xmath nor @xmath occur in @xmath or @xmath . Then the
subheap immediately above is the northwest corner of @xmath , where the
entry labeled by @xmath occurs in the top row. We are assuming that
@xmath is not of type I, so this cannot be all of @xmath . We cannot
have @xmath ; otherwise, @xmath would be left weak star reducible by
@xmath with respect to @xmath . The entry labeled by @xmath occurring in
@xmath must cover at least one entry labeled by @xmath or @xmath in
@xmath . But it cannot be an entry labeled by @xmath since we would
produce a convex chain corresponding to the subword @xmath . This
implies that

[]

is the top of @xmath . This cannot be all of @xmath since we are
assuming that @xmath is not of type I. So, we must have @xmath . Note
that this must be all of @xmath . Again, this cannot be all of @xmath .
So, we must have @xmath or @xmath occurring in @xmath . Since @xmath is
fully commutative, we cannot have @xmath occurring in @xmath , and so
@xmath . Yet again, this cannot be all of @xmath . At least one of
@xmath or @xmath must occur in @xmath , but it cannot be @xmath ;
otherwise, we produce a convex chain corresponding to the subword @xmath
. Therefore, the convex subheap

[]

is the top of @xmath . But then by Lemma 4.2.2 , @xmath must be of type
I, which is a contradiction. This completes the case @xmath .

Case (2): Now, assume that @xmath . Recall that we are assuming that
@xmath , but that the entries labeled by @xmath and @xmath occurring in
@xmath and @xmath , respectively, are not covered by entries labeled by
@xmath and @xmath , respectively. Then the entry in @xmath labeled by
@xmath must be covered by an entry labeled by @xmath . This implies that
@xmath cannot occur in @xmath since @xmath is fully commutative. Then

[]

is a convex subheap of @xmath . This cannot be all of @xmath since
@xmath would then be left weak star reducible by @xmath with respect to
@xmath . So, the entry labeled by @xmath in @xmath must be covered by an
entry labeled by @xmath (this entry cannot be covered by an entry
labeled by @xmath since @xmath is fully commutative). Again, since
@xmath is fully commutative, but not left weak star reducible, the entry
labeled by @xmath occurring in @xmath must be covered by an entry
labeled by @xmath . This implies that

[]

is a convex subheap of @xmath . Since @xmath is not of type I, this
cannot be all of @xmath . Since @xmath is fully commutative, the only
two possibilities are: (a) the entry labeled by @xmath in @xmath is
covered by an entry labeled by @xmath and (b) the entry labeled by
@xmath in @xmath covers an entry labeled by @xmath . In either case,
@xmath is of type I by Lemma 4.2.2 , which is a contradiction.

We have exhausted all possibilities. Therefore, it must be the case that
the entry labeled by @xmath is covered by an entry labeled by @xmath ,
as desired. ∎

The next lemma is similar to the previous, except that we assume that
@xmath . We have separated these two lemmas because their proofs are
different.

###### Lemma 4.2.12.

Let @xmath for @xmath and suppose that @xmath is irreducible and not of
type I. Consider the canonical representation of @xmath . Then

1.   [label= ()]

2.  if @xmath is covered by an entry labeled by @xmath , then an entry
    labeled by @xmath covers the entry labeled by @xmath ;

3.  if @xmath is covered by an entry labeled by @xmath , then an entry
    labeled by @xmath covers the entry labeled by @xmath .

###### Proof.

We prove (i); (ii) follows by a symmetric argument. Note that since
@xmath , @xmath . As in the proof of the previous lemma, if @xmath ,
then @xmath and @xmath . This implies that @xmath must occur in @xmath ,
otherwise, @xmath is left weak star reducible by @xmath with respect to
@xmath . Now, assume that @xmath , so that @xmath and this entry is
covered by an entry labeled by @xmath . Then by Lemma 4.2.10 , entries
labeled by @xmath and @xmath cover the entry labeled by @xmath occurring
in @xmath . Since @xmath is fully commutative, we must have the entry
labeled by @xmath occurring in @xmath covered by an entry labeled by
@xmath , as desired; otherwise, we produce one of the impermissible
configurations of Lemma 2.4.1 and violate @xmath being fully
commutative. ∎

###### Remark 4.2.13.

Lemmas 4.2.10 , 4.2.11 , and 4.2.12 all have “upside-down” versions,
where we replace @xmath with @xmath and we swap the phrases “is covered
by” and “covers.”

### 4.3 Proof of the classification of the irreducible elements in
@xmath

Finally, we are ready to prove the classification of the irreducible
elements in @xmath .

Proof of Theorem 4.1.1 . First, observe that if @xmath is irreducible in
@xmath for @xmath , then @xmath is also irreducible in @xmath when
considered as an element of the larger group. Also, we see that every
element on our list is, in fact, irreducible. It remains to show that
our list is complete. We induct on @xmath .

For the base case, consider @xmath . An exhaustive check verifies that
the only irreducible elements in @xmath are @xmath , @xmath , @xmath ,
and @xmath , which agrees with the statement of the theorem.

For the inductive step, assume that for all @xmath , our list is
complete. Let @xmath and assume that @xmath is irreducible. For sake of
a contradiction, assume that @xmath is not on our list. First, we argue
that @xmath must be all of @xmath . Suppose that there exists @xmath .
Say @xmath . Then we can factorize @xmath as @xmath (reduced), where
@xmath and @xmath . Note that since @xmath is irreducible, both @xmath
and @xmath are irreducible, as well. In particular, @xmath is
irreducible in @xmath . By induction, @xmath is on our list. Since no
generator occurring in @xmath involves a bond of strength 4, all weak
star reductions are equivalent to ordinary star reductions. Then by [ 12
, Theorem 6.3] , @xmath is equal to a product of commuting generators
(where we consider @xmath as an element of a type @xmath Coxeter group).
Since @xmath , @xmath must already be on our list, which contradicts our
assumption that it is not. So, we must have @xmath . In particular,
@xmath and @xmath occur in @xmath .

Next, we argue that there can only be a single occurrence of @xmath .
For sake of a contradiction, assume that there are at least two
occurrences of @xmath in any reduced expression for @xmath . Consider
any two consecutive occurrences of @xmath in the canonical
representation of @xmath . Since there is no generator @xmath , we can
apply Lemma 4.2.8 and conclude that

[]

is a convex subheap of @xmath and there are no other occurrences of
entries labeled by @xmath in @xmath . But then the heap above must be
all of @xmath . We see that @xmath is left weak star reducible by @xmath
with respect to @xmath , which contradicts @xmath being irreducible.
Thus, there must be a single occurrence of @xmath in any reduced
expression for @xmath .

Assume that the canonical representation for @xmath has @xmath rows and
suppose that the unique occurrence of @xmath is in @xmath . At this
point, we will consider three cases: (1) @xmath , (2) @xmath , and (3)
@xmath .

Case (1): First, assume that @xmath , so that @xmath . Since @xmath ,
the entry labeled by @xmath must cover an entry labeled by @xmath . But
since there is no generator @xmath available, we contradict the
upside-down version of Lemma 4.2.11 if @xmath and Lemma 4.2.12 if @xmath
.

Case (2): For the second case, assume that @xmath , so that @xmath .
Then we must have @xmath . But this implies that @xmath is left weak
star reducible by @xmath with respect to @xmath , which contradicts
@xmath being irreducible.

Case (3): For the final case, assume that @xmath . For this case, we
consider two separate subcases: (a) @xmath and (b) @xmath .

(a): Suppose that @xmath . In this case, there is a unique entry of
@xmath labeled by @xmath , which occurs in @xmath for @xmath . Then we
must have @xmath . Then @xmath since this is the only generator that is
available to cover an entry labeled by @xmath . By the upside-down
version of Lemma 4.2.11 , the entry labeled by @xmath occurring in
@xmath must cover an entry labeled by @xmath . Then

[]

is a convex subheap of @xmath , where we remind the reader that there is
a unique occurrence of an entry in @xmath labeled by @xmath . Since
@xmath is fully commutative, we cannot have the higher occurrence of
@xmath above covered an entry labeled by @xmath ; otherwise, we violate
@xmath being fully commutative. But then @xmath is left weak star
reducible by @xmath with respect to @xmath , which contradicts @xmath
being irreducible. That is, if @xmath , our list is complete.

(b): Now, suppose that @xmath . We have @xmath with @xmath and @xmath .
Then @xmath . By Lemma 4.2.10 , we must have the entry labeled by @xmath
occurring in @xmath covered by both an entry labeled by @xmath and an
entry labeled by @xmath . But this contradicts @xmath having a unique
occurrence of @xmath . Thus, if @xmath , our list is complete.

Therefore, there are no irreducible elements in @xmath with support
equal to all of @xmath , and so our list must be complete.

@xmath

## Chapter 5 Classification of the weak star irreducible elements in
@xmath

The goal of this chapter is to classify the irreducible elements of
@xmath .

### 5.1 Statement of theorem

The following theorem is a new result.

###### Theorem 5.1.1.

Let @xmath . Then @xmath is irreducible if and only if @xmath is equal
to one of the elements on the following list.

1.   [label= ()]

2.  @xmath , where @xmath is a type @xmath irreducible element and
    @xmath is a type @xmath irreducible element with @xmath ;

3.  @xmath , @xmath , @xmath , and @xmath ;

4.  Any type II element.

###### Remark 5.1.2.

The elements listed in (i) include all possible products of commuting
generators. This includes @xmath and @xmath , which are also included in
(iii). The elements listed in (ii) are the type I elements with left and
right descent sets equal to either @xmath or @xmath .

As with the proof of the classification of the irreducible elements of
@xmath , we require a few lemmas.

### 5.2 More preparatory lemmas

In this section, we state and prove a few more technical lemmas that
will be used to prove Theorem 5.1.1 . Note that all statements about
@xmath also apply to @xmath and @xmath . Also, recall that if @xmath ,
then @xmath is the @xmath th row of the canonical representation of
@xmath .

###### Lemma 5.2.1.

Let @xmath and suppose that @xmath is irreducible. Consider the
canonical representation of @xmath . If @xmath is not of type I, then
@xmath (respectively @xmath ) implies @xmath (respectively @xmath ).

###### Proof.

Note that when @xmath , we have @xmath and @xmath . If @xmath , then it
is clear that @xmath . Now, assume that @xmath . Then at least one of
@xmath or @xmath occurs in @xmath . For sake of a contradiction, assume
that only one of these occurs in @xmath , and without loss of
generality, assume that @xmath while @xmath (this makes sense since
@xmath ). We consider two cases: (1) @xmath and (2) @xmath .

Case (1): First, assume that @xmath , so that @xmath and @xmath , while
@xmath . This cannot be all of @xmath since @xmath is not of type I. So,
the occurrence of @xmath in @xmath must cover an entry labeled by either
@xmath or @xmath . Since @xmath is not left weak star reducible, we
cannot have the occurrence of @xmath in @xmath covering an entry labeled
by @xmath . So, we must have @xmath . Thus far, the top three rows of
the canonical representation for @xmath are as follows.

[]

Since @xmath is not of type I, this cannot be all of @xmath . Then
@xmath . Again, this cannot be all of @xmath since @xmath is not of type
I. So, we must have at least one of @xmath or @xmath occurring in @xmath
. However, since @xmath is fully commutative, @xmath , and so @xmath .
But then the top five rows of the canonical representation for @xmath
are as follows.

[]

According to Lemma 4.2.2 , @xmath is of type I, which is a
contradiction.

Case (2): For the second case, assume that @xmath . Then we must have
@xmath . Since @xmath is not left weak star reducible, we cannot have
@xmath ; otherwise, @xmath is left weak star reducible by @xmath with
respect to @xmath . Thus, @xmath , and hence at least one of @xmath or
@xmath occurs in @xmath . Since @xmath is fully commutative, we cannot
have @xmath , and so, @xmath . Thus far,

[]

is a convex subheap of @xmath . This cannot be all of @xmath since
@xmath is not of type I. The only possibilities are that @xmath or
@xmath (both possibilities could occur simultaneously). In either case,
@xmath must be of type I by Lemma 4.2.2 , which is a contradiction.

Therefore, @xmath (respectively @xmath ) implies @xmath (respectively
@xmath ). ∎

The next lemma is of a similar flavor as the previous, except here we
take @xmath . Also, observe that it is unnecessary to require @xmath to
not be of type I.

###### Lemma 5.2.2.

Let @xmath and suppose that @xmath is irreducible. Consider the
canonical representation of @xmath . Then @xmath (respectively @xmath )
implies @xmath (respectively @xmath ).

###### Proof.

Note that when @xmath , we have @xmath and @xmath . Assume that @xmath ;
the proof of the other case is similar. Then we must have @xmath since
this is the only generator available to cover @xmath . By Lemma 4.2.11 ,
the entry labeled by @xmath must be covered by an entry labeled by
@xmath . If @xmath , then @xmath , as desired. Assume that @xmath . Then
at least one of @xmath or @xmath occurs in @xmath . For sake of a
contradiction assume that @xmath , but @xmath . If @xmath , then @xmath
would be left weak star reducible by @xmath with respect to @xmath . So,
we must have @xmath , in which case, @xmath . But then we have a convex
chain corresponding to the subword @xmath , which contradicts @xmath
being fully commutative. Thus, @xmath . If @xmath , then the entry
labeled by @xmath that covers @xmath must occur in @xmath . So, @xmath ,
as desired. ∎

###### Lemma 5.2.3.

Let @xmath and suppose that @xmath is irreducible with @xmath . Consider
the canonical representation of @xmath . Then @xmath (respectively
@xmath ) implies @xmath (respectively @xmath ).

###### Proof.

Note that when @xmath , we have @xmath and @xmath . We consider two
cases: (1) @xmath and (2) @xmath .

Case (1): First, assume that @xmath . By Lemma 4.2.10 , the entry
labeled by @xmath is covered by labeled by @xmath and @xmath , where at
least one of these occurs in @xmath . Since @xmath (respectively, @xmath
) is the only generator that may cover an entry labeled by @xmath
(respectively, @xmath ), we must have both @xmath and @xmath occurring
in @xmath , as desired.

Case (2): Now, assume that @xmath . First, we argue that an entry
labeled by @xmath covers the occurrences of @xmath and @xmath in @xmath
. For sake of a contradiction, assume otherwise. Then we must have
@xmath and @xmath both occurring in @xmath .

Assume that @xmath , so that @xmath and @xmath . We cannot have @xmath
(respectively, @xmath ) occurring in @xmath ; otherwise @xmath would be
left weak star reducible by @xmath (respectively @xmath ) with respect
to @xmath (respectively, @xmath ). Since @xmath , we must have @xmath .
By the upside-down version of Lemma 4.2.10 , the entry labeled by @xmath
must cover entries labeled by @xmath and @xmath . But this produces
convex chains corresponding to the subwords @xmath and @xmath , which
contradicts @xmath being fully commutative.

Now, assume that @xmath . Then we must have @xmath and @xmath occurring
in @xmath . Since @xmath is not left weak star reducible, we must have
@xmath ; otherwise, @xmath is left weak star reducible by @xmath
(respectively, @xmath ) with respect to @xmath (respectively, @xmath ).
We cannot have the entry labeled by @xmath (respectively, @xmath )
occurring in @xmath covered by @xmath (respectively, @xmath );
otherwise, we produce one of the impermissible configurations of Lemma
2.4.1 and violate @xmath being fully commutative. So, we must have
@xmath . If @xmath , then @xmath would be left weak star reducible by
@xmath with respect to either @xmath or @xmath . Thus, @xmath . By Lemma
4.2.10 , the entry labeled by @xmath is covered by entries labeled by
@xmath and @xmath . But then we produce convex chains corresponding to
@xmath and @xmath , which contradicts @xmath being fully commutative.

We have shown that if @xmath , then the entries labeled by @xmath and
@xmath occurring in @xmath must be covered by an entry labeled by @xmath
. By Lemma 4.2.12 , an entry labeled by @xmath (respectively, @xmath )
covers the entry labeled by @xmath (respectively, @xmath ) occurring in
@xmath . If @xmath , we quickly contradict Lemma 2.4.1 or Lemma 4.2.10 .
Therefore, we must have @xmath , as desired. ∎

###### Lemma 5.2.4.

Let @xmath for @xmath and suppose that @xmath is irreducible. Consider
the canonical representation of @xmath . Then @xmath (respectively
@xmath ) implies @xmath (respectively @xmath ).

###### Proof.

If @xmath , then the result follows by Lemmas 4.2.10 and 4.2.12 . If
@xmath , the result follows by making repeated applications of Lemmas
4.2.10 and 4.2.12 while avoiding the convex chains of Lemma 2.4.1 . ∎

###### Remark 5.2.5.

Lemmas 5.2.1 , 5.2.2 , 5.2.3 and 5.2.4 all have “upside-down” versions
since all of the arguments reverse nicely. That is, if @xmath is
irreducible (and not of type I when @xmath ), then @xmath (respectively,
@xmath ) implies @xmath (respectively, @xmath ).

### 5.3 Proof of the classification of the irreducible elements in
@xmath

We are now ready to prove the classification of the irreducible elements
in @xmath .

Proof of Theorem 5.1.1 . It is easily seen that every element on our
list is irreducible. For sake of a contradiction, assume that there
exists @xmath such that @xmath is irreducible, but not on our list. If
there exists @xmath , then @xmath is equal to @xmath (reduced), where
@xmath is of type @xmath and @xmath is of type @xmath and @xmath . Since
@xmath is irreducible, both @xmath and @xmath are irreducible. In this
case, @xmath must be one of the elements from (i). So, if @xmath is not
on our list, we must have @xmath . This implies that @xmath is not a
product of commuting generators. According to Proposition 3.1.5 , the
only irreducible elements with @xmath are already listed in (ii). Hence
@xmath (i.e., @xmath is not of type I).

Now, consider the canonical representation of @xmath and suppose that it
has @xmath rows. Since @xmath is not a product of commuting generators,
@xmath . We consider three main cases: (1) @xmath , (2) @xmath , and (3)
@xmath .

Case (1): Assume that @xmath . In this case, @xmath and @xmath . First,
we argue that @xmath or @xmath . If @xmath , then @xmath . Assume that
@xmath . Then at least one of @xmath or @xmath occurs in @xmath . Then
we must have @xmath . In fact, @xmath . By the upside-down version of
Lemma 5.2.1 , @xmath . We have shown that @xmath or @xmath . Now, by
repeated applications of Lemma 5.2.1 , @xmath must be equal to an
alternating product of @xmath and @xmath . This implies that @xmath is
of type II, which contradicts that @xmath is not on our list.

Case (2): For the second case, assume that @xmath . In this case, @xmath
and @xmath . As in Case (1), we wish to show that @xmath or @xmath . For
sake of a contradiction, assume that @xmath but @xmath , where @xmath .
We consider the subcases: (a) @xmath and (b) @xmath . The cases @xmath
and @xmath are similar.

(a): Suppose that @xmath , so that @xmath while @xmath . Then we must
have @xmath . Since @xmath and @xmath does not occur in @xmath or @xmath
, we must have @xmath . Then the entry labeled by @xmath occurring in
@xmath cannot be covered by an entry labeled by @xmath ; otherwise,
@xmath is right weak star reducible by @xmath with respect to @xmath .
Thus, @xmath . But according to Lemma 4.2.11 , the entry labeled by
@xmath occurring in @xmath must be covered by an entry labeled by @xmath
, which is a contradiction.

(b): Next, suppose that @xmath , so that @xmath while @xmath . Then at
least one of @xmath or @xmath occurs in @xmath . If @xmath , then @xmath
would be right weak star reducible by @xmath with respect to @xmath . In
fact, if the entry labeled by @xmath is covered by an entry labeled by
@xmath , we have the same contradiction. So, it must be the case that
@xmath , while the entry labeled by @xmath is not covered by an entry
labeled by @xmath . Since @xmath , we must have @xmath ; otherwise,
@xmath . This implies that @xmath . But then @xmath is right weak star
reducible by @xmath with respect to @xmath , which is a contradiction.

We have shown that @xmath or @xmath . Now, by repeated applications of
Lemma 5.2.2 , @xmath must be equal to an alternating product of @xmath
and @xmath . This implies that @xmath is of type II, which contradicts
that @xmath is not on our list.

Case (3): Lastly, assume that @xmath . As in the previous cases, we
first show that @xmath or @xmath . For sake of a contradiction, assume
that @xmath but @xmath , where @xmath . Without loss of generality,
assume that @xmath and @xmath , so that @xmath ; the remaining cases are
similar. We consider three possibilities: (a) @xmath , (b) @xmath , and
(c) @xmath .

(a): If @xmath , then this case is identical to (a) in Case (2), except
that we contradict Lemma 4.2.12 .

(b): Next, assume that @xmath , so that @xmath while @xmath . Then the
entry labeled by @xmath cannot be covered by an entry labeled by @xmath
; otherwise, @xmath would be right weak star reducible by @xmath with
respect to @xmath . This implies that we must have @xmath . Since @xmath
and @xmath does not occur in @xmath or @xmath , we must have @xmath .
Then @xmath . But then @xmath is right weak star reducible by @xmath
with respect to @xmath , which is a contradiction.

(c): Lastly, assume that @xmath , so that @xmath while @xmath . By Lemma
4.2.10 , the entry labeled by @xmath must be covered by entries labeled
by @xmath and @xmath . However, this implies that @xmath is right weak
star reducible by @xmath with respect to @xmath , which is a
contradiction.

We have shown that @xmath or @xmath . By making repeated applications of
Lemma 5.2.3 if @xmath or Lemma 5.2.4 if @xmath , @xmath must be equal to
an alternating product of @xmath and @xmath . This implies that @xmath
is of type II, which contradicts that @xmath is not on our list.

We have exhausted all possibilities, and hence our list is complete.
@xmath

## Chapter 6 Hecke algebras and Temperley–Lieb algebras

In this chapter, we recall the necessary terminology and facts about
Hecke algebras and their associated Temperley–Lieb algebras.

### 6.1 Hecke algebras

Let @xmath be an arbitrary Coxeter graph. We define the Hecke algebra of
type @xmath , denoted by @xmath , to be the @xmath -algebra with basis
consisting of elements @xmath , for all @xmath , satisfying

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath . This is enough to compute @xmath for arbitrary
@xmath . Also, it follows from the definition that each @xmath is
invertible.

It is convenient to extend the scalars of @xmath to produce an @xmath
-algebra, @xmath , where @xmath and @xmath . For more on Hecke algebras,
we refer the reader to [ 16 , Chapter 7] .

The Laurent polynomial @xmath will occur frequently and will usually be
denoted by @xmath .

###### Remark 6.1.1.

Since @xmath is an infinite group, @xmath is an @xmath -algebra of
infinite rank. On the other hand, since @xmath and @xmath are finite,
both @xmath and @xmath are @xmath -algebras of finite rank.

### 6.2 Temperley–Lieb algebras

Let @xmath be the two-sided ideal of @xmath generated by the set @xmath
, where

  -- -------- --
     @xmath   
  -- -------- --

and @xmath is the subgroup generated by @xmath and @xmath .

Following Graham [ 7 , Definition 6.1] , we define the (generalized)
Temperley–Lieb algebra , @xmath , to be the quotient @xmath -algebra
@xmath . We denote the corresponding canonical epimorphism by @xmath .

###### Remark 6.2.1.

Except for in the case of type @xmath , there are many Temperley–Lieb
type quotients that appear in the literature. That is, some authors
define a Temperley–Lieb algebra as a different quotient of @xmath . In
particular, the blob algebra of [ 23 ] is a smaller Temperley–Lieb type
quotient of @xmath than @xmath . Also, the symplectic blob algebra of [
15 ] and [ 22 ] is a finite rank quotient of @xmath , whereas, as we
shall see, @xmath is of infinite rank. Typically, authors that study
these smaller Temperley–Lieb type quotients are interested in
representation theory, where our motivation is Kazhdan–Lusztig theory.

Let @xmath . The following fact is due to Graham [ 7 , Theorem 6.2] .

###### Theorem 6.2.2.

The set @xmath is an @xmath -basis for @xmath . @xmath

We will refer to the basis of Theorem 6.2.2 as the “ @xmath -basis.” For
our purposes, it will be more useful to work a different basis, which we
define in terms of the @xmath -basis.

###### Definition 6.2.3.

For each @xmath , define @xmath , where @xmath is the identity in @xmath
. If @xmath , we will write @xmath in place of @xmath . If @xmath has
reduced expression @xmath , then we define

  -- -------- --
     @xmath   
  -- -------- --

Note that if @xmath and @xmath are two different reduced expressions for
@xmath , then @xmath since @xmath and @xmath are commutation equivalent
and @xmath when @xmath . So, we will write @xmath if we do not have a
particular reduced expression in mind. It is well-known (and follows
from [ 12 , Proposition 2.4] ) that the set @xmath forms an @xmath
-basis for @xmath . This basis is referred to as the monomial basis or “
@xmath -basis.” We let @xmath denote the identity of @xmath .

###### Remark 6.2.4.

Recall from Chapter 1 that @xmath contains an infinite number of fully
commutative elements, while @xmath and @xmath contain finitely many.
Hence @xmath is an @xmath -algebra of infinite rank while @xmath and
@xmath are of finite rank. (We can have @xmath infinite while @xmath is
finite, in which case, @xmath is of infinite rank and @xmath is of
finite rank.)

### 6.3 A presentation for @xmath

It will be convenient for us to have a presentation for @xmath in terms
of generators and relations. We follow [ 12 ] .

###### Definition 6.3.1.

Let @xmath be the sequence of polynomials defined by the conditions
@xmath , @xmath , and the recurrence relation @xmath for @xmath .

The polynomials @xmath are sometimes called “type II Chebyshev
polynomials.” If @xmath , we define @xmath to be the element of @xmath
given by the linear extension of the map sending @xmath to the product

  -- -------- --
     @xmath   
  -- -------- --

of alternating factors starting with @xmath . For example, if @xmath ,
then @xmath .

The following theorem is [ 12 , Proposition 2.6] .

###### Theorem 6.3.2.

As a unital algebra, @xmath is generated by @xmath and relations

1.   [label= ()]

2.  @xmath for all @xmath (where @xmath );

3.  @xmath if @xmath ;

4.  @xmath if @xmath .

@xmath

###### Remark 6.3.3.

If @xmath , then the last relation above becomes @xmath . If @xmath , we
have @xmath . This implies that @xmath is generated as a unital algebra
by @xmath with defining relations

1.  [label=(0)]

2.  @xmath for all @xmath (where @xmath );

3.  @xmath if @xmath ;

4.  @xmath if @xmath and @xmath ;

5.  @xmath if @xmath or @xmath .

In addition, @xmath (respectively, @xmath ) is generated as a unital
algebra by @xmath (respectively, @xmath ) with the corresponding
relations above. It is known that we can consider @xmath and @xmath as
subalgebras of @xmath in the obvious way.

### 6.4 Weak star reducibility and the monomial basis

###### Remark 6.4.1.

Suppose that @xmath is left weak star reducible by @xmath with respect
to @xmath . Recall from Chapter 1 that this implies that @xmath
(reduced) when @xmath or @xmath (reduced) when @xmath . In this case, we
have

  -- -------- --
     @xmath   
  -- -------- --

It is important to note that @xmath when @xmath and @xmath when @xmath .
We have a similar characterization for right weak star reducibility.

###### Example 6.4.2.

Let @xmath have reduced expression @xmath . Then @xmath is left weak
star reducible by @xmath with respect to @xmath , and so we have

  -- -------- --
     @xmath   
  -- -------- --

Observe that @xmath is left weak star reducible by @xmath with respect
to @xmath to the irreducible element @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 6.4.3.

It is tempting to think that if @xmath is a monomial basis element such
that @xmath , where @xmath and @xmath , then @xmath is weak star
reducible by some @xmath with respect to @xmath , where @xmath . But
this is not true. For example, let @xmath with @xmath , so that @xmath ,
and let @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

We see that @xmath , but @xmath is not left weak star reducible by
@xmath (or any generator).

The next lemma is useful for reversing the multiplication of monomials
corresponding to weak star reductions.

###### Lemma 6.4.4.

Let @xmath and suppose that @xmath is left weak star reducible by @xmath
with respect to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

We have an analogous statement if @xmath is right weak star reducible by
@xmath with respect to @xmath .

###### Proof.

Suppose that @xmath is left weak star reducible by @xmath with respect
to @xmath . Then we can write @xmath (reduced) when @xmath or @xmath
(reduced) when @xmath , which implies that

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we have

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

as desired. ∎

### 6.5 A characterization for an arbitrary product of monomials

It will be useful for us to know what form an arbitrary product of
monomial generators takes in @xmath . The next lemma is similar to [ 14
, Lemma 2.1.3] , which is a statement involving @xmath .

###### Lemma 6.5.1.

Let @xmath and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath .

###### Proof.

We induct on the length of @xmath . For the base case, assume that
@xmath . That is, @xmath . Then for any @xmath , we have @xmath , which
gives us our desired result. Now, assume that @xmath . There are three
possibilities to consider.

Case (1): First, if @xmath is reduced and fully commutative, then

  -- -------- --
     @xmath   
  -- -------- --

which agrees with the statement of the lemma.

Case (2): Second, if @xmath is not reduced, then @xmath , as so we must
be able to write @xmath (reduced). In this case, we see that

  -- -------- --
     @xmath   
  -- -------- --

Again, this agrees with the statement of the lemma.

Case (3): For the final case, assume that @xmath is reduced, but not
fully commutative. Then @xmath must have a reduced expression containing
the subword @xmath if @xmath or @xmath if @xmath . So, we must be able
to write

  -- -------- --
     @xmath   
  -- -------- --

where each product is reduced, @xmath , and @xmath commutes with every
element of @xmath , so that

  -- -------- --
     @xmath   
  -- -------- --

This implies that

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath in the @xmath case and that @xmath when @xmath . So, we
can apply the inductive hypothesis @xmath (respectively, @xmath ) times
if @xmath (respectively, @xmath ) starting with @xmath (respectively,
@xmath ). Therefore, we obtain

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath , as desired. ∎

###### Remark 6.5.2.

If @xmath is any collection of @xmath monomial generators, then it
follows immediately from Lemma 6.5.1 that

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath .

## Chapter 7 Free products of associative algebras

In the next chapter, we begin describing the construction of our desired
diagram algebra. In order to define the decoration set for our diagram
algebra, we will need to describe a method for combining two associative
algebras together to create a new associative algebra. To accomplish
this, we will make use of Bergman’s diamond lemma [ 1 ] . We follow the
development in [ 11 ] .

### 7.1 Bergman’s diamond lemma

Let @xmath be a commutative ring and let @xmath be a nonempty set.
Define @xmath to be the free monoid generated by @xmath . Let @xmath be
a semigroup partial order on @xmath : that is, if @xmath are (possibly
empty) words in @xmath and @xmath , then we have @xmath and @xmath . We
say @xmath satisfies the descending chain condition if any sequence
@xmath terminates. A reduction system @xmath for the module @xmath is a
set of rules @xmath of the form

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath and each @xmath . If a rule @xmath acts nontrivially
on a monomial @xmath , then we will write @xmath and denote the image of
@xmath after applying @xmath by @xmath . That is, @xmath . (Note that
@xmath is a linear combination of monomials with coefficients from
@xmath .) The @xmath -module maps @xmath used to apply rules are known
as reductions ; these may consist of several rules performed
sequentially. The two-sided ideal @xmath of @xmath is that generated by
all elements @xmath for all rules @xmath . We say @xmath is compatible
with @xmath if @xmath can be written as a linear combination of
monomials strictly less than @xmath in @xmath , and we say @xmath is
compatible with @xmath if each of its rules is.

An overlap ambiguity occurs when there are two rules @xmath and @xmath
such that there exist monomials @xmath and @xmath with @xmath ; it is
said to be resolvable if there are reductions @xmath and @xmath such
that @xmath . An inclusion ambiguity occurs when there are two rules
@xmath and @xmath such that there exist monomials @xmath and @xmath with
@xmath ; it is said to be resolvable if there are reductions @xmath and
@xmath such that @xmath .

A reduction @xmath is said to act trivially on @xmath if @xmath , and if
all reductions act trivally on @xmath , we say @xmath is irreducible .
The set of irreducible elements arising from @xmath is denoted @xmath
and has an obvious @xmath -module structure. A normal form of @xmath is
an element @xmath to which @xmath can be reduced; it is not immediate
that normal forms always exist or that they are unique.

The following theorem is part of Bergman’s diamond lemma, which is
proved in [ 1 ] .

###### Theorem 7.1.1 (Bergman’s diamond lemma).

Let @xmath be a commutative ring with 1. Let @xmath be a nonempty set,
let @xmath be a semigroup partial order on @xmath , and let @xmath be
reduction system for @xmath . If @xmath is compatible with @xmath , and
@xmath satisfies the descending chain condition, then the following are
equivalent:

1.   [label= ()]

2.  All ambiguities in @xmath are resolvable.

3.  Every element @xmath has a unique normal form equaling @xmath for
    some reduction @xmath .

4.  @xmath and @xmath are isomorphic as @xmath -modules.

@xmath

We will make use of Theorem 7.1.1 in the next section to prove a result
about the free product of two associative algebras.

### 7.2 Free product of associative algebras

Let @xmath be a commutative ring with @xmath . Let @xmath and @xmath be
two associative algebras over @xmath with bases @xmath and @xmath ,
respectively, each containing @xmath . Let @xmath and consider @xmath .
We wish to describe a set of rules on @xmath for reducing monomials. Let
@xmath . That is, each @xmath is a non-identity element of either @xmath
or @xmath . Recall that if both @xmath and @xmath are elements of the
same @xmath , then there exist @xmath and @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

For each such relation, define a rule @xmath on @xmath that sends the
product of two basis elements from @xmath to the corresponding linear
combination. Let @xmath be the reduction system for @xmath consisting of
all such rules. If @xmath and @xmath , then there is no rule for
reducing @xmath or @xmath . Define

  -- -------- --
     @xmath   
  -- -------- --

The algebra @xmath is generated as a unital algebra by the disjoint
union of @xmath and @xmath , subject to the corresponding relations of
@xmath and @xmath . The point is that there is no interaction between
the elements of @xmath and @xmath in @xmath . It turns out that @xmath
is the free product of @xmath and @xmath .

Next, define @xmath to be the union of @xmath with the set of all finite
alternating products of non-identity elements from @xmath and @xmath .
We will write an arbitrary non-identity element @xmath as @xmath , where
each @xmath is a non-identity element of either @xmath or @xmath and if
@xmath (respectively, @xmath ), then @xmath (respectively, @xmath ).
Note that @xmath is the set of all finite linear combinations of
elements from @xmath .

The following proposition is probably well-known, but we have been
unable to find a reference. So, we provide a proof here.

###### Proposition 7.2.1.

Let @xmath be a commutative ring with @xmath and let @xmath and @xmath
be two associative @xmath -algebras with bases @xmath and @xmath ,
respectively, each containing @xmath . Then @xmath is an associative
algebra over @xmath with basis @xmath containing @xmath .

###### Proof.

Certainly, @xmath is a spanning set for @xmath . We will use Bergman’s
diamond lemma to show that @xmath is in fact a basis. Define @xmath on
@xmath to be the partial order such that @xmath if and only if either
@xmath or @xmath and @xmath for all @xmath . This is a semigroup partial
order on @xmath and satisfies the descending chain condition. Since all
reductions acting nontrivially send pairs of elements from @xmath to
linear combinations of single elements from @xmath , @xmath is
compatible with @xmath . We now argue that all the ambiguities are
resolvable. Since all reductions apply (locally) to pairs of elements
from @xmath , there are no inclusion ambiguities. All overlap
ambiguities are of the form @xmath , where @xmath for some @xmath and
@xmath . Since each @xmath is associative, every overlap ambiguity must
be resolvable. Hence all ambiguities are resolvable. By Theorem 7.1.1 ,
every element @xmath has a unique normal form which equals @xmath for
some reduction @xmath and

  -- -------- --
     @xmath   
  -- -------- --

as @xmath -modules. This implies that

  -- -------- --
     @xmath   
  -- -------- --

as @xmath -modules, where @xmath is the set of all finite linear
combinations of elements from @xmath . Thus, @xmath is a basis for
@xmath . We have also shown that @xmath is an associative algebra. ∎

### 7.3 Free product of two Verlinde algebras

We are interested in a very specific free product of algebras. Recall
the definition of the type II Chebyshev polynomials @xmath given in
Definition 6.3.1 . We use these polynomials to define the Verlinde
algebra, which first appeared in [ 30 ] .

###### Definition 7.3.1.

Let @xmath . The Verlinde algebra , @xmath , is defined to be the
quotient of @xmath by the ideal generated by @xmath .

###### Lemma 7.3.2.

The algebra @xmath has rank @xmath and is equipped with a @xmath -basis
consisting of the images @xmath of the elements @xmath for @xmath .

###### Proof.

See [ 10 , Proposition 1.2.3] . ∎

For example, @xmath is equal to the quotient of @xmath by the ideal
generated by the polynomial @xmath . A basis for @xmath is given by the
images of @xmath , @xmath , and @xmath . We are interested in the
algebra @xmath , but for our current purposes, we need a different
basis. Define @xmath , @xmath , and @xmath and let @xmath , @xmath , and
@xmath be their respective images in @xmath . Then it is readily seen
that @xmath forms a basis for @xmath . Note that @xmath is the identity
in @xmath and the other basis elements satisfy the relations

1.  [label=(0)]

2.  @xmath ;

3.  @xmath .

Now, consider two copies of @xmath . As above, @xmath forms a basis for
@xmath . To avoid confusion, let @xmath denote the second copy of @xmath
and denote its basis by @xmath . It will be very useful for us to
establish the following correspondence, which will be used later to add
decorations to our diagrams:

1.  [label=(0)]

2.  @xmath ;

3.  @xmath ;

4.  @xmath ;

5.  @xmath ;

so that @xmath and @xmath are each a basis for @xmath and @xmath ,
respectively. Then, the relations in @xmath and @xmath , respectively,
become

1.  [label=(0)]

2.  @xmath ;

3.  @xmath ;

4.  @xmath ;

5.  @xmath

Note that these relations imply that

1.  [label=(0)]

2.  @xmath ;

3.  @xmath ;

4.  @xmath ;

5.  @xmath .

We will refer to @xmath and @xmath as closed decorations and @xmath and
@xmath as open decorations . By Proposition 7.2.1 , @xmath is an
associative algebra with a basis consisting of the identity and all
finite alternating products of open and closed decorations. For example,

  -- -------- --
     @xmath   
  -- -------- --

where the expression on the right is a basis element of @xmath , while
the expression on the left is not.

###### Remark 7.3.3.

We can also think of @xmath as being constructed in the following way.
Let @xmath and @xmath . Consider the free @xmath -algebra @xmath . Then
@xmath is equal to the quotient of @xmath by the following relations:

1.  [label=(0)]

2.  @xmath ;

3.  @xmath ;

4.  @xmath ;

5.  @xmath .

## Chapter 8 Diagram algebras

The goal of this chapter is to familiarize the reader with the necessary
background on diagram algebras and to define a generating set for the
diagram algebra that we are interested. We will also define a set of
diagrams that will turn out to be a basis for this diagram algebra (see
Chapter 9). It is important to note that there is currently no rigorous
definition of the term “diagram algebra.” However, our diagram algebras
possess many of the same features as those already appearing in the
literature.

### 8.1 Summary of notation

For the reader’s reference, we summarize here the notations used
throughout the remainder of this thesis (and indicate where each is
defined):

  @xmath   set of (undecorated) pseudo @xmath -diagrams                Definition 8.2.2
  -------- ----------------------------------------------------------- -------------------
  @xmath   @xmath -algebra having @xmath as a basis                    Definition 8.2.8
  @xmath   set of @xmath -decorated pseudo @xmath -diagrams            Definition 8.3.5
  @xmath   @xmath -algebra having @xmath as a basis                    Definition 8.3.8
  @xmath   set of LR-decorated diagrams from @xmath                    Definition 8.4.1
  @xmath   @xmath -module spanned by @xmath                            Definition 8.4.4
  @xmath   quotient of @xmath by the relations induced by @xmath       Definition 8.4.6
  @xmath   @xmath -algebra generated (as a unital algebra) by @xmath   Definition 8.4.9
  @xmath   set of all @xmath -admissible @xmath -diagrams              Definition 8.4.10
  @xmath   @xmath -module spanned by the admissible diagrams           Definition 8.4.12
  @xmath   @xmath -algebra generated (as a unital algebra) by @xmath   Definition 8.5.1
  @xmath   @xmath -algebra generated (as a unital algebra) by @xmath   Definition 8.5.1

### 8.2 Ordinary Temperley–Lieb pseudo diagrams

It is worth noting that our development in this chapter is more general
than many of the standard developments. The usual developments are too
restrictive to accomplish the task of finding a diagrammatic
representation of the infinite dimensional algebra @xmath . Yet, our
development is modeled after [ 10 ] , [ 15 ] , [ 18 ] , and [ 22 ] .

###### Definition 8.2.1.

Let @xmath be a nonnegative integer. The standard @xmath -box is a
rectangle with @xmath marks points, called nodes (or vertices ) labeled
as follows.

[]

We will refer to the top of the rectangle as the north face and the
bottom as the south face . Often, it will be useful for us to think of
the standard @xmath -box as being embedded in the plane. In this case,
we put the lower left corner of the rectangle at the origin such that
each node @xmath (respectively, @xmath ) is located at the point @xmath
(respectively, @xmath ).

Next, we summarize the construction of the ordinary Temperley–Lieb
pseudo diagrams.

###### Definition 8.2.2.

A concrete pseudo @xmath -diagram consists of a finite number of
disjoint curves (planar), called edges , embedded in the standard @xmath
-box. Edges may be closed (isotopic to circles), but not if their
endpoints coincide with the nodes of the box. The nodes of the box are
the endpoints of curves, which meet the box transversely. Otherwise, the
curves are disjoint from the box. We define an equivalence relation on
the set of concrete pseudo @xmath -diagrams. Two concrete pseudo @xmath
-diagrams are (isotopically) equivalent if one concrete diagram can be
obtained from the other by isotopically deforming the edges such that
any intermediate diagram is also a concrete pseudo @xmath -diagram. A
pseudo @xmath -diagram (or an ordinary Temperley-Lieb pseudo-diagram )
is defined to be an equivalence class of equivalent concrete pseudo
@xmath -diagrams. We denote the set of pseudo @xmath -diagrams by @xmath
.

###### Example 8.2.3.

Here is an example of a concrete pseudo 5-diagram.

[]

Here an example of a drawing that is not a concrete pseudo 5-diagram.

[]

###### Remark 8.2.4.

When representing a pseudo @xmath -diagram with a drawing, we pick an
arbitrary concrete representative among a continuum of equivalent
choices. When no confusion can arise, we will not make a distinction
between a concrete pseudo @xmath -diagram and the equivalence class that
it represents. We say that two concrete pseudo @xmath -diagrams are
vertically equivalent if they are equivalent in the above sense by an
isotopy that preserves setwise each vertical cross-section of the @xmath
-box.

We will refer to any closed curves occurring in the pseudo @xmath
-diagram as a loop edge , or simply a loop . The diagram in the example
above has a single loop. Note that we used the word “pseudo” in our
definition to emphasize that we allow loops to appear in our diagrams.
Most examples of diagram algebras in the literature “scale away” loops
that appear (i.e., remove and multiply by a scalar). There are loops in
the diagram algebra that we are interested in preserving, so as to
obtain infinitely many diagrams. When no confusion will arise, we will
refer to a pseudo @xmath -diagram as simply a diagram. The presence of
@xmath in the definition above is to emphasize that the edges of the
diagrams are undecorated. In the next section, we will allow for the
presence of decorations.

Let @xmath be a diagram. If @xmath has an edge @xmath that joins node
@xmath in the north face to node @xmath in the south face, then @xmath
is called a propagating edge from @xmath to @xmath . (Propagating edges
are often referred to as “through strings” in the literature.) If a
propagating edge joins @xmath to @xmath , then we will call it a
vertical propagating edge . If an edge is not propagating, loop edge or
otherwise, it will be called non-propagating .

If a diagram @xmath has at least one propagating edge, then we say that
@xmath is dammed . If, on the other hand, @xmath has no propagating
edges (which can only happen if @xmath is even), then we say that @xmath
is undammed . Note that the number of non-propagating edges in the north
face of a diagram must be equal to the number of non-propagating edges
in the south face. We define the function @xmath via

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 8.2.5.

There is only one diagram with @xmath -value @xmath having no loops;
namely

  -- -- --
        
  -- -- --

The maximum value that @xmath can take is @xmath . In particular, if
@xmath is even, then the maximum value that @xmath can take is @xmath ,
i.e., @xmath is undammed. On the other hand, if @xmath while @xmath is
odd, then @xmath has a unique propagating edge.

We wish to define an associative algebra that has the pseudo @xmath
-diagrams as a basis.

###### Definition 8.2.6.

Let @xmath be a commutative ring with @xmath . The associative algebra
@xmath over @xmath is the free @xmath -module having @xmath as a basis,
with multiplication defined as follows. If @xmath , the product @xmath
is the element of @xmath obtained by placing @xmath on top of @xmath ,
so that node @xmath of @xmath coincides with node @xmath of @xmath ,
rescaling vertically by a factor of @xmath and then applying the
appropriate translation to recover a standard @xmath -box.

###### Remark 8.2.7.

For a proof that this procedure does in fact define an associative
algebra see [ 10 , §2] and [ 18 ] .

We will refer to the multiplication of diagrams as diagram concatenation
. The (ordinary) Temperley–Lieb diagram algebra (see [ 8 , 10 , 18 , 25
] ) can be easily defined in terms of this formalism.

###### Definition 8.2.8.

Let @xmath be the associative @xmath -algebra equal to the quotient of
@xmath by the following relation:

  ----
  []
  ----

= @xmath

It is well-known that @xmath is the free @xmath -module with basis given
by the elements of @xmath having no loops. The multiplication is
inherited from the multiplication on @xmath except we multiply by a
factor of @xmath for each resulting loop and then discard the loop. We
will refer to @xmath as the (ordinary) Temperley–Lieb diagram algebra .

###### Example 8.2.9.

Here is an example of multiplication of three basis diagrams of @xmath .

  -- -------- -------- -- --
                          
     @xmath   @xmath      
  -- -------- -------- -- --

For a proof of the following theorem, see [ 19 ] or [ 25 ] .

###### Theorem 8.2.10.

As @xmath -algebras, @xmath . Moreover, each loop-free diagram from
@xmath corresponds to a unique monomial basis element of @xmath . @xmath

### 8.3 Decorated pseudo diagrams

Now, we will adorn the edges of a diagram with elements from an
associative algebra having a basis containing @xmath . First, we need to
develop some terminology and lay out a few restrictions on how we
decorate our diagrams.

Let @xmath be a commutative ring with @xmath and let @xmath be a set
such that @xmath does not contain @xmath . Let @xmath be a set of
relations on @xmath chosen so that @xmath has a basis @xmath given by a
subset of @xmath containing @xmath and @xmath . Then @xmath is an
associative @xmath -algebra. We will refer to each @xmath as a
decoration . Every basis element in @xmath can be written as a finite
product of decorations. Let @xmath be a finite sequence of decorations
in @xmath ; note that by definition each decoration is not equal to the
identity and that @xmath may or may not be a basis element of @xmath .
We say that @xmath and @xmath are adjacent if @xmath and we will refer
to @xmath as a block of decorations of width @xmath . Note that a block
of width @xmath is a just a single decoration.

Temporarily, we will ignore the relations of @xmath . That is, at this
point, we should consider blocks of decorations as elements of @xmath .

###### Example 8.3.1.

We remind the reader that according to Remark 7.3.3 , @xmath with basis
consisting of finite alternating products of open and closed decorations
is such an algebra, where the decoration set is @xmath . Observe that

  -- -------- --
     @xmath   
  -- -------- --

is block of width 7, but is not a basis element of @xmath since there
are two adjacent @xmath decorations in the second and third positions.

Next, let @xmath be a fixed concrete pseudo @xmath -diagram and let
@xmath be a non-loop edge of @xmath . We may adorn @xmath with a finite
sequence of blocks of decorations @xmath such that adjacency of blocks
and decorations of each block is preserved as we travel along @xmath .
The convention we adopt is that the decorations of the block are placed
so that we can read off the sequence of decorations from left to right
as we traverse @xmath from @xmath to @xmath if @xmath is propagating or
from @xmath to @xmath (respectively, @xmath to @xmath ) with @xmath
(respectively, @xmath ) if @xmath is non-propagating. Furthermore, we
should encounter block @xmath before block @xmath . We may also adorn a
loop edge with a sequence of blocks. In this case, reading the
corresponding sequence of decorations depends on an arbitrary choice of
starting point and direction round the loop. We say two sequences of
blocks are loop equivalent if one can be changed to the other or its
opposite by any cyclic permutation. Note that loop equivalence is an
equivalence relation on the set of sequences of blocks. So, the sequence
of blocks on a loop is only defined up to loop equivalence. That is, if
we adorn a loop edge with a sequence of blocks of decorations, we only
require that adjacency be preserved.

Again, let @xmath be a fixed concrete pseudo @xmath -diagram and let
@xmath be an edge of @xmath . Each decoration @xmath on @xmath has
coordinates in the plane. In particular, each decoration has an
associated @xmath -value, which we will call its vertical position . We
also require the following:

1.  [label=(0)]

2.  If @xmath and @xmath is non-propagating (loop edge or otherwise),
    then we allow adjacent blocks on @xmath to be conjoined to form
    larger blocks, and in particular, if we conjoin all adjacent blocks
    on @xmath , then there is a unique maximal block.

3.  If @xmath and @xmath is propagating, then as in (1), we allow
    adjacent blocks on @xmath to be conjoined to form larger blocks, and
    in particular, if we conjoin all adjacent blocks on @xmath , then
    there is a unique maximal block.

4.  If @xmath and @xmath is propagating, then we allow @xmath to be
    decorated subject to the following constraints.

    1.  [label=()]

    2.  All decorations occurring on propagating edges must have
        vertical position lower (respectively, higher) than the vertical
        positions of decorations occurring on the (unique)
        non-propagating edge in the north face (respectively, south
        face) of @xmath .

    3.  If @xmath is a block of decorations occurring on @xmath , then
        no other decorations occurring on any other propagating edges
        may have vertical position in the range of vertical positions
        that @xmath occupies.

    4.  If @xmath and @xmath are two adjacent blocks occurring on @xmath
        , then they may be conjoined to form a larger block only if the
        previous requirements are not violated.

###### Remark 8.3.2.

Note that 3 above is an unusual requirement for decorated diagrams. We
require this feature to ensure faithfulness of our diagrammatic
representation on monomial basis elements of @xmath indexed by the type
I elements of @xmath .

If an edge has no decorations on it, then we say that it is undecorated
, and in this case, we can think of the edge as being adorned with
@xmath . A diagram is undecorated if all of its edges are undecorated.
We require that all diagrams with @xmath -value 0 be undecorated. In
particular, the unique diagram @xmath having @xmath -value 0 and no
loops is undecorated.

###### Definition 8.3.3.

A concrete @xmath -decorated pseudo @xmath -diagram is any concrete
@xmath -diagram decorated by elements of the decoration set @xmath that
satisfies the conditions given above.

###### Example 8.3.4.

Let @xmath , so that @xmath is our decoration set.

1.  [label=()]

2.  Here is an example of a concrete @xmath -decorated pseudo @xmath
    -diagram.

    []

    In this example, there are no restrictions on the relative vertical
    position of decorations since the @xmath -value is greater than 1.

3.  Here is another example of a concrete @xmath -decorated pseudo
    @xmath -diagram, but with @xmath -value 1.

    []

    We use the horizontal dotted lines to indicate that the three closed
    decorations on the leftmost propagating edge are in three distinct
    blocks. We cannot conjoin these three decorations to form a single
    block because there are decorations on the last propagating edge
    occupying vertical positions between them. Similarly, the open
    decorations on the last propagating edge form two distinct blocks
    that may not be conjoined.

4.  Lastly, here is an example of a concrete @xmath -decorated pseudo
    @xmath -diagram.

    []

Note that an isotopy of a concrete @xmath -decorated pseudo @xmath
-diagram @xmath that preserves the faces of the standard @xmath -box may
not preserve the relative vertical position of the decorations even if
it is mapping @xmath to an equivalent diagram. However, if two diagrams
are vertically equivalent then the relative vertical position of
decorations will be preserved. This is a bit too restrictive for us. The
only time equivalence is an issue is when @xmath . In this case, we wish
to preserve the relative vertical position of the blocks. We define two
concrete pseudo @xmath -decorated @xmath -diagrams to be @xmath
-equivalent if we can isotopically deform one diagram into the other
such that any intermediate diagram is also a concrete pseudo @xmath
-decorated @xmath -diagram. Note that we do allow decorations from the
same maximal block to pass each other’s vertical position.

###### Definition 8.3.5.

An @xmath -decorated pseudo @xmath -diagram is defined to be an
equivalence class of @xmath -equivalent concrete @xmath -decorated
pseudo @xmath -diagrams. We denote the set of @xmath -decorated pseudo
@xmath -diagrams by @xmath .

###### Remark 8.3.6.

As in Remark 8.2.4 , when representing an @xmath -decorated pseudo
@xmath -diagram with a drawing, we pick an arbitrary concrete
representative among a continuum of equivalent choices. When no
confusion will arise, we will not make a distinction between a concrete
@xmath -decorated pseudo @xmath -diagram and the equivalence class that
it represents.

We wish to generalize Definition 8.2.6 to the case of @xmath -decorated
@xmath -diagrams. First, we need a lemma to justify that our
multiplication is well-defined and associative.

###### Lemma 8.3.7.

Let @xmath be a diagram with @xmath . Suppose that the unique
non-propagating edge in the north face of @xmath joins @xmath to @xmath
. Let @xmath be any other diagram. Then @xmath if and only if @xmath and
the unique non-propagating edge in the south face of @xmath joins either
@xmath @xmath to @xmath ; @xmath @xmath to @xmath ; or @xmath @xmath to
@xmath .

###### Proof.

First, assume that @xmath . It is a general fact that @xmath , which
implies that @xmath .

Conversely, assume that @xmath and that the unique non-propagating edge
in the south face of @xmath joins either (a) @xmath to @xmath ; (b)
@xmath to @xmath ; or (c) @xmath to @xmath .

Assume that we are in situation (a). Suppose that the propagating edge
leaving node @xmath in the south face of @xmath is connected to node
@xmath in the north face. Also, suppose that the propagating edge
leaving node @xmath in the north face of @xmath is connected to node
@xmath in the south face. Then @xmath has a propagating edge joining
node @xmath to node @xmath . Furthermore, the only non-propagating edge
in the north (respectively, south) face of @xmath is the same as the
unique non-propagating edge in the north (respectively, south) face of
@xmath (respectively, @xmath ). It follows that @xmath .

Next, assume (b) happens. Then @xmath has one more loop than the sum
total of loops from @xmath and @xmath . Furthermore, the only
non-propagating edge in the north (respectively, south) face of @xmath
is the same as the unique non-propagating edge in the north
(respectively, south) face of @xmath (respectively, @xmath ), and so
@xmath .

Lastly, if (c) happens, then the proof that @xmath is symmetric to case
(a). ∎

###### Definition 8.3.8.

Let @xmath be an associative algebra as in the beginning of this
section. We define @xmath to be the free @xmath -module having the
@xmath -decorated pseudo @xmath -diagrams @xmath as a basis. We define
multiplication in @xmath by defining multiplication in the case where
@xmath and @xmath are basis elements of @xmath , and then extend
bilinearly. To calculate the product @xmath , concatenate @xmath and
@xmath (as in Definition 8.2.6 ). While maintaining @xmath -equivalence,
conjoin adjacent blocks.

We emphasize that we are not currently applying any of the relations of
@xmath . We are simply adorning the edges with decorations subject to
certain constraints and describing rules for conjoining blocks when
multiplying diagrams.

###### Remark 8.3.9.

We claim that the multiplication defined above turns @xmath into a
well-defined associative @xmath -algebra. This claim follows from
arguments in [ 22 , §3] and Lemma 8.3.7 above. The only case that
requires serious consideration is when multiplying two diagrams that
both have @xmath -value @xmath . If @xmath while @xmath , then there are
no concerns. However, if @xmath , then according to Lemma 8.3.7 , if the
unique non-propagating edge @xmath in the south face of @xmath joins
@xmath to @xmath , it must be the case that unique non-propagating edge
@xmath in the north face of @xmath joins either (a) @xmath to @xmath ;
(b) @xmath to @xmath ; or (c) @xmath to @xmath . If (a) or (c) happens,
then the only blocks that get conjoined are the blocks on @xmath and
@xmath , which presents no problems. If (b) happens, then we get a loop
edge and we conjoin the blocks from @xmath and @xmath . As a
consequence, it is possible that the block occurring on a propagating
edge of @xmath having the lowest vertical position may be conjoined with
the block occurring on a propagating edge of @xmath having the highest
vertical position. This can only happen if these two edges are joined in
@xmath , and regardless, presents no problems. Since there are no
relations to apply, the product of two elements of @xmath is equal to a
single basis element.

### 8.4 The @xmath-decorated diagram algebra @xmath and admissible
diagrams

For the remainder of this thesis, we will assume that @xmath , where
@xmath , and that @xmath is equipped with basis consisting of the
identity and all finite alternating products of open and closed
decorations. Let @xmath . We now focus our attention on a particular set
of diagrams from @xmath .

###### Definition 8.4.1.

Let @xmath . That is, the blocks on the edges of @xmath consist of
sequences of the decorations @xmath , @xmath , @xmath , and @xmath .

1.  [label=(0)]

2.  An edge of @xmath is called L-exposed (respectively, R-exposed ) if
    it can be deformed to touch the left (respectively, right) wall of
    the diagram without crossing any other edges.

3.  We call @xmath L-decorated (respectively, R-decorated ) if the only
    edges labelled with closed (respectively, open) decorations are
    L-exposed (respectively, R-exposed).

4.  We call @xmath LR-decorated if @xmath is both L-decorated and
    R-decorated, with the added constraint that it must be possible to
    deform decorated edges so as to take open decorations to the left
    and closed decorations to the right simultaneously. We denote the
    set of LR-decorated diagrams from @xmath by @xmath .

5.  We say that a decoration on a non-propagating edge @xmath joining
    @xmath to @xmath (respectively, @xmath to @xmath ) with @xmath
    (respectively, @xmath ) is first (respectively, last ) if it is the
    first (respectively, last) decoration encountered as we traverse
    @xmath from @xmath to @xmath (respectively, @xmath to @xmath ).

6.  Similarly, if @xmath , then we say that a decoration on a
    propagating edge @xmath from @xmath to @xmath is first
    (respectively, last ) if it is the first (respectively, last)
    decoration encountered as we traverse @xmath from @xmath to @xmath .

###### Remark 8.4.2.

We make several observations.

1.  [label=(0)]

2.  The set of LR-decorated diagrams @xmath is infinite since there is
    no limit to the number of loops that may appear.

3.  Concatenating diagrams cannot change an L-exposed edge to a
    non-L-exposed edge, and similarly for R-exposed edges. Thus, the set
    of LR-decorated diagrams is closed under diagram concatenation.

4.  If @xmath is an undammed LR-decorated diagram, then all closed
    decorations occurring on an edge connecting nodes in the north face
    (respectively, south face) of @xmath must occur before all of the
    open decorations occurring on the same edge as we travel the edge
    from the left node to the right node. Otherwise, we would not be
    able to simultaneously deform decorated edges to the left and right.
    Furthermore, if an edge joining nodes in the north face of @xmath is
    adorned with an open (respectively, closed) decoration, then no
    non-propagating edge occurring to the right (respectively, left) in
    the north face may be adorned with closed (respectively, open)
    decorations. We have an analogous statement for non-propagating
    edges in the south face.

5.  Loops can only be decorated by both types of decorations if @xmath
    is undammed. Again, we would not be able to simultaneously deform
    decorated edges to the left and right, otherwise.

6.  If @xmath is a dammed LR-decorated diagram, then closed decorations
    (respectively, open decorations) only occur to the left of
    (respectively, right of) and possibly on the leftmost (respectively,
    rightmost) propagating edge. The only way a propagating edge can
    have decorations of both types is if there is a single propagating
    edge, which can only happen if @xmath is odd.

###### Example 8.4.3.

The diagram in Example 8.3.4 3 is an example that illustrates conditions
3 and 4 of Remark 8.4.2 above while the diagram in Example 8.3.4 1
illustrates condition 5 .

###### Definition 8.4.4.

We denote the @xmath -submodule of @xmath spanned by the LR-decorated
diagrams by @xmath .

The following proposition follows immediately from Remark 8.4.2 2 .

###### Proposition 8.4.5.

The @xmath -submodule @xmath is a @xmath -subalgebra of @xmath . @xmath

We remark that since the set of LR-decorated diagrams is infinite, that
@xmath is an infinite dimensional algebra. Next, we define a particular
quotient of @xmath , which is closely related to our diagram algebra of
interest.

###### Definition 8.4.6.

Let @xmath be the associative @xmath -algebra equal to the quotient of
@xmath by the following set of relations:

1.  [label=(0)]

2.  ----
      []
      ----

    = [] ;

3.  ----
      []
      ----

    = [] ;

4.  ----
      []
      ----

    = [] = 2 [] ;

5.  ----
      []
      ----

    = [] = 2 [] ;

6.  ----
      []
      ----

    = [] = [] = @xmath ;

where the decorations on the edges above represent adjacent decorations
of the same block.

Note that with the exception of the relations involving loops,
multiplication in @xmath is inherited from the relations of the
decoration set @xmath . Also, observe that all of the relations are
local in the sense that a single reduction only involves a single edge.
Furthermore, as a consequence of the relations above, we also have the
following relations:

1.  [label=(0), resume]

2.  ----
      []
      ----

    = 2 [] ;

3.  ----
      []
      ----

    = 2 [] .

###### Example 8.4.7.

Here is an example of multiplication of three diagrams in @xmath .

  -- -------- -------- -- --
                          
     @xmath   @xmath      
  -- -------- -------- -- --

Here is a second example, where each of the diagrams and their product
have @xmath -value 1.

  -- -------- -- -- --
                    
     @xmath         
  -- -------- -- -- --

Again, we use the dotted line to emphasize that the two closed
decorations on the leftmost propagating edge belong to distinct blocks.

Our immediate goal is to show that a basis for @xmath consists of the
set of LR-decorated diagrams having blocks corresponding to nonidentity
basis elements in @xmath . That is, no block may contain adjacent
decorations of the same type (open or closed). To accomplish this task,
we will make use of a diagram algebra version of Bergman’s diamond
lemma. For other examples of this type of application of Bergman’s
diamond lemma, see [ 15 ] and [ 22 ] .

Define the function @xmath via

  -- -------- --
     @xmath   
  -- -------- --

In the literature, if @xmath has no loops, then @xmath is sometimes
referred to as the “shape” of @xmath . For example, if

  ------ -------- -- -- --
         @xmath         
  then                  
         @xmath         
  ------ -------- -- -- --

Next, define a function @xmath via

  -- -------- --
     @xmath   
  -- -------- --

For example, if @xmath is the diagram from above, then @xmath (1 loop
plus 7 decorations). Define @xmath on @xmath via @xmath if and only if
@xmath and @xmath .

Let @xmath be the collection of reductions determined by the relations
of @xmath given Definition 8.4.6 . If we apply any single reduction
(loop removal or any other local reduction) to a diagram from @xmath ,
then we obtain a scalar multiple of a strictly smaller diagram with
respect to @xmath . Thus, our reduction system @xmath (i.e., diagram
relations) is compatible with @xmath . Now, suppose that @xmath and let
@xmath be any other element from @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath , multiplying @xmath or @xmath on the same side by @xmath
will increase the number of decorations and number of loops by the same
amount. So, we have

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Therefore, @xmath and @xmath . This shows that @xmath is a semigroup
partial order on @xmath . Clearly, @xmath satisfies the descending chain
condition.

###### Proposition 8.4.8.

The set of LR-decorated diagrams having maximal blocks corresponding to
nonidentity basis elements in @xmath forms a basis for @xmath .

###### Proof.

Let @xmath be as above. Following the setup of Bergman’s diamond lemma,
it remains to show that all of the ambiguities are resolvable. By
inspecting the relations of Definition 8.4.6 , we see that there are no
inclusion ambiguities, so we only need to check that the overlap
ambiguities are resolvable. Let @xmath be a diagram from @xmath and
suppose that there are two competing reductions that we could apply. If
both reductions involve the same non-loop edge, then the ambiguity is
easily seen to be resolvable since the algebra @xmath is associative. In
particular, in the @xmath -value @xmath case, the reductions could
involve two distinct blocks on the same edge, in which case, the order
that we apply the reductions is immaterial. If the reductions involve
distinct edges, loop edges or otherwise, the ambiguity is quickly seen
to be resolvable since the reductions commute. Lastly, suppose that the
two competing reductions involve the same loop edge. There are three
possibilities for this loop edge: (a) the loop is undecorated, (b) the
loop carries only one type of decoration (open or closed), and (c) the
loop carries both types of symbols. Note that (a) cannot happen since
then there could not have been two competing reductions involving this
edge to apply. If (b) happens, then any ambiguity involving this loop
edge (including removing the loop) is resolvable since each of @xmath
and @xmath are commutative and associative. Finally, assume (c) happens.
Note that the nature of our relations prevents the complete elimination
of closed (respectively, open) decorations from this loop edge. Since
all loop relations involve either undecorated loops or loops decorated
with a single type of decoration, this loop edge can never be removed.
Since @xmath is associative and none of the relations involve both
decoration types at the same time, the ambiguity is easily seen to be
resolvable since the reductions commute. According to Bergman’s diamond
lemma (Theorem 7.1.1 ), we can conclude that the LR-decorated diagrams
having no relations to apply are a basis, as desired. ∎

The algebra @xmath is still too large for our purposes. Next, we define
a few special diagrams that will form a generating set for a much
smaller algebra that will be our object of interest. Define the diagrams
@xmath via

  -- -------- -- -------- --
     @xmath               
     @xmath      @xmath   
     @xmath               
  -- -------- -- -------- --

We will refer to each of @xmath as a simple diagram . Note that the
simple diagrams are basis elements of @xmath .

###### Definition 8.4.9.

Let @xmath be the @xmath -subalgebra of @xmath generated (as a unital
algebra) by @xmath with multiplication inherited from @xmath .

The next definition describes the set of diagrams that will turn out to
form a basis for @xmath . This definition is motivated by the definition
of @xmath -admissible (after an appropriate change of basis) given by
R.M. Green in [ 9 , Definition 2.2.4] for diagrams in the context of
type @xmath . Since @xmath is, in some sense, type @xmath on one end and
type @xmath on the other, the general idea is to build the axioms of
@xmath -admissible into our definition of @xmath -admissible at both
ends.

###### Definition 8.4.10.

Let @xmath be an LR-decorated diagram. Then we say that @xmath is @xmath
-admissible , or simply admissible , if the following axioms are
satisfied.

1.  [label=(C0)]

2.  The only loops that may appear are equivalent to the following.

    []

3.  If @xmath is undammed (which can only happen if @xmath is even),
    then the (non-propagating) edges joining nodes @xmath and @xmath
    (respectively, nodes @xmath and @xmath ) must be decorated with a
    @xmath (respectively, @xmath ). Furthermore, these are the only
    @xmath (respectively, @xmath ) decorations that may occur on @xmath
    and must be the first (respectively, last) decorations on their
    respective edges.

4.  Assume @xmath has exactly one propagating edge @xmath (which can
    only happen if @xmath is odd). Then @xmath may be decorated by an
    alternating sequence of @xmath and @xmath decorations. If @xmath is
    decorated by both open and closed decorations and is connected to
    node 1 (respectively, @xmath ), then the first (respectively, last)
    decoration occurring on @xmath must be a @xmath . Similarly, if
    @xmath is connected to node @xmath (respectively, @xmath ), then the
    first (respectively, last) decoration occurring on @xmath must be a
    @xmath . If @xmath joins @xmath to @xmath (respectively, @xmath to
    @xmath ) and is decorated by a single decoration, then @xmath is
    decorated by a single @xmath (respectively, @xmath ). Furthermore,
    if there is a non-propagating edge connected to @xmath or @xmath
    (respectively, @xmath or @xmath ) it must be decorated only by a
    single @xmath (respectively, @xmath ). Finally, no other @xmath or
    @xmath decorations appear on @xmath .

5.  Assume that @xmath is dammed with @xmath and has more than one
    propagating edge. If there is a propagating edge joining @xmath to
    @xmath (respectively, @xmath to @xmath ), then it is decorated by a
    single @xmath (respectively, @xmath ). Otherwise, both edges leaving
    either of @xmath or @xmath (respectively, @xmath or @xmath ) are
    each decorated by a single @xmath (respectively, @xmath ) and there
    are no other @xmath or @xmath decorations appearing on @xmath .

6.  If @xmath , then the western end of @xmath is equal to one of the
    following:

    1.  [label=()]

    2.  ----
          []
          ----

        ;

    3.  ----
          []
          ----

        ;

    4.  ----
          []
          ----

        ;

    5.  ----
          []
          ----

        ;

    6.  ----
          []
          ----

        ;

    where the rectangle represents a sequence of blocks (possibly empty)
    such that each block is a single @xmath and the diagram in (ii) can
    only occur if @xmath is not decorated by any open decorations. Also,
    the occurrences of the @xmath decorations occurring on the
    propagating edge have the highest (respectively, lowest) relative
    vertical position of all decorations occurring on any propagating
    edge. In particular, if the rectangle in (iv) (respectively, (v)) is
    empty, then the @xmath decoration has the highest (respectively,
    lowest) relative vertical position among all decorations occurring
    on propagating edges. We have an analogous requirement for the
    eastern end of @xmath , where the closed decorations are replaced
    with open decorations. Furthermore, if there is a non-propagating
    edge connected to @xmath or @xmath (respectively, @xmath or @xmath )
    it must be decorated only by a single @xmath (respectively, @xmath
    ). Finally, no other @xmath or @xmath decorations appear on @xmath .

Let @xmath denote the set of all @xmath -admissible @xmath -diagrams.

###### Remark 8.4.11.

We collect a few comments concerning admissible diagrams.

1.  [label=(0)]

2.  Note that the only time an admissible diagram @xmath can have an
    edge adorned with both open and closed decorations is if @xmath is
    undammed (which only happens when @xmath is even) or if @xmath has a
    single propagating edge (which only happens when @xmath is odd). See
    Example 8.3.4  (a) and (c) for examples that demonstrate this
    restriction.

3.  If @xmath is an admissible diagram with @xmath , then the
    restrictions on the relative vertical position of decorations on
    propagating edges along with axiom 5 imply that the relative
    vertical positions of closed decorations on the leftmost propagating
    edge and open decorations on the rightmost propagating edge must
    alternate. In particular, the number of closed decorations occurring
    on the leftmost propagating edge differs from the number of open
    decorations occurring on the rightmost propagating edge by at
    most 1. For example, if

      -- -- --
            
      -- -- --

    where the leftmost propagating edge carries @xmath @xmath
    decorations, then the rightmost propagating edge must carry @xmath
    @xmath decorations, as well.

4.  Note that the rectangle in diagram (iii) of axiom 5 cannot be empty;
    otherwise, the leftmost propagating edge would not be decorated by a
    basis element of @xmath .

5.  It is clear that @xmath is an infinite set. If an admissible diagram
    @xmath is undammed, then there is no limit to the number of loops
    given in axiom 1 that may occur. Also, if @xmath is an admissible
    diagram with exactly one propagating edge, then there is no limit to
    the width of the block of decorations that may occur on the lone
    propagating edge. Furthermore, if @xmath is admissible with @xmath ,
    then there is no limit to the number of @xmath -blocks
    (respectively, @xmath -blocks) that may occur on the leftmost
    (respectively, righmost) propagating edge.

6.  Each of the admissible diagrams is a basis element of @xmath .

7.  The symbol @xmath in the notation @xmath is to emphasize that we are
    constructing a set of diagrams that are intended to correspond to
    the monomial basis of @xmath . A topic of future research is to
    construct diagrams that correspond to the “canonical basis” of
    @xmath , which is defined for arbitrary Coxeter groups in [ 13 ] .

###### Definition 8.4.12.

Let @xmath be the @xmath -submodule of @xmath spanned by the admissible
diagrams.

###### Proposition 8.4.13.

The set of admissible diagrams @xmath is a basis for the module @xmath .

###### Proof.

This follows immediately from 5 in Remark 8.4.11 . ∎

In the next chapter we will show that @xmath is, in fact, a subalgebra
of @xmath equal to @xmath . And, in the final chapter, we will prove our
main result, which states that @xmath is a faithful representation of
@xmath , where the admissible diagrams correspond to the monomial basis.

### 8.5 Temperley–Lieb diagram algebras of type @xmath

We conclude this chapter by discussing how @xmath and @xmath are related
to @xmath .

###### Definition 8.5.1.

Let @xmath and @xmath denote the subalgebras of @xmath generated by
@xmath and @xmath , respectively. We refer to @xmath (respectively,
@xmath as the Temperley–Lieb diagram algebra of type @xmath
(respectively, type @xmath ).

It is clear that @xmath (respectively, @xmath ) consist entirely of
L-decorated (respectively, R-decorated) diagrams. Also, note that all of
the technical requirements about how to decorate a diagram @xmath when
@xmath are irrelevant since only the leftmost (respectively, rightmost)
propagating edge can carry decorations in @xmath (respectively, @xmath
). The following fact is implicit in [ 9 , §2] after the appropriate
change of basis involving a change of basis on the decoration set.

###### Proposition 8.5.2.

As @xmath -algebras, @xmath and @xmath , where each isomorphism is
determined by

  -- -------- --
     @xmath   
  -- -------- --

for the appropriate restrictions on @xmath . @xmath

Recall from Lemma 7.3.2 that @xmath is an alternate basis for @xmath ,
where @xmath , @xmath , and @xmath are the images of @xmath , @xmath ,
and @xmath , respectively. Using the change of basis @xmath
(respectively, @xmath ) on the decoration set @xmath (respectively,
@xmath ), the basis diagrams in @xmath (respectively, @xmath ) become
@xmath -admissible in the sense of [ 9 , 10 ] . Moreover, it is easily
verified that the axioms for @xmath -admissible given in [ 9 ,
Definition 2.2.4] imply (again, under the appropriate change of basis
involving the decoration set) that all of the basis diagrams in @xmath
and @xmath are @xmath -admissible.

## Chapter 9 A basis for @xmath

The main result of this chapter will be that the @xmath -admissible
diagrams form a basis for @xmath . To achieve this end, we require
several intermediate results.

### 9.1 Preparatory lemmas

If @xmath is an admissible diagram, then we say that a non-propagating
edge joining @xmath to @xmath (respectively, @xmath to @xmath ) is
simple if it is identical to the edge joining @xmath to @xmath
(respectively, @xmath to @xmath ) in the simple diagram @xmath . That
is, an edge is simple if it joins adjacent vertices in the north face
(respectively, south face) and is undecorated, except when one of the
vertices is 1 or @xmath (respectively, @xmath or @xmath ), in which case
it is decorated by only a single @xmath (respectively, @xmath ).

The next six lemmas mimic Lemmas 5.1.4–5.1.7 in [ 9 ] . The proof of
each lemma is immediate and throughout we assume that @xmath is
admissible.

###### Lemma 9.1.1.

Assume that in the north face of @xmath there is an edge, say @xmath ,
connecting node @xmath to node @xmath , and assume that there is another
undecorated edge, say @xmath , connecting node @xmath to node @xmath
with @xmath and @xmath . Further, suppose that @xmath and @xmath are
chosen so that @xmath is minimal. Then @xmath is the admissible diagram
that results from @xmath by removing @xmath , disconnecting @xmath from
node @xmath and reattaching it to node @xmath , and adding a simple edge
to @xmath and @xmath (note that edge @xmath maintains its original
decorations). That is,

  -- -- --
        
  -- -- --

where @xmath represents an arbitrary (possibly empty) block of
decorations. @xmath

###### Lemma 9.1.2.

Assume that in the north face of @xmath there is an edge, say @xmath ,
connecting node @xmath to node @xmath labeled by a single @xmath (this
can only happen if @xmath is even), and assume that there is a simple
edge, say @xmath , connecting node @xmath to node @xmath (which must be
labeled by a single @xmath ). Then @xmath is the admissible diagram that
results from @xmath by joining the right end of @xmath to the left end
of @xmath , and adding a simple edge that joins @xmath to @xmath . Note
that the new edge formed by joining @xmath and @xmath connects node
@xmath to node @xmath and is labeled by the block @xmath . That is,

  -- -- --
        
  -- -- --

@xmath

###### Lemma 9.1.3.

Assume that @xmath has a propagating edge, say @xmath , joining node
@xmath to node @xmath with @xmath . Further, assume that there is a
simple edge, say @xmath , joining nodes @xmath and @xmath . Then @xmath
is the admissible diagram that results from @xmath by removing @xmath ,
disconnecting @xmath from node @xmath and reattaching it to node @xmath
, and adding a simple edge to @xmath and @xmath (note that @xmath
retains its original decorations). This procedure has an inverse, since
@xmath and @xmath . That is,

  -- -- --
        
  -- -- --

where @xmath represents an arbitrary (possibly empty) block of
decorations. @xmath

###### Lemma 9.1.4.

Assume that @xmath has simple edges joining node @xmath to node @xmath
and node @xmath to node @xmath . Then @xmath is the admissible diagram
that results from @xmath by adding a @xmath to the edge joining @xmath
to @xmath . That is,

  -- -- --
        
  -- -- --

@xmath

###### Lemma 9.1.5.

Assume that @xmath has two edges, say @xmath and @xmath , joining node
@xmath to node @xmath and node @xmath to node @xmath , respectively,
where @xmath and @xmath is simple. Then @xmath is the admissible diagram
that results from @xmath by removing the decorations from @xmath and
adding them to @xmath . This procedure has an inverse, since @xmath .
That is,

  -- -- --
        
  -- -- --

where @xmath represents an arbitrary (possibly empty) block of
decorations. @xmath

###### Lemma 9.1.6.

Assume that @xmath has two edges, say @xmath and @xmath , joining node
@xmath to node @xmath and node @xmath to node @xmath , respectively,
with @xmath . Further, assume that @xmath is decorated by a single
@xmath decoration only and that @xmath is decorated by a single @xmath
decoration only. Then @xmath is the admissible diagram that results from
@xmath by removing the @xmath decoration from @xmath and adding it to
@xmath to the right of the @xmath decoration. That is,

  -- -- --
        
  -- -- --

@xmath

###### Remark 9.1.7.

Each of Lemmas 9.1.1 – 9.1.6 have left-right symmetric analogues
(perhaps involving closed decorations), as well as versions that involve
edges in the south face.

### 9.2 The admissible diagrams are generated by the simple diagrams

Next, we state and prove several lemmas that we will use to prove that
each admissible diagram can be written as a product of simple diagrams
in @xmath . (Note that in each of the lemmas of this section, all
non-propagating edges are simple.)

###### Lemma 9.2.1.

If @xmath is an admissible diagram with @xmath , then @xmath can be
written as a product of simple diagrams.

###### Proof.

Assume that @xmath is an admissible diagram with @xmath . The proof is
an exhaustive case by case check, where we consider all the possible
diagrams that are consistent with axiom 5 . We consider five cases; any
remaining cases follow by analogous arguments.

Case (1): First, assume that

  -- -- --
        
  -- -- --

where the leftmost propagating edge carries @xmath @xmath decorations,
and hence, the rightmost propagating edge carries @xmath @xmath
decorations by 2 of Remark 8.4.11 . In this case, it can quickly be
verified that we can obtain @xmath via

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath . Therefore, @xmath can be written as a product
of simple diagrams, as desired.

Case (2): For the second case, assume that

  -- -- --
        
  -- -- --

Note that @xmath does not carry any open decorations. In this case,
@xmath , and so @xmath can be written as a product of simple diagrams,
as expected.

Case (3): For the third case, assume that

  -- -- --
        
  -- -- --

where the leftmost propagating edge carries @xmath @xmath decorations,
so that the rightmost propagating edge carries @xmath @xmath
decorations. Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are as in case (1), and hence @xmath can be
written as a product of simple diagrams.

Case (4): Next, assume that

  -- -- --
        
  -- -- --

where @xmath and the leftmost propagating edge carries @xmath @xmath
decorations. Then by Remark 8.4.11 2 , the rightmost propagating edge
carries @xmath @xmath decorations, where @xmath or @xmath . If @xmath ,
then define

  -- -- --
        
  -- -- --

where the leftmost (respectively, rightmost) propagating edge carries
@xmath @xmath (respectively, @xmath ) decorations. By case (1), @xmath
can be written as a product of simple diagrams. We see that

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath can be written as a product of simple
diagrams, as desired. If, on the other hand, @xmath , then define @xmath
to be identical @xmath except that the last @xmath decoration occurring
on the leftmost propagating edge has been removed. Then by the subcase
we just completed (where the rightmost propagating edge carried one more
@xmath decoration than the leftmost propagating edge carried @xmath
decorations), @xmath can be written as a product of simple diagrams. We
see that

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath can be written as a product of simple
diagrams.

Case (5): For the final case, assume that

  -- -- --
        
  -- -- --

where @xmath , @xmath , and the leftmost propagating edge carries @xmath
@xmath decorations. Then again by Remark 8.4.11 2 , the rightmost
propagating edge carries @xmath @xmath decorations, where @xmath .
Without loss of generality, assume that @xmath , so that @xmath or
@xmath . If @xmath , then without loss of generality, assume that the
first decoration occurring on the leftmost propagating edge has the
highest relative vertical position of all decorations occurring on
propagating edges. Define the diagram

  -- -- --
        
  -- -- --

where the leftmost (respectively, rightmost) propagating edge carries
@xmath @xmath (respectively, @xmath ) decorations. By case (4), @xmath
can be written as a product of simple diagrams. Also, we see that

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath can be written as a product of simple
diagrams, as desired. If, on the other hand, @xmath , define

  -- -- --
        
  -- -- --

where the leftmost propagating edge carries @xmath @xmath decorations
while the rightmost propagating edge carries @xmath @xmath decorations.
Again, by case (4), @xmath can be written as a product of simple
diagrams. We see that

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath can be written as a product of simple
diagrams. ∎

###### Lemma 9.2.2.

If @xmath is an admissible diagram with @xmath such that all
non-propagating edges are simple, then @xmath can be written as a
product of simple diagrams.

###### Proof.

Let @xmath be an admissible diagram with @xmath such that all
non-propagating edges are simple. (Note that the restrictions on @xmath
imply that @xmath has more than one propagating edge and has at least
one non-propagating edge.) We consider two cases, where the second case
has two subcases.

Case (1): First, assume that @xmath has a vertical propagating edge, say
@xmath , joining @xmath to @xmath . Now, define the admissible diagrams
@xmath and @xmath via

  -- -- --
        
  -- -- --

and

  -- -- --
        
  -- -- --

where each of the shaded regions is identical to the corresponding
regions of @xmath . Then @xmath . Furthermore, @xmath (respectively,
@xmath ) is L-exposed (respectively, R-exposed), and hence is only
decorated with closed (respectively, open) decorations. Since @xmath is
admissible, @xmath while @xmath . This implies that both @xmath and
@xmath can be written as a product of simple diagrams. Therefore, @xmath
can be written as a product of simple diagrams, as desired.

Case (2): Next, assume that @xmath has no vertical propagating edges.
Suppose that the leftmost propagating edge joins node @xmath in the
north face to node @xmath in the south face, and without loss of
generality, assume that @xmath . (Note that since @xmath has more than
one propagating edge, @xmath .) We wish to make use of case (1), but we
must consider two subcases.

(a): For the first subcase, assume that @xmath . Since @xmath is
admissible, we must have

  -- -- --
        
  -- -- --

where @xmath on the propagating edge from @xmath to @xmath is either
trivial (i.e., the edge is undecorated) or equal to a single @xmath
decoration. Define the admissible diagram

  -- -- --
        
  -- -- --

where the leftmost propagating edge carries the same decoration as the
leftmost propagating edge in @xmath and the shaded region is identical
to the corresponding region of @xmath . By case (1), @xmath can be
written as a product of simple diagrams. By making repeated applications
of Lemma 9.1.3 , we can transform @xmath into @xmath , which shows that
@xmath can be written as a product of simple diagrams, as desired.

(b): For the second subcase, assume that @xmath , so that

  -- -- --
        
  -- -- --

Since @xmath , there is at least one other propagating edge occurring to
the right of the leftmost propagating edge. Furthermore, since the
number of non-propagating edges in the north face is equal to the number
of non-propagating edges in the south face, there is at least one
undecorated non-propagating edge in the south face of @xmath . By making
repeated applications, if necessary, of the southern version of Lemma
9.1.3 , we may assume that

  -- -- --
        
  -- -- --

Now, define the admissible diagrams @xmath and @xmath via

  -- -- --
        
  -- -- --

and

  -- -- --
        
  -- -- --

where the shaded regions are identical to the corresponding regions of
@xmath . By case (1), @xmath can be written as a product of simple
diagrams. Also, we see that @xmath , which implies that @xmath can be
written as a product of simple diagrams, as well. By making repeated
applications of Lemma 9.1.3 , we must have @xmath can be written as a
product of simple diagrams. ∎

###### Lemma 9.2.3.

If @xmath is odd and @xmath is an admissible diagram with @xmath such
that all non-propagating edges are simple, then @xmath can be written as
a product of simple diagrams.

###### Proof.

Assume that @xmath is odd and that @xmath is an admissible diagram with
@xmath . In this case, @xmath has a unique propagating edge. Also,
assume that all of the non-propagating edges of @xmath are simple. The
proof is an exhaustive case by case check, where we consider the
possible edges that are consistent with axiom 3 of Definition 8.4.10 .
We consider five cases; any remaining cases follow by analogous
arguments.

Case (1): For the first case, assume that

  -- -- --
        
  -- -- --

where the rectangle on the propagating edge is equal to a block
consisting of an alternating sequence of @xmath @xmath decorations and
@xmath @xmath decorations. It is quickly verified that

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

This shows that @xmath can be written as a product of simple diagrams,
as desired.

Case (2): For the second case, assume that

  -- -- --
        
  -- -- --

In this case, we see that

  -- -------- --
     @xmath   
  -- -------- --

which shows that @xmath can be written as a product of simple diagrams.

Case (3): Next, assume that

  -- -- --
        
  -- -- --

where the rectangle on the propagating edge is either empty or equal to
a block consisting of an alternating sequence of @xmath @xmath
decorations and @xmath @xmath decorations, where @xmath or @xmath .
(Note that @xmath must be odd.) If the rectangle is empty, then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is as in case (1). In this case, @xmath can be written as a
product of simple diagrams. On the other hand, if the rectangle is
nonempty, so that the rectangle is equal to a block consisting of an
alternating sequence of @xmath @xmath decorations and @xmath @xmath
decorations, where @xmath or @xmath , define the admissible diagram

  -- -- --
        
  -- -- --

where the rectangle on the propagating edge is equal to a block
consisting of an alternating sequence of @xmath @xmath decorations and
@xmath @xmath decorations. By case (1), @xmath can be written as a
product of simple diagrams. If @xmath , then we see that

  -- -------- --
     @xmath   
  -- -------- --

which implies that @xmath can be written as a product of simple
diagrams, as desired. If, on the other hand, @xmath , then we see that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is as in case (1). This shows that @xmath can be written as
a product of simple diagrams.

Case (4): Now, assume that

  -- -- --
        
  -- -- --

where @xmath and the rectangle on the propagating edge is equal to a
block consisting of an alternating sequence of @xmath @xmath decorations
and @xmath @xmath decorations with @xmath . (Note that @xmath and @xmath
must be odd.) Without loss of generality, assume that @xmath , so that
@xmath or @xmath . Now, assume that the last decoration on the
propagating edge is a @xmath ; the case with the last decoration being a
@xmath is handled with an analogous argument. If @xmath (respectively,
@xmath ), then the first decoration on the propagating edge is a @xmath
(respectively, @xmath ). In either case, define the admissible diagram

  -- -- --
        
  -- -- --

where the rectangle on the propagating edge is equal to a block
consisting of an alternating sequence of @xmath @xmath decorations and
@xmath @xmath decorations. By case (3), @xmath can be written as a
product of simple diagrams. Then it is quickly verified that

  -- -------- --
     @xmath   
  -- -------- --

and so @xmath can be written as a product of simple diagrams.

Case (5): For the final case, assume that

  -- -- --
        
  -- -- --

where the rectangle on the propagating edge is equal to a block
consisting of an alternating sequence of @xmath @xmath decorations and
@xmath @xmath decorations. It is quickly seen that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are as in case (1). So, @xmath can be written as
a product of simple diagrams, as expected. ∎

Now, we make use of the previous lemmas to prove the next proposition,
which states that the admissible diagrams are generated by the simple
diagrams.

###### Proposition 9.2.4.

Each admissible diagram can be written as a product of simple diagrams.
In particular, the admissible diagrams are contained in @xmath .

###### Proof.

Let @xmath be an admissible diagram. We will show that @xmath can be
written as a product of simple diagrams. Lemma 9.1.1 , and if necessary
Lemma 9.1.2 , along with their analogues, allow us to assume that all of
the non-propagating edges of @xmath join adjacent vertices. Furthermore,
Lemmas 9.1.4 , 9.1.5 , and 9.1.6 , along with their analogues, allow us
to assume that all of the non-propagating edges of @xmath are simple. We
now consider four distinct cases: (1) @xmath , (2) @xmath , (3) @xmath
with @xmath odd (i.e., @xmath has a unique propagating edge), and (4)
@xmath with @xmath even (i.e., @xmath is undammed).

Cases (1), (2), and (3) follow immediately from Lemmas 9.2.1 , 9.2.2 ,
and 9.2.3 , respectively.

Case (4): For the final case, assume that @xmath with @xmath even. Then
@xmath is undammed and based on our simplifying assumptions, we must
have

  -- -- --
        
  -- -- --

where there are @xmath loop edges (we allow @xmath ). Define the
admissible diagram

  -- -------- --
     @xmath   
  -- -------- --

Then

  -- -- --
        
  -- -- --

In particular, @xmath is identical to @xmath , except that is has no
loop edges. If @xmath has no loop edges (i.e., @xmath ), then we are
done. Suppose @xmath . By making the appropriate repeated applications
of the left and right-handed versions of Lemmas 9.1.4 and 9.1.5 and a
single application of Lemma 9.1.6 , there exists a sequence of simple
diagrams @xmath such that

  -- -- --
        
  -- -- --

But then

  -- -- --
        
  -- -- --

To produce @xmath loops, we repeat this process @xmath more times. That
is,

  -- -------- --
     @xmath   
  -- -------- --

This shows that @xmath can be written as a product of simple diagrams,
as desired. ∎

### 9.3 More preparatory lemmas

Our immediate goal is to show that the @xmath -module @xmath is closed
under multiplication, so that it is, in fact, a @xmath -algebra. We
shall prove a few lemmas that will aid in the process.

###### Lemma 9.3.1.

Let @xmath be an admissible diagram with the following edge
configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath represents a (possibly trivial) block of decorations. Then
@xmath , where @xmath and @xmath is an admissible diagram. Moreover,
@xmath if and only if @xmath .

###### Proof.

The only case that requires serious consideration is if @xmath ; the
result follows immediately if @xmath . Assume that @xmath . Since @xmath
is admissible, @xmath . In any case, @xmath for some diagram @xmath ,
where the non-propagating edge joining node @xmath to node @xmath in
@xmath is one of the following blocks: @xmath , or @xmath . It follows
that @xmath is admissible. ∎

###### Lemma 9.3.2.

Let @xmath be an admissible diagram with the following edge
configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath represents a (possibly trivial) block of decorations. Then
@xmath , where @xmath and @xmath is an admissible diagram. Moreover,
@xmath if and only if @xmath .

###### Proof.

We consider two cases. For the first case, assume that @xmath . Since
@xmath is admissible, @xmath . (Note that @xmath only if @xmath is
undammed; otherwise @xmath would not be LR-decorated.) In either case,
@xmath produces a loop decorated with the block @xmath along with a
diagram that is identical to @xmath , except that the block @xmath has
been removed from the edge joining @xmath to @xmath . The loop decorated
with the block @xmath is equal to @xmath , unless @xmath , in which case
the loop is irreducible. Regardless, the resulting diagram is
admissible, as desired. For the second case, assume that @xmath or
@xmath . Without loss of generality, assume that @xmath , the other case
being symmetric. Since @xmath is admissible, @xmath . If @xmath , then
@xmath , as expected. If, on the other hand, @xmath (which can only
happen if @xmath is undammed), then @xmath results in an admissible
diagram that is identical to @xmath except that we add a loop decorated
by @xmath and remove the @xmath decoration from the edge connecting node
1 to node 2. ∎

###### Lemma 9.3.3.

Let @xmath be an admissible diagram with the following edge
configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath represent (possibly trivial) blocks of
decorations. Then @xmath , where @xmath and @xmath is an admissible
diagram.

###### Proof.

First, observe that @xmath has the following edge configuration at nodes
@xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath is a basis element. Note that since @xmath is
admissible, there will be at most one relation to apply in the product
@xmath , which will happen exactly when the last decoration in @xmath
and the first decoration in @xmath are of the same type (open or
closed). This implies that @xmath . If @xmath (respectively, @xmath ),
then the first (respectively, last) decoration in @xmath (respectively,
@xmath ) must be a @xmath (respectively, @xmath ) decoration.
Furthermore, if @xmath (respectively, @xmath ), then this is the only
occurrence of a @xmath (respectively, @xmath ) decoration on a
non-propagating edge in the north face of @xmath . By inspecting the
possible relations we can apply, this implies that if @xmath
(respectively, @xmath ), the first (respectively, last) decoration of
@xmath must be a @xmath (respectively, @xmath ) decoration and this is
the only occurrence of a @xmath (respectively, @xmath ) decoration on a
non-propagating edge of the diagram that results from the product @xmath
. If, on the other hand, @xmath and @xmath , then neither of @xmath or
@xmath may contain a @xmath or @xmath decoration. In this case, @xmath
will not contain any @xmath or @xmath decorations either. This argument
shows that the diagram that results from the product @xmath must be
admissible. ∎

###### Lemma 9.3.4.

Let @xmath be an admissible diagram such that @xmath with the following
edge configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath represent (possibly trivial) blocks of
decorations. Then @xmath , where @xmath and @xmath is an admissible
diagram.

###### Proof.

Note that @xmath . Since @xmath is dammed, @xmath is either equal to the
identity in @xmath or is equal to an open decoration. On the other hand,
@xmath could be equal to the identity in @xmath , a single closed
decoration, a single open decoration, or if @xmath has a unique
propagating edge, then @xmath could be an alternating sequence of open
and closed decorations. We consider two cases: (1) @xmath and (2) @xmath
.

Case (1): For the first case, assume that @xmath . In this case, there
will not be any relations to apply in the product of @xmath and @xmath
unless the first decoration on the edge joining @xmath to @xmath in
@xmath is open and @xmath is also an open decoration, in which case
@xmath will be equal to 2 times an admissible diagram, as desired.

Case (2): Now, assume that @xmath . Since @xmath is admissible, either
@xmath is trivial or the first decoration on the edge joining @xmath to
@xmath in @xmath must be closed. If @xmath is trivial, then @xmath , in
which case, @xmath is equal to a single admissible diagram. If the first
decoration is closed, then @xmath equals 2 times an admissible diagram,
as expected. ∎

###### Lemma 9.3.5.

Let @xmath be an admissible diagram such that @xmath with the following
edge configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath represent (possibly trivial) blocks of
decorations. Then @xmath , where @xmath and @xmath is an admissible
diagram with @xmath .

###### Proof.

Since @xmath , the non-propagating edge joining @xmath to @xmath is the
unique non-propagating edge in the north face of @xmath . Also, note
that @xmath , where @xmath must be odd. Furthermore, since @xmath , the
edge configuration at nodes @xmath and @xmath forces @xmath . According
to Lemma 8.3.7 , the diagram that is produced by multiplying @xmath
times @xmath has @xmath -value 1. We consider three cases: (1) @xmath ,
(2) @xmath , and (3) @xmath .

Case (1): Assume that @xmath . This implies that @xmath . Then the
possible edge configurations at nodes 1 and 2 of @xmath that are
consistent with axiom 5 of Definition 8.4.10 are as follows:

1.  [label=()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

where the rectangle represents a (possibly trivial) sequence of blocks
such that each block is a single @xmath . In any case, we see that
@xmath , where @xmath and @xmath is an admissible diagram.

Case (2): Next, assume that @xmath . In this case, since @xmath , the
restrictions on @xmath and @xmath imply that both @xmath and @xmath are
trivial. That is, the propagating edge from @xmath to @xmath and the
non-propagating edge from @xmath to @xmath are undecorated. Therefore,
it is quickly seen that @xmath for some admissible diagram @xmath .

Case (3): For the final case, assume that @xmath . This implies that
@xmath . Then the possible edge configurations at nodes @xmath and
@xmath of @xmath that are consistent with axiom 5 of Definition 8.4.10
are as follows:

1.  [label=()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

4.  ----
      []
      ----

    ;

where the rectangle represents a nontrivial sequence of blocks such that
each block is a single @xmath . In any case, we see that @xmath , where
@xmath and @xmath is an admissible diagram. ∎

###### Lemma 9.3.6.

Let @xmath be an admissible diagram such that @xmath with the following
edge configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath represent (possibly trivial) blocks of
decorations. Then @xmath , where @xmath and @xmath is an admissible
diagram.

###### Proof.

Since @xmath is LR-decorated, @xmath and @xmath cannot be of the same
type (open or closed). The only time there is potential to apply any
relations when multiplying @xmath times @xmath is if @xmath
(respectively, @xmath ) and @xmath (respectively, @xmath ) is
nontrivial. Regardless, it is easily seen that the statement of the
lemma is true. ∎

###### Lemma 9.3.7.

Let @xmath be an admissible diagram such that @xmath with the following
edge configuration at nodes @xmath and @xmath :

  -- -- --
        
  -- -- --

where @xmath and @xmath represent (possibly trivial) blocks of
decorations. Then @xmath , where @xmath and @xmath is an admissible
diagram with @xmath .

###### Proof.

According to Lemma 8.3.7 , the diagram that is produced by multiplying
@xmath times @xmath has @xmath -value strictly greater than 1. In this
case, the sequence of blocks of decorations occurring on the leftmost
(respectively, rightmost) propagating edge of @xmath will conjoin in the
product of @xmath and @xmath . This implies that @xmath for @xmath and
some diagram @xmath . To see that @xmath is admissible, we consider the
following five possibilities for @xmath ; any remaining possibilities
are analogous.

1.  [label=(0)]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

4.  ----
      []
      ----

    ;

5.  ----
      []
      ----

    ;

6.  ----
      []
      ----

    ;

where the rectangle on the leftmost (respectively, rightmost)
propagating edge represents a (possibly trivial) sequence of blocks such
that each block is a single @xmath (respectively, @xmath ). In each of
these cases, if @xmath has propagating edges joined to nodes @xmath and
@xmath in the north face, it is quickly seen that the diagram @xmath
that results from multiplying @xmath times @xmath will be consistent
with the axioms of Definition 8.4.10 since @xmath and @xmath
(respectively, @xmath and @xmath ) are equal to a power of 2 times
@xmath (respectively, @xmath ). ∎

### 9.4 The set of admissible diagrams form a basis for @xmath

The next lemma states that the product of a simple diagram and an
admissible diagram results in a multiple of an admissible diagram. The
proof relies on stringing together Lemmas 9.3.1 – 9.3.7 .

###### Lemma 9.4.1.

Let @xmath be an admissible diagram. Then

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and admissible diagram @xmath .

###### Proof.

Let @xmath be an admissible diagram and consider the product @xmath .
Observe that the possible edge configurations for @xmath at nodes @xmath
and @xmath are as follows:

1.  [label=(0)]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

4.  ----
      []
      ----

    ;

5.  ----
      []
      ----

    ;

6.  ----
      []
      ----

    ;

7.  ----
      []
      ----

    ;

8.  ----
      []
      ----

    ;

Case (1) follows from Lemma 9.3.1 and case (2) follows from a symmetric
argument. Case (3) follows from Lemma 9.3.2 . Lemma 9.3.3 yields case
(4). Case (5) follows from Lemmas 9.3.4 and 9.3.5 and case (6) follows
by a symmetric argument. Finally, Lemmas 9.3.6 and 9.3.7 prove case (7).
∎

###### Proposition 9.4.2.

The @xmath -module @xmath is a @xmath -subalgebra of @xmath .

###### Proof.

It remains to show that the product of any two admissible diagrams
results in a linear combination of admissible diagrams. According to
Proposition 9.2.4 , each admissible diagram can be written as product of
simple diagrams. It suffices to show that the product of a simple
diagram and an admissible diagram is equal to a linear combination of
admissible diagrams. But this is exactly Lemma 9.4.1 , and so we have
our desired result. ∎

We now state the main result of this chapter.

###### Theorem 9.4.3.

The @xmath -algebras @xmath and @xmath are equal. Moreover, the set of
admissible diagrams is a basis for @xmath .

###### Proof.

Propositions 9.2.4 and 9.4.2 imply that @xmath is a subalgebra of @xmath
. However, @xmath is the smallest algebra containing the simple
diagrams, which @xmath also contains since the simple diagrams are
admissible. Therefore, we must have equality of the two algebras. By
Proposition 8.4.13 , the set of admissible diagrams is a basis for
@xmath . Therefore, the set of admissible diagrams is a basis for @xmath
. ∎

## Chapter 10 Main results

We conclude this chapter with a proof that @xmath and @xmath are
isomorphic as @xmath -algebras under the correspondence induced by

  -- -------- --
     @xmath   
  -- -------- --

Moreover, we show that the admissible diagrams correspond to the
monomial basis of @xmath .

### 10.1 The homomorphism @xmath from @xmath to @xmath

###### Proposition 10.1.1.

Let @xmath be the function determined by

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath is a surjective algebra homomorphism.

###### Proof.

Checking that each of the following relations holds for the simple
diagrams is easily verified.

1.  [label=(0)]

2.  @xmath for all @xmath ,

3.  @xmath if @xmath ,

4.  @xmath if @xmath and @xmath ,

5.  @xmath if @xmath or @xmath .

That is, @xmath satisfies the relations of @xmath . This implies that
@xmath is an algebra homomorphism. Since the simple diagrams @xmath
generate @xmath , @xmath is surjective. ∎

###### Lemma 10.1.2.

Let @xmath have reduced expression @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and admissible diagram @xmath .

###### Proof.

By repeated applications of Lemma 9.4.1 , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

for some @xmath and admissible diagram @xmath . ∎

###### Remark 10.1.3.

Since @xmath is well-defined, @xmath , @xmath , and @xmath do not depend
on the choice of reduced expression for @xmath that we start with. We
will denote the diagram @xmath from Lemma 10.1.2 by @xmath . That is, if
@xmath , then @xmath is the admissible diagram satisfying

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 10.1.4.

Let @xmath be an admissible diagram. Since @xmath is surjective, there
exists @xmath such that @xmath . Suppose that @xmath has reduced
expression @xmath . Then @xmath . For each @xmath fix a concrete
representative that has straight propagating edges and no unnecessary
“wiggling” of the simple non-propagating edges. Now, consider the
concrete diagram that results from stacking the concrete simple diagrams
@xmath , rescaling to recover the standard @xmath -box, but not
deforming any of the edges or applying any relations among the
decorations. We will refer to this concrete diagram as the concrete
simple representation of @xmath (which depends on @xmath ). Since @xmath
is fully commutative and vertical equivalence respects commutation,
given two different reduced expressions @xmath and @xmath for @xmath ,
the concrete simple representations @xmath and @xmath will be vertically
equivalent. We define the vertical equivalence class of concrete simple
representations to be the simple representation of @xmath .

###### Example 10.1.5.

Consider @xmath in @xmath . Then

  -- -- --
        
  -- -- --

is vertically equivalent to the simple representation of @xmath , where
the vertical dashed lines in the figure indicate that the two curves are
part of the same generator.

###### Lemma 10.1.6.

Let @xmath be of type I. Then @xmath , where @xmath . If @xmath and
@xmath are both of type I with @xmath , then @xmath . Moreover, if
@xmath (respectively, @xmath ), then there is a simple edge joining
@xmath to @xmath (respectively, @xmath to @xmath ).

###### Proof.

This lemma follows easily from the definition of @xmath . ∎

###### Lemma 10.1.7.

Let @xmath be a non-type I irreducible element. Then @xmath , where
@xmath . If @xmath and @xmath are both non-type I irreducible elements
with @xmath , then @xmath . Moreover, if @xmath (respectively, @xmath ),
then there is a simple edge joining @xmath to @xmath (respectively,
@xmath to @xmath ).

###### Proof.

This lemma follows from definition of @xmath and the classification of
the irreducible elements in Theorem 5.1.1 . ∎

###### Remark 10.1.8.

The upshot of the previous two lemmas is that the image of a monomial
indexed by any type I element or any irreducible element is a single
admissible diagram (i.e., there are no powers of 2 or @xmath ).

Our immediate goal is to show that @xmath for any @xmath .

### 10.2 Preparatory lemmas

The next lemma is [ 26 , Lemma 2.9] .

###### Lemma 10.2.1.

Let @xmath be a Coxeter graph and let @xmath . If @xmath (respectively,
@xmath ) is defined, then @xmath (respectively, @xmath ). @xmath

###### Corollary 10.2.2.

Let @xmath . If @xmath (respectively, @xmath ) is defined, then @xmath
(respectively, @xmath ).

###### Proof.

This follows from Lemma 10.2.1 since weak star reductions (when defined)
are a special case of ordinary star reductions. ∎

We will state an “if and only if” version of the next lemma later (see
Lemma 10.2.10 ); the “only if” direction requires results that will
depend on results that we have not yet proved. We do, however, need the
“if” direction to prove Lemma 10.2.4 which follows.

###### Lemma 10.2.3.

Let @xmath . If @xmath (respectively, @xmath ), then there is a simple
edge joining node @xmath to node @xmath (respectively, node @xmath to
node @xmath ) in the north (respectively, south) face of @xmath .

###### Proof.

Assume that @xmath . Then we can write @xmath (reduced). By Lemma 10.1.2
applied to @xmath , we must have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

This implies that we obtain @xmath by concatenating @xmath on top of
@xmath . In this case, there are no relations to interact with the
simple edge from @xmath to @xmath in the north face of @xmath . So, we
must have a simple edge joining @xmath to @xmath in the north face of
@xmath .

The proof that @xmath implies that there is a simple edge joining @xmath
to @xmath is symmetric. ∎

###### Lemma 10.2.4.

Suppose @xmath is left weak star reducible by @xmath with respect to
@xmath to @xmath . Then @xmath .

###### Proof.

Since @xmath is left weak star reducible by @xmath with respect to
@xmath to @xmath , by Remark 6.4.1 , we have @xmath , where @xmath and
@xmath if and only if @xmath . This implies that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . But, on the other hand, we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where @xmath . Therefore, we have

  -- -------- --
     @xmath   
  -- -------- --

This implies that when we multiply @xmath times @xmath , we obtain a
scalar multiple of @xmath . Also, since @xmath is left weak star
reducible by @xmath with respect to @xmath , we must have @xmath .
Suppose that @xmath . By Lemma 10.2.3 , there must be a simple edge
joining @xmath to @xmath in north face of @xmath . Without loss of
generality, assume that @xmath ; the case with @xmath follows
symmetrically. Then the edge configuration at nodes @xmath , @xmath ,
and @xmath of @xmath must be as follows:

  -- -- --
        
  -- -- --

where @xmath if and only if @xmath and is trivial otherwise. Also, the
edge leaving node @xmath may be decorated and may be propagating or
non-propagating. Then multiplying @xmath on the left by @xmath , we see
that the resulting diagram has the same @xmath -value as @xmath .
Therefore, @xmath , as desired. ∎

###### Remark 10.2.5.

Lemma 10.2.4 has an analogous statement involving right weak star
reductions.

###### Lemma 10.2.6.

Let @xmath . Then @xmath if and only if @xmath is of type I.

###### Proof.

First, assume that @xmath . If @xmath is irreducible, then by Lemmas
10.1.6 and 10.1.7 , @xmath must be of type I. Assume that @xmath is not
irreducible. Then there exists a sequence of weak star reductions that
reduce @xmath to an irreducible element. By Lemma 10.2.4 , each diagram
corresponding to the elements of this sequence have the same @xmath
-value as @xmath , namely @xmath -value 1. Since the sequence of weak
star operations terminates at an irreducible element and the diagram
corresponding to this element has @xmath -value 1, the irreducible
element must have @xmath -value 1, as well (again, by Lemmas 10.1.6 and
10.1.7 ). Since weak star operations preserve the @xmath -value
(Corollary 10.2.2 ), it must be the case that @xmath was equal to 1 to
begin with. Therefore, @xmath is of type I. Conversely, if @xmath is of
type I, then according to Lemma 10.1.6 , @xmath . ∎

###### Lemma 10.2.7.

Let @xmath . Suppose that there exists @xmath with @xmath such that
@xmath does not occur between two consecutive occurrences of @xmath in
@xmath . Then one or both of the following must be true about @xmath :

1.   [label= ()]

2.  the western end of the simple representation of @xmath is vertically
    equivalent to

      -- -- --
            
      -- -- --

    where the vertical dashed lines in the figure indicate that the two
    curves are part of the same generator @xmath and the free horizontal
    arrow indicates a continuation of the pattern of the same shape.
    Furthermore, there are no other occurrences of the generators @xmath
    in the simple representation of @xmath .

3.  @xmath ;

###### Proof.

This follows immediately from Lemma 4.2.8 by applying @xmath to the
monomial indexed by the type I element @xmath . ∎

###### Lemma 10.2.8.

Let @xmath . Then the only way that an edge of the simple representation
of @xmath may change direction from right to left is if a convex subset
of the simple representation of @xmath is vertically equivalent to one
of

1.   [label= ()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

4.  ----
      []
      ----

    ;

where the vertical dashed lines in the figure indicate that the two
curves are part of the same generator @xmath and the arrows indicate a
continuation of the pattern of the same shape.

###### Proof.

An edge changing direction from right to left directly below node @xmath
indicates that there are two consecutive occurrences of the simple
diagram @xmath not having an occurrence of @xmath between them. (Note
that this forces @xmath .) If @xmath , then we must be in the situation
of Lemma 10.2.7 , in which case we have the diagram in (ii). If, on the
other hand, @xmath , then there are two possibilities. One possibility
is that there are two occurrences of @xmath occurring between the two
occurrences of @xmath . (Note that there can only be at most two
occurrences of @xmath occurring between the two consecutive occurrences
of @xmath ; otherwise we contradict Lemma 4.2.8 .) Then applying Lemma
10.2.7 to the two consecutive occurrences of @xmath forces us to have
the diagram in (iii). The second possibility is that there is a single
occurrence of @xmath between the two consecutive occurrences of @xmath .
This corresponds to the sequence @xmath , which yields the diagram in
(i). ∎

###### Remark 10.2.9.

If case (iii) from Lemma 10.2.8 occurs, then @xmath must be of type I by
Lemma 4.2.2 .

###### Lemma 10.2.10.

Let @xmath . Then @xmath (respectively, @xmath ) if and only if there is
a simple edge joining @xmath to @xmath (respectively, @xmath to @xmath )
in @xmath .

###### Proof.

First, assume that @xmath . Then by Lemma 10.2.3 there is a simple edge
joining @xmath to @xmath in the north face, as desired.

For the converse, assume that there is a simple edge joining node @xmath
to node @xmath in the north face of @xmath . We need to show that @xmath
. By Lemma 10.2.6 , if @xmath , then @xmath is of type I. In this case,
@xmath by Lemma 10.1.6 . Now, assume that @xmath . Consider the simple
representation for @xmath and let @xmath be the edge joining @xmath to
@xmath . For sake of a contradiction, assume that @xmath . Then either

1.  [label=()]

2.  it is not the case that the end of @xmath leaving node @xmath
    encounters the northernmost occurrence of @xmath before any other
    generator;

or

1.  [label=(), resume]

2.  it is not the case that the end of @xmath leaving node @xmath
    encounters the northernmost occurrence of @xmath before any other
    generator.

(We allow both (a) and (b) to occur.) Note that since @xmath crosses the
line @xmath , it must encounter @xmath at some stage. We consider three
distinct cases.

Case (1): Assume that @xmath . Then @xmath is undecorated. We deal with
case (a) from above; case (b) has a symmetric argument. Since the curve
must eventually encounter @xmath , the edge @xmath must change direction
from right to left. Then we must be in one of the three situations of
Lemma 10.2.8 . But since we are assuming that @xmath , by Remark 10.2.9
, there are only two possibilities for the edge leaving node @xmath in
the simple representation for @xmath :

1.  [label=()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    ;

where @xmath if @xmath and is trivial otherwise. Certainly, we cannot
have (i) since @xmath is undecorated and there is no sequence of
relations that can completely remove decorations from a non-loop edge.
If (ii) occurs, then it must be the case that @xmath does not occur
between two consecutive occurrences of @xmath in @xmath . Then by Lemma
10.2.7 , @xmath cannot occur again in @xmath . But this prevents the end
of @xmath leaving node @xmath to join up with the other end leaving node
@xmath , which contradicts @xmath having a simple edge joining @xmath to
@xmath .

Case (2): Assume that @xmath . Then, as in case (1), @xmath is
undecorated. We assume that @xmath ; the case with @xmath follows
symmetrically. If (a) from above happens, then we can apply the
arguments in case (1) and arrive at the same contradictions. If (b)
occurs, then the end of @xmath leaving node @xmath must immediately
encounter @xmath . This adds a @xmath decoration to @xmath , which is
again a contradiction since there is no sequence of relations that can
completely remove decorations from a non-loop edge.

Case (3): Assume that @xmath . We assume that @xmath ; the case with
@xmath follows symmetrically. Then @xmath is decorated precisely by a
single @xmath . We must be in the situation described in (a) above.
Since the curve must eventually encounter @xmath , the edge must change
direction from right to left. As in case (1), there are only two
possibilities for the edge leaving node @xmath in the simple
representation for @xmath :

1.  [label=()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    .

Either way, we arrive at contradictions similar to those in case (1).

The proof that @xmath if and only if there is a simple edge joining
@xmath to @xmath is symmetric to the above. ∎

### 10.3 Each monomial maps to a single admissible diagram

###### Proposition 10.3.1.

If @xmath , then @xmath . That is, each monomial basis element maps to a
single admissible diagram.

###### Proof.

Let @xmath . By Lemma 10.1.2 , we can write

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . We need to show that @xmath and @xmath . Since @xmath ,
there exists a sequence (possibly trivial) of left and right weak star
reductions that reduce @xmath to an irreducible element. We induct on
the number of steps in the sequence of weak star operations. For the
base case, assume that @xmath is irreducible. Then by Lemmas 10.1.6 and
10.1.7 , @xmath , which gives us our desired result. For the inductive
step, assume that @xmath is not irreducible. If @xmath is of type I,
then by Lemma 10.1.6 , @xmath . So, assume that @xmath is not of type I
(i.e., @xmath ). Without loss of generality, suppose that @xmath is left
weak star reducible by @xmath with respect to @xmath . Choose @xmath and
@xmath such that @xmath requires fewer steps to reduce to an irreducible
element. We can write: (1) @xmath (reduced) if @xmath or (2) @xmath
(reduced) if @xmath . We consider these two cases separately.

Case (1): Assume that @xmath . Without loss of generality, assume that
@xmath and @xmath with @xmath . This implies that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
                       
  -- -------- -------- --

where we are applying the induction hypothesis to @xmath ( @xmath is
left star reducible to @xmath and requires fewer steps to reduce to an
irreducible element) and we are using Lemma 10.2.10 to draw the bottom
diagram in the last line. By inspecting the product @xmath , we see that
there are no loops and no new relations to apply since @xmath is
admissible. Therefore, @xmath .

Case (2): Assume that @xmath . Without loss of generality, assume that
@xmath ; the case with @xmath is symmetric. Since @xmath (reduced) and
@xmath is fully commutative, neither @xmath nor @xmath are in @xmath .
Also, since @xmath is left weak star reducible by @xmath with respect to
@xmath to @xmath , by induction, we have @xmath . By Lemma 10.1.2 ,
there exists @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

But then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Since the product in the last line is equal to the admissible diagram
@xmath , we must have @xmath and @xmath . That is, @xmath , and a
similar argument shows that @xmath , as well. Now, we consider two
possible subcases: (a) @xmath and @xmath ; and (b) @xmath and @xmath .

(a): Assume that @xmath and @xmath . We see that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
  -- -------- -------- --

Since @xmath , by Lemma 10.2.10 , there cannot be a simple edge joining
node 1 to node 2 in the north face of @xmath . This implies that there
can be no loops in the product in the last line above, and so, @xmath .
It also implies that the edge leaving node 3 of @xmath is not exposed to
the west, and so it cannot be decorated with a closed symbol. Since
@xmath , there cannot be a simple edge joining node 2 to node 3 in
@xmath . This implies that in order for @xmath to be equal to a power of
2 times @xmath , the edge leaving node 1 in @xmath must be decorated
with a closed decoration. If the first decoration on the edge leaving
node 1 in @xmath is a @xmath , then in order to produce a power of 2 in
the product @xmath , we must have a simple edge between nodes 2 and 3,
but we have already said that this cannot happen. Suppose that the first
decoration occurring on the edge leaving node 1 in @xmath is a @xmath .
In this case, @xmath , for some admissible diagram @xmath . This
contradicts

  -- -------- --
     @xmath   
  -- -------- --

Therefore, there can be no power of 2 in the product @xmath . So, @xmath
, as desired.

(b): Now, assume that @xmath and @xmath . In this case, we see that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
                       
  -- -------- -------- --

Since @xmath , by Lemma 10.2.10 , there cannot be a simple edge joining
node 2 to node 3 in the north face of @xmath . This implies that there
can be no loops in the product in the last line above, and so, @xmath .
In order for @xmath to be equal to a power of 2 times @xmath , the edge
leaving node 1 in @xmath must be decorated with a closed decoration. For
sake of a contradiction, assume that this is the case. This implies that
if @xmath is written as a product of simple diagrams, there must be at
least one occurrence of @xmath (this is the only way we can acquire
closed decorations). Then we must have @xmath , which implies that
@xmath contains at least two occurrences of @xmath . Consider the top
two occurrences of @xmath in the canonical representation of @xmath .
Since @xmath (reduced) and @xmath is fully commutative, there must be an
entry in @xmath labeled by @xmath that covers the highest occurrence of
@xmath . By a right-handed version of Lemma 4.2.8 , we must have @xmath
as the subword of some reduced expression for @xmath . But by Lemma
4.2.2 , @xmath must be of type I. This contradicts our earlier
assumption that @xmath is not of type I. Therefore, the edge leaving
node 1 in @xmath does not carry any closed decorations. So, there can be
no power of 2 in the product @xmath , and hence @xmath , as desired. ∎

### 10.4 Proof of main result

The next lemma will be useful for simplifying the argument in the proof
of our main result (Theorem 10.4.3 ).

###### Lemma 10.4.1.

Let @xmath such that @xmath . Suppose that @xmath is left weak star
reducible by @xmath with respect to @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath .

###### Proof.

Since @xmath is left weak star reducible by @xmath with respect to
@xmath , we can write

  -- -------- --
     @xmath   
  -- -------- --

where each product is reduced. By Remark 6.4.1 , this implies that

  -- -------- --
     @xmath   
  -- -------- --

By Proposition 10.3.1 , we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Then again by Proposition 10.3.1 , there must exist @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

as desired. ∎

###### Remark 10.4.2.

Lemma 10.4.1 has an analogous statement involving right weak star
reductions.

Finally, we state our main result.

###### Theorem 10.4.3.

The map @xmath given in Proposition 10.1.1 is an isomorphism of @xmath
and @xmath . Moreover, each admissible diagram corresponds to a unique
monomial basis element.

###### Proof.

According to Proposition 10.1.1 , @xmath is a surjective homomorphism.
Also, by Proposition 10.3.1 , the image of each monomial basis element
is a single admissible diagram. It remains to show that @xmath is
injective. For sake of a contradiction, assume that @xmath is not
injective. Then there exist @xmath with @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

so that

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 10.2.10 , @xmath and @xmath .

If either of @xmath or @xmath are of type I, then according to Lemma
10.1.6 , @xmath . In this case, both @xmath and @xmath are of type I by
Lemma 10.2.6 . But then by Lemma 10.1.6 , we must have @xmath . So,
neither of @xmath or @xmath are of type I.

Now, we will argue that we may simplify the argument and assume that at
least one of @xmath or @xmath is irreducible. Suppose neither of @xmath
or @xmath is irreducible. Then there exist sequences of left and right
weak star reductions @xmath and @xmath , respectively, that reduce
@xmath to an irreducible element, say @xmath . Then

  -- -------- -- --------
     @xmath      (10.1)
  -- -------- -- --------

where @xmath . By Lemma 10.4.1 and Remark 10.4.2 , it follows that

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

for some @xmath . Since @xmath , by applying @xmath to equations 10.1
and 10.2 , we can conclude that @xmath , where @xmath is irreducible. By
making repeated applications of Lemma 6.4.4 , we see that there exists
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

which implies that

  -- -------- --
     @xmath   
  -- -------- --

That is, we can reverse the the sequences that reduced @xmath
(respectively, @xmath ) to a multiple of @xmath (respectively, @xmath ).
This shows that we may simplify the argument and assume that at least
one of @xmath or @xmath is irreducible.

Without loss of generality, assume that @xmath is irreducible. If @xmath
is also irreducible, then we must have @xmath since monomials indexed by
distinct irreducible elements map to distinct diagrams (see Lemmas
10.1.6 and 10.1.7 ). So, @xmath is not irreducible. Without loss of
generality, suppose that @xmath is left weak star reducible by @xmath
with respect to @xmath . Then we may write

  -- -------- --
     @xmath   
  -- -------- --

where each product is reduced. By Remark 6.4.1 , this implies that

  -- -------- --
     @xmath   
  -- -------- --

Note that since @xmath and @xmath , we have @xmath . Then since @xmath
is irreducible, @xmath is reduced and fully commutative. This implies
that

  -- -------- --
     @xmath   
  -- -------- --

This shows that @xmath ; otherwise, we contradict Lemma 10.4.1 . So, we
must have @xmath .

Without loss of generality, assume that @xmath and @xmath with @xmath ,
so that @xmath (reduced). By Lemma 10.2.10 , @xmath , and hence @xmath ,
has a simple edge joining node @xmath to node @xmath . For sake of
contradiction, assume that @xmath , and hence @xmath , has a simple edge
joining node @xmath to node @xmath . Then by Lemma 10.2.10 , @xmath ,
which contradicts @xmath . So, there cannot be a simple edge joining
node @xmath to node @xmath , which implies that @xmath . Since @xmath
while @xmath , @xmath cannot be of type II. Since @xmath is irreducible,
but not of type I or II, it follows from Theorem 5.1.1 that @xmath can
be written as a product of a type @xmath irreducible element times a
type @xmath irreducible element. This implies that @xmath contains a
single occurrence of @xmath and no occurrences of @xmath . Then @xmath ,
and hence @xmath , can be drawn so that no edges intersect the line
@xmath . Furthermore, there are no closed (respectively, open)
decorations occurring to the right (respectively, left) of the line
@xmath . However, we see that

  -- -------- -------- --
     @xmath   @xmath   
                       
  -- -------- -------- --

This implies that the edge leaving node @xmath in the simple
representation of @xmath must change direction from right to left. By
Lemma 10.2.8 and Remark 10.2.9 , the simple representation of @xmath
must be vertically equivalent to one of the following diagrams:

1.  [label=()]

2.  ----
      []
      ----

    ;

3.  ----
      []
      ----

    .

We cannot have the diagram in (i) since then we would have open
decorations occurring to the left of @xmath . So, we must have the
diagram in (ii). But then we are in the situation of Lemma 10.2.7 .
Since @xmath is not of type I, there are no other occurrences of the
generators @xmath in the simple representation of @xmath . This implies
that @xmath has a propagating edge connecting node @xmath to node @xmath
that is labeled by a single @xmath . By inspecting the images of
monomials indexed by non-type I and non-type II irreducible elements, we
see that none of them have this configuration. Therefore, we have a
contradiction, and hence @xmath is injective, as desired. ∎
