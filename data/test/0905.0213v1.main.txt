## Acknowledgments

First of all I would like to thank my supervisor Fay Dowker for guiding
me through this research, as well as for giving me the freedom to follow
different themes during my research. Fay has been supporting me and my
career in quantum gravity already since my time at Queen Mary in 2003.

Further, I would like to thank Jan Ambørn and Renate Loll at Utrecht
University for supervising me during my regular visits to Utrecht. With
respect to this I would like to thank the Theoretical Physics Institute
at Utrecht University for the kind hospitality during my many visits
there.

Special thanks also to my main collaborator and good friend Willem
Westra without whom my work would have been only half as enjoyable as it
was now. Thanks also to my other collaborators: Richard Gill, Romuald
Janik, David Rideout and Yoshiyuki Watabiki, as well as my friends and
colleagues at Imperial College and Utrecht University. I am also
grateful to Rafael Sorkin for stimulating discussions.

With respect to my visit in Japan I would like to thank everyone at the
Particle Physics Group at Ochanomizu University as well as at the
Theoretical High Energy Physics Group at Tokyo Institute of Technology
for the nice time we spent together. I am particularly grateful to Akio
Sugamoto and Yoshiyuki Watabiki. Many thanks also to Ishiro Oda for
inviting me to the University of the Ryukyus in Okinawa.

I would also like to thank the Niels Bohr Institute at Copenhagen
University, the Thiele Center For Applied Mathematics in Natural Science
at Ȧrhus University, the Perimeter Institute in Waterloo, the Department
of Physics at Reykjavik University, the Service de Physique Théorique at
CEA Saclay, the Institute of Physics at Jagellonian University and the
Mathematical Institute at Leiden University for hospitality during short
visits.

Financial support through ENRAGE (European Network on Random Geometry),
a Marie Curie Research Training Network in the European Community’s
Sixth Framework Programme, network contract MRTN-CT-2004-005616 as well
as through the JSPS (Japan Society for the Promotion of Science) is
kindly acknowledged. Additional financial support to visit GRG18 and
Perimeter Institute was provided through the Imperial College Trust and
Perimeter Institute.

To my family and Maru.

###### Contents

-    Abstract
-    Acknowledgments
-    1 Introduction
-    I Motivating causality: Causal sets
    -    2 Causal sets: Discrete causal geometry
        -    2.1 Introducing causal sets
        -    2.2 Towards a continuum approximation
        -    2.3 Discussion and outlook
    -    3 Entropy bounds from causal sets
        -    3.1 Entropy bounds in gravity
        -    3.2 An entropy bound from causal set theory
        -    3.3 Evidence for the claim
            -    3.3.1 The ball in Minkowski space-time
            -    3.3.2 Generalizations to different spatial
                hypersurfaces
        -    3.4 Discussion and outlook
-    II 2D causal dynamical triangulations
    -    4 Path integrals and quantum gravity
        -    4.1 Random paths and one-dimensional gravity
        -    4.2 Random surfaces and strings
        -    4.3 A path integral for quantum gravity
        -    4.4 Two-dimensional Euclidean quantum gravity and Liouville
            theory
    -    5 Two-dimensional dynamical triangulations
        -    5.1 Geometry from simplices
        -    5.2 The disc function
            -    5.2.1 Discrete solution
            -    5.2.2 Continuum limit
        -    5.3 Geodesic distance and the two-loop amplitude
            -    5.3.1 Defining geodesic distance and the two-loop
                function
            -    5.3.2 The peeling procedure
            -    5.3.3 The transfer matrix approach
        -    5.4 Physical observables
        -    5.5 Discussion and outlook to higher dimensions
    -    6 Two-dimensional causal dynamical triangulations
        -    6.1 Incorporating causality in dynamical triangulations
        -    6.2 The discrete solution
        -    6.3 The continuum limit
        -    6.4 Marked amplitudes
        -    6.5 Hamiltonians in causal quantum gravity
        -    6.6 Physical observables: Comparing CDT and DT
        -    6.7 Summary and outlook to higher dimensions
    -    7 Relating Euclidean and causal dynamical triangulations
        -    7.1 Introducing spatial topology changes: From CDT to DT
        -    7.2 Integrating out baby universes: From DT to CDT
        -    7.3 The renormalization relation
        -    7.4 Discussion and outlook
    -    8 The emergence of background geometry in two dimensions
        -    8.1 Two-dimensional Euclidean quantum gravity with
            non-compact space-time
        -    8.2 The emergence of background geometry
        -    8.3 The classical effective action
        -    8.4 Quantum fluctuations
        -    8.5 Discussion and outlook
-    III Third quantization of 2D causal dynamical triangulations
    -    9 A field theoretic perspective of spatial topology changes
        -    9.1 Taming spatial topology changes
        -    9.2 The disc amplitude
        -    9.3 The loop-loop amplitude and the consistency condition
        -    9.4 Discussion and outlook
    -    10 A causal string field theory
        -    10.1 The string field theory framework
        -    10.2 The genus zero limit
            -    10.2.1 The disc amplitude
            -    10.2.2 Inclusive amplitudes
        -    10.3 Dyson-Schwinger equations
        -    10.4 Application of the DSE
        -    10.5 Discussion
-    IV Matrix models for 2D causal dynamical triangulations
    -    11 Matrix models for two-dimensional Euclidean quantum gravity
        -    11.1 Counting triangulations with matrix models
        -    11.2 Loop equations from matrix models
        -    11.3 The loop insertion operator and higher loop amplitudes
        -    11.4 Discussion and outlook
    -    12 A loop equation and matrix model for CDT
        -    12.1 Geometrical loop equations for CDT
        -    12.2 A matrix model for generalized 2D causal quantum
            gravity
        -    12.3 Taking the continuum limit
        -    12.4 The finite time propagator
        -    12.5 Discussion and outlook
    -    13 A continuum matrix model for CDT
        -    13.1 Mapping the DSE
        -    13.2 Matrix loop equations
        -    13.3 Relation to the discrete matrix model
        -    13.4 Discussion and Outlook
    -    14 Summary and conclusions
    -    A Annexes: Causal sets
        -    A.1 Basic definitions regarding the causal structure
        -    A.2 Volume of the causal region between two events
        -    A.3 Asymptotics of the generalized hypergeometric function
    -    B Annexes: Causal dynamical triangulations
        -    B.1 Lorentzian angles and simplicial building blocks
        -    B.2 Analyzing Hamiltonians for causal quantum gravity
    -    C Curriculum Vitae

###### List of Figures

-    2.1 A so-called Hasse diagram of a partially order set. In this
    example @xmath and @xmath and hence @xmath through transitivity.
-    3.1 Illustration of a spacelike hypersurface @xmath , its boundary
    @xmath , its future domain of dependence @xmath and its future
    Cauchy horizon @xmath .
-    3.2 Shown is the expected number of maximal elements @xmath as a
    function of the total number of elements in the domain of dependence
    of the unit disk in 2+1 dimensional Minkowski space-time, on a
    logarithmic scale. Besides the analytical result and its
    asymptotics, data points with error bars from Monte-Carlo
    simulations are also shown.
-    3.3 A snapshot from a simulation showing @xmath space-time elements
    forming the domain of dependence of the two-dimensional ball in 2+1
    dimensional Minkowski space-time (illustrated in red) and @xmath
    maximal elements therein (illustrated in green).
-    3.4 Shown is the expected number of maximal elements @xmath as a
    function of the total number of elements in the domain of dependence
    of the 3-dimensional unit ball in 3+1 dimensional Minkowski
    space-time on a logarithmic scale. The plot shows the analytical
    result, its asymptotics, and numerical results from Monte-Carlo
    simulation.
-    3.5 Shown is the plot of the number of maximal elements @xmath as a
    function of the total number of elements in the domain of dependence
    of the 4-dimensional ball in 4+1 dimensional Minkowski space-time on
    a logarithmic scale, its asymptotics, and numerical results.
-    3.6 Shown is the plot of the fundamental length scale @xmath in
    Planck units ( @xmath ) as a function of the dimensions @xmath for
    even and odd dimensions and the analytic continuation.
-    3.7 Illustration of the different hyperbolic spherically symmetric
    spatial hypersurfaces @xmath parameterized by @xmath , and the
    domain of dependence @xmath .
-    3.8 Shown is the plot of the expected number of maximal elements
    @xmath in the domain of dependence as a function of the length of
    the boundary @xmath for different hyperbolic spherical symmetric
    spacelike hypersurfaces parameterized by @xmath in 2+1 dimensional
    Minkowski space-time. One sees that all functions approach the same
    asymptotic @xmath .
-    3.9 Shown is the plot of the expected number of maximal elements
    @xmath as a function of the length of the boundary @xmath for
    different hyperbolic spherical symmetric spacelike hypersurfaces in
    3+1 dimensional Minkowski space-time parameterized by @xmath . One
    sees that all functions approach the same asymptotics @xmath .
-    4.1 Illustration of the path integral for a one-dimensional
    relativistic quantum mechanical problem, e.g. a propagating
    particle. One possible path of the configuration space (path space)
    is drawn. The “virtual” particle is propagating from @xmath to
    @xmath in a piecewise linear path of @xmath steps each of size
    @xmath .
-    4.2  (a) A worldline parametrized by @xmath is embedded into @xmath
    by the mapping @xmath . (b) Analogous to the worldline a
    two-dimensional worldsheet of a closed string parametrized by @xmath
    and @xmath is embedded into @xmath by the mapping @xmath .
-    5.1 Illustration of a positive (a) and negative (b) deficit angle
    @xmath at a vertex @xmath .
-    5.2 Shown is a triangulation and its dual triangulation (dashed
    line). Highlighted is a vertex @xmath of the triangulation and its
    dual cell of volume @xmath .
-    5.3 Shown is a regular triangulation with topology of the disc
    @xmath and a unrestricted triangulation with topology of a disc
    @xmath .
-    5.4 Elementary decomposition moves: If the marked edge on the
    boundary belongs to a triangle this triangle is removed @xmath , if
    the mark corresponds to a double link the double link is removed and
    the triangulation splits into two @xmath .
-    5.5 Graphical representation of the loop equation ( 5.10 ) for the
    disc function.
-    5.6 A rooted branched polymer created by gluing double links with
    one marked link.
-    5.7 Fixed geodesic distance two-loop amplitude @xmath .
-    5.8 Decomposition of the triangulation for the fixed geodesic
    distance two-loop amplitude by a peeling procedure .
-    5.9 The peeling decomposition moves are the same as already used in
    the loop equation for the disc function (recall Fig. 5.5 ): If the
    marked edge on the initial loop belongs to a triangle the triangle
    is removed. If it belongs to a double link then the double link is
    removed causing the triangulation to split. The off-splitting part
    of the triangulation with the final loop has topology of a cylinder,
    whereas the other part has topology of a disc.
-    5.10 Graphical illustration of the composition law ( 5.60 ) for the
    fixed geodesic distance two-loop amplitude.
-    5.11 A typical quantum geometry of two-dimensional Euclidean
    quantum gravity [ 1 ] .
-    5.12 The phase diagram of four-dimensional Euclidean quantum
    gravity defined through DT.
-    6.1 Section of a two-dimensional Lorentzian triangulation
    consisting of spacetime strips of height @xmath . Each spatial slice
    is periodically identified, such that the simplicial manifold has
    topology @xmath . One sees that the lower strip with initial
    boundary length @xmath and final boundary length @xmath consists
    exactly of @xmath up-pointing triangles and @xmath down-pointing
    triangles.
-    6.2 A typical two-dimensional Lorentzian space-time. The
    compactified direction shows the spatial hypersurfaces of length
    @xmath and the vertical axis labels proper time @xmath .
    Technically, the picture was generated by a Monte-Carlo simulation,
    where a total volume of @xmath triangles and a total proper time of
    @xmath steps was used. Further, initial and final boundary has been
    identified.
-    7.1 Illustration of the double light cone causal structure at a
    Morse point in an up-side down trousers geometry.
-    7.2 Illustration of the one-step propagator with an off-splitting
    “baby universe”.
-    7.3 Decomposition of the disc function with a marked point in the
    bulk into a propagator with arbitrary time and a disc function with
    a mark on the boundary.
-    7.4 @xmath At every point in the quantum geometry there is an
    infinitesimal baby universe. @xmath When trying to draw the baby
    universes on a plane one is forced to draw smaller and smaller
    triangles reflecting the fractal structure of the geometry.
-    7.5 Illustration of the peeling relation ( 7.36 ). In each step of
    the decomposition either a triangle is removed or a double link
    which results into an off-splitting of a branched polymer.
-    9.1 Feynman rules: @xmath shows a vertex of @xmath -theory which is
    assigned a coupling @xmath . @xmath shows the analogous interaction
    term for a splitting string. Similar to @xmath -theory we assign a
    string coupling @xmath to this interaction.
-    9.2 In all four graphs, the geodesic distance from the final to the
    initial loop is given by @xmath . Differentiating with respect to
    @xmath leads to eq. ( 9.8 ). Shaded parts of graphs represent the
    full, @xmath -dependent propagator and disc amplitude, and
    non-shaded parts the CDT propagator.
-    9.3 Graphical illustration of eq. ( 9.10 ). Shaded parts represent
    the full disc amplitude, unshaded parts the CDT disc amplitude and
    the CDT propagator.
-    9.4 Two different ways of decomposing the loop-loop amplitude into
    proper-time propagators and a disc amplitude. Two points touch in
    the disc amplitude @xmath , pinching the boundary to a figure-8,
    which combinatorially implies a substitution @xmath in the formulas.
    The time variables are related by @xmath .
-    10.1 The elementary terms of the string field theory Hamiltonian (
    10.10 ): (a) the single spatial universe propagator, (b) the term
    corresponding to splitting into two spatial universes, (c) the term
    corresponding to the merging of two spatial universes and (d) the
    tadpole term.
-    11.1 Building blocks for Feynman graphs: (a) the scalar propagator
    and (b) the scalar three-point vertex.
-    11.2 Building blocks for fat-graphs: (a) the Hermitian matrix
    propagator and (b) the Hermitian matrix three-point vertex.
-    11.3 The contour @xmath encloses counterclockwise the cut @xmath
    but not @xmath .
-    12.1 Illustration of the two composition moves to add a triangle.
    The white dot on the right-hand-side shows the position of the mark
    before the triangle was added whereas the black dot shows the mark
    after the triangle was added.
-    12.2 Graphical representation of the loop equation ( 12.2 ).
-    12.3 Graphical representation of the loop equation ( 12.8 ).
-    B.1 Illustration of a space-like (a) and a time-like (b) Lorentzian
    deficit angle @xmath at a vertex @xmath .

] ] ]

### Chapter 1 Introduction

Finding a consistent theory of quantum gravity is a notoriously hard
problem. Such a theory should give a fundamental quantum description of
space-time geometry with general relativity as a classical limit.
However, more than ninety years have passed since Einstein’s discovery
of general relativity, and still very little is known about the ultimate
structure of space-time at very small scales.

Quantum field theory one the other hand has proven to be a marvelously
successful way to describe three of the four fundamental forces of
nature: the electro-magnetic, the weak and the strong force. For the
gravitational force however one does not have a well-defined predictive
quantum field theoretic description yet, but one does have a very
successful classical field theoretic description in the form of
Einstein’s theory of general relativity. Since the other forces can be
described by quantum field theories, it seems natural that there also
exists a quantum theory for the gravitational field.

Another reason which supports the existence of such a theory of quantum
gravity is the fact that gravity couples to all forms of energy. Hence,
one expects the energy fluctuations at small distances due to
Heisenberg’s uncertainty relations to induce also quantum fluctuations
in the gravitational field. This leads to the prediction that space-time
geometry has a highly non-trivial microstructure at extremely small
scales close to the Planck length, @xmath .

There are however obvious problems in constructing a quantum theory of
general relativity (see [ 2 ] for an overview). It has already been
shown in the seventies by ’t Hooft and Veltman that perturbative quantum
gravity is non-renormalizable in four dimensions [ 3 ] . There are
several ways to confront this problem:

One of the most prominent approaches to quantum gravity is string theory
(see standard text books [ 4 , 5 , 6 , 7 ] ). In this unifying theory
the worldlines of propagating particles are replaced by worldsheets of
propagating strings. The issue of non-renormalizability is thought to be
resolved from the start in string theory, since the point-like
interactions which cause the divergencies are replaced by extended
interactions which cannot be localized. Whereas string theory has
recently had some successes such as the calculation of strongly coupled
gauge theories using the AdS/CFT correspondence (see for instance [ 8 ]
), as a theory of quantum gravity it still relies on supersymmetry and
extra dimensions.

Another approach is loop quantum gravity [ 9 , 10 ] in which one uses a
Dirac (constraint) quantization [ 11 ] of Ashtekar’s connection
variables [ 12 ] . Recent advances in this approach have been made by
use of covariant spin-foam models [ 10 , 13 ] . These approaches suggest
that the ultraviolet divergences can be resolved by the existence of a
minimal length scale, commonly expressed in terms of the Planck length
@xmath . Finiteness of gravitational entropy can be seen as evidence for
such fundamental discreteness of space-time.

A more radical approach is causal set theory [ 14 , 15 ] which
postulates fundamental discreteness from the outset. In this approach
discrete sets of space-time events are viewed as fundamental objects
underlying continuum space-times. Even though some interesting
phenomenological models using causal sets have been proposed, there has
been little progress in formulating a quantum path integral for causal
sets.

There are other approaches which define quantum gravity
non-perturbatively. Renormalizability of the non-perturbative theory
could be achieved by a nontrivial fixed point scenario as described by
Weinberg [ 16 ] . One possible example of such a scenario is the exact
renormalization group flow method for Euclidean quantum gravity in the
continuum [ 17 ] .

Another famous attempt to non-perturbatively define quantum gravity is
dynamical triangulations (DT), a covariant path integral formulation, in
which quantum gravity is obtained as a continuum limit of a
superposition of simplicial space-time geometries (see for instance [ 18
] ). Two-dimensional DT has also been used as a worldsheet
regularization of the bosonic string. A particular strength of this
approach is that it expresses the theory as a statistical sum over
entirely geometric objects. Since the path integral assigns a
probability to each contributing geometry, we also call it a model of
random geometry. To perform the statistical sum one usually starts off
in the Euclidean sector including many “acausal” geometries. This leads
to unappealing features of the quantum geometries in dimensions higher
than two. It can be shown within the approach of causal dynamical
triangulations (CDT) that causality is essential to regulate this
pathological behaviour. In CDT one starts off with a sum over Lorentzian
geometries and then analytically continues to the Euclidean sector to
perform the summation [ 19 ] . Numerical simulations indicate that CDT
in contrast to DT leads to a well-behaved continuum limit in four
dimensions [ 20 , 21 ] .

In this thesis we focus on the implementation of causality in models of
random geometry.

In Part I of this thesis we concentrate on the approach of causal sets.
In Chap. 2 causal sets are introduced as a simple and instructive model
of causal random geometry. After defining causal sets we show how they
can correspond to continuum space-times in the continuum approximation.
Although we are not able to define a path integral for causal sets, we
describe a simple phenomenological model where causal sets are randomly
embedded in a fixed space-time. From this model we show in Chap. 3 how
causal sets could account for the microscopic origin of the Bekenstein
or Susskind entropy bound.

It seems that to define random geometry in terms of a non-perturbative
path integral over geometries more structure is needed. Such structure
is provided by causal dynamical triangulations (CDT) on which we focus
in Part II, III and IV of this thesis.

Part II gives an introduction to CDT as a model of causal quantum
gravity with emphasis on analytical results in two dimensions. In Chap.
4 we give a brief introduction into path integrals in general with
emphasis on the gravitational path integral. In Chap. 5 we introduce
dynamical triangulations (DT) as a non-perturbative definition of the
path integral for two-dimensional Euclidean quantum gravity. At the end
of this chapter we comment on the problems one encounters in
higher-dimensional DT. In the next chapter, Chap. 6 , CDT are introduced
as a model of two-dimensional causal quantum gravity. A comparison to
the Euclidean model (DT) is given as well as a brief outlook to results
in higher dimensions. In Chap. 7 several relations between DT and CDT in
two dimensions are discussed. In particular, we describe how CDT and DT
can be related by respectively introducing or “integrating out” baby
universes, i.e. spatial topology changes. In Chap. 8 we discuss CDT for
the case of non-compact geometries. We see how a semi-classical
background emerges from quantum fluctuations yielding a simple model of
two-dimensional quantum cosmology.

In Part III we introduce a generalized CDT model. This is formulated as
a third quantization of two-dimensional CDT, i.e. a model in which
spatial universes or strings can be annihilated and created from the
vacuum. In Chap. 9 we show how by introducing a coupling constant to the
process of off-splitting baby-universes one can non-perturbatively solve
for the disc function with an arbitrary number of baby-universes. In
Chap. 10 this result is embedded in the framework of a string field
theory (SFT) model of CDT. As an application of the resulting
Dyson-Schwinger equations (DSE) of the SFT we calculate amplitudes of
higher genus.

The last Part IV deals with the development of matrix models for CDT.
After a brief introduction to matrix models in the context of DT in
Chap. 11 , we formulate a matrix model description for the contributing
triangulations in CDT in Chap. 12 . In the continuum limit one recovers
the results of the generalized CDT model introduced in Chap. 9 giving a
combinatorial interpretation of this model. In Chap. 13 we show that
also the continuum CDT model is described by a matrix model. This is
particularly interesting, since contrary to DT the size of the matrices
@xmath does not have to scale with the cut-off in the so-called double
scaling limit. Further, the expansion in @xmath reorganizes the power
expansions in terms of topology, where terms with powers @xmath can be
identified with the continuum surfaces of genus @xmath . This makes the
new matrix model much closer to the original proposal by ’t Hooft for
QCD than the conventional matrix models of non-critical string theory.

In Chap. 14 we conclude this thesis by summarizing the results. Further,
we comment on possible applications of the newly discovered matrix model
to simple matter coupling in CDT. Interestingly, it might be possible to
give a simple derivation of the Onsager exponents from CDT.

Finally App. A and B provide supplementary information to the chapters
on causal sets and causal dynamical triangulations respectively.

Most of the novel results of this thesis have been published in research
articles. In particular, the following chapters are based on the
following articles:

-   Chapter 3 on D. Rideout and S. Zohren, Class. Quantum Grav. 23
    (2006) 6195–6213 ;

-   Chapter 8 on J. Ambjørn, R. Janik, W. Westra, and S. Zohren, Phys.
    Lett. B 641 (2006) 94–98 ;

-   Chapter 9 on J. Ambjørn, R. Loll, W. Westra, and S. Zohren, JHEP
    0712 (2007) 017 ;

-   Chapter 10 on J. Ambjørn, R. Loll, W. Westra, Y. Watabiki and
    S. Zohren, JHEP 0805 (2008) 032 ;

-   Chapter 12 on J. Ambjørn, R. Loll, W. Westra, Y. Watabiki and
    S. Zohren, Phys. Lett. B 670 (2008) 224-230 ;
    idem , to appear in Acta Phys. Polon. B 39  (2008) 3355-3364.

-   Chapter 13 on J. Ambjørn, R. Loll, W. Westra, Y. Watabiki and
    S. Zohren, Phys. Lett. B 665 (2008) 252–256 .

The remaining chapters are mainly introductory parts which review
existing literature. These are included to make the thesis
self-contained, but do not represent new work done by the author of this
thesis.

## Part I Motivating causality: Causal sets

### Chapter 2 Causal sets: Discrete causal geometry

In this chapter we introduce causal sets as a simple model of causal
random geometry. After giving a mathematical definition of causal sets
we show how those can correspond to continuum space-times in the
continuum approximation. Even though we are not able to define a path
integral for causal sets we describe a simple phenomenological model
where causal sets are randomly embedded in a fixed space-time [ 14 ] .
In the next chapter we will use this model to give a microscopic
understanding of the Susskind or Bekenstein entropy bound.

#### 2.1 Introducing causal sets

Causal order suggests itself as a fundamental principle for quantum
gravity because of the enormous amount of topological and geometrical
information which it contains [ 15 ] .

There are several reasons to support the assumption of causal structure
as primary in quantum gravity. It has been shown that, given merely the
causal relations of events in a space-time manifold, one needs only the
volume measure to recover the full geometry in the continuum [ 22 , 23 ]
.

Being faced with the non-renormalizability of perturbative quantum
gravity in four dimensions ’t Hooft already proposed in 1978 several
radical ideas to possibly define a theory of quantum gravity [ 24 ] , of
which one was to view quantum gravity as a theory of causal sets of
space-time events (see also [ 25 ] ). This idea was later picked up
again by Bombelli et al. [ 14 ] and further developed by many others to
what is sometimes referred to as causal set theory (see for instance [
26 , 27 ] for some reviews).

Mathematically speaking, a causal set is defined to be a locally finite
partially ordered set @xmath , namely a set @xmath together with a
relation @xmath , called “precedes”, which satisfy the following axioms:

###### Transitivity:

If @xmath and @xmath then @xmath , @xmath ;

###### Irreflexivity:

@xmath ;

###### Local Finiteness:

For any pair of fixed elements @xmath and @xmath of @xmath , the set of
elements lying between @xmath and @xmath is finite, @xmath , where
@xmath means the cardinality of the set @xmath .

Fig. 2.1 shows a graphical representation of a causal set as an example.
Of these axioms, the first two say that @xmath is a partially ordered
set or poset. The last expression, local finiteness, is related to the
“radical idea” of this approach, namely that space-time is fundamentally
discrete. The motivation for introducing fundamental discreteness is
that it provides us with a way to account for the missing volume
information. However, from a phenomenological point of view there are
also other reasons, for example the finiteness of gravitational entropy
which suggests that space-time might be fundamentally discrete.

In the following we summarize some basic definitions for intrinsic
causal set quantities of which most are “discrete” versions of analogous
concepts used to describe the causal structure of continuum space-times
(cf. App. A.1 ).

The past of an element @xmath is the subset @xmath . This corresponds to
the causal past @xmath in the continuum approximation. The past of a
subset of @xmath is the union of the pasts of its elements. The future
of an element @xmath is the subset @xmath which respectively corresponds
to the causal future @xmath in the continuum approximation.

An important concept for the formulation of the entropy bound from
causal set theory is that of a maximal element in a causal set @xmath .
This is an element which has no successors, i.e. an element @xmath for
which @xmath such that @xmath . The set of all maximal elements in
@xmath is denoted by @xmath . In analogy, a minimal element is one which
has no ancestors, i.e. an element @xmath for which @xmath such that
@xmath and the set of all minimal elements in @xmath is denoted by
@xmath .

#### 2.2 Towards a continuum approximation

Having given the precise definition of a causal set one might ask the
questions: How could one actually be able to formulate a theory of
quantum gravity using causal sets, and how do causal sets relate to the
known classical notion of smooth Lorentzian manifolds? In the following
we give a definition of what it means for a causal set @xmath to be
approximated by a Lorentzian space-time @xmath .

Consider a strongly causal space-time @xmath . The map @xmath from a
causal set @xmath into a space-time @xmath is called a conformal
embedding if @xmath . Consider the Alexandrov neighborhood @xmath , for
every @xmath , which forms a basis for the manifold topology of @xmath
if @xmath is strongly causal, which we assume throughout. sprinkling The
map @xmath is called a faithful embedding or sprinkling if it has the
following property: The number of elements @xmath mapped into an
Alexandrov neighborhood is equal to its space-time volume @xmath times
the space-time density, up to Poisson fluctuations. Thus, the
probability of finding @xmath elements in this region is given by the
Poisson distribution

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath is the density set by the fundamental length scale @xmath
in @xmath dimensions. In other words, this means that in a space-time
region of volume @xmath one finds on average @xmath elements of the
causal set embedded into this region, and the fluctuations are typically
of the order @xmath . Further, the properties of the Poisson
distribution lead to local Lorentz invariance in the continuum
space-time [ 28 , 29 ] .

Using the above definitions, we say that a space-time @xmath
approximates a causal set @xmath if there exists a faithful embedding of
@xmath into @xmath . This notion gives a correspondence between causal
sets and continuum space-times. In terms of this correspondence
continuum causal structure arises from the microscopic order relations
of the causal set elements and the continuum volume measure of a region
arises from counting the number of elements comprising this region.
Nevertheless, one still has to prove the uniqueness of this
correspondence (up to small fluctuations). In general the precise
formulation of such a uniqueness proof is a difficult mathematical
problem. However, it has been proven to hold for the limiting case
@xmath [ 30 ] and certain progress has been made in the generalization
to large but finite @xmath [ 31 ] .

#### 2.3 Discussion and outlook

The ultimate aim of causal set theory is to formulate a theory of
quantum gravity using a path integral approach, where the single
histories are causal sets. Continuum physics would then be supposed to
emerge in a suitable continuum approximation. However, since there is
basically no information on spatial distances of space-time events,
there is no obvious way to find a discretized version of the
gravitational action in this context. And even if such an action would
be found it is not clear how the sum over different causal sets in the
path integral could be performed.

A different path in the search for causal set dynamics has been taken by
analyzing certain sequential growth models of the causal sets [ 32 , 33
, 34 , 35 ] . These growth models aimed to determine an effective
classical dynamics of causal sets. One interesting result is that the
“early universe” phase of such growth models closely resembles de Sitter
space, at least in the way that volumes of causal intervals scale with
their length [ 36 ] .

From the above discussion we can say that it is still very ambitious to
view causal sets as a model for quantum gravity, but nevertheless, it
still gives a very simple and instructive model of causal random
geometry. In particular, we can take a fixed Lorentzian space time and
view it as a continuum approximation of a causal set. Using the Poisson
distribution, as mentioned in the previous section, we are then able to
randomly draw causal sets which can be faithfully embedded in this
space-time. From a phenomenological point of view we can now study
certain properties of such an ensemble, as will be done in the next
chapter with view on entropy bounds. Even though some of these
phenomenological models give interesting predictions [ 37 , 28 , 38 , 39
, 40 ] , one should still treat them with a bit of care for the
following reason: Already in the case of a quantum mechanical particle
we know that even though the classical path is smooth and nice, single
histories of the path integral look nothing like this and are not even
described by differentiable functions. Hence, it is not a priori clear,
that classical space-times should approximate a single causal sets
history. Keeping this in mind we use causal sets as a phenomenological
model of fundamentally discrete space-time.

### Chapter 3 Entropy bounds from causal sets

In this chapter we propose a measure for the maximal entropy of
spherically symmetric spacelike space-time regions in terms of the
ensemble of causal sets approximating this continuum space-time [ 39 ,
41 ] . A bound for the entropy contained in this region is obtained from
a counting of potential “degrees of freedom” associated to the Cauchy
horizon of its future domain of dependence. For different spherically
symmetric spacelike regions in Minkowski space-time of arbitrary
dimension, we show that this proposal leads, in the continuum
approximation, to Susskind’s or Bekenstein’s well-known spherical
entropy bound up to a numerical factor.

#### 3.1 Entropy bounds in gravity

In the history of general relativity there has been a long discussion
regarding the thermodynamics of gravitational systems. One of the most
famous examples is the Bekenstein-Hawking formula for black hole entropy
[ 42 , 43 , 44 , 45 ] , stating that the entropy of a black hole is
given by a quarter of the area of the event horizon in Planckian units ¹
¹ 1 As a convention we will throughout the discussion regarding entropy
bounds work in Planck units with

@xmath

where @xmath denote the speed of light, Boltzmann’s constant, Newton’s
constant and Planck’s constant respectively. In these units the Planck
length is given by

@xmath

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

This bound is truly universal, meaning that it is independent of the
characteristics of the matter system and can be derived without any
knowledge of the actual microstates of the quantum statistical system.

Along this line there have been several generalizations of this entropy
bound. One is Susskind’s spherical entropy bound [ 46 ] , stating that
the upper bound for the entropy of the matter content of an arbitrary
spherically symmetric spacelike region (of finite volume) is,

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

where @xmath is the area of the boundary of the region. ² ² 2 There was
an earlier proposed bound by Bekenstein [ 47 ] stating that the entropy
of any weakly gravitating matter system obeys @xmath , where @xmath is
the energy of the matter system and @xmath the circumferential radius of
the smallest sphere that contains it. If one further assumes that this
bound is valid for strongly gravitating matter systems, then
gravitational stability in four dimensions implies that @xmath and hence
@xmath . One sees that in four dimensions the Bekenstein bound is
stronger then the Susskind bound, however, in @xmath gravitational
stability and the Bekenstein bound only imply that @xmath [ 48 ] .
Hence, the geometrical Susskind bound is arguably more fundamental. Even
though this spacelike entropy bound cannot be generalized to arbitrary
non-spherically symmetric spacelike regions, there exists a
generalization in terms of light-sheets, namely the Bousso or covariant
entropy bound [ 49 , 50 ] . More precisely, let @xmath be the area of
any @xmath -dimensional surface @xmath , then the @xmath dimensional
hypersurface @xmath is called the light-sheet of @xmath if @xmath is
generated by light rays which begin at @xmath , extend orthogonally away
from @xmath and have everywhere non-negative expansion. The entropy flux
through the light-sheet is then bounded by

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

This entropy bound is also widely regarded as evidence for the
holographic principle [ 51 , 46 , 50 ] , stating that the maximum number
of degrees of freedom carried by @xmath is given by @xmath .

These entropy bounds suggest that an underlying theory of quantum
gravity should predict the bounds from a counting of microstates (see
for example [ 52 ] ). This verification of the thermodynamic laws is an
important consistency check for any approach to quantum gravity.
Further, the finiteness of the entropy might already give some
indications about the actual microstructure of space-time. There is a
semi-classical argument that the description of a quantum theory of
gravity by a local quantum field theory in the continuum, in the absence
of a high frequency cut-off, leads to infinitely many degrees of freedom
in a finite region, and therefore to a divergence in the entropy of this
region [ 38 , 53 ] . The entropy bounds therefore suggest that
space-time might posses a fundamental discreteness at scales of order of
the Planck scale. Continuum physics would then have to emerge from this
fundamental theory when making a continuum approximation at large
scales. This suggests that to obtain a theory of quantum gravity one
does not have to quantize the metric fields of the continuum geometries,
but should rather find a quantum theory of the discrete structure
underlying those continuum geometries [ 54 ] .

In the following we show how using causal sets as a phenomenological
model of causal random geometry one can derive a notion of maximum
entropy from a counting of potential horizon “degrees of freedom” of the
fundamental theory reminiscent of former ideas in the context of black
hole entropy [ 55 , 38 ] . Using this measure we formulate an entropy
bound for spherically symmetric spacelike regions within the causal set
approach. We then show that in the continuum approximation, for
different spherically symmetric spacelike regions in Minkowski
space-time of arbitrary dimension, this leads to Susskind’s spherical
entropy bound up to a numerical factor.

#### 3.2 An entropy bound from causal set theory

In the previous chapter we introduced causal sets as a phenomenological
model of causal random geometry. As explained earlier space-time volume
arises from a counting of fundamental space-time elements. In the
following we show how entropy bounds could arise from a counting of
potential horizon “degrees of freedom” at the fundamental level, giving
a microscopic origin for Susskind’s spherical entropy bound.

As already mentioned in the previous section, the spherical entropy
bound states that the entropy of the matter content of a spherically
symmetric spacelike region @xmath (of finite volume) is bounded by a
quarter of the area of the boundary of @xmath in Planck units

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

in full units @xmath , where @xmath is the area of the boundary of this
region.

Surprisingly, the maximum entropy in ( 3.4 ) can be determined without
any knowledge of the microscopic properties of the thermodynamic system.
A theory of quantum gravity however should be able to deduce ( 3.4 )
purely from a counting of the fundamental degrees of freedom at the
microscopic level. (One may wonder in what manner a counting of degrees
of freedom measures the entropy of a system. In a discrete context
“degrees of freedom” are generally finite, and a state counting can be
expected to yield something proportional to the exponential of the
number of degrees of freedom. Thus measuring the entropy as the
logarithm of the number of states can be seen to be equivalent to
counting the number of degrees of freedom of the system.) In the
following we want to give a notion of those fundamental degrees of
freedom in the context of causal set theory leading to the formulation
of an entropy bound within this approach.

Consider a spherically symmetric spacelike region of space-time,
potentially containing some matter system. We assume that the “back
reaction” of the matter content upon the space-time geometry can be
neglected, so that different states of the matter system lead to the
same spherically symmetric space-time geometry. The entropy of that
system must eventually “flow out” of the region by passing over the
boundary of its future domain of dependence. But because space-time is
fundamentally discrete, the amount of such entropy flux is bounded above
by the number of discrete elements comprising this boundary. This is a
fundamental limit imposed by discreteness on the amount of information
flux which can emerge from the region, and therefore on the amount of
entropy which it can contain. Thus we have argued that an entropy bound
arises from causal sets.

Proposal Consider a spherically symmetric spacelike hypersurface @xmath
of finite volume in a strongly causal space-time @xmath of dimension
@xmath . Denote the future domain of dependence of this hypersurface by
@xmath (c.f. App. A.1 and Fig. 3.1 ). Let @xmath be a causal set which
can be faithfully embedded into @xmath . Then the maximum entropy
contained in @xmath is given by the number of maximal elements of @xmath
,

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

Claim This proposal leads to Susskind’s entropy bound in the continuum
approximation,

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

where @xmath is the area of the boundary of this region @xmath , if the
fundamental discreteness scale is fixed at a dimension dependent value
to be calculated.

#### 3.3 Evidence for the claim

In this section we provide analytical and numerical evidence for the
claim that the entropy bound ( 3.5 ) leads to Susskind’s bound in the
continuum. In all discussed examples we consider @xmath -dimensional
spherically symmetric spacelike hypersurfaces @xmath in @xmath
-dimensional Minkowski space @xmath , and calculate the number of
maximal elements in its domain of dependence @xmath . Since we assume
that @xmath arises as a continuum approximation of a causal set @xmath ,
we know from the phenomenological model described above that the
elements of @xmath are faithfully embedded into @xmath according to the
Poisson distribution ( 2.1 ). Hence the expected number of maximal
elements in @xmath is given by

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

where again @xmath is the fundamental density of space-time. On the
right-hand-side of ( 3.7 ) one integrates over all points @xmath , where
every point is first weighted by the probability of finding an element
of @xmath embedded at this point and further weighted by the probability
of not finding any other element of @xmath embedded in @xmath . Note
that because of the fundamentally random nature of the
discrete-continuum correspondence in causal sets we calculate the
expected number of maximal elements in a sprinkling, even though the
proposal ( 3.5 ) is phrased in terms of a fixed causal set.

##### 3.3.1 The ball in Minkowski space-time

In this section we want to calculate the expected number of maximal
elements @xmath in @xmath , where @xmath is chosen to be a @xmath
-dimensional ball @xmath with radius @xmath in Minkowski space-time
@xmath . Due to the spherical symmetry of the problem it is useful to
introduce spherical coordinates @xmath , where we choose the origin to
be the futuremost event of @xmath . The volume element @xmath is equal
to the volume of the Alexandrov neighborhood of @xmath and @xmath ,
@xmath , where we denote proper time by @xmath . Using the result for
@xmath as calculated in App. A.2 and integrating out the spherical
symmetry in ( 3.7 ) one obtains a general expression for the expected
number of maximal elements in @xmath ,

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

where the dimension dependent constant @xmath is defined in App. A.2 .

In the following we evaluate ( 3.8 ) for various dimensions by
analytical and numerical methods.

###### 2+1 dimensions

In @xmath dimensions one can explicitly evaluate ( 3.8 ). It is useful
to express the result in terms of the expected total number of
space-time elements faithfully embedded into @xmath , @xmath , where
@xmath is the volume of the domain of dependence @xmath . The expected
number of maximal elements is

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

where @xmath is the exponential integral defined by

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

We also measured the expected number of maximal elements numerically by
“sprinkling” a causal set into a 2+1-dimensional @xmath square box,
which contains @xmath . By sprinkling we mean simply selecting @xmath
elements at random with uniform distribution within the box, and
computing the causal relation between each pair from the Minkowski
metric. For each of 100 trials @xmath , we deduce the set of elements
which fall within @xmath , compute its cardinality @xmath , and count
the number of such elements @xmath which are maximal within that region.
From these we compute the sample mean and its error, and repeat this
computation for a range of values of @xmath . These computations were
greatly facilitated by utilizing causal set and Monte-Carlo toolkits
within the Cactus computational framework [ 56 ] .

The plot of the expected number of maximal elements @xmath as a function
of @xmath for the unit disk is shown in Fig. 3.2 , on a logarithmic
scale. The agreement of analytical and numerical results justifies the
numerical methods.

For a large number of elements @xmath we can use the asymptotic
expansion of the exponential integrals

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

yielding

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

where @xmath are lower order terms in @xmath . The asymptotics are also
displayed in Fig. 3.2 together with the full expression for the expected
number of maximal elements. In terms of the density @xmath and the
radius @xmath of @xmath this result reads

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

up to lower order corrections. It is important to see that @xmath ,
where @xmath is the length of the boundary of @xmath . This is highly
non-trivial, as one can see by looking at a snapshot of a numerical
simulation (Fig. 3.2 ). There one observes that the maximal elements do
not align along the one-dimensional boundary @xmath . Instead they are
distributed along a hyperbola close to the two-dimensional Cauchy
horizon @xmath , with a density of maximal elements which decreases with
distance from the center. Hence the fact that the expected number of
maximal elements is indeed proportional to the length @xmath of the
one-dimensional boundary @xmath for large @xmath already gives very
non-trivial evidence for the proposed entropy bound.

To have the precise confirmation of the @xmath constant in @xmath one
has to choose the fundamental length scale @xmath to be @xmath . This
gives support to the belief that the fundamental discreteness scale of
space-time is of the order of the Planck length.

Hence, using this value for the fundamental discreteness scale we have
confirmed our claim, namely in the continuum approximation we have

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

or @xmath in full units, when we set @xmath . One now sees that the
assumption of large but finite @xmath used to obtain the asymptotic
behavior is equivalent to saying that @xmath is much larger than the
Planck length. However, one can see that even for relatively small
values of the length @xmath , such as @xmath in Planck units, the
approximation of @xmath by its asymptotic expansion is already very
accurate. For even smaller values of the length scale the Planck
corrections become significant. However, as one can see in Fig. 3.2 ,
the corrections always decrease the expected number of maximal elements,
such that @xmath never exceeds the bound ( 3.14 ).

###### 3+1 dimensions

Clearly from a physical point of view the evaluation of ( 3.8 ) in 3+1
dimensions is the most interesting case. For @xmath one can write ( 3.8
) as follows,

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

One can perform the first integration in ( 3.15 ) by using the following
integral relation [ 57 ]

  -- -- -- -------- -------- --------
           @xmath            (3.16)
           @xmath   @xmath   
  -- -- -- -------- -------- --------

for @xmath , @xmath and @xmath , where @xmath denotes Euler’s beta
function and @xmath is the generalized hypergeometric function defined
through

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

and @xmath are the usual Pochhammer polynomials. The second integration,
namely the one of the generalized hypergeometric function, can be
obtained by use of the following relation [ 57 ]

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

Expressed in terms of the number of causal set elements sprinkled into
@xmath , @xmath , where the volume of @xmath is given by @xmath , the
final result reads

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

For a large number of elements @xmath we can use the asymptotic
expansion of the generalized hypergeometric functions (cf. App. A.3 ),
yielding the asymptotic expression for the expected number of maximal
elements,

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

In terms of the fundamental density of space-time @xmath and the radius
@xmath of @xmath this result translates into

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

As in the previous case the number of maximal elements follows the right
scaling according to the entropy bound, namely @xmath , where the area
of the boundary of @xmath is given by @xmath . The factor of
proportionality is a @xmath constant as in the previous case, supporting
the assumption that the fundamental length scale @xmath is proportional
to the Planck length @xmath . More precisely, to have an exact agreement
with the Susskind bound the fundamental length scale in four dimensions
will be given by @xmath in Planck units. Using this value for the
fundamental length scale the asymptotic expansion for the expected
number of maximal elements reads

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

or @xmath in full units. At first sight one might feel uncomfortable in
absorbing the order one constant into the fundamental length scale to
exactly confirm the Susskind bound. However, as discussed in the
previous case, the scaling @xmath is nontrivial and already serves as a
confirmation of the bound. Taking the phenomenological law @xmath
(spherical entropy bound) as “data” gives the fundamental length scale
in four dimensions to be

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

In comparison to the previous case of 2+1 dimensions one observes that
the fundamental discreteness scale @xmath depends on the dimension. In
Sec. 3.3.1 we will derive an expression for the factor for arbitrary
(even) dimensions, showing that this factor tends exactly to one as
@xmath . It is important to check that @xmath is universal for all cases
with the same space-time dimension. In Sec. 3.3.2 we will provide
evidence that this is indeed the case.

At this point it is interesting to note that a similar method of fixing
the fundamental discreteness scale to obtain the right factor of
proportionality in the entropy bound is followed in loop quantum gravity
in the context of black hole entropy (cf. [ 58 ] ). There one fixes the
Immirzi parameter which can be regarded as a measure for the
discreteness scale (through its relation to the lowest eigenvalue of the
area operator) to obtain the right factor of a quarter in the black hole
entropy. However, since there are several ambiguities in the relation
between the Immirzi parameter and the fundamental discreteness scale in
the sense one uses it in causal set theory, it is hard to compare the
numerical values in any sense.

###### 4+1 dimensions

In @xmath dimensions one can also evaluate the integral in ( 3.8 ) in a
similar way to the calculation in 2+1 dimensions. As in the previous
cases the result is expressed in terms of the number of causal set
elements sprinkled into @xmath , @xmath , with the volume of @xmath
given by @xmath . The final result reads

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.24)
                                @xmath   
  -- -------- -------- -------- -------- --------

The plot of @xmath as a function of @xmath is shown in Fig. 3.5 on a
logarithmic scale as well as the numerical results obtained from
Monte-Carlo simulation and the asymptotic behavior. As in the previous
cases there is agreement between analytical and numerical results.

For large @xmath one can expand ( 3.24 ) using the asymptotic expansion
for the exponential integral ( 3.11 ), yielding

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

Re-expressed in terms of the density @xmath and the radius @xmath of
@xmath this result reads

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

As for the lower dimensional cases this result gives the correct
behavior @xmath , where @xmath is the volume of the boundary of @xmath ,
providing further evidence for the claim. Further, we can use the
coefficient in ( 3.26 ) to fix the fundamental length scale in 4+1
dimensions @xmath to be @xmath in Planck units. Using this fundamental
length scale the number of maximal elements ( 3.26 ) reads

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

or in full units @xmath , which confirms our claim.

###### Generalizations to higher dimensions

In the previous sections we have seen that causal set theory can provide
a fundamental explanation for Susskind’s entropy bound for the spacelike
hypersurface @xmath in 2+1, 3+1 and 4+1-dimensional Minkowski
space-time. In this section we want to generalize these results to
arbitrary dimensions. For the case of odd space-time dimension, it turns
out that one can easily calculate the expected number of maximal
elements, but one cannot write the results in a closed form. However,
for even dimensions one can find a closed expression.

As in the previous cases we will express the result of the expected
number of maximal elements in terms of @xmath , where @xmath is the
volume of the domain of dependence of @xmath , given by

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

Using the integration relations ( 3.16 ) and ( 3.18 ) one can integrate
( 3.8 ) for even dimensions, yielding

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

Note that this result is also valid for the case of @xmath dimensions,
however it is not related to any entropy of the system, and is thus
excluded from the proposal.

For large @xmath one can use the asymptotic expansion of the generalized
hypergeometric function (App. A.3 ) to derive the asymptotics of the
number of maximal elements for arbitrary even dimensions, yielding

  -- -------- -- --------
     @xmath      (3.30)
  -- -------- -- --------

From this result one can see that the number of maximal elements scales
like @xmath , where @xmath is the volume of the boundary of @xmath ,
i.e.

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

Further, we obtain @xmath precisely for the following value of the
fundamental length scale,

  -- -------- -- --------
     @xmath      (3.32)
  -- -------- -- --------

The analytic continuation of ( 3.32 ) as a function of the dimension is
shown in Fig. 3.6 together with the explicit values for 2+1 and 4+1
dimensions as determined in the previous sections. One observes that the
expression ( 3.32 ) agrees with these values. This suggests that ( 3.32
) also holds for arbitrary odd dimensions. For @xmath the value of (
3.32 ) diverges, since the Planck length @xmath is not well defined in
two dimensions. This also reflects the fact that the entropy bound only
holds for dimensions @xmath . For all values @xmath the fundamental
length scale is of order of the Planck length.

##### 3.3.2 Generalizations to different spatial hypersurfaces

In the previous section we have derived the Susskind bound for the case
where the spacelike hypersurface was chosen to be a @xmath -dimensional
ball in @xmath dimensional Minkowski space-time. Further, from this we
determined the fundamental discreteness scale of space-time. However, it
is important to prove that the fundamental discreteness scale so
determined yields the same entropy bound for all spacelike hypersurfaces
of a certain dimension.

In this section we show that the claim also holds for spacelike
hypersurfaces in Minkowski space-time different from those discussed in
the previous section. We investigate hyperbolic spherically symmetric
spacelike hypersurfaces given by

  -- -------- -- --------
     @xmath      (3.33)
  -- -------- -- --------

as shown in Fig. 3.7 together with its domain of dependence. For the
special case of @xmath the spacelike hypersurface given by ( 3.33 ) is
equivalent to the @xmath -dimensional ball @xmath for which we have
determined an analytic expression for the expected number of maximal
elements @xmath in the previous section. For other values @xmath one
cannot determine the number of maximal elements analytically. In the
following we will investigate this problem numerically for the
physically most important cases of 2+1 and 3+1 dimensions.

###### 2+1 dimensions

For @xmath dimensions we use Monte-Carlo methods to numerically obtain
the number of maximal elements in the domain of dependence of the
spacelike hypersurfaces @xmath defined by ( 3.33 ) for different values
of @xmath as a function total number @xmath of elements in the domain of
dependence. Since all these spacelike hypersurfaces @xmath have the same
boundary @xmath , it is useful to express @xmath as a function of the
length of the boundary @xmath . One can do this by using that @xmath ,
where the volume of the domain of dependence of @xmath is given by

  -- -------- -- --------
     @xmath      (3.34)
  -- -------- -- --------

Further, we use the value for the fundamental density of space-time as
obtained in Sec. 3.3.1 , i.e. @xmath .

The results of the simulations are summarized in Fig. 3.8 . Shown is the
expected number of maximal elements @xmath as a function of the boundary
length @xmath . For the special case of @xmath in ( 3.33 ) we know that
the result is given by ( 3.9 ), where @xmath is replaced by @xmath . The
asymptotics of this analytic result is given by @xmath as shown earlier.
For different values of @xmath the simulations show that even though the
number of maximal elements as a function of @xmath differs for small
values @xmath in Planck units, in the expansion for large @xmath ,
corresponding to the continuum approximation, all functions @xmath for
different @xmath enter the same asymptotic expansion @xmath , yielding
Susskind’s entropy bound. In addition, it shows that the prediction of
the fundamental discreteness scale is universal in 2+1 dimensions, at
least for all investigated cases of spacelike hypersurfaces in Minkowski
space-time. A generalization to examples in curved space-time has still
to be shown and will be investigated in future work.

###### 3+1 dimensions

As in the case of 2+1 dimensions we use Monte-Carlo methods to
numerically obtain the number of maximal elements in the domain of
dependence of the spacelike hypersurfaces @xmath defined by ( 3.33 ) for
@xmath and different values of @xmath . Again, the result is expressed
as a function of the area of the boundary of @xmath , i.e. @xmath . This
can be done by using the relation @xmath and noticing that the volume of
the domain of dependence of @xmath is given by

  -- -------- -- --------
     @xmath      (3.35)
  -- -------- -- --------

where we use @xmath for the value of the fundamental density of four
dimensional space-time.

The numerical and analytical results are shown in Fig. 3.9 . Displayed
is the expected number of maximal elements @xmath as a function of the
area @xmath of the boundary. For the special case of @xmath the
analytical result was given by ( 3.19 ), with @xmath replaced by @xmath
. The simulations show that for different values of @xmath all functions
@xmath enter the same asymptotics, @xmath , in the continuum limit,
giving further evidence for the claim. For very small values of @xmath
the expected number of maximal elements enters the asymptotic regime
only very slowly. However, the upper value for @xmath of the simulations
is still very small ( @xmath ). As in the lower dimensional case the
simulations show that the prediction for the value of the fundamental
discreteness scale of four-dimensional space-time, namely @xmath , is a
universal quantity for this dimension, at least for all investigated
cases of spherically symmetric spacelike hypersurfaces in Minkowski
space-time.

#### 3.4 Discussion and outlook

Using the phenomenological model of causal set theory as introduced in
the previous chapter we argued for a bound on the entropy in a
spherically symmetric spacelike region from a counting of potential
horizon “degrees of freedom” of the fundamental theory, namely the
maximal elements of the future domain of dependence of the region. It
was then shown that, for different spherically symmetric spacelike
regions in Minkowski space-time of arbitrary dimension, this leads to
Susskind’s spherical entropy bound. The evidence was given in terms of
analytical results for spatial @xmath -dimensional balls in @xmath
-dimensional Minkowski space-time, and in terms of numerical results
obtained from Monte-Carlo simulations for the case of hyperbolic
spherically symmetric hypersurfaces in Minkowski space-time.

So far results were given only in terms of examples in flat Minkowski
space-time. Clearly this is a very restricted class and further evidence
should be provided in different space-times. Spherically symmetric
spacelike regions in curved space-time such as in
Friedmann-Robertson-Walker cosmology will be investigated in future
work.

Another step would be to formulate the proposal intrinsically in terms
of order invariants, without making explicit reference to the continuum.
Such a formulation may be fruitful in providing a fundamental
understanding of Bousso’s covariant entropy bound.

Further work in progress in the direction of entropy bounds from causal
sets is the implementation of entropy evaluation through link counting
as proposed in [ 38 , 53 ] for black holes, to other situations such as
dS space-time.

## Part II 2D causal dynamical triangulations

### Chapter 4 Path integrals and quantum gravity

In Part I of this thesis we introduced causal sets as a simple model of
causal random geometry. The remaining three parts of this thesis will be
centered around the approach of causal dynamical triangulations. As
already discussed in the introduction, one way to confront the
non-renormalizability of perturbative quantum gravity in four dimensions
is to find a proper non-perturbative definition of the gravitational
path integral. Before describing dynamical triangulations as such, we
first give a brief introduction to path integrals in general.
Specifically, we comment on problems one encounters when formulating the
gravitational path integral.

#### 4.1 Random paths and one-dimensional gravity

Path integrals were first introduced by Dirac and Feynman [ 59 , 60 ] as
a quantization scheme to first quantize physical systems. One of the
most instructive examples is the free relativistic particle in @xmath
-dimensional Minkowski space-time @xmath . The amplitude of a particle
moving from @xmath to @xmath can be expressed by the so-called
propagator,

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where the action is simply given by the mass @xmath times the length of
the path

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

The classical equations of motion are derived by choosing a specific
parametrization

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

The action now reads

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

where we defined @xmath . The classical equations of motion can be
easily obtained by varying the action

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

which are simply straight lines from @xmath to @xmath and
reparametrizations of it.

To be able to define the path integral ( 4.1 ) one usually performs a
Wick rotation by taking time imaginary

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

One now deals with the corresponding Euclidean model in @xmath .

One way to define the path integral ( 4.1 ) is to introduce a
“geometrical” discretization scheme where one directly discretizes the
length of the worldline (see for instance [ 18 ] ). Therefore it is
useful to work with the action ( 4.2 ), since its definition does not
depend on parametrized quantities. Specifically, in the employed
discretization each worldline consists of a piecewise linear path, where
each edge is of size @xmath (see Fig. 4.1 ). Here @xmath serves as a
reparametrization invariant cut-off which will be taken to zero in the
continuum limit. For a piecewise linear path of length @xmath the action
simply becomes @xmath , where @xmath is the bare mass. Further, the path
integral can be written as a sum over all possible paths connecting
@xmath and @xmath :

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

Here the @xmath denote the vectors of the linear parts of the
discretized worldline, where the @xmath ’s are unit vectors in @xmath .
The propagator can now be defined as follows

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

To perform the integration it is helpful to use the Fourier transform

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

The integral in the above expression can be expanded as

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

where @xmath is given in ( A.5 ) and @xmath is an irrelevant constant.
We can now perform the summation leading to

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

One can define the continuum limit by taking the cut-off @xmath to zero
and at the same time taking the number of steps in the discretized path
to infinity. The latter is fulfilled when @xmath is taken to its
critical value @xmath at which @xmath approaches its radius of
convergence. Hence, we renormalize the bare mass @xmath such that

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

where @xmath is the physical mass. Using this renormalization we obtain

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

After a wave function renormalization the continuum propagator @xmath
becomes the well-known expression for the Feynman propagator

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

In terms of its Fourier transform this is precisely the solution of the
field equation for the Green function of a Klein-Gordon field,

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

In the above description we used a discretization scheme where we
directly discretized the length of the worldline. A different
prescription is to use the parametrized action ( 4.4 ) and to introduce
a cut-off on the worldline coordinates (see for instance [ 61 ] ).
However, since the square root in this expression is very difficult to
handle, it is useful to look at an alternative action for the free
relativistic particle first introduced in [ 62 ] ,

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

where @xmath is the internal metric of the one-dimensional worldline.
The action ( 4.16 ) can also be viewed as the action of one-dimensional
gravity coupled to @xmath scalar fields @xmath . Solving for the
equations of motion for @xmath and plugging the result back into the
equations of motion for @xmath one finds ( 4.5 ). This shows that the
systems desribed by both actions ( 4.4 ) and ( 4.16 ) are equivalent on
the classical level. Whether this is also true on the quantum level
remains to be checked. To obtain the propagator we now also have to
integrate over the worldline metric @xmath ,

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

where @xmath refers to the measure of the space of worldline metrics
modulo diffeomorphisms, i.e. coordinate transformations on the
worldline. Let us in the following briefly sketch how to calculate the
propagator ( 4.17 ) (for details see [ 61 ] ). The first step is to
perform the Wick rotation. One proceeds by defining the integral over
@xmath for fixed @xmath . Therefore one discretizes the worldline
coordinates by forming @xmath slices of arbitrary small parameter
differences

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

The integration over @xmath and the continuum limit @xmath can now be
performed in a similar manner as one usually does for the
non-relativistic particle. The remaining integral over @xmath can then
be done after a suitable gauge fixing. The result is precisely given by
( 4.14 ). This indicates that both actions ( 4.4 ) and ( 4.16 ) not only
lead to the same classical equations of motion, but also to the same
dynamics on the quantum level. A comparison of the two discretization
schemes further shows that the “geometrical” discretization employed
above is computationally rather simple in comparison to the continuum
method. Dynamical triangulations, as will be introduced in the next
chapter, is an analogous “geometrical” discretization scheme for
surfaces and higher-dimensional manifolds.

#### 4.2 Random surfaces and strings

The natural generalization to the random paths, as considered in the
previous section, are random surfaces or worldsheets of propagating
(closed) strings (Fig. 4.2 ). In analogy to the relativistic particle we
expect those to describe the relativistic string.

The simplest action for a surface @xmath is given by its area

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

where @xmath is a (cosmological) constant conjugate to the area. The
action ( 4.19 ) is a direct analog of ( 4.2 ). The parametrized form of
( 4.19 ) is called the Nambu-Goto action [ 63 ] and reads

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

is the determinant of the metric @xmath , @xmath , of the embedded
worldsheet induced by the mapping @xmath .

As for the relativistic particle we can also write an action in terms of
the internal metric @xmath , @xmath , of the worldsheet. This is the
so-called Polyakov action [ 62 ] , the analog of ( 4.16 ),

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

where one should integrate over both @xmath and @xmath in the path
integral [ 64 ] . Both ( 4.19 ) and ( 4.22 ) are equivalent on the
classical level, however, it is not so obvious that this also holds at
the quantum level (see for instance [ 18 ] ).

We will see in the following two sections how ( 4.22 ) can also be
viewed as the action for two-dimensional quantum gravity coupled to
@xmath scalar fields. An explicit “geometrical” discretization to define
the corresponding path integral will be discussed in the next chapter.

#### 4.3 A path integral for quantum gravity

In the previous section we discussed the Polyakov and Nambu-Goto action
as simple generalizations of random paths to random surfaces. The
natural action for a theory of quantum gravity in @xmath -dimensions is
the so-called Einstein-Hilbert action,

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

where @xmath is the Newton’s constant, @xmath the cosmological constant,
@xmath the scalar curvature of the metric @xmath and @xmath the
determinant of the metric. For manifolds with boundaries one also has to
include the Gibbons-Hawking-York boundary term [ 65 , 66 ]

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

where @xmath and @xmath are the induced metric and curvature on the
boundary. All physical degrees of freedom are encoded in the equivalence
class @xmath which is @xmath modulo diffeomorphisms, i.e. coordinate
transformations.

The expression of the gravitational path integral for the partition
function is then formally written as

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

where the integration should be taken over the space of all closed
geometries, i.e. the coset space @xmath . Generalizations to geometries
with boundaries are also possible. When trying to define the formal
expression ( 4.25 ) several problems arise:

First of all, @xmath has to be defined in a covariant way to preserve
the diffeomorphism invariance. Unfortunately, to perform further
calculations one would then have to gauge fix the field tensors which
would give rise to Faddeev-Popov determinants [ 67 ] whose
non-perturbative evaluation is exceedingly difficult. ¹ ¹ 1 See [ 68 ,
69 , 70 ] for an evaluation in the setting of two-dimensional Euclidean
quantum gravity in the light-cone gauge. In [ 71 ] a calculation for
three- and four-dimensional Lorentzian quantum gravity in the
proper-time gauge is presented. It is anticipated there that the
Faddeev-Popov determinants cancel the divergences coming from the
conformal modes of the metric non-perturbatively.

The second problem is due to the complex nature of the integrand. In
quantum field theory this problem is solved by doing the Wick rotation
@xmath , where @xmath is the time coordinate in Minkowski space @xmath .
Clearly, a prescription like this does not work out in the gravitational
setting, since all components of the metric field tensor depend on time.
Further @xmath is certainly not diffeomorphism invariant (as a simple
example consider the coordinate transformation @xmath for @xmath ).
Hence, the question arises: What is the natural generalization of the
Wick rotation in the gravitational setting? This problem is often
circumvented in the approach of Euclidean quantum gravity, where one
does an ad hoc substitution

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

In this substitution the path integral over Lorentzian manifolds @xmath
is replaced by an integral over Euclidean manifolds @xmath . Clearly,
the path integral now also includes many “acausal” manifolds and we will
see in the next chapter when discussing two-dimensional Euclidean
quantum gravity what consequences this brings with it. The main interest
of this thesis is however to analyze ways to define the gravitational
path integral in a Lorentzian setting including a proper definition of
the Wick rotation.

Another problem in the definition of ( 4.25 ) is the following. Since we
are working in a field theoretical context, some kind of regularization
and renormalization will be necessary, and again, has to be formulated
in a covariant way. In quantum field theory the use of lattice methods
provides a powerful tool to perform non-perturbative calculations, where
the lattice spacing @xmath serves as a cut-off of the theory. An
important question to ask at this point is whether or not the theory
becomes independent of the cut-off. Consider for example QCD and QED on
the lattice. All evidence suggests that QCD in four space-time
dimensions is a genuine continuum quantum field theory. By genuine
continuum quantum field theory we mean a theory which needs a cut-off at
an intermediate step, but whose continuum observables will be
independent of the cut-off at arbitrarily small scales. In QED the
situation seems to be different, one is not able to define a non-trivial
theory with the cut-off removed, unless the renormalized coupling @xmath
(trivial QED). Therefore, QED is considered as a low-energy effective
theory of a fundamental theory at the Planck scale.

Finally, one could argue to also include a sum over topologies in the
path integral ( 4.25 ). However, in higher dimensions such a sum over
topologies is quite intractable, since for @xmath there does not even
exist an obvious classification of topologies in terms of a finite set
of parameters.

These are some of the reasons to first look at the simpler case of two
dimensions.

#### 4.4 Two-dimensional Euclidean quantum gravity and Liouville theory

One of the big advantages of the two-dimensional Einstein-Hilbert action
is that the curvature term is a topological invariant. This follows from
the Gauss-Bonnet theorem which states that

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

where @xmath , is the so-called Euler-characteristic , @xmath is the
genus of the manifold @xmath , i.e. the number of holes in the surface,
and @xmath the number of boundary components of @xmath .

Using the Gauss-Bonnet theorem we can write the partition function for
two-dimensional Euclidean quantum gravity including a sum over
topologies (using a rescaling of the couplings)

  -- -------- -- --------
     @xmath      (4.28)
  -- -------- -- --------

where the partition function for manifolds with fixed genus @xmath is
given by

  -- -------- -- --------
     @xmath      (4.29)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

Here @xmath is the volume of the manifold @xmath . Eq. ( 4.28 ) is
called the topological expansion . Note that since the sum is taken over
closed surfaces, we have @xmath . Often one is only interested in the
genus zero contribution, i.e. the sum over surfaces with topology of
@xmath . In this case we denote the partition function by @xmath .

If the path integral is taken over surfaces with @xmath boundaries the
Euler characteristic reads @xmath . Further, it is natural to include
boundary terms in the action

  -- -------- -- --------
     @xmath      (4.31)
  -- -------- -- --------

where @xmath is the length of the @xmath th boundary loop @xmath with
respect to the metric @xmath . Here the @xmath take the role of boundary
cosmological constants. One should notice that in two dimensions the
intrinsic boundary geometry is completely determined by its lengths
@xmath . The partition function for the case of boundaries is given thus
by

  -- -------- -- --------
     @xmath      (4.32)
  -- -------- -- --------

and is called the multi-loop amplitude. Instead of fixing the boundary
cosmological constants @xmath one could have alternatively also fixed
the boundary lengths,

  -- -------- -- --------
     @xmath      (4.33)
  -- -------- -- --------

The length space versions of the multi-loop amplitudes are also called
the Hartle-Hawking wave functions [ 72 ] . For the case of one boundary
component we also call it the disc function. One observes that ( 4.33 )
and ( 4.32 ) are related by Laplace transforms,

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

So far we discussed only pure two-dimensional Euclidean quantum gravity,
i.e. without any coupling to matter fields. If one would like to couple
@xmath scalar fields @xmath one should add the following term in the
action

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

It is interesting to notice that @xmath is precisely the Polyakov action
( 4.22 ), discussed in the previous section. Hence we see that pure
two-dimensional Euclidean quantum gravity corresponds to string theory
in zero-dimensional target space, i.e. non-critical string theory.

In the following section we explain how to define the path integral for
two-dimensional Euclidean quantum gravity using a discretization scheme
called dynamical triangulations. Before doing so let us briefly mention
a different way of computing the gravitational path integral using
continuum methods. This is done by fixing the metric to the conformal
gauge

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

where @xmath is the reference metric. One sees that the theory is now
expressed in terms of a single field, the so-called Liouville field
@xmath . There are interesting analytical results for Liouville field
theory on the quantized level (see for example [ 73 , 74 ] ). Further,
whenever the continuum theory and the discretized theory (as described
in the next chapter) can be compared the results agree [ 75 ] . However,
contrary to what one might have expected the discretized theory allows
one to compute many quantities which are not accessible from the
continuum theory.

### Chapter 5 Two-dimensional dynamical triangulations

In this chapter we introduce dynamical triangulations as a
discretization of the Euclidean gravitational path integral. In the
special case of two dimensions analytical results can be obtained. In
particular, we show how both the Hartle Hawking wave function as well as
the gravitational propagator can be calculated explicitly within this
approach. The results agree with those of the continuum formulation of
two-dimensional Euclidean quantum gravity through Louiville theory as
briefly mentioned in the previous chapter.

#### 5.1 Geometry from simplices

The use of discrete approaches to quantum gravity has a long history [
76 ] . In classical general relativity, the idea of approximating a
space-time manifold by a triangulation of space-time goes back to the
early work of Regge [ 77 ] and was first used in [ 78 , 79 ] to give a
path integral formulation of gravity. By a triangulation we mean a
piecewise linear space-time obtained by a gluing of simplicial building
blocks. This one might think of as the natural analogue of the piecewise
linear path we used to describe the relativistic particle. In two
dimensions these simplicial building blocks are flat Euclidean triangles
¹ ¹ 1 In the next chapter, when discussion two-dimensional causal
dynamical triangulations, we will consider a similar construction with
Minkowskian triangles. , where flat means isomorphic to a piece of
Euclidean space respectively. One could in principle assign a coordinate
system to each triangle to recover the metric space @xmath , but the
strength of this ansatz lies just in the fact that even without the use
of coordinates, each geometry is completely described by the set of
edges length squared @xmath of the simplicial building blocks. This
provides us with a regularized parametrization of the space of all
geometries @xmath in a diffeomorphism invariant way, and hence, is the
first step towards defining the gravitational path integral.

For the further discussion it is essential to understand how a geometry
is encoded in the set of edges length squared @xmath of the simplicial
building blocks of the corresponding triangulation. In the case of two
dimensions this can be easily visualized, since the triangulation
consists just of triangles. Further, the Riemann scalar curvature @xmath
coincides with the Gaussian curvature @xmath up to a factor of @xmath .
There are several ways to reveal curvature of a simplicial geometry. The
most convenient method is by parallel transporting a vector around a
closed loop. Since all building blocks are flat, a vector parallel
transported around a vertex @xmath always comes back to its original
orientation unless the angles @xmath of the surrounding triangles do not
add up to @xmath , but differ by the so-called deficit angle @xmath
(Figure 5.1 ). The Gaussian curvature located at the vertex @xmath is
then given by

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

where @xmath is the volume associated to the vertex @xmath ; more
precisely, the dual volume of the vertex as shown in Fig. 5.2 . Note
that the curvature at each vertex takes the form of a conical
singularity. Then one can write the simplicial discretization of the
usual curvature and volume terms appearing in the two-dimensional
Einstein-Hilbert action,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (5.2)
     @xmath   @xmath   @xmath      (5.3)
  -- -------- -------- -------- -- -------

where @xmath is a triangulation of the manifold @xmath described by the
set of edge lengths squared. From this one can write down the simplicial
discretization of the two-dimensional Einstein-Hilbert action, the
so-called Regge action ,

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

where @xmath is the inverse Newton’s constant and @xmath the
cosmological constant. It is then an easy exercise of trigonometry to
evaluate the right hand side of ( 5.4 ) in terms of the squared edge
lengths.

From this notion of triangulations one can now write the gravitational
path integral as the integral over all possible edge lengths @xmath ,
where each configuration @xmath is weighted by the corresponding Regge
action ( 5.4 ). In this approach the triangulation is fixed and only the
length of the edges is varied. A potential problem one encounters with
this ansatz is a possible overcounting of triangulations, due to the
fact that one can continuously vary each edge length, as is clear from
flat space-time. Further, one still has to introduce a suitable cut-off
for the length variable @xmath . Among other things, this motivated the
approach of “rigid” Regge calculus or (Euclidean) dynamical
triangulations (DT) where one considers a certain class @xmath of
simplicial space-times as an explicit, regularized version of Euclidean
geometries, where each triangulation @xmath only consists of simplicial
building blocks whose edges have all the same edge length squared @xmath
. Here, the geodesic distance @xmath serves as the short-distance
cut-off, which will be sent to zero in the continuum limit.

Following early work by Tutte [ 80 , 81 , 82 , 83 ] and Brezin et al. [
84 ] , DT have in a quantum gravity context first been introduced as an
regularization of the bosonic string [ 85 , 86 , 87 , 88 , 89 ] .
Further developments have been made in many contributions, for an
overview the reader is referred to [ 18 ] . The motivation for using a
discretization of Euclidean geometries instead of Lorentzian geometries
is mainly to avoid the need to define a gravitational Wick rotation. One
simply starts off with a sum over Euclidean triangulations weighted by
the Euclidean (real) Regge action. In the continuum limit this theory of
(Euclidean) DT corresponds to two-dimensional Euclidean quantum gravity.
It is important to notice that this theory is distinct from
two-dimensional Lorentzian quantum gravity which we will introduce in
the next chapter.

Putting the above discussion into formulas we can give a definite
meaning to the formal continuum path integral of two-dimensional
Euclidean quantum gravity as a discrete sum over inequivalent
triangulations,

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

where @xmath is the measure on the space of discrete geometries, with
@xmath the dimension of the automorphism group of the triangulation
@xmath .

Now the problem of calculating the gravitational path integral reduces
to a statistical physics problem. Here the weight @xmath is the
so-called Bolzmann factor and the sum together with the measure factor
determines the entropy of configurations with equal weight. In the
following section we solve this statistical problem analytically for the
two-dimensional model.

#### 5.2 The disc function

In this section we calculate the disc function or Hartle-Hawking wave
function of two-dimensinal Euclidean quantum gravity defined through DT.
The disc function is defined as a sum over all triangulations with
topology of a disc with fixed boundary of length @xmath . In other words
the disc function describes the amplitude for the creation of a universe
from nothing [ 72 ] . Although rather “global” it is a simple observable
which can be used to calculate other interesting observables.

##### 5.2.1 Discrete solution

As we are in two space-time dimensions we have seen that the curvature
term in the Einstein-Hilbert action is a purely topological quantity.
Hence, if we are interested in computing sums over triangulations of
fixed space-time topology, the contribution from the curvature term
reduces to an irrelevant normalization constant.

The Regge action ( 5.4 ) is thus simply given by

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

where @xmath is the bare (dimensionfull) cosmological constant and
@xmath is the number of triangles in the triangulation @xmath . The
factor of @xmath comes from the volume of a single triangle where the
order one constant has been absorbed into @xmath .

The expression for the disc function @xmath now becomes

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

where we defined @xmath as the fugacity of a triangle. The sum is taken
over all triangulations with boundary length @xmath and a mark on one
boundary edge. The mark is introduced for convenience to remove a
symmetry factor of @xmath in the sum which corresponds to the factor
@xmath in the above expression. We can further write ( 5.7 ) as

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

where @xmath is the number of triangulations with @xmath boundary edges
and @xmath triangles. We now see that the problem of determine the disc
function reduces to a purely combinatorial problem, namely finding the
number @xmath of all possible triangulations with @xmath boundary edges
and @xmath triangles. Fig. 5.3 (a) shows an example of one triangulation
with @xmath boundary edges and @xmath triangles. This combinatorial
problem was first studied by Tutte in 1962 [ 80 , 81 , 82 , 83 ] .

In the following we will not follow the procedure by Tutte but rather
count the number of all possible triangulations of a wider class,
so-called non-restricted triangulations. Non-restricted triangulations
are more general than the ones considered above in the sense that they
can include double links (see Fig. 5.3 (b)). The double links are mainly
included to facilitate the calculation and to be able to map the results
to those of matrix models. The use of matrix models will be an important
part of this thesis and we will discuss them in detail at a later stage.
The justification for being able to include double links is that when
taking the continuum limit the contribution coming from the double links
will be “washed away” as they do not carry a factor of @xmath . Further,
using the results of Tutte it can be checked explicitly that both
regular and non-restricted triangulations lead to the same continuum
expression for the disc function (see for example [ 18 ] ).

When trying to solve a combinatorial problem it is often useful to
introduce generating functionals,

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

Here @xmath can be understood as the fugacity of a boundary edge or in
other terms as being related to a boundary cosmological constant @xmath
via @xmath .

Generating functionals are very useful tools especially since there are
helpful to find recursion equations for @xmath , the so-called loop
equations. Let us first make the observation that whenever one removes
triangles from a triangulation for each volume decrement of one triangle
the generating function is decreased by a factor of @xmath and for each
decrement in boundary length it is decreased by a factor of @xmath .

Starting with a triangulation one can now uniquely decompose it
step-by-step to a single dot by the following two elementary moves:
Firstly, if the marked edge on the boundary belongs to a triangle this
triangle is removed (see Fig. 5.4 (a)). Thus one boundary edge is
removed and two new edges are created of which by convenience the one
further counterclockwise is marked again. In this move the power of
@xmath in @xmath is decreased by one and the power of @xmath is
increased by one. The second move corresponds to the case where the mark
belongs to a double link (see Fig. 5.4 (b)). In this case the double
link is removed and the triangulation splits into two, each with a mark
next to where the double link was attached.

The step-by-step procedure described above leads to the following
recursion relation (see Fig. 5.5 )

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

where the first term corresponds to the first move and the last term to
the second move. The term @xmath in the bracket is subtracted to be in
accordance with the initial conditions of the the recursion relation.
One can now solve for @xmath , however, the solution is implicit since
@xmath still has to be determined.

To be in accordance with the notation adopted in matrix models and also
in later parts of this thesis one often rewrites this equation using a
slightly different definition of the generating functional

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

Here @xmath takes the roles of the fugacity of a boundary edge. The
formal solution to the recursion relation ( 5.10 ) reads in terms of the
newly defined generating function

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

where anticipating the discussion of matrix models in later chapters we
introduced the notation

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

The sign in front of the square root is determined by the initial
condition @xmath which leads to the requirement @xmath . In principle
one would now have to find a combinatorial solution for @xmath ,
however, there exists a way of determining an explicit solution for
@xmath by making use of the analytic structure of ( 5.12 ). Therefore we
first solve ( 5.12 ) for the limiting case of @xmath , where only double
links are present. In this case @xmath corresponds to the generating
function of rooted branched polymers (see Fig. 5.6 ). The implicit
solution ( 5.12 ) becomes explicit in this special case

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

This is precisely the generating function of the Catalan numbers

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

Hence we see that the number of rooted branched polymers with @xmath
links is given by the Catalan numbers @xmath .

Anticipating the general solution for @xmath it is instructive to
analyze the analytic structure of ( 5.14 ). The generating function
@xmath is analytic in @xmath with a branch cut on the real axis along
the interval @xmath . The endpoints of the cut precisely determine the
radius of convergence of @xmath which is needed to find the critical
points when taking the continuum limit later on.

The key to finding the solution for the general case of @xmath is to
notice that the analytic structure of @xmath as a function of @xmath
cannot change discontinuously at @xmath . For @xmath the branch cut is
determined by the following expression under the square root

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

For @xmath this expression becomes fourth order in @xmath ,

  -- -------- -- --------
     @xmath      
     @xmath      (5.17)
  -- -------- -- --------

Since the analytic structure of @xmath should not change in the
neighborhood of @xmath , this implies that the term under the square
root must be of the general form

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

where we labeled the roots such that @xmath . The solution for the disc
function then reads

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

Matching the coefficients of ( 5.18 ) in the expansion in @xmath yields
four equations which completely determine @xmath , @xmath , @xmath and
@xmath . This gives the full combinatorial solution for the disc
function in DT.

##### 5.2.2 Continuum limit

Having solved the gravitational path integral as a statistical sum over
triangulations we now have to perform the continuum limit to extract the
continuum physics. This is done by taking the lattice spacing @xmath to
zero while at the same time taking the number of triangles @xmath and
the discrete boundary length @xmath to infinity, such that physical area
@xmath and length @xmath stay finite.

In terms of critical phenomena the continuum limit relates to a
fine-tuning of the coupling constants, generally denoted by @xmath , to
the critical point @xmath of the phase transition. This means a
divergence of the correlation length @xmath in the scaling limit

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

while the cut-off @xmath goes to zero as

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

where @xmath is a critical exponent. In terms of the cut-off @xmath and
the correlation length @xmath , the physical correlation length is given
by @xmath and the continuum limit is defined as the simultaneous limit

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

From standard techniques of renormalization theory, we expect the
couplings with positive mass dimension, i.e. the cosmological constant
@xmath and the boundary cosmological constant @xmath to undergo an
additive renormalization,

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

where @xmath , @xmath denote the corresponding renormalized values.
Introducing the critical values

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

it follows that

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

The critical point for the coupling @xmath can be extracted from the
radius of convergence of @xmath at which the number of triangles @xmath
diverges. Using the result for @xmath which can be derived easily as
described below ( 5.2.2 ) one finds @xmath . To obtain the critical
value for @xmath at which also the boundary length diverges we look at
the radius of convergence of @xmath as a function of @xmath . From the
analysis of the analytic structure we know that the radius of
convergence is precisely given by the endpoints of the branch cut and
hence we conclude that @xmath (in the following we omit the precise
numerical values of the critical couplings, since they are not of
essential importance for the discussion).

Inserting the scaling relations ( 5.25 ) and the critical values into
the discrete solution of the disc function yields

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

where @xmath is the so-called non-scaling part of the disc function
which consists of terms of lower order in the cut-off, more precisely an
order one constant and a term proportional to @xmath . Further, for
convenience we rescaled @xmath and @xmath by positive multiplicative
constants to simplify the result.

Introducing a wave function renormalization of the continuum disc
function

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

we obtain

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

where we dropped the non-scaling part. This is precisely the result
obtained from Liouville theory.

We can now also go back to the physical length @xmath . The continuum
limit of the defining equation for the generating function ( 5.11 ) is
precisely the Laplace transform,

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

Hence performing the inverse Laplace transform

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

of ( 5.28 ) we obtain

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

Further we can also calculate the resulting disc function without a mark
on the boundary by simply dividing ( 5.32 ) by @xmath , yielding

  -- -------- -- --------
     @xmath      (5.32)
  -- -------- -- --------

where the @xmath stands for “unmarked”.

#### 5.3 Geodesic distance and the two-loop amplitude

##### 5.3.1 Defining geodesic distance and the two-loop function

In the previous section we calculated the disc function of
two-dimensional Euclidean quantum gravity using the framework of
dynamical triangulations. This is in a sense a rather “global”
observable and in the following we are interested in calculating more
“local” observables. The quantity we calculate is the fixed geodesic
distance two-loop amplitude which we also sometimes refer to as the
gravitational propagator or simply propagator.

To be able to calculate this quantity we first need to make some
definitions of basic concepts. Firstly, we have to give a proper
definition of geodesic distance. If we would reintroduce coordinates on
the simplicial building blocks one could simply employ the standard
continuum definition as used in general relativity. However, we have
seen that the strength of this approach lies in the fact that we have a
coordinate independent representation of geometries. Hence, we should
better look for a geodesic distance definition intrinsic to dynamical
triangulations. There are several such definitions. The one we employ
here defines the geodesic distance @xmath between two links (edges)
@xmath and @xmath in a triangulation as the number of links of the
shortest path between the corresponding links of the dual triangulation.
Now we want to extend the above definition for the case of geodesic
distance of boundaries of the triangulation, where each boundary
consists of a collection of links. In particular, we define the geodesic
distance of a boundary loop @xmath to a link @xmath as @xmath . Finally,
we say that a boundary loop @xmath has geodesic distance @xmath to
another boundary loop @xmath if all links @xmath have a geodesic
distance @xmath to @xmath . One should notice that this definition is
not symmetric in @xmath and @xmath .

As an example, Fig. 5.7 shows an amplitude with a boundary of length
@xmath and another boundary of length @xmath at geodesic distance @xmath
to the first boundary. One observes that the geodesic distance induces a
natural foliation or time-slicing for the triangulations by following
the sequence of loops of geodesic distance @xmath to @xmath . ² ² 2 This
notion of time essentially suggests the existence of a Hamiltonian for
two-dimensional Euclidean quantum gravity. The formulation of such
Hamiltonian dynamics lead to interesting results in the field of string
field theory [ 90 , 91 , 92 , 93 ] . We will not review this work,
however, in Chap. 10 we will propose an analogous string field theory
formulation for Lorentzian quantum gravity. Whereas the space-time
topology of the triangulation is fixed to @xmath , the topology of the
spatial sections changes in general as a function of geodesic distance
@xmath . We call these spatial topology changes . One should notice that
spatial topology changes are naturally present in Euclidean dynamical
triangulations. However, as we will argue in the next chapter, in a
proper theory of Lorentzian quantum gravity the branching points of
changing spatial topology relate essentially to points in the continuum
geometry of anomalous causal structure. This is one motivation for
studying triangulations without spatial topology change as we will do in
the next chapter.

We now have all ingredients at hand to define the fixed geodesic
two-loop amplitude

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

where the sum is taken over all triangulations with an initial boundary
of length @xmath and a final boundary of length @xmath at geodesic
distance @xmath to the initial boundary. For @xmath the initial and
final loop coincide which leads to the following initial condition

  -- -------- -- --------
     @xmath      (5.34)
  -- -------- -- --------

As for the disc function it will be useful to the introduce generating
function

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

with the initial condition equivalent to ( 5.34 ),

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

Solving ( 5.33 ) is a purely combinatorial problem. In the following we
describe two different methods to solve this problem. The first method
of solving the geodesic two-loop amplitude is the so-called peeling
procedure due to Watabiki [ 94 ] . It is very simple and instructive,
since it essentially uses the above loop equations and only views them
as a “time-dependent” process. The disadvantage however is that not all
steps of the calculation are rigorous. The second method due to Kawai et
al. [ 95 ] uses transfer matrices (see also [ 96 , 97 ] ). Though more
complicated it is on the other hand better defined. Further, it
introduces important techniques which will be essential to study
problems arising in the next chapter.

##### 5.3.2 The peeling procedure

In Fig. 5.7 we illustrate the fixed geodesic distance two-loop amplitude
as decomposed in slices of thickness @xmath . In the spirit of the loop
equation for the disc function, as discussed in the previous section, we
can also decompose the triangulation by a peeling procedure, a sequel of
elementary decomposition moves (see Fig. 5.8 ).

Similar to the loop equation for the disc function we can write down a
recursion relation for the geodesic two-loop amplitude (see Fig. 5.9 )

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

Here the two decomposition moves are essentially the same as for the
disc function. The factor of two comes from the two possibilities of
having the final boundary on either of the two off-splitting
triangulations. The prime on the expression on the left-hand-side means
that the surfaces contributing to this quantity do not exactly have
@xmath at geodesic distance @xmath from @xmath .

Rather than giving a precise definition of @xmath one makes a proposal
which approximates @xmath for large @xmath . When comparing to the exact
transfer matrix calculation in the next section we shall see that this
approximation indeed leads to the correct result. The basic idea in
approximating @xmath is that when applying the elementary decomposition
moves @xmath times on @xmath we will on average get @xmath , since
roughly speaking we peeled off a whole slice. Ignoring the fact that
@xmath is an integer we can then view @xmath . For large @xmath one can
Taylor expand

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

Inserting this into ( 5.37 ) gives

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.39)
                                @xmath   
  -- -------- -------- -------- -------- --------

or in terms of the generating functions

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

Plugging in the result for the disc function ( 5.2.2 ) we see that the
first term in the bracket cancels the non-scaling part of the disc
function and we get

  -- -------- -- --------
     @xmath      (5.41)
  -- -------- -- --------

where we defined

  -- -------- -- --------
     @xmath      (5.42)
  -- -------- -- --------

Instead of trying to solve the differential equation and then take the
continuum limit of the result, we will in the following take the
continuum limit directly of the differential equation ( 5.41 ) and its
initial condition ( 5.36 ). Therefore we extend the scaling relations (
5.25 ) to

  -- -------- -- --------
     @xmath      (5.43)
  -- -------- -- --------

using the same critical values as described above. Inserting these
relations into the initial conditions ( 5.36 ) gives

  -- -------- -- --------
     @xmath      (5.44)
  -- -------- -- --------

where we introduced the following wave function renormalization for the
geodesic two-loop amplitude

  -- -------- -- --------
     @xmath      (5.45)
  -- -------- -- --------

Further, inserting the scaling relations ( 5.43 ) and ( 5.45 ) into (
5.41 ) we observe that the geodesic distance should scale as

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

yielding the following continuum differential equation for the geodesic
distance two-loop amplitude

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

One observes that time does not scale canonically as maybe expected. We
will see in the next section that this is due to the fractal structure
of the quantum geometry.

This partial differential equation can be solved under the above initial
condition, yielding

  -- -------- -- --------
     @xmath      (5.48)
  -- -------- -- --------

where @xmath is the solution to the characteristic equation

  -- -------- -- --------
     @xmath      (5.49)
  -- -------- -- --------

Equivalently we can write

  -- -------- -- --------
     @xmath      (5.50)
  -- -------- -- --------

One can now insert the solution for the disc function ( 5.28 ) into this
equation and perform the integral,

  -- -------- -- --------
     @xmath      (5.51)
  -- -------- -- --------

where @xmath . Inverting this formula gives

  -- -------- -- --------
     @xmath      (5.52)
  -- -------- -- --------

which together with ( 5.48 ) yields the explicit solution for @xmath .

The geodesic two-loop amplitude is a useful quantity from which many
other quantities can be calculated. For the discussion of the quantum
geometry in the next section we will be especially interested in the
dependence on the geodesic distance. For simplicity, we shall analyze
this dependence by shrinking both boundaries to zero. The resulting
quantity is called the geodesic distance two-point function and was
introduced in [ 98 ] . It is much simpler than the full two-loop
amplitude, but still contains all essential dependence on the geodesic
distance.

Let us first shrink the outer boundary to zero. Performing the inverse
Laplace transform we get

  -- -------- -- --------
     @xmath      (5.53)
  -- -------- -- --------

and hence

  -- -------- -- --------
     @xmath      (5.54)
  -- -------- -- --------

One could have also obtained this result directly from the Laplace
transformed quantity ( 5.48 ) by taking @xmath , where the coefficient
is @xmath which lead to a finite expression. The quantity @xmath is in a
sense similar to @xmath with the difference that it has a marked point
in the bulk which has a geodesic distance @xmath to the entrance loop.
This marked point comes from the boundary which was shrunken to zero. If
we would integrate over @xmath this expression should correspond to the
disc function with a marked point anywhere in the bulk, given by @xmath
. A quick check reveals that this is indeed true, i.e. that

  -- -------- -- --------
     @xmath      (5.55)
  -- -------- -- --------

From ( 5.54 ) we then get for the two-point function @xmath ,

  -- -------- -- --------
     @xmath      (5.56)
  -- -------- -- --------

where we chose @xmath to get a finite expression. ³ ³ 3 The different
values for @xmath when shrinking the initial and final loop to a point
(i.e. @xmath and @xmath ) come from the fact that the initial loop was
marked and the final loop not. Using ( 5.52 ) one gets

  -- -------- -- --------
     @xmath      (5.57)
  -- -------- -- --------

##### 5.3.3 The transfer matrix approach

In this subsection we want to rederive the continuum result for the
fixed geodesic distance two-loop function as obtained by ( 5.48 ) in the
previous subsection using the so-called transfer matrix approach. This
exact method is more rigorous than the peeling method described in the
previous subsection. Further, it employs useful techniques which will be
of importance in the forthcoming chapters.

It was argued in [ 95 ] that any triangulation @xmath can in principle
be uniquely decomposed into triangulations of geodesic distance one,
i.e. @xmath , by slicing it in the way described above. This situation
is shown in Fig. 5.7 .

A nice feature of this construction is that it implies the following
semi-group property or composition law for the propagator

  -- -------- -- --------
     @xmath      (5.58)
  -- -------- -- --------

or in terms of the generating functions

  -- -------- -- --------
     @xmath      (5.59)
  -- -------- -- --------

Fig. 5.10 gives an graphical interpretation of the composition law.
Setting @xmath and @xmath one obtains

  -- -------- -- --------
     @xmath      (5.60)
  -- -------- -- --------

Here @xmath is the so-called one-step propagator which can be seen as
the matrix element of the so-called transfer matrix @xmath ,

  -- -------- -- --------
     @xmath      (5.61)
  -- -------- -- --------

Knowing the transfer matrix one can in principle iterate ( 5.60 ) @xmath
-times to obtain the fixed geodesic distance two-loop amplitude

  -- -------- -- --------
     @xmath      (5.62)
  -- -------- -- --------

If one is however only interested in calculating the continuum
expressions there exists a shortcut to obtain @xmath directly from the
continuum limit of ( 5.60 ) without having to perform the iteration as
we will see in the following.

Our first task is now to calculate the one-step propagator @xmath by
combinatorial methods. So far we have been working with amplitudes which
have a mark on the initial boundary. In some cases it is however useful
to work with amplitudes without a mark on the boundary. The marked and
unmarked propagators are related as follows

  -- -------- -- --------
     @xmath      (5.63)
  -- -------- -- --------

where the @xmath stands for unmarked. Remember that the marked amplitude
has only the initial loop marked and not the final loop. In terms of
generating functionals, ( 5.63 ) reads

  -- -------- -- --------
     @xmath      (5.64)
  -- -------- -- --------

For the unmarked propagator the composition law ( 5.60 ) becomes

  -- -------- -- --------
     @xmath      (5.65)
  -- -------- -- --------

where the measure factor @xmath in the sum is the direct manifestation
of the symmetry factor @xmath in ( 5.5 ).

We will now follow the results of [ 95 ] to combinatorially determine
@xmath . It was shown there that every one-step propagator is made out
of the following four elementary building blocks:

  -- -- -------- -------- -- --------
        @xmath   @xmath      (5.66)
        @xmath   @xmath      (5.67)
        @xmath   @xmath      (5.68)
        @xmath   @xmath      (5.69)
  -- -- -------- -------- -- --------

Here the dotted lines refer to the initial boundary with weight @xmath
per edge and the dashed lines refer to final boundary with weight @xmath
per edge. Again each triangles carries a weight @xmath . Further, the
blobs represent the DT disc function @xmath as derived in Sec. 5.2.1 .

Now we can write the one-step propagator as the composition of all these
terms

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.70)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Here the factor of @xmath reflects the circular symmetry, i.e. @xmath .

In the following we perform the continuum limit using the same scaling
relations as in the previous subsection

  -- -------- -- --------
     @xmath      (5.71)
  -- -------- -- --------

with the same critical values. Inserting the scaling relations and the
solution for @xmath , i.e. ( 5.70 ), into ( 5.64 ) we get to lowest
order in @xmath

  -- -------- -- --------
     @xmath      (5.72)
  -- -------- -- --------

Hence we introduce the following wave function renormalization for the
geodesic two-loop amplitude to match the desired initial condition (
5.44 ),

  -- -------- -- --------
     @xmath      (5.73)
  -- -------- -- --------

From the second term in the expansion of ( 5.72 ) we see that time has
to scale as

  -- -------- -- --------
     @xmath      (5.74)
  -- -------- -- --------

Inserting the full scaling relations and the solution ( 5.72 ) for the
one step propagator into the composition law ( 5.59 ) we obtain

  -- -------- -- --------
     @xmath      (5.75)
  -- -------- -- --------

This is precisely the differential equation for the fixed geodesic
distance two-loop function as derived in the previous subsection, i.e. (
5.47 ). Thus, we rederived the previous result obtained from the peeling
method using the transfer matrix formalism. The solution to the
differential equation ( 5.75 ) is again given by ( 5.48 ).

#### 5.4 Physical observables

One of the simplest observables in two-dimensional Euclidean quantum
gravity is the disc function or Hartle-Hawking wave function which
describes the amplitude of creation of a universe from nothing. The
result was obtained to be

  -- -------- -- --------
     @xmath      (5.76)
  -- -------- -- --------

or

  -- -------- -- --------
     @xmath      (5.77)
  -- -------- -- --------

Having determined the dependence on the geodesic distance through the
two-point function in Sec. 5.3.2 we can further calculate the Hausdorff
dimension @xmath of the quantum geometry. This dimension estimator is
formally defined as

  -- -------- -- --------
     @xmath      (5.78)
  -- -------- -- --------

Using the expression for the two-point function, i.e. ( 5.57 ),

  -- -------- -- --------
     @xmath      (5.79)
  -- -------- -- --------

we obtain

  -- -------- -- --------
     @xmath      (5.80)
  -- -------- -- --------

This equation reflects the fact that at large @xmath the quantum
geometry looks effectively one-dimensional, i.e. the volume is
proportional to the length. Further one can extract from this expression
that the average spatial length of the quantum geometry at intermediate
@xmath behaves as

  -- -------- -- --------
     @xmath      (5.81)
  -- -------- -- --------

Hence for typical time scales of @xmath we have

  -- -------- -- --------
     @xmath      (5.82)
  -- -------- -- --------

Thus we conclude that the Hausdorff dimension of two-dimensional
Euclidean quantum gravity is given by @xmath . This result is somehow
unexpected since we started off with a theory of two-dimensional
triangulations. In fact, this is an indication that the quantum geometry
is fractal [ 99 , 95 , 100 , 101 ] . As we will see explicitly in Sec.
7.1 the quantum geometry is dominated by a proliferation of baby
universes at the cut-off scale, meaning that at every point in the
geometry there splits off a geometry with disc topology. The infinite
number of baby universes causes the increment in the Hausdorff
dimension. This fractal structure can be nicely observed in Fig. 5.11 ,
which shows a typical configuration of the path integral obtained from a
Monte Carlo simulation [ 1 ] .

#### 5.5 Discussion and outlook to higher dimensions

In this chapter we introduced dynamical triangulations as a
regularization scheme to define the Euclidean gravitational path
integral. In particular, we considered the case of two dimensions in
which analytical results can be obtained. We calculated the disc or
Hartle-Hawking wave function, the fixed geodesic distance two-loop
amplitude as well as the two-point function. Using these quantities we
were able to analyze several properties of the quantum geometry. One
very interesting observation is the fractal structure of the quantum
geometry which manifests itself in a proliferation of baby universes at
the cut-off scale. This is related to the unexpected value of the
Hausdorff dimension of @xmath . Fig. 5.11 illustrates this situation by
showing a typical configuration of the path integral obtained from a
Monte Carlo simulation [ 1 ] .

It is interesting to note how this situation translates to higher
dimensions. In an analogous manner to two dimensions one can define the
gravitational path integral as a sum over @xmath -dimensional simplicial
complexes (see for example [ 18 ] for a detailed exposition). The
corresponding Regge action takes the following simple form

  -- -------- -- --------
     @xmath      (5.83)
  -- -------- -- --------

where @xmath denotes the number of @xmath -simplices and @xmath the
number of @xmath -simpices in the triangulation @xmath . The analog
expression to ( 5.5 ) for the partition function is then written as the
sum over closed @xmath -dimensional triangulations @xmath ,

  -- -------- -- --------
     @xmath      (5.84)
  -- -------- -- --------

Since analytical methods are absent in @xmath , one has to perform Monte
Carlo simulations of the quantum geometry (see for instance [ 18 ] ). DT
in three dimensions were considered in [ 102 , 103 , 104 , 105 ] . The
four-dimensional case was first analyzed in [ 106 , 107 , 108 ] ,
followed by further progress in [ 109 , 110 , 111 , 112 , 113 , 114 ] .
The results for @xmath are summarized by the following schematic phase
diagram (Fig. 5.12 ). ⁴ ⁴ 4 Although we only consider the case of @xmath
here, the picture turns out to be essentially the same in the case of
@xmath . One observes that the model possesses an infinite-volume limit
everywhere along the critical line @xmath , which fixes the bare
cosmological constant as a function of the inverse Newton constant
@xmath . Along this critical line, there is a critical point @xmath .
Below this critical point the geometries generically have a very large
Hausdorff dimension @xmath . This can be understood in terms of a
situation where every point in the quantum geometry is effectively at
Planck distance to any other point. We call this the crumpled phase of
the quantum geometry. Above @xmath we find the opposite situation where
a configuration contributing to the state sum looks likes a branched
polymer with Hausdorff dimension @xmath (see Fig. 5.6 ). This is called
the branched polymer phase of the quantum geometry.

One could hope that right at the transition point @xmath genuine
extended triangualtions with a finite Hausdorff dimension might be
dominating. For this to happen the phase transition at this point should
be of second or higher order. Unfortunately, it was found to be of first
kind ⁵ ⁵ 5 Evidence that the phase transition is of first order was
given both in three dimensions [ 105 , 115 ] as well as in four
dimensions [ 116 , 117 , 118 ] . which leaves us with little hope that a
sensible continuum theory of Euclidean quantum gravity can be obtained
from DT for @xmath .

This unsatisfactory situation is one of the reasons for incorporating
causality in DT. We have already seen above that many of the unappealing
features of the quantum geometry were related to the proliferation of
baby universes at the cut-off scale. In a genuine Lorentzian framework
we expect such “acausal” configurations to be suppressed and the path
integral should be much better behaved. The development of such a
genuine Lorentzian framework by so-called causal dynamical
triangulations is the subject of the next chapter.

### Chapter 6 Two-dimensional causal dynamical triangulations

In the previous chapter we introduced the reader to the concept of
dynamical triangulations (DT). As we discussed at the end of the
chapter, DT seems to be incompatible with a well-behaved continuum limit
in three and higher dimensions. This problem is related to the failure
of incorporating the Lorentzian signature into the gravitational path
integral. In this chapter we see how this issue can be resolved in the
framework of Lorentzian quantum gravity defined through causal dynamical
triangulations [ 19 ] . The presentation of this chapter closely follows
[ 19 , 119 , 120 ] .

#### 6.1 Incorporating causality in dynamical triangulations

Inspired by early ideas of Teitelboim [ 121 , 122 ] , we want to
construct a gravitational path integral, where we insist in starting
from space-times with Lorentzian signature. However, to address the
Lorentzian nature of the path integral it is essential to look at
geometries that have an intrinsically defined notion of time. In the
approach of causal dynamical triangulations (CDT), introduced by Ambjørn
and Loll in 1998 [ 19 ] for the case of two dimensions ¹ ¹ 1 Further
developments for two-dimensional CDT have been made in [ 123 , 124 , 125
, 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 ] which will be
partically discussed in more detail in the following chapters.
References to results in higher dimensions will be given in the last
section of this chapter. , this problem is addressed by studying
piecewise linear geometries that have an entirely time-sliced structure.
By virtue of the time-slicing one can globally distinguish timelike and
spacelike edges. We will see that this distinction is essential to
define a consistent Wick rotation.

As in the case of DT one uses triangles at cut-off length to discretize
the geometries. However, in contrary to DT, CDT uses Minkowskian instead
of Euclidean triangles. These have one spacelike edge of length squared
@xmath and two timelike edges of length squared @xmath . By construction
one chooses triangulations with topology of @xmath . Each triangulation
consists of @xmath time slices of height @xmath . The geometry of an
individual time slice is now determined by the composition of @xmath
up-pointing triangles and @xmath down-pointing triangles as illustrated
in Fig. 6.1 .

In this formulation the time @xmath by definition takes the role of
geodesic distance. Further, there are no spatial topology changes with
respect to the time-slicing. Hence, the layered structure does not only
introduce an intrinsic time-direction that enables us to define a Wick
rotation, but it also excludes spatial topology changes which in the
Lorentzian picture lead to singular points with ill-defined signature. ²
² 2 In the next chapter we will relax this constraint and we will show
how one can make sense of spatial topology changes in a Lorentzian
setting.

Since the triangles are simply patches of flat Minkowski space, they are
naturally equipped with a local light cone structure. Furthermore, due
to the sliced structure of the triangulations which glues spacelike to
spacelike and timelike to timelike edges, the triangulation is naturally
equipped with a global causal structure. By virtue of this global causal
structure it is possible to define a Wick rotation for curved manifolds
on the discretized level. In the triangulation context this is done by
performing a Wick rotation on the timelike edges, i.e. @xmath . The Wick
rotation acting on the whole manifold is then defined as

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

As in the continuum case this rotation should be treated with some care
and one must show that the Lorentzian action defined with @xmath can be
analytically continued to the Euclidean action defined with @xmath .
This is done in appendix B.1 , where we discuss in more detail the Regge
action for two-dimensional Lorentzian triangulations. It is shown there
that under the above defined Wick rotation the Boltzmann weight for each
triangulation indeed transforms as

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

We shall see in the forthcoming section that the above defined
kinematical structure reduces the computation of the path integral for
the fixed geodesic distance correlator or finite-time propagator to a
simple statistical mechanics problem.

#### 6.2 The discrete solution

As for DT we fix the space-time topology of the triangulation to be of
the form @xmath . The Regge action is then simply proportional to the
volume of the triangulation,

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

where @xmath is the bare cosmological constant and @xmath the number of
triangles in the triangulation @xmath . Note that an order one factor
coming from the volume term has been absorbed into @xmath . Since all
slices have the same geodesic distance, the propagator or fixed geodesic
distance two-loop function can be defined in a simple manner

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

where @xmath denotes the causal triangulations with initial boundary
length @xmath and final boundary length @xmath constructed out of @xmath
time-slices. Again, @xmath denotes the volume of the automorphism group
of a triangulation. As for DT we add a superscript @xmath to denote the
propagator with no marked points on the boundary. As discussed above,
after the Wick rotation the discrete sum over complex amplitudes is
converted to a genuine statistical model with a real Boltzmann weight,

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

where @xmath and @xmath differ by an order one constant due to the
different volume of Minkowskian and Euclidean triangles (see App. B.1 ).
As for the fixed geodesic distance two-loop amplitude in the case of DT
the propagator satisfies the following semi-group property or
composition law (e.g. ( 5.65 )),

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

where again the measure factor @xmath in the composition law comes from
the periodic boundary conditions. Writing the composition law for @xmath
we find the following relation for the one-step propagator,

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

As for DT we introduce a generating function for @xmath

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

where @xmath and @xmath can again be related to the boundary
cosmological constants of individual triangles,

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

The analogous fugacity of a triangle is again given by,

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

The total Boltzmann weight of one strip can be determined by noting that
for the one-step propagator in CDT a factor of @xmath is assigned for
triangles that have the spacelike edge on the initial loop and a factor
@xmath for triangles where the spacelike edge is on the final loop. This
relation is much simpler than in the case of DT. The one-step propagator
is now easily computed by,

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.11)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where the factor @xmath comes again from dividing by the volume @xmath
of the automorphism group for circular triangulations. Performing the
summations in ( 6.11 ) we readily obtain

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

From the inverse discrete Laplace transform of ( 6.12 ) it can be seen
that the one-step propagator with fixed boundary lengths is given by

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

where the division by the volume of the automorphism group now makes its
appearance in the factor @xmath . Similar expressions for different
boundary conditions can for instance be found in [ 119 ] .

Instead of obtaining the continuum limit directly of the one-step
propagator as done in the previous chapter we want to iteratively
compute the finite-time propagator @xmath and then perform the continuum
limit. To do so we rewrite the composition law ( 6.6 ) in terms of
generating functions and obtain,

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

Setting @xmath and performing the contour integration over @xmath one
gets

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

Inserting the expression for the one-step propagator, i.e. ( 6.12 ),
yields

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

This equation can be iterated and the implicit solution written as

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

where @xmath is defined iteratively by

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

The fixed point @xmath of this equation as defined by @xmath is given by

  -- -------- -- --------
     @xmath      (6.19)
  -- -------- -- --------

By standard techniques one can use the fixed point to give the explicit
solution to the iterative equation ( 6.18 )

  -- -------- -- --------
     @xmath      (6.20)
  -- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (6.21)
  -- -------- -- --------

The explicit solution for the propagator is now obtained by substituting
( 6.20 ) in ( 6.17 ), yielding

  -- -------- -- --------
     @xmath      (6.22)
  -- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (6.23)
  -- -------- -- --------

The combined region of convergence of this result as an expansion in
powers @xmath is

  -- -------- -- --------
     @xmath      (6.24)
  -- -------- -- --------

As in the case of DT we will use the radius of convergence to obtain the
critical points.

#### 6.3 The continuum limit

To define the continuum limit of the theory we assume canonical scaling
dimensions for the bulk and boundary cosmological constants as in the
case of DT,

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

The critical values for these couplings are again determined by the
region of convergence of the propagator, i.e. ( 6.24 ), yielding

  -- -------- -- --------
     @xmath      (6.26)
  -- -------- -- --------

One can quickly convince oneself that these are the correct critical
vales by looking at the average number of triangles in one strip

  -- -------- -- --------
     @xmath      (6.27)
  -- -------- -- --------

We see that the average number of triangles diverges at the critical
point @xmath . We hence arrive at the following scaling relations

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

The continuum limit of the propagator can now be determined by inserting
these scaling relations into ( 6.22 ). To get a sensible continuum limit
we require time to scale as

  -- -------- -- --------
     @xmath      (6.29)
  -- -------- -- --------

which yields the following result

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.31)
  -- -------- -- --------

As in the case of DT the propagator undergoes a wave function
renormalization

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

Again the power of @xmath is uniquely determined by the initial
condition coming from the composition law, i.e. ( 6.14 ).

The continuum expression for the propagator, where the boundary lengths
are fixed instead of the boundary cosmological constants can now be
obtained by an inverse Laplace transformation of ( 6.30 ) with respect
to both @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.33)
  -- -------- -- --------

where @xmath is a modified Bessel function of the first kind. The
continuum version of the composition law ( 6.14 ) for fixed lengths then
reads

  -- -------- -- --------
     @xmath      (6.34)
  -- -------- -- --------

An interesting observation is that in contrast to the Euclidean model
the time or geodesic distance scales canonically. We will further
comment on this when discussing the physical observables of the model.

#### 6.4 Marked amplitudes

To better compare to the results of the previous chapter for Euclidean
DT it is important to introduce the same convention of a marked edge on
the initial boundary in CDT. In terms of the propagator this convention
reads,

  -- -------- -- --------
     @xmath      (6.35)
  -- -------- -- --------

As before this marking removes the measure factor in the composition law
for the propagator ( 6.6 )

  -- -------- -- --------
     @xmath      (6.36)
  -- -------- -- --------

which corresponds to the following composition law for the generating
function,

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

The one-step propagator with a mark on the boundary can easily be
computed from ( 6.12 ) by taking a derivative with respect to the
boundary cosmological constant,

  -- -------- -- --------
     @xmath      (6.38)
  -- -------- -- --------

Inserting this expression into the composition law ( 6.36 ) gives an
iterative equation analogous to ( 6.16 ) ,

  -- -------- -- --------
     @xmath      (6.39)
  -- -------- -- --------

The explicit solution can be obtained from ( 6.22 ) by taking a
derivative with respect to the boundary cosmological constant,

  -- -------- -- --------
     @xmath      (6.40)
  -- -------- -- --------

where @xmath , @xmath , @xmath and @xmath were defined in ( 6.19 ) and (
6.21 ).

To obtain the continuum marked propagator we could now apply the scaling
relations ( 6.28 ) to this expression. Instead, one can also apply the
scaling relations directly to ( 6.39 ) in the manner we proceeded for
DT. Doing so one finds the following differential equation for the
continuum marked propagator,

  -- -------- -- --------
     @xmath      (6.41)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

The notation @xmath is introduced in analogy to the Euclidean result,
however, it should be noted that in the case of CDT @xmath is not the
disc function.

Solving the differential equation ( 6.41 ) with initial condition

  -- -------- -- --------
     @xmath      (6.43)
  -- -------- -- --------

gives

  -- -------- -- --------
     @xmath      (6.44)
  -- -------- -- --------

where @xmath is the solution to the characteristic equation

  -- -------- -- --------
     @xmath      (6.45)
  -- -------- -- --------

Proceeding as in Sec. 5.3.2 we obtain,

  -- -------- -- --------
     @xmath      (6.46)
  -- -------- -- --------

Inserting this expression in ( 6.44 ) gives the explicit solution for
the continuum marked propagator. Further, one can check that if one
marks the unmarked propagator ( 6.30 ) by taking a derivative with
respect to the initial boundary cosmology constant @xmath , the
resulting expression precisely coincides with this result. Inverse
Laplace transforming ( 6.44 ) with respect to @xmath and @xmath yields
the continuum marked propagator in the length representation,

  -- -------- -- --------
     @xmath      (6.47)
  -- -------- -- --------

which is simply ( 6.33 ) multiplied by @xmath as expected.

As in the case of DT we can also calculate the disc function from the
propagator. In CDT it can be defined as follows from the finite-time
propagator with one boundary shrunken to zero,

  -- -------- -- --------
     @xmath      (6.48)
  -- -------- -- --------

One notices that this definition differs slightly from the corresponding
relation in the Euclidean setting, i.e. ( 5.55 ). This is due to the
fact that the mark coming from the zero-length boundary is always at
latest @xmath and cannot be anywhere in the bulk as in the case of DT.
Therefore we do not have to differentiate with respect to @xmath .

Using ( 6.33 ) we get

  -- -------- -- --------
     @xmath      (6.49)
  -- -------- -- --------

Inserting this into ( 6.48 ) one readily arrives at the simple
expression

  -- -------- -- --------
     @xmath      (6.50)
  -- -------- -- --------

or in Laplace transform language

  -- -------- -- --------
     @xmath      (6.51)
  -- -------- -- --------

The corresponding result for the disc function without mark reads

  -- -------- -- --------
     @xmath      (6.52)
  -- -------- -- --------

From ( 6.49 ) we can also easily compute the two-point function for CDT,
i.e.

  -- -------- -- --------
     @xmath      (6.53)
  -- -------- -- --------

#### 6.5 Hamiltonians in causal quantum gravity

As mentioned earlier the concept of time or geodesic distance directly
relates to a notion of Hamiltonian dynamics. This can be seen explicitly
when viewing the differential equation for the continuum marked
propagator ( 6.41 ) as a Wick rotated Schrödinger equation,

  -- -------- -- --------
     @xmath      (6.54)
  -- -------- -- --------

Here @xmath can be interpreted as the effective quantum Hamiltonian of
the system and is given by

  -- -------- -- --------
     @xmath      (6.55)
  -- -------- -- --------

The effective quantum Hamiltonian in length space can be obtained from (
6.54 ) by inverse Laplace transformation, yielding

  -- -------- -- --------
     @xmath      (6.56)
  -- -------- -- --------

The corresponding Hamiltonian for the case of unmarked amplitudes reads

  -- -------- -- --------
     @xmath      (6.57)
  -- -------- -- --------

These kind of Hamiltonians are analyzed in detail in App. B.2 , where
several properties such as the spectrum and eigenfunctions are computed.
In particular, it is shown there that the Hamiltonian ( 6.57 ) is
self-adjoint with respect to the measure @xmath . This is also reflected
in the corresponding semi-group property, where the integration is taken
over the same measure. As we will see later for some comparisons it is
useful to transform this Hamiltonian to one which is self-adjoint on a
flat measure. This can be done by absorbing the measure in the wave
functions corresponding to the initial and final loop, i.e. @xmath .
Commuting ( 6.57 ) with @xmath gives ³ ³ 3 See App. B.2 for more
details.

  -- -------- -- --------
     @xmath      (6.58)
  -- -------- -- --------

In the following we present a calculation by Nakayama [ 134 ] which
reproduces the effective quantum Hamiltonian of CDT, i.e. ( 6.58 ) from
a continuum calculation. More precisely, Nakayama considered the
non-local “induced” action of two-dimensional quantum gravity in the
proper time gauge. The general form of this action was first introduced
by Polyakov [ 64 ] and reads

  -- -------- -- --------
     @xmath      (6.59)
  -- -------- -- --------

where @xmath is the scalar curvature corresponding to the metric @xmath
, @xmath denotes time and @xmath the spatial coordinate. In the proper
time gauge the metric has the form

  -- -------- -- --------
     @xmath      (6.60)
  -- -------- -- --------

This is in contrast to the conformal gauge with @xmath . It was shown by
Nakayama that in this gauge the classical dynamics is described entirely
by the following effective action

  -- -------- -- --------
     @xmath      (6.61)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.62)
  -- -------- -- --------

and where @xmath is an integration constant coming from the solution for
the energy-momentum tensor component @xmath . As can be seen from Eq. (
6.62 ) @xmath is precisely the length of a spatial universe at constant
@xmath , as calculated from the metric ( 6.60 ).

One can now quantize the action @xmath for @xmath , where @xmath can be
interpreted as a winding number. It was further argued in [ 134 ] that
in the quantum theory one should shift @xmath by @xmath leading to
@xmath . The classical Hamiltonian corresponding to the effective action
( 6.61 ) with @xmath then reads

  -- -------- -- --------
     @xmath      (6.63)
  -- -------- -- --------

where @xmath is the canonical momentum conjugate to @xmath . To
canonically quantize the system we make the standard replacement @xmath
, yielding ⁴ ⁴ 4 For completeness the spectrum of this Hamiltonian is
also derived in App. B.2 .

  -- -------- -- --------
     @xmath      (6.64)
  -- -------- -- --------

One observes that for @xmath this Hamiltonian precisely coincides with
the effective quantum Hamiltonian for CDT, i.e. ( 6.58 ). An
interpretation for @xmath in the context of CDT was given in [ 126 ] .

Quite remarkably, when computing the propagator,

  -- -------- -- --------
     @xmath      (6.65)
  -- -------- -- --------

one observes that

  -- -------- -- --------
     @xmath      (6.66)
  -- -------- -- --------

precisely coincides with the two-loop amplitude of Euclidean DT [ 134 ]
. While a summation over the winding number might seem natural, a
complete understanding of this relation is still lacking.

Before moving to the next section let us briefly mention that, since in
CDT we are using a lattice regularization, the continuum variables are
only defined up to a factor of proportionality which should be fixed by
comparing to a continuum calculation. Recall that the length @xmath
appearing in Nakayama’s Hamiltonian is not the physical length, @xmath ,
but @xmath . Hence, since both models are described by the same
effective quantum Hamiltonian, it is natural to also define the physical
length @xmath for CDT. We will use this assignment in Chap. 8 when
discussing the emergence of a semiclassical background in the context of
CDT.

#### 6.6 Physical observables: Comparing CDT and DT

As in the case of DT one of the simplest observables is the disc
function or Hartle-Hawking wave function which describes the amplitude
of creation of a universe from nothing. The result is given by ( 6.51 ),
i.e

  -- -------- -- --------
     @xmath      (6.67)
  -- -------- -- --------

The corresponding Euclidean expression ( 5.28 ), here labeled with a
superscript @xmath to distinguish from the analogous CDT expressions, is

  -- -------- -- --------
     @xmath      (6.68)
  -- -------- -- --------

Another interesting quantity to calculate is the Hausdorff dimension
@xmath of the quantum geometry formally defined as

  -- -------- -- --------
     @xmath      (6.69)
  -- -------- -- --------

We saw that in Euclidean DT we had a fractal dimension of @xmath which
was related to the non-canonical scaling of time. We already observed
above that in CDT time scales canonically and we therefore expect the
Hausdorff dimension to be @xmath . In the following we will check this
by a simple calculation.

From ( 6.53 ) we have

  -- -------- -- --------
     @xmath      (6.70)
  -- -------- -- --------

From this we obtain

  -- -------- -- --------
     @xmath      (6.71)
  -- -------- -- --------

This equation reflects the fact that at large @xmath the quantum
geometry looks effectively one-dimensional. Further we see from this
expression that the average spatial length of the quantum geometry at
intermediate @xmath behaves as

  -- -------- -- --------
     @xmath      (6.72)
  -- -------- -- --------

Hence for typical time scales of @xmath we have

  -- -------- -- --------
     @xmath      (6.73)
  -- -------- -- --------

which yields a Hausdorff dimension of @xmath . In this sense the quantum
geometry of CDT is much better behaved as a model of two-dimensional
quantum gravity in contrary to DT which has a fractal dimension of
@xmath .

To get a better picture of the quantum geometry of CDT it is instructive
to look at a typical space-time geometry (Fig. 6.2 ). We see that in
contrast to the Euclidean model there are no spatial topology changes.
Further, as we have already seen above the average spatial length of the
quantum geometry behaves as

  -- -------- -- --------
     @xmath      (6.74)
  -- -------- -- --------

A simple calculation as will be presented in Chap. 8 reveals that also
the fluctuations scale as

  -- -------- -- --------
     @xmath      (6.75)
  -- -------- -- --------

Hence we see that the two-dimensional quantum geometry is purely
governed by quantum fluctuations and there does not exist a sensible
semiclassical background geometry. We will see in Chap. 8 how this
situation changes when one of the boundaries is taken to infinity and
the geometry becomes non-compact.

#### 6.7 Summary and outlook to higher dimensions

In this chapter we introduced two-dimensional Lorentzian quantum gravity
defined through CDT.

The triangulations used in CDT have a global time-slicing without
spatial topology changes. This is unlike DT where spatial topology
changes are naturally present. The global notion of time enables us to
define a gravitational Wick rotation. We solved the combinatorial
problem and performed the continuum limit. As a result we saw that
two-dimensional CDT and DT are distinct theories. Whereas the continuum
dynamics of DT is completely dominated by spatial topology changes
leading to a fractal dimension of @xmath , the situation is different in
CDT where we have @xmath . In this sense two-dimensional CDT is arguably
better suited as a model of two-dimensional quantum gravity than DT.
Before discussing several relations between both theories in the next
chapter, let us first comment on the results for higher dimensions.

In contrast to the disappointing situation for DT in higher dimensions,
as described in the previous chapter, CDT lead to very interesting
results for both @xmath [ 135 , 136 , 137 , 138 , 139 , 140 , 141 ] as
well as @xmath [ 142 , 143 , 144 , 145 , 146 , 147 ] (see also [ 21 , 20
, 145 , 148 ] for a general overview).

Let use briefly mention some of the numerical results obtained from
Monte Carlo simulations in 3+1 dimensions. A very important non-trivial
test for every non-perturbative formulation of quantum gravity is
whether it can reproduce a sensible classical limit at macroscopic
scales. The numerical results indicate that the scaling behavior of the
spatial volume as a function of space-time volume is that of a
four-dimensional universe at large scales, a first indication of
sensible classical behavior [ 142 ] . Moreover, after integrating out
all dynamical variables apart from the spatial volume as a function of
proper time, one can derive the scale factor whose dynamics is described
by the simplest minisuperspace model used in quantum cosmology [ 143 ,
145 , 146 , 147 ] . In Chap. 8 we will describe an analogous model in
two dimensions where a semi-classical background emerges from quantum
fluctuations when the geometries become non-compact.

Having passed the first consistency checks regarding the macro scopical
structure of space-time it is very interesting what predictions one can
make for the quantum nature of the micro structure of space-time. One
important observable which has been measured is the spectral dimension
of space-time which is the dimension a diffusion process would feel on
the space-time ensemble. Surprisingly, this quantity depends on the
scale at which it is measured. More precisely, one observes a
dimensional reduction from four at large scales to two at small scales
within measurement accuracy [ 144 ] . This gives an indication that
non-perturbative quantum gravity defined through CDT provides an
effective ultraviolet cut-off through a dynamical dimensional reduction
of space-time and might therefore be non-perturbatively renormalizable.
The origin of the renormalizability could be a nontrivial fixed point
scenario as described by Weinberg [ 16 ] . It is interesting to note
that similar results were also obtained in the exact renormalization
group flow method for Euclidean quantum gravity in the continuum [ 149 ,
150 , 151 , 152 , 153 ] .

An interesting observation at this point is that such an effective
ultraviolet cut-off through a dynamical dimensional reduction of
space-time provides us with a non-perturbative mechanism which regulates
the theory. To come back to the discussion in Part I of this thesis,
this means in particular that it is priori not necessary to introduce a
fundamental cut-off such as the fundamental discreteness scale by hand.

### Chapter 7 Relating Euclidean and causal dynamical triangulations

In the previous two chapters we introduced two-dimensional Euclidean
quantum gravity defined through DT and two-dimensional Lorentzian
quantum gravity defined through CDT. Even though both theories have some
physically very distinct features such a the Hausdorff dimension it is
nevertheless possible to establish certain relations between them. In
particular, following [ 19 , 125 ] , we describe how CDT and DT can be
related by respectively introducing or “integrating out” baby universes,
i.e. spatial topology changes.

#### 7.1 Introducing spatial topology changes: From CDT to DT

In this section we discuss the incorporation of spatial topology changes
into the discretized framework of CDT and show how this model relates to
DT in the continuum limit. Although there exist several ways of
implementing spatial topology changes on the discrete level, they all
lead to the same continuum description [ 19 ] .

Before constructing the model let us first discuss some Lorentzian
aspects of spatial topology changes. While in the Euclidean model the
presence of baby universes was natural, their appearance in the
Lorentzian model is far from obvious. Even though the metrics are Wick
rotated from Lorentzian to Euclidean signature, one in general still has
to perform an inverse Wick rotation. However, this is not so easy for
geometries with baby universes, since these geometries do not admit a
Lorentzian metric everywhere, as we already mentioned above. This is
related to the fact that it is not possible to find a non-vanishing
vector field everywhere. However, since the geometry is compact there
are only finitely many isolated points where this is not possible. These
are so-called Morse points [ 154 , 155 , 156 , 157 , 158 ] . If one
imagines the splitting of a spatial universe into two, there is a Morse
point precisely at the moment where the spatial topology is that of a
“figure eight”. Embedded in @xmath the two-dimensional geometry looks
like an up-side down trousers and the Morse point precisely corresponds
to the saddle point. Contrary to a generic point on the manifold, such a
Morse point does not have a unique timelike vector field perpendicular
to its spatial slice. In fact it has two future, and two past light
cones which is referred to as a double light cone structure [ 158 ] and
the resulting geometry is called causally discontinuous. Such a double
light cone structure is illustrated in Fig. 7.1 for the case of the
up-side down trousers. One observes that both legs of the trousers carry
a future light cone belonging to the Morse point at the splitting, while
the mother universe carries the two past light cones.

Since there are indications that the Einstein-Hilbert action develops
complex valued singularities at these Morse points [ 159 ] , it is not a
priori clear that the Wick rotation as employed in CDT is valid at these
points. However, since we want to relate our model to Euclidean DT, we
can confine ourselves to the Euclidean sector of CDT. In Chap. 9 we
present a generalized model of CDT which includes spatial topology
changes, and where one in principle would like to Wick rotate back to
the Lorentzian sector. However, in this model there is a coupling
constant associated to every splitting which might be used to absorb
possible divergencies.

Let us now, after this short digression, focus on the explicit
construction of the discretized CDT model with spatial topology changes.
The first step is to generalize the one-step propagator by allowing the
initial loop to have topology of a “figure eight”. One possibility to do
so is to non-locally identify two points of an initial spatial universe
with topology @xmath . For a boundary of length @xmath this so-called
pinching leads to a combinatorial factor of @xmath in the full one-step
propagator. A baby universe is then created by assigning a disc function
to one of the loops of the “figure eight” and the initial loop of a
“bare” one-step propagator to the other one (see Fig. 7.2 ). Putting the
above relation into formulas, we see that the new, or “dressed”,
one-step propagator is related to the old, or “bare”, one-step
propagator as follows

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

where @xmath denotes the so far undetermined disc function and the
factor of two comes again from the two different ways of attaching the
disc function. One observes the analogy to the peeling equation for the
fixed geodesic distance two-loop amplitude in DT.

It is readily checked that the “dressed” one-step propagator obeys the
usual semi-group property, i.e. ( 6.36 ),

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

Making the standard choice @xmath and @xmath to relate to the one-step
propagator we obtain

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

or in terms of generating functions

  -- -------- -- -------
     @xmath      
     @xmath      (7.4)
  -- -------- -- -------

Inserting the explicit solution for the “bare” one-step propagator
@xmath , i.e. ( 6.38 ), as derived in the previous chapter, we get

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

At this point neither the dressed disc amplitude @xmath nor the
propagator @xmath are known. In particular, @xmath is not fixed to be
the Euclidean disc function. In the following we will show how one can
use scaling arguments to uniquely determine the continuum propagator
@xmath and the continuum disc amplitude @xmath from this equation. Let
us assume the standard scaling relations for the boundary and bulk
cosmological constants as used in DT and the “bare” CDT model,

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

Inserting the scaling relations into ( 7.5 ) and setting @xmath we
obtain the initial condition

  -- -------- -- -------
     @xmath      (7.7)
  -- -------- -- -------

where we introduced the following wave function renormalization

  -- -------- -- -------
     @xmath      (7.8)
  -- -------- -- -------

or in terms of the lengths variables

  -- -------- -- -------
     @xmath      (7.9)
  -- -------- -- -------

Extracting the scaling of the disc function is more difficult, since it
actually depends on the scaling of time. To do so Ambjørn and Loll used
the following combinatorial identity

  -- -------- -- --------
     @xmath      (7.10)
  -- -------- -- --------

which in terms of the generating functions reads

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

Fig. 7.3 illustrates this relation: If we introduce a mark in the bulk
by taking a derivative with respect to the fugacity @xmath , the disc
function can be decomposed into a propagator and a smaller disc function
which has this mark on its boundary. Further, one sums over all @xmath
to ensure that the mark can be anywhere in the bulk.

Recall from Chap. 5 and Chap. 6 that the disc function for DT scales as

  -- -------- -- --------
     @xmath      (7.12)
  -- -------- -- --------

while the disc function for CDT scales as

  -- -------- -- --------
     @xmath      (7.13)
  -- -------- -- --------

Hence, we make the following general ansatz for the scaling relation
which includes both cases

  -- -------- -- --------
     @xmath      (7.14)
  -- -------- -- --------

Further, the general scaling ansatz for the time variable reads

  -- -------- -- --------
     @xmath      (7.15)
  -- -------- -- --------

which describes both the non-canonical scaling of time for DT, i.e.
@xmath as well as the canonical scaling of time for CDT, i.e. @xmath .
Below we show that by allowing the branching into baby universes to
contribute in the continuum limit one is led to a non-canonical scaling
of time as for DT.

Inserting the scaling relations ( 7.6 ), ( 7.14 ) and ( 7.15 ) into the
combinatorial identity ( 7.11 ) we obtain

  -- -------- -- --------
     @xmath      
     @xmath      (7.16)
  -- -------- -- --------

where we have @xmath in the non-singular part.

From the last equation and the requirement that @xmath it follows that
there are only two consistent choices for @xmath :

-    Scaling 1: @xmath

    In this range the non-scaling part does not survive the continuum
    limit and Eq. ( 7.16 ) becomes

      -- -------- -- --------
         @xmath      (7.17)
      -- -------- -- --------

    Hence, we conclude that @xmath as in the case of CDT. We observe
    that whenever the non-scaling part of the disc function is not
    present in the continuum result time must scale canonically.

-    Scaling 2: @xmath

    In this range Eq. ( 7.16 ) splits into two equations

      -- -------- -- --------
         @xmath      (7.18)
      -- -------- -- --------

    and

      -- -------- -- --------
         @xmath      (7.19)
      -- -------- -- --------

    From the first equation we see that @xmath while from the second
    equation we have @xmath . Combining these requirements we get @xmath
    and @xmath which precisely correspond to the scaling relations of
    DT, i.e ( 5.46 ) and ( 5.27 ). Further, we observe that using @xmath
    and @xmath Eq. ( 7.18 ) reads

      -- -------- -- --------
         @xmath      (7.20)
      -- -------- -- --------

    which is nothing but the relation between the disc function and the
    propagator as obtained in DT, i.e. ( 5.55 ). In addition for @xmath
    and @xmath Eq. ( 7.19 ) becomes

      -- -------- -- --------
         @xmath      (7.21)
      -- -------- -- --------

    where the constant is related to the non-scaling part of the disc
    function and does not play any role in the continuum theory.

The relation ( 7.20 ) has an intersting interpretation in terms of baby
universes, namely, it shows that at any mark in the bulk there is a baby
universe whose boundary is of length of the cut-off. Further, since the
mark can be anywhere, we conclude that near every point of the quantum
geometry there is a baby universe with cut-off size boundary. This
situation is illustrated in Fig. 7.4 (a). Mapping the picture into the
plane, as shown in Fig. 7.4 (b), clearly visualizes the fractal
structure of the quantum geometry. Another indication for the importance
of geometries with infinitesimal boundaries comes from the Laplace
transform of ( 7.21 ), i.e.

  -- -------- -- --------
     @xmath      (7.22)
  -- -------- -- --------

Essentially, this equation shows that the distribution of geometries is
peaked around universes that have infinitesimal boundary length.

Using the above scaling relations one can now analyze the scaling limit
of ( 7.5 ) to obtain a differential equation for the dressed propagator.
In order for the scaling limit of the equation to exist, the critical
values @xmath and @xmath must satisfy two relations which can be
straightforwardly determined from ( 7.5 ). The remaining continuum
differential equation equation reads

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.23)
                                @xmath   
  -- -------- -------- -------- -------- --------

The first term on the right-hand-side of ( 7.23 ) is related to the bare
CDT model, while the second term corresponds to the creation of baby
universes as is also present in DT. In particular, we saw in the
previous chapter that the first term was related to the effective
quantum Hamiltonian of CDT and hence represents the kinetic term of the
more general model ( 7.23 ).

In the case where @xmath (more precisely @xmath ) the last term in (
7.23 ) diverges. This reflects the fact that the bare model is
incompatible with spatial topology changes. However, dropping the
divergent term, i.e. excluding spatial topology changes we have already
seen that for @xmath we need to have that @xmath leaving us with the
continuum differential equation for the propagator of the bare CDT
model, i.e. ( 6.41 ), as a unique solution

  -- -------- -- --------
     @xmath      (7.24)
  -- -------- -- --------

For the second possible scaling, where @xmath , the last term on the
right-hand-side of ( 7.23 ) will dominate over the first while still
being compatible with the time derivative term. Hence, the kinetic term
of the model does not survive the continuum limit and the dynamics is
entirely governed by the off-spliting baby universes , or as Ambjørn and
Loll express it, once we allow for the creation of baby universes, this
process will completely dominate the continuum limit. We have seen above
that the only scaling consistent with @xmath is @xmath . Inserting the
corresponding scaling relation into ( 7.23 ) we obtain the following
differential equation

  -- -------- -- --------
     @xmath      (7.25)
  -- -------- -- --------

This is precisely of the form of the differential equation ( 5.47 ) for
the propagator of DT. However, at this stage @xmath and with that @xmath
are still undetermined. In the following we want to show how this
equation combined with Eq. ( 7.20 ), completely determines the continuum
disc function @xmath to be that of DT. Integrating ( 7.25 ) with respect
to @xmath and using the initial condition

  -- -------- -- --------
     @xmath      (7.26)
  -- -------- -- --------

i.e. in Laplace transform language

  -- -------- -- --------
     @xmath      (7.27)
  -- -------- -- --------

we obtain

  -- -------- -- --------
     @xmath      (7.28)
  -- -------- -- --------

From dimensional analysis one can easily see that @xmath must have mass
dimension @xmath and hence can be written as @xmath . This condition
implies the following general form for the solution of the disc function

  -- -------- -- --------
     @xmath      (7.29)
  -- -------- -- --------

We can further fix one of the two constants by noting that @xmath is not
allowed to have any singularities or cuts for @xmath . This requirement
is essentially the same as saying that the inverse Laplace transform of
( 7.29 ), i.e. @xmath , should be bounded for @xmath . This completely
fixes the analytic structure of the disc function, yielding

  -- -------- -- --------
     @xmath      (7.30)
  -- -------- -- --------

Upon rescaling of the boundary and bulk cosmological constants we can
absorb the constant @xmath and obtain the disc function of DT, i.e. (
5.28 ),

  -- -------- -- --------
     @xmath      (7.31)
  -- -------- -- --------

#### 7.2 Integrating out baby universes: From DT to CDT

In the previous section we showed how to obtain DT from CDT by
introducing spatial topology changes, i.e. by allowing baby universes to
appear. In the following we want to show the opposite, namely how to
obtain CDT from DT by “integrating out” the baby universes [ 125 ] .
Since the baby universes completely dominate the continuum dynamics of
DT such a relationship has to be established on the discrete level.

We remind the reader of the following differential equation for the
discrete fixed geodesic distance two-loop function in DT, i.e. ( 5.41 ),
which we obtained from the peeling procedure,

  -- -------- -- --------
     @xmath      (7.32)
  -- -------- -- --------

where we defined

  -- -------- -- --------
     @xmath      (7.33)
  -- -------- -- --------

The initial condition of this differential equation was given in ( 5.36
), i.e.

  -- -------- -- --------
     @xmath      (7.34)
  -- -------- -- --------

Here the first term in ( 7.33 ) corresponded to the first decomposition
move, e.g. removing a triangle, while the second term corresponded to
the second move, where a double link was removed and a baby universe
(disc function) splits off. A first idea for integrating out the baby
universes would therefore be to drop the second term in ( 7.33 ).
However, as we are using unrestricted triangulations (recall Fig. ( 5.3
) (b)) also double links are present. Hence, there could still be
off-splitting branched polymers which correspond to zero volume disc
functions, i.e. ( 5.14 ),

  -- -------- -- --------
     @xmath      (7.35)
  -- -------- -- --------

Thus we integrate out the (non-zero volume) baby universes by simply
replacing the term @xmath in ( 7.33 ) by @xmath , yielding

  -- -------- -- --------
     @xmath      (7.36)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (7.37)
  -- -------- -- --------

subject to the same initial conditions ( 7.34 ). Fig. 7.5 illustrates
the peeling equation ( 7.36 ).

We now want to show how to obtain the continuum CDT propagator by taking
a suitable continuum limit of ( 7.36 ). It is natural to use the
standard scaling relations for the boundary and bulk cosmological
constants which were applicable for both DT and CDT,

  -- -------- -- --------
     @xmath      (7.38)
  -- -------- -- --------

As before the demanded continuum initial condition

  -- -------- -- --------
     @xmath      (7.39)
  -- -------- -- --------

already fixed the wave function renormalization of the propagator, i.e.

  -- -------- -- --------
     @xmath      (7.40)
  -- -------- -- --------

Further, we note that to obtain a non-trivial continuum dynamics we
demand that @xmath . This requirement completely fixed the scaling
relations: Firstly, form @xmath and the scaling relations ( 7.38 ) it
follows that

  -- -------- -- --------
     @xmath      (7.41)
  -- -------- -- --------

as it is the case for CDT. Secondly, the requirement that the order one
and order @xmath part of @xmath should vanish determines

  -- -------- -- --------
     @xmath      (7.42)
  -- -------- -- --------

Inserting the complete scaling relations into ( 7.36 ) yields (under
rescaling of the couplings)

  -- -------- -- --------
     @xmath      (7.43)
  -- -------- -- --------

with the above initial conditions. This differential equation precisely
coincides with the differential equation for the propagator of CDT, i.e.
( 6.41 ). Hence we showed how to obtain CDT from DT by integrating out
baby universes.

#### 7.3 The renormalization relation

As an interesting relation between DT and CDT, it was shown in [ 125 ]
that it is possible to “renormalize” the couplings and time of DT in
such a way that the differential equation for the DT propagator is
matched to the one of the CDT propagator. This “renormalization”
relation can be established both in the discrete as well as in the
continuum [ 125 ] . We will in the following only derive the continuum
relation.

Let us for the remainder of this chapter label all Euclidean quantities
with a tilde. The differential equation for the Euclidean propagator
thus reads,

  -- -------- -- --------
     @xmath      (7.44)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (7.45)
  -- -------- -- --------

was the Euclidean disc function. The corresponding equation in the
framework of CDT reads

  -- -------- -- --------
     @xmath      (7.46)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (7.47)
  -- -------- -- --------

Here the hat (not to be confused with the tilde) should remind ourself
that @xmath is not the disc function of CDT but rather related to the
effective quantum Hamiltonian of the system.

To relate ( 7.44 ) and ( 7.46 ) we make the following ansatz for the
renormalization relations of the couplings and time

  -- -------- -- --------
     @xmath      (7.48)
  -- -------- -- --------

where @xmath is a constant and the factor of @xmath in front of the
@xmath has been chosen for dimensional reasons. To map the differential
equation ( 7.44 ) for DT into the differential equation ( 7.46 ) for CDT
using the relations ( 7.48 ), we must have the following wave function
renormalizations

  -- -------- -- --------
     @xmath      (7.49)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (7.50)
  -- -------- -- --------

Integrating the second relation gives

  -- -------- -- --------
     @xmath      (7.51)
  -- -------- -- --------

Since we require that @xmath should imply @xmath the integration
constant must be @xmath . Inserting ( 7.45 ) and ( 7.47 ) into ( 7.51 )
with @xmath and performing the integrals gives

  -- -------- -- --------
     @xmath      (7.52)
  -- -------- -- --------

To further simplify this expression we perform a rescaling of both
@xmath and @xmath to choose

  -- -------- -- --------
     @xmath      (7.53)
  -- -------- -- --------

Using this relation ( 7.53 ) becomes

  -- -------- -- --------
     @xmath      (7.54)
  -- -------- -- --------

Together with

  -- -------- -- --------
     @xmath      (7.55)
  -- -------- -- --------

these equations determine the whole set of renormalization relations.

These renormalization relations map the differential equation of the DT
propagator ( 7.44 ) to the corresponding differential equation of the
CDT propagator ( 7.46 ). Further, it shows that the process of
“integrating out” baby universes which we discussed in the previous
section can be understood as a renormalization of the cosmological
constants and the time variable combined with a dressing of the
propagator.

It is interesting to notice that the relation ( 7.54 ) is similar to one
encountered in regularized bosonic string theory in dimensions @xmath [
160 , 85 , 161 ] , where the world sheet degenerates into so-called
branches polymer. The two-point function of these branched polymers is
related to the ordinary two-point function of the free relativistic
particle by chopping off (i.e. integrating out) the branches, just
leaving for each branched polymer connecting two points in target space
one path connecting the two points. The mass-parameter of the particle
is then related to the corresponding parameter in the partition function
for the branched polymers as @xmath to @xmath in ( 7.54 ).

#### 7.4 Discussion and outlook

In this chapter we explained several relations between two-dimensional
Euclidean quantum gravity defined through DT and two-dimensional
Lorentzian quantum gravity defined through CDT.

It was shown that when introducing spatial topology changes into the
framework of CDT one arrives at a continuum differential equation for
the gravitational propagator which only allows for two possible
scalings. In the first scaling time scales canonically and spatial
topology changes, i.e. off-splitting baby universes are forbidden. This
scaling leads back to the ‘bare” model of CDT without spatial topology
changes as described in the previous chapter. However, in the second
scaling where time scales non-canonical spatial topology changes are
possible and the model naturally leads to DT. Further, we observed how
in this scaling the baby universes completely dominate the continuum
limit, explaining the fractal structure of two-dimensional Euclidean
quantum gravity.

In the Sec. 7.2 of this chapter we showed the opposite relation, namely,
when integrating out the baby universes in DT one recovers CDT. This was
done by introducing a new peeling equation similar to the one used to
calculated the fixed geodesic distance two-loop function in Sec. 5.3.2 ,
where outgrowing baby universes are replaced by branched polymers,
i.e. zero-volume baby universes.

In the last section of this chapter we showed how the process of
“integrating out” baby universes could be understood as a
renormalization of the cosmological constants and the time variable
combined with a dressing of the propagator.

In summary, we showed many relations between CDT and DT by respectively
introducing or “integrating out” baby universes. An unsatisfactory
situation at this point is that we were in a sense not able to
“regularize” the spatial topology changes. Either baby universes are
absent as in CDT or the average number of baby universes is infinite as
in DT which completely dominates the continuum dynamics. In Chap. 9 we
show how one can naturally introduce a coupling which regulates spatial
topology changes, leading to a finite number of baby universes in the
continuum. Further, this formulation lead to the discovery of many other
relations between CDT and DT within the framework of matrix models as
will be discussed in Part IV.

### Chapter 8 The emergence of background geometry in two dimensions

In the previous chapters we studied both Euclidean as well as causal
dynamical triangulations with compact geometries. In particular, we saw
that the quantum geometry in both cases does not posses a semiclassical
background, but is rather dominated entirely by quantum fluctuations. In
this chapter we show how this situation changes when one studies the
case of non-compact space-times. Before moving to our prime interest of
non-compact space-times in CDT [ 129 , 162 ] let us first review some
results of the Euclidean model [ 163 ] .

#### 8.1 Two-dimensional Euclidean quantum gravity with non-compact
space-time

In this thesis we have so far only considered two-dimensional Euclidean
and Lorentzian quantum gravity with compact space-time. The study of
two-dimensional Euclidean quantum gravity with non-compact space-time
was initiated by the Zamolodchikovs (ZZ) in the context of Liouville
theory [ 164 ] . In particular, they showed how to use conformal
bootstrap and the cluster-decomposition properties to quantize Liouville
theory on the pseudo-sphere, i.e. the Poincaré disk.

It was later shown by Martinec [ 75 ] and Seiberg et al. [ 165 , 166 ]
how the work of the Zamolodchikovs fitted into the framework of
non-critical string theory, where the ZZ-theory could be reinterpreted
as special branes, now called ZZ-branes. Particularly, they found that
the ZZ-brane of two-dimensional Euclidean gravity was associated with
the zero of of the disc function,

  -- -------- -- -------
     @xmath      (8.1)
  -- -------- -- -------

In [ 163 , 167 , 168 ] it was shown how this could be understood in
terms of worldsheet geometry, i.e. from a two-dimensional quantum
gravity point of view. Let us briefly describe the main idea. We can use
the fixed geodesic distance two-loop function, i.e. ( 5.48 ), to compute
the average length of the final boundary,

  -- -------- -- -------
     @xmath      (8.2)
  -- -------- -- -------

Further, we see from this that the average length of the boundary of a
disc with a marked point in the bulk at geodesic distance @xmath to the
boundary is given by

  -- -------- -- -------
     @xmath      (8.3)
  -- -------- -- -------

with @xmath . Viewing @xmath as a “running” boundary cosmological
constant with scale @xmath , we see that both geodesic distance and
boundary length diverge simultaneously if we choose @xmath which was
precisely determined by @xmath (recall Eq. ( 5.49 )). Hence, the
geodesic distance from a generic point on the disk to the boundary
diverges and in this way effectively creates a non-compact space-time.

In this chapter we show that the same phenomenon occurs in the framework
of two-dimensional Lorentzian quantum gravity defined by CDT.

#### 8.2 The emergence of background geometry

Recall from Sec. 6.4 that the propagator of CDT is given by

  -- -------- -- -------
     @xmath      (8.4)
  -- -------- -- -------

where @xmath is the solution of the characteristic equation

  -- -------- -- -------
     @xmath      (8.5)
  -- -------- -- -------

The explicit solution to this equation was given by ( 6.46 ) which can
be rewritten as

  -- -------- -- -------
     @xmath      (8.6)
  -- -------- -- -------

As described above we can view @xmath as a “running” boundary
cosmological constant, with @xmath being the scale. For @xmath we have
@xmath for @xmath , i.e. @xmath can be seen as a “fixed point”, or in
other words a zero of the “ @xmath -function” @xmath in Eq. ( 8.5 ). ¹ ¹
1 Note that here @xmath is not the disc function of CDT, as it was for
the analogous term in DT.

Using the semi-group property of the marked propagator

  -- -------- -- -------
     @xmath      (8.7)
  -- -------- -- -------

we can now calculate the expectation value of the length of the spatial
slice at intermediate proper time @xmath :

  -- -------- -- -------
     @xmath      (8.8)
  -- -------- -- -------

Since the classical action is trivial, there is no reason to expect
@xmath to have a classical limit. We have already seen in Sec. 6.5 and
Sec. 6.6 that for a generic situation the system is purely governed by
quantum fluctuations. Except for boundary effects these quantum
fluctuations are determined by the ground state of the effective quantum
Hamiltonian @xmath as introduced in Sec. 6.5 . More precisely, an
explicit calculation using ( 8.8 ) shows that in the situation where
@xmath and @xmath are larger than @xmath and where @xmath the system has
forgotten everything about the boundaries and the expectation value of
@xmath is, up to corrections of order @xmath or @xmath , determined by
the ground state of the effective Hamiltonian @xmath .

We will now study the situation where a non-compact space-time is
obtained as a limit of the compact space-time in the same manner as
described in the previous subsection for the case of DT. Hence we want
to take @xmath and at the same time also take the length of the outer
boundary at time @xmath to infinity. Following the same reasoning as
above, we see that the only choice of the boundary cosmological constant
@xmath independent of @xmath where the length @xmath goes to infinity
for @xmath is the “fixed point” @xmath , since

  -- -------- -- -------
     @xmath      (8.9)
  -- -------- -- -------

which differs from the analogous DT expression, i.e. ( 8.2 ), only in
the definition of @xmath .

Inserting @xmath into ( 8.8 ) one obtains in the limit @xmath :

  -- -------- -- --------
     @xmath      (8.10)
  -- -------- -- --------

where @xmath is inversely defined through Eq. ( 8.6 ).

At this point we want to remind the reader that starting from a lattice
regularization and taking the continuum limit the length @xmath is only
determined up to a constant of proportionality which should be fixed by
comparing with a continuum effective action. In Sec. 6.5 we made such a
comparison with a continuum calculation by Nakayama and concluded that
@xmath has to be identified with @xmath . We thus have

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

We now consider the line element of the classical surface where the
intrinsic geometry is defined by proper time @xmath and spatial length
@xmath at constant @xmath

  -- -------- -- --------
     @xmath      (8.12)
  -- -------- -- --------

Here @xmath and @xmath is a function of the boundary cosmological
constant @xmath at the boundary corresponding to @xmath (see ( 8.6 )). A
remarkable observation about Eq. ( 8.12 ) is that the surfaces for
different boundary cosmological constants @xmath can be viewed as
sections of the same surface, namely the Poincaré disk with curvature
@xmath , since @xmath can be continued to @xmath . The whole Poincaré
disk is then obtained in the limit @xmath , where the initial boundary
is shrunken to a point and @xmath .

#### 8.3 The classical effective action

Even though the classical action of our theory is trivial, we discussed
in Sec. 6.5 that the effective quantum Hamiltonian of CDT can be derived
from the following classical effective action

  -- -------- -- --------
     @xmath      (8.13)
  -- -------- -- --------

With respect to this it is interesting to see in how far the results of
this chapter relate to the classical solutions of this effective action.
Solving the equations of motion of ( 8.13 ) gives

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (8.14)
     @xmath   @xmath   @xmath      (8.15)
     @xmath   @xmath   @xmath      (8.16)
  -- -------- -------- -------- -- --------

One observes that all solutions correspond to cylinders with constant
negative curvature @xmath . In the elliptic case, there is a conical
singularity at @xmath unless @xmath for which the geometry is regular at
@xmath and corresponds precisely to the Poincaré disc as described by (
8.12 ). However, @xmath is exactly the value for which Nakayama’s
Hamiltonian corresponds to the effective quantum Hamiltonian of CDT.
Concluding, we see that upon the required identification @xmath the
classical solution of Nakayama’s effective action coincides with ( 8.11
).

#### 8.4 Quantum fluctuations

In the considerations above we fixed the outer boundary cosmological
constant to a specific value, namely the “fixed point” of the running
boundary cosmological constant, rather than fixing the outer length of
the boundary to a specific value. Since the boundary length and the
boundary cosmological constant are conjugate variables, one pays the
price that the fluctuations of the boundary size are large. In
particular, it can be checked from ( 8.9 ) that the fluctuations are of
order of the average length of the boundary itself, as was also true for
the compact case

  -- -------- -- --------
     @xmath      (8.17)
  -- -------- -- --------

The same relation also holds for DT as was shown by Ambjørn et al. [ 163
] . These large fluctuations are not only present at the outer boundary
as described by ( 8.17 ), but also at @xmath . From this point of view
it is even more remarkable that the emergent semiclassical background
has such a nice interpretation in terms of the Poincaré disc.

In the following we want to analyze the situation, where we by hand fix
the boundary lengths @xmath and @xmath instead of the boundary
cosmological constants. This is done in the Hartle-Hawking Euclidean
path integral when the geometries @xmath are fixed at the boundaries [
72 ] . Recall from the previous chapters that the boundary geometry is
complete specified by its length and that amplitudes with fixed boundary
cosmological constants can be related to amplitudes with fixed boundary
lengths by a Laplace transformation. Let us in the following analyze the
temporal correlations between two spatial slices at intermediate times
@xmath and @xmath with @xmath . For simplicity we only consider the
situation where the entrance loop is shrunken to a point, i.e. @xmath .
The temporal correlations are determined by the so-called connected
loop-loop correlator

  -- -------- -- --------
     @xmath      (8.18)
  -- -------- -- --------

Using the semi-group property ( 8.7 ) and the length version of the
propagator ( 8.4 ) one obtains

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

In comparison the average length is given by

  -- -------- -- --------
     @xmath      (8.20)
  -- -------- -- --------

For fixed @xmath and @xmath , i.e. in the situation of compact
geometries, we obtain

  -- -------- -- --------
     @xmath      (8.21)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (8.22)
  -- -------- -- --------

These equations precisely agree with the picture presented above, namely
that except for small @xmath , where we are close to the initial
boundary we have @xmath , i.e. the dynamics is determined by the ground
state of the effective quantum Hamiltonian. Further, the quantum
fluctuations are

  -- -------- -- --------
     @xmath      (8.23)
  -- -------- -- --------

Thus the quantum geometry is entirely governed by quantum fluctuations
as is illustrated in Fig. 6.2 . The time correlation between two slices
@xmath and @xmath is also dictated by the same scale @xmath .
Particularly, we observe that temporal correlations between “elementary”
spatial elements of size @xmath , separated in time by @xmath fall off
exponentially as @xmath . This is precisely what one would expect from
the two-dimensional Einstein-Hilbert action with boundary terms, i.e.

  -- -------- -- --------
     @xmath      (8.24)
  -- -------- -- --------

If we force @xmath to be large and choose a generic @xmath at which
@xmath is not large, the quantum geometry will look like a thin tube
which expect close to the boundaries is “classically” of zero spatial
extension, but due to quantum fluctuations has average spatial length
@xmath .

Let us now repeat the above analysis for the case of non-compact
geometries. Recall that only when the boundary cosmological constant was
chosen to @xmath one obtains a non-compact geometry in the limit @xmath
. To implement this “critical value” of @xmath in a situation where
@xmath is fixed instead of @xmath we fix @xmath to the average value (
8.9 ) for @xmath , i.e.

  -- -------- -- --------
     @xmath      (8.25)
  -- -------- -- --------

From ( 8.4 ) and ( 8.20 ) one obtains in the limit @xmath the following
expression for the average length at intermediate time @xmath

  -- -------- -- --------
     @xmath      (8.26)
  -- -------- -- --------

which agrees with ( 8.10 ) as expected. Further, the loop-loop
correlator equates to

  -- -------- -- --------
     @xmath      (8.27)
  -- -------- -- --------

In contrast to the analogue expression for compact geometries, one
observes that ( 8.27 ) is independent of @xmath . In particular, using
@xmath we see that the quantum fluctuations for @xmath are given by

  -- -------- -- --------
     @xmath      (8.28)
  -- -------- -- --------

As in the case of compact geometries we can give an interpretation of (
8.28 ) in terms of correlations between “elementary” spatial elements of
size @xmath . More precisely, we can view the curve of length @xmath as
consisting of @xmath independently fluctuating “elementary” spatial
elements of size @xmath , each with a fluctuation of size @xmath ,
i.e. each corresponding to a section of compact geometry. Thus the
fluctuation @xmath of the total spatial slice @xmath are of order @xmath
, i.e.

  -- -------- -- --------
     @xmath      (8.29)
  -- -------- -- --------

Thus the fluctuations of @xmath around @xmath are small for @xmath . In
the same way we can understand the independence of the loop-loop
correlator of @xmath as the combined result, where @xmath is growing
exponentially in length with @xmath and the correlation between
“elementary” spatial elements of @xmath and @xmath is exponentially
decreasing with @xmath , causing a correlation constant in @xmath .

#### 8.5 Discussion and outlook

In this chapter we described the transition form compact to non-compact
quantum geometries within the framework of two-dimensional CDT. In
particular, the resulting quantum geometry can be viewed as the Poincaré
disk dressed with quantum fluctuations. Remarkably, it was shown that
the quantum fluctuations of @xmath are small compared to the average
value of @xmath . In contrast to the analogous construction in the
context of DT, this enables us to view the average geometry as a true
semiclassical background.

The main idea underlying this construction is similar to the appearance
of @xmath -branes when described from a worldsheet perspective,
i.e. form a two-dimensional quantum gravity point of view [ 163 ] . In
DT the non-compactness arose when the running boundary cosmological
constant @xmath approached its fixed point described by @xmath , i.e. to
@xmath (see ( 8.1 )). In the case of CDT the transition occurs in
exactly the same manner, namely when the running boundary cosmological
constant @xmath goes to @xmath for @xmath which is determined by @xmath
. However, in the case of CDT @xmath is not the disc function, but is
related to the effective quantum Hamiltonian of the system. It is
interesting to observe that both processes are essentially the same,
since both fixed points can be related by the mapping between the
coupling constants of both theories as derived in the previous chapter,
i.e. ( 7.54 ),

  -- -------- -- --------
     @xmath      (8.30)
  -- -------- -- --------

where the Euclidean couplings are labeled with a tilde again. From this
expression we can see that @xmath corresponds precisely to @xmath .

Another interesting observation is that the geometries described by (
8.12 ), for different initial boundary conditions, are all sections of
the same surface, namely the Poincaré disc. Hence, they obey the
Euclidean Hartle-Hawking no-boundary condition. This is particularly
surprising, since before rotating to the Euclidean sector we initially
started with a path integral over entirely Lorentzian geometries. It
would be interesting to investigate whether this also holds in higher
dimensional CDT. So far, the computer simulations, as briefly described
in Sec. 6.7 , seem to be compatible with this condition.

## Part III Third quantization of 2D causal dynamical triangulations

### Chapter 9 A field theoretic perspective of spatial topology changes

In the second part of this thesis we introduced causal dynamical
triangulations from a two-dimensional quantum gravity point of view in
which the two-dimensional geometries were interpreted as a toy model for
four-dimensional space-time. Taking the string theoretic point of view
we see the surfaces as worldsheets of propagating strings. Using this
interpretation one is naturally lead to the idea of formulating a
third-quantization of the theory, a so-called string field theory, in
which strings can be annihilated, and created from the vacuum. Models of
string field theory (SFT) have been intensively studied in the framework
of the Euclidean model [ 90 , 169 , 92 , 170 , 94 , 171 ] . In this part
of the thesis we develop an analogous formulation also for the
Lorentzian theory. While in this chapter we compute certain “Feynman
diagrams” of the model [ 130 ] , we will in the next chapter introduce
the whole string field theoretic framework.

#### 9.1 Taming spatial topology changes

In Chap. 7 we described how to introduce spatial topology changes into
CDT. We saw that when viewing them as a purely geometric process ¹ ¹ 1
By this we mean that each distinct geometry (distinct in the sense of
Euclidean geometry) appears with equal weight in the sum over
two-dimensional geometries. , one obtains Euclidean quantum gravity. In
particular, we recall from Sec. 7.1 that there are two possible scaling
relations entering the differential equation for the propagator ( 7.23
), i.e.

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (9.1)
                                @xmath   
  -- -------- -------- -------- -------- -------

In the scaling described by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (9.2)
     @xmath   @xmath   @xmath      (9.3)
  -- -------- -------- -------- -- -------

the creation of baby universes is forbidden, leading back to the “bare”
CDT model. Further, in the scaling with

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (9.4)
     @xmath   @xmath   @xmath      (9.5)
  -- -------- -------- -------- -- -------

the baby universes completely dominate the continuum limit, leading to
Euclidean quantum gravity described by DT.

Taking a string field theoretic perspective, however, one can view each
spatial topology change as a vertex of a Feynman diagram of the
corresponding string field theory (see Fig. 9.1 ). In this spirit it is
natural to assign a string coupling @xmath to this process. This is in
analogy to the coupling @xmath in front of the interaction term of
zero-dimensional @xmath -theory, described by the action

  -- -------- -- -------
     @xmath      (9.6)
  -- -------- -- -------

While in the Euclidean model such a coupling is absent ² ² 2 This is
also reflected in the Hamiltonian of the string field theory [ 90 ] . we
will see in the following that in the case of CDT it can be used to
regulate the number of baby universes. From renormalization arguments
one expects the coupling @xmath also to scale, i.e. to be a non-constant
function @xmath of the cut-off @xmath . A geometric interpretation of
this assignment will be given in the discussion at the end of this
chapter. Since we are interested in a theory which smoothly recovers CDT
in the limit as @xmath , it is natural to assume that @xmath , as in
CDT. Consequently, the only way to obtain a non-trivial consistent
equation is to assume that @xmath scales to zero with the cut-off @xmath
according to

  -- -------- -- -------
     @xmath      (9.7)
  -- -------- -- -------

where @xmath is a coupling constant of mass dimension three, which is
kept constant when @xmath [ 130 ] . With this choice, ( 9.1 ) is turned
into

  -- -------- -- -------
     @xmath      (9.8)
  -- -------- -- -------

The graphical representation of ( 9.8 ) is shown in Fig. 9.2 .

Differentiating the integral equation corresponding to this figure with
respect to the time @xmath one obtains ( 9.8 ). The disc amplitude
@xmath is at this stage unknown.

Note that one could in principle have considered an a priori more
general branching process, where more than one baby universe is allowed
to sprout at any given time step @xmath . However, one observes from the
scaling relation ( 9.7 ) that the corresponding extra terms in relation
( 9.1 ) would be suppressed by higher orders of @xmath and therefore
play no role in the continuum limit.

In the next section we show that the quantum geometry, in the sense
defined above, together with the requirement of recovering standard CDT
in the limit as @xmath , uniquely determines the disc amplitude and thus
@xmath .

#### 9.2 The disc amplitude

The disc amplitude of CDT was calculated in Sec. 6.4 , i.e. ( 6.50 ). In
( 6.48 ) it was determined directly by integrating @xmath over all
times. This decomposition is unique, since by assumption @xmath is a
global time and no baby universes can be created. In Sec. 7.2 it was
shown that it could also be obtained from Euclidean quantum gravity (DT)
by peeling off baby universes in a systematic way. By either method we
found

  -- -------- -- -------
     @xmath      (9.9)
  -- -------- -- -------

for the disc amplitude as function of the boundary cosmological constant
@xmath . In the present, generalized case we allow for baby universes,
leading to a graphical representation of the decomposition of the disc
amplitude as shown in Fig. 9.3 .

It translates into the equation

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.10)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

for the full propagator @xmath , where we have introduced a superscript
@xmath to indicate the “bare” CDT amplitudes, that is,

  -- -------- -- --------
     @xmath      (9.11)
  -- -------- -- --------

and similarly for @xmath , quantities which were defined in eqs. ( 9.9 )
and ( 8.4 ) respectively. The integrations in ( 9.10 ) can be performed,
yielding

  -- -------- -- --------
     @xmath      (9.12)
  -- -------- -- --------

Solving for @xmath we find

  -- -------- -- --------
     @xmath      (9.13)
  -- -------- -- --------

where we have defined

  -- -------- -- --------
     @xmath      (9.14)
  -- -------- -- --------

The sign of the square root is fixed by the requirement that @xmath for
@xmath , and @xmath is determined up to the value @xmath . We will now
show that this value is also determined by consistency requirements of
the quantum geometry. If we insert the solution ( 9.13 ) into ( 9.8 ) we
obtain

  -- -------- -- --------
     @xmath      (9.15)
  -- -------- -- --------

In analogy with ( 6.44 ) and ( 6.45 ), this is solved by

  -- -------- -- --------
     @xmath      (9.16)
  -- -------- -- --------

where @xmath is the solution of the characteristic equation for ( 9.15
),

  -- -------- -- --------
     @xmath      (9.17)
  -- -------- -- --------

such that

  -- -------- -- --------
     @xmath      (9.18)
  -- -------- -- --------

Physically, we require that @xmath can take values from 0 to @xmath , as
opposed to just in a finite interval. From expression ( 9.18 ) for
@xmath this is only possible if the polynomial under the square root in
the defining equation ( 9.13 ) has a double zero, which fixes the
function @xmath to

  -- -------- -- --------
     @xmath      (9.19)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (9.20)
  -- -------- -- --------

In order to have a physically acceptable @xmath , one has to choose the
solution to the third-order equation which is closest to 1. Quite
remarkably, one can also derive ( 9.19 ) from ( 9.13 ) by demanding that
the inverse Laplace transform @xmath falls off exponentially for large
@xmath . In this region @xmath equals @xmath plus a convergent power
series in the dimensionless coupling constant @xmath .

One can check the consistency of the quantum geometry by using ( 9.16 )
in

  -- -------- -- --------
     @xmath      (9.21)
  -- -------- -- --------

which comes form the decomposition of a disc function with a mark in the
bulk (see Fig. 7.3 ), i.e. the continuum version of ( 7.10 ).
Integrating ( 9.21 ) gives

  -- -------- -- --------
     @xmath      (9.22)
  -- -------- -- --------

which is indeed satisfied by the solution ( 9.13 ).

#### 9.3 The loop-loop amplitude and the consistency condition

We mentioned earlier that the propagator can be regarded as a building
block for other, more conventional “observables” in two-dimensional
quantum gravity. One of the most beautiful illustrations of this and at
the same time a non-trivial example of what we have called quantum
geometry is the calculation in two-dimensional Euclidean quantum gravity
of the loop-loop amplitude from the fixed geodesic distance two-loop
amplitude [ 97 ] . The full loop-loop amplitude is obtained by summing
over all Euclidean two-dimensional geometries with two boundaries,
without any particular restriction on the boundaries’ mutual position.
This amplitude was first calculated using matrix model techniques (for
cylinder topology) [ 172 ] .

To appreciate the underlying construction, consider a given geometry of
cylindrical topology. Its two boundaries will be separated by a geodesic
distance @xmath , in the sense of minimal distance of any point on the
final loop to the initial loop. It follows that we can consider the
geometry as composed of a cylinder where the entire final loop (i.e.
each of its points) has a distance @xmath from the initial one and a
“cap” related to the disc amplitude, as illustrated in Fig. 9.4 (a).

One can now obtain the loop-loop amplitude by integrating over all
@xmath and all gluings of the cap (we refer to [ 97 ] for details). An
intriguing aspect of the construction is that the decomposition of a
given geometry into cylinders and caps is not unique. One can choose
another decomposition consisting of two cylinders of length @xmath and
@xmath , with @xmath , joined by a cap, as illustrated in Fig. 9.4 (b).
As shown in [ 97 ] , the end result is indeed independent of this
decomposition.

The whole construction can be repeated for our new, generalized CDT
model, in this way defining a loop-loop amplitude. More precisely,
although an exact equality of amplitudes corresponding to different
decompositions like those depicted in Fig. 9.4 (a) and (b) is not
immediately obvious at the level of the triangulations of the
discretized theory ³ ³ 3 because of the different arrangements of the
proper-time slicings , the continuum ansatz ( 9.23 ) below is
self-consistent, in the sense that it leads to a non-trivial symmetric
expression for the amplitude with a well-defined @xmath limit. The
algebra is similar to that of [ 97 ] .

We will denote the loop-loop amplitude by @xmath , and its Laplace
transform by @xmath . The integral equation corresponding to Fig. 9.4
(a) is given by

  -- -------- -- --------
     @xmath      (9.23)
  -- -------- -- --------

Laplace-transforming eq. ( 9.23 ), the integrals can be performed using
eqs. ( 9.16 )-( 9.19 ). After some non-trivial algebra one obtains

  -- -------- -- --------
     @xmath      (9.24)
  -- -------- -- --------

where we are using the notation

  -- -------- -- --------
     @xmath      (9.25)
  -- -------- -- --------

In the limit @xmath one finds

  -- -------- -- --------
     @xmath      (9.26)
  -- -------- -- --------

a result which could of course also have been obtained directly from (
9.23 ) using ( 6.44 ), ( 6.45 ) and ( 9.9 ). We note that the
corresponding expression in the case of Euclidean two-dimensional
quantum gravity is given by

  -- -------- -- --------
     @xmath      (9.27)
  -- -------- -- --------

which can be obtained from expressions similar to ( 9.16 )-( 9.19 ),
only with @xmath replaced by the Euclidean disc function

  -- -------- -- --------
     @xmath      (9.28)
  -- -------- -- --------

We observe a structural similarity between ( 9.24 ) and ( 9.28 ), with
the function @xmath having the same relation to @xmath as @xmath has to
@xmath .

Let us now prove the consistency condition that the two composition of
the two-loop as shown in Fig. 9.4 lead to the same result. Decomposing
as in Fig. 9.4 (a) leads to

  -- -------- -- --------
     @xmath      (9.29)
  -- -------- -- --------

while the decompositions of Fig. 9.4 (b) reads

  -- -------- -- --------
     @xmath      (9.30)
  -- -------- -- --------

Thus we arrive at the consistency condition:

  -- -------- -- --------
     @xmath      (9.31)
  -- -------- -- --------

This condition was checked for the Euclidean model in [ 90 ] .
Remarkably, it is also satisfied in the our case. After a Laplace
transformation eq. ( 9.31 ) reads:

  -- -------- -- --------
     @xmath      (9.32)
  -- -------- -- --------

Using the explicit form of @xmath , eq. ( 9.16 ), we can perform the
@xmath -integration in eq. ( 9.32 ). Using ( 9.12 ) we can express
@xmath in terms of @xmath given by ( 9.10 ) and finally using ( 9.17 )
we can differentiate after @xmath . The result is ⁴ ⁴ 4 The
corresponding equation in the case of non-critical string theory is

@xmath

Again one obtains the remarkable result that the amplitude @xmath is
independent of the subdivision of @xmath as shown in Fig. 9.4 . In
addition we have in the non-critical SFT setting the additional
consistency test that @xmath , where @xmath is the so-called universal
loop-loop correlator calculated from matrix model [ 172 , 173 ] , i.e. (
9.27 ). This was verified in [ 90 ] .

  -- -------- -- --------
     @xmath      (9.33)
  -- -------- -- --------

which is satisfied.

The existence of well-defined, symmetric expressions for the
unrestricted loop-loop amplitudes in our generalized CDT model (at genus
0) and thus in standard two-dimensional CDT, formulas ( 9.24 ) and (
9.26 ), gives strong support to the claims that (i) the proper-time
propagator does indeed encode the complete information on the
quantum-gravitational system, and (ii) following the arguments given in
[ 97 ] concerning the decomposition invariance of the loop-loop
amplitude (c.f. Fig. 9.4 ), the continuum theory is
diffeomorphism-invariant.

#### 9.4 Discussion and outlook

The generalized CDT model of two-dimensional quantum gravity we have
defined in this chapter is a perturbative deformation of the original
model in the sense that it has a convergent power expansion of the form

  -- -------- -- --------
     @xmath      (9.34)
  -- -------- -- --------

in the dimensionless coupling constant @xmath [ 130 ] . This implies in
particular that the average number @xmath of “causality violations” in a
two-dimensional universe described by this model is finite, a property
already observed in previous two-dimensional models with topology change
[ 174 , 175 , 128 , 176 ] . The expectation value of the number @xmath
of branchings can be computed according to

  -- -------- -- --------
     @xmath      (9.35)
  -- -------- -- --------

which is finite as long as we are in the range of convergence of @xmath
. As already mentioned, this coincides precisely with the range where
the function @xmath behaves in a physically acceptable way, namely,
@xmath goes to zero exponentially in terms of the length @xmath of the
boundary loop. The same is true for the other functions considered,
namely, @xmath and @xmath .

The behaviour ( 9.35 ) should be contrasted with that in two-dimensional
Euclidean quantum gravity, and is reflected in the different scaling
behaviours ( 9.3 ) and ( 9.5 ) for the time @xmath . These scaling
relations show that the effective continuum “time unit” in Euclidean
quantum gravity is much longer than in CDT, giving rise to infinitely
many causality violations for a typical space-time history which appears
in the path integral when the cut-off @xmath is taken to zero. This
phenomenon was discovered in the seminal paper [ 95 ] .

As we will see in the next chapter, the calculations presented here
should be seen as pertaining to the genus-0 sector of a generalized CDT
model, which also includes a sum over space-time topologies. Although we
have not given a precise definition of the higher-genus amplitudes in
this chapter, one would expect them to be finite order by order. If the
handles are as scarce as are the baby universes in the genus-0
amplitudes, it might even be that the sum over all genera is uniquely
defined. Whether or not this is so will clearly also depend on the
combinatorics of allowed handle configurations.

In the context of higher-genus amplitudes, it is natural to associate
each handle with a “string coupling constant”, because one may think of
it as a process where (one-dimensional) space splits and joins again,
albeit as a function of an intrinsic proper time, rather than the time
of any embedding space. An explicit calculation reveals that in the
generalized CDT model this process is related with a coupling constant
@xmath (see next chapter), which one may think of as two separate
factors of @xmath , associated with the splitting and joining
respectively.

How does the disc amplitude fit into this picture? From a purely
Euclidean point of view all graphs appearing in Fig. 9.3 have the fixed
topology of a disc. However, from a Lorentzian point of view, which
comes with a notion of time, it is clear that the branching of a baby
universe is associated with a change of the spatial topology, a singular
process in a Lorentzian space-time [ 159 ] . One way of keeping track of
this in a Wick-rotated, Euclidean picture is as follows. Since each time
a baby universe branches off it also has to end somewhere, we may think
of marking the resulting “tip” with a puncture. From a gravitational
viewpoint, each new puncture corresponds to a topology change and
receives a weight @xmath , where @xmath is Newton’s constant, because it
will lead to a change by precisely this amount in the two-dimensional
(Euclidean) Einstein-Hilbert action

  -- -------- -- --------
     @xmath      (9.36)
  -- -------- -- --------

Identifying the dimensionless coupling constant in eq. ( 9.1 ) with
@xmath , one can introduce a renormalized gravitational coupling
constant by

  -- -------- -- --------
     @xmath      (9.37)
  -- -------- -- --------

This implies that the bare gravitational coupling constant @xmath goes
to zero like @xmath when the cut-off vanishes, @xmath , in such a way
that the product @xmath is independent of the cut-off @xmath . We can
now identify

  -- -------- -- --------
     @xmath      (9.38)
  -- -------- -- --------

as the genuine coupling parameter in which we expand.

This renormalization of the gravitational (or string) coupling constant
is reminiscent of the famous double-scaling limit in non-critical string
theory ⁵ ⁵ 5 It is called the double-scaling limit since from the point
of view of the discretized theory it involves a simultanous
renormalization of the cosmological constant @xmath and the
gravitational coupling constant @xmath . In this article we have already
performed the renormalization of the cosmological constant. For details
on this in the context of CDT we refer to [ 19 ] . . In that case one
also has @xmath , the only difference being that relation ( 9.37 ) is
changed to

  -- -------- -- --------
     @xmath      (9.39)
  -- -------- -- --------

whence the partition function of non-critical string theory appears
precisely as a function of the dimensionless coupling constant @xmath .

### Chapter 10 A causal string field theory

In the previous chapter we introduced a generalization of CDT by
incorporating spatial topology changes regularized by a coupling @xmath
. Using certain Feynman rules for propagation and splitting of strings
(spatial universes) we were able to solve the genus zero disc function
to all orders in @xmath . In this chapter we embed these results in a
broader framework of a causal string field theory [ 131 ] .

#### 10.1 The string field theory framework

In quantum field theory particles can be created and annihilated if the
process does not violate any conservation law of the theory. In string
field theories one operates in the same way with operators which can
create and annihilate strings. From the two-dimensional quantum gravity
point of view we thus have a third-quantization of gravity:
one-dimensional universes can be created and destroyed. In [ 90 , 169 ,
92 , 170 , 94 , 171 ] such a formalism was developed for non-critical
strings (or two-dimensional Euclidean quantum gravity). We will follow
the formalism developed there closely and develop a string field theory
or third quantization for CDT which will allow us in principle to
calculate any amplitude involving creation and annihilation of universes
[ 131 ] .

The starting point is the assumption of a vacuum from which universes
can be created. We denote this state @xmath and define creation and
annihilation operators:

  -- -------- -- --------
     @xmath      (10.1)
  -- -------- -- --------

This assignment corresponds to working with spatial universes where a
point has been marked. This avoids putting in certain combinatorial
factors by hand when gluing together universes. The operators @xmath and
@xmath will be assigned dimensions @xmath .

We could alternatively have chosen creation and annihilation operators
which create and annihilate universes without such a mark. Then instead
of ( 10.1 ) one would have

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

and the dimensional assignment would be @xmath and @xmath . One could
even let @xmath create marked universes and @xmath annihilate unmarked
universes if one just compensates for missing combinatorial factors by
hand. Here we will use the assignment ( 10.1 ).

Let us write the differential equation for the finite time propagator
derived in ( 6.41 ) using the boundary length rather than the boundary
cosmological constant as variable

  -- -------- -- --------
     @xmath      (10.3)
  -- -------- -- --------

For convenience we have in ( 10.3 ) also marked the exit-loop @xmath in
order to have symmetry between loops at the initial time and the loop at
the final time, i.e. @xmath , where @xmath was given by ( 6.47 ).

We can now also write

  -- -------- -- --------
     @xmath      (10.4)
  -- -------- -- --------

where @xmath was derived in ( 6.56 ). ¹ ¹ 1 We changed the notation from
@xmath in ( 6.56 ) to @xmath in ( 10.4 ) to indicate that it is the
first-quantized Hamiltonian. Associated with the spatial universe we
have a Hilbert space on the positive half-line, and a corresponding
scalar product making @xmath self-adjoint (see App. B.2 for more
details)

  -- -------- -- --------
     @xmath      (10.5)
  -- -------- -- --------

The introduction of the operators @xmath and @xmath in ( 10.1 ) can be
thought of as analogous to the standard second quantization in many-body
theory. The single particle Hamiltonian becomes in our case the “single
universe” Hamiltonian @xmath . It has eigenfunctions @xmath with
corresponding eigenvalues @xmath , @xmath :

  -- -------- -- --------
     @xmath      (10.6)
  -- -------- -- --------

where @xmath is a polynomial of order @xmath . ² ² 2 The precise form of
@xmath is not of relevance here, but it can be readily obtained from the
general formulas in App. B.2 . We now introduce creation and
annihilation operators @xmath and @xmath corresponding to these states,
acting on the Fock-vacuum @xmath and satisfying @xmath . We define

  -- -------- -- --------
     @xmath      (10.7)
  -- -------- -- --------

and from the orthonormality of the eigenfunctions with respect to the
measure @xmath we recover ( 10.1 ). The “second-quantized” Hamiltonian
is

  -- -------- -- --------
     @xmath      (10.8)
  -- -------- -- --------

and the propagator @xmath is now obtained as

  -- -------- -- --------
     @xmath      (10.9)
  -- -------- -- --------

While this is trivial, the advantage of the formalism is that it
automatically takes care of symmetry factors (like in the many-body
applications in statistical field theory) both when many spatial
universes are at play and when they are joining and splitting. We can
follow [ 90 ] and define the following Hamiltonian, describing the
interaction between spatial universes:

  -- -------- -- -------- -------- ---------
     @xmath      @xmath            (10.10)
                          @xmath   
  -- -------- -- -------- -------- ---------

where the different terms of the Hamiltonian are illustrated in Fig.
10.1 . Here @xmath is the coupling constant we have already encountered
in Chap. 9 of mass dimension 3. The factor @xmath is just inserted to be
able the identify the action of the two @xmath -terms in ( 10.10 ) when
expanding in powers of @xmath . We will think of @xmath unless
explicitly stated differently. Note that the sign of all the interaction
terms in ( 10.10 ) is negative. This reflects that we want these terms
to represent the insertion of new geometric structures compared to the
“free” propagation generated by @xmath . These structures should thus
appear with positive weight when we expand @xmath . @xmath is hermitian
except for the presence of the tadpole term. It tells us that universes
can vanish, but not be created from nothing. The meaning of the two
interaction terms is as follows: the first term replaces a universe of
length @xmath with two universes of length @xmath and @xmath . This is
precisely the process shown in Fig. 9.2 . The second term represents the
opposite process where two spatial universes merge into one, i.e.  the
time-reversed picture. The coupling constant @xmath seems to play the
role of a string coupling constant: one factor @xmath for splitting
spatial universes, one factor @xmath for merging spatial universes and
thus a factor @xmath when the space-time topology changes.

In a certain way the appearance of a tadpole term is more natural in the
CDT framework than in the original Euclidean framework in [ 90 ] .
Recall the discussion in Chap. 9 : In a Lorentzian setting there is no
regular disc geometry, it has to end in a “puncture”. The tadpole term
is a formal realization of this process. Also recall that we could
associate this process with a gravitational coupling constant, in this
way linking it to @xmath . It was done by observing that to each
splitting off of a baby universe we have a puncture where the baby
universe ends. Thus the coupling constant @xmath related to the
splitting of spatial universes could be identified with the vanishing of
universes. This shift can be made explicit in our string field
Hamiltonian @xmath in ( 10.10 ). In ( 10.10 ) the coupling constant
@xmath is associated with splitting and joining of spatial universes. No
coupling constant is associated with the tadpole term, i.e. the
vanishing of a spatial universe. However we can redefine @xmath and
@xmath :

  -- -------- -- ---------
     @xmath      (10.11)
  -- -------- -- ---------

With this substitution the coupling constant @xmath is shifted from the
splitting term to the tadpole term, i.e. precisely the shift mentioned
above. In addition the term associated with the joining of spatial
universes will have the coupling constant @xmath , which matches a
change in topology.

Finally, let us identify the real coupling constant appearing in ( 10.10
): let us measure everything in terms of @xmath which is the natural
length scale of our universe. Introducing the dimensionless length
variable @xmath , the dimensionless boundary cosmological constant
@xmath , the dimensionless time variable @xmath , the dimensionless
tadpole density @xmath , the dimensionless coupling constant @xmath
(already introduced in eq. ( 9.34 )) and finally the dimensionless
Hamiltonian @xmath , we can write

  -- -------- -- ---------
     @xmath      (10.12)
  -- -------- -- ---------

where @xmath and @xmath satisfy the same commutation relation as @xmath
when expressed in terms of @xmath , and @xmath , where

  -- -------- -- -------- -------- ---------
     @xmath      @xmath            (10.13)
                          @xmath   
  -- -------- -- -------- -------- ---------

From this equation it is clear that the real coupling constant in the
theory is the dimensionless @xmath , precisely the ”double scaling”
coupling constant which already appeared in the calculation of @xmath
and @xmath (i.e. ( 9.34 )). From the discussion above we also observe
that the expansion parameter for topology change of space-time is @xmath
.

In principle we can now calculate the process where we start out with
@xmath spatial universes at time 0 and end with @xmath universes at time
@xmath , represented as

  -- -------- -- ---------
     @xmath      (10.14)
  -- -------- -- ---------

#### 10.2 The genus zero limit

##### 10.2.1 The disc amplitude

Let us consider the simplest amplitude: a single spatial universe which
disappears in the vacuum. This is precisely the disc-amplitude
considered in the previous chapter. The topology of space-time was not
allowed to change in the calculation in Chap. 9 . We can incorporate
that in the SFT-picture by choosing @xmath in ( 10.10 ), i.e. the genus
zero limit. The disc-amplitude can then be expressed as:

  -- -------- -- ---------
     @xmath      (10.15)
  -- -------- -- ---------

It will describe all possible ways in which a spatial loop can develop
in time and disappear in the vacuum without changing the topology of
space-time. Note that the tadpole term in ( 10.10 ) is needed in order
that the amplitude ( 10.15 ) is different from zero since the state
@xmath is orthogonal to the vacuum state @xmath . We note that if @xmath
we have

  -- -------- -- -------- --
     @xmath               
                          
                 @xmath   
  -- -------- -- -------- --

this factorization being a consequence of the fact that if we start out
with @xmath spatial universes there is no way they can merge at any time
if @xmath (it is easy to prove ( 10.2.1 ) using the algebra of the
@xmath ’s).

Following [ 90 ] we obtain an equation for @xmath by differentiating (
10.15 ) with respect to @xmath and using @xmath :

  -- -------- -- ---------
     @xmath      (10.17)
  -- -------- -- ---------

The commutator can readily be calculated and after a Laplace
transformation eq. ( 10.17 ) reads

  -- -------- -- ---------
     @xmath      (10.18)
  -- -------- -- ---------

where the last term on the left-hand-side of ( 10.18 ) is a consequence
of the factorization ( 10.2.1 ).

Eq. ( 10.18 ) has the generalized CDT solution ( 9.19 )-( 9.20 )
discussed in Chap. 9 if

  -- -------- -- ---------
     @xmath      (10.19)
  -- -------- -- ---------

which is a reasonable physical requirement: the spatial universe can
only vanish in the vacuum when the length of the universe goes to zero.

##### 10.2.2 Inclusive amplitudes

Above we have understood how to reproduce the generalized CDT disc
amplitude @xmath as the connected amplitude arising in SFT in the limit
@xmath . We now want to understand how to reproduce the proper-time
propagator @xmath in the context of SFT. We have an “entrance” loop at
time @xmath and an “exit” loop at time @xmath . However, the propagator
@xmath allows baby-universes to split off and propagate further than
time @xmath if they only vanish into the vacuum eventually (see Fig. 9.2
).

We can reproduce this result in the @xmath limit of SFT by introducing
the “inclusive” Hamiltonian [ 90 ] . Since we are working in the @xmath
limit, we only have universes branching, not merging, during the time
evolution, and all the branching universes except one have to vanish in
the vacuum. The branching process is dictated by the term

  -- -------- -- ---------
     @xmath      (10.20)
  -- -------- -- ---------

in the Hamiltonian @xmath , eq. ( 10.10 ). Once the branching has
occurred, only one of the two universes can connect to the exit loop at
time @xmath , the other universe has to continue until it eventually
vanishes in the vacuum, a process which is allowed to occur a time later
than @xmath . This scenario is captured by the replacement

  -- -------- -- ---------
     @xmath      (10.21)
  -- -------- -- ---------

in eq. ( 10.20 ). Thus we arrive at the following “inclusive
Hamiltonian”

  -- -------- -- ---------
     @xmath      (10.22)
  -- -------- -- ---------

and we obtain the following representation of @xmath

  -- -------- -- ---------
     @xmath      (10.23)
  -- -------- -- ---------

Differentiating eq. ( 10.23 ) with respect to @xmath , commuting @xmath
to the right to @xmath (and using @xmath ) one obtains after a Laplace
transformation and removal of the mark on the final boundary ( 9.8 ).
Thus the generalized CDT proper-time propagator also has a simple SFT
description.

#### 10.3 Dyson-Schwinger equations

The disc amplitude is one of a set of functions for which it is possible
to derive Dyson-Schwinger equations (DSE). Here we consider a more
general class of functions. Define the generating function:

  -- -------- -- ---------
     @xmath      (10.24)
  -- -------- -- ---------

We have

  -- -------- -- ---------
     @xmath      (10.25)
  -- -------- -- ---------

We have already seen that in the case where the coupling constant @xmath
we had factorization:

  -- -------- -- ---------
     @xmath      (10.26)
  -- -------- -- ---------

where @xmath denotes the disk amplitude where the universe decays into
the vacuum before or at time @xmath , and where @xmath was the disc
amplitude we already calculated.

Following [ 90 ] we can obtain the DSE in the same way as for the disc
amplitude, the only difference being that when the constant @xmath is no
longer zero these equations do not close but connect various amplitudes
of more complicated topology. However, the equations can be solved
iteratively. We denote

  -- -------- -- ---------
     @xmath      (10.27)
  -- -------- -- ---------

@xmath being the generating functional for universes that disappear in
the vacuum. We now have

  -- -------- -- ---------
     @xmath      (10.28)
  -- -------- -- ---------

Commuting the @xmath ’s in @xmath past the source term effectively
replaces these operators by @xmath , after which they can be moved to
the left of any @xmath and outside @xmath . After that the remaining
@xmath ’s in @xmath can be replaced by @xmath and also moved outside
@xmath , leaving us with a integro-differential operator acting on
@xmath :

  -- -------- -- ---------
     @xmath      (10.29)
  -- -------- -- ---------

where

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

@xmath is a generating functional which also includes totally
disconnected universes which never “interact” with each other. It is of
more interest to restrict ourselves to the study of “connected
universes”, i.e. universes where space-time is connected. The generating
functional for connected universes is obtained in the standard way from
field theory by taking the logarithm of @xmath . Thus we write:

  -- -------- -- ---------
     @xmath      (10.31)
  -- -------- -- ---------

and we have

  -- -------- -- ---------
     @xmath      (10.32)
  -- -------- -- ---------

and we can readily transfer the DSE ( 10.29 )-( 10.3 ) into an equation
for the connected functional

  -- -------- -- ---------
     @xmath      (10.33)
  -- -------- -- ---------

From ( 10.29 )-( 10.3 ) we obtain

  -- -------- -- ---------
     @xmath      
     @xmath      (10.34)
  -- -------- -- ---------

From ( 10.34 ) one obtains the DSE by differentiating ( 10.34 ) after
@xmath a number of times and then taking @xmath .

#### 10.4 Application of the DSE

Let us introduce the notation

  -- -------- -- ---------
     @xmath      (10.35)
  -- -------- -- ---------

as well as the Laplace transform

  -- -------- -- ---------
     @xmath      (10.36)
  -- -------- -- ---------

for the higher loop amplitudes.

Let us differentiate eq. ( 10.34 ) after @xmath one, two and three
times, then take @xmath and Laplace transform the obtained equations. We
obtain the following three equations (where @xmath ):

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            
                                         
     @xmath   @xmath   @xmath            
                       @xmath            
                       @xmath            
                                         
     @xmath   @xmath   @xmath            (10.39)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

The structure of the DSE should now be clear.

We can solve the DSE iteratively. For this purpose let us introduce the
expansion of @xmath in terms of the coupling constants @xmath and @xmath
:

  -- -------- -- ---------
     @xmath      (10.40)
  -- -------- -- ---------

The amplitude @xmath starts with the power @xmath since we have to
perform @xmath mergings during the time evolution in order to create a
connected geometry if we begin with @xmath separated spatial loops. Thus
one can find the lowest order contribution to @xmath from ( 10.4 ), use
that to find the lowest order contribution to @xmath from ( 10.4 ) and
use this again in ( 10.39 ) which involves @xmath , etc. Returning to
eq. ( 10.4 ) we can use the lowest order expression for @xmath to find
the next order correction to @xmath , use this and the lowest order
correction for @xmath to find the next order correction to @xmath , etc.

Two remarks are in order: firstly, the integration constants which come
by integrating ( 10.4 )-( 10.39 ) and the corresponding higher order
equations are uniquely fixed by the requirement that the correlation
functions fall off for the lengths @xmath , i.e. the requirement that
the Laplace transformed amplitude @xmath is analytic for @xmath .
Secondly, the expressions obtained for @xmath can of course be obtained
directly from a diagrammatic expansion, using the interaction rules
shown in Fig. 10.1 , the propagation being defined by @xmath , and then
integrating in a suitable way over the times @xmath involved.

Let us just list the first few orders:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (10.41)
     @xmath   @xmath   @xmath      (10.42)
     @xmath   @xmath   @xmath      (10.43)
     @xmath   @xmath   @xmath      (10.44)
  -- -------- -------- -------- -- ---------

These amplitudes involve no change in space-time topology. The genus one
and genus two amplitudes to lowest order in @xmath , i.e. without any
additional baby universes, become, using the results ( 10.41 )-( 10.44 )
in the iteration as described above,

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (10.45)
     @xmath   @xmath   @xmath            (10.46)
                                @xmath   
  -- -------- -------- -------- -------- ---------

In terms of diagrams this genus 2 amplitude corresponds to the following
three diagrams (integrated suitably over the times @xmath ):

  -- -------- --
     @xmath   
  -- -------- --

As mentioned above the amplitude @xmath starts with the power @xmath
coming from merging the @xmath disconnected spatial universes. The rest
of the powers of @xmath will result in a topology change of the
resulting, connected worldsheet. From a Euclidean point of view it is
thus more appropriate to reorganize the series as follows

  -- -------- -- ---------
     @xmath      (10.47)
     @xmath      (10.48)
  -- -------- -- ---------

and aim for a topological expansion in @xmath , at each order solving
for all possible baby-universe creations which at some point will vanish
into the vacuum. Thus @xmath will be a function of @xmath although we do
not write it explicitly. The DSE allow us to obtain the topological
expansion iteratively, much the same way we already did as a power
expansion in @xmath .

Since we have @xmath this term does not contribute to the lowest order
and from the DSE ( 10.4 ) we obtain a closed equation for @xmath :

  -- -------- -- ---------
     @xmath      (10.49)
  -- -------- -- ---------

This equation is of course just eq. ( 10.17 ) and we have

  -- -------- -- ---------
     @xmath      (10.50)
  -- -------- -- ---------

Knowing @xmath allows us to obtain @xmath from ( 10.4 ) since @xmath is
of order @xmath . Thus the 3-loop term does not contribute to the lowest
@xmath order of eq. ( 10.4 ), which is @xmath , and we have to the
lowest order:

  -- -------- -- ---------
     @xmath      
     @xmath      (10.51)
  -- -------- -- ---------

Thus @xmath is entirely determined by the knowledge of @xmath . We note
that using the definition ( 9.12 ) we can simplify ( 10.51 ):

  -- -------- -- ---------
     @xmath      
     @xmath      (10.52)
  -- -------- -- ---------

The solution @xmath can readily be found from eq. ( 10.52 ), yielding

  -- -------- -- ---------
     @xmath      (10.53)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (10.54)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (10.55)
  -- -------- -- ---------

as in Sec. 9.2 .

In fact this solution was already found in Sec. 9.3 since we by
definition have

  -- -------- -- ---------
     @xmath      (10.56)
  -- -------- -- ---------

where @xmath is the Laplace transform of the loop-loop function @xmath
defined in ( 9.30 ) with @xmath . When expanded to lowest order in
@xmath we reproduce ( 10.43 ).

It should now be clear that one can iterate the DSE in a systematic way
as a power series in the number of handles of the world sheet exactly
the same way as we iterated the DSE as a function of the coupling
constant @xmath : As an instructive example we calculate the genus one
amplitude @xmath . We expand

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (10.57)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ---------

While ( 10.49 ) was the 0th order in @xmath of eq. ( 10.4 ), the 1st
order reads

  -- -------- -- ---------
     @xmath      (10.58)
  -- -------- -- ---------

where @xmath is given by ( 10.53 ). The integration constant is fixed by
the requirement that @xmath is analytic for @xmath , i.e. that @xmath
falls of as @xmath . We then obtain

  -- -------- -- ---------
     @xmath      (10.59)
  -- -------- -- ---------

It is seen that if we expand @xmath in powers of @xmath , the first term
will reproduce ( 10.45 ).

#### 10.5 Discussion

We have developed here a string-field theory based on the CDT
quantization of two-dimensional quantum gravity. It shares many
properties with the original non-critical SFT, and the whole formalism
was borrowed from non-critical SFT. Yet, it is different and in some
ways simpler. The tad-pole term is simpler. It is simply @xmath ,
telling us that universes can only disappear in the vacuum if they have
zero spatial “volume”. This is in accordance with the interaction
between spatial universes, which preserves the total length (the total
spatial volume). In non-critical SFT the evolution in proper time
results in a process where the original spatial universe at proper time
@xmath spawn an infinity of (infinitesimal) baby universe during the
time evolution. This is linked to the fact that the proper time in
non-critical SFT has the anomalous length dimension 1/2. In our new
CDT-based SFT the situation is different. The proper time @xmath has the
canonical dimension 1, and the number of baby universes created during
the time evolution is finite (see ( 9.35 )).

As discussed in Chap. 9 it is not possible to connect the non-critical
SFT and the CDT-based SFT by a simple analytic continuation in the
coupling constant @xmath , not even in the @xmath limit. As already
shown in Chap. 7 , starting out with a discretized, regularized version
of the theory, the Euclidean theory (quantum Liouville theory) is
obtained if the “bare” dimensionless coupling constant @xmath is of
order one. However, the relation between the bare coupling constant and
the dimensionful continuum coupling constant @xmath used here and in the
previous chapter is, as mentioned in Sec. 9.1 ,

  -- -------- -- ---------
     @xmath      (10.60)
  -- -------- -- ---------

As discussed in Sec. 9.1 the generalized CDT continuum limit corresponds
to @xmath fixed, @xmath , and thus to @xmath . The fact that @xmath goes
to zero in CDT SFT is of course related to the finite number of baby
universes generated in this theory. In contrast we have an infinite
number of baby universes generated in non-critical SFT where @xmath is
of order one.

However, there is clearly a deep connection between the Euclidean theory
and the CDT theory awaiting to be fully understood. In Sec. 7.2 it was
shown that if one integrate out the “excessive spawn” of baby universes
in Euclidean two-dimensional quantum gravity one recovers the CDT theory
and the mapping between the dimensionless variables @xmath in the two
theories was found, i.e. ( 7.54 ). This mapping was later discovered by
Seiberg et al. [ 165 ] as the uniformization map from the algebraic
surface representing the “semiclassical” non-critical string to the
complex plane. The singular points of the algebraic surface corresponds
to ZZ-branes where there is a transition from compact to non-compact
topology [ 163 , 167 , 168 ] . These singular points are mapped to
points in the complex plane where one has a similar transition from
compact to non-compact geometry in CDT context as discussed in Chap. 8 .

It is interesting to try to generalize the present CDT-based SFT to
include the coupling to matter. In particular, the presence of a @xmath
barrier can then be addressed. Since the @xmath barrier partly can be
understood as the result of an excessive creation of baby universes,
such that the two-dimensional worldsheet is torn apart [ 161 , 177 ] it
is clear that the CDT theory may behave differently at @xmath .
Numerical simulations hint that there still might be a barrier for large
@xmath [ 178 ] , but nothing is presently known with certainty and
CDT-based SFT may provide a useful analytic tool. Work in this direction
is in progress.

Equally interesting is the possibility of performing a summation over
wordsheets of all genera. Again, since the double-scaling limit in
CDT-based SFT is different from the double-scaling limit in non-critical
string theory and the penalty for creation of a higher genus surface is
larger in the sense mentioned above, viewing the creation a higher genus
worldsheet as a successive creation and annihilation of a baby universe,
one could hope the result of such a summation is better behaved and less
ambiguous than was the case in non-critical string theory. Work in this
direction is also in progress.

## Part IV Matrix models for 2D causal dynamical triangulations

### Chapter 11 Matrix models for two-dimensional Euclidean quantum
gravity

In the previous chapter we computed higher-loop and higher-genus
amplitudes in the framework of a SFT for the continuum model of
generalized CDT. An earlier formulation for DT was introduced by Kawai
et al. [ 90 ] as discussed above. If one would like to perform similar
calculations in the discrete framework of DT one could either formulate
a discrete STF as has been done in [ 94 ] or make use of so-called
matrix models and loop equations derived from them.

In this chapter we want to introduce the use of matrix models to solve
combinatorial counting problems of DT on the discretized level. Those
techniques are very powerful, since they allow for many generalizations
especially in the context of matter couplings.

#### 11.1 Counting triangulations with matrix models

In the following we want to give a short introduction to how certain
matrix integrals can be used as generating functionals for random
triangulation. The basic idea underlying this construction goes back to
the seminal work by ’t Hooft [ 179 ] on the large-N limit of QCD,