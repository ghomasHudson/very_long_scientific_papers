###### Contents

-    Introduction
-    1 Number of absorbed individuals in branching Brownian motion with
    a barrier
    -    1 Introduction
    -    2 First results by probabilistic methods
        -    2.1 Notation and preliminary remarks
        -    2.2 Branching Brownian motion with two barriers
        -    2.3 Proof of Proposition 2.1
    -    3 The FKPP equation
    -    4 Proof of Theorem 1.1
    -    5 Preliminaries for the proof of Theorem 1.2
        -    5.1 Notation
        -    5.2 Complex differential equations
        -    5.3 Singularity analysis
        -    5.4 An equation for continuous-time Galton–Watson processes
    -    6 Proof of Theorem 1.2
    -    7 Appendix
        -    7.1 A renewal argument for branching diffusions
        -    7.2 Addendum to the proof of Theorem 1.1
        -    7.3 Reduction to Briot–Bouquet equations
        -    7.4 Inversion of some analytic functions
    -    Acknowledgements
-    2 Branching Brownian motion with selection of the @xmath right-most
    particles
    -    1 Introduction
        -    1.1 Heuristic ideas and overview of the results
        -    1.2 Notation guide
    -    2 Brownian motion in an interval
        -    2.1 A function of Jacobi theta-type
        -    2.2 Brownian motion killed upon exiting an interval
        -    2.3 The Brownian taboo process
    -    3 Preliminaries on branching Markov processes
        -    3.1 Definition and notation
        -    3.2 Stopping lines
        -    3.3 Many-to-few lemmas and spines
        -    3.4 Doob transforms
    -    4 BBM with absorption at a critical line
        -    4.1 Proof of Proposition 4.1
    -    5 BBM in an interval
        -    5.1 Notation
        -    5.2 The processes @xmath and @xmath
        -    5.3 The number of particles
        -    5.4 The particles hitting the right border
        -    5.5 Penalizing the particles hitting the right border
    -    6 BBM with absorption before a breakout
        -    6.1 Definitions
        -    6.2 The time of the first breakout
        -    6.3 The particles that do not participate in the breakout
        -    6.4 The fugitive and its family
    -    7 The B-BBM
        -    7.1 Definition of the model
        -    7.2 Proof of Proposition 7.3
        -    7.3 Proof of Theorems 7.1 and 7.2
    -    8 The B @xmath -BBM
        -    8.1 Definition of the model
        -    8.2 Preparatory lemmas
        -    8.3 The probability of @xmath
        -    8.4 Proofs of the main results
    -    9 The B @xmath -BBM
        -    9.1 Definition of the model
        -    9.2 Preparatory lemmas
        -    9.3 The probability of @xmath
        -    9.4 Proofs of the main results
    -    10 The @xmath -BBM: proof of Theorem 1.1
        -    10.1 A monotone coupling between @xmath -BBM and more
            general particle systems
        -    10.2 Proof of Theorem 1.1
    -    Acknowledgments
-    3 A note on stable point processes occurring in branching Brownian
    motion
    -    1 Introduction
    -    2 Stability in convex cones
    -    3 A succinct proof of the decomposition ( 1.1 )
        -    3.1 Definitions and notation
        -    3.2 Infinitely divisible random measures
        -    3.3 Proof of Theorem 3.1
        -    3.4 Finiteness of the intensity
-    Errata

## Introduction

The ancestor of all branching processes is the Galton–Watson process ¹ ¹
1 See [ 101 ] for an entertaining historical overview. Note that it
should be called the Bienaymé–Galton–Watson process , but we will stick
to the standard name. . A Galton–Watson process @xmath with reproduction
law @xmath is defined in the following way: @xmath and @xmath , where
the @xmath are independent and identically distributed (iid) according
to @xmath . The generating function @xmath plays an important role in
the study of @xmath , because of the relation @xmath , the @xmath -fold
composition of @xmath with itself. With this basic fact, one can see for
example without difficulty that the probability of extinction (i.e. the
probability that @xmath for some @xmath ) equals the smallest fixed
point of @xmath in @xmath . In particular, the extinction probability is
one if and only if @xmath is less than or equal to one. This motivates
the classification of branching processes into supercritical, critical
and subcritical, according to whether @xmath is larger than, equal to or
less than one. Furthermore, generating function techniques have been
used extensively in the 1960’s and 1970’s in order to derive several
limit theorems, one of the most famous being the Kesten–Stigum theorem ,
which says that in the supercritical case, the martingale @xmath
converges to a non-degenerate limit if and only if @xmath .

The Galton–Watson process has two natural variants: First of all, one
can define a branching process @xmath in continuous time, where each
individual branches at rate @xmath into a random number of individuals,
distributed according to @xmath . The generating function of @xmath then
satisfies two differential equations called Kolmogorov’s forward and
backward equations (see ( 3.2 ) and ( 3.3 ) in Chapter 1 ). In passing
to continuous time one loses generality, because the discrete skeleton
@xmath for any @xmath is a Galton–Watson process in the above sense. In
fact, the question under which conditions a (discrete-time)
Galton–Watson process can be embedded into a continuous-time process has
been investigated in the literature (see [ 14 , Section III.12] ).

The second variant is to assign a type to each individual and possibly
let the reproduction of an individual depend on the type. In the
simplest case, the case of a finite number of types, this yields to
results which are similar to those of the single-type case. For example,
the classification into supercritical, critical or subcritical processes
now depends on the largest eigenvalue of a certain matrix and even the
Kesten–Stigum theorem has an analogue (see [ 14 , Chapter V] ).

###### Branching Brownian motion and FKPP equation.

In this thesis, we study one-dimensional branching Brownian motion (BBM)
, which is a fundamental example of a multitype branching processes in a
non-compact state space, namely the real numbers ² ² 2 Strictly
speaking, the type space of BBM is the space of continuous real-valued
functions, but we ignore this fact here. . Starting with an initial
configuration of particles ³ ³ 3 We will often, but not always, use the
terms “particle” and “individual” interchangeably. located at the
positions @xmath , the particles independently diffuse according to
Brownian motions and branch at rate one into a random number of
particles distributed according to the law @xmath . Starting at the
position of their parent, the newly created particles then repeat this
process independently of each other. It is the continuous counterpart of
the branching random walk (BRW) , a discrete-time multitype branching
process where the offspring distribution of an individual at the
position @xmath is given by a point process @xmath translated by @xmath
. As in the single-type case, the BRW is a more general object than the
BBM, because the discrete skeleton of a branching Brownian motion is
itself a BRW.

In losing generality, one gains in explicitness: When studying BBM one
often has more tools at hand than for the BRW, because of the explicit
calculations that are possible due to the Brownian motion. For example,
let @xmath denote the probability that there exists a particle to the
right ⁴ ⁴ 4 For @xmath , we say that @xmath is to the right of @xmath if
@xmath . of @xmath at time @xmath in BBM started from a single particle
at the origin. The function @xmath satisfies the so-called
Fisher–Kolmogorov–Petrovskii–Piskounov (FKPP) equation

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

where the forcing term is @xmath .

Starting with McKean [ 118 ] , this fact has been exploited many times
to give precise asymptotics on the law of the position of the right-most
particle when the process is supercritical, i.e. @xmath [ 44 , 45 , 62 ,
63 ] . Recently, it has also been used for the study of the whole point
process formed by the right-most particles [ 53 , 10 , 12 , 11 , 4 ] .
Many of these results have later been proven for the branching random
walk as well, either through the study of a functional equation which
takes the role of ( 1 ) above [ 71 , 131 , 16 , 46 , 141 ] or using more
probabilistic techniques [ 117 , 92 , 1 , 3 , 114 ] .

Let us state these results precisely. Fisher [ 80 ] and Kolmogorov,
Petrovskii, Piskounov [ 106 ] , who introduced the equation ( 1 ),
already noticed that it admits travelling wave solutions ,
i.e. solutions of the form @xmath for every @xmath . Furthermore, in [
106 ] it is proved that under the initial condition @xmath , there
exists a centring term @xmath , such that @xmath and @xmath as @xmath .
Together with tail estimates on the travelling wave, this implies a law
of large numbers for the position of the right-most particle in BBM ⁵ ⁵
5 An equivalent result for the BRW has been proven by Biggins [ 29 , 30
] , after more restrictive versions by Hammersley [ 85 ] and Kingman [
103 ] . . The next order of the centring term @xmath was then studied
first by McKean [ 118 ] , who provided the estimate @xmath and then by
Bramson [ 45 ] , who established almost fifty years after the
discoverers of ( 1 ) that one could choose @xmath , a result which
stimulated a wealth of research.

###### Travelling waves.

The fact that (semi-linear) parabolic differential equations could
describe wave-like phenomena has aroused great interest and spurred a
lot of research, which is now a central pillar of the theory of
parabolic differential equations (see for example [ 13 , 139 ] ) and has
also been discussed to a great extent in the physics literature (see [
138 ] for an exhaustive account). The FKPP equation has a central place
in this theory and is considered to be a basic prototype.

Since the beginning of the 1990’s, physicists have been especially
interested in the effect of noise on wave propagation. The types of
noise that one considers are mainly multiplicative white noise and
discretisation of the wave profile (for an exhaustive list of references
on this subject, see [ 124 ] ). The rationale behind the latter is that
real-life systems consisting of a finite number of parts are only
approximately described by differential equations such as ( 1 ). For
example, in the original work of Fisher [ 80 ] , the function @xmath
describes the proportion of an advantageous gene among a population in a
one-dimensional habitat (such as a coast-line). In a population of size
@xmath , it can therefore “in reality” only take values which are
multiples of @xmath . Discretisation therefore corresponds to “internal”
noise of the system. A multiplicative white noise on the other hand
models an external noise [ 52 ] .

During the 90’s, there were several studies which noticed that such a
noise had a tremendous effect on the wave speed, causing a significant
slowdown of the wave (see for example [ 48 ] ). This was then
brilliantly analysed by Brunet and Derrida [ 50 ] , who introduced the
cutoff equation, which is obtained by multiplying the forcing term
@xmath in ( 1 ) by @xmath . They found the solutions to this equation to
have a wave speed slower than the original one by a difference of the
order of @xmath and verified this numerically [ 51 ] for an @xmath
-particle model, where each particle of generation @xmath chooses two
parents uniformly from level @xmath , takes the maximum of both
positions and adds a noise term. But they did not stop there: In later
works, with coauthors, they studied the fluctuations of such microscopic
systems of “FKPP type” and developed an axiomatic phenomenological
theory of fluctuating FKPP fronts which permits to describe the
fluctuations of those systems. Among them, they proposed the particle
system we call the @xmath -BRW [ 58 ] : At each time step, the particles
reproduce as in the BRW, but only the @xmath right-most particles are
kept, the others being removed from the system. This can be seen as a
kind of selection mechanism , which has an obvious biological
interpretation: If one interprets the position of an individual as the
value of its “fitness” [ 57 ] , i.e. a measure of how well the
individual is adapted to an environment, then killing all but the @xmath
right-most particles at each step is a toy model for natural selection ,
a key concept of Darwinian evolution.

###### Further applications of BRW and BBM.

Besides their role as prototypes of travelling waves, BRW and BBM have
many other applications or interpretations, mainly because of their tree
structure. For example, the BRW can be seen as a directed polymer on a
disordered tree [ 74 ] and more generally as an infinite-dimensional
version of the Generalised Random Energy Model (GREM) [ 72 , 43 ] . It
also plays an important role in the study of the Gaussian Free Field on
a 2D lattice box [ 38 , 69 , 39 , 47 ] . On a more basic level, BRW and
BBM have been used as models for the ecological spread of a population
or of a mutant allele inside a population [ 132 , 120 , 133 ] ,
especially in the multidimensional setting, which has been studied at
least since [ 31 ] . Finally, a fascinating application of the BRW
appears in the proof by Benjamini and Schramm that every graph with
positive Cheeger constant contains a tree with positive Cheeger constant
[ 19 ] .

### Results

We now come to the results obtained in this thesis on branching Brownian
motion with selection . As before, by selection we mean the process of
killing particles, which can be interpreted as the effect of natural
selection on a population, but should rather be viewed in the more
global framework of fronts under the effect of noise. We will
concentrate on two selection mechanisms:

  BBM with absorption.  

    Here, we absorb the particles at the space-time line @xmath ,
    i.e. as soon as a particle hits this line (a.k.a. the barrier ), it
    is killed immediately. This process is studied in Chapter 1 .

  @xmath -BBM.  

    This is the continuous version of the @xmath -BRW described above:
    Particles evolve according to branching Brownian motion and as soon
    as the number of particles exceeds @xmath , we kill the left-most
    particles, such that only the @xmath right-most remain. This process
    is studied in Chapter 2 .

In the next two paragraphs we describe the results we have obtained for
those two models and place them into the context of the existing
literature.

###### Notational convention.

We assume from now on that the branching rate satisfies @xmath , such
that @xmath . On can always reduce the situation to this case by
rescaling time and/or space. This choice of parameters will also be made
in Chapter 2 . However, in Chapter 1 we will set @xmath to @xmath , the
reason being that it is based on the article [ 115 ] which was accepted
for publication before the submission of this thesis and where this
choice of parameters was made.

###### BBM with absorption.

The study of branching diffusions with absorption goes back at least to
Sevast’yanov [ 134 ] , who studied the case of absorption at the border
of a bounded domain. Watanabe [ 140 ] considered branching diffusions in
arbitrary domains under the condition that the probability of ultimate
survival is positive. Kesten [ 102 ] was the first to consider the
special case of one-dimensional BBM with absorption at a linear
boundary: Starting with a single particle at @xmath , he gives a
constant drift @xmath to the particles and kills them as soon as they
hit the origin. He proves that the process gets extinct almost surely if
and only @xmath and provides detailed asymptotics for the number of
particles in a given interval and for the probability that the system
gets extinct before the time @xmath in the critical case @xmath .

The work of Neveu [ 123 ] in the case @xmath , where the process gets
extinct almost surely, is of utmost importance to us. He made the simple
but crucial observation that if one starts with one particle at the
origin and absorbs particles at @xmath , then the process @xmath , where
@xmath denotes the number of particles absorbed at @xmath , is a
continuous-time Galton–Watson process (note that space becomes time for
the process @xmath ). This fact comes from the strong branching property
, which says that the particles absorbed at @xmath each spawn
independent branching Brownian motions, a fact that has been formalised
and proven by Chauvin [ 61 ] using the concept of stopping lines .

In the last two decades, there has been renewed interest in BBM and BRW
with absorption and among the many articles on this subject we mention
the article [ 34 ] , in which the criterion for almost sure extinction
is established for the BRW, the articles by Biggins and Kyprianou [ 32 ,
33 , 108 ] , who use it to study the system without absorption, the work
[ 87 ] which studies “one-sided travelling waves” of the FKPP equation,
and the articles [ 9 , 128 , 73 , 83 , 21 , 6 , 22 ] which study the
survival probability at or near the critical drift.

But let us get back to Neveu [ 123 ] and to the continuous-time
Galton–Watson process @xmath . Neveu observed the maybe surprising fact
that in the case of critical drift @xmath , this process does not
satisfy the conditions of the Kesten–Stigum theorem and that indeed
@xmath converges as @xmath to a non-degenerate limit @xmath .

This fact has recently aroused interest because of David Aldous’
conjecture [ 7 ] that this result was true for the BRW as well.
Specifically, he conjectured that @xmath , where @xmath denotes the
number of particles in branching random walk with critical drift that
cross the origin for the first time ⁶ ⁶ 6 Aldous was actually interested
in the total progeny of the process, but this question is equivalent,
see [ 5 , Lemma 2] . . Moreover, Aldous conjectured that in the case
@xmath , the variable @xmath had a power-law tail.

Aldous formulated its conjecture after Pemantle had already provided an
incomplete proof [ 127 ] in the Bernoulli case, based on singularity
analysis of the generating function of @xmath . A complete proof in the
case @xmath was then given by Addario-Berry and Broutin [ 1 ] for
general reproduction laws satisfying a mild integrability assumption.
Aïdékon [ 2 ] further refined the results in the case of @xmath -ary
trees by showing that there are positive constants @xmath , such that
for every @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

In Chapter 1 , we prove a precise refinement of this result in the case
of branching Brownian motion. Specifically, we prove the following:

###### Theorem.

Assume that the reproduction law admits exponential moments, i.e. that
the radius of convergence of the power series @xmath is greater than 1.

-    [label= @xmath ]

-    In the critical speed area @xmath , as @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

-    In the subcritical speed area @xmath there exists a constant @xmath
    , such that, as @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

    where @xmath are the two roots of the quadratic equation @xmath ,
    @xmath and @xmath if @xmath and @xmath otherwise.

The proof of this theorem is inspired by Pemantle’s incomplete proof
mentioned above, in that it determines asymptotics on the generating
function of @xmath near its singularity @xmath , which can be exploited
to give the above asymptotics. The analysis of the generating function
is made possible through a link between travelling waves of the FKPP
equation and a classical differential equation in the complex domain,
the Briot–Bouquet equation . We will not go further into details here
but instead refer to Chapter 1 .

If the reproduction law does not admit exponential moments, we can
nevertheless apply Tauberian theorems to obtain the following result in
the critical case:

###### Theorem.

Let @xmath and assume that @xmath . Then we have as @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

We further mention that Aïdékon, Hu and Zindy [ 5 ] have recently proven
these facts for the BRW without any (complex) analytical arguments and
under even better moment conditions in the case @xmath .

###### The @xmath-Bbm.

We now turn to the main part of this thesis: The study of the @xmath
-BBM. We have already outlined before the role that it takes as a
prototype of a travelling wave with noise and will now present the
heuristic picture obtained by Brunet, Derrida, Mueller and Munier [ 56 ,
58 ] .

We recall the model: @xmath particles diffuse according to Brownian
motions and branch at rate @xmath into a random number of particles
given by the reproduction law @xmath . As soon as the number of
particles exceeds @xmath , only the @xmath right-most particles are kept
and the others are immediately killed. This gives a cloud of particles,
moving to the right with a certain speed @xmath and fluctuating around
its mean. See Figure 1 at the end of the introduction for simulations.
The authors of [ 56 ] provide detailed quantitative heuristics to
describe this behaviour:

1.  Most of the time, the particles are in a meta-stable state. In this
    state, the diameter of the cloud of particles (also called the front
    ) is approximately @xmath , the empirical density of the particles
    proportional to @xmath , and the system moves at a linear speed
    @xmath . This is the description provided by the cutoff
    approximation from [ 50 ] mentioned above.

2.  This meta-stable state is perturbed from time to time by particles
    moving far to the right and thus spawning a large number of
    descendants, causing a shift of the front to the right after a
    relaxation time which is of the order of @xmath . To make this
    precise, we fix a point in the bulk, for example the barycentre of
    the cloud of particles, and shift our coordinate system such that
    this point becomes its origin. Playing with the initial conditions
    of the FKPP equation with cutoff, the authors of [ 56 ] find that a
    particle moving up to the point @xmath causes a shift of the front
    by

      -- -------- --
         @xmath   
      -- -------- --

    for some constant @xmath . In particular, in order to have an effect
    on the position of the front, a particle has to reach a point near
    @xmath .

3.  Assuming that such an event where a particle “escapes” to the point
    @xmath happens with rate @xmath , one sees that the time it takes
    for a particle to come close to @xmath (and thus causing shifts of
    the front) is of the order of @xmath .

4.  With this information, the full statistics of the position of the
    front (i.e. the speed @xmath and the cumulants of order @xmath ) are
    found to be

      -- -------- -- -----
         @xmath      (2)
      -- -------- -- -----

    where @xmath denotes the Riemann zeta-function.

In another paper [ 57 ] , the same authors introduce a related model,
called the exponential model . This is a BRW, where an individual at
position @xmath has an infinite number of descendants distributed
according to a Poisson process of intensity @xmath . Again, at every
step, only the @xmath right-most particles are kept. This model has some
translational invariance properties which render it exactly solvable.
Besides asymptotics on the speed of this system and the fluctuations,
the authors of [ 57 ] then show that the genealogy of this system
converges to the celebrated Bolthausen--Sznitman coalescent ⁷ ⁷ 7 The
Bolthausen–Sznitman coalescent [ 40 ] is a process on the partitions of
@xmath , in which a proportion @xmath of the blocks merge to a single
one at rate @xmath . See [ 26 ] and [ 24 ] for an introduction to
coalescent processes. . This gives first insight into the fact that the
genealogy of the @xmath -BBM apparently converges to the same coalescent
process, a fact that has been observed by numerical simulations [ 58 ,
59 ] .

Despite (or because of) the simplicity of the @xmath -BBM, it is very
difficult to analyse it rigorously, because of the strong interaction
between the particles, the impossibility to describe it exactly through
differential equations and the fact that the shifts in the position of
the system do not occur instantaneously but gradually over the fairly
large timescale @xmath . For this reason, there have been few rigorous
results on the @xmath -BBM or the @xmath -BRW: Bérard and Gouéré [ 20 ]
prove the @xmath correction of the linear speed of @xmath -BRW in the
binary branching case, thereby showing the validity of the approximation
by a deterministic travelling wave with cutoff. Durrett and Remenik [ 76
] study the empirical distribution of @xmath -BRW and show that it
converges as @xmath goes to infinity but time is fixed to a system of
integro-differential equations with a moving boundary. Recently, Comets,
Quastel and Ramírez [ 65 ] studied a particle system expected to exhibit
similar behaviour than the exponential model and show in particular that
its recentred position converges to a totally asymmetric Cauchy process.

In [ 56 ] , the authors already had the idea of approximating the @xmath
-BBM by BBM with absorption at a linear barrier with the weakly
subcritical slope @xmath . This idea was then used with success in [ 20
] for the proof of the cutoff-correction to the speed of the @xmath
-BRW, relying on a result [ 83 ] about the survival probability of BRW
with absorption at such a barrier and a result by Pemantle about the
number of nearly optimal paths in a binary tree [ 128 ] . In the same
vein, Berestycki, Berestycki and Schweinsberg [ 23 ] studied the
genealogy of BBM with absorption at this barrier and found that it
converges at the @xmath timescale to the Bolthausen–Sznitman coalescent,
as predicted. In Chapter 2 of this thesis, we build upon their analysis
in order to study the position of the @xmath -BBM itself. The results
that we prove are summarised in the following theorem, which confirms (
2 ) (see Theorem 1.1 of Chapter 2 for a complete statement).

###### Theorem.

Let @xmath denote the position of the @xmath -th particle from the right
in @xmath -BBM. Then under “good” initial conditions, the
finite-dimensional distributions of the process

  -- -------- --
     @xmath   
  -- -------- --

converge weakly as @xmath to those of the Lévy process @xmath with

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the image of the measure @xmath by the map @xmath and
@xmath is a constant depending only on the reproduction law @xmath .

In order to prove this result, we approximate the @xmath -BBM by BBM
with absorption at a random barrier instead of a linear one, a process
which we call the B-BBM (“B” stands for “barrier”). This random barrier
has the property that the number of individuals stays almost constant
during a time of order @xmath . We then couple the @xmath -BBM with two
variants of the B-BBM, the B @xmath -BBM and the B @xmath -BBM, which in
a certain sense bound the @xmath -BBM from below and from above,
respectively. For further details about the idea of the proof, we refer
to Section 1 in Chapter 2 .

###### Stable point processes occurring in branching Brownian motion.

This paragraph describes the content of Chapter 3 , which is independent
from the first two and has nothing to do with selection. It concerns the
extremal particles in BBM and BRW without selection, i.e. the particles
which are near the right-most. The study of these particles has been
initiated again by Brunet and Derrida [ 53 ] , who gave arguments for
the following fact: The point process formed by the particles of BBM at
time @xmath , shifted to the left by @xmath , converges as @xmath to a
point process @xmath which has the “superposability” property: the union
of @xmath translated by @xmath and @xmath translated by @xmath has the
same law as @xmath , where @xmath is an independent copy of @xmath and
@xmath . Moreover, they conjectured that this process, and possibly
every process with the previous property, could be represented as a
Poisson process with intensity @xmath , decorated by an auxiliary point
process @xmath , i.e. each point @xmath of the Poisson process is
replaced by an independent copy of @xmath translated by @xmath .

In Chapter 3 we show that the “superposability” property has a classical
interpretation in terms of stable point processes , pointed out to us by
Ilya Molchanov, and the above-mentioned representation is known in this
field as the LePage series representation of a stable point process. We
furthermore give a short proof of this representation using only the
theory of infinitely divisible random measures. For the BBM and BRW, the
convergence of the extremal particles to such a process was proven by
Arguin, Bovier, Kistler [ 10 , 12 , 11 ] , Aïdékon, Berestycki, Brunet,
Shi [ 4 ] and Madaule [ 114 ] . Kabluchko [ 98 ] also has an interesting
result for BRW started with an infinite number of particles distributed
with density @xmath , with @xmath , which corresponds to travelling
waves of speed larger than @xmath .

### Conclusion and open problems

In this thesis, we have studied two models of branching Brownian motion
with selection: the BBM with absorption at a linear barrier and the
@xmath -BBM. For the first model, we have given precise asymptotics on
the number of absorbed particles in the case where the process gets
extinct almost surely. For the second model, the study of which
represents the major part of the thesis, we have shown that the
recentred position of the particle system converges at the time-scale
@xmath to a Lévy process which is given explicitly. Finally, in the last
chapter, we have pointed out a relation between the extremal particles
of BBM and BRW and stable point processes.

The study of the @xmath -BBM constitutes an important step in the
understanding of general fluctuating wave fronts, whose phenomenology is
believed to be the same in many cases [ 56 ] . Furthermore, it is a
natural and intricate example of a selection mechanism for BBM and BRW
and an intuitive model of a population under natural selection.

We have not considered models of BBM with selection with
density-dependent selection, i.e. where particles get killed with a rate
depending on the number of particles in their neighbourhood. This kind
of selection is indeed the most relevant for applications in ecology and
has appeared in the literature mostly as branching-coalescing particle
systems (see for example [ 136 , 135 , 18 , 125 , 75 , 15 ] ), but also
as systems with a continuous self-regulating density [ 137 , 84 ] .
However, although we have not directly considered this type of selection
mechanism, the @xmath -BBM is closely related to a particular case:
Suppose particles perform BBM and furthermore coalesce at rate @xmath
when they meet (i.e. let two particles coalesce when their intersection
local time is equal to an independent exponential variable of parameter
@xmath ). Shiga [ 135 ] showed that this system is in duality with the
noisy FKPP equation

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

where @xmath is space-time white noise. This equation admits “travelling
wave” solutions whose wave speed equals the speed of the right-most
particle of the branching-coalescing Brownian motion (BCBM) [ 121 ] .
Now, following the argumentation in [ 121 ] , the invariant measures of
the BCBM are the Poisson process of intensity @xmath and the
configuration of no particles, the first being stable and the second
unstable. Hence, if one looks at the right-most particles in the BCBM,
they will ultimately form a wave-like profile with particles to the left
of this wave distributed with a density @xmath . We have thus a similar
picture than in the @xmath -BBM, in that when particles get to the left
of the front, they get killed quickly, in this case approximately with
rate 1 instead of instantaneously. If @xmath is small, this does not
make a difference because the typical diameter of the front goes to
infinity as @xmath . It is therefore plausible that our results about
the @xmath -BBM can be transferred to the BCBM and thus to the noisy
FKPP equation ( 3 ). Indeed, Mueller, Mytnik and Quastel [ 121 ] have
showed that the wave speed of solutions to ( 3 ) is approximately @xmath
(although they still have an error of @xmath , where @xmath ).

In what follows, we will outline several other open problems, mostly
concerning the @xmath -BBM.

###### Speed of the @xmath-Bbm.

If the reproduction law satisfies @xmath , then the speed of the system
is the constant @xmath , such that @xmath as @xmath , where @xmath is
again the position of the @xmath -th particle from the right in @xmath
-BBM. It has been shown [ 20 ] for the BRW with binary branching that
this speed exists and it is not difficult to extend their proof to the
BBM. Now, although our result about the position of the @xmath -BBM
describes quite precisely the fluctuations at the timescale @xmath it
tells us nothing about the behaviour of the system as time gets
arbitrarily large. A priori , it could be possible that funny things
happen at larger timescales, which lead to stronger fluctuations or a
different speed of the system. In their proof [ 20 ] of the cutoff
correction for the speed, Bérard and Gouéré had to consider in fact
timescales up to @xmath . It is therefore an open problem to prove that
@xmath for some constant @xmath and that the cumulants scale as in ( 2 )
as @xmath , which we conjecture to be true.

###### Empirical measure of the @xmath-Bbm.

Let @xmath be the empirical measure of the particles at time @xmath in
@xmath -BBM seen from the left-most particle. Durrett and Remenik [ 76 ]
show (for BRW) that the process @xmath is ergodic and therefore has an
invariant probability @xmath and furthermore converges as @xmath in law
to a deterministic measure-valued process whose density with respect to
Lebesgue measure solves a free boundary integro-differential equation.
Our result on the @xmath -BBM and those prior to our work [ 50 , 56 , 23
] suggest that the @xmath should converge, as @xmath , to the Dirac
measure concentrated on the measure @xmath . If one was to prove this,
the methods of [ 76 ] , which are essentially based on Gronwall’s
inequality, would not directly apply, since they only work for
timescales of at most @xmath . On the other hand, our technique of the
coupling with BBM with absorption has fairly restrictive requirements on
the initial configuration of the particles. A method of proof would
therefore be to show that these requirements are met after a certain
time for any initial configuration and then couple the processes.

###### The genealogy of the @xmath-Bbm.

As mentioned above, the genealogy of the @xmath -BBM is expected to
converge at the timescale @xmath to the Bolthausen–Sznitman coalescent
as @xmath goes to infinity. A step towards this conjecture is the
article [ 23 ] , in which the authors show that this convergence holds
for BBM with absorption at a weakly subcritical barrier; it should be
easy to extend their arguments for the B-BBM defined in Section 7 of
Chapter 2 . However, this would not be enough, since the monotone
coupling we use to couple the @xmath -BBM with the B-BBM (or rather its
variants B @xmath -BBM and B @xmath -BBM) does not preserve the
genealogical structure of the process. More work is therefore required
to prove the conjecture for the @xmath -BBM.

###### The @xmath-Brw.

It should be possible to transfer the results obtained here for the
@xmath -BBM to the @xmath -BRW, as long as the displacements have
exponential right tails and the number of offspring of a particle has
finite variance, say. Naturally, this would require a lot more work
because of the lack of explicit expressions for the density of the
particles; one can wonder whether this work would be worth it. However,
it would be interesting to consider cases where one could get different
behaviour than for the @xmath -BBM, such as subexponentially decaying
right tails of the displacements or models where particles have an
infinite number of children, as in the exponential model. Another
possible point of attack in the same direction would be to make rigorous
for the @xmath -BBM the findings in [ 55 ] . In that article, the
authors weight the process by an exponential weight @xmath , where
@xmath is the position of the right-most particle at time @xmath , and
obtain thus a one-parameter family of coalescent processes as
genealogies.

###### Superprocesses.

If one considers @xmath independent BBMs with weakly supercritical
reproduction (i.e. @xmath for some constant @xmath ), gives the mass
@xmath to each individual and rescales time by @xmath and space by
@xmath , then one obtains in the limit a (supercritical) superprocess,
such as the Dawson–Watanabe process in the case that the variance of the
reproduction law is finite (see [ 77 ] for a gentle introduction to
superprocesses). One may wonder whether the results obtained in this
thesis have analogues in that setting. This is true for the results
obtained in Chapter 1 , as shown in [ 110 ] , in which the authors
indeed transfer the results directly via the so-called backbone
decomposition of the superprocess [ 109 ] . As for an analogue of the
@xmath -BBM: one could consider a similar model of a superprocess whose
mass is kept below @xmath by stripping off some mass to the left as soon
as the total mass exceeds @xmath . It is possible that this process then
exhibits similar fluctuations, which could again be related to those of
the @xmath -BBM by the backbone decomposition.

## Chapter 1 The number of absorbed individuals in branching Brownian
motion with a barrier

This chapter is based on the article [ 115 ] .

### 1 Introduction

We recall the definition of branching Brownian motion mentioned already
in the introductory chapter: Starting with an initial individual sitting
at the origin of the real line, this individual moves according to a
1-dimensional Brownian motion with drift @xmath until an independent
exponentially distributed time with rate 1. At that moment it dies and
produces @xmath (identical) offspring, @xmath being a random variable
taking values in the non-negative integers with @xmath . Starting from
the position at which its parent has died, each child repeats this
process, all independently of one another and of their parent. For a
rigorous definition of this process, see for example [ 94 ] or [ 61 ] .

We assume that @xmath , which means that the process is supercritical.
At position @xmath , we add an absorbing barrier , i.e. individuals
hitting the barrier are instantly killed without producing offspring.
Kesten proved [ 102 ] that this process becomes extinct almost surely if
and only if the drift @xmath (he actually needed @xmath for the “only
if” part, but we are going to prove that the statement holds in
general). Neveu [ 123 ] showed that the process @xmath is a
continuous-time Galton–Watson process of finite expectation, but with
@xmath for every @xmath , if @xmath .

Let @xmath and @xmath . Define the infinitesimal transition rates (see [
14 ] , p. 104, Equation (6) or [ 89 ] , p. 95)

  -- -------- --
     @xmath   
  -- -------- --

We propose a refinement of Neveu’s result:

###### Theorem 1.1.

Let @xmath and assume that @xmath . Then we have as @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The heavy tail of @xmath suggests that its generating function is
amenable to singularity analysis in the sense of [ 81 ] . This is in
fact the case in both the critical and subcritical cases if we impose a
stronger condition upon the offspring distribution and leads to the next
theorem.

Define @xmath the generating function of the offspring distribution.
Denote by @xmath the span of @xmath , i.e. the greatest positive
integer, such that @xmath is concentrated on @xmath . Let @xmath be the
two roots of the quadratic equation @xmath and denote by @xmath the
ratio of the two roots. Note that @xmath if and only if @xmath if and
only if @xmath .

###### Theorem 1.2.

Assume that the law of @xmath admits exponential moments, i.e. that the
radius of convergence of the power series @xmath is greater than 1.

-    [label= @xmath ]

-    In the critical speed area @xmath , as @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

-    In the subcritical speed area @xmath there exists a constant @xmath
    , such that, as @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

Furthermore, @xmath for all @xmath and @xmath .

###### Remark 1.3.

The idea of using singularity analysis for the study of @xmath comes
from Robin Pemantle’s (unfinished) manuscript [ 127 ] about branching
random walks with Bernoulli reproduction.

###### Remark 1.4.

Since the coefficients of the power series @xmath are real and
non-negative, Pringsheim’s theorem (see e.g. [ 82 ] , Theorem IV.6,
p. 240) entails that the assumption in Theorem 1.2 is verified if and
only if @xmath is analytic at 1.

###### Remark 1.5.

Let @xmath and @xmath . We consider a more general branching Brownian
motion with branching rate given by @xmath and the drift and variance of
the Brownian motion given by @xmath and @xmath , respectively. Call this
process the @xmath -BBM (the reproduction is still governed by the law
of @xmath , which is fixed). In this terminology, the process described
at the beginning of this section is the @xmath -BBM. The @xmath -BBM can
be obtained from @xmath -BBM by rescaling time by a factor @xmath and
space by a factor @xmath . Therefore, if we add an absorbing barrier at
the point @xmath , the @xmath -BBM gets extinct a.s. if and only if
@xmath . Moreover, if we denote by @xmath the number of particles
absorbed at @xmath , we obtain that

  -- -------- --
     @xmath   
  -- -------- --

In particular, if we denote the infinitesimal transition rates of @xmath
by @xmath , for @xmath , then we have

  -- -------- --
     @xmath   
  -- -------- --

One therefore easily checks that the statements of Theorems 1.1 and 1.2
are still valid for arbitrary @xmath and @xmath , provided that one
replaces the constants @xmath by @xmath , @xmath , @xmath , @xmath ,
respectively.

The content of the paper is organised as follows: In Section 2 we derive
some preliminary results by probabilistic means. In Section 3 , we
recall a known relation between @xmath and the so-called
Fisher–Kolmogorov–Petrovskii–Piskounov (FKPP) equation. Section 4 is
devoted to the proof of Theorem 1.1 , which draws on a Tauberian theorem
and known asymptotics of travelling wave solutions to the FKPP equation.
In Section 5 we review results about complex differential equations,
singularity analysis of generating functions and continuous-time
Galton–Watson processes. Those are needed for the proof of Theorem 1.2 ,
which is done in Section 6 .

### 2 First results by probabilistic methods

The goal of this section is to prove

###### Proposition 2.1.

Assume @xmath and @xmath . There exists a constant @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

This result is needed to assure that the constant @xmath in Theorem 1.2
is non-zero. It is independent from Sections 3 and 4 and in particular
from Theorem 1.1 . Its proof is entirely probabilistic and follows
closely [ 2 ] .

#### 2.1 Notation and preliminary remarks

Our notation borrows from [ 108 ] . An individual is an element in the
space of Ulam–Harris labels

  -- -------- --
     @xmath   
  -- -------- --

which is endowed with the ordering relations @xmath and @xmath defined
by

  -- -------- --
     @xmath   
  -- -------- --

The space of Galton–Watson trees is the space of subsets @xmath , such
that @xmath , @xmath if @xmath and @xmath and for every @xmath there is
a number @xmath , such that for all @xmath , @xmath if and only if
@xmath . Thus, @xmath is the number of children of the individual @xmath
.

Branching Brownian motion is defined on the filtered probability space
@xmath . Here, @xmath is the space of Galton–Watson trees with each
individual @xmath having a mark @xmath , where @xmath is a cemetery
symbol and @xmath denotes the Skorokhod space of cadlag functions from
@xmath to @xmath . Here, @xmath denotes the life length and @xmath the
position of @xmath at time @xmath , or of its ancestor that was alive at
time @xmath . More precisely, for @xmath , let @xmath denote the time of
death and @xmath the time of birth of @xmath . Then @xmath for @xmath
and if @xmath is such that @xmath , then @xmath .

The sigma-field @xmath contains all the information up to time @xmath ,
and @xmath .

Let @xmath and @xmath be some random variable taking values in @xmath .
@xmath is the unique probability measure, such that, starting with a
single individual at the point @xmath ,

-   [nolistsep, label= @xmath ]

-   each individual moves according to a Brownian motion with drift
    @xmath until an independent time @xmath following an exponential
    distribution with parameter 1.

-   At the time @xmath the individual dies and leaves @xmath offspring
    at the position where it has died, with @xmath being an independent
    copy of @xmath .

-   Each child of @xmath repeats this process, all independently of one
    another and of the past of the process.

Note that often @xmath and @xmath are regarded as fixed and @xmath as
variable. In this case, the notation @xmath is used. In the same way,
expectation with respect to @xmath is denoted by @xmath or @xmath .

A common technique in branching processes since [ 113 ] is to enhance
the space @xmath by selecting an infinite genealogical line of descent
from the ancestor @xmath , called the spine . More precisely, if @xmath
and @xmath its underlying Galton–Watson tree, then @xmath is a spine of
@xmath if @xmath and for every @xmath , @xmath is a child of @xmath in
@xmath . This gives the space

  -- -------- --
     @xmath   
  -- -------- --

of marked trees with spine and the sigma-fields @xmath and @xmath . Note
that if @xmath , then @xmath is necessarily infinite.

Assume from now on that @xmath . Let @xmath be the set of individuals
alive at time @xmath . Note that every @xmath -measurable function
@xmath admits a representation

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an @xmath -measurable function for every @xmath . We can
therefore define a measure @xmath on @xmath by

  -- -- -- -------
           (2.1)
  -- -- -- -------

It is known [ 108 ] that this definition is sound and that @xmath is
actually a probability measure with the following properties:

-   [nolistsep, label= @xmath ]

-   Under @xmath , the individuals on the spine move according to
    Brownian motion with drift @xmath and die at an accelerated rate
    @xmath , independent of the motion.

-   When an individual on the spine dies, it leaves a random number of
    offspring at the point where it has died, this number following the
    size-biased distribution of @xmath . In other words, let @xmath be a
    random variable with @xmath for every positive measurable function
    @xmath . Then the number of offspring is an independent copy of
    @xmath .

-   Amongst those offspring, the next individual on the spine is chosen
    uniformly. This individual repeats the behaviour of its parent.

-   The other offspring initiate branching Brownian motions according to
    the law @xmath .

Seen as an equation rather than a definition, ( 2.1 ) also goes by the
name of “many-to-one lemma”.

#### 2.2 Branching Brownian motion with two barriers

We recall the notation @xmath from the previous subsection for the law
of branching Brownian motion started at @xmath and @xmath the
expectation with respect to @xmath . Recall the definition of @xmath and
define @xmath and @xmath analogously.

Let @xmath such that @xmath . Let @xmath be the (random) set of those
individuals whose paths enter @xmath and all of whose ancestors’ paths
have stayed inside @xmath . For @xmath we denote by @xmath the first
exit time from @xmath by @xmath ’s path, i.e.

  -- -------- --
     @xmath   
  -- -------- --

and set @xmath for @xmath . The random set @xmath is an (optional)
stopping line in the sense of [ 61 ] .

For @xmath , define @xmath . Denote by @xmath the number of individuals
leaving the interval @xmath at the point @xmath , i.e.

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 2.2.

Assume @xmath and define @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

If, furthermore, @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

On the space @xmath of marked trees with spine, define the random
variable @xmath by @xmath if @xmath and @xmath otherwise. For an event
@xmath and a random variable @xmath write @xmath instead of @xmath .
Then

  -- -------- --
     @xmath   
  -- -------- --

by the many-to-one lemma extended to optional stopping lines (see [ 33 ]
, Lemma 14.1 for a discrete version). But since the spine follows
Brownian motion with drift @xmath , we have @xmath , @xmath -a.s. and
the above quantity is therefore equal to

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the law of standard Brownian motion with drift @xmath
started at @xmath , @xmath the canonical process and @xmath the first
exit time from @xmath of @xmath . By Girsanov’s theorem, and recalling
that @xmath , this is equal to

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Evaluating this expression ( [ 41 ] , p. 212, Formula
1.3.0.5) gives the first equality.

For @xmath , let @xmath be the operator that maps a tree in @xmath to
its sub-tree rooted in @xmath . Denote further by @xmath the set of
@xmath ’s children, i.e. @xmath . Then note that for each @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

hence

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

Define the @xmath -algebras

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

such that @xmath contains the information about the path of the spine up
to the individual that quits @xmath first, @xmath adds to @xmath the
information about the fission times on the spine and @xmath adds to
@xmath the information about the individuals of the spine and the number
of their children. Now, conditioning on @xmath and using the strong
branching property, the second term in the last line of ( 2.2 ) is equal
to

  -- -------- --
     @xmath   
  -- -------- --

(recall that @xmath is the time of death of @xmath ). Conditioning on
@xmath and noting the fact that @xmath follows the size-biased law of
@xmath for an individual @xmath on the spine, yields

  -- -------- --
     @xmath   
  -- -------- --

Finally, since under @xmath the fission times on the spine form a
Poisson process of intensity @xmath , conditioning on @xmath and
applying Girsanov’s theorem yields

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the local time of @xmath at the time @xmath and the
point @xmath . The last expression can be evaluated explicitly ( [ 41 ]
, p. 215, Formula 1.3.3.8) and gives the desired equality. ∎

###### Corollary 2.3.

Under the assumptions of Lemma 2.2 , for each @xmath there are positive
constants @xmath , @xmath , such that as @xmath ,

1.   [nolistsep, label=)]

2.  @xmath ,

3.   if @xmath , @xmath and

4.   if @xmath , @xmath .

The following result is well known and is only included for
completeness. We emphasize that the only moment assumption here is
@xmath . Recall that @xmath denotes the number of particles absorbed at
@xmath of a BBM started at the origin. For @xmath , define @xmath to be
the smaller root of @xmath , thus @xmath .

###### Lemma 2.4.

Let @xmath .

-    [nolistsep, label= @xmath ]

-    If @xmath , then @xmath .

-    If @xmath , then @xmath .

###### Proof.

We proceed similarly to the first part of Lemma 2.2 . Define the
(optional) stopping line @xmath of the individuals whose paths enter
@xmath and all of whose ancestors’ paths have stayed inside @xmath .
Define @xmath as in the proof of Lemma 2.2 . By the stopping line
version of the many-to-one lemma we have

  -- -------- --
     @xmath   
  -- -------- --

By Girsanov’s theorem, this equals

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the law of standard Brownian motion started at 0 and
@xmath is the first hitting time of @xmath . The result now follows from
[ 41 ] , p. 198, Formula 1.2.0.1. ∎

#### 2.3 Proof of Proposition 2.1

By hypothesis, @xmath , @xmath and the BBM starts at the origin. Let
@xmath and let @xmath be the stopping line of those individuals hitting
the point @xmath for the first time. Then @xmath .

Let @xmath and @xmath . By the strong branching property,

  -- -------- --
     @xmath   
  -- -------- --

If @xmath denotes the law of branching Brownian motion started at the
point @xmath with drift @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

In order to bound this quantity, we choose @xmath in such a way that
@xmath By Corollary 2.3 a), c) (applied with drift @xmath ) and the
Paley–Zygmund inequality, there is then a constant @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, by Corollary 2.3 a) (applied with drift @xmath ), we have

  -- -------- --
     @xmath   
  -- -------- --

and therefore @xmath . Again by the Paley–Zygmund inequality and
Corollary 2.3 a), b) (applied with drift @xmath ), there exists @xmath ,
such that for large @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This proves the proposition with @xmath .

### 3 The FKPP equation

As was already observed by Neveu [ 123 ] , the translational invariance
of Brownian motion and the strong branching property immediately imply
that @xmath is a homogeneous continuous-time Galton–Watson process (for
an overview to these processes, see [ 14 ] , Chapter III or [ 89 ] ,
Chapter V). There is therefore an infinitesimal generating function

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

associated to it. It is a strictly convex function on @xmath , with
@xmath and @xmath . Its probabilistic interpretation is

  -- -------- --
     @xmath   
  -- -------- --

hence @xmath for @xmath . Note that with no further conditions on @xmath
and @xmath , the sum @xmath need not necessarily be @xmath , i.e. the
rate @xmath , where @xmath , with which the process jumps to @xmath ,
may be positive.

We further define @xmath , which is linked to @xmath by Kolmogorov’s
forward and backward equations ( [ 14 ] , p. 106 or [ 89 ] , p. 102):

  -- -------- -------- -- -- -------
     @xmath   @xmath         (3.2)
     @xmath   @xmath         (3.3)
  -- -------- -------- -- -- -------

The forward equation implies that if @xmath and @xmath , then @xmath ,
whence @xmath . On the other hand, if @xmath , then the process jumps to
@xmath with positive rate, hence @xmath for all @xmath .

The next lemma is an extension of a result which is stated, but not
proven, in [ 123 ] , Equation (1.1). According to Neveu, it is due to
A. Joffe. To the knowledge of the author, no proof of this result exists
in the current literature, which is why we prove it here.

###### Lemma 3.1.

Let @xmath be a homogeneous Galton–Watson process started at 1, which
may explode and may jump to @xmath with positive rate. Let @xmath be its
infinitesimal generating function and @xmath . Let @xmath be the
smallest zero of @xmath in @xmath .

1.   [nolistsep]

2.   If @xmath , then there exists @xmath and a strictly decreasing
    smooth function @xmath with @xmath and @xmath , such that on @xmath
    we have @xmath , @xmath .

3.   If @xmath , then there exists @xmath and a strictly increasing
    smooth function @xmath with @xmath and @xmath , such that on @xmath
    we have @xmath , @xmath .

The functions @xmath and @xmath are unique up to translation.

Moreover, the following statements are equivalent:

-    [nolistsep, label= @xmath ]

-    For all @xmath , @xmath a.s.

-   @xmath or @xmath .

###### Proof.

We first note that @xmath on @xmath and @xmath on @xmath , since @xmath
is strictly convex, @xmath and @xmath . Since @xmath , Kolmogorov’s
forward equation ( 3.2 ) implies that @xmath is strictly increasing in
@xmath for @xmath and strictly decreasing in @xmath for @xmath . The
backward equation ( 3.3 ) implies that @xmath converges to @xmath as
@xmath for every @xmath . Repeated application of ( 3.3 ) yields that
@xmath is a smooth function of @xmath for every @xmath .

Now assume that @xmath . For @xmath set @xmath , such that @xmath ,
@xmath and @xmath as @xmath . Set @xmath and define @xmath recursively
by

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath is a decreasing sequence and thus has a limit @xmath . We
now define for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The function @xmath is well defined, since for every @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

by the branching property. The same argument shows us that if @xmath ,
@xmath and @xmath such that @xmath , then @xmath for all @xmath . In
particular, @xmath , hence @xmath . The backward equation ( 3.3 ) now
gives

  -- -------- --
     @xmath   
  -- -------- --

The second part concerning @xmath is proven completely analogously.
Uniqueness up to translation of @xmath and @xmath is obvious from the
requirement @xmath , where @xmath is either @xmath or @xmath .

For the last statement, note that @xmath for all @xmath if and only if
@xmath for all @xmath . But this is the case exactly if @xmath or @xmath
. ∎

The following proposition shows that the functions @xmath and @xmath
corresponding to @xmath are so-called travelling wave solutions of a
reaction-diffusion equation called the
Fisher–Kolmogorov–Petrovskii–Piskounov (FKPP) equation. This should not
be regarded as a new result, since Neveu ( [ 123 ] , Proposition 3)
proved it already for the case @xmath and @xmath a.s. (dyadic
branching). However, his proof relied on a path decomposition result for
Brownian motion, whereas we show that it follows from simple renewal
argument valid for branching diffusions in general.

Recall that @xmath denotes the generating function of @xmath . Let
@xmath be the unique fixed point of @xmath in @xmath (which exists,
since @xmath ), and let @xmath be the smallest zero of @xmath in @xmath
.

###### Proposition 3.2.

Assume @xmath . The functions @xmath and @xmath from Lemma 3.1
corresponding to @xmath are solutions to the following differential
equation on @xmath and @xmath , respectively.

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

Moreover, we have the following three cases:

1.   [nolistsep]

2.   If @xmath , then @xmath , @xmath , @xmath , @xmath , @xmath for all
    @xmath .

3.   If @xmath , then @xmath , @xmath , @xmath , @xmath , @xmath for all
    @xmath .

4.   If @xmath , then @xmath , @xmath , @xmath , @xmath for all @xmath .

###### Proof.

Let @xmath and define the function @xmath for @xmath . By symmetry,
@xmath has the same law as the number of individuals @xmath absorbed at
the origin in a branching Brownian motion started at @xmath and with
drift @xmath . By a standard renewal argument (Lemma 7.1 ), the function
@xmath is therefore a solution of ( 3.4 ) on @xmath with @xmath . This
proves the first statement, in view of the representation of @xmath in
terms of @xmath and @xmath given by Lemma 3.1 .

Let @xmath and let @xmath if @xmath and @xmath otherwise. By ( 3.4 ),

  -- -------- --
     @xmath   
  -- -------- --

whence, by convexity,

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

Assume @xmath . By Lemma 2.4 , @xmath , hence @xmath and @xmath , in
particular, @xmath for @xmath and @xmath for @xmath . By convexity,
@xmath for @xmath and @xmath for @xmath . The last statement of Lemma
3.1 now implies that @xmath if @xmath .

Now assume @xmath . By Lemma 2.4 , @xmath for all @xmath , hence either
@xmath or @xmath and @xmath , in particular, @xmath by convexity.
However, if @xmath , then by ( 3.5 ), @xmath , whence the second case
cannot occur. Thus, @xmath and @xmath by ( 3.5 ).

It remains to show that @xmath if @xmath . Assume @xmath . Then @xmath
by the (strict) convexity of @xmath and @xmath by ( 3.5 ). In
particular, @xmath , which is a contradiction to @xmath being strictly
convex. ∎

### 4 Proof of Theorem 1.1

We have @xmath by hypothesis. Let @xmath be the travelling wave from
Proposition 3.2 , which is defined on @xmath , since @xmath . Let @xmath
, such that @xmath , @xmath and

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

by ( 3.4 ). Furthermore, @xmath and @xmath .

Under the hypothesis @xmath , it is known [ 143 ] that there exists
@xmath , such that @xmath as @xmath . Since @xmath and @xmath by
Proposition 3.2 , this entails that @xmath , as @xmath .

Set @xmath and @xmath . By ( 4.1 ),

  -- -------- --
     @xmath   
  -- -------- --

Setting @xmath , this gives

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

The Jordan decomposition of @xmath is given by

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

Setting @xmath = @xmath , we get with @xmath :

  -- -------- --
     @xmath   
  -- -------- --

which, in integrated form, becomes

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

Note that

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

With the above asymptotic of @xmath , the integral @xmath is finite by
Theorem B of [ 36 ] (see also Theorem 8.1.8 in [ 37 ] ). Equations ( 4.4
) and ( 4.5 ) now imply that

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

and since @xmath and @xmath , this gives

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

With this information, one can now show by elementary calculus (see
Section 7.2 ), that

  -- -------- -------- -- -------
     @xmath   @xmath      (4.7)
     @xmath   @xmath      (4.8)
  -- -------- -------- -- -------

By standard Tauberian theorems ( [ 79 ] , Section XIII.5, Theorem 5), (
4.7 ) implies that

  -- -------- --
     @xmath   
  -- -------- --

By integration by parts, this entails that

  -- -- --
        
  -- -- --

But the last integral is equivalent to @xmath ( [ 79 ] , Section VIII.9,
Theorem 1), which proves the first part of the theorem. The second part
is proven analogously, using ( 4.8 ) instead.

### 5 Preliminaries for the proof of Theorem 1.2

In light of Proposition 2.1 , one may suggest that under suitable
conditions on @xmath one may extend the proof of Theorem 1.1 to the
subcritical case @xmath and prove that as @xmath , @xmath for some
constant @xmath . In order to apply Tauberian theorems, one would then
have to establish asymptotics for the @xmath -th derivatives of @xmath
and @xmath as @xmath . In trying to do this, one quickly sees that the
known asymptotics for the travelling wave ( @xmath as @xmath , see [ 108
] ) are not precise enough for this method to work. However, instead of
relying on Tauberian theorems, one can analyse the behaviour of the
holomorphic function @xmath near its singular point @xmath . This method
is widely used in combinatorics at least since the seminal paper by
Flajolet and Odlyzko [ 81 ] and is the basis for our proof of Theorem
1.2 . Not only does it work in both the critical and subcritical cases,
it even yields asymptotics for the density instead of the tail only.

In the rest of this section, we will define our notation for the complex
analytic part of the proof and review some necessary general complex
analytic results.

#### 5.1 Notation

In the course of the paper, we will work in the spaces @xmath and @xmath
, endowed with the Euclidean topology. An open connected set is called a
region , a simply connected region containing a point @xmath is also
called a neighbourhood of @xmath . The closure of a set @xmath is
denoted by @xmath , its border by @xmath . The disk of radius @xmath
around @xmath is denoted by @xmath , its closure and border by @xmath
and @xmath , respectively. We further use the abbreviation @xmath for
the unit disk. For @xmath , @xmath and @xmath , we define

  -- -------- -------- -------- -------- --
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   @xmath   
     @xmath   @xmath                     
  -- -------- -------- -------- -------- --

Note that @xmath . Here and during the rest of the paper, @xmath and
@xmath are the principal values of argument and logarithm, respectively.

Let @xmath be a region in @xmath , @xmath and @xmath and @xmath analytic
functions in @xmath with @xmath for all @xmath . We write

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

specifying that the relations hold as @xmath .

#### 5.2 Complex differential equations

In this section, we review some basics about complex differential
equations. We start with the fundamental existence and uniqueness
theorem ( [ 28 ] , p. 1, [ 90 ] , Theorem 2.2.1, p. 45 or [ 95 ] ,
Section 12.1, p. 281).

###### Fact 5.1.

Let @xmath be a region in @xmath and @xmath a point in @xmath . Let
@xmath be analytic in @xmath , i.e. @xmath is continuous and both
partial derivatives exist and are continuous. Then there exists a
neighbourhood @xmath of @xmath and a unique analytic function @xmath ,
such that

1.   [nolistsep]

2.  @xmath ,

3.  @xmath for all @xmath and

4.  @xmath for all @xmath .

In other words, the differential equation @xmath with initial condition
@xmath has exactly one solution @xmath which is analytic at @xmath .

The following standard result is a special case of a theorem by Painlevé
( [ 28 ] , p. 11, [ 90 ] , Theorem 3.2.1, p. 82 or [ 95 ] , Section
12.3, p. 286f).

###### Fact 5.2.

Let @xmath be a region in @xmath and @xmath analytic in @xmath . Let
@xmath be a region in @xmath , such that @xmath for each @xmath and
suppose that there exists an analytic function @xmath , such that @xmath
for each @xmath . Let @xmath . Suppose that @xmath is continuous at
@xmath and that @xmath . Then @xmath is a regular point of @xmath , i.e.
@xmath admits an analytic extension at @xmath .

Let @xmath denote a power series of the variables @xmath , converging in
a neighbourhood of @xmath and which contains only terms of order @xmath
or higher. The complex differential equation

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

was introduced in 1856 by Briot and Bouquet [ 49 ] as an example of a
complex differential equation admitting analytic solutions at a singular
point of the equation. More precisely, they obtained ( [ 90 ] , Theorem
11.1.1, p. 402):

###### Fact 5.3.

If @xmath is not a positive integer, then there exists a unique function
@xmath which is analytic in a neighbourhood of @xmath and which
satisfies ( 5.1 ). Furthermore, @xmath .

The singular solutions to this equation were later investigated by
Poincaré, Picard and others (for a full bibliography, see [ 93 ] ). We
are going to need the following result (see [ 93 ] , Paragraph III.9.
@xmath or [ 90 ] , Theorem 11.1.3, p. 405, but note that the latter
reference is without proof and the statement is slightly incomplete).

###### Fact 5.4.

Assume @xmath . There exists a function @xmath , converging in a
neighbourhood of @xmath and such that @xmath and @xmath , such that the
general solution of ( 5.1 ) which vanishes at the origin is @xmath ,
with

-    [nolistsep, label= @xmath ]

-   @xmath , if @xmath ,

-   @xmath , if @xmath .

Here, @xmath is an arbitrary constant and @xmath is a fixed constant
depending only on the right-hand side of ( 5.1 ).

###### Remark 5.5.

The above statement is slightly imprecise, in that the term solution is
not defined, i.e. what a priori knowledge of @xmath (regarding its
domain of analyticity, smoothness, behaviour at @xmath , …) is required
in order to guarantee that it admits the representation stated in Fact
5.4 ? Inspecting the proof (as in [ 93 ] , for example) shows that it is
actually enough to know that @xmath satisfies ( 5.1 ) on an interval
@xmath of the real line and that @xmath . We briefly explain why:

In order to prove Fact 5.4 , one shows that there exists a function
@xmath of the form stated above, such that when changing variables by
@xmath , the function @xmath formally satisfies one of the equations

  -- -------- --
     @xmath   
  -- -------- --

according to whether @xmath or @xmath .

Now suppose that @xmath satisfies the above conditions. By the implicit
function theorem ( [ 91 ] , Theorem 2.1.2), we can invert @xmath to
obtain a function @xmath , @xmath , such that @xmath in a neighbourhood
of @xmath . We may thus define @xmath for all @xmath for some @xmath .
Moreover, @xmath now truly satisfies the above equations on @xmath and
@xmath . Standard theory of ordinary differential equations on the real
line now yields that @xmath is necessarily of the form stated in Fact
5.4 .

We further remark that since @xmath is analytic in the slit plane @xmath
and goes to @xmath as @xmath in @xmath , there exists an @xmath , such
that @xmath is in the domain of convergence of @xmath for every @xmath .
Hence, every solution @xmath can be analytically extended to @xmath .

#### 5.3 Singularity analysis

We now summarise results about the singularity analysis of generating
functions. The basic references are [ 81 ] and [ 82 ] , Chapter VI. The
results are of two types: those that establish an asymptotic for the
coefficients of functions that are explicitly known, and those that
estimate the coefficients of functions which are dominated by another
function. We start with the results of the first type:

###### Fact 5.6.

Let @xmath , @xmath , @xmath , @xmath and the functions @xmath , @xmath
defined by

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Let @xmath be the coefficients of the Taylor expansion of
@xmath around the origin, @xmath . Then @xmath satisfy the following
asymptotics as @xmath :

  -- -------- --
     @xmath   
  -- -------- --

for some non-zero constants @xmath . We have @xmath .

###### Proof.

For @xmath , this is Proposition 1 from [ 81 ] . For @xmath this is
Remark 3 at the end of Chapter 3 in the same paper. Note that the
additional factors @xmath do not change the nature of the singularities,
since @xmath is analytic at 1 (see the footnote on p. 385 in [ 82 ] ).
The last statement follows from Remark 3 as well. ∎

The results of the second type are contained in the next theorem. It is
identical to Corollary 4 in [ 81 ] . Note that a potential difficulty
here is that it requires analytical extension outside the unit disk.

###### Fact 5.7.

Let @xmath , @xmath and @xmath be analytic in @xmath Assume that as
@xmath in @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Then the coefficients @xmath of the Taylor expansion of @xmath around 0
satisfy

  -- -------- --
     @xmath   
  -- -------- --

#### 5.4 An equation for continuous-time Galton–Watson processes

In this section, let @xmath be a homogeneous continuous-time
Galton–Watson process starting at 1. Let @xmath be its infinitesimal
generating function and @xmath . Assume @xmath and @xmath such that
@xmath has a unique root @xmath in @xmath .

The following proposition establishes a relation between the
infinitesimal generating function of a Galton–Watson process and its
generating function at time @xmath . For real @xmath , the formulae
stated in the proposition are well known, but we will need to use them
for complex @xmath , which is why we have to include some (complicated)
hypotheses to be sure that the functions and integrals appearing in the
formulae are well defined.

###### Proposition 5.8.

Suppose that @xmath and @xmath have analytic extensions to some regions
@xmath and @xmath . Let @xmath . Let there be simply connected regions
@xmath and @xmath with @xmath and @xmath . Then the following equations
hold for all @xmath :

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where @xmath is defined for all @xmath as

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

and the integrals may be evaluated along any path from @xmath to @xmath
in @xmath .

###### Proof.

For @xmath , equation ( 5.2 ) follows readily from Kolmogorov’s backward
equation ( 3.3 ), when the integral is interpreted as the usual Riemann
integral ( [ 14 ] , p. 106). Now note that by definition of @xmath ,
both @xmath and @xmath are analytic in the simply connected region
@xmath and therefore possess antiderivatives @xmath and @xmath in @xmath
. Thus, the functions

  -- -------- --
     @xmath   
  -- -------- --

are analytic in @xmath . By the analytic continuation principle, ( 5.2 )
then holds for every @xmath , since @xmath by hypothesis. This proves
the first equation. For the second equation, note that @xmath is an
antiderivative of @xmath in @xmath , whence the right-hand side of ( 5.3
) equals

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath , by ( 5.2 ). This gives ( 5.3 ). ∎

###### Corollary 5.9.

If 1 is a regular point of @xmath , then it is a regular point for
@xmath for every @xmath .

###### Proof.

Define @xmath . Then @xmath , since @xmath is the only zero of @xmath in
@xmath (every probability generating function @xmath with @xmath has
exactly one fixed point @xmath in @xmath ; this can easily be seen by
applying Schwarz’s lemma to @xmath , where @xmath is the Möbius
transformation of the unit disk that maps @xmath to @xmath ). Let @xmath
be such that @xmath for every @xmath . We can then apply Proposition 5.8
to conclude that ( 5.3 ) holds for every @xmath .

Since @xmath is analytic in a neighbourhood @xmath of 1 by hypothesis,
it is easy to show that @xmath is analytic in @xmath as well. Thus,
@xmath has an antiderivative @xmath in @xmath . We define the function
@xmath on @xmath . Since @xmath , there exists an inverse @xmath of
@xmath in a neighbourhood @xmath of @xmath . Let @xmath be a
neighbourhood of 1, such that @xmath for every @xmath . Define the
analytic function @xmath for @xmath . Then by ( 5.3 ), we have @xmath
for every @xmath , hence @xmath is an analytic extension of @xmath at 1.
∎

###### Corollary 5.10.

Suppose that @xmath has an analytic extension to @xmath for some @xmath
and @xmath . Suppose further that there exist @xmath , @xmath , such
that @xmath as @xmath . Then for every @xmath there exists @xmath , such
that @xmath can be analytically extended to @xmath , mapping @xmath into
@xmath .

###### Proof.

Recall that @xmath . By hypothesis, we can then assume that @xmath in
@xmath by choosing @xmath small enough. Then @xmath has an
antiderivative @xmath on @xmath . Define @xmath for @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

We can therefore apply Lemma 7.7 to @xmath and deduce that there exist
@xmath and @xmath , such that @xmath is injective on @xmath and such
that @xmath for every @xmath . Hence, @xmath is defined and analytic on
@xmath . By ( 5.2 ), @xmath on @xmath , hence @xmath is an analytic
extension of @xmath , mapping @xmath into @xmath by definition. ∎

### 6 Proof of Theorem 1.2

We turn back to branching Brownian motion and to our Galton–Watson
process @xmath of the number of individuals absorbed at the point @xmath
. Throughout this section, we place ourselves under the hypotheses of
Theorem 1.2 , i.e. we assume that @xmath and that the radius of
convergence of @xmath is greater than @xmath . The equation @xmath then
has the solutions @xmath and @xmath , hence @xmath if @xmath and @xmath
otherwise. The ratio @xmath is therefore greater than or equal to one,
according to whether @xmath or @xmath , respectively. Recall further
that @xmath denotes the span of @xmath .

Let @xmath be the infinitesimal generating function of @xmath and let
@xmath . We recall the equation ( 3.5 ) from Section 3 : For @xmath ,

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

By the analytic continuation principle, this equation is satisfied on
the domain of analyticity of @xmath , in particular, on @xmath .

We now give a quick overview of the proof. Starting point is the
equation ( 6.1 ). We are going to see that this equation is closely
related to the Briot–Bouquet equation ( 5.1 ) with @xmath . The
representation of the solution to this equation given by Fact 5.4 will
therefore enable us to derive asymptotics for @xmath near its singular
point @xmath (Theorem 6.4 ). Via the results in Section 5.4 , we will be
able to transfer these to the functions @xmath (Corollary 6.6 ).
Finally, the theorems of Flajolet and Odlyzko in Section 5.3 yield the
asymptotics for @xmath and @xmath .

More specifically, we will see that the main singular term in the
expansion of @xmath or @xmath near @xmath is @xmath , if @xmath and
@xmath , if @xmath . At first sight, this dichotomy might seem strange,
but it becomes evident if one remembers that we expect the coefficients
of @xmath (i.e. the probabilities @xmath , assume @xmath ) to behave
like @xmath , if @xmath (see Proposition 2.1 ). In light of Fact 5.6 , a
logarithmic factor must therefore appear if @xmath is a natural number,
otherwise @xmath would be analytic at 1, in which case its coefficients
would decrease at least exponentially.

We start by determining the singular points of @xmath and @xmath on the
boundary of the unit disk, which is the content of the next three
lemmas.

###### Lemma 6.1.

Let @xmath be a random variable with law @xmath and let @xmath . Then
the spans of @xmath and of @xmath are equal to @xmath .

###### Proof.

This follows from the fact that the BBM starts with one individual and
the number of individuals increases by @xmath when an individual gives
birth to @xmath children. ∎

###### Lemma 6.2.

If @xmath , then @xmath and @xmath are analytic at every @xmath . If
@xmath , then there exist a function @xmath and a family of functions
@xmath , all analytic on @xmath , such that

  -- -------- --
     @xmath   
  -- -------- --

for every @xmath . Furthermore, @xmath and @xmath are analytic at every
@xmath .

###### Proof.

Assume first that @xmath . Define

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 6.1 , @xmath for every @xmath and @xmath , whence @xmath and
@xmath for every @xmath .

We now claim that @xmath and @xmath are analytic at every @xmath with
@xmath . Note that if @xmath , this implies that @xmath and @xmath are
analytic at every @xmath , since the function @xmath has an analytic
inverse in a neighbourhood of any @xmath .

First note that by [ 79 ] , Lemma XV.2.3, p. 475, we have @xmath for
every @xmath , such that @xmath , whence @xmath . Now write the
differential equation ( 6.1 ) in the form

  -- -------- --
     @xmath   
  -- -------- --

Since the radius of convergence of @xmath is greater than 1 by
hypothesis, @xmath is analytic at @xmath . Furthermore, @xmath is
continuous at @xmath , since @xmath converges absolutely for every
@xmath . Fact 5.2 now shows that @xmath is analytic at @xmath .

It remains to show that @xmath is analytic at @xmath . Kolmogorov’s
forward and backward equations ( 3.2 ) and ( 3.3 ) imply that @xmath on
@xmath , and the analytic continuation principle implies that this holds
on @xmath . Now, let @xmath , such that @xmath . Then we have just shown
that @xmath is analytic and non-zero at @xmath . Furthermore, @xmath ,
by the above stated lemma in [ 79 ] and Lemma 6.1 . Thus, the function
@xmath is analytic at @xmath , hence we can apply Fact 5.2 again to
conclude that @xmath is analytic at @xmath as well. ∎

The next lemma ensures that we can ignore certain degenerate cases
appearing in the course of the analysis of ( 3.5 ). It is the analytic
interpretation of the probabilistic results in Section 2 .

###### Lemma 6.3.

1 is a singular point of @xmath . If @xmath , then @xmath .

###### Proof.

If @xmath , the second assertion follows from Theorem 1.1 or from
Neveu’s result that @xmath for @xmath (see the remark before Theorem 1.1
). This implies that 1 is a singular point of @xmath . If @xmath ,
Proposition 2.1 implies that @xmath for every @xmath , whence @xmath is
a singular point of the generating function @xmath by Pringsheim’s
theorem ( [ 82 ] , Theorem IV.6, p. 240). By Corollary 5.9 , it follows
that 1 is a singular point of @xmath as well. ∎

The next theorem is the core of the proof of Theorem 1.2 .

###### Theorem 6.4.

Under the assumptions of Theorem 1.2 , for every @xmath there exists
@xmath , such that @xmath possesses an analytical extension (denoted by
@xmath as well) to @xmath . Moreover, as @xmath in @xmath , the
following holds.

-    [label= @xmath ]

-    If @xmath , then

      -- -------- -- -------
         @xmath      (6.2)
      -- -------- -- -------

-    If @xmath , then there is a @xmath and a polynomial @xmath , such
    that

      -- -------- -- -------
         @xmath      (6.3)
         @xmath      (6.4)
      -- -------- -- -------

###### Proof of Theorem 6.4.

We set @xmath . By ( 6.1 ),

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

Since @xmath is analytic at 1 by hypothesis, there exists @xmath and a
function @xmath analytic on @xmath with @xmath , such that @xmath for
@xmath .

As a first step, we analyse ( 6.5 ) for real non-negative @xmath . Since
@xmath , @xmath on @xmath , whence we can divide both sides by @xmath to
obtain

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

Introduce the parameter @xmath , @xmath , such that @xmath , @xmath and
@xmath is strictly decreasing on @xmath . There exists then an inverse
@xmath on @xmath , which satisfies @xmath . Hence, we have

  -- -------- --
     @xmath   
  -- -------- --

In matrix form, this becomes

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

for @xmath . Note that this extends ( 4.2 ) to the subcritical case.
This time, the Jordan decomposition of @xmath is given by

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

and by ( 4.3 ), if @xmath . Setting

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

transforms ( 6.7 ) into

  -- -------- -------- -------- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (6.10)
     @xmath   @xmath   @xmath   @xmath   @xmath   @xmath      (6.11)
  -- -------- -------- -------- -------- -------- -------- -- --------

for @xmath . Furthermore, by ( 6.9 ), we have

  -- -------- -------- -- --------
     @xmath   @xmath      (6.12)
     @xmath   @xmath      (6.13)
     @xmath   @xmath      (6.14)
  -- -------- -------- -- --------

From now on, let @xmath be positive numbers that are as small as
necessary. By the strict convexity of @xmath and the fact that @xmath by
Lemma 2.4 , equation ( 6.13 ) implies that @xmath is a strictly convex
non-negative function of @xmath on @xmath . This implies that the
inverse @xmath exists and is non-negative and strictly concave on @xmath
. It follows that @xmath exists on @xmath . Equations ( 6.10 ) and (
6.11 ) then yield for @xmath ,

  -- -------- -------- -- -------- -- --------
     @xmath   @xmath      @xmath      (6.15)
     @xmath   @xmath      @xmath      (6.16)
  -- -------- -------- -- -------- -- --------

By ( 6.12 ) and the fact that @xmath is strictly concave, @xmath is a
strictly concave function of @xmath as well, hence strictly monotone on
@xmath . We claim that @xmath as @xmath . For @xmath , one checks by (
6.13 ) that @xmath , as @xmath , whence @xmath , as @xmath , by ( 6.12
). If @xmath , then @xmath by Lemma 2.4 and @xmath by Lemma 6.3 .
Equation ( 6.13 ) then implies that @xmath as @xmath , whence @xmath .
The claim now follows by ( 6.12 ).

Proposition 7.4 now tells us that there exists a function @xmath , such
that the function @xmath has an inverse @xmath on @xmath and @xmath
satisfies the Briot–Bouquet equation

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

on @xmath . By Fact 5.4 and Remark 5.5 , there exists then a function
@xmath , @xmath , such that @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

for some constant @xmath (the form of @xmath in the case @xmath can be
obtained from the one in Fact 5.4 by changing @xmath , @xmath and @xmath
). Moreover, comparing the coefficient of @xmath on both sides of ( 6.17
), we get, if @xmath , @xmath , whence @xmath and if @xmath : @xmath ,
whence @xmath .

Assume now @xmath . Then @xmath . Recall that @xmath and @xmath . By (
6.12 ),

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath and @xmath , as @xmath , where @xmath , if @xmath and
@xmath , if @xmath . By Lemmas 7.6 and 7.8 , for every @xmath there
exists @xmath , such that the inverse @xmath exists and is analytic on
@xmath and satisfies

  -- -------- --
     @xmath   
  -- -------- --

This entails that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

It follows that

  -- -------- --
     @xmath   
  -- -------- --

We finally get by ( 6.9 ),

  -- -------- --
     @xmath   
  -- -------- --

which proves ( 6.3 ) and ( 6.4 ).

If @xmath , recall that @xmath and @xmath for some @xmath . By ( 6.12 ),

  -- -- --
        
  -- -- --

such that @xmath and @xmath . Lemma 7.6 now implies that for every
@xmath there exists @xmath , such that the inverse @xmath exists and is
analytic on @xmath . Now, by ( 6.9 ),

  -- -------- --
     @xmath   
  -- -------- --

Lemma 7.9 now yields ( 6.2 ). ∎

###### Remark 6.5.

The reason why we cannot explicitly determine the constant @xmath in
Theorem 6.4 is that we are analysing ( 3.5 ) only locally around the
point 1. Since the solution of ( 3.5 ) with boundary conditions @xmath
is unique (this follows from the uniqueness of the travelling wave
solutions to the FKPP equation), a global analysis of this equation
should be able to exhibit the value of @xmath . But it is probably
easier to refine the probabilistic arguments of Section 2 , which
already give a lower bound that can be easily made explicit.

The asymptotics established in Theorem 6.4 for the infinitesimal
generating function can now be readily transferred to the generating
functions @xmath .

###### Corollary 6.6.

Under the assumptions of Theorem 1.2 , for every @xmath and @xmath there
exists @xmath , such that @xmath can be analytically extended to @xmath
. Furthermore, the following holds as @xmath in @xmath .

-    [label= @xmath ]

-    If @xmath , then

      -- -------- -- --------
         @xmath      (6.18)
      -- -------- -- --------

-    If @xmath , then there is a polynomial @xmath , such that

      -- -------- -- --------
         @xmath      (6.19)
         @xmath      (6.20)
      -- -------- -- --------

    where @xmath , with @xmath being the constant from Theorem 6.4 .

###### Proof.

Let @xmath . By Theorem 6.4 , there exists @xmath , such that @xmath can
be analytically extended to @xmath and satisfies the hypothesis of
Corollary 5.10 . It follows that there exists @xmath , such that @xmath
can be analytically extended to @xmath and maps @xmath into @xmath .
Hence, the functions

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is defined as in ( 5.4 ), are analytic in @xmath . In what
follows, we always assume that @xmath . Appearance of the symbols @xmath
means that we let @xmath go to @xmath in @xmath .

First of all, we note that by Proposition 5.8 , we have

  -- -------- -- --------
     @xmath      (6.21)
  -- -------- -- --------

Now assume @xmath . By Theorem 6.4 , @xmath , where @xmath or @xmath ,
according to whether @xmath or @xmath , respectively. It follows that

  -- -------- --
     @xmath   
  -- -------- --

Now, @xmath , since @xmath by Lemma 2.4 . Thus,

  -- -------- -- --------
     @xmath      (6.22)
  -- -------- -- --------

Since @xmath equations ( 6.21 ) and ( 6.22 ) now give

  -- -------- -- --------
     @xmath      (6.23)
  -- -------- -- --------

If @xmath , we deduce that @xmath . Straightforward calculus now shows
that

  -- -------- -- --------
     @xmath      (6.24)
  -- -------- -- --------

and ( 6.23 ) and ( 6.24 ) now yield

  -- -------- --
     @xmath   
  -- -------- --

Repeated application of this equation shows that @xmath , which yields (
6.19 ) and ( 6.20 ).

In the critical case @xmath , Theorem 6.4 tells us that

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

Write @xmath . For our first approximation of @xmath , we note that

  -- -------- --
     @xmath   
  -- -------- --

hence, by ( 6.21 ),

  -- -------- -- --------
     @xmath      (6.26)
  -- -------- -- --------

To obtain a finer approximation, we decompose @xmath into

  -- -------- --
     @xmath   
  -- -------- --

We then have

  -- -------- --
     @xmath   
  -- -------- --

and, because of ( 6.26 ),

  -- -------- --
     @xmath   
  -- -------- --

Plugging this back into ( 6.21 ) finishes the proof. ∎

###### Proof of Theorem 1.2.

Let @xmath . We want to apply the methods from singularity analysis
reviewed in Section 5.3 to the functions @xmath and @xmath , if @xmath ,
or the functions @xmath and @xmath from Lemma 6.2 , if @xmath . Let
@xmath . By Theorem 6.4 and Corollary 6.6 , there exists @xmath , such
that @xmath and @xmath can be analytically extended to @xmath , which
implies that for some @xmath and @xmath , @xmath and @xmath can be
extended to @xmath , as well. Moreover, by Lemma 6.2 , each of these
functions is analytic in a neighbourhood of every point of @xmath ,
which is a compact set. Hence, there exists a finite number of
neighbourhoods which cover @xmath . It is then easy to show that there
exists @xmath , such that the functions are analytic in @xmath .

If @xmath , we can then immediately apply Facts 5.6 and 5.7 , together
with the asymptotics on @xmath and @xmath established in Theorem 6.4 and
Corollary 6.6 , to prove Theorem 1.2 .

If @xmath , let @xmath be the inverse of @xmath in a neighbourhood of 1,
then @xmath near 1, by Lemma 6.2 . But since @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

for some constants @xmath , and so equations ( 6.2 ), ( 6.3 ) and ( 6.4
) transfer to @xmath with the coefficient of the main singular term
divided by @xmath . We can therefore use Facts 5.6 and 5.7 for the
function @xmath to obtain the asymptotic for @xmath in Theorem 1.2 . In
the same way, equations ( 6.18 ), ( 6.19 ) and ( 6.20 ) yield
asymptotics for @xmath , such that we can use again Facts 5.6 and 5.7 to
prove the second part of Theorem 1.2 . ∎

### 7 Appendix

#### 7.1 A renewal argument for branching diffusions

Let @xmath be a diffusion on an interval with endpoints @xmath , such
that @xmath for every @xmath , where @xmath and @xmath , @xmath -almost
surely. For @xmath , and only in the scope of this section, we define
@xmath to be the law of the branching diffusion starting with a single
particle at position @xmath where the particles move according to the
diffusion @xmath and branch with rate @xmath according to the
reproduction law with generating function @xmath . Moreover, particles
hitting the point @xmath are absorbed at that point. Denote by @xmath
the number of particles absorbed during the lifetime of the process and
define @xmath for @xmath and @xmath .

###### Lemma 7.1.

Let @xmath and @xmath be the generator of the diffusion @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The proof proceeds by a renewal argument similar to the one in [ 118 ] .
As for the BBM, for an individual @xmath , we denote by @xmath its time
of death, @xmath its position at time @xmath and @xmath the number of
@xmath ’s children. Define the event @xmath . For @xmath we have by the
strong branching property

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a diffusion with generator @xmath starting at @xmath
under @xmath , @xmath and the random variable @xmath is exponentially
distributed with rate @xmath and independent from @xmath . Setting
@xmath we get by integration by parts

  -- -------- --
     @xmath   
  -- -------- --

and therefore @xmath on @xmath ( [ 41 ] , Paragraph II.1.10, p. 18).

Denote the @xmath -resolvent of the diffusion by @xmath . By the strong
Markov property,

  -- -------- --
     @xmath   
  -- -------- --

hence @xmath , with @xmath . It follows that

  -- -------- --
     @xmath   
  -- -------- --

By the above hypothesis on @xmath , @xmath as @xmath , whence @xmath . ∎

#### 7.2 Addendum to the proof of Theorem 1.1

With the notation used in the proof of Theorem 1.1 , recall that for
some constant @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

In what follows, formulae containing the symbols @xmath and @xmath are
meant to hold as @xmath . The above equation yields

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

Now, by ( 3.5 ), we have

  -- -------- --
     @xmath   
  -- -------- --

where we recall that @xmath was defined as @xmath . From the above
equation, one gets

  -- -------- --
     @xmath   
  -- -------- --

By definition, @xmath and @xmath . The previous equation together with (
7.1 ) then yields ( 4.7 ).

Kolmogorov’s forward and backward equations ( 3.2 ) and ( 3.3 ) give

  -- -------- --
     @xmath   
  -- -------- --

and taking the derivative on both sides of this equation gives

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

By ( 4.7 ) and @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

This equation, together with ( 7.2 ) now yields

  -- -------- --
     @xmath   
  -- -------- --

which is ( 4.8 ).

#### 7.3 Reduction to Briot–Bouquet equations

In this section, we show how one can reduce differential equations as
those obtained in the proof of Theorem 1.2 to the canonical form ( 5.1
). It is mostly based on pp. 64 and 65 of [ 28 ] .

###### Lemma 7.2.

Let @xmath and @xmath . Then the equation

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

has an analytic solution @xmath in a neighbourhood of the origin.

###### Proof.

We choose the ansatz @xmath . This transforms ( 7.3 ) into

  -- -------- --
     @xmath   
  -- -------- --

Writing the inverse of the denominator as a power series in @xmath and
@xmath , this equals

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath . This finally yields

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is not a positive integer, this equation now has an
analytic solution @xmath by Fact 5.3 , whence @xmath solves ( 7.3 ). ∎

###### Remark 7.3.

The important point in Lemma 7.2 is that the coefficient of @xmath in
the numerator of ( 7.3 ) is 0, which is why @xmath .

###### Proposition 7.4.

Let @xmath and @xmath . Suppose @xmath is a strictly monotone
real-valued function on @xmath , @xmath , with @xmath as @xmath and
satisfying

  -- -------- -- -------
     @xmath      (7.4)
  -- -------- -- -------

Then there exists @xmath and @xmath , such that @xmath has an inverse
@xmath on @xmath and such that

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

###### Proof.

By hypothesis, @xmath is monotone on @xmath and therefore possesses an
inverse @xmath on @xmath , @xmath , which satisfies

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

By Lemma 7.2 , there exists then an analytic solution @xmath to ( 7.6 ),
since @xmath by hypothesis. Setting @xmath transforms ( 7.6 ) into a
differential equation, which has @xmath as a solution, hence it is of
the form

  -- -------- --
     @xmath   
  -- -------- --

We have @xmath . By ( 7.4 ),

  -- -------- --
     @xmath   
  -- -------- --

by hypothesis. Hence, there exists @xmath , such that @xmath is strictly
increasing on @xmath and therefore has an inverse. Thus, @xmath
satisfies

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath . Expanding @xmath as a power series at @xmath gives (
7.5 ). ∎

#### 7.4 Inversion of some analytic functions

The results in this section are needed in the proofs of Corollary 5.10
and Theorem 1.2 .

###### Lemma 7.5.

Let @xmath , @xmath and @xmath be an analytic function on @xmath with
@xmath as @xmath . Then there exists @xmath , such that for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath . Write @xmath , with @xmath , @xmath , @xmath . Define the
paths

  -- -------- --
     @xmath   
  -- -------- --

such that their concatenation forms a path from @xmath to @xmath in
@xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

As a consequence,

  -- -------- --
     @xmath   
  -- -------- --

This proves the statement. ∎

###### Lemma 7.6.

Let @xmath and @xmath . Let @xmath and @xmath be analytic functions on
@xmath with @xmath , @xmath , @xmath and @xmath as @xmath in @xmath .
Then for each @xmath and @xmath there exist @xmath , such that @xmath
and @xmath are injective on @xmath and the images of @xmath by @xmath
and @xmath contain @xmath .

###### Proof.

By hypothesis, @xmath as @xmath in @xmath , whence @xmath . Thus, there
exists @xmath , such that @xmath .

Suppose that there exist @xmath , such that @xmath . Let @xmath be a
path from @xmath to @xmath in @xmath . Then @xmath is a loop in @xmath ,
whence

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 7.5 , we can choose @xmath so small, that this equality cannot
hold, whence @xmath is injective on @xmath .

Since @xmath and @xmath as @xmath , there exists @xmath , such that
@xmath encloses @xmath . Now, since @xmath is injective on @xmath ,
@xmath and @xmath are conformally equivalent, whence @xmath is simply
connected. It follows that @xmath .

Exactly the same arguments hold for @xmath , since @xmath by hypothesis,
whence @xmath and @xmath as @xmath . ∎

###### Lemma 7.7.

Let @xmath , @xmath and @xmath . Let @xmath be an analytic function on
@xmath with

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath and @xmath . Then for each @xmath there exist @xmath ,
such that @xmath is injective on @xmath and @xmath for every @xmath .

###### Proof.

By the hypothesis on @xmath , we have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

By Lemma 7.5 , there exists therefore @xmath , such that @xmath is
injective on @xmath .

Since @xmath is integrable near 0, we have

  -- -------- --
     @xmath   
  -- -------- --

where we assume without loss of generalisation that the constant of
integration is 0. It follows that @xmath and @xmath as @xmath , since
@xmath . Hence, there exists an @xmath , such that @xmath encloses the
strip @xmath . As in the proof of Lemma 7.6 , it follows that @xmath .
Furthermore, again by the asymptotics of @xmath and @xmath , there
exists @xmath , such that @xmath for every @xmath . This concludes the
proof. ∎

###### Lemma 7.8.

Let @xmath be an analytic function on an open subset of @xmath , such
that @xmath as @xmath and

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath , @xmath and @xmath . Then there exist @xmath , such
that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For every @xmath , we have by hypothesis

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath . For @xmath , define recursively (with @xmath )

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath The statement now follows from the fact that @xmath as
@xmath by hypothesis, whence @xmath . ∎

###### Lemma 7.9.

Let @xmath be an analytic function on an open subset of @xmath , such
that @xmath as @xmath and

  -- -------- --
     @xmath   
  -- -------- --

for some constants @xmath , @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Set @xmath . By hypothesis, @xmath , whence @xmath . Now define @xmath
by

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath By hypothesis,

  -- -------- --
     @xmath   
  -- -------- --

whence @xmath , which implies @xmath . It now follows from the
hypothesis that

  -- -------- --
     @xmath   
  -- -------- --

whence

  -- -- --
        
  -- -- --

The statement now follows from the series representation of @xmath at
@xmath . ∎

### Acknowledgements

The author is grateful to Elie Aïdékon for stimulating discussions, to
Louis Boutet de Monvel for several useful comments, to Jean Bertoin for
useful comments on the proof of Lemma 7.1 and to Andreas Kyprianou and
Yanxia Ren for having brought to my attention the reference [ 143 ] .
Furthermore, the author thanks two anonymous referees for their detailed
comments, which led to a considerable improvement in the exposition of
the paper.

## Chapter 2 Branching Brownian motion with selection of the @xmath
right-most particles

### 1 Introduction

In this chapter, we consider the @xmath -BBM, whose definition we
recall: Given a reproduction law @xmath with @xmath and finite second
moment, particles diffuse according to standard Brownian motion and
branch at rate @xmath into @xmath particles with probability @xmath .
Furthermore, we fix a (large) parameter @xmath and as soon as the number
of particles exceeds @xmath , we keep the @xmath right-most particles
and instantaneously kill the others.

For a finite counting measure @xmath on @xmath , define for @xmath and
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, set

  -- -------- --
     @xmath   
  -- -------- --

For @xmath large enough, we then define @xmath and

  -- -------- --
     @xmath   
  -- -------- --

and set

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the counting measure formed by the positions of the
particles of @xmath -BBM at time @xmath . Our main theorem is then the
following:

###### Theorem 1.1.

Suppose that at time @xmath there are @xmath particles distributed
independently according to the density proportional to @xmath . Then for
every @xmath , the finite-dimensional distributions of the process

  -- -------- --
     @xmath   
  -- -------- --

converge weakly as @xmath to those of the Lévy process @xmath with
@xmath and

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

Here, @xmath is the image of the measure @xmath by the map @xmath and
@xmath is a constant depending on the reproduction law @xmath .

For a motivation of why this process is interesting, we refer to the
introductory chapter. In the next subsection, we present a detailed
sketch of the ideas in the proof of Theorem 1.1 .

#### 1.1 Heuristic ideas and overview of the results

In the introductory chapter of this thesis, we have outlined the
semi-deterministic description of the @xmath -BBM from [ 56 ] : Most of
the time the system is in a meta-stable state, where the particles are
approximately distributed according to the density proportional to
@xmath . From time to time (with a rate of order @xmath ), a particle
goes far to the right and reaches a point near @xmath defined above.
This particle then spawns a large number of descendants (of the order of
@xmath ), which leads to a shift of the front. Our proof of Theorem 1.1
is inspired by this description and by the article by Berestycki,
Berestycki and Schweinsberg [ 23 ] , who made some of these ideas
rigorous. We briefly recall their results and arguments.

They consider BBM with absorption at the origin and with drift @xmath .
Their starting point is to introduce a second barrier at the point
@xmath for some large positive constant @xmath and divide the particles
at time @xmath into two parts; on the one hand those that have stayed
inside the interval @xmath , on the other hand those that have hit the
point @xmath before hitting @xmath . This corresponds roughly to the
division of the process into a deterministic and a stochastic part.
Indeed, killing the particles at @xmath prevents the number of particles
from growing fast and thus permits to calculate expectations and
variances of various quantities. For example, if at time @xmath we have
@xmath particles distributed according to the meta-stable density, then
the variance of the number of particles at the time @xmath is of order
of @xmath . For large @xmath , the particles inside the interval @xmath
therefore behave almost deterministically at the timescale @xmath .
Moreover, the leading term in the Fourier expansion of the transition
density of Brownian motion (with drift @xmath and killed at the border
of the interval @xmath ) is proportional to @xmath , which explains the
meta-stable density predicted by the physicists.

As for the particles that hit @xmath , the authors of [ 23 ] find that
1) the number of descendants at a later time of such a particle is of
the order of @xmath , where @xmath is a random variable with tail @xmath
, as @xmath and 2) the rate at which particles hit the right barrier is
of the order of @xmath . Putting the pieces together, they then show
that the process which counts the number of particles of the system
converges in the @xmath timescale to Neveu’s continuous-state branching
process ¹ ¹ 1 A continuous-state branching process (CSBP) @xmath is a
time-changed Lévy process without negative jumps: at time @xmath , time
is sped up by the factor @xmath . CSBPs are scaling limits of
Galton–Watson processes and thus have an inherent notion of genealogy.
Neveu’s CSBP is the CSBP with Lévy measure @xmath , whose genealogy is
given by the Bolthausen–Sznitman coalescent [ 27 ] . As a wise reader,
you have read the introductory chapter, such that you know what this
coalescent is. and its genealogy to the Bolthausen–Sznitman coalescent.

Our proof of Theorem 1.1 builds upon the ideas of [ 23 ] presented
above. The basic idea is to approximate the @xmath -BBM by a BBM with
absorption at a random barrier, which is chosen in such a way that it
keeps the number of particles almost constant . We call the resulting
system the “B-BBM” (B stands for “barrier”). The B-BBM takes two (large)
parameters @xmath and @xmath , which have similar purposes than @xmath
and @xmath above. We then set @xmath and start with BBM with drift
@xmath and an absorbing barrier at the origin. Now, at the beginning,
this barrier stays at the origin and does not move. When and only when a
particle hits @xmath and spawns a lot of descendants do we increase the
drift to the left. This increase is in order to kill particles and thus
make the population size stay almost constant. Note that moving the
barrier to the right is an equivalent operation, but increasing the
drift is technically more convenient. After the system has relaxed
(which takes a time of order @xmath ) the drift is set to @xmath again
and the process is repeated.

As in [ 23 ] , an important quantity is

  -- -------- --
     @xmath   
  -- -------- --

Here, we sum over all the particles @xmath alive at time @xmath and
@xmath denotes the position of the particle @xmath at time @xmath . The
process @xmath is important because it is a martingale for BBM with
absorption at @xmath and @xmath and drift @xmath . Furthermore, it gives
the approximate number of particles at a time @xmath . More precisely,
set @xmath and suppose we kill particles at @xmath and @xmath . The
expected number of particles at a time @xmath , with @xmath , is then
approximately @xmath . Moreover, the variance is of the order of @xmath
. Therefore, if @xmath then the number of particles is concentrated
around its expectation for large @xmath .

When a particle hits the right barrier at the time @xmath , say, we
absorb its descendants at the space-time line @xmath , where @xmath is a
large constant depending on @xmath only (this idea comes from [ 23 ] ).
In doing so, the number of particles absorbed at the barrier has the
same law as in BBM with drift @xmath and absorption at @xmath , starting
from a single particle at the origin. Moreover, the time it takes for
all the particles to be absorbed depends only on @xmath , not on @xmath
. Now, if @xmath are the positions of the absorbed particles and @xmath
, then the number of descendants of this particle at a later time is of
the order of @xmath , provided that the drift stays constant.
Consequently, we say that a breakout occurs, whenever @xmath , where
@xmath will be chosen such that @xmath .

In order to define a breakout properly, we classify the particles into
tiers . Particles that have never hit the point @xmath form the
particles of tier 0. As soon as a particle hits @xmath (at the time
@xmath , say) it advances to tier 1. Its descendants then belong to tier
1 as well, but whenever a descendant hits @xmath and has an ancestor
which has hit the line @xmath after @xmath , it advances to tier 2 and
so on. Whenever a particle advances to the next tier, it has a chance to
break out. We can then define the time @xmath of the first breakout and
will indeed show that @xmath is approximately exponentially distributed
with rate proportional to @xmath . Interestingly, we will see that with
high probability breakouts only occur from particles which are of tier
@xmath or @xmath . In fact, the number of breakouts occuring from
particles of tier @xmath between the times @xmath and @xmath is
approximately proportional to @xmath (and the remaining @xmath breakouts
occur from particles of tier @xmath ).

After the breakout, we will then increase the drift to the left
slightly, in order to kill more particles than usual (remember that
increasing the drift to the left corresponds to moving the barrier to
the right). For this, we first choose a family of increasing smooth
functions @xmath with @xmath and @xmath for all @xmath . Such a function
will be called a barrier function . The drift after a breakout is then
set to @xmath , where @xmath is the total amount by which we have to
move the barrier. Thus, the only randomness in the choice of the barrier
is in its total shift, not in its shape. Looking at the definition of
@xmath and the fact that @xmath , one easily guesses that we have to
choose @xmath in order to get @xmath ultimately back to its initial
value. This already explains the convergence of the barrier to the Lévy
process given by ( 1.1 ): On the one hand, we have @xmath , where @xmath
is the random variable mentioned above. This implies that the law of
@xmath conditioned on @xmath is approximately @xmath for large @xmath
and @xmath . ² ² 2 The statement “for large @xmath and @xmath ” means
that we let first @xmath , then @xmath go to infinity, see Section 6.1 .
On the other hand, we will show that breakouts occur at a rate
proportional to @xmath . Together with the definition of @xmath , this
explains the Lévy measure @xmath in ( 1.1 ). One easily checks that the
cumulants of this Lévy process coincide with ( 2 ).

As for the shape of the barrier, it is determined by the fact that we
want the number of particles at each time to be approximately @xmath .
By first-moment estimates, it will become clear in Section 5.3 that the
correct barrier function to choose is

  -- -------- --
     @xmath   
  -- -------- --

where the theta function @xmath is defined in ( 2.1 ).

We remark that in order to study the B-BBM up to the time @xmath of the
first breakout, we need to study it conditioned to break out at time
@xmath for every @xmath . We will see in Section 6.4 that this will lead
to a decomposition of the particles into 1) a fugitive , which is
conditioned to break out at @xmath and which will effectively be a spine
, and 2) the other particles conditioned not to break out before @xmath
. This is essentially a Doob transform of the process, which we will
introduce in Section 3.4 . Furthermore, we will see that the tier @xmath
particles will have an essential role: At the timescale @xmath they will
lead to an additional shift of the barrier by an amount of the order of
@xmath . This term will play the role of the linear compensation that is
necessary in order to obtain in the limit the Lévy process of infinite
variation stated in Theorem 1.1 .

We now describe how we use the results on the B-BBM in order to prove
Theorem 1.1 . Initially, our plan was to couple the @xmath -BBM and the
B-BBM, i.e. construct them on the same probability space. We would then
assign a colour to each particle: blue to the particles which appear in
the @xmath -BBM but not in the B-BBM, red to those that appear in the
B-BBM but not in the @xmath -BBM, and white to the particles that appear
in both processes. Our aim was then to show that the number of blue and
red particles was negligible after a time of order @xmath . This,
unfortunately, did not work out, because we were not able to handle the
intricate dependence between the red and blue particles.

Instead, we couple the @xmath -BBM with two different processes, the B
@xmath - and the B @xmath -BBM, which are variants of the B-BBM and
which bound the position of the @xmath -BBM in a certain sense from
below and above, respectively. The B @xmath -BBM is defined as follows:
Initially, all particles are coloured white and evolve as in the B-BBM.
A white particle is coloured red as soon as it has @xmath or more white
particles to its right. Children inherit the colour of their parent.
After a breakout and the subsequent relaxation, all the red particles
are killed immediately and the process restarts with the remaining
particles. It is intuitive that the collection of white particles then
bounds the @xmath -BBM from below (in some sense) because we kill “more”
particles than in the @xmath -BBM. Indeed, in Section 10.1 , we show by
a coupling method that the empirical measure of the white particles in B
@xmath -BBM is stochastically dominated by the one of the @xmath -BBM
with respect to the usual stochastic ordering of measures. It then
remains to show that the number of red particles in B @xmath -BBM is
negligible when @xmath and @xmath are large. We do this through precise
estimates on the number of particles in the interval @xmath for every
@xmath . These allow us to estimate the expected number of particles
which turn red at the point @xmath . It turns out that this expectation
is small enough, which permits to conclude.

The definition of the B @xmath -BBM, which is used to bound the @xmath
-BBM from above, is more intricate than the one of B @xmath -BBM. Again,
we colour all initial particles white and particles evolve as in B-BBM
with the following change: Whenever a white particle hits @xmath and has
less than @xmath particles to its right, instead of killing it
immediately, we colour it blue and let it survive for a time of order
@xmath . More precisely, we cut time into intervals @xmath , with @xmath
for some large constant @xmath . A particle which gets coloured blue
during @xmath then survives until the time @xmath . At this time, all of
its descendants to the left of the origin are killed and the others
survive. It will turn out that this system bounds the @xmath -BBM from
above with high probability and that the number of blue particles will
remain negligible during a time of order @xmath , as long as @xmath and
@xmath are large.

We note that although our technique of bounding the @xmath -BBM from
below and from above works well for the position of the particles, it
does not give us information about the genealogy; the reason being that
the coupling deforms the genealogical tree of the process. Thus,
although it should not be difficult to show that the genealogy of the
B-BBM (and of the B @xmath - and B @xmath -BBM) converges to the
Bolthausen–Sznitman coalescent we do not know at present how one could
transfer this information to the @xmath -BBM.

#### 1.2 Notation guide

This chapter is quite long and therefore also uses a lot of different
notation. Below is a list of recurrent symbols, roughly in the order of
their first appearance. Following this list are some further remarks
about notational conventions.

From Section 5 on, the symbol @xmath stands for a positive constant,
which may only depend on the reproduction law @xmath and the value of
which may change from line to line. Furthermore, if @xmath is any
mathematical expression, then the symbol @xmath stands for a possibly
random term whose absolute value is bounded by @xmath .

In Section 6 , we introduce two parameters @xmath and @xmath and will
first let @xmath then @xmath go to infinity. This will be expressed by
the statements “for large @xmath and @xmath we have…” or “as @xmath and
@xmath go to infinity…” (see Section 6.1 for a precise definition).
These phrases will become so common that in Sections 7 to 9 they will
often be used implicitly, although they will always be explicitly stated
in the theorems, propositions, lemmas etc. Section 6 furthermore
introduces the notation @xmath , which stands for a (non-random) term
that only depends on the reproduction law @xmath and the parameters
@xmath , @xmath , @xmath , @xmath , @xmath and @xmath and which goes to
@xmath as @xmath and @xmath go to infinity.

Sections 8 and 9 each use special notation which only appears in those
sections. This notation is defined at the beginning of both sections.
Moreover, in both sections, we sometimes denote quantities which refer
to descendants of the fugitive after a breakout by the superscript
“fug”.

### 2 Brownian motion in an interval

In this section, we recall some explicit formulae concerning real-valued
Brownian motion killed upon exiting an interval. These formulae
naturally involve Jacobi theta functions, since these are fundamental
solutions of the heat equation with periodic boundary conditions. We
will therefore first review their definition and some of their
properties.

#### 2.1 A function of Jacobi theta-type

We define for @xmath and @xmath the following function of Jacobi
theta-type:

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

The definition ( 2.1 ) is a representation of @xmath as a Fourier
series, which is particularly well suited for large @xmath , but which
does not reveal its behaviour as @xmath . This is where the following
representation comes in, which is related to ( 2.1 ) by the Poisson
summation formula (see [ 17 ] , §9):

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

One recognises immediately that for real @xmath and @xmath , @xmath is
the probability density at time @xmath of Brownian motion on the circle
@xmath started at @xmath . In other words, @xmath is the unique solution
to the PDE

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

where @xmath denotes the Dirac delta-function. This is the heat equation
with periodic boundary condition and the Dirac comb as initial
condition. Note that (PDE) and (BC) also follow directly from ( 2.1 ).

We define

  -- -------- --
     @xmath   
  -- -------- --

which is a smooth function on @xmath . By ( 2.1 ) and ( 2.2 ), one can
show that @xmath is stricly increasing ³ ³ 3 More precisely, by
elementary computations, ( 2.1 ) gives @xmath , such that @xmath is
strictly increasing on @xmath and ( 2.2 ) gives @xmath , such that
@xmath is strictly increasing on @xmath . with @xmath and @xmath .

#### 2.2 Brownian motion killed upon exiting an interval

Various quantities of Brownian motion killed upon exiting an interval
can be expressed by theta functions. For @xmath , let @xmath be the law
of Brownian motion started at @xmath , let @xmath be the canonical
process and let @xmath . For @xmath and @xmath , denote by @xmath the
law of Brownian motion started at @xmath and killed upon leaving the
interval @xmath . Let @xmath be its transition density, i.e.

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

Then @xmath is the fundamental solution to the heat equation (PDE) with
boundary condition

  -- -------- --
     @xmath   
  -- -------- --

Hence (see also [ 96 ] , Problem 1.7.8 or [ 41 ] , formula 1.1.15.8),

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

Equation ( 2.1 ) then yields

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

This representation is particularly useful for large @xmath : Define

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

By ( 2.6 ) and the inequality @xmath , @xmath , one sees that

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

Note that the Green function (see e.g. [ 100 ] , Lemma 20.10, p379) is
given by

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

Set @xmath and define

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

Then (see [ 41 ] , formula 1.3.0.6),

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

where @xmath denotes the derivative of @xmath with respect to @xmath .

The following two integrals are going to appear several times throughout
the article, which is why we give some useful estimates here. For a
measurable subset @xmath , define

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

which satisfy the scaling relations

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

with @xmath and @xmath . The following lemma provides estimates on
@xmath and @xmath .

###### Lemma 2.1.

There exists a universal constant @xmath , such that for every @xmath
and every measurable @xmath , we have

  -- -- --
        
  -- -- --

where @xmath denotes the Lebesgue measure of @xmath and @xmath is
defined in ( 2.7 ).

###### Proof.

First note that @xmath is a positive measure on @xmath for every @xmath
, such that we have by ( 2.12 ),

  -- -------- --
     @xmath   
  -- -------- --

since the scale function of Brownian motion is @xmath . Furthermore,
decomposing @xmath into

  -- -------- --
     @xmath   
  -- -------- --

it is enough to prove that @xmath for all @xmath with @xmath . Now, by (
2.11 ) and ( 2.1 ),

  -- -------- --
     @xmath   
  -- -------- --

where the exchange of integral and sum is justified by the uniform
convergence of the sum for @xmath . We now have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

as well as

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, we have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

It follows that

  -- -------- --
     @xmath   
  -- -------- --

This proves the statement about @xmath . The proof of the statement
about @xmath is similar, drawing on ( 2.6 ) instead and on the following
estimate:

  -- -------- --
     @xmath   
  -- -------- --

by ( 2.9 ). ∎

#### 2.3 The Brownian taboo process

The Markov process on @xmath with infinitesimal generator

  -- -------- --
     @xmath   
  -- -------- --

is called the Brownian taboo process on @xmath . It is a diffusion with
scale function @xmath and speed measure @xmath , where

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

The singular points @xmath and @xmath are therefore entrance-not-exit.
For @xmath we denote the law of the Brownian taboo process on @xmath
started from @xmath by @xmath . Often we will drop the @xmath if its
value is clear from the context.

The name of this process was coined by F. Knight [ 104 ] who showed that
it can be interpreted as Brownian motion conditioned to stay inside the
interval @xmath (hence, @xmath and @xmath are taboo states ). The
Brownian taboo process is also known as the three-dimensional Legendre
process , because of its relation to Brownian motion on the 3-sphere
(see [ 96 ] , p270). The 3-dimensional Bessel process is obtained by
taking the limit in law as @xmath . Note that the normalisation of the
scale function and speed measure in ( 2.15 ) was chosen in such a way
that they converge, respectively, to the scale function and speed
measure of the 3-dimensional Bessel process, as @xmath .

Below we list some useful properties of the Brownian taboo process:

1.  [nolistsep]

2.  It satisfies the following scaling relation : If @xmath is a
    Brownian taboo process on @xmath , then @xmath is a Brownian taboo
    process on @xmath .

3.  It is the Doob transform of Brownian motion killed at @xmath and
    @xmath , with respect to the space-time harmonic function @xmath .
    In other words, for @xmath , @xmath is obtained from @xmath by a
    Cameron–Martin–Girsanov change of measure with the martingale

      -- -------- --
         @xmath   
      -- -------- --

4.  As a consequence, its transition probabilities are given by

      -- -------- -- --------
         @xmath      (2.16)
      -- -------- -- --------

    Equation ( 2.8 ) now implies that

      -- -------- -- --------
         @xmath      (2.17)
      -- -------- -- --------

5.  As can be seen from above or directly, it admits the stationary
    probability measure

      -- -------- --
         @xmath   
      -- -------- --

6.  If @xmath denotes the taboo bridge from @xmath to @xmath of length
    @xmath , then @xmath by the second property.

7.  As a consequence, the taboo process is self-dual in the sense that
    for a measurable functional @xmath and @xmath , we have

      -- -------- --
         @xmath   
      -- -------- --

The following lemma will be needed in Sections 6 and 7 .

###### Lemma 2.2.

Let @xmath and define @xmath . There exists a constant @xmath ,
depending only on @xmath , such that we have for every @xmath ,

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

and for @xmath ,

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

with @xmath . If @xmath , we still have,

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

Note: one could probably show by induction that the law of the integral
is dominated by an exponential law, by showing that its moments are
bounded by @xmath .

###### Proof.

We first show that ( 2.18 ) implies ( 2.19 ). By the self-duality of the
taboo process, we have

  -- -------- --
     @xmath   
  -- -------- --

It therefore remains to prove that

  -- -------- --
     @xmath   
  -- -------- --

Conditioning on @xmath , this integral equals

  -- -------- --
     @xmath   
  -- -------- --

By ( 2.17 ), there exists a universal constant @xmath , such that for
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Equation ( 2.18 ) therefore implies ( 2.19 ).

Heuristically, one can estimate the left side of ( 2.18 ) in the
following way: Since @xmath is decreasing very fast, only the times at
which @xmath is of order @xmath contribute to the integral. When started
from the stationary distribution, the process takes a time of order
@xmath to reach a point at distance @xmath from @xmath [ 111 ] and it
stays there for a time of order @xmath , hence the integral is of order
@xmath . When started from the point @xmath , an additional error is
added, which is of order @xmath , when @xmath is at distance of order
@xmath away from @xmath . Adding both terms gives the bound appearing in
the statement of the lemma.

The exact calculations are most easily performed in the following way.
Let @xmath be a random variable with values in @xmath distributed
according to @xmath , which is the stationary probability measure of the
taboo process. Let @xmath . We then have

  -- -------- --
     @xmath   
  -- -------- --

By the inequality @xmath for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

for some constant @xmath depending only on @xmath .

Recall the definition of scale function and speed measure in ( 2.15 ).
Define the Green functions

  -- -------- --
     @xmath   
  -- -------- --

We then have (see e.g. [ 129 ] , Chapter 3, Corollary 3.8),

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

By Fubini’s theorem, the first term in ( 2.21 ) is easily bounded by

  -- -------- --
     @xmath   
  -- -------- --

and noticing that @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

where again we made use of the inequality @xmath for @xmath .

For the term @xmath a little bit more care is needed. Using the fact
that @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

To estimate the first two terms, note that

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -- --
        
  -- -- --

because @xmath for @xmath . The third term is seen to be bounded by

  -- -------- --
     @xmath   
  -- -------- --

Altogether, we get

  -- -------- --
     @xmath   
  -- -------- --

This proves ( 2.19 ) and therefore ( 2.18 ).

In order to prove ( 2.20 ), a different method is needed. We may assume
that @xmath , otherwise we decompose the path at the first and/or last
time it hits @xmath and bound the parts above @xmath trivially by @xmath
. The transition density of the taboo bridge can be written

  -- -------- --
     @xmath   
  -- -------- --

If we denote by @xmath the transition density of Brownian motion killed
at @xmath , then we have the trivial inequality @xmath and furthermore
@xmath for @xmath and @xmath by Brownian scaling. It follows that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the law of the Bessel bridge of dimension 3. This
Bessel bridge is the Doob transform of the Bessel process started at
@xmath with respect to the space-time harmonic function @xmath . By the
standard theory of Doob transforms, this is the Bessel process with
additional drift

  -- -------- --
     @xmath   
  -- -------- --

This in an increasing function in @xmath and standard comparison
theorems for diffusions (see e.g. [ 129 ] , Theorem IX.3.7) now yield
that for @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

since @xmath is a decreasing function. This is true in particular for
@xmath . Using the self-duality of the Bessel bridge, we can repeat the
same reasoning with @xmath . We thus have altogether

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath . This calculation can be done explicitly and yields (
2.20 ). ∎

### 3 Preliminaries on branching Markov processes

In this section we recall some known results about branching Brownian
motion and branching Markov processes in general.

#### 3.1 Definition and notation

Branching Brownian motion can be formally defined using Neveu’s marked
trees [ 122 ] as in [ 62 ] and [ 61 ] . We will follow this path here,
but with slight differences, because we will need to consider more
general branching Markov processes and the definition of branching
Brownian motion in [ 61 ] formally relied on the translational
invariance of Brownian motion.

We first define the space of Ulam–Harris labels, or individuals ,

  -- -------- --
     @xmath   
  -- -------- --

where we use the notation @xmath and @xmath . Hence, an element @xmath
is a word over the alphabet @xmath , with @xmath being the empty word.
For @xmath , we denote by @xmath the concatenation of @xmath and @xmath
. The space @xmath is endowed with the ordering relations @xmath and
@xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

A tree is by definition a subset @xmath , such that 1) @xmath , 2)
@xmath and @xmath imply @xmath and 3) for every @xmath there is a number
@xmath , such that for all @xmath , we have @xmath if and only if @xmath
. Thus, @xmath is the number of children of the individual @xmath . We
denote the space of trees by @xmath and endow it with the sigma-field
@xmath generated by the subsets @xmath .

For a tree @xmath and @xmath , we define the subtree rooted at @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Given a measurable space @xmath , a marked tree (with space of marks
@xmath ) is a pair

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath for all @xmath . The space of marked trees is
denoted by @xmath and is endowed with the sigma-field @xmath , where
@xmath is the canonical projection. Accordingly, we also define @xmath .
The definition of a subtree extends as well to marked trees: For @xmath
, we define

  -- -------- --
     @xmath   
  -- -------- --

For our purposes, the space of marks @xmath is always going to be a
function space, namely, for a Polish space @xmath and a cemetary symbol
@xmath , we define the Skorokhod space @xmath of functions @xmath which
are right-continuous with left limits, with @xmath and for which @xmath
implies @xmath for all @xmath . Then we define @xmath . For an
individual @xmath , its mark is denoted by @xmath and we define @xmath .
The branching Markov process will then be defined on the space (we
suppress the superscript @xmath )

  -- -------- --
     @xmath   
  -- -------- --

endowed with the sigma-field @xmath generated by the sets @xmath . We
define for @xmath the random variables

  -- -------- --
     @xmath   
  -- -------- --

which are the birth and death times of the individual @xmath ,
respectively. We then define the set of individuals alive at time @xmath
by

  -- -------- --
     @xmath   
  -- -------- --

The position of @xmath at time @xmath is defined for @xmath with @xmath
by @xmath , where @xmath is such that @xmath and @xmath . If @xmath ,
then we set @xmath .

Now suppose we are given a defective strong Markov process @xmath on
@xmath , with paths in @xmath . The law of @xmath started in @xmath will
be denoted by @xmath . For simplicity, we will assume that for every
@xmath , we have @xmath , @xmath -almost surely. Furthermore, let @xmath
be a family of probability measures on @xmath , measurable with respect
to @xmath . Then we define the branching Markov process with particle
motion @xmath and reproduction law @xmath as the (unique) family of
probability measures @xmath on @xmath which satisfies

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

Note that by looking at the space-time process @xmath , we can (and
will) extend this definition to the time-inhomogeneous case.

#### 3.2 Stopping lines

The analogue to stopping times for branching Markov processes are
(optional) stopping lines , for which several definitions exist. For
branching Brownian motion, they have first been defined by Chauvin [ 61
] , the definition there is however too restricted for our purposes.
Jagers [ 97 ] has given a definition of more general stopping lines for
discrete-time branching processes; our definition will in fact mix both
approaches. Note also that Biggins and Kyprianou [ 33 ] build up on
Jagers’ definition of stopping lines and define the subclasses of simple
and very simple stopping lines (again for discrete-time processes).
Chauvin’s definition then corresponds to the class of very simple
stopping lines.

We first define a (random) line (called “stopping line” in [ 97 ] ) to
be a set @xmath , such that

1.  [nolistsep]

2.  @xmath for all @xmath and

3.  @xmath implies @xmath for all @xmath and @xmath .

Note that a line is at most a countable set. For a pair @xmath and a
line @xmath , we write @xmath if there exists @xmath , such that @xmath
and @xmath . For a subset @xmath , we write @xmath if @xmath for all
@xmath . If @xmath and @xmath are two lines, we define the line @xmath
to be the maximal line (with respect to @xmath ), which is smaller than
both lines.

We now define for each @xmath two filtrations on @xmath by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Informally, @xmath contains the information on the path from @xmath to
the root between the times @xmath and @xmath , and @xmath contains this
information and of all the other particles excluding the descendants of
@xmath . In particular, we have @xmath The filtration @xmath is denoted
by @xmath in Chauvin’s paper [ 61 ] and @xmath corresponds to the pre-
@xmath -sigma-algebra as defined by Jagers [ 97 ] .

We can now define a stopping line (“optional line” in [ 97 ] ) @xmath to
be a random line with the additional property

-   @xmath

The sigma-algebra @xmath of the past of @xmath is defined to be the set
of events @xmath , such that for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

For example, for any @xmath , the set @xmath is a stopping line. This
permits us to define the filtration @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Following Biggins and Kyprianou [ 33 ] , we now say that @xmath is a
simple stopping line or a very simple stopping line , if it satisfies
the property 3b or 3c below, respectively:

-   @xmath

-   @xmath

Then @xmath is obviously a very simple stopping line. Furthermore, if
@xmath is a stopping time ⁴ ⁴ 4 In other words, @xmath for every @xmath
. , then

  -- -------- --
     @xmath   
  -- -------- --

is a very simple stopping line as well. We recall that the definition of
stopping lines in [ 61 ] is equivalent to the definition of very simple
stopping lines given here.

The first important property of stopping lines is the strong branching
property. In order to state it, we define for @xmath , @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath for @xmath . The strong branching property ( [ 61
, Proposition 2.1] , [ 97 , Theorem 4.14] ) then states that for every
stopping line @xmath , conditioned on @xmath , the subtrees @xmath , for
@xmath , are independent with respective distributions @xmath .

#### 3.3 Many-to-few lemmas and spines

Another important tool in the theory of branching processes is the
so-called Many-to-one lemma and its recently published extension, the
Many-to-few lemma [ 88 ] along with the spine decomposition technique
which comes along with it and has its origins in [ 113 ] , although it
appeared implicitly in the literature before that, see e.g. the
references in the same paper. Here we state stopping line versions of
these lemmas, which to the knowledge of the author have not yet been
stated in this generality in the literature, although they belong to the
common folklore. We will therefore only sketch how they can be derived
from the existing literature.

We assume for simplicity that the strong Markov process @xmath admits a
representation as a conservative strong Markov process @xmath with paths
in @xmath , which is killed at a rate @xmath , where @xmath is
measurable. The law of @xmath started at @xmath is denoted by @xmath and
the time of killing by @xmath . Given a stopping time @xmath for @xmath
, we can then define a stopping time @xmath for @xmath by setting @xmath
, if @xmath and @xmath otherwise. For simplicity, we write @xmath for
@xmath . Finally, for every @xmath , define @xmath , @xmath and @xmath .

We are now going to present the spine decomposition technique, following
[ 86 ] . They assume that @xmath , but this restriction is actually not
necessary, as noted in [ 88 ] . Given a tree @xmath , a spine of @xmath
is an element of the boundary of @xmath , i.e. it is a line of descent
@xmath from the tree, which is finite if and only if the last element is
a leaf of the tree. We augment our space @xmath to the space @xmath by

  -- -------- --
     @xmath   
  -- -------- --

We are going to denote by @xmath the individual @xmath that satisfies
@xmath and @xmath if it exists, and @xmath otherwise. Instead of the
redundant @xmath , we write @xmath . We also note that the definition of
stopping lines can be extended to @xmath by projection.

Now, for every @xmath , one can define a probability measure @xmath on
@xmath in the following way:

-   [nolistsep, label= @xmath ]

-   Initially, @xmath .

-   The individuals on the spine move according to the strong Markov
    process @xmath and die at the rate @xmath , when at the point @xmath
    .

-   When an individual on the spine dies at the point @xmath , it leaves
    @xmath offspring at the point where it has died, with probability
    @xmath (this is also called the size-biased distribution of @xmath ⁵
    ⁵ 5 The size-biased distribution of the Dirac-mass at @xmath is
    again the Dirac-mass at @xmath . ).

-   Amongst those offspring, the next individual on the spine is chosen
    uniformly. This individual repeats the behaviour of its parent
    (started at the point @xmath ).

-   The other offspring initiate independent branching Markov processes
    according to the law @xmath , independently of the spine.

This decomposition first appeared in [ 62 ] .

If we start with @xmath initial particles @xmath at positions @xmath ,
we can extend this definition by defining a (non-probability) measure
@xmath , which is the sum of @xmath probability measures @xmath , where
under @xmath , the particle @xmath follows the law @xmath and the
remaining particles @xmath follow the law @xmath .

We now have the important

###### Lemma 3.1 (Many-to-one).

Let @xmath be a simple stopping line. Define @xmath by @xmath if it
exists, and @xmath otherwise. Let @xmath be a random variable of the
form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath an @xmath -measurable random variable for every @xmath .
Then

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

Proofs of this result can be found for fixed time in [ 108 ] , [ 86 ] or
[ 88 ] . With simple stopping lines, it has been proven in the discrete
setting [ 33 , Lemma 14.1] and their arguments can be used to adapt the
proofs in [ 86 ] and [ 88 ] to yield the result stated here.

Often, we will use a simpler version of the Many-to-one lemma, which is
the following

###### Lemma 3.2 (Simple Many-to-one).

Let @xmath be a stopping time for the strong Markov process @xmath which
satisfies @xmath for every @xmath . Let @xmath be measurable. Then we
have

  -- -------- --
     @xmath   
  -- -------- --

The next lemma tells us about second moments of sums of the previous
type. To state it, we define for a stopping time @xmath for @xmath the
density of the branching Markov process before @xmath , by

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

###### Lemma 3.3.

Let @xmath be the hitting time functional of a closed set @xmath on
@xmath which satisfies @xmath for every @xmath . Let @xmath be
measurable. Then we have

  -- -- -- -------
           (3.4)
  -- -- -- -------

###### Remark 3.4.

This lemma can be proven using the Many-to-few lemma from [ 88 ] (which
is valid for stopping lines as well by the same argument as the one
above) or with Lemma 3.1 , by noting that

  -- -------- --
     @xmath   
  -- -------- --

It also has an intuitive explanation (see, e.g.  the proof of
Proposition 18 in [ 23 ] ): Write the above sum slightly differently as

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

Now, a particle at the point @xmath spawns an expected number of @xmath
of ordered pairs of particles during the time interval @xmath , and by
the strong branching property, the two particles in a pair evolve
independently. This yields ( 3.4 ). Note that this heuristic argument
can be seen as a decomposition of the ordered pairs of particles in the
second sum in ( 3.5 ) according to their most recent common ancestor, an
approach which can be made rigorous in a discrete setting.

Taking for @xmath the space-time process @xmath of a possibly
non-homogeneous strong Markov process @xmath with paths in @xmath and
the closed set @xmath , for some @xmath , we obtain the following useful
corollary, which appeared already in [ 140 ] and [ 132 ] in the
homogeneous case.

###### Lemma 3.5.

Let @xmath be measurable and let @xmath . Then we have

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

#### 3.4 Doob transforms

As in the previous subsection, we assume for simplicity that the strong
Markov process @xmath admits a representation as a conservative strong
Markov process @xmath with paths in @xmath , which is killed at a rate
@xmath , where @xmath is measurable. Let @xmath be the hitting time
functional of a closed set @xmath on @xmath . Furthermore, let @xmath be
a measurable function. We extend the function @xmath to @xmath by
setting

  -- -------- --
     @xmath   
  -- -------- --

We are going to assume that @xmath for all @xmath . Then for all such
@xmath we can define a law @xmath on @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where the multiplication is in the sense of a Radon–Nikodym derivative.
Now define

  -- -------- --
     @xmath   
  -- -------- --

By ( 3.1 ), we now have (dropping the symbol @xmath for better reading
and setting @xmath )

  -- -------- --
     @xmath   
  -- -------- --

If we denote by @xmath the process @xmath stopped at @xmath , and the
law of @xmath under @xmath by @xmath , then the last equation and the
strong Markov property give

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

In particular, integrating over @xmath , @xmath , @xmath , and @xmath
for @xmath , we get that

  -- -------- --
     @xmath   
  -- -------- --

We can therefore define a law @xmath on the paths in @xmath stopped at
@xmath by

  -- -------- --
     @xmath   
  -- -------- --

where the multiplication is again in the sense of a Radon–Nikodym
derivative. Then ( 3.7 ) yields the following decomposition of the law
@xmath :

-   [nolistsep,label= @xmath ]

-   As long as a particle has not hit the set @xmath yet, it moves
    according to the law @xmath . If it gets killed at the point @xmath
    , it spawns @xmath offspring according to the law @xmath , which
    initiate independent branching Markov processes according to the law
    @xmath .

-   When a particle hits the set @xmath at the point @xmath , it
    continues as a branching Markov process according to the law @xmath
    .

If @xmath , one gets a simpler characterisation of the law @xmath : In
this case, @xmath is a harmonic function for the law of the stopped
process @xmath under @xmath , whence we can define the Doob transform

  -- -------- --
     @xmath   
  -- -------- --

Then the law @xmath is obtained from the law @xmath by killing the
process at the time-dependent rate @xmath .

### 4 BBM with absorption at a critical line

From this section on, @xmath will denote a law on @xmath and @xmath a
random variable with law @xmath . We define @xmath and @xmath and
suppose that @xmath and @xmath . We study the branching Markov process
where, starting with a single particle at the origin, particles move
according to standard Brownian motion with drift @xmath and branch at
rate @xmath into @xmath particles according to the reproduction law
@xmath . At the point @xmath , we add an absorbing barrier to the
process, i.e. particles hitting this barrier are instantly killed.
Formally, we are considering the process up to the stopping line @xmath
, where @xmath is the hitting time functional of the point @xmath . It
is well-known since Kesten [ 102 ] that this process gets extinct almost
surely. As a consequence, the number of particles absorbed at the
barrier, i.e. the random variable

  -- -------- --
     @xmath   
  -- -------- --

is almost surely finite. By the strong branching property and the
translational invariance of Brownian motion, one sees that the process
@xmath is a continuous-time Galton–Watson process, a fact which was
first noticed by Neveu [ 123 ] (see [ 14 ] , Chapter III or [ 89 ] ,
Chapter V for an introduction to continuous-time Galton–Watson
processes). Let @xmath be its infinitesimal generating function. Neveu
stated that @xmath , where @xmath is a so-called travelling wave of the
FKPP (Fisher–Kolmogorov–Petrovskii–Piskounov) equation: Write @xmath .
Then @xmath is a solution of the equation

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

with @xmath and @xmath is the extinction probability of the process,
i.e. the smaller root of @xmath . For a proof of these results, see
Section 3 of Chapter 1 .

In the same paper [ 123 ] , Neveu introduced his multiplicative
martingales , which he used to derive the Seneta-Heyde norming for the
martingale @xmath . He proved that in the case of binary branching, one
has

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

where @xmath almost surely. His proof relied on a known asymptotic for
the travelling wave @xmath , namely that

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

for some constant @xmath . It was recently shown [ 143 ] that this
asymptotic is true if and only if @xmath and the proof of ( 4.2 ) works
in this case as well. We also still have in this case, for every @xmath
,

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

a fact which was already proven by Neveu [ 123 ] for dyadic branching.

In [ 23 ] , further properties of the limit @xmath have been established
under the hypothesis of dyadic branching, namely

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

for some constant @xmath . Equation ( 4.5 ) has been proven in
Propositions 27 and 40 of [ 23 ] , and ( 4.6 ) appears in the proof of
Proposition 39 of the same paper. Their arguments were very ingenious
but indirect and although they could be extended to general reproduction
laws with finite variance, we will reprove them here directly under
(probably) minimal assumptions, based on methods of [ 115 ] . The main
result in this section is

###### Proposition 4.1.

If @xmath , then ( 4.5 ) holds. If @xmath , then ( 4.6 ) holds.

See also [ 60 ] for a proof of ( 4.5 ) in the case of branching random
walk. Before proving this result in the next subsection, we state a
lemma which is immediate from ( 4.2 ) and the fact that @xmath is almost
surely finite (see also Corollary 25 in [ 23 ] ):

###### Lemma 4.2.

Suppose @xmath . For any @xmath , there exist @xmath and @xmath , such
that @xmath and

  -- -------- --
     @xmath   
  -- -------- --

#### 4.1 Proof of Proposition 4.1

Define @xmath for @xmath . Our first result is:

###### Lemma 4.3.

Suppose @xmath . Then @xmath as @xmath . Furthermore, @xmath if and only
if @xmath for @xmath , with @xmath .

###### Proof.

Define @xmath , such that @xmath . By ( 4.3 ) and the hypothesis @xmath
,

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

Furthermore, by ( 4.1 ), we have

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

Setting @xmath and @xmath , we get from ( 4.8 ), and the fact that
@xmath and @xmath by definition,

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

As in the proof of Theorem 1.1 from Chapter 1 , we will study the
function @xmath through the integral equation corresponding to ( 4.9 ),
namely

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

Now, by Theorem B of [ 36 ] (see also Theorem 8.1.8 in [ 37 ] ) we have
for every @xmath ,

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

Furthermore, by Proposition 3.2 from Chapter 1 , we have @xmath as
@xmath , and by ( 4.7 ), we have @xmath as @xmath . By the hypothesis
@xmath , this gives

  -- -------- --
     @xmath   
  -- -------- --

whence, by ( 4.10 ),

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

where the constant @xmath is actually the same as the one in ( 4.7 ),
see again the proof of Theorem 1.1 from Chapter 1 . Now, from ( 4.4 ),
we get @xmath , whence, by ( 4.9 ) and ( 4.10 ),

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

where the last equation follows from integration by parts. This proves
the first statement, with the constant @xmath instead of @xmath , since
the last integral vanishes as @xmath . Now, setting

  -- -------- --
     @xmath   
  -- -------- --

we first remark that @xmath , since the integrand is negative for @xmath
. By the Fubini–Tonelli theorem, we then have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

which is finite if and only if @xmath , by ( 4.11 ) and the fact that
@xmath This proves the second statement, again with the constant @xmath
instead of @xmath .

The previous arguments worked for every travelling wave @xmath . In
order to show that that the constant @xmath is equal to 1 in our case,
we use Neveu’s multiplicative martingale (this idea was also used in [
112 ] , Theorem 2.5). It was observed by Neveu [ 123 ] (see also [ 61 ]
for a rigorous proof), that @xmath is a martingale for every @xmath with
values in @xmath . By ( 4.2 ) and ( 4.7 ), we then get by dominated
convergence, for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This yields @xmath . ∎

###### Remark 4.4.

Choosing arbitrary initial points @xmath instead of @xmath in ( 4.10 ),
one sees that

  -- -------- --
     @xmath   
  -- -------- --

In particular, since @xmath is bounded, letting @xmath and @xmath yields

  -- -------- --
     @xmath   
  -- -------- --

One could hope (see the proof of Proposition 4.1 below) that this helps
in determining the constant @xmath , but apparently this does not seem
to be the case.

###### Proof of Proposition 4.1.

For @xmath we define the function

  -- -------- --
     @xmath   
  -- -------- --

such that with @xmath denoting the @xmath -th derivative of @xmath , we
have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , Proposition 4.1 and Karamata’s Tauberian theorem ( [ 79 ] ,
Theorem XIII.5.2 or [ 37 ] , Theorem 1.7.1) now yields

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

By an integration by parts argument (see also [ 79 ] , Theorem VIII.9.2
or [ 37 ] , Theorem 8.1.2), we get ( 4.5 ). Now suppose that @xmath . By
Lemma 4.3 , we have @xmath , as @xmath . By Theorem 3.9.1 from [ 37 ]
(with @xmath ), this yields

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the Euler–Mascheroni constant. This is exactly ( 4.6 ).

∎

### 5 BBM in an interval

In this section we study branching Brownian motion killed upon exiting
an interval. Many ideas in this section (except for Section 5.5 and
parts of Section 5.3 ) stem from Sections 2 and 3 of [ 23 ] and for
completeness, we will reprove some of their results with streamlined
proofs. However, we will also extend their results to the case of
Brownian motion with variable drift.

#### 5.1 Notation

During the rest of the paper, the symbol @xmath stands for a positive
constant, which may only depend on the reproduction law @xmath . Its
value may change from line to line. If a subscript is present, then this
subscript is the number of the equation where this constant appears for
the first time (example: @xmath ). In this case, this constant is fixed
after its value has been chosen in the corresponding equation. If @xmath
is any mathematical expression, then the symbol @xmath stands for a
possibly random term whose absolute value is bounded by @xmath .

Recall the definition of @xmath , @xmath , @xmath and @xmath from
Section 4 and the hypotheses on @xmath and @xmath . In this section, we
let @xmath and set

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

From ( 5.1 ), one easily gets the basic estimate

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

We then denote by @xmath the law of the branching Markov process where,
starting with a single particle at the point @xmath , particles move
according to Brownian motion with variance @xmath and drift @xmath and
branch at rate 1 into @xmath particles according to the reproduction law
@xmath . Expectation with respect to @xmath is denoted by @xmath . On
the space of continuous functions from @xmath to @xmath , we define
@xmath and @xmath to be the hitting time functionals of @xmath and
@xmath . We further set @xmath . Then note that the density of the
branching Brownian motion before @xmath , as defined in ( 3.3 ), has a
density with respect to Lebesgue measure given for @xmath and @xmath by

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where @xmath was defined in ( 2.4 ).

Now, let @xmath be non-decreasing, with @xmath , continuous and such
that the left-derivative @xmath exists everywhere and is of bounded
variation. Such a function will be called a barrier function . We define

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

where @xmath is the usual supremum norm. Furthermore, we set @xmath .
Now define

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

such that @xmath and @xmath for all @xmath . We denote by @xmath the law
of the branching Brownian motion described above, but with infinitesimal
drift @xmath . Expectation with respect to @xmath is denoted by @xmath
and the density of the process is denoted by @xmath .

The above definitions can be extended to arbitrary initial
configurations of particles distributed according to a counting measure
@xmath on @xmath . In this case the superscript @xmath is replaced by
@xmath or simply omitted if @xmath is known from the context.

#### 5.2 The processes @xmath and @xmath

Recall from Section 3 that the set of particles alive at time @xmath is
denoted by @xmath . We define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath was defined in the previous subsection. Now set @xmath and
@xmath and define

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath is a martingale under @xmath , the proof of which is
standard and relies on the branching property, the Many-to-one lemma
(Lemma 3.2 ) and the fact that @xmath is a martingale for a Brownian
motion with drift @xmath killed at @xmath and @xmath , which is easily
seen by Itō’s formula, for example. Furthermore, it is easy to see as
well that @xmath is a supermartingale under @xmath .

The following lemma relates the density of BBM with variable drift to
BBM with fixed drift.

###### Lemma 5.1.

For all @xmath , @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By the Many-to-one lemma and Girsanov’s theorem, we have

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

By integration by parts, we have

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

Since @xmath for all @xmath , we have

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

Furthermore,

  -- -------- --
     @xmath   
  -- -------- --

such that

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

Finally,

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

Equations ( 5.3 ), ( 5.6 ), ( 5.7 ), ( 5.8 ), ( 5.9 ) and ( 5.10 ) now
give

  -- -------- --
     @xmath   
  -- -------- --

and the lemma now follows from ( 5.2 ). ∎

###### Proposition 5.2.

Under any initial configuration of particles, for every @xmath , we have

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

and if in addition @xmath , then

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

Furthermore, we have for every @xmath (without hypothesis on @xmath ),

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

and for @xmath ,

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

Moreover, for every @xmath , we have

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

###### Proof.

Equation ( 5.11 ) follows from Lemma 5.1 and the fact that @xmath is a
martingale under @xmath . In order to show ( 5.13 ) and ( 5.14 ), it
suffices by Lemma 5.1 to consider the case without variable drift. We
first suppose that @xmath . By ( 5.3 ) and ( 2.8 ), we get

  -- -------- --
     @xmath   
  -- -------- --

The last integral is independent of @xmath . Summing over @xmath yields
( 5.14 ) as well as ( 5.13 ) in the case @xmath . Now, if @xmath , by
the Many-to-one lemma and Girsanov’s theorem, we have

  -- -------- --
     @xmath   
  -- -------- --

Summing over @xmath yields ( 5.13 ).

In order to prove ( 5.12 ), we have by Lemma 3.5 ,

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

By Lemma 5.1 and the fact that @xmath is a martingale with respect to
the law @xmath , this yields

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

Now we have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

because @xmath by hypothesis. This yields

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

by ( 5.13 ). Now, by ( 5.3 ) and ( 2.13 ), we have

  -- -------- --
     @xmath   
  -- -------- --

Lemma 2.1 now gives

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

the last line following again from the change of variables @xmath and
the inequality @xmath . Using again the fact that @xmath , equations (
5.17 ), ( 5.18 ) and ( 5.19 ) now imply

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

If we write the positions of the initial particles as @xmath , then by
the independence of their contributions to @xmath ,

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

Equations ( 5.20 ) and ( 5.21 ) now prove ( 5.12 ). Equation ( 5.15 ) is
proven similarly. ∎

#### 5.3 The number of particles

In this subsection, we establish precise first and second moment
estimates for the number of particles alive at a time @xmath . These
estimates extend those of [ 23 ] , which are effective only when @xmath
. For @xmath and @xmath , we denote by @xmath the number of particles in
@xmath at time @xmath .

###### Proposition 5.3.

Suppose @xmath . Let @xmath , @xmath and suppose that @xmath . Then

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

In particular, if @xmath , then

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

Moreover, for every @xmath and @xmath , we have

  -- -- -- --------
           (5.24)
  -- -- -- --------

with @xmath .

###### Proof.

Let @xmath and @xmath . By ( 5.3 ) and Brownian scaling, we have

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

Note that @xmath , by ( 2.5 ). Taylor’s formula then implies that there
exists @xmath , such that

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

We first note that for all @xmath and @xmath , or for all @xmath and
@xmath , one has by ( 2.1 ) and ( 2.2 ),

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

Furthermore, if @xmath , we have

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

by the inequality @xmath , @xmath . Equations ( 5.26 ), ( 5.27 ) and (
5.28 ) now give

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

Now suppose that @xmath , @xmath and @xmath . By ( 2.5 ) and the mean
value theorem, we have @xmath for some @xmath . With ( 2.2 ), one then
easily sees that for @xmath , one has

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

Equations ( 5.26 ), ( 5.27 ) and ( 5.30 ) now give, for @xmath ,

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

Furthermore, we have

  -- -------- -- --------
     @xmath      (5.32)
  -- -------- -- --------

Equations ( 5.25 ), ( 5.29 ), ( 5.31 ), ( 5.32 ) and the hypothesis on
@xmath now imply ( 5.22 ).

In order to prove ( 5.23 ), let @xmath . By ( 2.3 ) and Taylor’s
formula, there exists @xmath , such that

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

With ( 2.1 ) and ( 2.2 ), one now easily sees that @xmath . Equations (
5.2 ), ( 5.22 ) and ( 5.33 ) now readily imply ( 5.23 ). For the last
equation, by ( 5.3 ) and ( 2.8 ), we have for every @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (5.34)
  -- -------- -- --------

with @xmath . Evaluating this integral and using ( 5.2 ) and the
hypothesis on @xmath yields ( 5.24 ). ∎

We will often use the following handier upper bounds on @xmath :

###### Lemma 5.4.

Suppose @xmath . Let @xmath , @xmath and suppose that @xmath .

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

Furthermore, we have for all @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

###### Proof.

One sees from ( 2.1 ) and ( 2.2 ) that @xmath for @xmath . Equation (
5.35 ) now follows from ( 5.22 ) and the mean value theorem. For ( 5.36
), we have by ( 5.13 ),

  -- -- --
        
  -- -- --

∎

###### Lemma 5.5.

Suppose @xmath and @xmath . For every @xmath and @xmath , we have for
large @xmath ,

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

###### Proof.

As in the proof of ( 5.12 ), we have by Lemmas 3.5 and 5.1 ,

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

By ( 5.3 ), Lemma 5.4 and the hypotheses on @xmath and @xmath , we have
after a change of variables @xmath in the integral,

  -- -- -- --------
           (5.39)
  -- -- -- --------

Integrating ( 5.39 ) over @xmath from @xmath to @xmath and splitting the
interval at @xmath , we have by ( 2.9 ) (for the first piece) and ( 2.8
) (for the second),

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

Equations ( 5.36 ), ( 5.38 ) and ( 5.40 ) and the hypotheses on @xmath
and @xmath now imply the lemma. ∎

#### 5.4 The particles hitting the right border

In this section we recall some formulae from [ 23 ] about the number of
particles hitting the right border of the interval. We reprove these
formulae here for completeness and because Lemma 2.1 makes their proofs
straightforward. For most formulae we will assume that @xmath ,
i.e. that we are working under the measure @xmath . Only Lemma 5.9
contains an upper bound on the expected number of particles for general
@xmath , which will be useful in Section 7 .

For a measurable subset @xmath , define @xmath to be the number of
particles killed at the right border during the (time) interval @xmath ,
i.e.

  -- -------- --
     @xmath   
  -- -------- --

The following lemma gives exact formulae of the expectation and the
second moment of @xmath .

###### Lemma 5.6.

For every @xmath , we have

  -- -------- -------- -- --------
     @xmath   @xmath      (5.41)
     @xmath   @xmath      (5.42)
  -- -------- -------- -- --------

We will first prove a more general result, which will be needed in
Section 6.4 .

###### Lemma 5.7.

For every @xmath and any measurable function @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Recall that @xmath and @xmath denote the hitting time functionals of
@xmath and @xmath and @xmath . Then note that @xmath for all @xmath . We
then have

  -- -------- -------- -- --
     @xmath   @xmath      
              @xmath      
              @xmath      
  -- -------- -------- -- --

Note that in the second line we used the fact that @xmath by definition.
∎

###### Proof of Lemma 5.6.

Equation ( 5.41 ) follows from Lemma 5.6 and ( 2.14 ) by taking @xmath .
Equation ( 5.42 ) follows from Lemma 3.3 and ( 5.41 ). ∎

###### Lemma 5.8.

For any initial configuration @xmath and any @xmath , we have

  -- -------- -- --------
     @xmath      (5.43)
  -- -------- -- --------

where @xmath is defined in ( 2.7 ). Furthermore, if @xmath and @xmath ,
then for each @xmath ,

  -- -------- -- --------
     @xmath      (5.44)
  -- -------- -- --------

###### Proof.

We have @xmath , such that ( 5.43 ) follows from ( 5.41 ) and Lemma 2.1
. For the second moment, we have by ( 5.42 ),

  -- -------- --
     @xmath   
  -- -------- --

Performing the change of variables @xmath in the integral and making use
of the inequalities @xmath and @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

where we used the hypothesis @xmath . The last inequality, together with
( 5.43 ) and the hypothesis @xmath yields ( 5.44 ). ∎

###### Lemma 5.9.

Let @xmath be a function as in Section 5.1 . Then for every @xmath , we
have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As in the proof of Lemma 5.6 , we have

  -- -------- --
     @xmath   
  -- -------- --

by Girsanov’s theorem and the definition of @xmath . Now, we have by (
5.7 ), on the event @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

since @xmath for @xmath . This gives

  -- -------- --
     @xmath   
  -- -------- --

by the proof of Lemma 5.6 . ∎

We finish this section with a lemma which links BBM with absorption at a
critical line to our BBM with selection model.

###### Lemma 5.10.

Let @xmath , @xmath , @xmath and @xmath be a barrier function (defined
in Section 5.1 ). Suppose that @xmath and @xmath . Let @xmath be a
collection of space-time points with

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for all @xmath . Define @xmath , @xmath and @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

In particular, for large @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By ( 5.2 ) and the hypotheses @xmath and @xmath , we have for all @xmath
,

  -- -------- --
     @xmath   
  -- -------- --

Hence, by ( 5.2 ) and the hypotheses @xmath , @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (5.45)
  -- -------- -- --------

Furthermore, since @xmath for @xmath and by the hypotheses @xmath and
@xmath ,

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

The lemma now follows by summing over ( 5.45 ) and ( 5.46 ). ∎

#### 5.5 Penalizing the particles hitting the right border

In this section, let @xmath be iid random variables, uniformly
distributed on @xmath , independent of the branching Brownian motion.
Furthermore, let @xmath be measurable and such that @xmath for large
enough @xmath . Recall that @xmath . We define the event

  -- -------- --
     @xmath   
  -- -------- --

Our goal in this section is to describe the law @xmath . We first note
that

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

In order to apply the results from Section 3.4 , we define

  -- -------- -------- -- --------
     @xmath   @xmath      (5.48)
     @xmath   @xmath      (5.49)
     @xmath   @xmath      (5.50)
  -- -------- -------- -- --------

By the results from Section 3.4 , under the law @xmath , the BBM stopped
at @xmath is the branching Markov process where

-   [nolistsep,label=–]

-   particles move according to the Doob transform of Brownian motion
    with drift @xmath (stopped at @xmath and @xmath ) by the space-time
    harmonic function @xmath and

-   a particle located at the point @xmath at time @xmath branches at
    rate @xmath , throwing @xmath offspring with probability @xmath .

We have the following useful Many-to-one lemma for the conditioned
process stopped at the stopping line @xmath : Define the function

  -- -------- -- --------
     @xmath      (5.51)
  -- -------- -- --------

###### Lemma 5.11.

For any measurable function @xmath , @xmath and @xmath , we have

  -- -- -- --------
           (5.52)
  -- -- -- --------

In particular, if we denote by @xmath the density of the @xmath -BBM,
then

  -- -------- -- --------
     @xmath      (5.53)
  -- -------- -- --------

and for general @xmath ,

  -- -------- -- --------
     @xmath      (5.54)
  -- -------- -- --------

###### Proof.

By Lemma 3.2 and the description of the law @xmath given above, we have

  -- -- --
        
  -- -- --

where @xmath , which yields ( 5.52 ). Equation ( 5.53 ) follows from (
5.52 ) applied to the Dirac Delta-function @xmath , @xmath , together
with ( 5.3 ). ∎

The previous lemma immediately gives an upper bound for the quantities
we are interested in:

###### Corollary 5.12.

Let @xmath , @xmath and @xmath be measurable with @xmath . Define @xmath
. Then,

  -- -------- -------- -- --------
     @xmath   @xmath      (5.55)
     @xmath   @xmath      (5.56)
  -- -------- -------- -- --------

###### Proof.

Equation ( 5.55 ) immediately follow from ( 5.53 ). In order to prove
the second-moment estimates, we note that by Lemma 3.5 and the
description of the conditioned process,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath By ( 5.50 ), we have @xmath . Equation ( 5.56 ) then
follows from ( 5.16 ), ( 5.53 ) and ( 5.55 ). ∎

The following lemma gives a good lower bound on the first-moment
estimates in the case where @xmath .

###### Lemma 5.13.

Suppose @xmath , @xmath and @xmath for all @xmath . Let @xmath be as in
Corollary 5.12 . We have

  -- -------- -- --------
     @xmath      (5.57)
  -- -------- -- --------

This follows from the following estimate on @xmath , which will be
sharpened in Lemma 6.3 .

###### Lemma 5.14.

Suppose @xmath for all @xmath . Then for all @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Markov’s inequality, we have

  -- -------- --
     @xmath   
  -- -------- --

The lemma now follows from Lemmas 5.8 and 5.9 and the inequality @xmath
, @xmath . ∎

###### Proof of Lemma 5.13.

By ( 5.53 ),

  -- -- -- --------
           (5.58)
  -- -- -- --------

By Lemma 5.14 and the hypothesis on @xmath , we have for every @xmath ,

  -- -------- -- --------
     @xmath      (5.59)
  -- -------- -- --------

This gives

  -- -- -- --------
           (5.60)
  -- -- -- --------

by ( 5.51 ), ( 5.59 ), Lemma 2.2 , the inequality @xmath for @xmath and
the fact that the law of the Brownian taboo process is preserved under
the map @xmath . The lemma now follows from ( 5.58 ), ( 5.59 ) and (
5.60 ). ∎

Finally, we study the law of @xmath under the new probability.

###### Lemma 5.15.

We have for every @xmath ,

  -- -------- -- --------
     @xmath      (5.61)
  -- -------- -- --------

and if there is a @xmath , such that @xmath for @xmath , then we even
have

  -- -------- -- --------
     @xmath      (5.62)
  -- -------- -- --------

###### Proof.

Let @xmath be the stopping line

  -- -------- --
     @xmath   
  -- -------- --

We have by definition of the law @xmath ,

  -- -- -- --------
           (5.63)
  -- -- -- --------

Now the denominator is @xmath by ( 5.48 ), which yields the right-hand
side of ( 5.61 ). The left-hand side follows by noticing that

  -- -------- --
     @xmath   
  -- -------- --

For ( 5.62 ), we note that if @xmath for @xmath , then by ( 5.63 ),

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is decreasing in @xmath , this yields ( 5.62 ). ∎

### 6 BBM with absorption before a breakout

In this section, we are studying branching Brownian motion with drift
@xmath and absorption at @xmath until a breakout occurs, an event which
will be defined in Section 6.1 and which corresponds to a particle going
far to the right and spawning a large number of descendants. In ( 6.20
), we decompose the system into a particle conditioned to break out at a
specific time @xmath (this particle will be called the fugitive ) and
the remaining particles, which are conditioned not to break out before
time @xmath . These two parts will be studied separately, the former in
Section 6.4 and the latter in Section 6.3 . Before that, in Section 6.2
, we study the law of the time of the first breakout, showing that it is
approximately exponentially distributed. First of all, however, we start
with the necessary definitions:

#### 6.1 Definitions

We will introduce several parameters which will be used during the rest
of the paper. The two most important parameters are @xmath and @xmath ,
which are both large positive constants. The meaning of @xmath is as in
the previous sections: It is the right border of an interval in which
the particles are staying most of the time. The parameter @xmath has a
more subtle meaning and controls the number of particles of the system
and with it the intensity at which particles hit the point @xmath . In
Section 7 , we will indeed choose the initial conditions such that
@xmath .

When we study the system for large @xmath and @xmath , we first let
@xmath go to infinity, then @xmath . Thus, the statement “For large
@xmath and @xmath we have…” means: “There exist @xmath and a function
@xmath , both depending on the reproduction law @xmath only, such that
for @xmath and @xmath we have…”. Likewise, the statement “As @xmath and
@xmath go to infinity…” means “For all @xmath there exists @xmath ,
depending on the reproduction law @xmath only, such that as @xmath goes
to infinity and @xmath …”. These phrases will become so common that in
Sections 7 to 9 they will often be used implicitly, although they will
always be explicitly stated in the theorems, propositions, lemmas etc.
We further introduce the notation @xmath , which stands for a
(non-random) term that only depends on the reproduction law @xmath and
the parameters @xmath , @xmath , @xmath , @xmath , @xmath and @xmath and
which goes to @xmath as @xmath and @xmath go to infinity.

The remaining parameters we introduce are all going to depend on @xmath
, but not on @xmath . First of all, there is the small parameter @xmath
, which controls the intensity of the breakouts. Indeed, when @xmath ,
the mean time one has to wait for a breakout will be approximately
proportional in @xmath . Morally, one could choose @xmath such that
@xmath , but for technical reasons we will require that

  -- -------- -------- -- -------
     @xmath   @xmath      (6.1)
     @xmath   @xmath      (6.2)
  -- -------- -------- -- -------

Another protagonist is @xmath , which we will choose as small as we need
and which will be used to bound the probability of very improbable
events, as well as the contribution of the variable @xmath . It will be
enough to require that

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

which, by ( 6.2 ), implies

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

The last parameters are @xmath and @xmath , which are defined as in
Lemma 4.2 , with @xmath there being the @xmath defined above. Note that
the parameters @xmath , @xmath and @xmath appeared already in [ 23 ] and
had the same meaning there.

We can now proceed to the definition of the process. Recall the
definition of @xmath in ( 5.1 ). As in Section 5.1 , we denote by @xmath
and @xmath the law and expectation of branching Brownian motion with
drift @xmath starting from a particle at the point @xmath ; we extend
this definition to general initial distributions of particles according
to a counting measure @xmath . Recall from Section 3.1 that @xmath
denotes the set of individuals alive at time @xmath . We want to absorb
the particles at 0 and do this formally by setting

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is again the hitting time functional of 0.

Instead of absorbing particles at @xmath , we are now going to classify
them into tiers as described in the introduction. Let @xmath , @xmath .
We define two sequences of random times @xmath and @xmath by @xmath ,
@xmath and for @xmath :

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

where we set @xmath . See Figure 2.1 for a graphical description. We now
define for @xmath the stopping lines

  -- -------- -------- -- -------
     @xmath   @xmath      (6.6)
     @xmath   @xmath      (6.7)
  -- -------- -------- -- -------

That means, @xmath contains the particles of tier @xmath at the moment
at which they touch the right barrier and @xmath contains the particles
of tier @xmath at the moment at which they come back to the critical
line. Note that the sets @xmath and @xmath are increasing in @xmath and
@xmath for every @xmath . We also set

  -- -------- --
     @xmath   
  -- -------- --

In order to extend the definitions of the variables @xmath and @xmath to
the current setup, we could simply replace @xmath by @xmath in their
definition (see Section 5.1 ). However, it will be more useful to take
special care of the individuals @xmath for which @xmath for some @xmath
, since these are in some kind of “intermediary” state which is
difficult to analyse. We therefore define the stopping lines

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

In other words, the stopping line @xmath contains the particles of tier
@xmath that have already come back to the critical line at time @xmath ,
as well as the descendants of those that haven’t, at the moment at which
they hit the critical line. We then define for @xmath (recall the
definitions of @xmath and @xmath from Section 5 ),

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, for any symbol @xmath and @xmath , we write,

  -- -------- --
     @xmath   
  -- -------- --

For a particle @xmath , we now define the stopping line

  -- -------- --
     @xmath   
  -- -------- --

This stopping line yields a collection @xmath of space-time points and
we denote by @xmath , @xmath and @xmath the quantities from Lemma 5.10
corresponding to this collection of points (in particular, @xmath ). Of
course, we have chosen the stopping line in such a way that the variable
@xmath follows the same law as the variable @xmath defined in ( 4.2 ).
We also define @xmath . We then define the “good” event

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

and the event of a breakout ,

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

(the inclusion of the “bad” event @xmath is for technical reasons). If
the event @xmath occurs, the particle @xmath is then also called the
fugitive . We set

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

and define the law of BBM started at @xmath with the first particle
conditioned not to break out:

  -- -------- --
     @xmath   
  -- -------- --

where we set @xmath . We further set @xmath and @xmath and note that by
Lemmas 5.10 and 4.2 , we have for large @xmath ,

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

where @xmath is defined as in ( 4.2 ). Hence, by ( 6.3 ), ( 4.5 ) and
Lemma 4.2 , we get

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

which goes to 0 as @xmath and @xmath go to infinity, by ( 6.2 ).
Furthermore, ( 6.13 ) yields for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

by ( 4.6 ), ( 6.1 ), ( 6.3 ) and ( 6.14 ). In particular, we have for
@xmath and large @xmath ,

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

Moreover, by ( 4.5 ), ( 6.13 ) and ( 6.3 ), we have for @xmath and large
@xmath ,

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

Finally, note that by Lemma 5.10 , we have @xmath , @xmath -almost
surely, a fact that will often be used without further reference.

We now define for every @xmath the time of the first breakout of a
particle of tier @xmath ,

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

and set

  -- -------- -- --------
     @xmath      (6.19)
  -- -------- -- --------

Now fix @xmath and @xmath . We want to describe the system conditioned
on @xmath . For this, suppose that at time @xmath the particles are
distributed according to a counting measure @xmath . We denote by @xmath
the fugitive of the breakout that happened at time @xmath and define
@xmath . This yields a law @xmath on the initial particles, depending on
@xmath and @xmath . Since the variable @xmath , the time of the first
breakout, is the minimum of the variables @xmath , @xmath , the times of
the first breakout of the BBM descending from the particle @xmath , we
can decompose the process into

  -- -------- -- --------
     @xmath      (6.20)
  -- -------- -- --------

That is, we first choose according to the law @xmath the initial
particle that is going to cause the breakout. This particle spawns a BBM
conditioned to break out at time @xmath . The remaining particles spawn
independent BBM conditioned not to break out before time @xmath .

###### Remark 6.1.

Note that many results in this section can be done for BBM with varying
drift given by a barrier function @xmath . For example, with Lemma 5.9
one gets immediately that @xmath for all @xmath and it will be clear
from the next section that in fact @xmath as well. However, in order to
simplify notation and because we will not need the results often in this
generality, we state them here only for BBM with fixed drift.

#### 6.2 The time of the first breakout

For large @xmath and @xmath , define

  -- -------- -- --------
     @xmath      (6.21)
  -- -------- -- --------

We want to prove that the random variable @xmath defined in the previous
section is approximately exponentially distributed with parameter @xmath
, which is the statement of the following proposition:

###### Proposition 6.2.

Let @xmath . For @xmath and @xmath large enough, we have

  -- -------- -- --------
     @xmath      (6.22)
  -- -------- -- --------

The proof proceeds by a sequence of lemmas. Lemma 6.3 gives a estimate
on @xmath . This is used in Lemma 6.4 , in order to obtain an estimate
on @xmath , using a recursive argument. Finally, Proposition 6.2 is
proven by combining Lemmas 6.3 and 6.4 .

###### Lemma 6.3.

Let @xmath . Suppose that @xmath . Then,

  -- -------- -- --------
     @xmath      (6.23)
  -- -------- -- --------

###### Proof.

Let @xmath be the positions of the initial particles. Since the initial
particles spawn independent branching Brownian motions, we have

  -- -------- -- --------
     @xmath      (6.24)
  -- -------- -- --------

We have for every @xmath ,

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

since by the strong branching property, the random variables @xmath are
independent conditioned on @xmath . By Lemma 5.8 and the assumption
@xmath , we have

  -- -------- -- --------
     @xmath      (6.26)
     @xmath      (6.27)
  -- -------- -- --------

By Jensen’s inequality, ( 6.26 ) and the inequality @xmath for @xmath ,

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

Furthermore, the inequality @xmath and Equations ( 6.26 ) and ( 6.27 )
give

  -- -------- -- --------
     @xmath      (6.29)
  -- -------- -- --------

The lemma now follows from ( 6.25 ), ( 6.28 ) and ( 6.29 ) together with
the inequality @xmath for @xmath . ∎

In the following lemma, note that according to the definition of the
tiers, a particle starting at @xmath starts immediately in tier 1.

###### Lemma 6.4.

Let @xmath . Then, for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

###### Proof.

We have

  -- -------- -- --------
     @xmath      (6.31)
  -- -------- -- --------

where @xmath . Since @xmath implies @xmath , we have

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

Let @xmath and @xmath , such that @xmath , @xmath -almost surely, by
Lemma 5.10 and the definition of the “bad” event @xmath . By Lemma 6.3 ,
we have for large @xmath ,

  -- -------- -- --------
     @xmath      (6.33)
  -- -------- -- --------

Furthermore, with the notation from Section 5.5 , with @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
  -- -------- -------- --

By Jensen’s inequality and Lemmas 5.15 and 5.8 , this implies

  -- -------- -- --------
     @xmath      (6.34)
  -- -------- -- --------

Equations ( 6.31 ), ( 6.32 ), ( 6.33 ) and ( 6.34 ), together with
Jensen’s inequality and ( 6.15 ), now yield for large @xmath and @xmath
,

  -- -------- -- --------
     @xmath      (6.35)
  -- -------- -- --------

By the hypothesis on @xmath and ( 6.3 ), the exponent of @xmath in (
6.35 ) is smaller than @xmath for large @xmath and @xmath . This yields
the statement. ∎

###### Proof of Proposition 6.2.

The upper bound follows from Lemma 6.3 and the trivial inequality @xmath
. For the lower bound, we note that as in the proof of Lemma 6.4 , we
have by Jensen’s inequality and Lemma 5.15 ,

  -- -------- -- --------
     @xmath      (6.36)
  -- -------- -- --------

By Lemmas 6.4 and 5.8 , we have

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

The lower bound in ( 6.22 ) now follows from ( 6.36 ), ( 6.37 ) and
Lemma 6.3 , together with the hypothesis on @xmath , ( 6.3 ) and ( 6.14
). ∎

###### Lemma 6.5.

Define @xmath . Suppose that @xmath and let @xmath and @xmath . Then,
for large @xmath , for every @xmath ,

  -- -------- -- --------
     @xmath      (6.38)
  -- -------- -- --------

Furthermore, if @xmath , then for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.39)
  -- -------- -- --------

###### Proof.

We first note that we have, for @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.40)
  -- -------- -- --------

Now, we have

  -- -------- --
     @xmath   
  -- -------- --

The inequality ( 6.38 ) now follows from Lemma 6.3 and ( 6.40 ) and the
hypothesis on @xmath . For the second part, we note that

  -- -- --
        
  -- -- --

and by Proposition 6.2 and the hypothesis on @xmath , we have for @xmath
and large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Equation ( 6.39 ) now follows from the last two equations. ∎

We now show how we can couple the variable @xmath with an exponentially
distributed variable:

###### Lemma 6.6.

Suppose that @xmath and that @xmath . Then there exists a coupling
@xmath , such that @xmath is a random variable which is exponentially
distributed with parameter @xmath , @xmath is @xmath -measurable and
@xmath for large @xmath and @xmath .

###### Proof.

For brevity, set @xmath . Let @xmath be the tail distribution function
of @xmath , i.e. @xmath . The number of individuals in a BBM tree being
at most countable, @xmath has no atoms except @xmath . We can therefore
define a random variable @xmath which is uniformly distributed on @xmath
by setting

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a uniformly distributed random variable on @xmath ,
independent of @xmath . Now we define @xmath . Then @xmath is
exponentially distributed with parameter @xmath and @xmath , where
@xmath denotes the generalised right-continuous inverse of @xmath .
Hence, @xmath is @xmath -measurable. On @xmath , we have by Proposition
6.2 , for @xmath large enough,

  -- -------- -- --------
     @xmath      (6.41)
  -- -------- -- --------

by the hypotheses on @xmath and @xmath . Hence, by ( 6.2 ), ( 6.4 ) and
( 6.14 ), we have for @xmath large enough,

  -- -------- --
     @xmath   
  -- -------- --

But now we have by Lemma 6.3 , for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

The statement now follows from ( 6.41 ) and ( 6.42 ) together with ( 6.1
) ∎

#### 6.3 The particles that do not participate in the breakout

In this section, we fix @xmath . We define the law of BBM conditioned
not to break out before @xmath in the tiers @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Expectation w.r.t. @xmath is denoted by @xmath . Under the law @xmath ,
the process stopped at @xmath then follows the law @xmath from Section
5.5 , with

  -- -------- -- --------
     @xmath      (6.43)
  -- -------- -- --------

such that by Lemma 6.4 , ( 6.3 ), ( 6.16 ) and the trivial inequality
@xmath , we have for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.44)
  -- -------- -- --------

In particular, by Lemma 5.14 , ( 5.2 ) and ( 6.44 ), we have for large
@xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.45)
  -- -------- -- --------

Lemmas 5.11 and 5.13 , together with ( 6.44 ) and ( 6.45 ) now
immediately imply the following:

###### Corollary 6.7.

Let @xmath , @xmath and @xmath be measurable with @xmath . Define @xmath
or @xmath . Then, with @xmath as above,

  -- -------- --
     @xmath   
  -- -------- --

Moreover, as in the proof of Lemma 5.15 , one can show that

  -- -------- -- --------
     @xmath      (6.46)
  -- -------- -- --------

We define two filtrations @xmath and @xmath by

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath for every @xmath . Now define for measurable @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath . Furthermore, recall from Section 6.1 the
definition of @xmath , @xmath and @xmath and the corresponding
quantities for @xmath .

###### Lemma 6.8.

We have for all @xmath , @xmath and large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.47)
  -- -------- -- --------

In particular, for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.48)
  -- -------- -- --------

In the case @xmath , we also have for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.49)
  -- -------- -- --------

###### Proof.

We have for @xmath ,

  -- -- -- --------
           (6.50)
  -- -- -- --------

since conditioned on @xmath , the random variables @xmath are iid under
@xmath of the same law as @xmath under @xmath and independent of @xmath
, by the strong branching property. Now, we have

  -- -------- --
     @xmath   
  -- -------- --

such that by Lemma 5.8 and Corollary 6.7 ,

  -- -------- -- --------
     @xmath      (6.51)
  -- -------- -- --------

Equations ( 6.50 ) and ( 6.51 ) together with ( 6.46 ) give ( 6.47 ).
Equation ( 6.48 ) follows easily from ( 6.47 ) by ( 6.16 ) and the fact
that @xmath , @xmath -almost surely for @xmath . Now, in the case @xmath
, we have @xmath by definition. Denote the positions of the initial
particles by @xmath . By Lemmas 5.8 , 5.15 and ( 6.44 ),

  -- -------- --
     @xmath   
  -- -------- --

which yields ( 6.49 ). ∎

###### Lemma 6.9.

Suppose that @xmath . Then for large @xmath and @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

If moreover @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

First note that we have @xmath for large @xmath , by ( 6.45 ).
Furthermore, by the hypothesis @xmath and ( 6.3 ), we have @xmath for
large @xmath and @xmath . The first two inequalities now follow from
Proposition 5.2 , Corollary 6.7 , Lemma 6.8 , ( 6.46 ) and ( 6.3 ) by
summing over @xmath . In particular, if @xmath , then for large @xmath
and @xmath , @xmath and @xmath . Together with Proposition 5.2 , Lemma
5.8 and Corollary 6.7 , this proves the other two inequalities. ∎

In order to estimate second moments, we will make use of the following
extension to the Many-to-two lemma (Lemma 3.5 ). For @xmath and @xmath ,
we define @xmath to be the quantity @xmath from Section 5.5
corresponding to the penalisation from ( 6.43 ) and @xmath to be the
density of tier @xmath particles at position @xmath and time @xmath
under the law @xmath , not counting the particles @xmath with @xmath .
Then set @xmath .

###### Lemma 6.10.

Let @xmath be measurable and define @xmath . Then

  -- -------- -- --------
     @xmath      (6.52)
  -- -------- -- --------

###### Proof.

For @xmath we write @xmath for their most recent common ancestor. Then
define for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

We then have

  -- -------- -- --------
     @xmath      (6.53)
  -- -------- -- --------

and by Lemma 3.5 (see also Remark 3.4 ),

  -- -------- -- --------
     @xmath      (6.54)
  -- -------- -- --------

Equations ( 6.53 ) and ( 6.54 ), together with ( 3.5 ) and the tower
property of conditional expectation yield the lemma. ∎

###### Remark 6.11.

An analogous result holds for @xmath .

###### Lemma 6.12.

We have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Lemma 6.9 and the hypothesis @xmath , we have for every @xmath and
@xmath ,

  -- -------- -- --------
     @xmath      (6.55)
  -- -------- -- --------

Now, as in the proof of ( 5.20 ), we have by ( 6.55 ) and Corollary 6.7
,

  -- -------- -- --------
     @xmath      (6.56)
  -- -------- -- --------

which yields

  -- -- -- --------
           (6.57)
  -- -- -- --------

by Lemma 6.8 and the hypothesis @xmath . Furthermore, by ( 6.55 ), ( 6.3
) and Lemma 5.10 , we have

  -- -------- -- --------
     @xmath      (6.58)
  -- -------- -- --------

by ( 6.17 ) and Lemmas 5.8 and Corollary 6.7 . Lemma 6.10 , together
with ( 6.57 ) and ( 6.58 ) as well as Lemma 6.9 and the inequality
@xmath gives

  -- -------- -- --------
     @xmath      (6.59)
  -- -------- -- --------

Summing over the initial particles yields the inequality for @xmath .
The proof of the second inequality is analogous, relying on Lemma 5.8
and Remark 6.11 . ∎

We finish the section by a corollary which will be useful in the next
section.

###### Corollary 6.13.

Suppose that @xmath and @xmath . Then for large @xmath and @xmath , we
have @xmath , @xmath and @xmath .

###### Proof.

Immediate from Lemmas 6.9 and 6.12 and ( 5.2 ). ∎

#### 6.4 The fugitive and its family

We now describe the BBM conditioned to break out at a given time. Recall
that @xmath denotes the fugitive. For simplicity, we write @xmath and
@xmath for @xmath and @xmath , respectively, @xmath . On the event
@xmath , we define @xmath to be the ancestor of @xmath alive at the time
@xmath , @xmath . By the strong branching property, we have the
following decomposition:

###### Lemma 6.14.

Let @xmath , @xmath with @xmath and @xmath . Conditioned on @xmath ,
@xmath , @xmath and @xmath , the BBM admits the following recursive
decomposition:

1.   [nolistsep]

2.   The initial particles @xmath spawn independent BBM conditioned on
    @xmath ,

3.   independently, the particle @xmath spawns BBM conditioned on a
    particle (call it @xmath ) hitting @xmath for the first time at the
    time @xmath , all the children of which born before @xmath being
    conditioned on @xmath .

    1.   If @xmath , this particle @xmath spawns BBM conditioned on the
        event @xmath of a breakout.

    2.   If @xmath , it spawns BBM starting at the space-time point
        @xmath conditioned on @xmath . In particular, if we write @xmath
        , then conditioned on @xmath , the particles in @xmath spawn BBM
        starting from the collection of space-time points @xmath ,
        conditioned on @xmath .

Note that in the case 2b above, the subtree spawned by @xmath follows
the law @xmath conditioned on @xmath , hence the law of @xmath is not
the same as under @xmath . In particular, @xmath . Indeed, conditioning
on one of its descendants breaking out at a later time corresponds to a
kind of size-bias on the number of particles. However, it is still true
that @xmath , by the definition of a breakout.

Lemma 6.14 gives a decomposition of the BBM conditioned on @xmath into
@xmath pieces. In order to describe what happens in a single piece,
define @xmath to be the @xmath -field generated by the family of events
@xmath and by @xmath , @xmath , @xmath and @xmath , for @xmath , on the
event @xmath . Note that in particular, on the event @xmath , @xmath ,
@xmath are @xmath -measurable, @xmath . It is plain that conditioned on
@xmath , the subtrees spawned by the children of the ancestors of @xmath
during the intervals @xmath are independent BBM conditioned not to break
out before @xmath .

It remains to describe the trajectory of the fugitive and its
reproduction. By a decomposition at the first time of branching as in
Section 3.4 , we could describe the law of BBM starting from a single
particle at position @xmath at time @xmath and conditioned on a particle
hitting @xmath for the first time at a time @xmath , all the children of
which born before @xmath being conditioned on @xmath . However, it is
faster to use the Many-to-one lemma instead, which is the method of
proof of the following lemma, which we state for general penalisations
@xmath . This result is essentially [ 64 , Theorem 1] .

###### Lemma 6.15.

Let @xmath , @xmath and @xmath be measurable with @xmath for @xmath
large enough. Denote by @xmath the law associated to @xmath as in
Section 5.5 . Recall the definition of @xmath from ( 5.51 ). Then, given
a family of @xmath -measurable non-negative random variables @xmath , we
have

  -- -------- --
     @xmath   
  -- -------- --

where under @xmath , the spine follows standard Brownian motion and
spawns particles with rate @xmath according to the reproduction law
@xmath , which start independent @xmath -BBM. In particular, conditioned
on @xmath and @xmath , the children of the ancestors of @xmath follow
independent @xmath -BBM.

###### Proof.

We have

  -- -- -- --------
           (6.60)
  -- -- -- --------

and by Lemma 3.1 ,

  -- -------- -- --------
     @xmath      (6.61)
  -- -------- -- --------

According to the description of the conditioned process in Section 5.5
and the description of the spine in Section 3.3 , the particles on the
spine follow the Doob transform of Brownian motion with drift @xmath by
the harmonic function @xmath and spawn particles with rate @xmath
according to the reproduction law @xmath . With Girsanov’s transform, (
6.61 ) yields,

  -- -------- -- --------
     @xmath      (6.62)
  -- -------- -- --------

Equations ( 6.60 ) and ( 6.62 ) yield the first statement. The second
statement follows by taking appropriate test functionals @xmath . ∎

###### Corollary 6.16.

In addition to the assumptions in Lemma 6.15 , suppose @xmath and @xmath
, where @xmath is some universal constant implicitly defined below.
Then,

  -- -------- -- --------
     @xmath      (6.63)
  -- -------- -- --------

###### Proof.

By Lemma 2.2 , the inequality @xmath and the hypothesis on @xmath , we
have

  -- -------- -- --------
     @xmath      (6.64)
  -- -------- -- --------

The statement now follows from ( 6.64 ) and Lemma 6.15 . ∎

We come back to the BBM conditioned to break out at a given time and set
up the important definitions. Recall that @xmath denotes the fugitive.
We will denote by a bar the quantities referring to the particles
spawned between the times @xmath and @xmath for some @xmath , and by a
check those referring to the particles spawned between the times @xmath
and @xmath . See Figure 2.2 for a visualization. Formally, we set

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

We then define

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Note that on the event @xmath , we have @xmath by definition.

By Corollary 6.13 , the following @xmath -measurable functional will be
of use in the study of the bar-quantities.

  -- -------- -- --------
     @xmath      (6.65)
  -- -------- -- --------

where we recall that @xmath and @xmath are respectively the time of
death and the number of children of the individual @xmath .

###### Lemma 6.17.

For large @xmath and @xmath , we have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Lemma 6.14 and Corollary 6.16 (which can be applied because of ( 6.44
)), we have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the law of a Brownian bridge of length @xmath from
@xmath to @xmath . The statement now follows readily from Lemma 2.2 . ∎

We can now study the probability that the fugitive stems from a given
tier.

###### Lemma 6.18.

Suppose that @xmath and @xmath . Then for large @xmath and @xmath , we
have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By ( 6.2 ), ( 6.14 ) and ( 6.46 ), we have for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (6.66)
  -- -------- -- --------

Now, for the rest of the proof, let @xmath and let @xmath . We have by
the decomposition ( 6.20 ) of the process conditioned on @xmath ,

  -- -------- -- --------
     @xmath      (6.67)
  -- -------- -- --------

Define @xmath , which is less than @xmath for large @xmath and @xmath by
the hypothesis on @xmath . By Lemma 6.8 and the hypothesis, we have for
every @xmath ,

  -- -------- -- --------
     @xmath      (6.68)
  -- -------- -- --------

and moreover for every @xmath ,

  -- -------- -- --------
     @xmath      (6.69)
  -- -------- -- --------

For every @xmath , ( 6.68 ) applied to the particles in @xmath , @xmath
yields

  -- -------- -- --------
     @xmath      (6.70)
  -- -------- -- --------

Moreover, by ( 6.69 ), Corollary 6.13 and Lemma 6.17 , we have

  -- -------- -- --------
     @xmath      (6.71)
  -- -------- -- --------

In total, we get by ( 6.68 ), ( 6.69 ) and ( 6.70 ), the hypothesis on
@xmath and ( 6.2 ),

  -- -------- -- --------
     @xmath      (6.72)
  -- -------- -- --------

Jensen’s inequality and Proposition 6.2 together with ( 6.72 ) and the
inequality @xmath give

  -- -------- -- --------
     @xmath      (6.73)
  -- -------- -- --------

Summing ( 6.73 ) over @xmath , the law of total expectation gives

  -- -------- -- --------
     @xmath      (6.74)
  -- -------- -- --------

The lemma now follows by integrating ( 6.74 ) over @xmath from @xmath to
@xmath and using Lemma 6.5 and ( 6.66 ). ∎

###### Remark 6.19.

One may wonder whether one can simply calculate @xmath for every @xmath
and @xmath , using only the tools from Section 6.3 . This would require
fine estimates on the density of the point process formed by the
particles from tier @xmath hitting @xmath just before @xmath . These
estimates can be most easily obtained if one stops descendants of the
particles hitting @xmath at a (large) fixed time @xmath instead of the
line from Lemma 5.10 , with which the results in this paper would hold
as well. However, in order not to lose generality, we stick to Lemma
6.18 , which is enough for our purposes.

### 7 The B-BBM

We will now define properly the BBM with the moving barrier, also called
the B-BBM (the “B” stands for “barrier”), which will be used in the
subsequent sections to approximate the @xmath -BBM. We will still use
all the definitions from Section 6.1 , with one notational change:
Recall that by ( 6.20 ), we can decompose the process into two parts;
the first part consisting of the particles spawned by the ancestor of
the fugitive and the second part consisting of the remaining particles.
As in Section 6.4 , the quantities which refer to the particles of the
first part will be denoted by a bar (e.g. @xmath ) or check (e.g. @xmath
). The quantities of the second part will be denoted with a hat in this
section (e.g. @xmath ), in reference to the law @xmath from Section 6.3
.

#### 7.1 Definition of the model

Suppose that we are given a family @xmath of non-decreasing functions
@xmath , such that for each @xmath , @xmath for @xmath , @xmath and for
each @xmath small enough there exist @xmath , @xmath , such that

1.  [nolistsep]

2.  @xmath as @xmath ,

3.  @xmath for all @xmath ,

4.  @xmath for all @xmath and

5.  @xmath .

where @xmath is defined in ( 5.4 ). A family of functions with the above
properties exists, for example the following, which we will choose in
Sections 8 and 9 .

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

For every @xmath and @xmath , let @xmath be a (possibly random) finite
counting measure. We now define the B-BBM with initial configuration of
particles @xmath . Starting from BBM with constant drift @xmath with
initial configuration @xmath , we define for each @xmath a stopping time
@xmath and for each @xmath the barrier process @xmath as follows:

1.  We set @xmath .

2.  Denote by @xmath the time of the first breakout of the BBM absorbed
    at 0 and by @xmath the fugitive, as in Section 6.1 . We set @xmath
    for @xmath .

3.  Define @xmath and

      -- -------- -- -------
         @xmath      (7.2)
      -- -------- -- -------

    where @xmath if @xmath and @xmath otherwise. The above quantities
    are defined in Section 6.4 , after Corollary 6.16 .

4.  Define @xmath and @xmath . Note that @xmath and therefore also
    @xmath is a stopping time for the BBM. Now define

      -- -------- --
         @xmath   
      -- -------- --

    We then give to the particles an additional drift @xmath for @xmath
    , in the meaning of Section 5.1 .

5.  We have now defined @xmath , @xmath , @xmath and @xmath . We further
    define @xmath to be the measure formed by the particles at time
    @xmath , which have never hit @xmath . To define @xmath , @xmath ,
    @xmath and @xmath , we repeat the above steps with the process
    formed by the BBM started from those particles, with the definitions
    changed such that the barrier process starts at @xmath , time starts
    at @xmath etc.

6.  We now construct the barrier process @xmath from the pieces by
    @xmath , if @xmath .

Define the event @xmath . Recall the definition of the phrase “As @xmath
and @xmath go to infinity” from Section 6.1 . Define the predicate

-   (The law of) @xmath is such that @xmath as @xmath and @xmath go to
    infinity.

-   @xmath is deterministic and such that @xmath is verified.

Furthermore, if for some @xmath , @xmath for all @xmath and @xmath ,
then define the predicate

-   There exists @xmath , such that for all @xmath , @xmath as @xmath
    and @xmath go to infinity, with @xmath if @xmath .

###### Theorem 7.1.

Suppose (HB). Let @xmath and @xmath such that (Ht) is verified. Define
the process

  -- -------- --
     @xmath   
  -- -------- --

Then, as @xmath and @xmath go to infinity, the law of the vector @xmath
converges to the law of @xmath , where @xmath is the Lévy process from
Theorem 1.1 .

A stronger convergence than convergence in the sense of
finite-dimensional distributions is convergence in law with respect to
Skorokhod’s ( @xmath -)topology (see [ 78 , Chapter 3] ). Obviously, the
convergence in Theorem 7.1 does not hold in this stronger sense, because
the barrier is continuous but the Lévy process is not and the set of
continuous functions is closed in Skorokhod’s @xmath -topology ⁶ ⁶ 6 One
could prove convergence in the @xmath -topology (cf. [ 142 ,
Section 3.3] ), but the use of this less standard topology would lead us
away from our real goal: the proof of Theorem 1.1 . . However, if we
create artificial jumps, we can rectify this:

###### Theorem 7.2.

Suppose (HB). Define @xmath , if @xmath , for @xmath . Then as @xmath
and @xmath go to infinity, the process @xmath converges in law with
respect to Skorokhod’s topology to the Lévy process defined in the
statement of Theorem 7.1 .

For each @xmath , we define the event @xmath to be the intersection of
@xmath with the following events (see Section 6.1 for the definition of
@xmath ):

-   @xmath ,

-   @xmath and @xmath (for @xmath ),

-   @xmath and @xmath .

Note that @xmath for every @xmath .

The core of the proof of Theorems 7.1 and 7.2 will be the following
proposition:

###### Proposition 7.3.

Fix @xmath and define @xmath . There exists a numerical constant @xmath
, such that for large @xmath and @xmath , we have @xmath for every
@xmath and

  -- -- -- -------
           (7.3)
  -- -- -- -------

where @xmath is the cumulant from ( 1.1 ) and where @xmath and @xmath
may depend on @xmath .

#### 7.2 Proof of Proposition 7.3

First note that conditioning on @xmath , we can and will assume without
loss of generality that the hypothesis (HB @xmath ) holds and will only
state it again in the lemmas. In the same vein, we will always assume
that @xmath and @xmath are large and will omit stating this fact, except
again in the statements of the lemmas .

Furthermore, it is only necessary to treat the case @xmath , since the
rest can be obtained by induction: Suppose that we have shown the result
for @xmath . Since the process starts afresh at the stopping time @xmath
, we then have @xmath for every @xmath , which implies the statement on
the probability of @xmath . Similarly, if we set @xmath , where @xmath
is the term from ( 7.3 ), then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

because @xmath by ( 6.14 ). It follows that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

By induction, and the fact that @xmath , we then obtain ( 7.3 ).

Throughout the proof, we will work on several “good sets”, which we all
define here for easy reference, since they will be reused in the
following sections. For this reason, some of them (for example @xmath )
are actually more restrictive than what would be necessary for the proof
of Proposition 7.3 .

-   @xmath .

-   @xmath (the event @xmath was defined in ( 6.10 )).

-   @xmath .

-   @xmath (we define @xmath analogously to @xmath ).

-   @xmath .

-   @xmath (“nbab” stands for “no breakout after breakout”) is the event
    that no bar-particle breaks out between @xmath and @xmath and that
    no hat-, fug- or check-particle (fug-particles = descendants of
    @xmath ) hits @xmath between @xmath and @xmath .

Recall the definition of @xmath from Section 6.4 and set @xmath , such
that @xmath and the random variable @xmath is measurable with respect to
@xmath . Define further @xmath and @xmath analogously. Finally, define
@xmath .

###### The probability of @xmath.

###### Lemma 7.4.

Suppose (HB @xmath ). For large @xmath and @xmath , we have @xmath .

###### Proof.

By Proposition 6.2 and Lemma 6.18 , we have

  -- -------- -- -------
     @xmath      (7.4)
  -- -------- -- -------

Since @xmath for large @xmath by ( 6.1 ), Equation ( 7.4 ) and Markov’s
inequality applied to Lemma 6.17 yield

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

Furthermore, by ( 6.13 ), we have,

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

by ( 4.5 ), ( 6.2 ), ( 6.3 ) and ( 6.14 ).

In order to estimate the probability of @xmath , we will calculate
first- and second moments of the quantities in the definition of @xmath
. These estimates will be needed again later on, when we calculate the
Fourier transform of the variable @xmath .

By Lemma 6.9 and the hypotheses, together with ( 6.14 ), ( 6.2 ) and (
6.3 ),

  -- -------- -- -------
     @xmath      (7.7)
  -- -------- -- -------

which together with Lemma 6.12 gives

  -- -------- -- -------
     @xmath      (7.8)
  -- -------- -- -------

by the hypotheses on the initial configuration. Lemma 6.5 and ( 7.7 ),
together with ( 6.1 ), ( 6.4 ) and ( 6.15 ), now give

  -- -------- -- -------
     @xmath      (7.9)
  -- -------- -- -------

Similarly, ( 7.7 ) and ( 7.8 ) and Lemma 6.5 give

  -- -------- -- --------
     @xmath      (7.10)
  -- -------- -- --------

Furthermore, by Lemma 6.9 and Markov’s inequality, together with ( 6.3 )
and the hypotheses, we have

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

By the same arguments, and since @xmath by the definition of a breakout,
we have

  -- -------- -- --------
     @xmath      (7.12)
     @xmath      (7.13)
     @xmath      (7.14)
  -- -------- -- --------

be ( 6.3 ). Equations ( 7.11 ) and ( 7.14 ) and Chebychev’s inequality
applied to ( 7.10 ) and ( 7.13 ) together with ( 6.1 ) now give

  -- -------- -- --------
     @xmath      (7.15)
  -- -------- -- --------

The lemma now follows from ( 7.5 ), ( 7.6 ) and ( 7.15 ). ∎

###### The probability of @xmath.

###### Lemma 7.5.

We have @xmath for large @xmath and @xmath .

###### Proof.

Define @xmath . By Markov’s inequality, Lemmas 5.8 , and 5.9 and
Corollary 6.7 we have

  -- -------- --
     @xmath   
  -- -------- --

by the definition of @xmath , ( 6.2 ) and ( 6.3 ). Now, by Corollary
6.13 ,

  -- -------- --
     @xmath   
  -- -------- --

where we used the fact that @xmath by the definition of a breakout. By
Proposition 6.2 and the inequality @xmath , the probability conditioned
on @xmath and on @xmath that a check- or bar-particle breaks out between
@xmath and @xmath is now bounded by @xmath by ( 6.14 ) and ( 6.2 ). This
yields the lemma. ∎

###### The particles at the time @xmath. The probability of @xmath.

Recall that from the time @xmath on, we move the barrier according to
the function @xmath , which is equivalent to having the variable drift
@xmath . On @xmath , we have @xmath and @xmath . Furthermore, @xmath on
@xmath and by the hypotheses on the functions @xmath and ( 6.2 ) it
follows,

  -- -------- -- --------
     @xmath      (7.16)
  -- -------- -- --------

where @xmath is defined in ( 5.4 ).

###### Lemma 7.6.

Suppose (HB @xmath ). Then @xmath for large @xmath and @xmath .

###### Proof.

By Proposition 5.2 , Lemmas 5.1 and 7.5 , Corollaries 6.7 and 6.13 and (
7.16 ),

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

such that by Chebychev’s inequality and ( 6.2 ),

  -- -------- -- --------
     @xmath      (7.17)
  -- -------- -- --------

Furthermore, by Lemma 6.9 , Corollary 6.13 and Markov’s inequality, we
have

  -- -------- -- --------
     @xmath      (7.18)
  -- -------- -- --------

by ( 6.3 ) and ( 6.2 ). The lemma now follows from ( 7.17 ) and ( 7.18 )
together with Lemmas 7.4 and 7.5 . ∎

###### Remark 7.7.

Lemma 7.6 obviously still holds if one replaces @xmath by @xmath . This
will be needed in Sections 8 and 9 .

###### The Fourier transform of the barrier process.

Define @xmath and @xmath , which are independent random variables.
Recall that @xmath on @xmath . By ( 7.12 ) and Lemmas 6.18 and 7.4 , we
have

  -- -------- --
     @xmath   
  -- -------- --

such that with ( 7.9 ), we get,

  -- -------- -- --------
     @xmath      (7.19)
  -- -------- -- --------

Furthermore, ( 7.10 ) and ( 7.13 ) and the inequality @xmath yield

  -- -------- -- --------
     @xmath      (7.20)
  -- -------- -- --------

Equation ( 7.20 ) and ( 6.1 ) imply

  -- -------- -- --------
     @xmath      (7.21)
  -- -------- -- --------

Fix @xmath . Since @xmath , we have by ( 7.16 ), ( 7.21 ) and Lemma 7.4
,

  -- -------- -- --------
     @xmath      (7.22)
  -- -------- -- --------

for any @xmath . We will first study the term concerning @xmath . Write
@xmath and let @xmath be a real-valued constant with @xmath . Then,

  -- -------- -- --------
     @xmath      (7.23)
  -- -------- -- --------

where

  -- -------- --
     @xmath   
  -- -------- --

By definition of @xmath and @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

by ( 4.6 ), ( 6.2 ), ( 6.3 ), ( 6.14 ) and ( 6.13 ). It follows that

  -- -------- -- --------
     @xmath      (7.24)
  -- -------- -- --------

where we define @xmath for @xmath . Denote by @xmath its left-hand
derivative. Note that @xmath and @xmath for @xmath . By integration by
parts, ( 4.5 ) and ( 6.13 ), we have

  -- -------- -- --------
     @xmath      (7.25)
  -- -------- -- --------

Now, one readily sees that

  -- -------- -- --------
     @xmath      (7.26)
  -- -------- -- --------

where @xmath is as in the statement of Proposition 7.3 and @xmath is a
numerical constant. Equations ( 7.23 ), ( 7.24 ), ( 7.25 ) and ( 7.26 )
and the Taylor expansion of @xmath at @xmath now yield

  -- -- -- --------
           (7.27)
  -- -- -- --------

Coming back to ( 7.22 ), we have by the Taylor expansion of @xmath at
@xmath ,

  -- -------- -- --
     @xmath      
     @xmath      
     @xmath      
     @xmath      
  -- -------- -- --

where the last equation follows from Lemma 6.3 and the Taylor expansion
of @xmath at @xmath . This equation, together with ( 7.22 ) and ( 7.27 )
and the fact that @xmath is independent from @xmath , @xmath and @xmath
, yields ( 7.3 ) in the case @xmath .

#### 7.3 Proof of Theorems 7.1 and 7.2

We define the process @xmath by

  -- -------- --
     @xmath   
  -- -------- --

###### Proposition 7.8.

Suppose (HB). Then, as @xmath and @xmath go to infinity, the process
@xmath converges in law (with respect to Skorokhod’s topology) to the
Lévy process @xmath defined in Theorem 1.1 .

###### Proof.

Conditioning on @xmath , we can assume without loss of generality that
the initial configuration @xmath is deterministic and that @xmath is
verified. Denote by @xmath the natural filtration of the process @xmath
and note that @xmath . In order to show convergence of the
finite-dimensional distributions, it is enough to show (see
Proposition 3.1 in [ 107 ] or Lemma 8.1 in [ 78 ] , p. 225), that for
every @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (7.28)
  -- -------- -- --------

as @xmath and @xmath go to infinity. Now, define @xmath and @xmath ,
such that @xmath , by ( 6.1 ) and ( 6.14 ). Then we have by Proposition
7.3 ,

  -- -------- -- --------
     @xmath      (7.29)
  -- -------- -- --------

In total, we get for @xmath and @xmath large enough,

  -- -- --
        
  -- -- --

By Proposition 7.3 , this goes to @xmath as @xmath and @xmath go to
infinity, which proves ( 7.28 ).

In order to show tightness in Skorokhod’s topology, we use Aldous’
famous criterion [ 8 ] (see also [ 35 ] , Theorem 16.10): If for every
@xmath , every family of @xmath -stopping times @xmath taking only
finitely many values, all of which in @xmath and every @xmath with
@xmath as @xmath and @xmath go to infinity, we have

  -- -------- -- --------
     @xmath      (7.30)
  -- -------- -- --------

then tightness follows for the processes @xmath (note that the second
point in the criterion, namely tightness of @xmath for every fixed
@xmath , follows from the convergence in finite-dimensional
distributions proved above). Now let @xmath be such a stopping time and
let @xmath be the (finite) set of values it takes. We first note that
since @xmath for every @xmath , we have for every @xmath and every
@xmath and @xmath large enough,

  -- -------- -- --------
     @xmath      (7.31)
  -- -------- -- --------

by Proposition 7.3 . Moreover, since @xmath for every @xmath , we have
for every @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

which converges to @xmath as @xmath and @xmath go to infinity. This
implies ( 7.30 ) and therefore proves tightness in Skorokhod’s topology,
since @xmath was arbitrary. Together with the convergence in
finite-dimensional distributions proved above, the lemma follows. ∎

###### A coupling with a Poisson process.

Let @xmath be a sequence of independent exponentially distributed random
variable with mean @xmath . In order to prove convergence of the
processes @xmath and @xmath , we are going to couple the BBM with the
sequence @xmath in the following way: Suppose we have constructed the
BBM until time @xmath . Now, on the event @xmath , by Lemma 6.6 , the
strong Markov property of BBM and the transfer theorem ( [ 100 ] ,
Theorem 5.10), we can construct the BBM up to time @xmath such that
@xmath (recall that @xmath denotes the time of the first breakout after
@xmath ). On the event @xmath , we simply let the BBM evolve
independently of @xmath . Setting @xmath , there is by Lemma 6.6 and
Proposition 7.3 a @xmath , such that for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (7.32)
  -- -------- -- --------

Furthermore, we have @xmath on @xmath , whence for large @xmath and
@xmath ,

  -- -------- -- --------
     @xmath      (7.33)
  -- -------- -- --------

This construction now permits us to do the

###### Proof of Theorem 7.2.

Let @xmath denote the Skorokhod metric on the space of cadlag functions
@xmath (see [ 78 ] , Section 3.5). Let @xmath be the space of strictly
increasing, continuous, maps of @xmath onto itself. Let @xmath be
elements of @xmath . Then ( [ 78 ] , Proposition 3.5.3), @xmath as
@xmath if and only if for every @xmath there exists a sequence @xmath in
@xmath , such that

  -- -------- -- --------
     @xmath      (7.34)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (7.35)
  -- -------- -- --------

If @xmath is another sequence of functions in @xmath , with @xmath ,
then by the triangle inequality and the fact that @xmath is stable under
the operations of inverse and convolution, we have @xmath if and only if
there exists a sequence @xmath in @xmath , such that ( 7.34 ) holds and

  -- -------- -- --------
     @xmath      (7.36)
  -- -------- -- --------

For every @xmath and @xmath , we define the (random) map @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath and define @xmath . Then we have by the monotonicity of
@xmath ,

  -- -------- -- --------
     @xmath      (7.37)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (7.38)
  -- -------- -- --------

By Doob’s @xmath inequality and the fact that @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, on the set @xmath , we have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

In total, we get with ( 7.37 ) and ( 7.38 ), as @xmath and @xmath go to
infinity,

  -- -------- -- --------
     @xmath      (7.39)
  -- -------- -- --------

which is equivalent to

  -- -------- -- --------
     @xmath      (7.40)
  -- -------- -- --------

Now, suppose that @xmath and @xmath go to infinity along a sequence
@xmath and denote by @xmath , @xmath and @xmath the processes
corresponding to these parameters. By Proposition 7.8 and Skorokhod’s
representation theorem ( [ 35 ] , Theorem 6.7), there exists a
probability space, on which the sequence @xmath converges almost surely
as @xmath to the limiting Lévy process @xmath stated in the theorem.
Applying again the representation theorem as well as the transfer
theorem, we can transfer the processes @xmath and @xmath to this
probability space in such a way that the convergence in ( 7.40 ) holds
almost surely, which implies that the convergence in ( 7.39 ) holds
almost surely as well. By the remarks at the beginning of the proof, it
follows that on this new probability space,

  -- -------- --
     @xmath   
  -- -------- --

almost surely, as @xmath . This proves the theorem. ∎

###### Proof of Theorem 7.1.

Let @xmath be as in the statement of the theorem. By the virtue of
Theorem 7.2 , it suffices to show that

  -- -------- -- --------
     @xmath      (7.41)
  -- -------- -- --------

Suppose for simplicity that @xmath for all @xmath ; the proof works
exactly the same in the general case. Let @xmath , such that @xmath , by
( 6.14 ). By Chebychev’s inequality, we then have

  -- -------- -- --------
     @xmath      (7.42)
  -- -------- -- --------

Furthermore, define the intervals @xmath , @xmath and denote by @xmath
the point process on the real line with points at the positions @xmath .
Then @xmath is a Poisson process with intensity @xmath and thus,

  -- -------- -- --------
     @xmath      (7.43)
  -- -------- -- --------

We now have

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

Letting @xmath and @xmath go to infinity and using the hypothesis (HB)
yields ( 7.41 ) and thus proves the theorem. ∎

### 8 The B@xmath-Bbm

In this section, we define and study the B @xmath -BBM, which is
obtained from the B-BBM by killing some of its particles. It will be
used in Section 10 to bound the @xmath -BBM from below.

#### 8.1 Definition of the model

We will use throughout the notation from Section 7 . Furthermore, we fix
@xmath and @xmath such that @xmath , where @xmath was defined in ( 2.7
). Define @xmath , where @xmath . We will then use interchangeably the
phrases “as @xmath and @xmath go to infinity” and “as @xmath go to
infinity”. Furthermore, in the definition of these phrases (see Section
6.1 , @xmath and the function @xmath may now also depend on @xmath . The
symbols @xmath and @xmath have the same meaning as @xmath (see Section
5.1 ), except that they may depend on @xmath or @xmath and @xmath as
well, @xmath being defined later.

The B @xmath -BBM is then defined as follows: Given a possibly random
initial configuration @xmath of particles in @xmath , we let particles
evolve according to B-BBM with barrier function given by ( 7.1 ), where,
in addition, we colour the particles white and red as follows:
Initially, all particles are coloured white. As soon as a white particle
has @xmath or more white particles to its right, it is coloured red ⁷ ⁷
7 This can be ambiguous if there are more than one of the particles at
the same position, for example when the left-most particle branches. In
order to eliminate this ambiguity, induce for every @xmath a total order
on the particles in @xmath by @xmath iff @xmath or @xmath and @xmath
precedes @xmath in the lexicographical order on @xmath . Whenever there
are more than @xmath white particles, we then colour the particles in
this order, which is well defined. . Children inherit the colour of
their parent. At each time @xmath , @xmath , all the red particles are
killed immediately and the process goes on with the remaining particles.
See Figure 2.4 for a graphical description.

For an interval @xmath , we define the stopping line @xmath by @xmath if
and only if the particle @xmath gets coloured red at the time @xmath and
has been white up to the time @xmath , with @xmath . We then set @xmath
and @xmath by summing respectively @xmath and @xmath over the particles
of this stopping line. Furthermore, we define @xmath and @xmath to be
the subsets of @xmath formed by the red and white particles,
respectively, and define @xmath , @xmath , @xmath and @xmath
accordingly.

Let @xmath be the configuration of white particles at the time @xmath
and abuse notation by setting @xmath . We set @xmath and for each @xmath
, we define the event @xmath to be the intersection of @xmath with the
following events (we omit the braces).

-   @xmath ,

-   @xmath and @xmath (for @xmath ),

-   @xmath and @xmath .

-   @xmath .

The last event is of course uniquely defined up to a set of probability
zero. Note that @xmath for each @xmath . Furthermore, we define the
predicates

-   (The law of) @xmath is such that @xmath as @xmath and @xmath go to
    infinity.

-   @xmath is deterministic and such that @xmath holds.

-   @xmath is obtained from @xmath particles distributed independently
    according to the density proportional to @xmath .

We now state the important results on the B @xmath -BBM.

###### Lemma 8.1.

(HB @xmath ) implies (HB @xmath ) for large @xmath and @xmath .

###### Proposition 8.2.

Proposition 7.3 still holds for the B @xmath -BBM, with @xmath replaced
by @xmath . The same is true for Theorems 7.1 and 7.2 , with (HB)
replaced by (HB @xmath ).

Recall the definition of @xmath and @xmath from the introduction and of
(Ht) from Section 7 .

###### Proposition 8.3.

Suppose (HB @xmath ). Let @xmath satisfy (Ht) and let @xmath . As @xmath
and @xmath go to infinity,

  -- -------- --
     @xmath   
  -- -------- --

#### 8.2 Preparatory lemmas

In this section, we will establish some fine estimates for the number of
particles of the process, which will be used later to bound the number
of creations of red particles. If a particle @xmath satisfies @xmath for
some @xmath , we call it an “in between” particle (because it is in some
kind of intermediary stage) and otherwise a “regular” particle. We then
define

  -- -------- --
     @xmath   
  -- -------- --

The main lemma in this section is the following:

###### Lemma 8.4.

Suppose (HB @xmath ). Let @xmath . Then, for @xmath and every @xmath
there exists @xmath , such that for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, conditioned on @xmath , for @xmath , for large @xmath and
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

The following lemma about BBM conditioned not to break out will be used
many times in the proof:

###### Lemma 8.5.

Let @xmath be a barrier function, @xmath and suppose that @xmath . For
@xmath , define @xmath . Then, for all @xmath and for large @xmath and
@xmath ,

  -- -------- -- -------
     @xmath      (8.1)
     @xmath      (8.2)
  -- -------- -- -------

###### Proof.

By Lemma 5.9 , the upper bound of Lemma 6.8 is still valid with varying
drift (see also Remark 6.1 ). This gives,

  -- -------- -- -------
     @xmath      (8.3)
  -- -------- -- -------

where the second inequality follows from Lemma 5.10 . Equation ( 8.1 )
then follows from Lemma 5.4 and ( 8.3 ), noting that @xmath for large
@xmath , by the hypotheses on @xmath and @xmath .

For the second equation, suppose for simplicity that @xmath . By Lemma
6.10 , we have for all @xmath ,

  -- -------- -- -------
     @xmath      (8.4)
  -- -------- -- -------

Now, for large @xmath we have by ( 5.54 ) and Lemma 5.1 ,

  -- -------- -- -------
     @xmath      (8.5)
  -- -------- -- -------

With Lemmas 5.4 and 6.8 and ( 8.1 ), we have as in the proof of Lemma
5.5 , for any @xmath ,

  -- -------- -- -------
     @xmath      (8.6)
  -- -------- -- -------

Equations ( 8.5 ) and ( 8.6 ) together with Lemma 6.8 now give

  -- -- -- -------
           (8.7)
  -- -- -- -------

Moreover, we have

  -- -------- -- -------
     @xmath      (8.8)
  -- -------- -- -------

by ( 6.17 ) and Lemma 5.8 . Equation ( 8.2 ) now follows from ( 6.2 ), (
8.1 ), ( 8.4 ), ( 8.7 ) and ( 8.8 ). ∎

###### Corollary 8.6.

With the hypotheses from Lemma 8.5 , we have for large @xmath and @xmath
,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

This follows immediately from Lemmas 5.1 , 5.4 and 8.5 and Corollary 6.7
. ∎

###### Lemma 8.7.

Suppose (HB @xmath ). Let @xmath . For large @xmath and @xmath , we have
for every @xmath and @xmath ,

  -- -------- -- -------
     @xmath      (8.9)
  -- -------- -- -------

###### Proof.

Conditioned on @xmath , define @xmath . Then,

  -- -- -- --------
           (8.10)
  -- -- -- --------

and Lemma 8.5 now implies

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

Furthermore, by Corollary 8.6 ,

  -- -------- -- --------
     @xmath      (8.12)
  -- -------- -- --------

Equation ( 8.9 ) now follows from ( 8.11 ) and ( 8.12 ) together with
the conditional Chebychev inequality and the fact that @xmath on @xmath
. ∎

###### Proof of Lemma 8.4.

Assume @xmath . By the hypothesis on @xmath , the definition of @xmath ,
Proposition 5.3 and Corollary 6.7 , we have for large @xmath and @xmath
,

  -- -------- -- --------
     @xmath      (8.13)
  -- -------- -- --------

Moreover, we have by Lemma 8.5 ,

  -- -------- -- --------
     @xmath      (8.14)
  -- -------- -- --------

by the hypotheses on @xmath and @xmath . Equations ( 8.13 ) and ( 8.14 )
now give for large @xmath and @xmath , for all @xmath ,

  -- -------- -- --------
     @xmath      (8.15)
  -- -------- -- --------

Furthermore, by Lemma 8.5 and the hypotheses on @xmath and @xmath , we
have

  -- -------- -- --------
     @xmath      (8.16)
  -- -------- -- --------

Chebychev’s inequality, ( 8.15 ) and ( 8.16 ) yield the first equation
of the lemma.

Conditioned on @xmath , let @xmath . Define @xmath to be the number of
hat- and check-particles to the right of @xmath at time @xmath that have
not hit @xmath between @xmath and @xmath and likewise @xmath the number
of fug-particles with the same properties. Set @xmath , where @xmath .
Note that we have on @xmath : @xmath .

Define @xmath . By Lemma 5.1 and Proposition 5.3 , we have for large
@xmath and @xmath ,

  -- -------- -- --------
     @xmath      (8.17)
  -- -------- -- --------

by the definition of @xmath and @xmath . Furthermore, we have by
Proposition 5.3 and Lemma 5.1 , for large @xmath ,

  -- -------- -- --------
     @xmath      (8.18)
  -- -------- -- --------

Equations ( 8.17 ) and ( 8.18 ) now give,

  -- -------- -- --------
     @xmath      (8.19)
  -- -------- -- --------

Similarly, one has by Lemma 5.5 ,

  -- -- -- --------
           (8.20)
  -- -- -- --------

Equations ( 8.19 ) and ( 8.20 ) and the conditional Chebychev inequality
now yield for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

This, together with Lemma 8.7 and the fact that the hat-, fug- and
check-particles do not hit @xmath on @xmath finishes the proof of the
lemma. ∎

We finish this section with a result which fills the gap in Lemma 8.4
under the hypothesis (HB @xmath ).

###### Lemma 8.8.

Suppose (HB @xmath ). Then @xmath . Moreover, let @xmath . Then for
large @xmath and @xmath , we have for every @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and @xmath .

###### Proof.

Recall that initially, there are @xmath particles distributed
independently according to the density @xmath proportional to @xmath .
An elementary calculation yields that

  -- -------- -- --------
     @xmath      (8.21)
  -- -------- -- --------

This immediately yields the first statement, by Chebychev’s and Markov’s
inequalities. Moreover, ( 8.21 ) with Lemmas 5.8 and 5.9 yields

  -- -------- -- --------
     @xmath      (8.22)
  -- -------- -- --------

which gives the last statement. Note that on the event @xmath , the B
@xmath -BBM equals BBM with absorption at @xmath and @xmath . Since the
density @xmath is stationary w.r.t. this process, a quick calculation
shows that

  -- -------- -- --------
     @xmath      (8.23)
  -- -------- -- --------

Furthermore, by the independence of the initial particles and the law of
total variance,

  -- -------- -- --------
     @xmath      (8.24)
  -- -------- -- --------

where @xmath is a random variable distributed according to the density
@xmath and the outer variance and expectation are with respect to @xmath
. By Lemma 5.5 , we have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and a simple calculation then yields for @xmath ,

  -- -------- -- --------
     @xmath      (8.25)
  -- -------- -- --------

Moreover, by Lemma 5.4 and the hypothesis on @xmath , we have for every
@xmath ,

  -- -- --
        
  -- -- --

which yields

  -- -------- -- --------
     @xmath      (8.26)
  -- -------- -- --------

Equations ( 8.24 ), ( 8.25 ) and ( 8.26 ) now yield for large @xmath ,

  -- -------- -- --------
     @xmath      (8.27)
  -- -------- -- --------

The lemma now follows from ( 8.23 ) and ( 8.27 ), together with
Chebychev’s inequality. ∎

#### 8.3 The probability of @xmath

Most of the work in this section will be devoted to bounding the number
of creations of red particles. For this, we will discretize time: We set
@xmath and @xmath for all @xmath . Furthermore, define the @xmath
-measurable random variables @xmath and @xmath .

For an interval @xmath and @xmath , we now define

  -- -------- --
     @xmath   
  -- -------- --

the number of red particles created to the right of @xmath during the
time interval @xmath and set @xmath . Furthermore, we denote by @xmath
the number of white particles with positions @xmath at time @xmath ,
including the “in between particles”.

###### Lemma 8.9.

Suppose (HB @xmath ). Let @xmath , with @xmath . Then for every @xmath ,
for sufficiently small @xmath , there exists @xmath , such that for
large @xmath and @xmath , for every @xmath , if @xmath ,

  -- -------- -- --------
     @xmath      (8.28)
                 (8.29)
     @xmath      (8.30)
  -- -------- -- --------

Likewise, conditioned on @xmath , we have for @xmath ,

  -- -------- -- --------
     @xmath      (8.31)
     @xmath      (8.32)
  -- -------- -- --------

Finally, suppose (HB @xmath ). Then

  -- -------- -- --------
     @xmath      (8.33)
  -- -------- -- --------

###### Proof.

Define the stopping time @xmath , with @xmath . Define further the law
@xmath and the event @xmath , where @xmath . Then @xmath for every
@xmath , such that by Lemma 8.4 , we have

  -- -------- -- --------
     @xmath      (8.34)
  -- -------- -- --------

For @xmath , we can bound @xmath by the sum of

1.  [nolistsep]

2.  @xmath : the number of descendants at time @xmath of {the particles
    in @xmath which are to the right of @xmath },

3.  @xmath : the number of descendants of {the particles in @xmath which
    are to the left of @xmath } and which reach the point @xmath before
    the time @xmath and

4.  @xmath : the number of “in between” particles at time @xmath .

Conditioned on @xmath and the event @xmath , @xmath is stochastically
bounded by the number of individuals at time @xmath in a Galton–Watson
process with reproduction law @xmath and branching rate @xmath ,
starting from @xmath individuals. Let @xmath be such a process, then
@xmath is a martingale and by Doob’s @xmath -inequality, we get

  -- -------- -- --------
     @xmath      (8.35)
  -- -------- -- --------

By ( 8.35 ), Chebychev’s inequality and the hypothesis on @xmath , we
get,

  -- -------- -- --------
     @xmath      (8.36)
  -- -------- -- --------

Now, if @xmath , we have @xmath , so suppose that @xmath . Let the
random variable @xmath denote the number of particles in BBM which reach
@xmath before the time @xmath . Since there are at most @xmath white
particles to the left of @xmath at time @xmath , we have by Lemma 3.1 ,

  -- -------- -- --------
     @xmath      (8.37)
  -- -------- -- --------

where @xmath follows standard Brownian motion under @xmath . For each
@xmath , let @xmath be the contribution of the descendants of @xmath to
@xmath . By Lemma 3.5 ,

  -- -------- -- --------
     @xmath      (8.38)
  -- -------- -- --------

Trivially, @xmath and @xmath for any @xmath , @xmath . Together with (
8.37 ) and ( 8.38 ), this yields,

  -- -------- -- --------
     @xmath      (8.39)
  -- -------- -- --------

Chebychev’s inequality and the inequality @xmath now yields

  -- -------- -- --------
     @xmath      (8.40)
  -- -------- -- --------

As for @xmath , we have @xmath by Lemma 6.12 as well as Lemmas 5.8 , 6.8
and Corollary 6.7 , such that by the definition of a breakout event,

  -- -------- --
     @xmath   
  -- -------- --

Markov’s inequality then gives

  -- -------- -- --------
     @xmath      (8.41)
  -- -------- -- --------

Equations ( 8.34 ), ( 8.36 ), ( 8.40 ) and ( 8.41 ) now yield ( 8.29 ).
As for ( 8.28 ) and ( 8.30 ), we first note that the expected number of
individuals created until time @xmath in a Galton–Watson process with
reproduction law @xmath is bounded by the number of individuals at time
@xmath of a Galton–Watson process with reproduction law @xmath , whose
expectation is bounded by @xmath . This gives,

  -- -------- -- --------
     @xmath      (8.42)
  -- -------- -- --------

because there are at most @xmath white particles at the time @xmath and
the total number of in-between particles is bounded by @xmath by Lemmas
5.8 and 6.8 and Corollary 6.7 . As for the overshoot, i.e. the particles
that have been coloured red at the time @xmath , we first note that

  -- -------- -- --------
     @xmath      (8.43)
  -- -------- -- --------

Now,

  -- -------- -- --------
     @xmath      (8.44)
  -- -------- -- --------

By the definition of a breakout event, the set on the right-hand side of
( 8.44 ) contains no “in between” particles for @xmath . Furthermore,
the expected number of branching events of “regular” particles to the
right of @xmath is bounded by

  -- -------- -- --------
     @xmath      (8.45)
  -- -------- -- --------

where the inequality follows from ( 8.13 ). This yields,

  -- -------- -- --------
     @xmath      (8.46)
  -- -------- -- --------

where the last inequality follows from the Cauchy–Schwarz and Chebychev
inqualities. By ( 8.29 ), ( 8.42 ), ( 8.43 ) and ( 8.46 ) we finally get
for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (8.47)
  -- -------- -- --------

For the proof of ( 8.30 ), we note that on the set @xmath there are no
in-between particles during @xmath . Taking away the corresponding terms
in the above proof yields ( 8.30 ).

The proof of the other three equations is very similar. The proof of (
8.31 ) and ( 8.32 ) uses the second half of Lemma 8.4 instead of the
first and ( 8.12 ) in addition to ( 8.13 ) for the proof of ( 8.45 ).
The proof of the last equation draws on Lemma 8.8 instead of Lemma 8.4
and requires covering the interval @xmath by pieces of length @xmath . ∎

###### Corollary 8.10.

Suppose (HB @xmath ). For an interval @xmath , let @xmath be the event
that no particle is coloured red during the time interval @xmath and to
the right of @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Follows immediately from ( 8.29 ) and ( 8.32 ) by summing over the
intervals @xmath (note that @xmath on @xmath ). ∎

###### Lemma 8.11.

Suppose (HB @xmath ). Set @xmath and define the intervals @xmath and
@xmath For large @xmath and @xmath ,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

Now suppose (HB @xmath ). Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Lemma 8.9 , we have for every @xmath and @xmath ,

  -- -- -- --------
           (8.48)
  -- -- -- --------

by Lemma 6.5 and ( 6.3 ). Now, by integration by parts, we have for
every (possibly random) interval @xmath ,

  -- -------- -- --------
     @xmath      (8.49)
  -- -------- -- --------

The first equation in the statement of the lemma now follows from ( 8.48
) and ( 8.49 ), since @xmath and @xmath for @xmath . The remaining
equations follow similarly. ∎

The following lemma will only be needed in the proof of Proposition 8.3
.

###### Lemma 8.12.

Suppose (HB @xmath ). Let @xmath and @xmath . Then, for every @xmath ,
for large @xmath and @xmath ,

  -- -- --
        
  -- -- --

###### Proof.

For an interval @xmath , denote by @xmath the number of red particles to
the right of @xmath at time @xmath which have turned red during @xmath .
Define the event

  -- -------- --
     @xmath   
  -- -------- --

and note that @xmath for large @xmath and @xmath , by Corollary 8.10 ,
Lemma 6.9 and the hypothesis.

Write @xmath . If @xmath for some function @xmath with @xmath , then by
integration by parts,

  -- -------- --
     @xmath   
  -- -------- --

Define @xmath and @xmath . By ( 5.24 ), ( 5.25 ) and Corollary 6.7 , we
have for @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Similarly to the proof of Lemma 8.11 , we now have by the inequality
@xmath , for large @xmath and @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

by Lemma 8.9 and the definition of @xmath . As for the particles created
during @xmath , we have by Lemma 8.9 , the definition of @xmath and the
hypothesis on @xmath , for all @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Now, with ( 2.6 ), one easily sees that for large @xmath , @xmath for
all @xmath and @xmath , whence, by ( 2.9 ) and Fubini’s theorem, we get

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
              @xmath   
  -- -------- -------- --

In total, we have

  -- -------- --
     @xmath   
  -- -------- --

An application of Markov’s inequality finishes the proof. ∎

###### Lemma 8.13.

Suppose (HB @xmath ). Let @xmath be the event that the fugitive does not
get coloured red. Then, for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Set @xmath . Let @xmath be the law of BBM with absorption at zero from
Section 6 (i.e. we do not move the barrier when a breakout occurs). Let
@xmath be the first breakout of a red particle. Then

  -- -------- -- --------
     @xmath      (8.50)
  -- -------- -- --------

Define @xmath . Then, since @xmath is a stopping line, we have by
Proposition 6.2 and Corollary 8.10 ,

  -- -------- -- --------
     @xmath      (8.51)
  -- -------- -- --------

Recall that @xmath by hypothesis. By the tower property of conditional
expectation and ( 8.51 ), this gives

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The lemma now follows from ( 8.50 ) together with Lemma 8.11 , ( 6.1 )
and the hypothesis. ∎

###### Lemma 8.14.

Suppose (HB @xmath ). There exists a numerical constant @xmath , such
that for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Recall the event @xmath from Section 7 and change its definition
slightly by requiring that @xmath , call the new event @xmath . Define
the random variable

  -- -------- --
     @xmath   
  -- -------- --

By Proposition 7.3 and Remark 7.7 , it suffices to show that

  -- -------- --
     @xmath   
  -- -------- --

for some numerical constant @xmath .

Let @xmath , @xmath and @xmath as in Lemma 8.11 . We then have by
Markov’s inequality, Lemma 8.11 and Corollary 8.10 ,

  -- -------- -- --------
     @xmath      (8.52)
  -- -------- -- --------

Markov’s inequality applied to ( 8.52 ) then yields

  -- -------- -- --------
     @xmath      (8.53)
  -- -------- -- --------

Now define @xmath . Conditioned on @xmath and @xmath , on the set @xmath
, the particles from the stopping line @xmath then all spawn BBM
conditioned not to break out before @xmath (because the neither the
fugitive nor any in-between particles are on the stopping line). By
Lemma 8.11 , Lemma 6.9 and the tower property of conditional
expectation, we then have

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

By Lemma 6.9 , we now have

  -- -------- --
     @xmath   
  -- -------- --

and Lemma 8.11 and the tower property of conditional expectation give

  -- -------- -- --------
     @xmath      (8.54)
  -- -------- -- --------

Furthermore, by the hypothesis, Corollary 8.10 and Lemmas 7.4 , 7.5 and
8.13 , we have

  -- -------- -- --------
     @xmath      (8.55)
  -- -------- -- --------

The lemma now follows from ( 8.53 ), ( 8.55 ) and Markov’s inequality
applied to ( 8.54 ), together with ( 6.1 ). ∎

#### 8.4 Proofs of the main results

###### Proof of Lemma 8.1.

By Lemma 8.8 , it remains to estimate the probability of the last event
in the definition of @xmath . Define the random variable @xmath . By
Lemma 8.8 and Markov’s inequality applied to the last equation of Lemma
8.11 , we have @xmath . By Markov’s inequality, we then have

  -- -------- --
     @xmath   
  -- -------- --

Together with ( 8.22 ), this finishes the proof. ∎

###### Proof of Proposition 8.2.

Let @xmath . Conditioned on @xmath , the barrier process until @xmath is
by definition the same in B @xmath -BBM and B-BBM. Furthermore, @xmath
and @xmath . The first statement then follows by induction from Lemma
8.14 , as in the beginning of the proof of Proposition 7.3 .

As for the second statement, inspection of the proofs of Theorems 7.1
and 7.2 shows that they only rely on Proposition 7.3 and on the
existence of the coupling with a Poisson process constructed in Section
7.3 . But this construction only relied on the law of @xmath conditioned
on @xmath and @xmath and thus readily transfers to the B @xmath -BBM. ∎

###### Proof of Proposition 8.3.

Define @xmath , such that @xmath . Recall from Section 7.3 the coupling
of the process @xmath with a Poisson process @xmath of intensity @xmath
. As indicated above, this coupling can be constructed for the B @xmath
-BBM as well. In particular, setting @xmath , we have as in ( 7.32 ),
for every @xmath ,

  -- -------- -- --------
     @xmath      (8.56)
  -- -------- -- --------

by Proposition 8.2 (where @xmath is a numerical constant). Now let
@xmath satisfy (Ht). For simplicity, suppose that @xmath for all @xmath
, the proof of the general case is exactly the same. We want to show
that @xmath as @xmath and @xmath go to infinity. By ( 7.43 ), the
probability that there exists @xmath , such that @xmath and @xmath are
in the same interval @xmath is bounded by @xmath for large @xmath and
@xmath . We can therefore suppose that @xmath , the general case is a
straightforward extension.

It thus remains to show that for every @xmath , @xmath as @xmath and
@xmath go to infinity (the case @xmath is a straightforward
calculation). Let @xmath and @xmath . Then @xmath and @xmath , such that
@xmath (for this proof, we allow the constants @xmath and the expression
@xmath depend on @xmath ). Defining the event

  -- -------- --
     @xmath   
  -- -------- --

(define @xmath ) we then have by ( 7.43 ) and ( 8.56 ), @xmath .

We now prove by induction that there exists a numerical constant @xmath
, such that for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

as @xmath and @xmath go to infinity (we accept the abuse of notation
@xmath ). By definition, @xmath . Now, suppose the statement is true for
some @xmath . We then have for every @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

We first have, by the definition of @xmath and the fact that the process
starts afresh at the stopping time @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Second, we have again by the definition of @xmath ,

  -- -------- -- --------
     @xmath      (8.57)
  -- -------- -- --------

Write @xmath . For @xmath , we now have by Proposition 5.3 and Corollary
6.7 for the first inequality and Lemma 5.5 and Corollary 6.7 for the
second,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

such that

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

by Chebychev’s inequality applied to the first term and Lemma 8.12 to
the second. Altogether, this gives,

  -- -------- --
     @xmath   
  -- -------- --

for large @xmath and @xmath . Finally, we get @xmath for all @xmath ,
which yields @xmath for large @xmath and @xmath , by ( 6.1 ). This gives

  -- -------- --
     @xmath   
  -- -------- --

as @xmath and @xmath go to infinity. The statement follows. ∎

### 9 The B@xmath-Bbm

In this section, we define and study the B @xmath -BBM, a model which
will be used in Section 10 to bound the @xmath -BBM from above .

#### 9.1 Definition of the model

As in the previous section, we will use throughout the notation from
Section 7 and furthermore fix @xmath and define @xmath to be the
smallest number, such that @xmath and @xmath . We now define however
@xmath . Again, we will use interchangeably the phrases “as @xmath and
@xmath go to infinity” and “as @xmath go to infinity” and @xmath and the
function @xmath in the definition of these phrases may now also depend
on @xmath . The symbols @xmath and @xmath have the same meaning as in
the last section.

The B @xmath -BBM is then defined as follows: Given a possibly random
initial configuration @xmath of particles in @xmath , we let particles
evolve according to B-BBM with barrier function given by ( 7.1 ) and
with the following changes: Define @xmath and @xmath (note that these
definitions differ from those of Section 8 ). Colour all initial
particles white. When a white particle hits @xmath during the time
interval @xmath and has at least @xmath particles to its right, it is
killed immediately. If less than @xmath particles are to its right, it
is coloured blue and survives until the time @xmath , where all of its
descendants to the left of @xmath are killed and the remaining survive
and are coloured white again. At the time @xmath , the process starts
afresh. See Figure 2.5 for a graphical description.

For bookkeeping, we add a shade of grey to the white particles which
have hit 0 at least once (and call them hence the grey particles). We
then add the superscripts “nw”, “gr”, “blue” or “tot” to the quantities
referring respectively to the non-white, grey, blue or all the
particles. Quantities without this superscript refer to the white
particles.

In particular, we define @xmath and @xmath to be the number of white,
respectively, white and grey particles touching the left barrier during
the time interval @xmath with less than @xmath particles to their right
(i.e. those which are coloured blue). We set @xmath and @xmath .

Let @xmath be the configuration of (all) the particles at the time
@xmath and abuse notation by setting @xmath . We set @xmath and for each
@xmath , we define the event @xmath to be the intersection of @xmath
with the following events (we omit the braces).

-   @xmath ,

-   @xmath and @xmath (for @xmath ),

-   @xmath and @xmath ,

-   @xmath and for all @xmath with @xmath : @xmath ,

-   @xmath .

The last event is of course uniquely defined up to a set of probability
zero. Note that @xmath for each @xmath . Furthermore, we define the
predicates

-   (The law of) @xmath is such that @xmath as @xmath and @xmath go to
    infinity.

-   @xmath is deterministic and such that @xmath holds.

-   @xmath is obtained from @xmath particles distributed independently
    according to the density proportional to @xmath .

We now state the important results on the B @xmath -BBM.

###### Lemma 9.1.

(HB @xmath ) implies (HB @xmath ) for large @xmath and @xmath .

###### Proposition 9.2.

Proposition 7.3 still holds for the B @xmath -BBM, with @xmath replaced
by @xmath . The same is true for Theorems 7.1 and 7.2 , with (HB)
replaced by (HB @xmath ).

Recall the definition of @xmath and @xmath from the introduction and of
(Ht) from Section 7 .

###### Proposition 9.3.

Suppose (HB @xmath ). Let @xmath satisfy (Ht). Let @xmath . As @xmath
and @xmath go to infinity,

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 9.4.

Define a variant called C @xmath -BBM of the B @xmath -BBM by killing
blue particles only if there are at least @xmath particles to their
right. Then Propositions 9.2 and 9.3 hold for the C @xmath -BBM as well.

#### 9.2 Preparatory lemmas

We first derive upper bounds on the probability that the number of white
particles is less than @xmath at a given time @xmath . We do not impose
any particular condition on the initial configuration..

###### Lemma 9.5.

Let @xmath with @xmath and let @xmath . We have for small @xmath and for
@xmath and @xmath large enough,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By ( 5.24 ), Corollary 6.7 and the definition of @xmath , we have for
@xmath and @xmath large enough,

  -- -------- --
     @xmath   
  -- -------- --

By the conditional Chebychev inequality, we then have

  -- -------- --
     @xmath   
  -- -------- --

The lemma now follows from Lemma 5.5 and Corollary 6.7 ∎

###### Corollary 9.6.

Under the conditions of Lemma 9.5 , suppose furthermore that @xmath .
Then, for small @xmath and for @xmath and @xmath large enough,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

First condition on @xmath and apply Lemma 9.5 . Then condition on @xmath
and apply ( 5.14 ) and Corollary 6.7 . ∎

For @xmath , define the event

  -- -------- --
     @xmath   
  -- -------- --

and set @xmath . In using the last two results, the following lemma will
be crucial:

###### Lemma 9.7.

Suppose @xmath . Let @xmath and set @xmath . Then @xmath for large
@xmath and @xmath .

###### Proof.

Let @xmath and note that @xmath by ( 6.45 ). Define @xmath , which is a
supermartingale under @xmath by Lemma 5.11 , with @xmath by Corollary
6.7 . For large @xmath and @xmath , we then have by Doob’s @xmath
inequality,

  -- -------- --
     @xmath   
  -- -------- --

The lemma now follows from the previous equation, Proposition 5.2 and
Corollary 6.7 . ∎

The following lemma is the analogue of Lemma 9.5 for the system after
the breakout.

###### Lemma 9.8.

Let @xmath and let @xmath . Then, for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As in the proof of Lemma 8.4 , set @xmath , where @xmath . Recall that
on @xmath : @xmath . For a particle @xmath , we define @xmath and @xmath
to be the number of hat-, respectively, fug-particles which are not
descendants of @xmath and which have not hit @xmath after the time
@xmath .

Now, by Lemma 5.1 and Proposition 5.3 , we have for large @xmath and
@xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Moreover, by Lemma 5.10 , we have for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

In total, this gives for large @xmath and @xmath ,

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

Moreover, by Lemma 5.5 , we have for large @xmath and @xmath ,

  -- -------- -- -------
     @xmath      (9.2)
  -- -------- -- -------

by the definition of @xmath . Lemma 7.5 , ( 9.1 ) and ( 9.2 ) and the
conditional Chebychev inequality now yield the lemma. ∎

For a barrier function @xmath , let @xmath denote the law of BBM with
drift @xmath defined in ( 5.5 ) starting from a single particle at
@xmath . Let @xmath be the number of particles hitting @xmath before the
time @xmath and define @xmath , @xmath by summing @xmath , respectively
@xmath over the particles at time @xmath .

###### Lemma 9.9.

Let @xmath and @xmath be a barrier function. Then,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By Lemma 3.2 and Girsanov’s theorem, we have

  -- -------- --
     @xmath   
  -- -------- --

which implies the first two inequalities, since @xmath . As for the
third one, by Lemma 3.1 and again Girsanov’s theorem,

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, we have @xmath as in Lemma 5.9 . This finishes the proof of
the lemma. ∎

#### 9.3 The probability of @xmath

For an interval @xmath , we define the random variable @xmath counting
the number of particles hitting the origin during the time interval
@xmath :

  -- -------- --
     @xmath   
  -- -------- --

and set @xmath .

###### Lemma 9.10.

Let @xmath , @xmath , @xmath and @xmath . Furthermore, let @xmath be a
barrier function with @xmath . Then, for large @xmath and @xmath , we
have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Write @xmath . Define @xmath . As in the proof of Lemma 5.1 , we have
for every interval @xmath , @xmath and @xmath ,

  -- -------- -- -------
     @xmath      (9.3)
  -- -------- -- -------

by ( 2.12 ) and Corollary 6.7 . Lemma 2.1 and ( 9.3 ) now give,

  -- -------- -- -------
     @xmath      (9.4)
  -- -------- -- -------

Lemma 2.1 now gives for large @xmath ,

  -- -------- -- -------
     @xmath      (9.5)
  -- -------- -- -------

and by Lemmas 5.6 , 5.9 and 6.8 , Corollary 6.7 and ( 6.15 ), we have

  -- -------- -- -------
     @xmath      (9.6)
  -- -------- -- -------

The lemma now follows from ( 9.4 ), ( 9.5 ) and ( 9.6 ), together with
the hypothesis @xmath . ∎

The following lemma is crucial. It will permit to estimate the number of
particles turning blue upon hitting the origin.

###### Lemma 9.11.

Suppose that @xmath is deterministic with @xmath . Let @xmath and @xmath
. Write @xmath Then, for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

For an individual @xmath and @xmath , define @xmath , where @xmath is
the ancestor of @xmath at the time 0. By the trivial inequality @xmath
for every @xmath and by the independence of the initial particles,

  -- -- --
        
  -- -- --

The lemma now follows from Lemma 9.5 , since for every @xmath , we have
@xmath for large @xmath , by hypothesis. ∎

###### Before the breakout.

For every @xmath , define the (sub-probability) measure @xmath . The
following lemma gives an estimate on the number of white particles (not
counting the grey ones) turning blue during the interval @xmath .

###### Lemma 9.12.

For every @xmath with @xmath , we have for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath be the number of particles turning blue during @xmath and
which have not hit @xmath before @xmath and let @xmath . Lemmas 9.10 and
9.11 now yield,

  -- -------- --
     @xmath   
  -- -------- --

Proposition 5.2 now gives

  -- -------- -- -------
     @xmath      (9.7)
  -- -------- -- -------

As for the remaining particles, by the strong branching property,

  -- -------- --
     @xmath   
  -- -------- --

by Corollary 9.6 and Lemma 9.10 . Lemma 5.8 and ( 6.46 ) then give

  -- -------- -- -------
     @xmath      (9.8)
  -- -------- -- -------

by the hypothesis on @xmath . The lemma now follows from ( 9.7 ) and (
9.8 ). ∎

Up to now, we have only considered the white particles turning blue and
will now turn to @xmath , @xmath . For @xmath and @xmath , we define
@xmath to be the number of particles that turn blue at a time @xmath ,
have an ancestor that turned blue at a time @xmath , have none that has
hit 0 between @xmath and @xmath and have never hit @xmath between @xmath
and @xmath .

Let @xmath the event that no blue particle hits @xmath before @xmath and
@xmath the event that among the descendants of the particles counted by
@xmath , @xmath , no grey particle breaks out before @xmath (i.e. that
no particle that turned blue before @xmath has a grey descendent that
breaks out before @xmath ). Then set

  -- -------- --
     @xmath   
  -- -------- --

###### Lemma 9.13.

For every @xmath with @xmath and @xmath , we have for large @xmath and
@xmath ,

  -- -- --
        
  -- -- --

###### Proof.

Let @xmath be the stopping line consisting of the particles that turn
blue during @xmath , at the moment at which they turn blue (hence,
@xmath ). Note that @xmath , such that the descendants of @xmath and of
@xmath are independent, given their past, by the strong branching
property. Note also that @xmath , since by definition this @xmath -field
contains all the information about the descendents of the particles in
@xmath , @xmath . By Corollary 9.6 , we then have

  -- -------- -- -------
     @xmath      (9.9)
  -- -------- -- -------

where here @xmath . By Lemmas 9.9 and 9.10 , each summand in the
right-hand side of the above inequality is bounded by @xmath . The lemma
follows. ∎

###### Lemma 9.14.

For all @xmath with @xmath , we have for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (9.10)
  -- -------- -- --------

###### Proof.

By Lemma 9.12 , the statement is true for @xmath , because @xmath by
definition. Now we have for every @xmath , by Lemmas 9.12 and 9.13 and
the fact that @xmath on @xmath ,

  -- -------- -- --------
     @xmath      (9.11)
  -- -------- -- --------

The lemma now follows easily by induction over @xmath , since @xmath by
hypothesis. ∎

###### Lemma 9.15.

Suppose (HB @xmath ). For large @xmath and @xmath , we have @xmath for
every @xmath .

###### Proof.

Let @xmath . By definition, the event @xmath implies that a descendant
of a particle in @xmath hits @xmath before @xmath . Markov’s inequality
and Lemma 9.9 then imply,

  -- -------- -- --------
     @xmath      (9.12)
  -- -------- -- --------

by Lemma 9.14 . Furthermore, by Proposition 6.2 and Lemmas 9.9 and 9.14
, we have

  -- -------- -- --------
     @xmath      (9.13)
  -- -------- -- --------

by ( 6.14 ) and ( 6.2 ). By ( 9.12 ) and ( 9.13 ), we have for large
@xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

By induction over @xmath and the hypothesis, this gives for every @xmath
,

  -- -------- --
     @xmath   
  -- -------- --

Together with Lemma 9.7 , the statement follows. ∎

Define the random variable @xmath and note that @xmath for large @xmath
. Define the events @xmath and @xmath .

###### Lemma 9.16.

We have for large @xmath and @xmath ,

  -- -- --
        
  -- -- --

###### Proof.

By definition, @xmath . Lemmas 6.9 , 9.9 and 9.14 then give

  -- -- -- --------
           (9.14)
  -- -- -- --------

Similarly, we have

  -- -------- -- --------
     @xmath      (9.15)
  -- -------- -- --------

Finally, we have as in ( 9.14 ), by Lemmas 9.13 and 9.14 ,

  -- -- -- --------
           (9.16)
  -- -- -- --------

The lemma now follows from ( 9.14 ), ( 9.15 ) and ( 9.16 ), together
with Markov’s inequality. ∎

###### After the breakout.

We study now the system after the breakout. Recall that @xmath by
definition and define @xmath . We define @xmath and the event @xmath .
We denote by the superscript “gr @xmath " the quantities relative to
particles the descending from those that were grey before or at time
@xmath . Then let @xmath be the intersection of @xmath with the event
that none of these particles hits @xmath between @xmath and @xmath
before hitting 0. Define then the (sub-probability) measure @xmath .

###### Lemma 9.17.

For large @xmath and @xmath , @xmath and @xmath .

###### Proof.

On @xmath , we have @xmath for large @xmath and @xmath , in particular,
@xmath . By Lemmas 9.15 and 9.16 and ( 6.2 ), we then have for large
@xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

With Lemma 7.4 , this yields the first statement. For the second
statement, we have by Lemmas 5.8 and 5.9 ,

  -- -------- --
     @xmath   
  -- -------- --

Together with Lemma 7.5 , this implies the lemma. ∎

We change the notation of @xmath a bit: it is defined to be the number
of particles hitting @xmath during @xmath for the first time after
@xmath . In particular, we also count the descendants of the grey
particles at that time.

###### Lemma 9.18.

For large @xmath and @xmath , we have for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Define @xmath . We have for @xmath , as in Lemma 9.11 ,

  -- -------- --
     @xmath   
  -- -------- --

by Lemma 9.8 . By Lemma 9.10 , ( 6.1 ) and the definition of @xmath and
@xmath , this gives for large @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (9.17)
  -- -------- -- --------

Furthermore, by the independence of the check- and bar particles from
the others, we have by Lemmas 9.8 and 9.10 and by the inequality @xmath
, valid for every @xmath and @xmath large enough,

  -- -------- -- --------
     @xmath      (9.18)
  -- -------- -- --------

by ( 6.1 ) and the definition of @xmath . Similarly, we have for @xmath
,

  -- -------- -- --------
     @xmath      (9.19)
  -- -------- -- --------

and @xmath on the event @xmath . The lemma now follows from ( 9.17 ), (
9.18 ) and ( 9.19 ), together with ( 6.3 ) and ( 6.2 ). ∎

For @xmath , define @xmath to be the event that no descendant of a
particle which has been coloured blue between @xmath and @xmath hits
@xmath before @xmath .

###### Lemma 9.19.

We have for every @xmath and for large @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The proof is similar to the proof of Lemma 9.14 : Substituting Lemma 9.5
by Lemma 9.8 , one first shows that for every @xmath , one has

  -- -------- -- --------
     @xmath      (9.20)
  -- -------- -- --------

which, by a recurrence similar to ( 9.11 ), yields the lemma. ∎

###### Lemma 9.20.

For large @xmath and @xmath , @xmath

###### Proof.

Similarly to the proof of Lemma 9.15 , but using Lemmas 5.8 and 5.9
instead of Proposition 6.2 , we have for large @xmath and @xmath ,

  -- -- --
        
  -- -- --

where the last inequality follows from Lemma 9.19 and ( 6.3 ). The lemma
now follows by induction over @xmath . ∎

###### Lemma 9.21.

Suppose (HB @xmath ). Then @xmath for large @xmath and @xmath .

###### Proof.

By Lemma 9.5 , Corollary 9.6 and the union bound we have

  -- -------- -- --------
     @xmath      (9.21)
  -- -------- -- --------

Furthermore, by Lemma 9.8 , we have

  -- -------- -- --------
     @xmath      (9.22)
  -- -------- -- --------

by ( 6.3 ) and ( 6.2 ). Now, by Proposition 5.2 and Lemmas 9.9 and 9.17
,

  -- -------- -- --------
     @xmath      (9.23)
  -- -------- -- --------

by Lemma 9.19 . Similarly, we get

  -- -------- -- --------
     @xmath      (9.24)
  -- -------- -- --------

Moreover, we have by Lemma 9.19 ,

  -- -------- --
     @xmath   
  -- -------- --

Setting @xmath , we then have @xmath by Markov’s inequality. Applying
the Markov inequality once more to @xmath as in the proof of Lemma 8.1
yields

  -- -------- -- --------
     @xmath      (9.25)
  -- -------- -- --------

by ( 6.2 ). The lemma now follows from ( 9.21 ), ( 9.22 ) and ( 9.25 ),
Lemmas 9.17 and 9.20 and Markov’s inequality applied to ( 9.23 ) and (
9.24 ). ∎

#### 9.4 Proofs of the main results

###### Proof of Lemma 9.1.

The property about @xmath and @xmath follows as in the proof of Lemma
8.8 from ( 8.21 ). Moreover, again as in the proof of Lemma 8.8 , we
have by ( 8.21 ), ( 8.23 ) and ( 8.25 ), for every @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where we denote the initial particles by @xmath . By the independence of
the particles, we now have,

  -- -------- --
     @xmath   
  -- -------- --

by ( 8.21 ). Setting @xmath , we then have @xmath by Markov’s
inequality. Applying Markov’s inequality once more to @xmath as in the
proof of Lemma 8.1 yields the lemma. ∎

###### Proof of Proposition 9.2.

Exactly the same reasoning as in the proof of Proposition 8.2 , but
using Lemma 9.21 instead of Lemma 8.14 . ∎

###### Proof of Proposition 9.3.

Define @xmath , such that @xmath . As in the proof of Proposition 8.3
(see ( 8.57 )), it is enough to show that

  -- -- -- --------
           (9.26)
  -- -- -- --------

for large @xmath and @xmath . Let @xmath and @xmath . If @xmath , then
the above probability is bounded by @xmath by Proposition 6.2 . Suppose
therefore that @xmath and write @xmath . By definition, we have @xmath .
Let @xmath be the largest integer such that @xmath ; note that @xmath
for large @xmath . By Lemmas 6.9 and 6.12 together with Chebychev’s and
Markov’s inequalities, ( 6.2 ) and ( 6.1 ), we have for large @xmath and
@xmath ,

  -- -------- -- --------
     @xmath      (9.27)
  -- -------- -- --------

And as in the proof of Lemma 9.16 , the same holds for @xmath and @xmath
as well, which yields

  -- -------- -- --------
     @xmath      (9.28)
  -- -------- -- --------

Lemmas 5.8 and 9.9 and Corollary 6.7 then show that @xmath .

Let @xmath be the white and grey particles to the right of @xmath at
time @xmath which descend from the white and grey particles at time
@xmath and which have not hit @xmath between @xmath and @xmath . By
Proposition 5.3 and Corollary 6.7 , we have for large @xmath and @xmath
,

  -- -------- -------- -- --------
              @xmath      (9.29)
     @xmath   @xmath      (9.30)
  -- -------- -------- -- --------

Chebychev’s inequality and ( 9.28 ) then give for large @xmath and
@xmath ,

  -- -------- -- --------
     @xmath      (9.31)
  -- -------- -- --------

Furthermore, denote by @xmath the number of blue particles to the right
of @xmath at time @xmath which have turned blue after @xmath and which
have not hit @xmath between @xmath and @xmath . Then by Lemma 9.11 and (
9.3 ), we have

  -- -------- -- --------
     @xmath      (9.32)
  -- -------- -- --------

where we set @xmath . Note that @xmath . By Lemma 3.2 and Girsanov’s
theorem, we have now for every @xmath ,

  -- -------- -- --------
     @xmath      (9.33)
  -- -------- -- --------

where @xmath is the Gaussian density with variance @xmath . If @xmath ,
then @xmath , such that for every @xmath and @xmath ,

  -- -------- -- --------
     @xmath      (9.34)
  -- -------- -- --------

by Lemma 2.1 . Moreover, by Lemma 2.1 , we have @xmath for every @xmath
, such that

  -- -------- -- --------
     @xmath      (9.35)
  -- -------- -- --------

Equations ( 9.32 ), ( 9.33 ), ( 9.34 ) and ( 9.35 ) now yield

  -- -------- -- --------
     @xmath      (9.36)
  -- -------- -- --------

Furthermore, if @xmath denotes the particles to the right of @xmath at
time @xmath descending from those turning blue between @xmath and @xmath
, then by ( 9.33 ) and the supremum bound on @xmath ,

  -- -------- -- --------
     @xmath      (9.37)
  -- -------- -- --------

by Lemma 9.14 . Markov’s inequality applied to ( 9.37 ) and ( 9.36 )
together with ( 9.28 ), Lemmas 9.15 and 9.7 give

  -- -------- -- --------
     @xmath      (9.38)
  -- -------- -- --------

by ( 6.2 ). The statement now follows from ( 9.31 ), ( 9.38 ) and the
above-mentioned bound on @xmath . ∎

###### Proof of Lemma 9.4.

By definition, the B @xmath -BBM and C @xmath -BBM coincide until @xmath
on the set @xmath . By Proposition 9.2 , we have @xmath for some
numerical constant @xmath and by the coupling of @xmath with a Poisson
process of intensity @xmath , we have @xmath , as @xmath and @xmath go
to infinity. Propositions 9.2 and 9.3 then readily transfer to the C
@xmath -BBM. ∎

### 10 The @xmath-BBM: proof of Theorem 1.1

We will first establish a monotone coupling between the @xmath -BBM and
a class of slightly more general BBM with selection which includes the B
@xmath -BBM from Section 8 and the C @xmath -BBM from Lemma 9.4 . In a
second part, Theorem 1.1 is proven.

#### 10.1 A monotone coupling between @xmath-BBM and more general
particle systems

A selection mechanism for branching Brownian motion is by definition a
stopping line @xmath , which has the interpretation that if @xmath , we
think of @xmath being killed at the time @xmath . The set of particles
in the system at time @xmath then consists of all the particles @xmath ,
which do not have an ancestor which has been killed at a time @xmath ,
i.e. all the particles @xmath with @xmath .

Now suppose we have two systems of BBM with selection, the @xmath -BBM
and the @xmath -BBM, whose selection mechanisms satisfy the following
rules.

1.  [nolistsep]

2.  Only left-most particles are killed.

3.  @xmath -BBM: Whenever a particle gets killed, there are at least
    @xmath particles to its right (but not necessarily all the particles
    which have @xmath particles to their right get killed). @xmath -BBM:
    Whenever at least @xmath particles are to the right of a particle,
    it gets killed (but possibly more particles get killed).

Let @xmath , @xmath and @xmath be the counting measures of the particles
at time t in @xmath -BBM, @xmath -BBM and @xmath -BBM, respectively. On
the space of (finite) counting measures on @xmath we denote by @xmath
the usual stochastic ordering: For two counting measures @xmath and
@xmath , we write @xmath if and only if @xmath for every @xmath . If
@xmath and @xmath denote the atoms of @xmath and @xmath respectively,
then this is equivalent to the existence of an injective map ⁸ ⁸ 8 We
use the notation @xmath . @xmath with @xmath for all @xmath .
Furthermore, for two families of counting measures @xmath and @xmath ,
we write @xmath if @xmath for every @xmath . If @xmath and @xmath are
random, then we write @xmath if there exists a coupling between the two
(i.e. a realisation of both on the same probability space), such that
@xmath .

###### Lemma 10.1.

Suppose that @xmath . Then @xmath .

###### Proof.

We only prove the second inequality @xmath , the proof of the first one
is similar. By a coupling argument and conditioning on @xmath it is
enough to show it for deterministic @xmath and @xmath . Let @xmath and
let @xmath be a forest of independent BBM trees with the atoms of @xmath
as initial positions. We denote by @xmath the set of individuals alive ⁹
⁹ 9 The term “alive” has the same meaning here as in Section 3.1 . at
time @xmath and by @xmath the position of an individual @xmath . Denote
by @xmath the subset of individuals which form the @xmath -BBM
(i.e. those which have not been killed by the selection mechanism of the
@xmath -BBM). We set @xmath .

From the forest @xmath we will construct a family of forests @xmath (not
necessarily comprised of independent BBM trees), such that

-   [nolistsep]

-   if @xmath , then the forests @xmath and @xmath agree on the time
    interval @xmath ,

-   the initial positions in the forest @xmath are the atoms of @xmath ,

-   for every @xmath , the @xmath -BBM is embedded in @xmath up to the
    time @xmath , i.e. for @xmath , if @xmath denotes the set of
    individuals ¹⁰ ¹⁰ 10 Note that this does not depend on @xmath . from
    @xmath alive at time @xmath and @xmath the position of the
    individual @xmath , then there is a subset @xmath such that @xmath
    is equal in law to the empirical measure of @xmath -BBM,

-   for every @xmath , there exists a (random) injective map @xmath ,
    such that @xmath for every @xmath .

We will say that the individuals @xmath and @xmath are connected . If at
a time @xmath an individual @xmath is not connected to another
individual (i.e. @xmath ), we say that @xmath is free .

The construction of the coupling goes as follows: Since @xmath , we can
construct @xmath , @xmath and @xmath , such that for every @xmath we
have @xmath and the subtrees @xmath and @xmath are the same up to
translation. We now define a sequence of random times @xmath recursively
by @xmath and for each @xmath , we define @xmath to be the first time
after @xmath at which either

1.  [nolistsep]

2.  a particle of the @xmath -BBM branches, or

3.  the left-most particle of the @xmath -BBM dies without a particle of
    the @xmath -BBM branching.

We then set @xmath and @xmath for all @xmath . Now, let @xmath and
suppose that

-   [nolistsep]

-   @xmath and @xmath have been defined for all @xmath and are equal to
    @xmath and @xmath , respectively,

-   for each @xmath , the subtrees @xmath and @xmath are the same, up to
    translation.

Note that this is the case for @xmath . We now distinguish between the
two cases above, starting with the second:

Case 2: The left-most particle @xmath of the @xmath -BBM gets killed
without a particle of the @xmath -BBM branching. If @xmath is free,
nothing has to be done. Suppose therefore that @xmath is connected to a
particle @xmath of the @xmath -BBM. Then, since there are at most @xmath
remaining particles in the @xmath -BBM and there are at least @xmath
particles to the right of @xmath in the @xmath -BBM (otherwise it would
not have been killed), at least one of those particles is free. Denote
this particle by @xmath . We then “rewire” the particle @xmath to @xmath
by setting @xmath and define @xmath by replacing the subtree @xmath in
@xmath by @xmath , properly translated. Note that we then have

  -- -------- --
     @xmath   
  -- -------- --

where the first inequality follows from the fact that @xmath is the
left-most individual in @xmath -BBM at time @xmath and the second
inequality holds by hypothesis. See Figure 2.7 for a picture.

If more than one particle of the @xmath -BBM gets killed at the time
@xmath , we repeat the above for every particle, starting from the
left-most.

Case 1: A particle @xmath of the @xmath -BBM branches at time @xmath .
By the hypothesis b), the particle @xmath then branches as well into the
same number of children. We then define @xmath for each @xmath (recall
that @xmath denotes the number of children of @xmath ), i.e. we connect
each child of @xmath to the corresponding child of @xmath . Now first
define @xmath to be the restriction of @xmath to the surviving
particles. Then continue as in Case 2, i.e. for each particle @xmath of
the @xmath -BBM which gets killed and which is connected through @xmath
to a particle @xmath of the @xmath -BBM, rewire @xmath to a free
particle @xmath . In the end, we get @xmath .

In both cases, we then set @xmath and @xmath for each @xmath . Note that
each time we are rewiring a particle, we rewire it to a particle whose
subtree is independent of the others by the strong branching property,
whence the particles from @xmath and @xmath still follow the law of
@xmath -BBM and @xmath -BBM, respectively. Furthermore, we have for
every @xmath : @xmath for every @xmath . This finishes the proof. ∎

#### 10.2 Proof of Theorem 1.1

Let @xmath be measure-valued @xmath -BBM starting from the initial
condition

-   at time 0, there are @xmath particles independently distributed
    according to the density proportional to @xmath , where @xmath .

Recall the definitions from the introduction. Let @xmath . We wish to
show that the finite-dimensional distributions of the process

  -- -------- -- --------
     @xmath      (10.1)
  -- -------- -- --------

converge weakly as @xmath to those of the Lévy process @xmath stated in
Theorem 1.1 with @xmath . We will do this by proving seperately a lower
and an upper bound and show that in the limit these bounds coincide and
equal the Lévy process @xmath .

###### Lower bound.

Fix @xmath and @xmath . We will let @xmath and in parallel @xmath and
@xmath go to infinity (in the meaning of Section 7 ) in such a way that
@xmath and such that @xmath goes to infinity sufficiently slowly such
that the results from Section 8 hold. We then have with @xmath ,

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

Let @xmath be the measure-valued B @xmath -BBM starting from the initial
configuration (HB @xmath ), i.e. @xmath is obtained from @xmath
particles distributed independently according to the density
proportional to @xmath . An easy calculation now shows that @xmath for
large @xmath , by ( 10.2 ). Now, if @xmath denotes the barrier process
of the B @xmath -BBM, then @xmath is by definition an instance of the
@xmath -BBM. Lemma 10.1 now gives for large @xmath , @xmath , which by
definition implies

  -- -------- -- --------
     @xmath      (10.3)
  -- -------- -- --------

Given @xmath , we now define @xmath , such that @xmath for every @xmath
, as @xmath . We then have

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath            
              @xmath            
              @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

where the last inequality follows from Propositions 8.2 and 8.3 , with
@xmath being the Lévy process from the statement of Theorem 1.1 starting
from @xmath . Letting first @xmath , then @xmath yields the proof of the
lower bound.

###### Upper bound.

The proof is analogous to the previous case, relying on Propositions 9.2
and 9.3 instead of Propositions 8.2 and 8.3 . There are only two
differences to notice: First, the B @xmath -BBM is not a realisation of
the @xmath -BBM. However, the C @xmath -BBM (defined in Lemma 9.4 ) is
such a realisation and by that lemma, Propositions 9.2 and 9.3 hold for
the C @xmath -BBM as well. Second, if @xmath is distributed according to
(HB @xmath ), we do not have @xmath . However, if @xmath is obtained
from @xmath by killing the particles in the interval @xmath , then by (
10.2 ), a quick calculation shows that @xmath with high probability and
@xmath as @xmath goes to infinity. This finishes the proof of the upper
bound and of Theorem 1.1 .

### Acknowledgments

I wish to thank my PhD advisor Zhan Shi for his continuous support and
encouragements and Julien Berestycki for numerous discussions and his
interest in this work.

## Chapter 3 A note on stable point processes occurring in branching
Brownian motion

### 1 Introduction

Brunet and Derrida [ 54 , p. 18] asked the following question, which
arose during the study of the extremal particles in branching Brownian
motion: Let @xmath be a point process on @xmath , with the following
property they called “superposability”: @xmath is equal in law to @xmath
, where @xmath is an independent copy of @xmath , @xmath and @xmath is
the translation by @xmath . Is it true that @xmath can be obtained from
a Poisson process of intensity @xmath on @xmath by replacing each point
by independent copies of an auxiliary point process @xmath (they called
@xmath the “decoration”)? More precisely, can @xmath be written as

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

where @xmath are the atoms of the above-mentioned Poisson process and
@xmath are independent copies of @xmath and independent of @xmath ? This
question was answered in the affirmative by the author [ 116 ] , and
independently in the special case arising in branching Brownian motion
by Arguin, Bovier, Kistler [ 10 , 11 ] and Aïdékon, Berestycki, Brunet,
Shi [ 4 ] . The representation ( 1.1 ) was also shown for the branching
random walk by Madaule [ 114 ] , relying on the author’s result. See
also [ 98 ] for a related result concerning branching random walks.

Immediately after the article [ 116 ] was published on the arXiv, the
author was informed by Ilya Molchanov that the superposability property
had a classical interpretation in terms of stable point processes , and
the representation ( 1.1 ) was known in this field as the LePage series
representation of a stable point process.

The purpose of this note is two-fold: First, we want to outline how (
1.1 ) can be obtained via the theory of stability in convex cones.
Second, we give a succinct and complete proof of ( 1.1 ) and an
extension to random measures for easy reference.

### 2 Stability in convex cones

Let @xmath be the image (in the sense of measures) of @xmath by the map
@xmath (this was suggested by Ilya Molchanov), such that @xmath is a
point process on @xmath . By the superposability of @xmath , @xmath has
the following stability property : @xmath is equal in law to @xmath ,
where @xmath is an independent copy of @xmath , @xmath with @xmath and
@xmath is the image of @xmath by the map @xmath . If @xmath is a simple
point process, one can see the collection of points of the point process
@xmath as a random closed subset of @xmath , and the stability property
is then also known as the union-stability for random closed sets (see
e.g. [ 119 , Ch. 4.1] ).

Davydov, Molchanov and Zuyev [ 70 ] have introduced a very general
framework for studying stable distributions in convex cones , where a
convex cone @xmath is a topological space equipped with two continuous
operations: addition (i.e. a commutative and associative binary
operation @xmath with neutral element @xmath ) and multiplication by
positive real numbers. Furthermore, the two operations must distribute
and @xmath be a complete separable metric space. For example, the space
of compact subsets of @xmath containing the origin is a convex cone,
where the addition is the union of sets and the multiplication by @xmath
is the image of the set by the map @xmath (see Example 8.11 in [ 70 ] ).
Furthermore, it is a pointed cone , in the sense that there exists a
unique origin @xmath , such that for each compact set @xmath , @xmath as
@xmath (the origin is of course @xmath ). The existence of the origin
permits to define a norm by @xmath , with @xmath the Hausdorff distance
in @xmath . An example of a convex cone without origin (Example 8.23 in
[ 70 ] ) is the space of measures on @xmath equipped with the usual
addition of measures and multiplication by @xmath being defined as the
image of the measure by the map @xmath , as above.

A random variable @xmath with values in @xmath is now called @xmath
-stable if @xmath is equal in law to @xmath for every @xmath , where
@xmath is an independent copy of @xmath and @xmath . With the theory of
Laplace transforms and infinitely divisible distributions on semigroups
(the main reference to this subject is [ 25 ] ), the authors of [ 70 ]
then show that to every @xmath -stable random variable @xmath there
corresponds a Lévy measure @xmath which is homogeneous of order @xmath ,
i.e. @xmath for any Borel set @xmath . Actually, @xmath is a priori only
defined on a certain dual of @xmath , and a considerable part of the
work in [ 70 ] is to give conditions under which @xmath is supported by
@xmath itself. These conditions are satisfied for the first example
given above, but not for the second, since they require in particular
that the cone be pointed. Moreover, and this is their most important
result, under some conditions satisfied by the first example, @xmath can
be expressed as its LePage series , i.e. the sum over the points of the
Poisson process with intensity measure @xmath .

In order to get to the decomposition ( 1.1 ), one must then disintegrate
the homogeneous Lévy measure @xmath into a radial and an angular
component, such that @xmath for @xmath and some measure @xmath on the
unit sphere @xmath . This is also called the spectral decomposition and
@xmath is called the spectral measure . If @xmath has mass 1, then the
LePage series can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are the atoms of a Poisson process of intensity @xmath and
@xmath are iid according to @xmath , independent of the @xmath . This is
exactly the decomposition ( 1.1 ).

### 3 A succinct proof of the decomposition (1.1)

As mentioned in the introduction, we will give here a short proof of the
decomposition ( 1.1 ) and its extension to random measures. We hope that
this proof will be more accessible to probabilists who are not familiar
with the methods used in [ 70 ] . Furthermore, the results in [ 70 ]
cannot be directly applied to give the extension of ( 1.1 ) to random
measures, such that it may be of interest to give a rigorous proof in
that setting.

#### 3.1 Definitions and notation

We denote by @xmath the space of boundedly finite measures on @xmath ,
i.e. measures, which assign finite mass to every bounded Borel set in
@xmath , and by @xmath the subspace of counting measures. It is known
(see e.g. [ 66 ] , p. 403ff) that there exists a metric @xmath on @xmath
which induces the vague topology and under which @xmath is complete and
separable (but not locally compact). We further set @xmath , which is an
open subset and hence a complete separable metric space as well ( [ 42 ]
, IX.6.1, Proposition 2), when endowed with the metric @xmath ,
equivalent to @xmath on @xmath . The spaces @xmath and @xmath are closed
subsets of @xmath and @xmath , and therefore complete separable metric
spaces as well ( [ 42 ] , IX.6.1, Proposition 1).

For every @xmath , we define the translation operator @xmath , by @xmath
for every Borel set @xmath . Furthermore, we define the function @xmath
by

  -- -------- --
     @xmath   
  -- -------- --

Note that if @xmath , then @xmath is the position of the right-most atom
of @xmath , i.e. @xmath . It is easy to show that the maps @xmath and
@xmath are continuous, hence measurable.

A random measure @xmath on @xmath is a random variable taking values in
@xmath . If @xmath takes values in @xmath , we also call @xmath a point
process . For every non-negative measurable function @xmath , we define
the cumulant

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . The cumulant uniquely characterises @xmath ( [ 66 ] ,
p. 161).

###### Theorem 3.1.

Let @xmath be a random measure and let @xmath be its cumulant. Then
@xmath is superposable if and only if for every measurable non-negative
function @xmath ,

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

for some constant @xmath and some measure @xmath on @xmath , such that

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

for every bounded Borel set @xmath . Moreover, @xmath can be chosen such
that @xmath , and as such, it is unique unless @xmath almost surely.

###### Corollary 3.2.

A point process @xmath is superposable if and only if it has the
representation ( 1.1 ) for some point process @xmath satisfying

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

If @xmath , then there exists a unique pair @xmath , such that @xmath .

#### 3.2 Infinitely divisible random measures

Our proof is based on the theory of infinitely divisible random measures
as exposed in Kallenberg [ 99 ] . A random measure @xmath is said to be
infinitely divisible if for every @xmath there exist iid random measures
@xmath such that @xmath is equal in law to @xmath . It is said to be
infinitely divisible as a point process, if @xmath can be chosen to be a
point process. Note that a (deterministic) counting measure is
infinitely divisible as a random measure but not as a point process.

The main result about infinitely divisible random measures is the
following (see [ 99 ] , Theorem 6.1 or [ 67 ] , Proposition 10.2.IX,
however, note the error in the theorem statement of the latter
reference: @xmath may be infinite as it is defined).

###### Fact 3.3.

The random measure @xmath is infinitely divisible if and only if

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath is a measure on @xmath satisfying

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

for every bounded Borel set @xmath .

The probabilistic interpretation ( [ 99 ] , Lemma 6.5) of this fact is
that @xmath is the superposition of the non-random measure @xmath and of
the atoms of a Poisson process on @xmath with intensity @xmath , which
is exactly the representation of @xmath as the LePage series mentioned
in Section 2 . It has the following analogous result in the case of
point processes ( [ 67 ] , Proposition 10.2.V), where the measure @xmath
is also called the KLM measure .

###### Fact 3.4.

A point process @xmath is infinitely divisible as a point process if and
only if @xmath and @xmath is concentrated on @xmath , where @xmath and
@xmath are the measures from Fact 3.3 . Then, ( 3.4 ) is equivalent to
@xmath for every bounded Borel set @xmath .

In particular, the Lévy/KLM measure of a Poisson process on @xmath with
intensity measure @xmath is the image of @xmath by the map @xmath .

#### 3.3 Proof of Theorem 3.1

We can now prove Theorem 3.1 and Corollary 3.2 . For the “if” part, we
note that ( 3.2 ) implies ( 3.4 ) for the measure @xmath , such that the
process with cumulant given by ( 3.1 ) exists. The superposability is
readily verified. Further note that for point processes the condition (
3.3 ) is equivalent to ( 3.2 ).

It remains to prove the “only if” parts. Let @xmath be a superposable
random measure. Then, for @xmath , such that @xmath , we have

  -- -- --
        
  -- -- --

Setting @xmath for @xmath (with @xmath ) and replacing @xmath by @xmath
in the above equation, we get @xmath for all @xmath , or @xmath for all
@xmath . This is the famous Cauchy functional equation and since @xmath
is by definition non-negative on @xmath , it is known and easy to show [
68 ] that @xmath for all @xmath . As a consequence, we obtain the
following corollary:

###### Corollary 3.5.

@xmath for all @xmath .

Furthermore, it is easy to show that superposability implies infinite
divisibility. We then have the following lemma.

###### Lemma 3.6.

Let @xmath be the measures corresponding to @xmath by Fact 3.3 .

1.   [nolistsep]

2.   There exists a constant @xmath , such that @xmath .

3.   For every @xmath , we have @xmath in the sense of Radon-Nikodym
    derivatives.

4.  @xmath for @xmath -almost every @xmath .

###### Proof.

The measures @xmath , @xmath are the measures corresponding to the
infinitely divisible random measure @xmath by Fact 3.3 . But by
Corollary 3.5 , the measures @xmath and @xmath correspond to @xmath , as
well. Since these measures are unique, we have @xmath and @xmath . The
second statement follows immediately. For the first statement, note that
@xmath , since @xmath is a bounded set. It follows that

  -- -------- --
     @xmath   
  -- -------- --

hence @xmath for every @xmath . The first statement of the lemma
follows. For the third statement, let @xmath and @xmath . By ( 3.4 ), we
have

  -- -------- --
     @xmath   
  -- -------- --

By monotonicity, the first integral is greater than or equal to @xmath
for every @xmath , hence @xmath for some constant @xmath . By the second
statement, it follows that

  -- -------- --
     @xmath   
  -- -------- --

for every @xmath . Hence, @xmath . By the Borel-Cantelli lemma,

  -- -------- --
     @xmath   
  -- -------- --

which implies @xmath . ∎

###### Lemma 3.7.

The measure @xmath admits the decomposition @xmath , where @xmath is a
unique measure on @xmath with @xmath which satisfies ( 3.2 ).

###### Proof.

We follow the proof of Proposition 4.2 in [ 130 ] . Set @xmath , which
is a closed subset of @xmath , and therefore a complete seperable metric
space ( [ 42 ] , IX.6.1, Proposition 1). By the continuity of @xmath ,
the map @xmath defined by @xmath is a Borel isomorphism, i.e. it is
bijective and @xmath and @xmath are measurable. The translation operator
@xmath then acts on @xmath by @xmath . If @xmath , then @xmath for every
@xmath by ( 3.4 ). By the theorem on the existence of conditional
probability distributions (see e.g. [ 100 ] , Theorems 5.3 and 5.4)
there exists then a measure @xmath on @xmath with @xmath for every
@xmath and a measurable kernel @xmath , with @xmath for every @xmath ,
such that

  -- -------- --
     @xmath   
  -- -------- --

Moreover, we can assume in the above construction that @xmath for every
@xmath and @xmath , and with this normalization, @xmath is unique. By
Lemma 3.6 , we now have @xmath for every @xmath and @xmath . As in the
proof of the first statement of Lemma 3.6 , we then conclude that @xmath
for some constant @xmath , and by the above normalization, @xmath .
Setting @xmath then gives

  -- -------- --
     @xmath   
  -- -------- --

which finishes the proof. ∎

The “only if” part of Theorem 3.1 now follows from the previous lemmas.
If @xmath is a point process, then Fact 3.4 implies that @xmath and that
@xmath is concentrated on @xmath , hence @xmath as well. Equation ( 3.2
) then implies that @xmath for any bounded Borel set @xmath . In
particular, this holds for @xmath . But since @xmath implies @xmath and
since @xmath is concentrated on @xmath , it has finite mass. If @xmath
has mass zero, then @xmath almost surely. If @xmath has positive mass,
set @xmath . The measure @xmath is then a probability measure and @xmath
. Furthermore, @xmath satisfies ( 1.1 ), where @xmath follows the law
@xmath . Uniqueness of the pair @xmath follows from Lemma 3.7 . This
finishes the proof of Corollary 3.2 .

#### 3.4 Finiteness of the intensity

If @xmath is a superposable point process and has finite intensity (i.e.
@xmath for every bounded Borel set @xmath ), then it is easy to show
that the intensity is proportional to @xmath . However, in the process
which occurs in the extremal particles of branching Brownian motion or
branching random walk, the intensity of the decoration grows with @xmath
, as @xmath [ 54 , Section 4.3] . The following simple result shows that
in these cases, @xmath does not have finite intensity.

###### Proposition 3.8.

Let @xmath be defined as in ( 1.1 ). Then @xmath has finite intensity if
and only if @xmath .

###### Proof.

By Tonelli’s theorem,

  -- -------- --
     @xmath   
  -- -------- --

for every bounded Borel set @xmath . Again by Tonelli’s theorem we have

  -- -- --
        
  -- -- --

For @xmath , @xmath implies @xmath . Since @xmath is decreasing, we
therefore have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the Lebesgue measure of @xmath . We conclude that
@xmath if and only if @xmath ∎
