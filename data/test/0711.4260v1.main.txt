##### Definition 3.4.1.

A function @xmath is called a classical solution of eq. ( 3.2 ) if it is
continuously differentiable and satisfies eq. ( 3.2 ) (in particular we
must have @xmath ).

##### Well–posedness

In order to obtain a reasonable Cauchy problem we require eq. ( 3.2 ) to
possess the following property: For given initial data there exists a
unique solution which depends continuously on the data. This assumption
is usually referred to as well–posedness. Now we give the precise
definition.

###### Definition 3.4.2.

The abstract evolution problem ( 3.2 ) is said to be well–posed if for
every @xmath there exists a unique classical solution @xmath of eq. (
3.2 ) such that for each fixed @xmath the mapping @xmath is uniformly
continuous in @xmath on compact intervals @xmath , @xmath .

We remark that there is no overall standard and different definitions of
well–posedness might be found in the literature, e.g. one sometimes
includes growth bounds for the solution. In this sense our requirements
are weaker.

##### Well–posedness and semigroups

Suppose @xmath generates a strongly continuous semigroup @xmath on
@xmath satisfying @xmath where @xmath is a continuous positive function.
Let @xmath . Then the unique classical solution @xmath of eq. ( 3.2 ) is
given by @xmath (recall that @xmath for all @xmath if @xmath ).
Moreover, we have @xmath and therefore, the mapping @xmath is uniformly
continuous in @xmath on each @xmath , @xmath . Hence, if @xmath
generates a strongly continuous semigroup @xmath satisfying @xmath then
the abstract Cauchy problem eq. ( 3.2 ) is well–posed.

Furthermore, the existence of a semigroup extends the notion of a
solution of eq. ( 3.2 ). Since @xmath is defined for general @xmath and
not only for @xmath we can define (generalized) solutions @xmath of eq.
( 3.2 ) by @xmath for @xmath .

#### 3.4.4 Second Order Cauchy Problems

##### Reduction to first order system

We are concerned with wave equations and hence it is desireable to have
a semigroup formulation for second order Cauchy problems. This can be
achieved by the usual reduction of a second order equation to a first
order system. Consider informally the Cauchy problem

  -- -------- --
     @xmath   
  -- -------- --

This second order equation can be rewritten as the first order system

  -- -------- --
     @xmath   
  -- -------- --

with initial data @xmath .

##### Function spaces

We have avoided a precise consideration of the involved function spaces
because this issue can be very subtle. Instead we will prove a
generation result for the case when @xmath satisfies certain additional
conditions which will be enough for our purposes. However, higher order
Cauchy problems on Banach spaces have been systematically investigated
and we refer to [ 20 ] and [ 58 ] for more information.

## Chapter 4 Self–Adjoint Operators

We continue collecting mathematical prerequisites. In the first part of
this chapter we note some important properties of self–adjoint
operators. Then we turn to Sturm–Liouville theory which deals with
self–adjoint operators that are generated by symmetric ordinary
differential expressions of second order.

### 4.1 Properties of Self–Adjoint Operators

We recall some well–known properties of general self–adjoint operators.
Everything in this section can be found in standard textbooks, e.g. [ 26
] , [ 59 ] .

#### 4.1.1 The Square Root

Let @xmath be a self–adjoint operator on a Hilbert space @xmath . Then,
for @xmath , we have @xmath and hence, @xmath for all @xmath . @xmath is
said to be nonnegative if @xmath for all @xmath . For a nonnegative
operator @xmath there exists a square root @xmath with nice properties.

###### Theorem 4.1.1.

Let @xmath be a Hilbert space and @xmath a self–adjoint operator which
satisfies @xmath for all @xmath . Then, there exists a unique
self–adjoint operator @xmath such that @xmath is a core of @xmath ,
@xmath and @xmath for all @xmath . Moreover, @xmath whenever @xmath for
@xmath , i.e. @xmath commutes with any bounded operator that commutes
with @xmath .

###### Proof.

The claim follows from [ 26 ] , p. 281 Theorem 3.35 together with [ 26 ]
, p. 279, Problem 3.32. ∎

In connection with the square root we note the following triviality
which will be useful later on.

###### Lemma 4.1.1.

Let @xmath be a nonnegative self–adjoint operator on a Hilbert space
@xmath . If @xmath for some @xmath and all @xmath then @xmath for all
@xmath .

###### Proof.

From @xmath we conclude that @xmath for all @xmath . Let @xmath . Since
@xmath is a core for @xmath by Theorem 4.1.1 , there exists a sequence
@xmath such that @xmath in @xmath and @xmath in @xmath . We have @xmath
for all @xmath and hence, this inequality remains valid in the limit
@xmath . ∎

###### Remark 4.1.1.

A self–adjoint operator @xmath satisfying @xmath for all @xmath and some
@xmath is called semibounded from below .

#### 4.1.2 Boundedness of the Spectrum

For self–adjoint operators there exists an important connection between
semiboundedness and boundedness of the spectrum similar to the finite
dimensional case. The following result makes it possible to deduce
inequalities by studying spectra.

###### Proposition 4.1.1.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath and
@xmath . Then, @xmath for all @xmath if and only if @xmath .

###### Proof.

See [ 26 ] , p. 278. ∎

### 4.2 Sturm–Liouville Operators

In this section we review some aspects of Sturm–Liouville theory. We
will also give proofs for most of the results stated below since they
are very instructive. For more detailed expositions see e.g. [ 39 ] , [
54 ] .

#### 4.2.1 Basic Definitions

##### Absolutely continuous functions

We introduce a new function space which turns out to be useful in
connection with ordinary differential operators. Let @xmath . Then,
@xmath if there exists a function @xmath and a @xmath such that @xmath
for all @xmath . In particular, it follows that @xmath is continuous and
possesses a weak derivative given by @xmath . Clearly, @xmath is a
vector space and it is called the space of absolutely continuous
functions . As usual, the local version @xmath is defined as @xmath .

##### Sturm–Liouville operators

A Sturm–Liouville operator is generated by a formal differential
expression @xmath of the form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , @xmath and @xmath is a weight function.

Formal integration by parts yields the Green’s formula

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

for any @xmath where @xmath .

##### The initial value problem

Consider the equation

  -- -------- --
     @xmath   
  -- -------- --

on @xmath for a complex parameter @xmath . The assumptions on @xmath are
sufficient to guarantee existence and uniqueness of the initial value
problem. More precise, we have the following theorem.

###### Theorem 4.2.1.

Let @xmath and @xmath . Then, there exists a unique function @xmath with
@xmath such that @xmath and @xmath , @xmath . Moreover, the function
@xmath is holomorphic on @xmath for any @xmath .

The proof is similar to the classic Picard–Lindelöf theorem and can be
found e.g. in [ 39 ] .

##### The maximal operator

We set @xmath and define the maximal operator @xmath associated to
@xmath by

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for @xmath . Note that functions @xmath in @xmath satisfy the
minimal requirements to give sense to @xmath and to guarantee @xmath as
well as @xmath . That is why @xmath is called the maximal operator. Note
further that @xmath implies the existence of

  -- -------- --
     @xmath   
  -- -------- --

as follows from the Green’s formula eq. ( 4.1 ).

##### Endpoint classification

The endpoint @xmath of the interval @xmath is classified as follows.

-   The endpoint @xmath is said to be regular if @xmath and there exists
    a @xmath such that @xmath .

-   @xmath is said to be in the limit–circle case if there exist @xmath
    such that @xmath .

-   Finally, @xmath is said to be in the limit–point case if @xmath for
    all @xmath .

An analogous classification is applied to @xmath .

There exists a close connection between endpoint classification and
integrability of solutions of the equation @xmath known as the Weyl
alternative . This fact will be discussed later on.

##### The minimal operator

The minimal operator @xmath associated to @xmath is defined by

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for @xmath . Obviously, we have @xmath . Furthermore, @xmath
for all @xmath and @xmath , i.e. the operators @xmath and @xmath are
adjoint to each other. This observation leads to the first easy
relationship between @xmath and @xmath .

###### Lemma 4.2.1.

We have the inclusion @xmath .

###### Proof.

Let @xmath , i.e. there exists a @xmath such that @xmath . Choose any
@xmath . Then, since @xmath and @xmath are adjoint to each other, we
have @xmath . ∎

#### 4.2.2 Regular Sturm–Liouville Operators

We prove some properties of @xmath and @xmath . However, it is easier to
consider the regular case first. Thus, we assume that both endpoints
@xmath and @xmath are regular, i.e. @xmath . The regular case allows
major simplifications. First of all, any @xmath belongs to @xmath thanks
to the inequality @xmath and, secondly, the initial value problem can be
uniquely solved at the endpoints, i.e. the point @xmath in Theorem 4.2.1
can be chosen to be @xmath or @xmath . Moreover, any solution @xmath of
@xmath satisfies @xmath .

##### Relation between @xmath and @xmath

###### Lemma 4.2.2.

Let @xmath . Then, we can find a function @xmath satisfying @xmath and
@xmath . In particular, @xmath is surjective.

###### Proof.

Let @xmath . Since @xmath is regular we can find two linearly
independent functions @xmath satisfying @xmath and @xmath for @xmath .
Moreover, @xmath is a constant @xmath as follows from the Green’s
formula eq. ( 4.1 ) and thus, by normalization we can assume that @xmath
. We set

  -- -------- --
     @xmath   
  -- -------- --

The involved integrals exist thanks to the inequality

  -- -------- --
     @xmath   
  -- -------- --

A direct computation reveals @xmath , @xmath and @xmath . ∎

Now we are ready to prove the converse statement to Lemma 4.2.1 .

###### Lemma 4.2.3.

Let @xmath . Then, @xmath .

###### Proof.

Let @xmath . According to Lemma 4.2.2 we can find a @xmath such that
@xmath and @xmath . Let @xmath satisfy @xmath and @xmath . Such
functions exist thanks to Theorem 4.2.1 and the regularity of @xmath .
Invoking Green’s formula eq. ( 4.1 ) we calculate

  -- -------- --
     @xmath   
  -- -------- --

for @xmath which yields @xmath . Thus, @xmath and we have @xmath which
shows that @xmath . ∎

###### Remark 4.2.1.

Taking together Lemmas 4.2.1 and 4.2.3 we have proved that @xmath . Note
that the existence and uniqueness Theorem 4.2.1 implies that @xmath is
two–dimensional and in particular, as a finite–dimensional normed vector
space, it is closed. Thus, by taking the orthogonal complement, the
relation @xmath implies @xmath .

##### Density of @xmath

Next we prove that @xmath is dense in @xmath which shows that @xmath and
@xmath are densely defined.

###### Lemma 4.2.4.

The domain @xmath is dense in @xmath .

###### Proof.

It suffices to show that any element which is orthogonal to @xmath is
zero. Let @xmath , i.e. @xmath for all @xmath . Invoking Lemma 4.2.2 we
see that there exists a @xmath such that @xmath . Thus, we have @xmath
for all @xmath which shows that @xmath . However, according to Remark
4.2.1 we have @xmath and thus, @xmath which yields @xmath . ∎

##### The adjoints

We calculate the adjoints of @xmath and @xmath (which are now known to
exist since @xmath and @xmath are densely defined).

###### Lemma 4.2.5.

The operator @xmath is the adjoint of @xmath , i.e. @xmath .

###### Proof.

According to the Green’s formula eq. ( 4.1 ) we know that @xmath for all
@xmath and @xmath which means that @xmath . Let @xmath , i.e. there
exists an @xmath such that @xmath for all @xmath . However, since @xmath
is surjective by Lemma 4.2.2 there exists a @xmath such that @xmath .
Hence, we have

  -- -------- --
     @xmath   
  -- -------- --

which shows that @xmath . We conclude that @xmath (Remark 4.2.1 ) and
therefore, since @xmath , we infer that @xmath . Thus, we have shown
that @xmath which finishes the proof. ∎

###### Remark 4.2.2.

In particular it follows that @xmath is closed since it coincides with
the adjoint of a densely defined operator which is always closed.

###### Lemma 4.2.6.

The operator @xmath is the adjoint of @xmath , i.e. @xmath .

###### Proof.

Applying ” @xmath ” to the relation @xmath (Lemma 4.2.5 ) yields @xmath
. Thus, it remains to show that @xmath . The relation @xmath implies
@xmath and we infer @xmath . Let @xmath . By definition of the adjoint
we have @xmath for all @xmath . On the other hand, by the Green’s
formula eq. ( 4.1 ), we have @xmath for all @xmath and thus, @xmath for
all @xmath . However, since @xmath is regular we can choose @xmath
arbitrarily and we conclude that @xmath which shows that @xmath and
therefore, @xmath . ∎

###### Remark 4.2.3.

Again, it follows that @xmath is closed.

##### A special case

The operator @xmath is symmetric but it is not self–ajoint since @xmath
. Thus, possible self–adjoint extensions of @xmath lie between @xmath
and @xmath . We give a simple example. Let @xmath and @xmath for @xmath
. Then, @xmath . We claim that @xmath is self–adjoint.

###### Lemma 4.2.7.

The operator @xmath is self–adjoint.

###### Proof.

First of all we note that @xmath for all @xmath by the Green’s formula
eq. ( 4.1 ) and therefore, since @xmath is densely defined by Lemma
4.2.4 , @xmath is symmetric. Hence, it remains to show that @xmath .

The relation @xmath together with Lemmas 4.2.5 and 4.2.6 imply @xmath .
Let @xmath . By definition we have @xmath for all @xmath . On the other
hand, according to the Green’s formula eq. ( 4.1 ), we observe that
@xmath for all @xmath which yields @xmath for all @xmath . However,
since @xmath is regular we can choose @xmath and @xmath arbitrarily
which yields @xmath . Thus, @xmath and therefore we have @xmath . ∎

#### 4.2.3 Singular Sturm–Liouville Operators

The results of the previous section are not very useful for concrete
applications since most of the interesting Sturm–Liouville problems are
singular. Thus, we have to generalize the theory to the singular case,
i.e. in the sequel we merely assume @xmath .

##### An auxiliary operator

We define an auxiliary operator @xmath by

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for @xmath .

##### Regularized operators

The main idea is to restrict the problem to a fixed interval @xmath
where everything is regular and then use the fact that @xmath is
arbitrary. We define @xmath . Consider the mapping @xmath , @xmath
defined by

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is injective we can identify @xmath with @xmath and in this
sense we have the inclusion @xmath . We define the regular operators
@xmath and @xmath on @xmath analogous to @xmath and @xmath where @xmath
is substituted by @xmath . According to the results of the previous
section we have @xmath and @xmath . Note further that @xmath implies
@xmath and hence, we have @xmath in the same sense as @xmath .

##### Density of @xmath

We show that @xmath is dense in @xmath .

###### Lemma 4.2.8.

The operator @xmath is densely defined.

###### Proof.

Let @xmath with @xmath for all @xmath . Since @xmath it follows that
@xmath for all @xmath and we can substitute the inner product on @xmath
by the inner product on @xmath which yields @xmath for all @xmath .
Since @xmath is densely defined by Lemma 4.2.4 we conclude that @xmath .
However, @xmath was arbitrary and therefore we infer that @xmath almost
everywhere. ∎

Lemma 4.2.8 together with @xmath for all @xmath imply that @xmath is
symmetric. Furthermore, since @xmath , we observe that @xmath and @xmath
are densely defined as well.

##### The equation @xmath

We consider the inhomogeneous equation @xmath .

###### Lemma 4.2.9.

Let @xmath . Then, there exists a @xmath with @xmath satisfying @xmath .

###### Proof.

According to Theorem 4.2.1 there exist two linearly independent
functions @xmath with @xmath satisfying @xmath ( @xmath ). Without loss
of generality we can assume @xmath (Green’s formula eq. ( 4.1 )). We
define @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where the constants @xmath and @xmath can be chosen arbitrarily. A
direct computation shows that @xmath and @xmath . ∎

##### The adjoint operator

Since @xmath is densely defined by Lemma 4.2.8 , the adjoint @xmath is
defined.

###### Lemma 4.2.10.

The operator @xmath is the adjoint of @xmath , i.e. @xmath .

###### Proof.

According to the Green’s formula eq. ( 4.1 ) we have @xmath for all
@xmath and all @xmath which means that @xmath is adjoint to @xmath ,
i.e. @xmath . Thus, it suffices to show that @xmath . Let @xmath , i.e.
there exists an @xmath such that @xmath for all @xmath . In particular
it follows that @xmath for all @xmath since @xmath . Invoking Lemma
4.2.9 we find a @xmath satisfying @xmath . Hence, we have @xmath for all
@xmath . On the other hand we can write @xmath for all @xmath . This
yields @xmath for all @xmath which shows that @xmath . Thus, @xmath
which implies @xmath . Since this relation holds for all @xmath we infer
@xmath . Hence, we have @xmath and @xmath which shows that @xmath .
Therefore, we have shown that @xmath and we are done. ∎

##### The special case limit–point, limit–point

We consider the special case of a singular Sturm–Liouville operator
where both endpoints are limit–point.

###### Lemma 4.2.11.

Suppose that both endpoints @xmath and @xmath are in the limit–point
case. Then, the maximal operator @xmath is self–adjoint.

###### Proof.

According to Green’s formula eq. ( 4.1 ), the operator @xmath is
symmetric and thus, @xmath . However, we have @xmath which implies
@xmath by Lemma 4.2.10 . ∎

###### Corollary 4.2.1.

Let both endpoints @xmath and @xmath be in the limit–point case. Then,
the maximal operator @xmath is the closure of @xmath .

###### Proof.

Lemma 4.2.10 tells us that @xmath . This implies @xmath by Lemma 4.2.11
and we are done since @xmath is the closure of @xmath . ∎

##### The special case limit–circle, limit–point

We study the special case of a singular Sturm–Liouville operator on
@xmath where @xmath is limit–circle and @xmath is limit–point. The
question is what kind of boundary condition one can choose in order to
construct a self–adjoint operator.

###### Lemma 4.2.12.

Suppose @xmath is in the limit–circle case and @xmath in the limit–point
case. Fix a @xmath such that there exists a @xmath with @xmath (such a
@xmath exists since @xmath is limit–circle) and define @xmath , @xmath
for @xmath . Then, the operator @xmath is self–adjoint.

###### Proof.

For @xmath we have the so–called Plücker identity

  -- -------- --
     @xmath   
  -- -------- --

Thus, choosing @xmath , @xmath and @xmath such that @xmath we obtain
@xmath for all @xmath . Hence, the operator @xmath is symmetric ( @xmath
is limit–point) and it remains to show that @xmath .

We have @xmath which implies @xmath by Lemma 4.2.10 . Let @xmath . By
definition we have @xmath for all @xmath . Thus, the Green’s formula
yields @xmath for all @xmath . Note that @xmath by definition and hence,
the above formula with @xmath yields @xmath which shows that @xmath .
Therefore, we have @xmath . ∎

#### 4.2.4 The Weyl Alternative

Finally, we come back to the already mentioned relationship between
integrability of solutions of @xmath and endpoint classification. The
following theorem, known as the Weyl alternative , is very important for
applications since it simplifies the endpoint classification for
concrete Sturm–Liouville operators a lot.

###### Theorem 4.2.2 (Weyl alternative).

The endpoint @xmath is in the limit–circle case if and only if there
exist two linearly independent functions @xmath with @xmath which belong
to @xmath near @xmath ¹ ¹ 1 One says that the function @xmath belongs to
@xmath near @xmath if there exists a @xmath such that @xmath . and
satisfy @xmath ( @xmath ).

###### Sketch of Proof.

Given two functions @xmath satisfying the properties stated in the
theorem one can easily construct @xmath such that @xmath and @xmath near
@xmath (use appropriate cut–off functions). Since @xmath are linearly
independent it follows that @xmath have the same property which implies
@xmath and hence, @xmath is limit–circle.

Conversely, let @xmath be limit–circle, i.e. there exist @xmath such
that @xmath . By specifying an appropriate boundary condition at @xmath
(or none, if @xmath is limit–point) we can construct two self–adjoint
operators @xmath and @xmath where @xmath implies @xmath and @xmath
satisfies @xmath (cf. Lemma 4.2.12 ). We choose an @xmath with compact
support and define @xmath , @xmath . Since @xmath for some @xmath , it
follows that @xmath . By playing around with the variation of constants
formula one can show that @xmath can be chosen in such a way that
neither @xmath nor @xmath are identically zero. Moreover, from @xmath it
follows easily that @xmath and @xmath are linearly independent. Hence,
by solving an initial value problem at @xmath we can extend @xmath and
@xmath to @xmath . By construction the resulting functions belong to
@xmath near @xmath and solve @xmath . ∎

###### Remark 4.2.4.

Clearly, Theorem 4.2.2 is equally valid for the endpoint @xmath .
Moreover, one can show that @xmath can be substituted by any @xmath .

## Chapter 5 Semigroups and Abstract Wave Equations

In this chapter we prove a generation result for an abstract second
order Cauchy problem on a Banach space. Then we consider the
inhomogeneous abstract Cauchy problem and prove its well–posedness under
certain assumptions. Next, using a fixed point argument, we show
existence and uniqueness of solutions of a nonlinear abstract wave
equation.

### 5.1 The Abstract Wave Equation

We prove well–posedness of an abstract second order Cauchy problem on a
Banach space where the involved operator satisfies certain conditions.

#### 5.1.1 Reduction to a First Order Equation

##### Statement of the problem

In what follows we will assume that @xmath is a densely defined closed
linear operator on a Hilbert space @xmath satisfying @xmath for all
@xmath and a @xmath .

Since @xmath is densely defined, there exists the unique adjoint @xmath
. The following theorem is due to von Neumann.

###### Theorem 5.1.1.

Let @xmath be a densely defined closed linear operator on a Hilbert
space @xmath . Then, @xmath is self–adjoint and @xmath is a core of
@xmath .

###### Proof.

See [ 26 ] , p. 275. ∎

We set @xmath and consider the abstract second order Cauchy problem

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

for a function @xmath .

##### Function spaces

Define @xmath and @xmath for @xmath .

###### Lemma 5.1.1.

The normed vector space @xmath is a Banach space.

###### Proof.

Let @xmath be a Cauchy sequence in @xmath , i.e. @xmath is a Cauchy
sequence in @xmath . @xmath is complete and therefore @xmath has a limit
@xmath . Since @xmath for all @xmath , @xmath is a Cauchy sequence in
@xmath as well and hence it has a limit @xmath . Therefore, we have
@xmath and @xmath in @xmath . Since @xmath is closed, it follows that
@xmath , @xmath and we have @xmath . ∎

###### Lemma 5.1.2.

The Banach space @xmath is continuously embedded in @xmath , i.e. the
inclusion map @xmath defined by @xmath for @xmath is bounded.

###### Proof.

Let @xmath and calculate @xmath . ∎

###### Remark 5.1.1.

We write @xmath whenever @xmath embeds continuously in @xmath .

We define @xmath and @xmath . Introducing the norm @xmath for @xmath ,
@xmath becomes a Banach space thanks to Lemma 5.1.1 . We define @xmath
by @xmath for @xmath and consider the Cauchy problem

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

for @xmath and @xmath which is (formally) equivalent to eq. ( 5.1 ).
Then the following holds.

###### Proposition 5.1.1.

The evolution problem eq. ( 5.2 ) is well–posed.

#### 5.1.2 Well–Posedness

We prove Prop. 5.1.1 by showing that the operator @xmath generates a
strongly continuous one–parameter semigroup on @xmath , thus we verify
the assumptions of the Hille–Yosida Theorem.

##### Analytic properties

###### Lemma 5.1.3.

The operator @xmath is densely defined.

###### Proof.

According to Theorem 5.1.1 , @xmath is a core of @xmath , i.e. there
exists a closeable operator @xmath such that @xmath and @xmath . We
define the @xmath of @xmath by @xmath . We equip @xmath with the norm
@xmath and hence, @xmath is a Banach space. The fact that @xmath is
closed is equivalent to @xmath being a closed subset of @xmath , i.e.
@xmath . @xmath is a subset of @xmath and @xmath .

Now let @xmath . Then, @xmath and, since @xmath is dense in @xmath ,
there exists a sequence @xmath with @xmath in @xmath . Observe that
@xmath for all @xmath since @xmath is an extension of @xmath . Therefore
we have

  -- -------- --
     @xmath   
  -- -------- --

which shows that @xmath is dense in @xmath .

By assumption we have @xmath dense in @xmath and hence @xmath is dense
in @xmath . ∎

###### Lemma 5.1.4.

The operator @xmath is closed.

###### Proof.

Let @xmath be a sequence with @xmath in @xmath and @xmath in @xmath ,
i.e. @xmath in @xmath , @xmath in @xmath , @xmath in @xmath and @xmath
in @xmath . Convergence in @xmath implies convergence in @xmath since
@xmath by Lemma 5.1.2 and hence we also have @xmath in @xmath which
implies @xmath by uniqueness of limits. Therefore, @xmath .

By the same argument we have @xmath in @xmath and together with @xmath
in @xmath and the closedness of @xmath we conclude @xmath and @xmath .

Hence, we have shown that @xmath and @xmath which proves closedness of
@xmath . ∎

##### Spectral properties

###### Lemma 5.1.5.

The spectrum @xmath of @xmath satisfies @xmath .

###### Proof.

@xmath is self–adjoint and satisfies @xmath for all @xmath . Invoking
Prop. 4.1.1 finishes the proof. ∎

###### Lemma 5.1.6.

The spectrum @xmath of @xmath satifies @xmath , i.e. @xmath .

###### Proof.

Consider the equation

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

for @xmath and @xmath which is equivalent to the system

  -- -------- --
     @xmath   
  -- -------- --

Suppose @xmath . Then @xmath is invertible and we define @xmath and
@xmath for given @xmath and @xmath . Then, @xmath and @xmath which shows
that @xmath is surjective. Let @xmath and @xmath . It follows that
@xmath which implies @xmath since @xmath . We conclude that @xmath and
hence @xmath which proves injectivity of @xmath and therefore, @xmath is
bijective which implies @xmath .

Thus, we have shown @xmath which is equivalent to @xmath and this is the
claim. ∎

###### Corollary 5.1.1.

The interval @xmath is contained in the resolvent set of @xmath , i.e.
@xmath .

###### Proof.

Suppose @xmath and @xmath , i.e. @xmath . From Lemma 5.1.6 it follows
that @xmath but this is a contradiction to Lemma 5.1.5 which states that
@xmath and @xmath . ∎

###### Lemma 5.1.7.

The resolvent @xmath of @xmath satisfies @xmath for all @xmath .

###### Proof.

Let @xmath . From Corollary 5.1.1 we know that @xmath exists and we set
@xmath for @xmath . Then we have @xmath . We take the inner product with
@xmath and obtain @xmath . Substituting @xmath yields @xmath . Using the
Cauchy–Schwarz inequality we estimate

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

which yields @xmath and this is equivalent to @xmath . Since @xmath was
arbitrary this implies @xmath .

∎

##### Generation of the semigroup

Taking together Lemmas 5.1.3 , 5.1.4 , 5.1.7 and Corollary 5.1.1 we have
shown that @xmath satisfies the requirements of the Hille–Yosida Theorem
and hence, @xmath generates a strongly continuous one–parameter
semigroup @xmath on @xmath satisfying @xmath for all @xmath . Thus, the
abstract Cauchy problem eq. ( 5.2 ) is well–posed as claimed in Prop.
5.1.1 .

##### Summary

We summarize the results of this section in the following theorem.

###### Theorem 5.1.2.

Let @xmath be a Hilbert space and @xmath a densely defined closed linear
operator which satisfies @xmath for all @xmath and a @xmath . Define
@xmath , @xmath , @xmath for @xmath , @xmath , @xmath and @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath generates a strongly continuous one–parameter semigroup
@xmath on @xmath satisfying @xmath for all @xmath . In particular, the
abstract evolution problem

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and @xmath is well–posed.

#### 5.1.3 A Simple Example

##### The wave equation

As a simple example we apply the generation result to the
one–dimensional wave equation with Dirichlet boundary conditions, i.e.
we consider the Cauchy problem

  -- -- --
        
  -- -- --

##### Operator formulation

As a Hilbert space we take @xmath and set @xmath . We define @xmath by
@xmath for @xmath .

###### Lemma 5.1.8.

The operator @xmath is closed.

###### Proof.

See e.g. [ 34 ] , p. 29, Example 3.10. ∎

We claim that @xmath for @xmath and thus,

  -- -------- --
     @xmath   
  -- -------- --

is an operator version of the one–dimensional wave equation.

###### Lemma 5.1.9.

For @xmath we have @xmath .

###### Proof.

Integration by parts immediately yields @xmath for all @xmath and thus,
@xmath is adjoint to @xmath , i.e. @xmath . Let @xmath . Then we have
@xmath . ∎

Now we show well–posedness using Theorem 5.1.2 .

###### Lemma 5.1.10.

The operator @xmath satisfies @xmath for all @xmath .

###### Proof.

Let @xmath and observe that

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath by Cauchy–Schwarz. Integration yields @xmath . ∎

Thus, our previous results in this section (Theorem 5.1.2 ) imply that
the first–order operator evolution problem which is associated to the
one–dimensional wave equation is well–posed.

### 5.2 The Case @xmath

In Theorem 5.1.2 the bound @xmath is assumed to be strictly positive.
The obvious question is whether this requirement can be weakened. In
this section we discuss the case @xmath , i.e. we assume that @xmath is
a densely defined closed linear operator on a Hilbert space @xmath
satisfying @xmath . The main difficulty one encounters in this case is
the fact that the normed vector space @xmath defined by @xmath and
@xmath is not complete. Hence, the semigroup cannot act on @xmath (which
is the energy space). To go around this problem one has to introduce a
slightly different Banach space in order to recover the existence of the
semigroup. This yields a well–posedness result but the growth estimate
becomes worse. However, this can partly be compensated by energy
conservation.

#### 5.2.1 Generation of the Semigroup

Without loss of generality we can assume @xmath to be self–adjoint (
@xmath is self–adjoint and nonnegative and hence, there exists the
self–adjoint nonnegative square root of @xmath , cf. sec. 4.1 ). The
idea is to consider the operator @xmath for @xmath instead of @xmath and
”repair” this defect by a bounded perturbation.

##### Splitting of the operator

We define the operator @xmath by @xmath where @xmath and @xmath are
given by

  -- -------- --
     @xmath   
  -- -------- --

We show that @xmath generates a strongly continuous one–parameter
semigroup and apply the bounded perturbation theorem.

###### Theorem 5.2.1 (Bounded Perturbation Theorem).

Let @xmath be the generator of a strongly continuous one–parameter
semigroup @xmath on a Banach space @xmath satisfying

  -- -------- --
     @xmath   
  -- -------- --

for an @xmath and all @xmath . If @xmath then @xmath is the generator of
a strongly continuous one–parameter semigroup @xmath satisfying the
estimate

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

###### Proof.

See [ 17 ] , p. 158. ∎

##### Generation of the semigroup

Since @xmath for all @xmath , Theorem 5.1.2 implies that the operator
@xmath generates a strongly continuous one–parameter contraction
semigroup on @xmath . Note that the space @xmath on which the semigroup
acts depends on @xmath since the norm @xmath is given by @xmath for
@xmath ! The perturbation @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Thus, applying the bounded perturbation theorem we
conclude that @xmath generates a strongly continuous one–parameter
semigroup @xmath on @xmath satisfying @xmath for all @xmath .

#### 5.2.2 Removing the @xmath–Dependence

We show how to remove the bothersome @xmath –dependence of the
underlying Banach space. We define @xmath , i.e. @xmath and @xmath for
@xmath . Since @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and any @xmath . Thus, we conclude that

  -- -- --
        
  -- -- --

for all @xmath and any @xmath . Hence, we infer the estimate

  -- -- --
        
  -- -- --

for all @xmath which implies @xmath for any @xmath . Furthermore, all
@xmath (for different @xmath ) have the same generator @xmath which does
not depend on @xmath and hence, they all coincide. Thus, we can drop the
superscript @xmath and, for any @xmath , we obtain @xmath for all @xmath
. Finally, choosing @xmath for @xmath we arrive at

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

#### 5.2.3 Energy Conservation

We define the energy ”norm” on @xmath by @xmath for @xmath ¹ ¹ 1 In
general this is only a seminorm since @xmath might be an eigenvalue of
@xmath and thus, there might exist elements @xmath with @xmath but
@xmath . . Thus, we have @xmath for all @xmath . Consider the time
evolution of initial data @xmath . According to semigroup theory, the
solution @xmath stays in @xmath for all @xmath and satisfies the
equation

  -- -------- --
     @xmath   
  -- -------- --

in the strong sense, i.e. it is a classical solution. Recall that the
norm @xmath is given by @xmath and note that @xmath . Hence, we can
write ² ² 2 Recall the definition of the graph norm @xmath given by
@xmath for @xmath . @xmath and this implies that the derivative @xmath
exists with respect to the graph norm of @xmath , i.e. @xmath exists for
all @xmath . Therefore, since @xmath is a closed operator, we have
@xmath . Having these observations in mind we readily calculate

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath where @xmath . Thus, the function @xmath is constant.
This shows that for all classical solutions the energy is conserved.

Now let @xmath . Then, there exists a sequence @xmath such that @xmath
in @xmath . Since @xmath is bounded we conclude that @xmath in @xmath
for any @xmath . Recall that @xmath which shows that @xmath with respect
to @xmath as well. In particular we have

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . This shows that energy conservation holds for
generalized solutions as well.

#### 5.2.4 Summary

We formulate the results of this section as a theorem.

###### Theorem 5.2.2.

Let @xmath be a Hilbert space and @xmath a self–adjoint operator
satisfying @xmath for all @xmath . Define @xmath and @xmath for @xmath .
Then, the operator @xmath , defined by @xmath and

  -- -------- --
     @xmath   
  -- -------- --

generates a strongly continuous one–parameter semigroup @xmath on @xmath
satisfying

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

Furthermore, if @xmath and @xmath , the function @xmath is constant for
all @xmath .

### 5.3 The Inhomogeneous Problem

As a next step we discuss semigroup theory for inhomogeneous evolution
problems. This approach relies on the notion of an integral of a
semigroup whose definition requires a little background in measure
theory which will be outlined first.

#### 5.3.1 Basic Aspects of Measure Theory

We briefly discuss the construction of the Lebesgue integral for Banach
space valued functions on intervals. An introduction to measure theory
can be found in e.g. [ 4 ] . For the definition of the Bochner integral
we also refer to [ 59 ] .

##### @xmath–algebra, measure

Let @xmath be a set and @xmath where @xmath denotes the power set of
@xmath , i.e. the set of all subsets of @xmath . @xmath is said to be a
@xmath –algebra if

-   @xmath

-   @xmath

-   @xmath for @xmath @xmath

Let @xmath . The smallest @xmath –algebra which contains @xmath is
denoted by @xmath . We remark that @xmath exists for any @xmath since
@xmath is a @xmath –algebra itself.

A mapping @xmath is called a measure on @xmath if @xmath and @xmath for
@xmath , @xmath and @xmath for @xmath .

##### Borel @xmath–algebra, Lebesgue measure

Let @xmath and set @xmath . Then, @xmath is called the Borel @xmath
–algebra . One can show that there exists a unique measure @xmath on
@xmath such that @xmath for all half–open intervals @xmath . The measure
@xmath is called the Lebesgue measure . A similar construction can be
applied to @xmath .

##### Measurable functions, simple functions

Let @xmath be the Borel @xmath –algebra on @xmath , @xmath a set and
@xmath a @xmath –algebra. A function @xmath is said to be measurable if
@xmath for all @xmath .

Now we restrict ourselves to real–valued functions. We denote the
characteristic function of a set @xmath by @xmath , i.e.

  -- -------- --
     @xmath   
  -- -------- --

A function @xmath is called simple if there exist @xmath for @xmath
which satisfy @xmath and @xmath for @xmath and @xmath where @xmath ,
@xmath .

##### Lebesgue integral

One defines the Lebesgue integral @xmath over a simple function @xmath
with @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the Lebesgue measure.

Let @xmath be a nonnegative measurable function. One can show that there
exists a sequence of simple functions @xmath such that @xmath for all
@xmath and @xmath . Then one defines

  -- -------- --
     @xmath   
  -- -------- --

For general measurable functions @xmath one sets @xmath and @xmath . One
easily shows that the nonnegative functions @xmath and @xmath are
measurable. If @xmath and @xmath one says that @xmath is integrable and
defines

  -- -------- --
     @xmath   
  -- -------- --

The generalization to complex–valued functions is obtained by
considering the real and imaginary parts separately.

##### Lebesgue’s theorem on dominated convergence

We have the following important convergence theorem.

###### Theorem 5.3.1 (Dominated convergence theorem).

Let @xmath be a measure space (i.e. @xmath is a @xmath –algebra and
@xmath a measure on @xmath ) and @xmath measurable functions.
Furthermore, assume that @xmath pointwise almost everywhere and there
exists a nonnegative measurable function @xmath with @xmath and @xmath
almost everywhere for all @xmath . Then, @xmath is integrable for all
@xmath and we have

  -- -------- --
     @xmath   
  -- -------- --

##### Banach space valued functions

Let @xmath be a Banach space. Again, @xmath denotes the Borel @xmath
–algebra on @xmath and @xmath the Lebesgue measure.

A function @xmath is said to be simple if there exist @xmath , @xmath
with @xmath , @xmath for @xmath and @xmath such that @xmath , @xmath .

##### Measurable functions

A function @xmath is said to be weakly measurable if, for any @xmath ,
the complex–valued function @xmath is measurable. @xmath is said to be
strongly measurable if there exists a sequence @xmath of simple
functions and a @xmath with @xmath such that @xmath for all @xmath ,
i.e. @xmath in @xmath for almost all @xmath . It turns out that, if
@xmath is separable, the notions ”weakly measurable” and ”strongly
measurable” are equivalent.

##### The Bochner integral

Let @xmath be a simple function with @xmath . Then, the Bochner integral
@xmath of @xmath is defined by

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be a strongly measurable function. One can show that the
real–valued function @xmath is measurable. The function @xmath is said
to be Bochner integrable if there exists a sequence @xmath of simple
functions such that

  -- -------- --
     @xmath   
  -- -------- --

It turns out that this condition implies the existence of the limit of
the sequence @xmath in @xmath . Then, one defines the Bochner integral
of @xmath by

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 5.3.2 (Bochner).

Let @xmath be a Banach space. A strongly measurable function @xmath is
Bochner integrable if and only if the function @xmath is integrable. In
this case the estimate

  -- -------- --
     @xmath   
  -- -------- --

holds.

##### Notation

To improve readability we will adapt the usual ”Riemann–like” notation
for integrals, i.e. consider a function @xmath where @xmath is some
interval and @xmath a Banach space. Then we define a function @xmath by

  -- -------- --
     @xmath   
  -- -------- --

and set

  -- -------- --
     @xmath   
  -- -------- --

#### 5.3.2 The Abstract Problem

We consider the inhomogeneous abstract Cauchy problem, see [ 17 ] . We
also refer to [ 44 ] for an extensive treatment of this subject.

##### Statement of the problem

Let @xmath be a separable ³ ³ 3 The assumption of separability is
introduced here for convenience only, it is by no means necessary.
Banach space, @xmath a linear operator and @xmath a function. Consider
the abstract inhomogeneous evolution problem

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

for a function @xmath and initial data @xmath . Now we extend the notion
of well–posedness to the inhomogeneous problem.

###### Definition 5.3.1.

A function @xmath is called a classical solution of eq. ( 5.5 ) if it is
continuously differentiable and satisfies eq. ( 5.5 ).

The abstract evolution problem eq. ( 5.5 ) is said to be well–posed if
for every @xmath there exists a unique classical solution @xmath of eq.
( 5.5 ) such that the mapping @xmath is uniformly continuous in @xmath
on compact intervals @xmath for any @xmath .

##### Construction of solutions

Suppose that @xmath generates a strongly continuous one–parameter
semigroup @xmath on @xmath satisfying @xmath for a continuous positive
function @xmath and all @xmath , i.e. the associated homogeneous problem
( @xmath ) is well–posed. Assume further that @xmath is continuous.
Then, the function @xmath is continuous and hence, for any @xmath , the
function @xmath is continuous and thus measurable. This shows that
@xmath is weakly measurable. Since @xmath is separable we conclude that
@xmath is strongly measurable. Moreover, for @xmath we have @xmath which
shows that

  -- -------- --
     @xmath   
  -- -------- --

exists. Thus, Bochner’s Theorem implies that @xmath is Bochner
integrable.

Define

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

Then, @xmath is called the mild solution of eq. ( 5.5 ).

##### Classical solutions

It is easy to show that every classical solution is a mild solution. In
particular, this implies that a classical solution is unique. It turns
out that, if @xmath satisfies certain additional regularity conditions,
a classical solution can be constructed by formula eq. ( 5.6 ). If, for
instance, @xmath has a weak @xmath –derivative which is integrable and
@xmath then @xmath defined by eq. ( 5.6 ) is the classical solution of
eq. ( 5.5 ). More precise, we have the following theorem.

###### Theorem 5.3.3.

Let @xmath be the generator of a strongly continuous one–parameter
semigroup @xmath on @xmath . If @xmath and @xmath then @xmath defined by
eq. ( 5.6 ) is the unique classical solution of eq. ( 5.5 ).

###### Proof.

See [ 17 ] , p. 439. ∎

###### Remark 5.3.1.

The space @xmath is a Sobolev space of Banach space valued functions
@xmath analogous to @xmath for complex–valued functions. One can define
@xmath as follows. Consider the vector space of functions @xmath such
that @xmath is integrable (in the sense of Bochner) and there exists an
integrable function @xmath such that @xmath can be written as

  -- -------- --
     @xmath   
  -- -------- --

for a @xmath . Two such functions are identified if they coincide for
almost all @xmath . Then, the quotient space defined by this equivalence
relation is denoted by @xmath .

##### Well–posedness of the inhomogeneous problem

We summarize the results of this section in a theorem.

###### Theorem 5.3.4.

Let @xmath be a separable Banach space, @xmath a linear operator and
@xmath . If @xmath generates a strongly continuous one–parameter
semigroup @xmath then the abstract inhomogeneous Cauchy problem eq. (
5.5 ) is well–posed. Its unique classical solution @xmath is given by
eq. ( 5.6 ) for @xmath .

### 5.4 A Nonlinear Problem

In this section we consider existence and uniqueness of an abstract
nonlinear evolution equation for a function @xmath on a separable Banach
space @xmath given by

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

where @xmath and @xmath is Lipschitz–continuous, i.e. there exists a
@xmath such that @xmath for all @xmath . We assume that @xmath generates
a strongly continuous semigroup @xmath satisfying @xmath for all @xmath
and an @xmath .

#### 5.4.1 Existence and Uniqueness

Let @xmath and denote the vector space of continuous functions @xmath by
@xmath . For @xmath the real–valued function @xmath is continuous and
hence attains its maximum on the compact interval @xmath . We define a
norm @xmath on @xmath by

  -- -------- --
     @xmath   
  -- -------- --

It is easy to show that @xmath is a Banach space.

Now let @xmath be fixed and define a mapping @xmath by

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

for @xmath . The function @xmath is continuous since @xmath is
continuous. Hence, it is Bochner integrable and the above definition of
@xmath makes sense.

Note that the function @xmath is the unique mild solution of the linear
inhomogeneous problem

  -- -------- --
     @xmath   
  -- -------- --

as discussed in sec. 5.3 . Thus, a fixed point @xmath of @xmath ( @xmath
) is a mild solution of the nonlinear problem eq. ( 5.7 ). Hence, to
show existence of solutions of eq. ( 5.7 ) it suffices to show existence
of a fixed point of the mapping @xmath . To do so we will invoke the
Banach fixed point theorem.

###### Theorem 5.4.1 (Banach fixed point theorem).

Let @xmath be a Banach space and @xmath a mapping that satisfies

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and a @xmath . Then, there exists a unique fixed point of
@xmath .

With the help of this theorem we can prove existence and uniqueness of
mild solutions of eq. 5.7 for small times.

###### Lemma 5.4.1.

There exists a @xmath such that the mapping @xmath defined by eq. ( 5.8
) has a unique fixed point.

###### Proof.

Let @xmath , @xmath and observe that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

where we have used @xmath for all @xmath and the Lipschitz–continuity of
@xmath . Thus, we have

  -- -------- --
     @xmath   
  -- -------- --

Hence, choosing @xmath such that @xmath shows that @xmath satisfies the
contraction property required by the Banach fixed point theorem.
Therefore, for such a @xmath , @xmath has a unique fixed point. ∎

Thus, we have shown that eq. ( 5.7 ) has a unique solution @xmath for
any @xmath satisfying @xmath .

From the local result we immediately obtain a global result.

###### Lemma 5.4.2.

There exists a unique global (mild) solution @xmath of eq. ( 5.7 ).

###### Proof.

Applying Lemma 5.4.1 we obtain a constant @xmath and a local–in–time
solution @xmath of eq. ( 5.7 ) for given initial data @xmath . Now we
set @xmath and apply Lemma 5.4.1 again to obtain a solution @xmath
satisfying @xmath . Repeating this process yields a sequence @xmath of
solutions of eq. ( 5.7 ) in @xmath satisfying @xmath for @xmath . Now we
define @xmath for @xmath , @xmath . By construction, @xmath , @xmath
satisfies @xmath for each @xmath and @xmath . ∎

#### 5.4.2 Dependence on Data and Growth Estimates

By construction, the global solution @xmath of eq. ( 5.7 ) satisfies the
equation

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

for all @xmath . In order to obtain an estimate for @xmath in terms of
the initial data @xmath we apply Gronwall’s inequality.

###### Lemma 5.4.3 (Gronwall’s inequality).

Let @xmath be a nonnegative integrable function which satisfies

  -- -------- --
     @xmath   
  -- -------- --

for constants @xmath and almost all @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

for almost all @xmath .

###### Proof.

See e.g. [ 19 ] , p. 625. ∎

###### Lemma 5.4.4.

The unique global solution @xmath satisfies the estimate

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and a constant @xmath .

###### Proof.

Using eq. ( 5.9 ), @xmath for all @xmath and the Lipschitz–continuity of
@xmath we readily estimate

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Application of Gronwall’s inequality yields

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Setting @xmath we infer the desired result since @xmath
is arbitrary. ∎

Although the estimate stated in Lemma 5.4.4 is very weak, it suffices to
ensure continuous dependence on the initial data.

#### 5.4.3 Summary

We reformulate the results on the nonlinear problem as a theorem.

###### Theorem 5.4.2.

Let @xmath be a linear operator on a Banach space @xmath which generates
a strongly continuous one–parameter semigroup @xmath satisfying @xmath
for all @xmath and an @xmath . Moreover, let @xmath be a
Lipschitz–continuous function. Then, the nonlinear abstract evolution
problem

  -- -------- --
     @xmath   
  -- -------- --

for @xmath has a unique mild solution @xmath which depends continuously
on @xmath .

## Chapter 6 The Cauchy Problem for Wave Maps

We formulate the Cauchy problem for the wave maps system eq. ( 2.1 )

  -- -------- --
     @xmath   
  -- -------- --

and state some basic results. As a technical requirement we need
fractional Sobolev spaces which are introduced first. Then, we state a
general result concerning local well–posedness of nonlinear wave
equations which can be applied to the wave maps system. We also mention
some recent developments in connection with global existence for
solutions with small data.

### 6.1 Fractional Sobolev Spaces

We introduce noninteger Sobolev spaces by using the Fourier transform
(cf. e.g. [ 19 ] , [ 59 ] ).

##### Lebesgue spaces

We have already defined Lebesgue spaces for functions defined on
intervals. The generalization to complex–valued mappings on open subsets
of @xmath is similar and goes as follows. Let @xmath be open and
consider the set @xmath of smooth functions from @xmath to @xmath having
compact support. For @xmath we define a norm @xmath on @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where integration is understood with respect to the ordinary Lebesgue
measure on @xmath . The Lebesgue space @xmath is defined as the
completion of @xmath with respect to @xmath . We also define local
versions @xmath by

  -- -------- --
     @xmath   
  -- -------- --

##### The Fourier transform

Now suppose @xmath and define

  -- -------- --
     @xmath   
  -- -------- --

where @xmath for @xmath . Since @xmath and @xmath , @xmath is
well–defined and it is called the Fourier transform of @xmath . It turns
out that the mapping @xmath can be extended to @xmath . We list some
important properties.

-   @xmath is an isometric isomorphism, i.e. it is linear, invertible
    and norm–preserving (Plancherel’s theorem).

-   For @xmath the inverse @xmath is given by

      -- -------- --
         @xmath   
      -- -------- --

-   ” @xmath maps derivatives into multiplication”, i.e. @xmath if
    @xmath where @xmath , @xmath and @xmath for @xmath .

##### Fractional Sobolev spaces

For @xmath we define the Sobolev space @xmath by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the Euclidean norm of the vector @xmath , i.e. @xmath .
Furthermore, we set

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Note that @xmath . Equipped with this norm, @xmath becomes
a Banach space. Another commonly used notion is the homogeneous Sobolev
space @xmath which is defined as

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

For brevity we will write @xmath instead of @xmath .

### 6.2 Local Well–Posedness

We state some known results concerning local well–posedness of nonlinear
wave equations and wave maps.

#### 6.2.1 Semilinear Wave Equations

We consider the Cauchy problem for a nonlinear wave equation of the form

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

for a function @xmath where @xmath , @xmath is smooth and satisfies
@xmath . @xmath is a shorthand notation to indicate that @xmath might
depend on the function @xmath and its first partial derivatives. The
necessity to prescribe @xmath and @xmath as initial data follows from
the fact that the equation is second order in time: One has to know the
function and its first time derivative on the initial surface @xmath to
be able to formally calculate higher derivates.

By a (local) solution of the Cauchy problem eq. ( 6.1 ) we mean a
function @xmath with @xmath that satisfies

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

for all test functions @xmath and a constant @xmath (which might depend
on @xmath and @xmath ). For simplicity we write @xmath instead of @xmath
. We state the classical local well–posedness theorem.

###### Theorem 6.2.1.

Let @xmath be smooth and @xmath . Then, for any @xmath and @xmath there
exists a @xmath such that the Cauchy problem

  -- -------- --
     @xmath   
  -- -------- --

has a unique solution @xmath . Moreover, @xmath is bounded below by a
strictly positive continuous function of @xmath and the mapping @xmath
is continuous.

We say that the Cauchy problem eq. ( 6.1 ) is locally well–posed in
@xmath for any @xmath . The proof (see e.g. [ 29 ] ) of Theorem 6.2.1
relies on a fixed point iteration together with energy estimates for the
linear wave equation, a Sobolev embedding, the so–called Moser
inequality and the Gronwall inequality. We remark that Theorem 6.2.1 is
equally valid for systems of equations, i.e. vector–valued @xmath and
@xmath .

#### 6.2.2 Wave Maps

Observe that the wave maps equation is in fact a system of semilinear
wave equations and the involved nonlinearity satisfies the requirements
of Theorem 6.2.1 . Thus, we immediately obtain local well–posedness of
the Cauchy problem for wave maps in @xmath for any @xmath . At this
point we should remark that wave maps have orginally been required to be
@xmath (cf. ch. 2 ). However, from the point of view of partial
differential equations this is an unnecessary restrictive assumption and
therefore we relax it.

It turns out that this local well–posedness result can be improved. The
important observation in this respect is the fact that the nonlinearity
in the wave maps system is not generic. It satisfies the so–called null
condition (cf. [ 27 ] ). Exploiting this special algebraic structure it
is possible to show local well–posedness of the Cauchy problem for wave
maps in @xmath for @xmath and @xmath (see [ 29 ] and references
therein). This result is sharp in the sense that there exist wave map
systems which are not locally well–posed (i.e. ill–posed ) in @xmath for
@xmath , see [ 14 ] .

### 6.3 Global Results

In general, global existence of solutions for semilinear wave equations
is expected to hold only if the data satisfy certain ”smallness”
conditions. We cite some results in this direction for wave maps. On the
other hand, if the solution does not exist for all times, the question
arises how the breakdown occurs. For our particular wave map model this
issue will be studied in the next chapter.

There are many recent results concerning the global well–posedness for
the Cauchy problem of wave maps and we are unable to mention them all
(see e.g. [ 53 ] , [ 32 ] , [ 28 ] and references therein). However, of
most interest for our purposes is Tao’s work [ 51 ] which deals with
wave maps from ( @xmath )–dimensional Minkowski space to the ( @xmath
)–sphere for @xmath . In this work it is shown that, roughly speaking, a
wave map with smooth initial datum @xmath which is small in the
homogeneous Sobolev space @xmath extends globally in time and stays
smooth. Thus, for time evolutions starting from smooth data @xmath ,
blow up can only occur if @xmath is sufficiently large.

Finally, we mention two earlier global existence results for wave maps
from ( @xmath ) Minkowski space to the three–sphere which have been
obtained by Kovalyov [ 30 ] and Sideris [ 48 ] . We also refer to the
work of Shatah and Tahvildar–Zadeh [ 47 ] for the special case of
equivariant wave maps.

## Chapter 7 Self–Similar Solutions

### 7.1 Blow Up

We discuss solutions of the wave map problem eq. ( 2.3 ) with smooth
initial data which become singular after a finite time. Such a behaviour
is called blow up . We remark that this phenomenon can already be
observed for ordinary differential equations. Consider for example the
equation @xmath with initial data @xmath . The solution is given by
@xmath and thus it ceases to exist at @xmath . We have already mentioned
regularity results which state that the solution is smooth for all times
provided the initial data are smooth and small in some Sobolev space.
Hence, blow up can only occur if the data are large enough.

Technically we note that the derivations in this section have an
informal character, i.e. we relax the mathematical rigor and restrict
ourselves to a heuristic discussion.

#### 7.1.1 Scaling and Criticality Class

We consider the conserved energy

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

of the wave map equation

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

A mapping @xmath for a constant @xmath is called a dilation . Note that
eq. ( 7.2 ) is invariant under dilations: Suppose @xmath solves eq. (
7.2 ). Then, @xmath defined by @xmath is also a solution of eq. ( 7.2 )
provided that @xmath in eq. ( 7.2 ) is substituted by @xmath . This
scale invariance can be used to classify conserved quantities of the
equation. Let @xmath be a solution of eq. ( 7.2 ). The energy eq. ( 7.1
) scales as @xmath for @xmath . One says that the scaling of energy is
subcritical , critical or supercritical if @xmath , @xmath or @xmath ,
respectively. Thus, the energy for the wave map equation eq. ( 7.2 ) is
supercritical. An informal principle states that solutions of energy
supercritical equations develop singularities for large initial data
while they stay regular for small ones. Based on the criticality
classification one gains a heuristic understanding of certain aspects of
the dynamics. In the supercritical case it is favourable for solutions
to shrink since this process is connected with a decrease of the local
energy. Such a shrinking may eventually lead to singularity formation.
Conversely, in the subcritical case shrinking is forbidden since it
requires a larger and larger amount of energy. Hence, we expect eq. (
7.2 ) to possess blow up solutions.

#### 7.1.2 Characteristics and Finite Speed of Propagation

We discuss a fundamental feature of wave equations: Finite speed of
propagation of information.

##### Characteristics

It turns out that information propagates along certain curves in
spacetime which are called characteristics . In what follows we will
explain what is meant by this statement. Consider a first–order
differential equation

  -- -------- --
     @xmath   
  -- -------- --

for a vector–valued function @xmath and a @xmath –matrix @xmath
depending on @xmath and @xmath . We assume @xmath to be diagonalizable
with eigenvalues @xmath (the @xmath ’s are functions of @xmath and
@xmath as well). Hence, there exists an invertible matrix @xmath
(depending on @xmath and @xmath ) such that @xmath is diagonal. Defining
@xmath we can write the system in component form

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

where @xmath . Now let @xmath be a function of @xmath such that @xmath
for all @xmath where @xmath . Then, the spacetime curve @xmath is called
a characteristic .

##### Finite speed of propagation

Let @xmath be a solution of eq. ( 7.3 ). We calculate the directional
derivative of @xmath along the characteristic @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Integrating this equation yields

  -- -------- --
     @xmath   
  -- -------- --

Thus, the solution at a spacetime point @xmath depends solely on the
value of the solution along the characteristics through that point. If
@xmath for all @xmath and @xmath it follows that information encoded in
the initial data propagates with finite speed. Hence, initial data given
on a compact subset of the initial surface can only influence a compact
spacetime domain in the future, the domain of influence . On the other
hand, the value of the solution at a fixed spacetime point depends
solely on the value of the field in a compact region of spacetime in the
past, the domain of dependence .

Note that the notion of domain of dependence is of fundamental
importance for the numerical treatment of wave equations. Discretizing
the equation in a way which is compatible with the characteristic
structure is absolutely necessary in order to obtain a stable scheme.

##### Characteristics of the Wave Map Equation

We set @xmath , @xmath , @xmath and write eq. ( 7.2 ) in the form

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

The eigenvalues of @xmath are @xmath and hence, there are three
characteristics, @xmath , @xmath and @xmath . In a spacetime diagram the
characteristics @xmath and @xmath are lines with slope @xmath or @xmath
and hence, the speed of propagation of information is limited by @xmath
.

Finally, we remark that the notion of characteristics can be defined in
the more general context of a fully nonlinear first–order partial
differential equation, see e.g. [ 19 ] .

#### 7.1.3 Blow Up Solutions

We intend to construct an explicit example of a solution of eq. ( 7.2 )
with smooth initial data which develops a singularity in finite time.
The most promising strategy is to look for self–similar solutions. We
have already discussed the dilation invariance of the wave map equation
( 7.2 ). Hence, it is natural to look for a solution which shares this
invariance, i.e. we seek solutions @xmath with the property @xmath for
any @xmath . Such solutions are called self–similar . To this end we
plug the ansatz @xmath in eq. ( 7.2 ) and obtain

  -- -------- -- -------
     @xmath      (7.4)
  -- -------- -- -------

where @xmath , @xmath and @xmath is an arbitrary constant. Shatah [ 45 ]
showed that eq. ( 7.4 ) has a smooth solution. This solution has been
found in closed form by Turok and Spergel [ 56 ] and is given by

  -- -------- --
     @xmath   
  -- -------- --

Set @xmath . Then, @xmath is perfectly smooth for @xmath but @xmath and
hence the spatial derivative at the center @xmath blows up for @xmath .
Thus, @xmath is an explicit example of a solution of eq. ( 7.2 ) with
smooth initial data @xmath and @xmath which develops a singularity in
finite time.

One might argue that this example is of no physical relevance since the
solution @xmath is not a finite energy solution, i.e. @xmath . However,
as we have seen in the previous section, the speed of propagation of
information is limited by @xmath . This fact can be used to construct a
blow up solution with finite energy. Consider smooth initial data which
equal @xmath and @xmath for @xmath and are identically zero for @xmath .
These data have finite energy and due to finite speed of propagation the
singularity at @xmath will form before any information of the region
@xmath reaches the center. Hence, the existence of self–similar
solutions together with finite propagation speed implies the existence
of a physically relevant blow up solution.

#### 7.1.4 Some Numerics

A natural question is whether blow up occurs for generic initial data or
the example given above is an ”exceptional case” in a certain sense. In
order to answer this question we employ some very simple numerics.

##### Coordinate transformation

Since interesting things are expected to happen around @xmath it is
useful to make a coordinate change @xmath , @xmath , in order to gain a
better resolution near the center. The value of the constant @xmath
determines the quality of this primitive mesh refinement. The wave map
equation ( 7.2 ) in these new coordinates reads

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

##### Characteristics

We calculate the characteristics of this equation. Setting @xmath ,
@xmath and @xmath we write eq. ( 7.5 ) in first–order form

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

The eigenvalues of @xmath are @xmath and hence the characteristic curves
@xmath and @xmath satisfy the differential equations @xmath and @xmath .
Thus, the characteristic speeds @xmath and @xmath at the center @xmath
are given by @xmath and therefore they diverge as @xmath approaches
zero.

##### Discretization

We choose one of the simplest second–order accurate schemes to
discretize eq. ( 7.5 ), the centered space and centered time method. We
label discrete spacetime points by @xmath where @xmath are natural
numbers including zero and use the following approximations for
derivatives of @xmath .

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

where we have applied the usual abbreviation @xmath . Plugging these
approximations in eq. ( 7.5 ) and solving for @xmath we obtain

  -- -------- -- -------
     @xmath      (7.6)
  -- -------- -- -------

where @xmath , @xmath , @xmath .

We use a finite spatial grid which covers the interval @xmath for some
large @xmath and impose Dirichlet conditions @xmath and @xmath for all
@xmath at the endpoints. Since the discretization scheme ( 7.6 )
requires two time steps in the past we have to calculate the first time
step by Taylor expansion. This yields the initialization formula

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are the initial data.

##### Domain of dependence

As we have already mentioned, the characteristic speeds at the center
are given by @xmath . In order to obtain a stable discretization scheme
it is necessary to make sure that the physical domain of dependence is
included in the numerical domain of dependence. This requirement is
known as the Courant–Friedrichs–Lewy condition (cf. [ 25 ] ). Hence, we
have to choose @xmath , @xmath and @xmath in such a way that the
condition @xmath is satisfied. We observe that in order to improve the
quality of the mesh refinement (i.e. decrease @xmath ) we have to
decrease @xmath as well if @xmath is kept fixed. Thus, one cannot
increase the resolution around the center without increasing the
computational effort.

##### Numerical results

We choose a Gaussian with amplitude @xmath as initial data. This pulse
splits into an ingoing and an outgoing wave packet. We make the grid
large enough and focus on the ingoing pulse since nothing interesting
happens to the outgoing one. Fig. 7.1 shows the time evolution of a Gauß
pulse with small amplitude in the original @xmath –coordinates. Then we
successively increase the amplitude @xmath and monitor the @xmath
–derivative of the solution @xmath at the center, given by @xmath . Fig.
7.2 shows @xmath of the solution @xmath plotted against @xmath .

We observe that the spatial derivative of the solution at the center
diverges when @xmath approaches a critical value from below. A similar
result can be produced when using other types of initial data. From this
observation we conclude that the blow up is a generic phenomenon which
occurs whenever the initial data are large enough.

#### 7.1.5 Universality of Blow Up

Bizoń et. al. [ 10 ] have studied eq. ( 7.2 ) numerically and based on
their observations they have formulated some conjectures concerning the
blow up. They claim that there exists a large open set of initial data
which lead to blow up and, in addition, the asymptotic shape of the blow
up solution approaches the Turok Spergel solution @xmath as @xmath
locally near the center @xmath . Hence, the self–similar blow up
behaviour defined by the solution @xmath is conjectured to be universal
in this sense. Furthermore, families of initial data depending on a
parameter @xmath which interpolate between dispersion and blow up have
been studied. There exists a critical value @xmath of the parameter
@xmath such that initial data with @xmath lead to dispersion while data
with @xmath blow up. Considering initial data which lie exactly at the
boundary, i.e. @xmath , another self–similar solution @xmath which plays
the role of an ”intermediate attractor” has been identified. This means
that the solution approaches @xmath locally around the center for a
certain time and eventually disperses or blows up via @xmath since
@xmath exactly is numerically impossible. With the help of the code
developed in the previous section it is possible to reproduce these
results. Fig. 7.3 for example shows the last stages of the self–similar
blow up of a solution @xmath with initial data of the form

  -- -- --
        
  -- -- --

and @xmath . The dashed line is a plot of the Turok Spergel solution
@xmath with appropriately chosen @xmath . One sees that for small @xmath
the two solutions @xmath and @xmath coincide.

Hence, the simple equation ( 7.2 ) shows very interesting behaviour and
a better (mathematically rigorous) understanding of these phenomena is
desireable.

### 7.2 Properties of Self–Similar Solutions

Numerical studies of eq. ( 7.2 ) suggest that self–similar solutions
play an important role in the dynamics of time evolution. Hence, it is
necessary to take a closer look at the equation

  -- -------- -- -------
     @xmath      (7.7)
  -- -------- -- -------

#### 7.2.1 Existence of Self–Similar Solutions

Eq. ( 7.7 ) can be solved numerically using a shooting and matching
technique. This has been done first by Åminneborg and Bergström [ 3 ]
and later in [ 10 ] and [ 33 ] . The singular behaviour of eq. ( 7.7 )
at @xmath and @xmath yields the regularity requirements @xmath and
@xmath for smooth solutions @xmath . One imposes these boundary
conditions and integrates the equation away from the singularities
towards @xmath with a standard ODE integrator. By this, one obtains two
solutions @xmath and @xmath on @xmath and @xmath , respectively. Varying
the free parameters @xmath and @xmath one tries to smoothly match the
two solutions at @xmath . It turns out that there exists a countable
family @xmath of different self–similar solutions whose existence has
been proved by Bizoń [ 6 ] .

###### Theorem 7.2.1.

There exists a countable family of smooth solutions @xmath of eq. ( 7.7
) satisfying the boundary conditions @xmath and @xmath . The index
@xmath denotes the number of intersections of @xmath with the line
@xmath (the equator of @xmath ) on @xmath .

Additionally it is shown in [ 6 ] that, for @xmath , the solutions
@xmath converge to the limiting solution @xmath pointwise for all @xmath
. Furthermore, we note that the self–similar solutions @xmath can be
interpreted as harmonic maps from the hyperbolic space @xmath to @xmath
(cf. [ 13 ] ).

#### 7.2.2 Stability Properties

Stability of self–similar solutions is an important issue. Highly
unstable solutions are not expected to play a role in the time evolution
of generic initial data since they cannot be approached while stable
solutions may act as attractors. In order to make these ideas more
precise it is useful to transform the wave map equation ( 7.2 ) to the
new space coordinate @xmath which yields

  -- -------- -- -------
     @xmath      (7.8)
  -- -------- -- -------

Hence, all self–similar solutions with blow up time @xmath are static
solutions of eq. ( 7.8 ). Based on the numerical observations of sec.
7.1 we expect the Turok Spergel solution @xmath to act as a static
attractor for solutions of eq. ( 7.8 ). However, the situation is more
delicate. Since the Turok Spergel solution is not a single solution but
a family of solutions (depending on the parameter @xmath ), we expect a
solution of eq. ( 7.8 ) with blow up initial data to converge to a
certain @xmath for an appropriate @xmath . Hence, if one fixes @xmath ,
not all blow up solutions will converge to @xmath but only the ones with
the ”right” blow up time. Numerically this can be tested by considering
a family of initial data depending on a parameter @xmath . Then, it
should be possible to adjust the parameter @xmath such that the
fine–tuned solution converges to @xmath with a prescribed @xmath .

#### 7.2.3 Hyperbolic Coordinates

Eq. ( 7.8 ) is not well–suited for a rigorous mathematical analysis
since the coefficients depend on @xmath . Furthermore, the mixed
derivative is bothersome. Hence, we intend to introduce a new time
coordinate @xmath in order to simplify the structure of the equation. To
this end we interpret the new coordinates @xmath , @xmath as functions
of @xmath , @xmath and calculate the new coordinate vector fields @xmath
, @xmath with the help of the equations @xmath and @xmath . In order to
avoid bothersome off–diagonal terms we require the new coordinates to be
orthogonal, i.e. @xmath where @xmath is the (coordinate representation
of the) Minkowski metric. Setting @xmath this yields the partial
differential equation

  -- -------- --
     @xmath   
  -- -------- --

which is a transport equation for the function @xmath . The general
solution is given by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a free function and @xmath an arbitrary constant. We
transform eq. ( 7.8 ) to the new time coordinate @xmath . By
construction, the mixed derivative @xmath drops out. We use the
remaining freedom to make the coefficients of the equation @xmath
–independent. This yields @xmath and @xmath where @xmath is a constant.
Therefore, we obtain @xmath . Since we want @xmath to increase with
@xmath we choose @xmath negative and it turns out that @xmath is
convenient. Hence, we arrive at @xmath . The wave map equation ( 7.8 )
transforms to

  -- -------- -- -------
     @xmath      (7.9)
  -- -------- -- -------

We will refer to @xmath as hyperbolic self–similar coordinates or simply
hyperbolic coordinates since the lines @xmath are hyperbolae in a
spacetime diagram.

Note that @xmath is only defined for @xmath and hence, the hyperbolic
coordinates cover the interior of the backward lightcone @xmath of the
blow up point @xmath . The inverse transformation is given by

  -- -------- --
     @xmath   
  -- -------- --

Fig. 7.4 shows lines of constant @xmath in a spacetime diagram where
@xmath . The dashed line is the backward lightcone of the blow up point.

### 7.3 Well–Posedness

We prove well–posedness of the Cauchy problem for the linearization of
eq. ( 7.9 ) which governs the linear flow around a self–similar solution
@xmath .

#### 7.3.1 Linearization

##### Linearized flow around @xmath

We substitute the ansatz @xmath in eq. ( 7.9 ) where @xmath is a
self–similar solution of eq. ( 7.2 ). Expanding the nonlinear term in
powers of @xmath and neglecting all terms of order higher than @xmath
yields the linear evolution equation

  -- -------- -- --------
     @xmath      (7.10)
  -- -------- -- --------

for the perturbation @xmath . The wave map @xmath is said to be linearly
stable if solutions of eq. ( 7.10 ) do not grow (with respect to some
suitable norm) as @xmath increases. However, we emphasize that our
discussion is still on a heuristic level since we have not specified
what we mean by a solution so far. Furthermore, we note that it is by no
means clear whether the nonlinear flow around @xmath can be approximated
by this linear equation. There are explicit examples of nonlinear
evolution equations where certain phenomena cannot be treated by linear
perturbation theory, although the perturbations are small in a certain
sense (e.g. [ 9 ] ). However, it is generally believed that
instabilities in the linearized problem lead to instabilities in the
nonlinear case and therefore it is useful to study the linearized
equation.

##### Symmetries

We informally discuss the role of the time translation symmetry of eq. (
7.2 ). Let @xmath be a solution of the original wave map equation ( 7.2
) in @xmath –coordinates. Define a function @xmath by @xmath . Then,
@xmath is also a solution of eq. ( 7.2 ). Hence, the mapping @xmath maps
solutions to solutions and satisfies @xmath , @xmath and @xmath . Let
@xmath be a self–similar solution with blow up time @xmath given by
@xmath . Then, @xmath and @xmath . Thus, @xmath maps self–similar
solutions with blow up time @xmath to self–similar solutions with blow
up time @xmath . The generator of the orbit @xmath is given by @xmath
and we readily calculate @xmath . For a self–similar solution @xmath in
@xmath –coordinates we obtain

  -- -------- --
     @xmath   
  -- -------- --

By direct calculation one easily verifies that @xmath solves eq. ( 7.10
) and hence, the time translation symmetry of eq. ( 7.2 ) is reflected
by an exponentially growing solution of the linearized equation ( 7.10
). This exponential instability is referred to as the gauge instability
.

Although @xmath is not differentiable at @xmath (the backward lightcone
of the singularity) we expect this solution to play a role in dynamical
time evolution since @xmath is not in the domain covered by the
hyperbolic coordinates (only @xmath is valid, cf. fig. 7.4 ). This fact
spoils the linear stability analysis to a certain degree since the best
we can expect is a growth estimate like @xmath for solutions of eq. (
7.10 ) which would only rule out the existence of solutions that grow
faster than the gauge instability.

#### 7.3.2 The Operator @xmath

Our aim is to give a rigorous operator formulation of the evolution
problem eq. ( 7.10 ) and apply the semigroup theory developed in sec.
5.1 to show well–posedness.

##### Simplifications

First of all we make the simple transformation @xmath where @xmath to
get rid of the first order term @xmath in eq. ( 7.10 ). The transformed
equation reads

  -- -------- -- --------
     @xmath      (7.11)
  -- -------- -- --------

We split the ”potential” and write eq. ( 7.11 ) as

  -- -------- -- --------
     @xmath      (7.12)
  -- -------- -- --------

where

  -- -------- --
     @xmath   
  -- -------- --

Note that @xmath is regular at @xmath , i.e. @xmath which can easily be
checked using de l’Hospital’s rule. The idea now is to give a well–posed
operator formulation of eq. ( 7.12 ) without @xmath and to apply a
perturbation argument. Thus, we first consider the formal differential
expression @xmath given by

  -- -------- --
     @xmath   
  -- -------- --

We set @xmath and define the Hilbert space @xmath by @xmath .

##### The method of Frobenius

We give a brief description of a well–known method which provides us
with asymptotic estimates for solutions of the equation @xmath . The
method of Frobenius is a standard approach for obtaining series
expansions for solutions of linear second order ordinary differential
equations with meromorphic coefficients around singular points. Consider
a differential equation @xmath in @xmath where @xmath and @xmath are
holomorphic functions except for a set of isolated points in the complex
plane. Suppose that @xmath is a regular singular point which means that
@xmath and @xmath exist. Then, there exist two linearly independent
solutions @xmath , @xmath whose asymptotic behaviour for @xmath can be
stated explicitly: We denote the solutions of the so–called indicial
equation @xmath by @xmath and @xmath (the indices ) where @xmath .

-   If the difference @xmath is not an integer then @xmath and @xmath
    where @xmath and @xmath are holomorphic around @xmath with @xmath
    and @xmath .

-   If the difference is an integer then we have @xmath and @xmath where
    again @xmath and @xmath are holomorphic around @xmath with @xmath
    and @xmath . The constant @xmath may also be zero and thus it is
    possible that the logarithmic term does not appear.

In either case these representations are valid in the largest open
circle around @xmath which contains no other singularity of @xmath or
@xmath .

##### Endpoint classification

Consider the Sturm–Liouville problem @xmath on @xmath . The endpoints
@xmath and @xmath are regular singular points and therefore, we can
apply the method of Frobenius to obtain asymptotic estimates for
solutions. Around @xmath the indices are @xmath and @xmath . Thus, there
is only one solution which belongs to @xmath near @xmath and
Sturm–Liouville theory (sec. 4.2 ) tells us that @xmath is in the
limit–point case. Around @xmath the indices are both equal to @xmath
which shows that there does not exist a solution which belongs to @xmath
near @xmath . Thus, @xmath is in the limit–point case as well.

##### Definition of the operator @xmath

We set @xmath and @xmath . Then, @xmath reads

  -- -------- --
     @xmath   
  -- -------- --

We define @xmath and @xmath for @xmath . According to Lemma 4.2.11 , the
operator @xmath is self–adjoint.

#### 7.3.3 Properties of @xmath

We claim that @xmath satisfies the estimate @xmath for some @xmath and
all @xmath . In order to show this we apply Hardy’s inequality.

###### Lemma 7.3.1 (Hardy’s inequality).

Let @xmath and @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

Similarly, if @xmath then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Let @xmath with @xmath . Integration by parts yields

  -- -------- --
     @xmath   
  -- -------- --

Using de l’Hospital’s rule and @xmath we conclude that

  -- -------- --
     @xmath   
  -- -------- --

Observe that @xmath and hence we have

  -- -------- --
     @xmath   
  -- -------- --

by Cauchy–Schwarz. Dividing by @xmath and squaring the resulting
inequality yields the claim. The same calculation can be applied for the
case @xmath . ∎

###### Lemma 7.3.2.

There exists a @xmath such that the operator @xmath satisfies the
estimate

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath .

###### Proof.

Suppose @xmath has compact support. Then, @xmath , @xmath and
integration by parts shows

  -- -------- --
     @xmath   
  -- -------- --

Observe that

  -- -------- --
     @xmath   
  -- -------- --

We use the letter @xmath for a generic real constant greater than zero
which is not assumed to have the same value every time it appears.
Furthermore, using Hardy’s inequality we estimate

  -- -------- --
     @xmath   
  -- -------- --

Adding up these two estimates we arrive at

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is a core for @xmath (Corollary 4.2.1 ) this inequality is
valid for all @xmath and we conclude that @xmath for a @xmath and all
@xmath . ∎

##### Well–posedness

We define @xmath , @xmath , @xmath , @xmath for @xmath . Applying
Theorem 5.1.2 we conclude that @xmath generates a strongly continuous
one–parameter semigroup @xmath on @xmath satisfying @xmath . In
particular, the Cauchy problem

  -- -------- --
     @xmath   
  -- -------- --

for @xmath with initial data @xmath which is an operator formulation of
the unperturbed equation

  -- -------- --
     @xmath   
  -- -------- --

is well–posed.

#### 7.3.4 Bounded Perturbations

Now we turn to the full linear equation

  -- -------- --
     @xmath   
  -- -------- --

An operator formulation can be given as follows. We adopt the notation
of the last section, i.e.

  -- -------- --
     @xmath   
  -- -------- --

for @xmath with initial data @xmath is an operator formulation of the
unperturbed equation ( @xmath ). Now we introduce a perturbation
operator @xmath defined by @xmath for @xmath . This definition makes
sense since @xmath and hence, @xmath if @xmath . We readily estimate
@xmath for all @xmath . Thus, @xmath is a bounded operator on @xmath and
@xmath for any @xmath . Therefore,

  -- -------- -- --------
     @xmath      (7.13)
  -- -------- -- --------

for @xmath with initial data @xmath is an operator formulation of the
full linearized problem eq. ( 7.12 ).

We apply the bounded perturbation theorem 5.2.1 to the operator @xmath
defined above which shows that @xmath generates a strongly continuous
one–parameter semigroup @xmath on @xmath satisfying

  -- -------- -- --------
     @xmath      (7.14)
  -- -------- -- --------

for all @xmath . It follows that the Cauchy problem eq. ( 7.13 )
describing the linearized flow around a self–similar solution @xmath in
hyperbolic coordinates is well–posed.

We note that the above estimate eq. ( 7.14 ) is not very satisfactory
because for the Turok Spergel solution @xmath we have @xmath which
yields

  -- -------- --
     @xmath   
  -- -------- --

while the original intention was to rule out solutions that grow faster
than the gauge instability. Translated to the semigroup approach this
would require the estimate @xmath (remember the transformation @xmath )
for the semigroup @xmath generated by @xmath . In order to achieve this
we have to study the spectrum of the operator @xmath in more detail
which is the topic of the next chapter.

## Chapter 8 The Spectrum of @xmath

We study in detail the spectrum of the operator @xmath which is the
generator of the semigroup describing the linearized flow around the
Turok Spergel solution @xmath . This will lead to a significant
refinement of the growth estimate 7.14 and eventually we will be able to
derive a result which rules out the existence of solutions of the
linearized equation ( 7.10 ) that grow faster than the gauge
instability.

### 8.1 The Operators @xmath and @xmath

We adopt the notation of sec. 7.3 , i.e. @xmath with @xmath , @xmath ,
@xmath , @xmath and @xmath , @xmath . First we discuss properties of the
operator @xmath defined by @xmath and

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the @xmath –th self–similar wave map (cf. Theorem 7.2.1
). Hence, @xmath is given by @xmath for @xmath where @xmath with @xmath
for @xmath . Thus, @xmath is the essential nontrivial part of @xmath .

First of all we note that the operator @xmath is self–adjoint. This can
either be shown directly via Sturm–Liouville theory or it follows from
the fact that @xmath is self–adjoint, the boundedness of the symmetric
multiplication operator @xmath on @xmath and the following theorem.

###### Theorem 8.1.1.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath . If
@xmath is bounded and symmetric then @xmath is self–adjoint.

###### Proof.

See [ 26 ] , p. 287. ∎

Hence, we see that the spectrum of @xmath is real. The following lemma
shows how the spectra of @xmath and @xmath are related.

###### Lemma 8.1.1.

Let @xmath . Then, @xmath if and only if @xmath .

###### Proof.

Invoking Lemma 5.1.6 we conclude that @xmath . Hence, it remains to show
that @xmath implies @xmath which is equivalent to @xmath .

Suppose @xmath , i.e. @xmath exists as a bounded operator on @xmath .
Let @xmath and define @xmath . Then, @xmath and hence, @xmath which
shows that @xmath is surjective. Now let @xmath with @xmath . We have
@xmath . However, since @xmath is injective, we conclude that @xmath
which shows that @xmath is injective as well. Thus, we infer @xmath . ∎

The above result shows that the spectrum of @xmath can be calculated
from the spectrum of @xmath and therefore, it suffices to study the
operator @xmath . Furthermore, since @xmath if @xmath , we observe that
@xmath is a subset of the union of the real and imaginary axis.

### 8.2 The Spectrum of @xmath

We explicitly calculate the spectrum of @xmath .

#### 8.2.1 Prerequisites

##### A technical lemma

In what follows we will frequently encounter two types of singular
behaviour. Terms of the form @xmath where @xmath becomes unbounded for
@xmath and expressions like @xmath where the integral is divergent for
@xmath while @xmath goes to zero. In either case the singular behaviour
of one factor might be compensated by the other one. Note that we cannot
treat these problems with de l’Hospital’s rule since normally the
function @xmath belongs to some Lebesgue space only and hence it cannot
be evaluated at single points. The following technical lemma shows how
to deal with such problems.

###### Lemma 8.2.1.

Let @xmath .

1.   If @xmath then @xmath , defined by @xmath , belongs to @xmath .

2.   If @xmath then @xmath , defined by @xmath , belongs to @xmath .

###### Proof.

Let @xmath .

1.  We define @xmath where @xmath . Using integration by parts and
    Cauchy’s inequality with @xmath we readily calculate

      -- -------- --
         @xmath   
      -- -------- --

    and hence, we arrive at the inequality

      -- -------- --
         @xmath   
      -- -------- --

    However, using the Cauchy–Schwarz inequality we estimate

      -- -------- --
         @xmath   
      -- -------- --

    which implies

      -- -------- --
         @xmath   
      -- -------- --

    and the claim follows.

2.  Define @xmath . For @xmath the very same calculation as above can be
    applied. For @xmath one encounters logarithmic terms but
    nevertheless the same reasoning goes through.

∎

###### Remark 8.2.1.

Of course, the choice of the interval @xmath in Lemma 8.2.1 is
completely arbitrary and therefore analogous results are true for a
general finite interval @xmath at either endpoint @xmath or @xmath .

##### The @xmath notation

In connection with asymptotic estimates it is useful to introduce a
common notation. Let @xmath and @xmath . We write @xmath for @xmath if
@xmath ¹ ¹ 1 @xmath is sometimes denoted as @xmath where @xmath is a
so–called Landau symbol. . Note that due to the usage of @xmath in the
definition, @xmath is not required to converge for @xmath . For instance
we have @xmath for @xmath . Simpler examples are @xmath and @xmath for
@xmath . But note carefully that according to our definition we also
have @xmath for @xmath .

#### 8.2.2 The Point Spectrum of @xmath

##### Singular points

We consider perturbations around the Turok Spergel solution @xmath . The
function @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

However, the term @xmath can be written as a rational function

  -- -------- --
     @xmath   
  -- -------- --

which reveals two singularities @xmath in the complex plane. Thus,
@xmath is meromorphic and the equation @xmath has six regular singular
points @xmath . With the help of the transformation @xmath this number
can be reduced by two. Hence, the general (formal) ² ² 2 We remark that
the term ”formal” in this context refers to the fact that an actual
solution must belong to @xmath . We do not consider so–called formal
power series solutions, i.e. series solutions whose convergence radius
is zero. solution of @xmath can be given in terms of Heun’s functions
which are the solutions of the general Fuchsian equation with four
regular singular points (cf. [ 43 ] ). However, since the study of
Heun’s functions relies heavily on numerical techniques, this
observation is not very useful for us at the present stage.

##### Asymptotic estimates

Nevertheless we can apply Frobenius’ method to obtain asymptotic
estimates of (formal) solutions of @xmath around @xmath and @xmath . The
equation @xmath reads

  -- -------- --
     @xmath   
  -- -------- --

and thus, the indices at @xmath and @xmath are @xmath and @xmath ,
respectively. It is clear that the solution which behaves as @xmath for
@xmath does not belong to @xmath and hence, eigenfunctions @xmath are
holomorphic around @xmath and satisfy @xmath . Furthermore, the
requirement @xmath yields @xmath . To conclude, we have the result that
every eigenfunction @xmath of @xmath is in @xmath and satisfies @xmath .

From the asymptotic estimates around @xmath we immediately infer that
there are no eigenvalues @xmath since neither of the two solutions is in
@xmath for @xmath because @xmath . Hence, we have shown that @xmath .

##### Nonexistence of eigenvalues smaller than 0

We apply a standard oscillation argument to show that there are no
negative eigenvalues of @xmath . The proof is based on the observation
that the gauge mode @xmath , defined by

  -- -------- --
     @xmath   
  -- -------- --

(formally) satisfies @xmath as already discussed in connection with the
gauge instability (cf. sec. 7.3 ). However, note that @xmath and hence,
it is only a formal solution. We remark that @xmath has no zeros in
@xmath which will be crucial now.

###### Lemma 8.2.2.

The equation @xmath has no nontrivial solutions for @xmath .

###### Proof.

Suppose @xmath is a nontrivial solution of @xmath for @xmath . It
follows that @xmath for @xmath and @xmath for @xmath where @xmath by
Frobenius’ method. The function @xmath satisfies the equation

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Let @xmath . We multiply by @xmath and integrate by parts
to obtain

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the Wronskian of the functions @xmath and @xmath .
For @xmath we obtain

  -- -------- --
     @xmath   
  -- -------- --

Note that the limit @xmath of the left–hand side exists thanks to the
asymptotic behaviour @xmath and @xmath . Without loss of generality we
assume @xmath . Suppose @xmath has its first zero at @xmath . It follows
that @xmath and

  -- -------- --
     @xmath   
  -- -------- --

which is a contradiction since the left–hand side is strictly negative (
@xmath !) while the right–hand side is either zero or positive. Hence,
@xmath does not have a zero in the interval @xmath which is a
contradiction to @xmath for @xmath and @xmath . ∎

###### Remark 8.2.2.

We note that this observation has first been made by Bizoń [ 10 ] .

Combining this result with @xmath we conclude that there are no
eigenfunctions at all and hence, the point spectrum of @xmath is empty!
We formulate this result as a proposition.

###### Proposition 8.2.1.

The point spectrum @xmath of @xmath is empty.

#### 8.2.3 Invertibility of @xmath for @xmath

Next, we study the continuous spectrum of @xmath , i.e. we consider the
inhomogeneous equation @xmath for a given @xmath . We are interested in
solutions defined on the open interval @xmath and fix @xmath . Let
@xmath and @xmath denote nontrivial (formal) solutions of the
homogeneous equation @xmath with the asymptotic behaviour @xmath for
@xmath and @xmath for @xmath where @xmath . The solutions @xmath ,
@xmath exist by Frobenius’ method and they are both defined on @xmath
since the minimal distance from @xmath (resp. @xmath ) to the next
singularity of the equation in the complex plane is @xmath . The two
solutions @xmath and @xmath are linearly independent as the following
lemma shows.

###### Lemma 8.2.3.

The functions @xmath and @xmath are linearly independent.

###### Proof.

Suppose @xmath and @xmath are linearly dependent. Then, the asymptotic
behaviour of @xmath is @xmath for @xmath which means that @xmath . Thus,
@xmath is an eigenfunction of @xmath which is a contradiction to Prop.
8.2.1 which states that @xmath . ∎

By normalization we can always have @xmath which will be assumed from
now on.

We apply the variation of constants formula to obtain a formal solution
of @xmath for @xmath . The general solution can be written as

  -- -------- -- -------
     @xmath      (8.1)
  -- -------- -- -------

for @xmath where @xmath and @xmath are free constants. The so–defined
@xmath satisfies @xmath and by differentiation one easily verifies that
it (formally) satisfies @xmath . Thus, the question is whether the
constants @xmath can be adjusted in such a way that the resulting @xmath
belongs to @xmath . The answer is yes as the following lemma shows.

###### Lemma 8.2.4.

For a given @xmath define

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Then, @xmath and @xmath .

###### Proof.

With the help of the asymptotic estimates @xmath , @xmath for @xmath and
@xmath , @xmath for @xmath where @xmath , @xmath together with Lemma
8.2.1 one easily observes that @xmath belongs to @xmath . ∎

Hence, for any @xmath and @xmath we can explicitly construct a function
@xmath such that @xmath which shows that the operator @xmath is
surjective. Combining this result with @xmath we arrive at the following
proposition.

###### Proposition 8.2.2.

The set @xmath is contained in the resolvent set @xmath of the operator
@xmath , i.e. @xmath exists for @xmath .

#### 8.2.4 The Operator @xmath for @xmath

Finally, we study invertibility of the operator @xmath for @xmath . We
fix @xmath and consider the homogeneous equation @xmath . The method of
Frobenius implies the existence of two linearly independent solutions
around @xmath which both behave as @xmath for @xmath . Furthermore,
around @xmath we have a solution which behaves as @xmath for @xmath .
Thus, we can find two linearly independent solutions @xmath and @xmath
on @xmath which satisfy @xmath for @xmath and @xmath for @xmath . Again,
by normalization we can assume that @xmath . According to the variation
of constants formula eq. ( 8.1 ), solutions @xmath of @xmath for given
@xmath have the form

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Now we try to adjust the constants @xmath in such a way
that the resulting @xmath belongs to @xmath . Since @xmath for @xmath we
are forced to choose @xmath to compensate this bad behaviour. Hence, we
have

  -- -------- -- -------
     @xmath      (8.2)
  -- -------- -- -------

For any choice of @xmath we can certainly find an @xmath satisfying

  -- -------- --
     @xmath   
  -- -------- --

For such an @xmath we have @xmath for @xmath since the first two terms
in eq. ( 8.2 ) cancel in the limit @xmath . Obviously, @xmath and hence
there exists an @xmath which is not in the range of @xmath . Thus, the
operator @xmath is not surjective for @xmath . This shows that every
@xmath belongs to the continuous spectrum of @xmath since self–adjoint
operators do not have residual spectra and hence, we have @xmath .

This result concludes our discussion of the spectrum of @xmath and
eventually we arrive at the following theorem.

###### Theorem 8.2.1.

The spectrum of the operator @xmath is given by @xmath .

### 8.3 Improved Growth Estimate

With the results of the previous sections at hand we are able to improve
the insufficient growth estimate

  -- -------- --
     @xmath   
  -- -------- --

derived in sec. 7.3 for the semigroup @xmath governing the linearized
flow around the Turok Spergel solution in hyperbolic coordinates.

Since @xmath we conclude that @xmath for all @xmath (Lemma 4.1.1 ).
Thus, Theorem 5.2.2 tells us that @xmath generates a strongly continuous
one–parameter semigroup @xmath satisfying @xmath for all @xmath .

Consider the conserved energy given by @xmath for a classical solution
@xmath with initial data @xmath . Since @xmath we see that there does
not exist a @xmath , @xmath with @xmath . Hence, the energy is a norm on
@xmath and we have @xmath for a classical solution with initial data
@xmath . Actually we are interested in the function @xmath (recall the
rescaling @xmath ) and hence, we conclude that there does not exist a
classical solution which grows faster than the gauge instability.
According to the discussion in sec. 7.3 this is the best result we could
have expected. It shows that the Turok Spergel solution is as stable as
it can possibly be in these coordinates. Hence, this result strongly
supports the conjecture of linear stability of @xmath .

### 8.4 Discussion

We give a physical interpretation of the spectral behaviour of the
operator @xmath .

#### 8.4.1 The Spectrum of @xmath

According to Lemma 8.1.1 , the spectrum @xmath of @xmath is given by
@xmath . Thus, since @xmath , it follows that @xmath , i.e. the spectrum
of @xmath fills the imaginary axis. However, we emphasize that the point
spectrum @xmath is empty and hence, there are no eigenvalues.
Nevertheless, this spectrum is expected to lead to an exponential growth
of solutions of the equation

  -- -------- -- -------
     @xmath      (8.3)
  -- -------- -- -------

which describes the time evolution of linear perturbations of the Turok
Spergel solution (remember the rescaling @xmath where @xmath drives the
evolution of @xmath ). We have already discussed that the gauge
instability is supposed to lead to solutions that grow like @xmath for
@xmath . However, this instability cannot be responsible for the whole
spectrum. Hence, the spectral behaviour of @xmath calls for a physical
(or more intuitive) explanation.

#### 8.4.2 Physical Explanation

It turns out that the structure of the spectrum of @xmath is closely
related to the nature of the coordinate system @xmath . A heuristic
explanation of the instabilities caused by the spectrum of @xmath can be
given by the following argument. Consider a perturbation which has the
form of a Gaussian. The time evolution will lead to outgoing wave
packets which travel from smaller @xmath to larger @xmath . However,
they cannot leave the backward lightcone of the singularity since the
hyperbolic coordinates break down at @xmath . Hence, the wave will
eventually cumulate near @xmath and one observes exponential growth of
the solution. Thus, this seemingly unstable behaviour is due to a defect
of the coordinate system @xmath .

Fig. 8.1 illustrates this phenomenon. The hyperbolic lines are sections
@xmath . The shaded region represents an outgoing wave which eventually
leaves the backward lightcone (the dashed line). In @xmath coordinates
the wave comes closer and closer to @xmath but never reaches it.

#### 8.4.3 Numerical Verification

We employ some simple numerics to integrate the equation

  -- -------- --
     @xmath   
  -- -------- --

in order to illustrate the behaviour of solutions of the perturbation
equation ( 8.3 ). We discretize the equation using the same scheme as in
sec. 7.1 . The characteristic speeds are given by @xmath and hence, they
attain their maximal absolute value @xmath at @xmath which implies that
@xmath is sufficient to satisfy the CFL–condition.

Fig. 8.2 shows the time evolution of a Gauß pulse. As expected, the wave
packets slow down and eventually freeze as they approach the backward
lightcone at @xmath . Fig. 8.3 shows a plot of the function @xmath of
the same time evolution. For late times the norm behaves like a constant
and hence, the corresponding @xmath grows exponentially. This
instability is caused by the continuous spectrum of the operator @xmath
as discussed in the previous section.

## Chapter 9 The Functional Calculus

For the sake of completeness we discuss another, completely different
method for the treatment of ordinary differential equations on Banach
spaces. This method is the standard operator theoretic approach in
quantum mechanics for studying dynamics of the Schrödinger equation. It
relies on the concept of functions of self–adjoint operators, i.e. the
functional calculus provides a method to define an operator @xmath for a
complex–valued function @xmath and a self–adjoint operator @xmath .
Thus, solutions of ordinary differential equations on Banach spaces can
be given in ”explicit” form as functions of self–adjoint operators.
However, this approach is not an equivalent substitute to semigroup
theory since it is by construction restricted to self–adjoint operators
while the notion of self–adjointness does not play a role in the
formulation of semigroup theory. However, the examples we have studied
so far have been formulated in a self–adjoint manner and hence, the
functional calculus provides an alternative approach to these problems.

### 9.1 The Spectral Theorem

The material outlined in this section can be found in much more detail
in standard textbooks, e.g. [ 59 ] .

#### 9.1.1 Spectral Families, Measures

##### Spectral Families

Let @xmath be a Hilbert space and consider a family @xmath of orthogonal
projections @xmath depending on a real parameter @xmath . Hence, for
each @xmath , @xmath is a linear bounded self–adjoint operator on @xmath
which satisfies @xmath . The family @xmath is called a spectral family
or resolution of the identity if it satisfies

-   @xmath for all @xmath

-   @xmath and @xmath for all @xmath

-   @xmath for all @xmath

##### Measures

Once there is given a spectral family it is possible to construct
certain measures. Fix @xmath and define @xmath . Then, @xmath is
monotonically increasing and right continuous, i.e. @xmath if @xmath and
@xmath . Hence, @xmath is a distribution function in the sense of
measure theory. Given a distribution function @xmath one can show that
there exists a unique measure @xmath which satisfies @xmath for @xmath
where @xmath denotes the Borel @xmath –algebra on @xmath . Note that
@xmath and hence, the measure is finite. Moreover, observe that due to
the special properties of @xmath we have @xmath for @xmath .

For fixed @xmath we define another, complex–valued finite measure @xmath
by

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Invoking the polarization identity it follows that
@xmath for @xmath .

#### 9.1.2 Operators Defined via Measures

##### Projections

Fix @xmath , @xmath and consider the mapping @xmath defined by @xmath .
First, we claim that @xmath for any @xmath . Since the measure @xmath is
uniquely determined by its values on half–open intervals it suffices to
show properties for @xmath where @xmath and they automatically remain
true for arbitrary @xmath . Hence, the claim follows immediately from
the formula @xmath . Furthermore, we have @xmath for @xmath and @xmath .
Therefore, @xmath is a bounded linear functional on @xmath . Invoking
the Riesz representation theorem 3.1.1 we conclude that there exists a
unique @xmath such that @xmath for all @xmath . Hence, for any @xmath
there exists a well–defined unique mapping @xmath such that @xmath for
all @xmath . It is easy to see that @xmath is linear and bounded. Note
that by construction we have @xmath and hence, we have extended these
projections to arbitrary Borel sets. Another way to write @xmath is
@xmath for all @xmath .

##### Properties of @xmath

Note that @xmath by definition of @xmath and hence, @xmath is
self–adjoint. Furthermore, @xmath for all @xmath and @xmath half–open
intervals. By uniqueness of the measure we have @xmath for arbitrary
@xmath and half–open intervals @xmath . However, using the
self–adjointness of @xmath we can interchange the role of @xmath and
@xmath and hence, @xmath holds for all @xmath . In particular it follows
that @xmath and thus, @xmath is an orthogonal projection.

##### The domain of @xmath

With the help of the measures @xmath and @xmath we can define an
operator @xmath for a given measurable function @xmath in the following
way. Set

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath implies @xmath for any @xmath since by definition we have
@xmath for @xmath and, by uniqueness of the measure @xmath , it follows
that @xmath . Similarly, for @xmath we have @xmath by the triangle
inequality and hence, @xmath implies @xmath which shows that @xmath is a
subspace of @xmath .

Furthermore, @xmath is dense in @xmath which can be seen as follows.
Define @xmath for @xmath . Since @xmath is measurable, @xmath for all
@xmath . Let @xmath and set @xmath . Then we have

  -- -------- --
     @xmath   
  -- -------- --

since @xmath for all @xmath . Therefore, @xmath for all @xmath and one
easily sees that @xmath in @xmath .

##### The operator @xmath

Fix @xmath and consider the mapping @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

One readily observes that @xmath is a bounded linear functional on
@xmath and hence, by the Riesz representation theorem there exists a
well–defined operator @xmath such that @xmath for all @xmath . It is
easily seen that @xmath is linear and symbolically one usually writes

  -- -------- --
     @xmath   
  -- -------- --

#### 9.1.3 Spectral Families and Self–Adjoint Operators

##### The spectral theorem

It turns out that to every self–adjoint operator there is associated a
unique spectral family. This result is known as the spectral theorem .
More precise we have the following statement.

###### Theorem 9.1.1.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath . Then,
there exists a unique spectral family @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

##### Representations

All the information concerning the spectrum of a self–adjoint operator
@xmath is encoded in its spectral family @xmath .

To see this we note that for any spectral family @xmath we have the
representation

  -- -------- --
     @xmath   
  -- -------- --

for the identity operator @xmath on @xmath . This can be immediately
seen by inserting the definitions. Consider the operator @xmath (cf.
sec. 9.1.2 ). Then we have @xmath and @xmath for all @xmath and hence,
@xmath . Thus, the operator @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the unique spectral family associated to @xmath .
Furthermore, one can show that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the measure associated to @xmath defined in sec. 9.1.1 .

##### The spectrum of @xmath

We have @xmath if and only if there exists a @xmath , @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

We conclude that the distribution function @xmath given by @xmath has to
be constant except for a possible discontinuity at @xmath . The
requirements @xmath and @xmath together with right continuity of @xmath
imply @xmath for @xmath and @xmath for @xmath . Hence, @xmath is an
eigenvalue of @xmath with eigenvector @xmath if and only if @xmath for
@xmath and @xmath for @xmath .

Similarly, one can show that @xmath is equivalent to @xmath for all
@xmath and @xmath for @xmath . As already proved in sec. 3.3.3 , the
residual spectrum @xmath is empty.

Thus, we have @xmath if and only if the associated spectral family
@xmath is constant on a neighbourhood of @xmath . This, together with
the requirements @xmath and @xmath implies that the spectrum of a
self–adjoint operator is nonempty!

### 9.2 Functions of Self–Adjoint Operators

Let @xmath be a self–adjoint operator on a Hilbert space @xmath . With
the help of the spectral theorem we are now able to define functions of
@xmath . Again, all the material presented in this section can be found
in standard textbooks, e.g. [ 59 ] . We also mention the freely
available book [ 54 ] .

#### 9.2.1 Definitions and Properties

##### Definition of @xmath

By the spectral theorem there exists a unique spectral family @xmath
such that @xmath has the representation @xmath or, less symbolically,
@xmath for all @xmath and @xmath where @xmath is the complex–valued
measure associated to @xmath defined in sec. 9.1.1 . Let @xmath be a
measurable function. Then, we define an operator @xmath by @xmath and
@xmath where @xmath is the operator defined in sec. 9.1.2 , i.e. we have

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and @xmath where, as before, @xmath . As already
mentioned, @xmath is densely defined and linear.

##### Calculus for functions of self–adjoint operators

One can show that @xmath for any @xmath , i.e. @xmath commutes with
@xmath . Furthermore, we have the following functional calculus for
@xmath (see e.g. [ 59 ] for a proof).

-   @xmath and @xmath for all @xmath .

-   Let @xmath be a measurable function. Then, we have the
    representation

      -- -------- --
         @xmath   
      -- -------- --

    for all @xmath and @xmath .

-   @xmath for all @xmath , @xmath and @xmath for all @xmath .

-   @xmath for @xmath is equivalent to @xmath and we have @xmath for all
    @xmath .

-   If @xmath is finite everywhere on @xmath then the adjoint @xmath is
    given by @xmath and hence, @xmath which shows that @xmath is a
    normal operator . In particular, @xmath is self–adjoint if @xmath is
    finite everywhere and real–valued.

#### 9.2.2 Unitary Groups

Let @xmath be a Hilbert space. A mapping @xmath is called a strongly
continuous one–parameter group of linear operators on @xmath if @xmath
satisfies @xmath , @xmath for all @xmath and the mapping @xmath is
continuous for all @xmath . @xmath is called unitary if @xmath for all
@xmath and any @xmath . In particular, every strongly continuous
one–parameter group is a strongly continuous one–parameter semigroup of
linear operators and hence, the notion of a generator of a semigroup
carries over to groups. The following proposition shows how to
explicitly construct a strongly continuous unitary one–parameter group
with the help of the functional calculus for a given self–adjoint
generator.

###### Proposition 9.2.1.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath . Define
@xmath and @xmath via the functional calculus. Then, @xmath have the
following properties.

1.   For any @xmath , @xmath is a bounded linear operator on @xmath
    which satisfies @xmath for all @xmath .

2.  @xmath and @xmath for all @xmath .

3.   For any @xmath , the function @xmath is continuous.

4.   The limit @xmath exists if and only if @xmath and in this case we
    have

      -- -------- --
         @xmath   
      -- -------- --

    Thus, @xmath is the generator of @xmath .

###### Proof.

1.  Let @xmath . Application of the functional calculus yields

      -- -------- --
         @xmath   
      -- -------- --

    for any @xmath where @xmath is the measure defined in sec. 9.1.1 for
    the spectral family @xmath associated to the self–adjoint operator
    @xmath . Hence, @xmath is a unitary linear operator on @xmath .

2.  This follows immediately from the functional calculus.

3.  Fix @xmath and let @xmath . Applying the functional calculus we have

      -- -------- --
         @xmath   
      -- -------- --

    by Lebesgue’s theorem on dominated convergence.

4.  Let @xmath . Applying the functional calculus we obtain

      -- -------- --
         @xmath   
      -- -------- --

    by Lebesgue’s theorem on dominated convergence. Hence, we have shown
    @xmath for all @xmath . However, using the group property and strong
    continuity of @xmath we infer

      -- -------- --
         @xmath   
      -- -------- --

    and similarly we obtain @xmath .

    Now let @xmath be the generator of @xmath , i.e.

      -- -------- --
         @xmath   
      -- -------- --

    and @xmath . Then we have

      -- -------- --
         @xmath   
      -- -------- --

    for all @xmath since @xmath by the functional calculus. This shows
    that the operator @xmath is a symmetric extension of @xmath .
    However, since @xmath is self–adjoint there do not exist proper
    symmetric extensions and therefore we have @xmath .

∎

###### Remark 9.2.1.

We have shown that @xmath generates a strongly continuous unitary
one–parameter group if @xmath is self–adjoint. It turns out that the
converse is also true, i.e. that any strongly continuous unitary
one–parameter group @xmath on a Hilbert space @xmath is of the form
@xmath for a self–adjoint operator @xmath . This result is known as
Stone’s theorem (cf. [ 59 ] ).

### 9.3 Well–Posedness of Wave Equations

Applying the theory outlined in the previous sections we are now able to
consider abstract wave equations on Hilbert spaces. This yields a
well–posedness result for a certain class of equations and moreover, it
is possible to write down the solution in a rather explicit form with
the help of the functional calculus. For more information we refer to [
5 ] .

#### 9.3.1 Well–Posedness for Strictly Positive Generators

The first result is the analogue of Theorem 5.1.2 in semigroup theory.
Let @xmath be a self–adjoint operator on a Hilbert space @xmath
satisfying @xmath for all @xmath . Then there exists the square root
@xmath of @xmath which is again self–adjoint (Theorem 4.1.1 or directly
via functional calculus). We consider the unitary groups @xmath .

###### Lemma 9.3.1.

Let @xmath be a self–adjoint operator satisfying @xmath for all @xmath .
For @xmath define @xmath via the functional calculus. Then, the function
@xmath satisfies the wave equation @xmath for all @xmath where @xmath .
Furthermore, the same holds true for @xmath .

###### Proof.

Define @xmath for @xmath . From Prop. 9.2.1 we already know that @xmath
for all @xmath . Furthermore, @xmath commutes with @xmath . Thus, since
@xmath , we have @xmath and hence, applying Prop. 9.2.1 again, we obtain

  -- -------- --
     @xmath   
  -- -------- --

The same reasoning goes through for @xmath . ∎

Now we assume the slightly stronger condition @xmath for all @xmath and
some @xmath and consider the operators @xmath and @xmath . According to
the functional calculus they are given by

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, since @xmath , it follows that @xmath (cf. Lemma 5.1.5 )
and in particular, @xmath is bounded invertible. Hence, the operator
@xmath exists and is inverse to @xmath . Now we have collected all the
necessary tools to prove the analogue of the generation result Theorem
5.1.2 .

###### Theorem 9.3.1.

Let @xmath be a self–ajoint operator on a Hilbert space @xmath
satisfying @xmath for all @xmath and a @xmath . Then, for given @xmath ,
there exists a unique function @xmath such that @xmath for all @xmath
and @xmath , @xmath . The unique solution @xmath can be given explicitly
as

  -- -------- --
     @xmath   
  -- -------- --

Moreover, the real–valued function @xmath (”the energy ”) is constant
for all @xmath .

###### Proof.

Let @xmath . Applying Lemma 9.3.1 it follows immediately that @xmath
given by

  -- -------- --
     @xmath   
  -- -------- --

satisfies @xmath for all @xmath and @xmath , @xmath . Moreover,
inserting for @xmath and using the functional calculus we directly
compute

  -- -------- --
     @xmath   
  -- -------- --

which shows conservation of energy.

Let @xmath be another solution with initial data @xmath and @xmath .
Then, @xmath is again a solution with zero initial data. However,
conservation of energy implies that @xmath . Note that by definition we
have @xmath and hence,

  -- -------- --
     @xmath   
  -- -------- --

which shows @xmath for all @xmath . ∎

###### Remark 9.3.1.

Note that the solution operators @xmath and @xmath are bounded and
hence, they can be applied to general functions @xmath and not only to
@xmath . Analogous to semigroup theory this leads to the notion of
generalized solutions of abstract wave equations.

#### 9.3.2 Well–Posedness for Nonnegative Generators

The condition @xmath for a @xmath assumed in the previous section was
necessary to assure existence of the operator @xmath . However, the
operator @xmath appears only as @xmath in the solution formula. Thus,
the question is whether @xmath can be defined reasonably even if @xmath
does not exist. This problem is analogous to considering the real–valued
function @xmath defined by @xmath . Since @xmath by de l’Hospital,
@xmath can be continuously extended to @xmath . Thanks to the functional
calculus it is exactly this construction which can be used for the
operator @xmath as well.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath which
satisfies @xmath for all @xmath . Then, the self–adjoint square root
@xmath exists and it satisfies @xmath for all @xmath (Theorem 4.1.1 ).
For @xmath we define @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Then, @xmath is continuous and hence, @xmath is well–defined via the
functional calculus. Note that the inequality @xmath for all @xmath
implies @xmath (cf. Lemma 5.1.5 ) and hence, the distribution function
@xmath for @xmath is constant on @xmath where @xmath is the spectral
family associated to @xmath . Thus, the values of @xmath on @xmath do
not contribute.

###### Lemma 9.3.2.

The function @xmath defined by @xmath for a given @xmath satisfies
@xmath for all @xmath .

###### Proof.

Let @xmath be the spectral family of @xmath (spectral theorem) and
@xmath the spectral measure associated to @xmath defined in sec. 9.1.1 .
Observe that @xmath since @xmath is bounded and therefore, the operator
@xmath is bounded for any @xmath . Applying the functional calculus we
obtain

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath by Lebesgue’s theorem on dominated convergence and
therefore, @xmath . Analogously, we have

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath which is the claim. ∎

###### Remark 9.3.2.

In particular it follows that @xmath for all @xmath if @xmath .

Now we are able to prove the well–posedness result for nonnegative
generators.

###### Theorem 9.3.2.

Let @xmath be a self–adjoint operator on a Hilbert space @xmath
satisfying @xmath for all @xmath . Then, for given @xmath there exists a
unique function @xmath such that @xmath for all @xmath and @xmath ,
@xmath . This unique @xmath can be given explicitly as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is defined by

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, the energy

  -- -------- --
     @xmath   
  -- -------- --

is constant.

###### Proof.

Let @xmath . Applying Lemmas 9.3.2 and 9.3.1 we conclude that @xmath ,
given by @xmath , satisfies @xmath for all @xmath and @xmath , @xmath .
By inserting for @xmath and direct computation (functional calculus) we
obtain

  -- -------- --
     @xmath   
  -- -------- --

Uniqueness can be obtained analogously to Theorem 9.3.1 . ∎

###### Remark 9.3.3.

Again, we also have generalized solutions since the solution operators
@xmath and @xmath are bounded and hence, they can be applied to any
element in @xmath .

#### 9.3.3 Application to the Linearized Wave Map Problem

Now we return to the equation

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

which describes the (rescaled) linearized flow around the Turok Spergel
solution in hyperbolic coordinates (cf. sec. 7.3 ).

##### Operator formulation

As before we define @xmath for @xmath and @xmath denotes the operator
constructed in sec. 8.1 . Hence, the equation @xmath for a function
@xmath is an operator formulation of eq. ( 9.1 ).

##### Well–posedness

According to sec. 8.1 , the operator @xmath is self–adjoint and from
Theorem 8.2.1 we know that @xmath . Thus, @xmath satisfies @xmath for
all @xmath (Lemma 4.1.1 ). Applying Theorem 9.3.2 we infer that the
Cauchy problem

  -- -------- -- -------
     @xmath      (9.2)
  -- -------- -- -------

for given @xmath and a function @xmath is well–posed.

Moreover, Theorem 9.3.2 tells us that for any classical solution of eq.
( 9.2 ) the energy @xmath is conserved.

##### Nonexistence of growing solutions

As discussed previously (sec. 8.3 ), the mapping @xmath is a norm on
@xmath and hence, conservation of energy implies the nonexistence of
growing solutions with respect to @xmath . Thus, there are no solutions
of the equation

  -- -------- --
     @xmath   
  -- -------- --

that grow faster than the gauge instability which behaves as @xmath for
@xmath . This shows that the Turok Spergel solution is as stable as it
can be in the hyperbolic coordinates.

##### Discussion

We conclude that the functional calculus yields essentially the same
result as the semigroup approach but it is more explicit. In either case
the main effort lies in determining the spectrum of the operator @xmath
.

Thus, we have exploited the self–adjoint approach (hyperbolic
coordinates) to the linear stability problem and have obtained the best
possible result. To gain further insight one has to change coordinates.
However, in a different coordinate system the involved operators become
much less convenient since they are not self–adjoint anymore.

## Chapter 10 The Spectra of @xmath

This chapter is devoted to the study of the spectra of the operators
@xmath for @xmath . We show that the operator @xmath has exactly @xmath
negative eigenvalues and give a rough lower bound for the smallest
eigenvalue. Furthermore, we investigate the spectral behaviour of @xmath
for @xmath .

Througout this chapter we adopt the previously used notation, i.e.
@xmath with @xmath , @xmath is the self–adjoint operator generated by
the Sturm–Liouville differential expression @xmath given by @xmath where
@xmath and @xmath . Moreover, the operator @xmath is defined by @xmath
and

  -- -------- --
     @xmath   
  -- -------- --

for @xmath and

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the @xmath –th self–similar wave map.

### 10.1 The Spectrum

#### 10.1.1 The Continuous Spectrum

As already mentioned (Theorem 7.2.1 ), Bizoń has shown existence of the
smooth self–similar wave maps @xmath . However, in fact the solutions
@xmath are not only smooth but even analytic on @xmath , i.e. they can
be expanded in a convergent power series around any point @xmath (cf. [
11 ] ). Furthermore, they satisfy @xmath and @xmath . Hence, all the
results of sec. 8.2 which do not depend on the explicit form of @xmath
but solely on the asymptotic behaviour for @xmath and @xmath carry over
to @xmath without change. In particular, the whole Frobenius analysis is
equally valid for @xmath . Thus, we have the following proposition.

###### Proposition 10.1.1.

The continuous spectrum @xmath of @xmath for any @xmath is given by
@xmath .

#### 10.1.2 The Point Spectrum

As in the case @xmath , the gauge instability (cf. sec. 7.3 ) is
present. Thus, the function @xmath defined by @xmath is a formal
solution of @xmath . More explicitly, @xmath reads

  -- -------- -- --------
     @xmath      (10.1)
  -- -------- -- --------

According to theorem 7.2.1 , the self–similar wave map @xmath has
exactly @xmath intersections with the line @xmath on @xmath . Thus,
since @xmath , it follows that @xmath has exactly @xmath zeros on @xmath
. Hence, an oscillation argument similar to Lemma 8.2.2 implies that
there are exactly @xmath numbers @xmath such that eq. ( 10.1 ) with
@xmath has a nontrivial solution @xmath satisfying @xmath ( @xmath ).
According to the Frobenius analysis in sec. 8.2 , @xmath has the
asymptotic behaviour @xmath for @xmath and @xmath for @xmath where
@xmath . Thus, we immediately observe that @xmath for @xmath and hence,
@xmath is an eigenfunction of @xmath if @xmath . This shows that the
operator @xmath has exactly @xmath negative eigenvalues @xmath .
Analogous to sec. 8.2 it follows that @xmath is invertible for negative
@xmath which are not in the point spectrum and hence, we arrive at the
following theorem.

###### Theorem 10.1.1.

The spectrum of the operator @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

for @xmath .

#### 10.1.3 A Simple Estimate

We apply an elementary argument to obtain a rough lower bound for the
smallest eigenvalue of @xmath .

###### Lemma 10.1.1.

The smallest eigenvalue @xmath of @xmath satisfies the estimate

  -- -------- --
     @xmath   
  -- -------- --

for any @xmath .

###### Proof.

First of all we show that the infimum exists. We abbreviate

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath for all @xmath it follows that @xmath and @xmath . However,
@xmath and therefore it must have a minimum on @xmath .

Now suppose @xmath is an eigenfunction of @xmath with eigenvalue @xmath
. By Frobenius it follows that @xmath and @xmath . Without loss of
generality we assume @xmath . In order to satisfy the boundary condition
@xmath , @xmath has to have a maximum. Let the first maximum be located
at @xmath . Thus, we have @xmath , @xmath and @xmath . Inserting in eq.
( 10.1 ) we obtain

  -- -------- --
     @xmath   
  -- -------- --

which is a contradiction. ∎

### 10.2 Numerics

We intend to numerically calculate the point spectrum of the operator
@xmath . To this end it is necessary to construct the self–similar wave
map @xmath . As already mentioned, this has first been done in [ 3 ]
with a shooting and matching procedure and we will reproduce these
results. The point spectrum of @xmath can be obtained by the same
technique and this has been done in [ 10 ] .

#### 10.2.1 Construction of Self–Similar Wave Maps

We construct the self–similar solutions @xmath with a standard shooting
and matching technique. It turns out that the derivative @xmath
increases very quickly with @xmath becoming larger and hence, it is
advantageous to use a logarithmic coordinate. Thus, we define @xmath for
a small @xmath . Eq. ( 7.7 ) transforms into

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

where @xmath . We have the regularity conditions @xmath and @xmath . For
integrating eq. ( 10.2 ) we use the ODE solver provided by the GNU
Scientific Library [ 24 ] . Fig. 10.1 shows the first five solutions
calculated with @xmath .

#### 10.2.2 Calculation of the Point Spectrum

We numerically calculate solutions of the eigenvalue equation @xmath
which is given explicitly by

  -- -------- -- --------
     @xmath      (10.3)
  -- -------- -- --------

for @xmath . We have @xmath by Theorem 10.1.1 and hence, we restrict
ourselves to @xmath . The boundary conditions at the singular points
@xmath and @xmath are dictated by the requirement @xmath . According to
the Frobenius analysis of sec. 8.2 , @xmath implies @xmath for @xmath
and @xmath for @xmath where @xmath . However, since @xmath increases as
@xmath decreases we encounter a technical diffculty: In order to ”shoot
away” from the singular point @xmath we have to calculate more and more
derivatives as @xmath decreases. To go around this problem we define a
new unknown @xmath . It follows that @xmath as @xmath if @xmath and
hence, @xmath is analytic if @xmath . Moreover, the ”bad” solution
around @xmath behaves as @xmath and thus, it can easily be distinguished
numerically from the ”good” one since it is singular at @xmath . This is
essential in order to obtain a well–behaved numerical approximation. Eq.
( 10.3 ) transforms into the generalized eigenvalue problem

  -- -------- -- --------
     @xmath      (10.4)
  -- -------- -- --------

where we have set @xmath .

We solve the eigenvalue problem with the shooting and matching method
similar to the construction of self–similar wave maps in the previous
section: Let @xmath and @xmath denote the solutions obtained by
integrating eq. ( 10.4 ) from @xmath to @xmath and @xmath to @xmath ,
respectively. As a matching condition we require the Wronskian @xmath to
vanish. This has the advantage that we can fix @xmath as well as @xmath
and the only free parameter is the eigenvalue @xmath . Hence,
eigenvalues can be found by a simple bisection and one is not forced to
use a multidimensional root finder which can be tricky. The numerical
results are summarized in Table 10.1 .

We avoid a detailed error analysis since we do not need these numbers in
the sequel but merely note the interesting observation that the
horizontal rows seem to converge. This numerical convergence raises the
question whether there exists a relation like ” @xmath ” where @xmath is
the perturbation operator around the limiting solution @xmath (cf. sec.
7.2 ). We will discuss this issue in the following section.

### 10.3 The Operator @xmath

We study the operator @xmath which describes linear perturbations around
the limiting solution @xmath (cf. sec. 7.2 ).

The (rescaled) flow of linear perturbations around the limiting solution
@xmath is governed by eq. ( 7.11 ) with @xmath substituted by the
constant @xmath , i.e.

  -- -------- -- --------
     @xmath      (10.5)
  -- -------- -- --------

Thus, the operator @xmath is generated by the formal differential
expression @xmath defined by

  -- -------- -- --------
     @xmath      (10.6)
  -- -------- -- --------

where @xmath , @xmath and @xmath . Thus, we define the underlying
Hilbert space @xmath as @xmath and apply the method of Frobenius in
order to obtain asymptotic estimates for solutions of @xmath . Around
@xmath the indices of the Frobenius analysis are both equal to @xmath
and thus, the situation is completely analogous to @xmath and @xmath is
in the limit–point case. However, around @xmath the indices are @xmath
which means that all nontrivial solutions of @xmath belong to @xmath
near @xmath . Thus, @xmath is in the limit–circle case and in order to
define a self–adjoint operator we have to specify a boundary condition
at @xmath . But which boundary condition is the ”correct” one? Bizoń [ 7
] has studied the analogous problem for Yang–Mills equations and he
proposed to choose the boundary condition in such a way that there
exists a nontrivial solution of @xmath similar to the gauge instability
for @xmath .

#### 10.3.1 The Boundary Condition

For @xmath let @xmath be the solution of @xmath with asymptotic
behaviour @xmath for @xmath where @xmath (which exists by Frobenius’
method). We are interested in the asymptotic behaviour of @xmath for
@xmath . According to Frobenius’ method we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath as well as @xmath are holomorphic around @xmath and satisfy
@xmath . The complex number @xmath is called the connection coefficient
. The asymptotic behaviour of @xmath can be written in a more convenient
way.

###### Lemma 10.3.1.

For @xmath let @xmath be a real solution of @xmath with asymptotic
behaviour @xmath for @xmath where @xmath . Then, @xmath can be written
as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a real constant, @xmath , @xmath and

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As already mentioned above, we have

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is real by assumption, we have @xmath and hence, we infer

  -- -- --
        
  -- -- --

where @xmath and @xmath are real–valued and defined by @xmath .
Moreover, @xmath , @xmath and @xmath which follows immediately from the
properties of @xmath and @xmath . Thus, the identity @xmath where @xmath
finishes the proof. ∎

According to Bizoń’s proposal, eigenfunctions should satisfy @xmath .
The following lemma shows how this requirement can be translated into a
boundary condition.

###### Lemma 10.3.2.

For @xmath let @xmath be a real solution of @xmath with asymptotic
behaviour @xmath where @xmath . Assume further that @xmath where @xmath
is defined in Lemma 10.3.1 . Then, @xmath is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

###### Proof.

Applying Lemma 10.3.1 and using the addition theorem for trigonometric
functions we readily obtain

  -- -------- --
     @xmath   
  -- -------- --

which yields the claim since @xmath . ∎

#### 10.3.2 Construction of the Operator

We construct the self–adjoint operator @xmath by imposing the boundary
condition discussed in the previous section.

To this end recall the definition of the maximal operator @xmath
generated by @xmath which is given by

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for @xmath .

We denote by @xmath a real–valued nontrivial function satisfying @xmath
with asymptotic behaviour @xmath for @xmath . Such a function exists by
Frobenius’ method and it is unique up to constant multiples since the
other linearly independent solution of @xmath around @xmath contains a
logarithmic term. Note, however, that @xmath due to its asymptotic
behaviour for @xmath . Using a smooth cut–off function we construct a
@xmath satisfying @xmath for @xmath . Obviously, there exists a @xmath
with @xmath . We define the operator @xmath by

  -- -------- --
     @xmath   
  -- -------- --

and @xmath for @xmath . Invoking Lemma 4.2.12 we immediately infer that
@xmath is self–adjoint.

#### 10.3.3 Calculation of the Point Spectrum

Consider the formal eigenvalue equation @xmath . We make a coordinate
transformation @xmath and define a new unknown

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath . The equation @xmath transforms into

  -- -------- -- --------
     @xmath      (10.7)
  -- -------- -- --------

where @xmath , @xmath and @xmath . Eq. ( 10.7 ) is the hypergeometric
differential equation (cf. [ 1 ] ). Around @xmath there exist two
linearly independent solutions @xmath and @xmath given by @xmath and
@xmath where @xmath denotes the hypergeometric function (cf. [ 1 ] ). We
are interested in eigenfunctions and hence, the condition @xmath rules
out the solution @xmath since @xmath for @xmath . Around @xmath the two
linearly independent solutions @xmath and @xmath are given by @xmath and
@xmath . By the general theory of linear second order ordinary
differential equations we infer that for @xmath we can write

  -- -------- --
     @xmath   
  -- -------- --

The connection coefficient @xmath can be given explicitly in terms of
the @xmath –function [ 18 ] and reads

  -- -------- --
     @xmath   
  -- -------- --

The boundary condition specified in the definition of @xmath translates
into the requirement @xmath . This transcendental equation can be solved
numerically using bisection and by this we obtain the point spectrum
@xmath of @xmath . The results are given in Table 10.2 where we have set
@xmath . Furthermore, we have duplicated Table 10.1 for comparison.

Hence, the numerical results suggest that the point spectrum of @xmath
converges to @xmath for @xmath .

## Chapter 11 Further Results and Outlook

So far we have studied linear stability of the Turok Spergel solution
@xmath in hyperbolic coordinates. We have identified two features which
spoil the analysis to a certain degree. First, the time translation
symmetry of the original problem leads to an exponentially growing
solution of the perturbation equation. This fact corresponds to an
isolated point in the continuous spectrum of the operator @xmath .
However, one could easily go around this problem by defining a
projection operator which removes this point from the spectrum of @xmath
. By this, one would immediately gain linear stability of @xmath as
conjectured. The reason why this does not work is the nature of the
coordinate system which induces an unbounded part in the continuous
spectrum of @xmath . Thus, the only possibility is to introduce a new
time coordinate @xmath different from @xmath . However, this destroys
the self–adjoint character of the problem which makes it much more
difficult. To illustrate the problems one has to deal with we consider
the (possibly simplest) choice @xmath . The resulting linarized equation
around the self–similar solution @xmath reads

  -- -------- -- --------
     @xmath      (11.1)
  -- -------- -- --------

Thus, one obtains a mixed derivative since the coordinate lines are not
orthogonal anymore. Such a term turns out to be very inconvenient. We
formally rewrite this evolution equation as a first order system of the
form

  -- -------- --
     @xmath   
  -- -------- --

for a matrix differential operator @xmath . Now we consider the
eigenvalue equation @xmath which reduces to

  -- -------- -- --------
     @xmath      (11.2)
  -- -------- -- --------

Since @xmath this equation has six regular singular points @xmath .
Using the transformation @xmath one is left with the four singularities
@xmath . Thus, solutions are given in terms of Heun’s functions (cf. [
43 ] ). However, most of the knowledge concerning Heun’s functions is
based on numerical techniques and thus, it is very difficult to obtain
the ”spectrum” of this generalized eigenvalue problem. Furthermore, it
is by no means clear what boundary conditions one should specify at the
singular points @xmath and @xmath . In the self–adjoint formulation the
choice of the function space is dictated by the operator itself but in
this non–self–adjoint setting we do not have such an information. Thus,
as a first step one would have to find a function space such that @xmath
is properly defined and the linear evolution problem eq. ( 11.1 ) is
well–posed which is probably not so easy. Secondly, one has to analyse
the spectrum of @xmath , i.e. study eq. ( 11.2 ) with appropriate
boundary conditions. There exist partial results addressing this issue
by the author [ 16 ] which state that eq. ( 11.2 ) has no analytic
solutions for real @xmath unless @xmath . Furthermore, this problem has
been investigated numerically (cf. [ 8 ] , [ 15 ] ) and these studies
strongly suggest that @xmath is indeed the only ”eigenvalue” with
positive real part. We note that the origin of this unstable mode is
well understood since it stems from the time translation symmetry of the
wave map equation similar to the gauge instability we have encountered
in the self–adjoint formulation. Thus, if one could make these ideas
rigorous it would be possible to use a spectral projection which removes
the eigenvalue @xmath from the spectrum of @xmath and prove linear
stability of @xmath .

Of course, the ultimate goal would be proving nonlinear stability of
this solution. We do not try to make this precise but merely note that
quite recently [ 31 ] rigorous results have been obtained for a
different (easier) problem where some of the difficulties arising there
seem to be similar to our wave map model. Concerning self–similar blow
up for semilinear wave equations we also mention [ 22 ] and [ 36 ] , [
35 ] although the latter deal with the energy (sub)critical case. There
is also a notion of orbital stability pioneered by Weinstein (cf. e.g. [
57 ] ) which might be able to deal with the difficulties arising from
the fact that @xmath is a one–parameter family of functions rather than
a single solution. However, this approach has mainly been worked out for
the Schrödinger equation which is quite a different problem. To conclude
we have to admit that a rigorous proof of nonlinear stability of @xmath
seems to be beyond the scope of present techniques.

Finally, we emphasize that the results obtained in this thesis are not
confined to the particular wave map model which has been considered. In
principle, they are equally applicable to any evolution equation of the
form

  -- -------- --
     @xmath   
  -- -------- --

if it shows similar behaviour (existence of self–similar solutions). A
prominent example is the Yang–Mills field in @xmath dimensions which is
in the same criticality class as our wave maps model and analogous
phenomena have been observed for this system. Bizoń has studied this
model [ 7 ] and he has proved existence of a countable family of
self–similar solutions. The analysis presented in this thesis carries
over to the Yang–Mills model with minor changes.

## Appendix A Symbols

  -------- -------------------------------------------------------
  @xmath   The natural numbers @xmath
  @xmath   The natural numbers including zero @xmath
  @xmath   The integer numbers @xmath
  @xmath   The real numbers
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  @xmath   @xmath
  @xmath   The complex numbers
  @xmath   @xmath
  @xmath   The complex conjugate of @xmath
  @xmath   The real part of @xmath
  @xmath   The imaginary part of @xmath
  @xmath   Partial derivative of @xmath with respect to @xmath
  @xmath   The identity on a set @xmath , i.e. @xmath for @xmath
  @xmath   The null space or kernel of a linear mapping @xmath
           between two vector spaces @xmath and @xmath ,
           i.e. @xmath
  @xmath   The image or range of a mapping @xmath between
           two sets @xmath , @xmath , i.e. @xmath
  -------- -------------------------------------------------------