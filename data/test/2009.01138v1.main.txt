##### Contents

-    Publications
-    1 Introduction
    -    1.1 QCD
    -    1.2 Relativistic hydrodynamics
    -    1.3 Heavy Ion Collisions
    -    1.4 Neutron stars
    -    1.5 Holography
        -    1.5.1 Bottom-up holography: IHQCD and V-QCD
-    2 (Inverse) Magnetic Catalysis in Holographic QCD
    -    2.1 Analysis of V-QCD model in the presence of a magnetic field
        and anisotropy
        -    2.1.1 Extending V-QCD to incorporate a magnetic field and
            anisotropy
        -    2.1.2 Equations of motion and boundary conditions
        -    2.1.3 Symmetries of the equations of motion
        -    2.1.4 Computing observables
        -    2.1.5 Satisfying constraints
        -    2.1.6 Obtaining a phase diagram
    -    2.2 Inverse magnetic catalysis due to a magnetic field
        -    2.2.1 Varying the @xmath potential
        -    2.2.2 Varying the number of flavors
    -    2.3 Inverse magnetic catalysis in the presence of a nonzero
        chemical potential
        -    2.3.1 Phase diagram and thermodynamics
        -    2.3.2 Chiral condensate and inverse magnetic catalysis
    -    2.4 Inverse anisotropic catalysis due to an anisotropy
        -    2.4.1 IR behavior
        -    2.4.2 Thermodynamics
        -    2.4.3 Observables
    -    2.5 Interplay between magnetic field and anisotropy
-    3 Holographic Baryons and Neutron Stars
    -    3.1 Baryons in V-QCD
        -    3.1.1 Expansion of the DBI action
        -    3.1.2 Obtaining baryon number from the Chern-Simons action
        -    3.1.3 The homogeneous approximation
        -    3.1.4 The Legendre transformed action
        -    3.1.5 Numerical method
        -    3.1.6 Results
    -    3.2 Hybrid neutron star equations of state
        -    3.2.1 Matching procedure
        -    3.2.2 Mass-radius relation and tidal deformability
        -    3.2.3 Holographic neutron star mergers
-    4 Simulation of Heavy Ion Collisions with Trajectum
    -    4.1 Overall design of Trajectum
    -    4.2 collide executable
        -    4.2.1 Initial conditions
        -    4.2.2 Hydrodynamics models
        -    4.2.3 Transport coefficients
        -    4.2.4 PDE solvers
        -    4.2.5 Hadronizers
    -    4.3 analyze executable
        -    4.3.1 Charged particle multiplicities and spectra
        -    4.3.2 Mean transverse momentum
        -    4.3.3 Anisotropic flow
        -    4.3.4 Event-by-event anisotropic flow
-    5 Discussion and Outlook
    -    5.1 (Inverse) magnetic catalysis in holographic QCD
    -    5.2 Holographic baryons and neutron stars
    -    5.3 Simulation of heavy ion collisions with Trajectum
-    Acknowledgements
-    Samenvatting
-    A V-QCD potentials
    -    A.1 Inverse magnetic catalysis
    -    A.2 Baryons

## Publications

This thesis is based on the following publications:

-   Umut Gürsoy, Ioannis Iatrakis, Matti Järvinen and Govert Nijs,
    Inverse Magnetic Catalysis from improved Holographic QCD in the
    Veneziano limit ,
    JHEP 03  (2017) 053 , [ 1611.06339 ].

-   Umut Gürsoy, Matti Järvinen and Govert Nijs,
    Holographic QCD in the Veneziano Limit at a Finite Magnetic Field
    and Chemical Potential ,
    Phys. Rev. Lett. 120  (2018) 242002 , [ 1707.00872 ].

-   Umut Gürsoy, Matti Järvinen, Govert Nijs and Juan F. Pedraza,
    Inverse Anisotropic Catalysis in Holographic QCD ,
    JHEP 04  (2019) 071 , [ 1811.11724 ].

-   Takaaki Ishii, Matti Järvinen and Govert Nijs,
    Cool baryon and quark matter in holographic QCD ,
    JHEP 07  (2019) 003 , [ 1903.06169 ].

-   Christian Ecker, Matti Järvinen, Govert Nijs and Wilke van der
    Schee,
    Gravitational Waves from Holographic Neutron Star Mergers ,
    Phys. Rev. D 101  (2020) 103006 , [ 1908.03213 ].

## Chapter 1 Introduction

The work described in this thesis is all centered around one goal:
understanding the theory of the strong interaction, QCD. Looking at the
Lagrangian that defines it, this theory is simple and elegant. Yet this
simple fundamental description results in a rich phenomenology, because
the theory is strongly coupled in many regimes of interest. This leads
to two reasons why studying QCD is interesting. On the one hand, the
strongly coupled nature of many of the objects of study in QCD provides
us with a playground in which we can learn how non-perturbative physics
works. On the other hand, many outstanding problems in QCD are the main
obstacles to understanding other problems. As an example of this, many
properties of neutron stars require an equation of state (EoS) to
compute, and to obtain this EoS one has to solve a QCD problem. In a
way, these two reasons for studying QCD go hand in hand. Returning to
the example of neutron stars, as our knowledge of the QCD equation of
state grows, so does our knowledge of neutron stars, and on the other
hand, as more measurements on neutron stars are done, we can use those
measurements to learn something about QCD, and hence about strong
coupling.

During my PhD, I have worked towards the goal of understanding QCD from
three directions, corresponding to the remaining chapters in this
thesis, excluding the conclusion. Each of these chapters can be read
mostly independently, as only minor details should be unclear from
reading a chapter by itself. Wherever this occurs I reference where the
details can be looked up for the interested reader. In the sections
below I give an introduction to the concepts used throughout the
remaining chapters, starting with an QCD itself, its main features and
its quantities of interest.

### 1.1 Qcd

QCD is the non-Abelian gauge theory of @xmath , which is minimally
coupled to a number of quark flavors @xmath . In the standard model,
there are of course 6 flavors. However, the three heaviest flavors are
too heavy to be of importance for many observables, and can be safely
neglected. ¹ ¹ 1 Heavy quarks serve as excellent probes for energy loss
in a quark-gluon plasma though, as they retain their identities on the
timescales of a heavy ion collision, and hence serve as experimentally
clean probes. In this thesis, we need a slight generalization of QCD,
namely to that of a gauge group @xmath , where now @xmath and @xmath can
be freely chosen as theory parameters. The Lagrangian for this
generalized QCD is

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

with

  -- -------- --
     @xmath   
  -- -------- --

with @xmath , and @xmath the mass of quark flavor @xmath .

This theory has the property that the beta function of the coupling
@xmath is negative to first order in perturbation theory provided that
@xmath [ 119 , 204 ] . A consequence of this negative beta function is
that the coupling constant decreases towards higher energies, a
phenomenon known as asymptotic freedom, and increases towards lower
energies. In figure 1.1 , one can see that this is indeed also seen in
experiments.

It can be seen that around @xmath , the coupling constant becomes @xmath
, and the theory can no longer be accurately described by perturbation
theory. This is a huge obstacle in the way of understanding QCD at low
energy scales. One method by which one can still compute certain
observables in the non-perturbative regime is lattice QCD. This method
discretizes QCD on a Euclidean lattice, enabling the computation of
non-dynamical observables by Monte Carlo integration of the euclidean
path integral. Lattice QCD is a reliable method to compute not only
thermal properties of QCD, but also hadron masses, which have been
favorably compared to experimental values. It is not without its
downsides though, as the Euclidean formalism makes the computation of
dynamical processes extremely challenging. Also, for similar reasons, it
turns out to be rather difficult to introduce a finite baryon chemical
potential, an issue known as the sign problem [ 7 ] . A detailed
discussion of lattice QCD is beyond the scope of this thesis, but
excellent introductions can be found in [ 239 , 110 ] .

Two features of QCD which appear in the low energy regime are
confinement and chiral symmetry breaking. Confinement is the phenomenon
that states have to be color neutral, implying that particles carrying
color charge, such as quarks and gluons, can not occur as isolated
particles. One example of this which can be computed in lattice QCD is
the quark-antiquark potential, which is shown in the left panel of
figure 1.2 [ 38 ] .

This quark-antiquark potential quantifies the potential energy between a
heavy quark paired with an antiquark of the same flavor, and can be seen
to grow linearly at large separation. Assuming that all quarks in the
theory are infinitely massive, this means that one would have to spend
an infinite amount of energy to separate the quark-antiquark pair. In
the case of realistic quark masses, instead this implies that once the
quarks are separated far enough, the potential energy stored in the
gluon field will be large enough such that a new quark-antiquark pair
can be created. The new quarks then each pair with one of the original
quarks to create two color neutral mesons.

Chiral symmetry breaking refers to the approximate global chiral
symmetry

  -- -------- --
     @xmath   
  -- -------- --

which acts on ( 1.1 ) such that the @xmath generators act on the
left-handed quark components by multiplication, while the @xmath
generators act on the right-handed components. This symmetry is only
approximate in ( 1.1 ), but becomes exact in the limit where the quarks
are massless. The QCD vacuum, however, breaks this approximate symmetry
further spontaneously. The order parameter of this chiral symmetry
breaking is the chiral condensate operator @xmath , which can be defined
for each flavor @xmath . In the right panel of figure 1.2 , one can see
the chiral condensate as a function of temperature, computed using
lattice QCD [ 103 ] . Note that the renormalized chiral condensate is
shown, which is defined by the subtraction of a constant such that the
chiral condensate at zero temperature vanishes. One can clearly see that
indeed the order parameter @xmath , which is small at large
temperatures, grows for small temperatures.

A subsequent question one can ask is whether the transition between a
chirally symmetric phase without confinement, known as the quark-gluon
plasma, at high temperatures and the chirally broken confining vacuum
are separated by a cross-over or a first order phase transition. In the
Columbia plot [ 83 ] , shown in the left panel of figure 1.3 , one can
see that the answer to this question depends on the masses of the
quarks.

One can see that for the physical values of the quark masses, the
transition is a cross-over. In the right panel of figure 1.3 , one can
see the equation of state as a function of temperature for vanishing
baryon chemical potential [ 46 ] . Here too, it is apparent that the
transition is a cross-over.

In the presence of a finite baryon chemical potential, the situation may
be different. In figure 1.4 , a sketch is shown of what the phase
diagram is expected to look like as a function of both temperature and
baryon chemical potential.

Also, the regions probed by heavy ion collision experiments at RHIC and
LHC are shown, with center-of-mass energies indicated. The cross-over
seen in figure 1.3 is seen in figure 1.4 along the vertical axis. As one
moves to larger chemical potentials, the cross-over is expected to turn
into a first order phase transition at a critical endpoint. The search
for such an endpoint is the purpose of the Beam Energy Scan program at
RHIC [ 185 ] . If we look at the low temperature, large chemical
potential region of the phase diagram, we see nuclear matter indicated.
At chemical potential values beyond this value, still at low
temperatures, we enter the regime in which the matter making up neutron
stars exists. It is not known whether the densities inside a neutron
star are large enough to probe a potential phase transition as indicated
in figure 1.4 , but at some large density it is expected that yet a new
state of matter forms, known as a color superconductor [ 18 ] . One of
the main reasons why these features in the phase diagram are as of yet
unknown is the aforementioned sign problem, which precludes a first
principles calculation of these features. The two experimental probes
into the phase diagram, namely heavy ion collisions and neutron stars,
are both described by relativistic hydrodynamics, which is what we will
describe next.

### 1.2 Relativistic hydrodynamics

Relativistic hydrodynamics is an effective theory which describes the
behavior of fluids in local thermal equilibrium. It can be described by
the conservation of conserved quantities that the underlying theory has.
This always includes the conservation of the stress-energy tensor, but
can also include other conserved currents, such as baryon number
density. ² ² 2 In principle, one can write down as many conserved
currents as desired. We will restrict ourselves to just the baryon
number density. Let us take this theory as an example. We then have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the conserved current associated to baryon number
density. This set of equations cannot be solved though, which can be
seen by a simple counting argument. Indeed, we have 10 independent
components in the stress-energy tensor, and 4 in the baryon current,
whereas we have only 5 equations to constrain them. Further input is
therefore needed. This comes as no surprise, as it would be rather
strange if the behavior of the conserved quantities were completely
determined by the conservation laws themselves, and had no dependence on
the underlying microscopic theory.

The extra input used to close the system of equations is called the
constitutive relations, which determine @xmath and @xmath in terms of
the temperature @xmath , baryon chemical potential @xmath and fluid
velocity @xmath . The constitutive relations can framed in terms of an
expansion in derivatives of @xmath , @xmath and @xmath . Below, we will
discuss three examples of such relations, namely that of ideal
hydrodynamics with a conserved baryon number density, first order
Israel-Stewart theory without a conserved baryon number density, and
second order hydrodynamics, also without any conserved quantities other
than the stress-energy tensor. These three cases correspond exactly to
the three cases which will be used in the remainder of this thesis. We
will however restrict ourselves to just a description of these theories,
giving just the basic idea of the ingredients used to derive them. There
are many different detailed derivations available in the literature, see
e.g. [ 224 , 40 , 176 ] . Before moving on to the examples of
constitutive relations however, note that one can easily couple the
equations of hydrodynamics to those of general relativity by using the
hydrodynamic stress-energy tensor defined by the constitutive relations
in the Einstein equations.

Let us now look at the first example of constitutive relations, namely
that of ideal hydrodynamics with a conserved baryon number density. In
this case, we have

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath is a projector satisfying @xmath , and @xmath , @xmath and
@xmath are for now arbitrary functions of the temperature and chemical
potential. Note also that the metric @xmath follows the mostly minus
convention, in accordance with most literature on hydrodynamics. Also,
since the metric can in principle be something other than Minkowski, all
derivatives in this section can be assumed to be covariant unless stated
otherwise. One can check that ( 1.2 ) are the most general expressions
for @xmath and @xmath which do not involve derivatives of @xmath ,
@xmath or @xmath . For this reason this constitutive relation is zeroth
order in the derivative expansion. Now let us examine the above
expression in the fluid rest frame, in which @xmath . We then have

  -- -------- --
     @xmath   
  -- -------- --

which we can compare to the known result for a fluid at rest to deduce
that we should interpret the arbitrary functions @xmath , @xmath and
@xmath as energy density, pressure and baryon number density,
respectively. Relating these three quantities through the equation of
state, we can close the system of equations, rendering it solvable.
These constitutive relations are used for the neutron star merger
simulations in chapter 3 , where they are solved together with the
Einstein equations.

For the remainder of this section, we will disregard @xmath , and
consider a theory with only a conserved stress-energy tensor. We will
also add the first order in derivative corrections. To this end, let us
first introduce the following derivatives:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the gradient in the fluid rest frame, and @xmath is the
time derivative in the fluid rest frame. We now write the first equation
of ( 1.2 ) as

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

Here we have removed the dependence on @xmath as there is no more baryon
number density, and added the bulk pressure @xmath and the shear tensor
@xmath , where @xmath is traceless ( @xmath ) and orthogonal ( @xmath ).
We have also rewritten @xmath and @xmath as a single function @xmath .
For the bulk pressure and shear tensor we have the following expression
in terms of derivatives:

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

which is the most general expression at first order in derivatives which
satisfies the second law of thermodynamics [ 176 ] . Here @xmath and
@xmath are the bulk viscosity and shear viscosity, respectively. Both
@xmath and @xmath are required to be positive to respect the second law
of thermodynamics [ 176 ] . The @xmath tensor is a symmetric tensor
satisfying the same tracelessness and orthogonality conditions as @xmath
:

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

Here we define the angled brackets as symmetrizing a tensor, and at the
same time removing the trace.

There is one big problem with these constitutive relations though,
namely that they allow for superluminal propagation, thereby violating
causality. This can be solved in the following way, which may seem ad
hoc, but can be derived in several different ways [ 224 ] . The solution
is to replace the identifications in ( 1.4 ) by the following
differential equations, called the Israel-Stewart equations [ 159 ] :

  -- -------- -------- -- -------
     @xmath   @xmath      (1.6)
     @xmath   @xmath      (1.7)
  -- -------- -------- -- -------

where the projectors in front of @xmath ensure that the differential
equation preserves tracelessness and orthogonality, and the positive
functions @xmath and @xmath are called the shear relaxation time and
bulk relaxation time, respectively. Summarizing, the Israel-Stewart
equations give us four parameters, called transport coefficients:

  -- -------- --
     @xmath   
  -- -------- --

where the dependence on the energy density, or equivalently the
temperature, is indicated. These transport coefficients depend on the
microscopic details of the theory, and hence encode information about
the underlying theory. Since they also enter the equations governing the
hydrodynamical evolution, they also have an influence on macroscopic
observables, which can in principle be measured experimentally.

Second order hydrodynamics is a generalization of the above discussion.
The stress-energy tensor is still described by ( 1.3 ), but the
relaxation equations for the bulk pressure ( 1.6 ) and shear stress (
1.7 ) are expanded to the following form:

  -- -------- -------- -- -------
     @xmath   @xmath      (1.8)
              @xmath      
     @xmath   @xmath      (1.9)
              @xmath      
  -- -------- -------- -- -------

We can see that the second order terms add the following transport
coefficients:

  -- -------- --
     @xmath   
  -- -------- --

These transport coefficients can, just as the first order transport
coefficients, in principle be derived from the microscopic theory, and
they also can potentially be measured experimentally. Both the first and
second order constitutive relations will be used in chapter 4 , where
they will be used to describe the quark-gluon plasma stage of
simulations of heavy ion collisions.

### 1.3 Heavy Ion Collisions

At large temperatures, QCD matter undergoes a transition to a
quark-gluon plasma (QGP) phase, as can be seen in figure 1.4 . Such
large temperatures can be achieved experimentally by depositing extreme
amounts of energy inside a small volume, and letting the system
equilibrate towards a thermal state. For this system to be able to reach
a near-equilibrium state though, the spatial extent of the system must
be sufficient such that the energy density dissipates away faster than
the system takes to equilibrate. If this condition is met, a significant
portion of the system’s evolution will be described by a QGP, which can
be described using hydrodynamics as discussed above. Systems in which
this is possible are heavy ion collisions. In a heavy ion collision
experiment such as those conducted at RHIC and the LHC, two atomic
nuclei are accelerated in opposite directions, and collide inside a
particle detector. The resulting matter produced in the collision
‘hydrodynamizes’ on a timescale of less than @xmath , which is much
smaller than the spatial extent of the resulting plasma if the colliding
nuclei are large and collide ‘head-on’. An interesting question is
indeed how small a collision system can be for it to still form a QGP
(See [ 199 ] for a recent review.). In the following paragraphs, we will
describe in some detail the physical processes occuring during a heavy
ion collision. We will subsequently end this section with a discussion
of experimental observables. See also [ 69 ] for a recent review of this
topic.

For the discussion of the processes occuring during a heavy ion
collision, let us focus on a specific example. At the LHC, lead-208
nuclei are collided at center-of-mass energy per nucleon of @xmath and
@xmath . Different snapshots of an animation of such a collision can be
seen in the left panel of figure 1.5 .

Here the numbers in the bottom of each snapshot indicate the time in
@xmath , with @xmath being defined as the moment the collision occurs,
and the collision is viewed from the side, i.e. the beam passes through
the figure from left to right. Because the nuclei each have a very large
energy, in the lab frame they appear extremely Lorentz contracted, as
can be seen in the snapshot at @xmath . The nuclei then pass through
each other, interacting and leaving matter in their wake. This matter is
what we will be discussing the evolution of below.

Before continuing the discussion on the different stages this matter
goes through, one important point is that the two nuclei need not
collide head-on, as can be seen in the right panel of figure 1.5 . In
that figure, we are looking in the direction of the beam, i.e. the two
dimensions shown are transverse to the beam. Since the nuclei are very
small compared to the size of the beam, the so-called ‘impact
parameter’, or the transverse distance between the centers of the
colliding nuclei, is essentially random. As a consequence of this, heavy
ion collisions as measured in an experiment are not all of the same
type, as collisions with a small impact parameter (called central
events) are very different from those with a large impact parameter
(called peripheral or off-central events). One difference is that the
number of participants in the collision correlates with the number of
particles measured in the final state, which causes central events to
have more particles in their final states. Another difference is in the
initial geometry. Lead-208 is spherical on average, and therefore
central events are also to a good approximation spherical. Off-central
events like the one shown in the right panel of 1.5 instead are quite
elongated.

Let us now consider with the discussion of what happens after the
collision. As was mentioned, when the nuclei pass through each other,
they leave matter in their wake. This matter is produced, to a good
approximation, in a way which is invariant under boosts in the beam
direction. At some time after the initial collision, the resulting
matter can be described by hydrodynamics. This process is called
‘hydrodynamization’. Note that this is different from thermalization, as
the matter is at this stage not yet in equilibrium, which shows itself
in the fact that the matter is not homogeneous, and large gradients of
the stress-energy tensor exist. The process by which this
hydrodynamization happens is poorly understood, and even how fast this
happens is subject to debate. Kinetic theory suggests that
hydrodynamization occurs after roughly @xmath [ 178 ] . Holography,
which will be discussed in section 1.5 , predicts even earlier values of
perhaps @xmath [ 248 ] . Furthermore, different models for this
pre-equilibrium stage describing this hydrodynamization process give
qualitatively different answers for the state of the hydrodynamic fluid
immediately after hydrodynamization.

The next stage in the description of a heavy ion collision is the
hydrodynamical evolution of the fluid created in the hydrodynamization
process. For this stage, the physical description is well understood,
namely viscous hydrodynamics. What is less well understood are the
values of the various transport coefficients entering the evolution
through ( 1.8 – 1.9 ). Of the transport coefficients listed, the ones
with the most pronounced effect on the experimental observables are the
shear and bulk viscosities. This makes sense, because hydrodynamics is a
derivative expansion, where higher order derivatives are assumed to be
less important for the evolution. The shear and bulk viscosities are the
only first order coefficients in this expansion, expressing the fact
that they have the most influence on the evolution of the fluid and
hence on the final experimental observables. In figure 1.6 , the results
from a Bayesian analysis are shown, in which among other quantities both
these viscosities were fitted to experimental data.

Of theoretical interested is that these viscosities can be obtained by
means of holography, which will be discussed in section 1.5 . In
particular, [ 188 , 203 , 175 , 70 ] obtained a surprisingly small value
for the ratio of the shear viscosity to entropy density ratio:

  -- -------- --
     @xmath   
  -- -------- --

where one should note that the assumption of infinite coupling strength
is an important ingredient in the holographic computation. As can be
seen in figure 1.6 , this value is compatible with the results from the
Bayesian analysis for values near the QCD cross-over, where the
effective coupling strength is expected to be large. This lends
credibility to the idea that holography can be used to at least give
qualitative insight into QCD.

At some point after the collision, the fluid has cooled and diluted
enough so that the interactions can no longer maintain local
hydrodynamic equilibrium, and hydrodynamics no longer provides a good
description of the fluid. Theoretical models reflect this change by
switching to a particle description at a certain temperature called the
freeze-out temperature @xmath . Note here that this change in
description depends not so much on the time, but instead on the
temperature. This means that even though the language in this section
conveys this process as occuring sequentially in time, the time at which
freeze-out occurs is not the same for different regions of the plasma.

After the system has cooled enough so that it is no longer described by
hydrodynamics, there are still interactions between the particles, which
can be well described by solving a Boltzmann equation. However, as the
system expands further, at some point the particles become far enough
separated that they no longer interact. After this time, except for the
decay of unstable particles, no further interactions occur, and the
particles travel in straight trajectories until they are detected. In
fact, these final particles are all that can be measured. None of the
other processes mentioned can be directly observed, so all conclusions
about the processes described above have to be inferred from the final
state particles and their correlations. As one can imagine, this is an
enormous obstacle towards understanding the processes involved, because
the final state typically depends on all of the physical processes
involved in the collision.

Before discussing the various observables one can define in terms of the
final state particles, let us mention one more physical process, which
will be neglected in the rest of this thesis, but should nevertheless be
mentioned. During the initial collision, it is possible that two
nucleons undergo a hard scattering, creating high-momentum particles.
These particles form jets, which subsequently propagate through the
medium. This process contains a wealth of information about the medium,
but as we will not simulate jets in chapter 4 , we will not discuss them
in detail.

Let us now move on to the discussion of the observables which can be
experimentally measured. This discussion will necessarily be limited to
a small subset, but this should give a good impression of the main types
of observables and the type of information they carry about the physical
processes mentioned above. Here, note that this will be a general
discussion, and the precise definitions of observables computed in this
thesis and their comparison to experimental data will be done in chapter
4 . To start, let us note that the spatial extent of the QGP is only a
couple of femtometers, which is too small to be able to measure any
spatial information. Hence all observables are defined in terms of the
momenta of the final state particles, where subtle differences between
observables can be made based on which particles to count, such as
conditions on the momenta and particle species.

For these definitions, let us decompose the transverse momentum of each
particle in the following way:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the transverse momentum and @xmath is the azimuthal
angle. In addition, we define the rapidity @xmath and the pseudorapidity
@xmath :

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

where @xmath is the energy of the particle, and the @xmath -component of
the momentum points along the beam axis. Note that in the case of
massless particles, we have @xmath , and also note that while computing
@xmath requires knowledge of a particle’s mass, @xmath is a pure angle.
Most observables are defined in terms of only particles satisfying
certain constraints on their momenta. The main reason for this is that
experimentally, detectors are not 100% efficient in detecting every
single particle from an event, where efficiencies vary depending on
particularly @xmath and @xmath . One could try and correct for this, but
it is easier to just exclude particles from the most inefficient regions
from the analysis. Indeed, for theorists it is easy to simply apply the
same cuts, and this allows for a cleaner comparison.

With the momentum decomposition in hand, let us now define centrality.
As was mentioned in the beginning of this section, the amount of overlap
of the initial nuclei is very important, where central events with a
small impact parameter produce many particles in a roughly spherical
manner, while more peripheral events produce fewer particle in a more
anisotropic way. Unfortunately, there is no way to experimentally
determine the impact parameter, and therefore the ‘centrality’ is
defined in a different way. Since we know that central events produce
more particles than peripheral ones, it makes sense to use the number of
particles (most often the number of charged particles to be precise)
produced by an event as a proxy for the impact parameter. In this way,
we determine for each event how many particles it produced, and sort all
of them from many particles to few. Then we define centrality by
percentiles, i.e. the event with the most particles is by definition 0%
central, while the event with the fewest is by definition 100% central,
and the other events interpolate between these extremes.

Using the above discussion, we can already define a few observables,
such as the number of particles produced per unit pseudorapidity @xmath
and the mean transverse momentum @xmath . As it turns out, the number of
particles produced correlates well with the entropy produced in the
initial stage of the collision, because viscous corrections in the
hydrodynamical evolution are too small to generate appreciable amounts
of entropy, and the final state entropy is proportional to the number of
particles. The momenta of the particles produced in the final state are
to some approximation those of a boosted thermal ensemble. Because of
this, the mean transverse momentum is mostly sensitive to the freeze-out
temperature and the velocity of the fluid at the freeze-out surface.

It was mentioned above that the initial geometry of the plasma is
generically anisotropic. It turns out that this initial spatial
anisotropy is translated by the hydrodynamic evolution into anisotropy
in momentum space, specifically in the azimuthal distribution of the
momenta of the final state particles. In particular, one can perform a
Fourier decomposition of the particle distribution @xmath in an event:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are called the anisotropic flow coefficients, and @xmath
are the event plane angles. Averaged over a large number of events, the
flow coefficients show a pronounced dependence on the centrality and
hence on the impact parameter. The reason for this is that the @xmath ,
but also correlations between different @xmath , inherit information
about the initial geometry, and this depends strongly on the impact
parameter. This is however not the complete story. The viscosities tend
to smooth out spatial structure. As such, large values of the
viscosities tend to lower the final anisotropy present, making @xmath a
probe of especially the shear viscosity.

These observables will be discussed in more detail in section 4.3 ,
along with figures of these experimental results compared to theoretical
predictions described in section 4.2 . Next, we will examine a different
corner of the QCD phase diagram, namely neutron stars.

### 1.4 Neutron stars

When a star burns through its supply of hydrogen, it reaches the end of
its life. In a sequence in which it starts burning ever heavier
elements, it eventually sheds its outer layers to leave behind a compact
remnant. The nature of this remnant is determined mainly by the mass of
the progenitor star. For stars like our sun, the remnant will be a
so-called white dwarf: an object with a mass in the order of magnitude
of one solar mass ( @xmath ) and a radius comparable with that of the
earth. Unlike an ordinary main sequence star, a white dwarf is not held
in static equilibrium by thermal pressure of gas resisting gravitational
collapse. Instead, the degeneracy pressure due to the Pauli exclusion
principle of the electrons is what resists further gravitational
collapse. There is however a limit to how much mass such an object can
have before electron degeneracy pressure becomes insufficient to
maintain hydrostatic equilibrium. This is called the Chandrasekhar
limit, and is equal to about @xmath .

Indeed, if the progenitor star is too massive, the resulting compact
remnant is no longer a white dwarf, but a neutron star instead. For
small pressures, neutrons are unstable, as they can undergo beta decay
into a proton, an electron and an anti-electronneutrino. At extreme
densities, however, it is thermodynamically favorable for the protons
and electrons inside ordinary matter to merge and form neutrons and
neutrinos. This explains the name neutron star, as a neutron star is
extremely neutron-rich. Observationally, it is known that the masses of
known neutron stars are typically about @xmath , but with masses of
around @xmath also occuring. The radius depends on the mass, as we see
below, and recent experimental constraints by NICER put the radius of a
typical @xmath neutron star at around @xmath [ 212 ] . Finally, we note
that neutron stars are cold as far as QCD is concerned. This may seem
like an odd statement given the fact that they have temperatures on the
order of @xmath [ 250 ] . ³ ³ 3 Newly formed neutron stars are much
hotter, but this phase does not last very long. However, since neutron
stars consist of densely packed neutron-rich matter, for which the
relevant physics is QCD, one should compare this temperature to the
energy scale of QCD, which is around @xmath . In this unit, we can
safely neglect the effects of temperature on the structure of the
neutron star and assume @xmath . ⁴ ⁴ 4 Note though that for non-QCD
processes, like the emission of thermal energy in the form of light, the
temperature can most definitely not be neglected. Note also that during
a binary neutron star merger event, the temperatures cannot be
neglected. This means that, given their enormous density and cold
temperature, neutron stars occupy the low temperature, large chemical
potential region of the QCD phase diagram.

Let us now show that indeed the mass and radius are related. Assuming a
non-rotating neutron star, one can assume spherical symmetry. This, in
combination with the assumption of hydrostatic equilibrium ( @xmath ),
allows us to write down the Tolman-Oppenheimer-Volkov (TOV) equations:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the radial coordinate, @xmath the gravitational constant
and where the mass @xmath enclosed within radius @xmath satisfies

  -- -------- --
     @xmath   
  -- -------- --

Supplying these two equations with the boundary conditions at the center
of the star at @xmath that @xmath and that the central density is some
specified value @xmath , the differential equations can be integrated to
yield @xmath and @xmath . From the solution, we can then identify the
radius @xmath of the star as the point where @xmath , and subsequently
we can also find the mass @xmath . ⁵ ⁵ 5 Note that there is a subtlety
here, namely that in general relativity one has to define what one means
by radius and mass. We define the radius @xmath to be in Schwarzschild
coordinates, which implies that the area of a star of radius @xmath
equals @xmath . For the mass, we define that the gravitational mass, as
measured by examining the Schwarzschild metric outside the star, is the
same as that of a black hole of mass @xmath . In this way, we obtain
@xmath and @xmath as parametric functions of the central density @xmath
.

Note though that the TOV equations can only be solved given an equation
of state. In [ 26 ] , a large number of equations of state was
generated, which are shown in the left panel of figure 1.7 .

Here only equations of state were used which are causal, i.e. the speed
of sound is less than the speed of light, and which simultaneously
satisfy constraints from nuclear matter models at low densities and from
perturbative QCD at high densities. In the right panel, the resulting
mass to radius relations are shown for the same equations of state. One
can see several important features. First of all, each equation of state
has a maximum allowed mass for neutron stars it supports, in much the
same way as we saw above for white dwarfs. It is observationally not
precisely known what this maximum mass is precisely, but it is known
that a neutron star named J0348+0432 has a precisely measured mass of
@xmath [ 27 ] . ⁶ ⁶ 6 An even more massive star, J0740+6620, was
detected after the publication of [ 26 ] , with a mass of @xmath [ 79 ]
. This means that all the equations of state colored blue in figure 1.7
are excluded by this observation, as these equations of state do not
support a @xmath star. Similarly, the equations of state colored red are
also excluded by observational constraints, this time by the tidal
deformability @xmath of the neutron stars involved in the binary neutron
star merger GW170817 [ 9 ] .

Let us next discuss neutron star mergers. In 2017, the first neutron
star merger, GW170817, was discovered using gravitational waves [ 9 ] ,
and was accompanied by an electromagnetic counterpart [ 114 , 10 , 8 ] .
In the remainder of this section, we will discuss the various stages
involved in such a merger, and how QCD enters the problem. For more
detailed reviews, see [ 33 , 213 ] . In figure 1.8 , a schematic
overview is given of the different stages of a merger event.

The first stage of the merger is by far the longest lasting, as it
covers the inspiral. This inspiral can quite literally take billions of
years, as gravitational wave emission circularizes the orbit and slowly
but surely shrinks the size of the orbit. As the orbits shrink, the
orbital period does too, and the amplitude of the emitted gravitational
waves increases. Only in the last minute or so does this happen to a
large enough extent such that observatories such as LIGO and VIRGO can
detect the gravitational waves emanating from the source. During the
merger, the two stars exert a tidal force on one another, which slightly
deforms the stars. This produces an imprint in the gravitational wave
emission, the size of which depends on the equation of state through the
tidal deformability @xmath [ 220 ] .

When the stars touch, two things can happen. Either the stars are heavy
enough that the densities immediately exceed what the equation of state
can support, and they collapse to a black hole. In this case, very
little material will be ejected, producing only a small electromagnetic
counterpart. Also, gravitational wave emission dies down quickly, as the
resulting black hole will ring down with its characteristic quasinormal
mode frequencies. The other option is that the stars merge to form a
highly deformed object, which loses energy by gravitational wave
emission, and ejects a substantial amount of neutron-rich matter. This
matter, no longer under enormous pressure, decays to form heavy
elements, and emits electromagnetic radiation in the process. The
gravitational waves emitted during this phase are characteristic of the
equation of state.

As the deformed object circularizes over a timescale of around @xmath ,
gravitational wave emission dies down, there is again the possibility of
gravitational collapse to a black hole. If this does not happen, the
merger remnant will slowly lose angular momentum due to various
processes over the course of a few seconds. The angular momentum
effectively contributes partly to the pressure preventing the star from
collapsing, and therefore as the star spins down, there is again the
possibility of collapse to a black hole. If the mass of the merger
remnant is below the maximum allowed mass however, the remnant will be a
heavier neutron star.

To end this section, let us discuss the methods used to theoretically
compute a waveform. Neutron star mergers are described theoretically by
relativistic hydrodynamics coupled to general relativity. In figure 1.9
, one can see the amplitude of gravitational waves emitted as a function
of frequency.

The low frequencies are mostly produced during the inspiral phase, while
the peaks at high frequencies are mostly produced during the post-merger
phase. Also indicated are the methods used, namely analytical methods
for most of the inspiral, and numerical relativity for the merger part,
where there is an overlap interval in which both methods are applicable.
Numerical relativity is immensely computationally expensive, so it would
be impractical to have to compute the inspiral using numerical
relativity. In this way, the two methods neatly complement each other.
Explaining either of these methods in detail is beyond the scope of this
thesis, however good introductions can be found in [ 256 , 45 ] .

### 1.5 Holography

Holography is a duality between two at first sight very different
classes of theories. To illustrate this, let us focus on the first
constructed example, namely that of @xmath super Yang-Mills (SYM) theory
living in four spacetime dimensions. For the purpose of this section,
this can be seen as a highly supersymmetric version of QCD, where we
take the number of colors @xmath to be infinite. In [ 188 ] , a
convincing argument was made that this theory is the same as type-IIB
string theory living in an anti-de Sitter (AdS) background with five
spacetime dimensions. In other words, the string theory lives in one
dimension more than the gauge theory that it is dual to.

Furthermore, what makes this duality particularly interesting, is that
the string theory side of the duality simplifies if in addition to
@xmath we also take the ’t Hooft coupling @xmath to be infinite, where
@xmath is the gauge theory coupling constant. When taking this limit,
known as the ’t Hooft limit, two things happen: The string coupling on
the string theory side of the duality goes to zero, leaving us with a
classical string theory. Additionally, also the string length vanishes,
reducing the classical string theory further to a theory of point-like
particles, which in this example is classical type IIB supergravity.

In this way, we obtain a duality between on one side a strongly coupled
quantum field theory, which we say lives on the boundary, and on the
other side a classical gravitational theory which lives in one dimension
extra, which we say lives in the bulk. This is extremely useful, because
this duality relates something difficult, namely strongly coupled QFT,
to something relatively easy, namely classical general relativity. Note
that in [ 188 ] , the duality was only introduced for @xmath SYM theory
and related theories, and that there is no known general way to obtain a
holographic dual for an arbitrary QFT. It is expected though, both from
the large @xmath expansion in gauge theory [ 3 ] and from black hole
thermodynamics [ 49 , 4 , 241 ] , that the class of theories with
holographic duals is larger. We will touch further upon this problem of
constructing holographic duals in section 1.5.1 . Before doing so
however, let us discuss some more how the duality precisely works.
Indeed, for the two theories on either side of the duality to be equal,
one needs a precise dictionary for how to relate quantities and problems
on one side to the corresponding quantities and problems on the other
side. Such a dictionary has been developed over the years, and in the
following paragraphs we will discuss a selection of this dictionary,
introducing only the quantities that will be used in this thesis. This
discussion will just describe the dictionary without going into the
derivations. An excellent review which goes in more detail can be found
in [ 70 ] .

Let us start the discussion of the dictionary with a few thermodynamical
quantities. The first of these is the free energy. The starting point
for this is the observation that the partition functions of both sides
of the duality are equal [ 121 , 257 , 16 ] . After performing a Wick
rotation, and using the fact that the bulk theory is classical, one
obtains that the free energy of the boundary theory @xmath obeys

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the temperature, and @xmath is the on-shell action of
the bulk theory. Note here that the on-shell bulk action is divergent
towards the AdS boundary. This problem is similar in origin to the UV
divergences originating in QFTs, and the solution is similar, namely
holographic renormalization [ 85 ] . In holographic renormalization, one
regularizes the divergence by introducing a cutoff @xmath in the bulk
spacetime integral for the action. Subsequently, one then compares the
desired action to that of a reference solution, after which one can take
the limit @xmath for the difference of the two regularized actions. In
this way one can compute free energies up to an overall constant, which
is for most purposes enough.

Let us next discuss temperature and entropy. In a bulk geometry with a
horizon, such as one with a planar horizon called a black brane, one can
obtain the temperature as the Hawking temperature of the horizon, which
can be expressed in terms of the local metric at the horizon by
requiring that the Wick rotated geometry has no conical singularity at
the horizon [ 113 ] . The entropy can also be obtained purely from
horizon data, namely by use of the Bekenstein-Hawking formula [ 49 ] :

  -- -------- --
     @xmath   
  -- -------- --

where now @xmath is the entropy, and @xmath is the area of the black
hole. Note that in the case of a black brane solution, the black hole is
infinite in extent, in which case it makes more sense to divide out the
volume on the boundary. Indeed, when one examines the entropy density,
the result is still finite.

The next important element in the holographic dictionary that we will
need is the field-operator correspondence [ 121 , 257 ] . Imagine an
operator @xmath in the boundary theory that we want to compute, and
imagine introducing a source for that operator @xmath . Then the
field-operator correspondence tells us that in the corresponding bulk
theory there is a field @xmath , with @xmath the bulk coordinate, where
@xmath corresponds to the boundary of AdS. This bulk field @xmath then
has the following near-boundary expansion:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the scaling dimension of the operator @xmath . For most
operators the first term will be non-normalizable, and the second will
be normalizable. One can see that in this way, one obtains a way to
evaluate expectation values of operators in the boundary theory by an
equivalent computation in the bulk theory, namely by extracting the
subleading behavior of the corresponding bulk field. This result also
allows for the computation of Green’s functions. For example, by
considering the appropriate space-time dependent metric fluctuation
@xmath as the source for the stress-energy tensor @xmath , one can
obtain the Green’s function for the stress-energy tensor, leading to the
famous result mentioned earlier, namely that the shear viscosity divided
by the entropy density of a holographic fluid is equal to @xmath [ 203 ,
175 , 70 ] .

Let us next move on to two non-local operators, namely the Polyakov loop
correlator and the entanglement entropy. In QCD, the Wilson line
operator

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes path ordering and @xmath denotes a closed path,
contains information on among other things confinement. The reason for
this is that if one takes @xmath to run in the time direction from
@xmath to @xmath , and if one then takes two such loops at a constant
distance @xmath from each other, the expectation value of this Polyakov
loop correlator is equal to the potential energy stored in the gluon
field separating a heavy quark-antiquark pair. The holographic dual of
this operator is the on-shell action of an open string in the bulk
attached to the path @xmath on the boundary [ 187 , 222 ] . As the
action of a string is just the area measured in the string frame metric,
the complicated non-perturbative problem of evaluating the expectation
value of the Polyakov loop correlator itself is therefore replaced in
the holographic dual by the much easier task of finding a minimal
surface.

A computationally related quantity to the Polyakov loop correlator is
the entanglement entropy. In a QFT, if we imagine dividing the spacetime
into a region @xmath and its complement @xmath , we can partition the
Hilbert space as @xmath , and define the reduced density matrix for a
pure state @xmath by @xmath . We can subsequently define the
entanglement entropy as

  -- -------- --
     @xmath   
  -- -------- --

For static spacetimes, [ 228 ] proposed that the holographic dual of
entanglement entropy is, similarly to the Wilson loop, a minimal surface
in the bulk with its ends attached to the boundary of the region @xmath
. Important differences with the Wilson loop are that in the case of
entanglement entropy, the minimal surface is a codimension 2 surface in
the bulk, whereas in the case of the Wilson loop, the minimal surface is
a dimension 2 surface. Also, for the entanglement entropy we use the
Einstein frame metric, whereas for the Wilson loop, one had to use the
string frame metric. The proposition was later generalized to non-static
spacetimes in [ 149 ] , and both propositions were proven in [ 179 ] and
[ 92 ] , respectively.

Lastly, let us briefly discuss baryons, which are important if one aims
for a holographic description of neutron stars, as at least up to some
depth these are composed of mostly baryons. In [ 259 , 118 ] , it was
shown in the @xmath SYM example which was also used above, that baryons
in the boundary theory can be identified with D5-branes wrapping the 5
compact dimensions in the bulk, which we previously neglected. In this
way the baryon appears in the bulk as a small pointlike topological
defect, i.e. a soliton. This analysis was later extended to other
holographic models obtained from string theory, such as the
Witten-Sakai-Sugimoto (WSS) model [ 258 , 229 , 230 ] , with similar
conclusions [ 147 , 142 , 148 , 141 , 170 , 74 , 75 , 60 , 227 , 164 ,
82 , 165 , 210 , 58 , 50 , 226 , 111 , 180 , 102 ] .

#### 1.5.1 Bottom-up holography: IHQCD and V-QCD

One issue that we have so far glossed over is the fact that even though
holography allows for an enormous simplification of certain
computations, the theories discussed so far are not QCD. For example,
even though @xmath SYM theory is in essence ‘just’ QCD with a large
number of colors and a lot of supersymmetry, phenomenologically the two
theories are quite different, most notably in the fact that @xmath SYM
theory is conformal, whereas QCD is not. In the construction of
holographic models to describe QCD, there are two general classes of
models. On the one hand, there are the ‘top-down’ approaches, which
includes @xmath SYM theory, but also the previously mentioned WSS model.
In a top-down approach, one starts from a string theoretical
construction, and in that way arrives at a precise holographic theory.
This has the obvious advantage that in this approach, the holographic
dictionary is precisely known, and the general amount of control over
the computations is larger. The main disadvantage of such theories is
that, like @xmath SYM, the phenomenological resemblance to QCD is not
very good.

An alternative approach is the so-called ‘bottom-up’ approach, where one
tries to construct a holographic model without a derivation from string
theory, where the aim is to make the model as phenomenologically
accurate as possible. Early examples of this approach are the
‘hard-wall’ models [ 105 , 81 ] , which were followed by the ‘soft-wall’
model introduced in [ 166 ] . In this subsection, we will focus on the
IHQCD model, including its extension V-QCD, as this is the model we will
be using in later chapters.

In Improved Holographic QCD (IHQCD), a holographic theory is constructed
for the fields dual to the @xmath and @xmath operators in QCD. These
fields are the dilaton @xmath and the metric @xmath , respectively. Note
though that in this thesis we will write @xmath . The IHQCD action is
the following [ 129 , 128 ] :

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

with @xmath the Ricci scalar, and @xmath a potential function. The
choice of a non-trivial potential @xmath allows for breaking of
conformality in IHQCD. One can see this as follows: The metric which
solves the IHQCD action is, near the AdS boundary, of the form

  -- -------- --
     @xmath   
  -- -------- --

where the scale factor @xmath can be interpreted as the renormalization
scale. On the other hand, @xmath can be interpreted as the QCD coupling
strength. With the appropriate choice for the small @xmath expansion of
@xmath , one can then make sure that @xmath is equal to the QCD @xmath
-function in the UV.

Another demand on the potential fixes the large @xmath behavior of the
potential as well. By requiring that the theory is confining and
simultaneously has a linear glueball spectrum, the large @xmath behavior
of @xmath is restricted to be of the form

  -- -------- --
     @xmath   
  -- -------- --

The intermediate behavior of the potentials can still be freely chosen,
but can in principle be fixed by computing observables also computed on
the lattice. Doing this results in the conclusion that IHQCD can match
very well lattice results for pure Yang-Mills [ 126 , 127 ] .

IHQCD does not contain quarks. For this reason, it has been extended to
include @xmath flavor @xmath and @xmath branes, yielding V-QCD [ 235 ,
56 , 72 , 71 , 160 , 20 ] . The V in the name stands for Veneziano, as
we take @xmath to be large, with @xmath fixed, a limit known as the
Veneziano limit [ 249 ] . We then obtain the following action in
addition to the one for IHQCD ( 1.11 ):

  -- -------- -------- -- --------
     @xmath   @xmath      (1.12)
              @xmath      
  -- -------- -------- -- --------

with

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

and where the covariant derivative for the tachyon @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath and @xmath are gauge fields corresponding to the global
@xmath flavor symmetry, and @xmath and @xmath are the corresponding
field strength tensors. This action contains 3 new phenomenological
potentials: @xmath , @xmath and @xmath , which we will discuss shortly.
While ( 1.12 ) is required in chapter 3 , in chapter 2 we can make the
simplifying assumption that the non-Abelian parts of the gauge fields
are zero, and that @xmath , which simplifies @xmath to the following
expression:

  -- -------- -------- -- --------
     @xmath   @xmath      (1.13)
              @xmath      
  -- -------- -------- -- --------

which we will call the diagonalized action. Here @xmath is the Abelian
component of both the left and right gauge fields, which are also
assumed to be equal.

As was done for IHQCD, the potentials are chosen to satisfy
phenomenological properties of QCD. For the @xmath -potential, the UV
(small @xmath ) behavior is fixed by requiring that the beta function
matches that of QCD for different values of @xmath . The UV behavior of
the @xmath -potential is determined by the RG flow of the quark mass [
160 ] , as well as the behavior at large quark mass [ 161 ] . In the IR,
the potentials are constrained to reproduce phenomenologically
reasonable features in the phase diagram, as well as the properties of
meson spectra [ 29 , 28 , 20 , 19 , 152 , 153 , 21 ] . In [ 162 ] , the
potentials were fitted to lattice data, resulting in a holographic model
of QCD which matches with known phenomenological constraints as much as
possible.

## Chapter 2 (Inverse) Magnetic Catalysis in Holographic QCD

Magnetic fields play an important role in two widely studied QCD
systems, namely heavy ion collisions, and neutron stars. In peripheral
heavy ion collisions, the spectator nucleons, which are charged and are
moving close to the speed of light, induce a magnetic field of @xmath
which, in the appropriate units of the pion mass squared, gives around
@xmath [ 238 , 246 , 251 , 87 , 247 , 191 , 134 ] . In the context of
neutron stars, magnetars exhibit magnetic fields of potentially @xmath [
99 ] , which in units of the pion mass squared is about @xmath . Given
that one of the salient features of QCD at vanishing magnetic field is
its phase structure, it makes sense to study the effect of the magnetic
field on the phase structure. In particular, one can study how the phase
transition temperatures, as well as the associated order parameters,
change as one applies a magnetic field. It was precisely in this context
that a surprising effect was discovered.

As was discussed in section 1.1 , at low temperatures QCD spontaneously
breaks chiral symmetry. At low temperatures, one expects that the order
parameter of this chiral symmetry breaking, the chiral condensate,
increases as one applies a magnetic field [ 193 , 136 , 137 , 138 ] .
This phenomenon is called ‘magnetic catalysis’, and the reason for this
is that Landau quantization leads to an effective reduction from @xmath
to @xmath dimensions. In lower dimensions, the gauge theory IR dynamics
are stronger, leading to a strengthening of the chiral condensate.

However, when lattice studies were done, surprisingly the opposite
effect was seen in around the crossover temperature, and this effect was
named ‘inverse magnetic catalysis’ (IMC) [ 36 , 35 , 37 , 80 ] . In
figure 2.1 , two such lattice results are shown.

In the left panel, one can see the chiral condensate as a function of
@xmath for fixed temperature. One can see that for small temperatures,
one sees magnetic catalysis, whereas for larger temperatures the
condensate instead decreases with @xmath . In the right panel, a related
quantity is shown, namely the cross-over temperature as a function of
@xmath . One can see that the cross-over temperature decreases with
@xmath , signalling inverse magnetic catalysis. Given that IMC seems to
require strong coupling to exhibit itself, it is natural to study this
effect in holography, where we can hope to obtain a qualitative
understanding of the mechanism leading to IMC.

In this chapter, which is based on [ 130 , 132 , 131 ] as well as
upcoming work with the authors of [ 131 ] , we will address these
questions. While the questions asked in each of these papers are
different, the model and the methods used are quite similar. So similar
in fact, that it is possible to write down a ‘master’ model, which
contains each of the models used in the papers that this chapter is
based on by taking appropriate limits. In section 2.1 , we will discuss
this master model, as well as how to obtain useful information from it.
This should allow for a streamlined treatment of computations that would
otherwise have to return in slightly different setups in sections 2.2
through 2.5 . The strategy for solving the model parallels [ 19 ] ,
where of course the discussion is slightly modified because our master
model is more general than the one considered there. Also, in a few
places, it was necessary to make non-trivial adjustments to the
analysis. Wherever this occurs this will be clearly stated.

### 2.1 Analysis of V-QCD model in the presence of a magnetic field and
anisotropy

In this section, we will go through the computations necessary to obtain
the relevant observables for sections 2.2 through 2.5 . This section is
written with the aim of providing the reader with a practical guide as
to how to perform these computations. As such, it necessarily contains a
lot of technical details, which are required for the computations. The
rest of this chapter has been written to only use the results from this
section, and not the computations themselves, so it should be possible
to follow the rest of this chapter without having read this section.

#### 2.1.1 Extending V-QCD to incorporate a magnetic field and
anisotropy

To study magnetic fields in V-QCD, we consider the diagonalized action
1.13 . A magnetic field in the @xmath -direction can then be introduced
by changing the ansatz for the Abelian gauge field to [ 130 , 132 ]

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where we recall that @xmath was dual to the baryon chemical potential.
This ansatz makes one important assumption, namely that all quark
flavors have are identical, and in particular, that they have the same
electric charge. In nature, this is of course not the case, but this
assumption allows us to consider only the Abelian part of the DBI
action, greatly simplifying the analysis.

In addition to a magnetic field, we will also be adding an axion field
@xmath to the action [ 112 , 131 ] , where we will use the following
ansatz:

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

In this way, we can introduce an anisotropy to the system in a way that
is different from a magnetic field. With this ansatz, the axion is dual
to a space-dependent theta term. As the axion will only appear in the
action through a derivative, the presence of the axion does not break
translation symmetry. Instead, it breaks rotational symmetry. To
determine the remaining symmetry left over from rotations, we can
distinguish two cases: one in which the axion is parallel to the
magnetic field ( @xmath , @xmath ) or where there is no magnetic field,
and all other configurations. In the first case, the remaining symmetry
is given by axial symmetry around the @xmath axis, whereas in the latter
case the rotational symmetry is completely broken. As will become clear
below, it turns out that to be able to use a diagonal ansatz for the
metric, we have to choose either @xmath or @xmath if a non-zero magnetic
field is present. Also, for notational convenience, whenever no magnetic
field is present @xmath and @xmath will both be denoted @xmath , since
in this case the orientation of the axion is irrelevant.

With the addition of the magnetic field and the axion, the V-QCD action
becomes

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- -------- -- -------
     @xmath   @xmath      (2.3)
     @xmath   @xmath      (2.4)
              @xmath      
  -- -------- -------- -- -------

where @xmath is the electromagnetic field strength tensor for the gauge
field given by ( 2.1 ), and the potentials @xmath , @xmath , @xmath ,
@xmath and the axion potential @xmath are given in appendix A.1 . We
will keep using these potentials throughout this chapter. In the rest of
this section, it will be explained how this model can be solved to
obtain black hole solutions which are dual to a QGP-like phase. It is
sufficient to focus on solutions containing a black hole, as horizonless
solutions must always be obtained from a black hole solution where a
limit is taken that lets the horizon shrink to zero size. This
requirement ensures that the IR singularity contained in such a
horizonless geometry is of the ‘good’ type, as discussed in more detail
in [ 123 ] .

#### 2.1.2 Equations of motion and boundary conditions

To obtain the equations of motion, we first choose the following ansatz
for the metric: ¹ ¹ 1 Note that we use the Minkowski signature here. In
principle one has to perform a Wick rotation for the thermodynamical
observables, but since we only consider time-independent solutions to
the equations of motion this is trivial.

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

which contains the anisotropy factors @xmath and @xmath . These are
necessary in order for the Einstein equations to be consistent. ² ² 2
Note that if @xmath we have @xmath as well, and if @xmath we have @xmath
. Note that this is also the reason that if a magnetic field is present,
either @xmath or @xmath must vanish, because otherwise one of the
Einstein equations cannot be satisfied. This problem could be remedied
by choosing instead a more general metric ansatz. However this would
greatly complicate the analysis, while the additional physical insight
from allowing for a general angle between @xmath and @xmath would
probably be limited. Note further that the metric contains a blackening
factor @xmath . This allows for the existence of a black hole horizon at
the location where @xmath .

Before stating the Einstein equations and the equations of motion for
the dilaton, tachyon and @xmath field, note that in principle @xmath and
@xmath also have equations of motion, so we are not completely free to
choose any ansatz for them that we want. It is important therefore that
we check that our ansätze ( 2.1 ), ( 2.2 ) are consistent with these
equations of motion, and it turns out that this is indeed the case.
Using the metric ansatz ( 2.5 ) we can write the Einstein equations as
follows:

  -- -------- -------- -- -------
     @xmath   @xmath      (2.6)
              @xmath      
  -- -------- -------- -- -------

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (2.7)
              @xmath      
  -- -------- -------- -- -------

where we use a dot for derivatives with respect to @xmath , a convention
we will keep throughout this chapter. We also define

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an integration constant that arises from integrating the
@xmath equation of motion. Using the above definitions, the @xmath
equation of motion can now be written as what is essentially a simple
integral.

  -- -------- --
     @xmath   
  -- -------- --

Even though @xmath can be integrated out in favor of the integration
constant @xmath , we still need to integrate its equation of motion,
because as we will see below the value of the chemical potential equals
the difference of @xmath evaluated at the boundary and at the horizon,
necessitating that we evaluate this integral. Lastly, to complete the
system, we also have equations of motion for @xmath and @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- -- -------
     @xmath   @xmath      (2.8)
              @xmath      
              @xmath      
              @xmath      
              @xmath      
  -- -------- -------- -- -------

Observe that we have 8 equations of motion for 7 degrees of freedom, so
in principle this system could be overconstrained. One can check however
that ( 2.7 ) is a constraint, by taking the derivative of the right hand
side, and using the other equations of motion to show that the
derivative of ( 2.7 ) is automatically zero. This implies that if ( 2.7
) is satisfied for one particular @xmath , it is satisfied for any
@xmath . Therefore this equation will be trivially solved, provided that
we choose the proper boundary conditions.

Before stating the boundary conditions, it is useful to write the
equations of motion in another form. The reason why this is useful is
that near the boundary, which in @xmath -coondinates is located at
@xmath , @xmath grows like @xmath . Numerically this poses a problem, as
this behavior makes it difficult to satisfy the boundary conditions at
the AdS boundary to a good accuracy, and as we shall see below, the
observables that we are interested in require the boundary conditions to
be precisely met. The solution for this is to use @xmath as the
independent variable instead of @xmath . We can do this as long as
@xmath is a monotonic function of @xmath throughout the bulk.
Interestingly, this is not always the case. For this reason, it is
prudent to use @xmath as the independent variable near the horizon, and
to do a coordinate transformation at some point in the bulk in order to
use @xmath as the independent variable near the boundary.

Since @xmath satisfies a second order differential equation in @xmath
-coordinates, to perform the transformation to @xmath -coordinates one
has to introduce @xmath . Using this definition, one obtains for the
Einstein equations:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath is now given by

  -- -------- --
     @xmath   
  -- -------- --

and where we introduce the notational convention, which will be used for
the rest of this chapter, that a prime denotes a derivative with respect
to @xmath . For the remaining equations of motion, one obtains:

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

  -- -------- -------- -- -------
     @xmath   @xmath      (2.9)
              @xmath      
              @xmath      
              @xmath      
  -- -------- -------- -- -------

In addition to satisfying the equations of motion, solutions must also
obey boundary conditions. We will first discuss the boundary conditions
that need to be imposed at the horizon, before moving on the the
boundary conditions at the boundary. The first of these boundary
conditions is of course that @xmath , where a subscript @xmath will from
now on always denote a quantity evaluated at the horizon. This first
boundary condition simply follows from the definition of a black hole
horizon, as this makes an observer stationary at the horizon move on a
lightlike trajectory. We will also assume @xmath and @xmath . ³ ³ 3
Here, we swapped the usual definition of @xmath by a minus sign so that
@xmath . This means that a few signs are different from other texts, but
this is more convenient when computing the solutions. While it may seem
strange to just assume this, it turns out one can do this without loss
of generality. The reason for this is that the solutions are invariant
under symmetries which can be used to rescale the solutions to satisfy
the boundary conditions at the boundary. For this reason it is
irrelevant which choice we make for these assumptions, as any different
choice will later be absorbed by these symmetries. This will be
discussed in more detail in the next subsection. The last remaining
boundary conditions are consequences of the horizon being just a
coordinate singularity. This can be imposed by requiring that all
variables are smooth at the horizon. Taking equation ( 2.6 ) as an
example, this means that we must require in particular that @xmath is
finite. Given that @xmath by definition, to make sure that @xmath is
finite we must make sure that all terms inversely proportional to @xmath
cancel. This leads to the following condition:

  -- -------- --
     @xmath   
  -- -------- --

Similar arguments for the other equations of motion yield

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
              @xmath      
              @xmath      
     @xmath   @xmath      (2.10)
  -- -------- -------- -- --------

Note here that even though ( 2.7 ) does not contribute a non-trivial
equation of motion in the bulk, it is important to take it into account
in the boundary conditions, so in particular the constraint on @xmath
comes from ( 2.7 ). The last boundary condition at the horizon that is
required, is that @xmath . This is needed because @xmath is a component
of the gauge field, and in the Euclidean geometry the gauge field would
not be continuous unless @xmath [ 91 ] . Applying these boundary
conditions one is left with the freedom to choose @xmath and @xmath .
These, together with @xmath , @xmath , and either @xmath or @xmath ,
determine the entire parameter space of allowed solutions.

For the boundary conditions near the boundary, one needs to consider the
asymptotic behavior of the variables near the boundary. This asymptotic
behavior essentially boils down to that to leading order the geometry is
AdS, and it turns out that one can analytically expand around this
ansatz for small @xmath . For the @xmath , @xmath and @xmath , the
result of this procedure is that these variables approach constant
values. Subleading corrections come in at @xmath , and for all works
described in this thesis approximating them as constants is good enough.
In order to make sure that on the boundary the @xmath , @xmath
coordinates agree with the familiar coordinates for Minkowski space, we
require that

  -- -------- --
     @xmath   
  -- -------- --

where a subscript @xmath will from now on always denote a quantity
evaluated at the boundary.

The near-boundary expansion for @xmath and @xmath are a bit more
complicated, they are given by [ 20 ] :

  -- -------- -------- --
     @xmath   @xmath   
                       
  -- -------- -------- --

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

where @xmath , @xmath and @xmath are determined by the potentials as
discussed in appendix A , and where @xmath is an overall energy scale.
It turns out that all quantities one might want to compute scale with
@xmath to some power, so in practice we just put @xmath and if desired
we can rescale later. For the next subsections, it turns out that it is
convenient to combine both of these equations, to write @xmath as a
function of @xmath . Doing this, one obtains [ 19 ] :

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

where @xmath and @xmath are given by the potentials and can be found in
appendix A . The last near-boundary expansion that we will need is that
of the tachyon [ 20 ] :

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (2.13)
  -- -------- -------- -- --------

where @xmath is the quark mass and @xmath is the chiral condensate.
@xmath is given by the potentials, and can be found in appendix A . In
the following we will consider massless quarks, so we will be imposing
@xmath as the UV boundary condition for the tachyon. How this can be
achieved will be detailed in section 2.1.5 .

With this, we now have a complete list of all the equations of motion,
as well as the boundary conditions that we will need. In the next
section, we will describe a set of symmetries of these equations of
motion that are necessary to compute solutions. After that all the
ingredients are set to describe the algorithm for obtaining the
geometries, and finally the observables that one is after.

#### 2.1.3 Symmetries of the equations of motion

Numerically, one of the simplest and best known methods to solve ODEs
such as the ones describing this model is to initialize a solver for a
specific value of the independent variable (in this case @xmath or
@xmath ), and then integrate the equation from that value to the entire
domain one is interested in. However, we have boundary conditions on
both the horizon and the boundary, and initializing the system of
equations at one of the two locations by no means guarantees that the
boundary conditions at the other location will also be satisfied. While
there are methods available for solving such problems, it turns out we
can use symmetry properties of the equations of motion to mostly
overcome this issue. This will allow us to initialize the system of
equations at the horizon, integrate towards the boundary, and rescale
the solution such that the boundary conditions at the boundary are also
met.

The symmetries of the equations of motion are essentially the
diffeomorphism invariance that is left over after choosing the metric
ansatz ( 2.5 ). It can easily be verified that the following five
transformations leave the equations of motion invariant:

-   Shift of @xmath :

      -- -------- --
         @xmath   
      -- -------- --

-   Shift of @xmath :

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

-   Shift of @xmath :

      -- -------- --
         @xmath   
      -- -------- --

-   Shift of @xmath :

      -- -------- --
         @xmath   
      -- -------- --

-   Scaling of @xmath :

      -- -------- --
         @xmath   
      -- -------- --

Together, @xmath , @xmath , @xmath , @xmath and @xmath will denoted
‘symmetry parameters’ for the remainder of this chapter.

Note first that these symmetries indeed justify our assumptions that
@xmath and @xmath , as these choices can just be absorbed into the
various deltas defined above. Next, observe that after generating a
solution that satisfies the horizon boundary conditions, one can choose
@xmath , @xmath , @xmath and @xmath to ensure that @xmath , @xmath ,
@xmath , and that @xmath . In equation ( 2.12 ), only the left hand side
transforms under these transformations, and it is easy to see that by
using the appropriate @xmath , one can make sure that ( 2.12 ) is
satisfied. Summarizing, we can satisfy all boundary conditions except
that of the tachyon, namely that the quark mass vanishes. This issue
will be addressed in section 2.1.5 . Lastly, note that there is a price
to pay for using these symmetries. Quantities like @xmath , @xmath and
@xmath enter in the transformations. This implies that while we are
guaranteed to get a solution that satisfies the correct boundary
conditions on both sides, we have no direct control over for instance
the value of the magnetic field we want to compute the solution of. This
need not necessarily be a bad thing though, because we are guaranteed
that together with @xmath , all possible values of @xmath , @xmath and
@xmath before any rescaling happens span the space of all possible
solutions. If it is feasible to produce solutions which explore this
entire parameter space, then we will be guaranteed to find all possible
solutions for all possible rescaled values of @xmath , @xmath and @xmath
as well. In some of the setups that will be described below this is
indeed the case, but in other cases it is necessary to fine tune the
unrescaled values to produce the desired rescaled values. The procedure
for doing so will also be described in section 2.1.5 .

#### 2.1.4 Computing observables

Now that the equations of motion, their symmetries, and the boundary
conditions are established, we can describe how to obtain the solutions,
and how to extract useful information from these solutions. As it turns
out, many quantities of interest can be expressed purely in terms of
quantities defined at the horizon, and the symmetry parameters described
in the previous section. The reason for this is that these quantities do
not require the solving of any additional differential equations or
integrals on top of the ones already mentioned in section 2.1.2 . ⁴ ⁴ 4
Note that for example the magnetization does require solving an
integral, but this only has to be done once, so it is done at the same
time as solving the equations of motion for the metric, dilaton and
tachyon. The quantities for which this is the case will from now on be
called ‘background’ observables, and their computation will be discussed
first. There are also observables which do require the solving of
additional equations of motion. In principle, one could follow the same
computation scheme as for the background observables, but as this would
require solving the same background equations of motion multiple times
with the same boundary conditions, it is more efficient to solve the
background once, and then solve the additional equations afterward. The
computations of these non-background observables will be discussed
towards the end of this subsection.

##### Background observables

In this subsection, we will focus on the background observables, where
for convenience we will introduce the notation that quantities with a
tilde denote quantities before the symmetries are used to impose the
boundary conditions at the AdS boundary, and quantities without a tilde
do correspond to the quantities with the proper boundary conditions
imposed. Before moving on to the computation of these obervables,
observe that the property of only needing symmetries and horizon data is
extremely useful. Because the required symmetry transformations only
depend on the non-rescaled solution that one has computed at the
boundary, there is actually no need to retain the information about the
bulk geometry at all, and therefore it can be immediately discarded.
This does away with the need for reading/writing a lot of data to
memory, making the computation faster. Of course, if one is interested
in one of the quantities that do not have this property, this shortcut
cannot be taken, but since the quark-antiquark potential and the
entanglement entropy will only be computed for zero temperature
solutions, it turns out that for a majority of the computations in this
chapter, the shortcut is possible.

From the above discussion, the strategy for computing observables
becomes clear. Choose @xmath , @xmath , @xmath , @xmath and @xmath , and
then initialize according to the horizon boundary conditions described
above. Subsequently integrate the equations of motion, switching from
@xmath - to @xmath -coordinates once close enough to the boundary, and
then integrate further up to some large enough value of @xmath . Then
extract the symmetry parameters @xmath , @xmath , @xmath and @xmath ,
and use them to evaluate the desired observables. ⁵ ⁵ 5 It turns out
that @xmath is not needed for any of the observables that will be listed
below. The next few paragraphs will describe how to compute the
following observables in this way:

-   Temperature @xmath ,

-   Entropy density @xmath ,

-   Baryon chemical potential @xmath ,

-   Magnetic field @xmath ,

-   Anisotropies @xmath and @xmath ,

-   Baryon number density @xmath ,

-   Magnetization @xmath ,

-   ‘Anisotropization’ @xmath . This is the analog of magnetization for
    the anisotropy;

-   Quark mass @xmath ,

-   Chiral condensate @xmath .

The first 5 of these are straightforward, whereas the latter 5 require a
bit more work. We will now go through each of these observables in
order, after which there will be a discussion on how to accurately
determine the required symmetry parameters.

The temperature is given by the Hawking temperature associated to the
horizon. Using the metric ansatz 2.5 , this can be expressed as

  -- -------- --
     @xmath   
  -- -------- --

where the @xmath -dependence enters because of @xmath , as we will see
below the discussion of the observables that we can only extract @xmath
from the model. Moving on to the entropy density, note that the entropy
is given by the area of the black brane. Once again using the metric
ansatz 2.5 and dividing out the overall volume factor, one obtains the
entropy density

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (2.14)
  -- -------- -------- -- --------

where one may note that this result is different from literature by a
factor 4. This amounts to choosing @xmath in the action ( 2.3 , 2.4 ),
and is done for notational convenience. If desired, desired values of
@xmath can be reinstated by multiplying @xmath , @xmath , @xmath and
@xmath by appropriate factors. The chemical potential is given by the
value of @xmath at the boundary. As @xmath can be shifted by a constant
due to gauge symmetry, naively one would say that this is ill-defined.
However, as discussed before in section 2.1.2 , @xmath to ensure
continuity of the gauge field at the horizon. Therefore we obtain:

  -- -------- --
     @xmath   
  -- -------- --

The magnetic field and the anisotropy can be obtained as follows:

  -- -------- --
     @xmath   
  -- -------- --

Next, we move on to compute the number density, magnetization and
anisotropization. These quantities have in common that they are computed
by taking derivatives of the on-shell action. Recall that

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

where @xmath is the grand potential. By definition, the number density
is given by

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

which means that we can express @xmath in terms of the action. To make
this more concrete, consider the variation of the action with respect to
@xmath :

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

where the last equality holds because the action is on-shell, and where
the @xmath factor comes from integration over @xmath and @xmath . ⁶ ⁶ 6
Note that the action only depends on @xmath . This is ultimately the
reason why we could immediately integrate the equation of motion for
@xmath . As it turns out, the integration constant that we defined as
@xmath obeys

  -- -------- --
     @xmath   
  -- -------- --

allowing us to write

  -- -------- --
     @xmath   
  -- -------- --

where we keep @xmath , and recognize @xmath as being an infinitesimal
change in baryon chemical potential. Combining the last equation with (
2.15 ) and ( 2.16 ), one obtains that @xmath . Applying the appropriate
rescalings, one then obtains

  -- -------- --
     @xmath   
  -- -------- --

where in the last step we used ( 2.14 ).

For the magnetization, defined by @xmath , one can perform a similar
computation to obtain the following integral:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

In this case there is no way to analytically evaluate the integral, so
it has to be integrated along with the other equations of motion. Note
however that @xmath factorizes into a factor containing all the
rescalings, and an integral that depends only on unrescaled variables.
This allows us to still perform the integral first, without the need to
retain any intermediate quantities. One further point of interest is
that @xmath is a divergent quantity, as the integrand diverges near the
boundary. This means that in practice we can only compute differences in
@xmath between solutions which have the same @xmath , by cutting off the
integral at some non-zero value of @xmath , and comparing the
differences. ⁷ ⁷ 7 Note here that it is important to cut off the
integral at some prescribed value of @xmath , not @xmath . Also,
defining the anisotropization @xmath , we can obtain in a similar
fashion that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where we note that @xmath in the second case, whereas in the first case
both a non-trivial @xmath and @xmath can occur if both @xmath and @xmath
are non-vanishing.

The last quantities we would like to extract are the quark mass and the
chiral condensate. Both of these can be extracted from ( 2.13 ). Given
that the term containing @xmath becomes dominant near the boundary, it
can be extracted by simply ignoring the term containing @xmath , and
rearranging:

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

The procedure for extracting the chiral condensate is slightly more
involved. The problem is of course that the @xmath term gets smaller
relative to the @xmath term as one gets closer to the boundary. In [ 130
] , we developed a relatively simple way to solve this problem. The
trick is to divide ( 2.13 ) by @xmath , so that the @xmath -term is to
leading order constant. Subsequently taking a derivative on both sides
and rearranging, one obtains the following expression:

  -- -------- -------- -- --------
     @xmath   @xmath      (2.19)
              @xmath      
  -- -------- -------- -- --------

This works well enough to extract the chiral condensate reliably, but
one has to be careful not to do the extraction too close to the
boundary. This is because ( 2.19 ) essentially computes the difference
of two numbers, where that difference tends to zero as one approaches
the boundary. For this reason, one eventually runs into accuracy issues.

To conclude this subsection, we will discuss how to obtain the symmetry
parameters required for the computation of the observables discussed
above. As an example, consider @xmath . The blackening factor @xmath
does not change under any of the symmetry transformations listed in
section 2.1.3 except for the one parameterized by @xmath . This implies
that after having computed an unrescaled solution by shooting from the
horizon, one can extract @xmath solely by using information from the
blackening factor. Since @xmath approaches a constant value with
subleading corrections only entering at @xmath as one approaches the
boundary, one can simply divide the unrescaled @xmath and rescale such
that it becomes zero:

  -- -------- --
     @xmath   
  -- -------- --

As the anisotropy factors @xmath and @xmath approach constants in the
same way @xmath does, @xmath and @xmath can be extracted in an analogous
way by demanding that @xmath and @xmath both vanish to obtain

  -- -------- --
     @xmath   
  -- -------- --

The remaining symmetry parameter that is important for computing
observables, @xmath , is slightly more complicated to obtain. The key is
to use 2.12 , which, by substituting @xmath , can be written in the
following form:

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

Using this equation, we can find @xmath as long as we evaluate the right
hand side close enough to the boundary. Note that this is the reason why
in the observables computed above every power of @xmath came with a
factor of @xmath . We can now either choose to compute observables in
units of @xmath , which is something we will mostly do in this chapter,
or we can try to use a physically reasonable value for @xmath , which is
something we will do in chapter 3 .

We will conclude this section with an improvement to the computation of
@xmath as described above, developed in [ 130 ] . Note that in ( 2.20 )
the subleading corrections go like @xmath . Also recall that @xmath goes
to zero on the boundary by equation ( 2.11 ). Taking these two facts
together, one can see that if we linearly extrapolate @xmath as computed
by ( 2.20 ) to @xmath , then the subleading linear correction should
cancel. We tested that this works in practice, against the code used in
[ 19 ] . We compared specifically that with the extrapolation, where one
extrapolates linearly using @xmath and @xmath to compute two values of
@xmath , one gets a @xmath deviation from a solution computed up to
@xmath without extrapolation. Furthermore, the deviation is an overall
deviation which is always the same regardless of input parameters like
@xmath . This means that such a deviation is acceptable, as it
effectively amounts to a slight redefinition of @xmath . The linear
extrapolation procedure presents an immediate advantage in computation
time because it is computationally a lot cheaper. However, as it turns
out, for ( 2.19 ), the accuracy issues one always eventually runs into
as one gets closer to the boundary imply that for this observable one
has to do the extraction at a value of @xmath for which subleading
corrections are sizable. For this reason, the extrapolation procedure is
also done for ( 2.18 ) and ( 2.19 ), as both of these have subleading
behavior which is linear in @xmath .

##### Non-background observables

We will now continue with what we defined to be ‘non-background’
observables. These observables will all be computed on top of a
background metric, dilaton field and tachyon, where we can assume that
the backgrounds have been properly rescaled using the symmetries, so
that all the boundary conditions are satisfied. We will discuss the
following observables:

-   Helicity 2 glueballs,

-   Quark-antiquark potential,

-   Entanglement entropy.

Let us start by discussing the helicity 2 glueballs. To compute the
spectral density associated to these glueballs, one needs to examine the
behavior of the @xmath metric perturbation:

  -- -------- --
     @xmath   
  -- -------- --

where by an appropriate coordinate transformation we may assume @xmath ,
and where the sum in the plane wave term goes over the time and space
indices. The linearized Einstein’s equations then become

  -- -------- --
     @xmath   
  -- -------- --

These equations can also be put in the Schrödinger form, by defining
@xmath :

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

Here we can easily determine whether the spectrum is discrete by looking
at the asymptotics of @xmath . In the UV, @xmath diverges as @xmath ,
and if in the IR @xmath diverges as well, the spectrum will be discrete,
otherwise it will be continuous.

To extract the spectral density, we recall that it can be obtained from
the correlator of the energy-momentum tensort @xmath , which we can
obtain from @xmath by the following near-boundary expansion:

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath has to satisfy infalling boundary conditions in the IR
@xmath . We then want to extract the imaginary part of @xmath , which is
equal to the spectral density. In practice, numerically, it is easier to
define @xmath , and solve the corresponding equations of motion for
@xmath . This simplifies the IR boundary conditions to @xmath , and more
importantly it removes the oscillatory behavior that @xmath will usually
have. Furthermore, the @xmath terms in the near-boundary expansion drop
out as they are real, and allow one to write:

  -- -------- --
     @xmath   
  -- -------- --

where we note that this expression has the added advantage of being
insensitive to @xmath having the correct normalization to 1 at the
boundary. Note lastly that because the equations of motion for @xmath
are linear, we can easily demand that the constant term in the
near-boundary expansion equals 1.

As mentioned in the introduction, the quark-antiquark potential
indicates whether it is possible to pull a quark-antiquark pair apart.
In holography, this quantity is computed by evaluating the on-shell
Nambu-Goto action of a static string hanging in the bulk from two points
on the boundary [ 34 ] . In principle, this is a divergent quantity.
However, the difference of such a solution with a solution of two
strings extending infinitely deep into the IR with non-holographic
coordinates fixed is finite. By varying the distance between the
endpoints, one can then examine the free energy, and hence the
potential, associated to each quark-antiquark distance. Throughout this
discussion, it is important that we use the string frame metric for the
computation, as this is what the string ‘feels’. This amounts ro
replacing the @xmath metric factor by @xmath .

As it turns out, it is not necessary to solve equations of motion for
the Nambu-Goto action, as it has been worked out that the on-shell
action satisfies [ 128 , 171 ] :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath is the string tension, and @xmath is the turning point of
the string in the bulk. This allows us to compute @xmath as a parametric
function by choosing a value for @xmath and integrating. Also note that
while the integrals above are given for @xmath , one can obtain the
integral for @xmath by setting @xmath .

The last observable we will be examining is the entanglement entropy of
the following two regions:

-   A region, @xmath , defined by @xmath , where we note that @xmath is
    in the parallel to both @xmath and @xmath . We denote the
    entanglement entropy of this region by @xmath .

-   A region, @xmath , defined by @xmath , where we note that @xmath is
    perpendicular to any source of anisotropy, be it @xmath or @xmath .
    We denote the entanglement entropy of this region by @xmath .

The entanglement entropy can be computed in holography by finding a
minimal surface with its endpoints fixed to the boundary of region
@xmath or @xmath , respectively. Such a surface is called a
Ryu-Takayanagi (RT) surface [ 228 ] . Given the symmetries of both
regions considered, this results in a similar computation to that for
the quark-antiquark potential, with the difference that for the
entanglement entropy we need to minimize the surface in the Einstein
frame instead of the string frame. Using the same techniques as for the
quark-antiquark potential, one can find both @xmath and @xmath as
functions of the turning point in the bulk @xmath : ⁸ ⁸ 8 This
regularization defines the entanglement entropy of the entire boundary
as 0.

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
  -- -------- -------- --

with @xmath an infinite factor arising becaus the region is spatially
infinite in two dimension. Analogously, one obtains for @xmath and
@xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
     @xmath   @xmath   
  -- -------- -------- --

#### 2.1.5 Satisfying constraints

With the above discussion, it is now possible to obtain a solution and
extract observables given the inputs @xmath , @xmath , @xmath , @xmath
and either @xmath or @xmath , which together parameterize the available
space of solutions. We will now move up a level of abstraction, treating
the entire discussion above as a function which takes in these inputs
and outputs the observables listed in section 2.1.4 . Here we must also
emphasize that for some of these inputs this function will fail to
return an answer, because it is not guaranteed that every set of inputs
correspond to a valid solution. All of these inputs are given at the
horizon, and there is no guarantee that the geometry near the horizon
smoothly connects to a near-boundary geometry. For example, for some of
these solutions @xmath might grow to negative infinity instead of
positive infinity, or some of the other variables might hit poles at
some point in the bulk.

One issue that arises now is that while we have an efficient way of
evaluating this function, we would rather have control over some of the
outputs. In particular, even one of the boundary conditions, namely
@xmath , is not satisfied automatically. Also, it is sometimes needed to
for example look at solutions at fixed @xmath or @xmath , which requires
to fine-tune the inputs to reproduce the desired outputs. In this
subsection, we will explain the solutions to both of these problems,
starting with fixing @xmath .

Requiring that @xmath can be done in two ways, namely setting @xmath ,
and finding a non-zero @xmath for which @xmath . While this seems like a
trivial distinction, making this distinction immediately leads to
finding out whether the chiral condensate is zero or not, which is one
of the order parameters we’re interested in. In the case where the
chiral condensate is non-zero, it can immediately be concluded that such
a solution spontaneously breaks chiral symmetry since @xmath , which is
one of the main features of V-QCD. First, note that setting @xmath
immediately implies that @xmath by ( 2.10 ), which by the equation of
motion for @xmath , ( 2.9 ), implies that @xmath everywhere. Then from
the near-boundary expansion ( 2.13 ), it immediately follows that @xmath
and @xmath both vanish.

Finding a non-zero @xmath for which @xmath , keeping the other inputs
fixed, is a more complicated procedure. The algorithm for doing so must
determine where a solution with @xmath exists at all. If it does, it
must choose the largest such value of @xmath , and then accurately
determine the outputs for that value of @xmath . The reason for choosing
the largest such value is that one needs to find, given @xmath , @xmath
, @xmath and @xmath , the value with the smallest grand potential. It
turns out that the value for @xmath which corresponds to this most
stable solution is the one with the largest @xmath [ 160 , 20 ] . The
procedure to find this value is done using the steps described below,
where any failure in any of the steps will lead to the conclusion that
no solution with @xmath exists for a non-zero @xmath . ⁹ ⁹ 9 Note that
this algorithm, and also the algorithm for constraining other output
values like @xmath and @xmath to be described later, are obtained
empirically. There are cases in which it fails to find legitimate
solutions or when the solution it finds does not have the largest @xmath
possible, but occurances of this are rare, and when they do occur the
result stands out as being wrong. Therefore the algorithm can safely be
used. This algorithm is mostly the same as in [ 19 ] , except for the
last step, which is modified in a non-trivial way. Also, several minor
things like the amount of iterations before an algorithm terminates have
been changed. These changes turn out to have little effect on the
accuracy of the algorithm, but have a large effect on execution time, as
every time we generate a bulk geometry and extract the observables takes
a few milliseconds. For this reason iterating over this process is very
computationally expensive, and lowering the amount of iterations saves a
lot of computation time.

1.  The first step involves finding any @xmath for which a bulk solution
    exists, without any requirements on @xmath . This is done by
    starting with @xmath , and doubling @xmath until a solution is
    found, which we call @xmath . If no solution is found after 30
    iterations, and the procedure terminates.

2.  We next need to find a solution @xmath for which @xmath . Having
    found at least one solution @xmath , we check the sign of @xmath .
    If it is negative, this step is complete. If it is positive, we
    bisect the interval @xmath . If @xmath for this solution, we found
    @xmath and continue to the next step. If @xmath , we continue
    searching in the interval @xmath . If for this value of @xmath there
    exists no solution, we continue searching in the interval @xmath .
    We keep bisecting in this way until we find @xmath , or, if we
    haven’t found @xmath after 30 iterations, we terminate the
    procedure, and conclude that no solution with @xmath exists.

3.  After finding a value of @xmath for which @xmath , we need to find a
    value @xmath for which @xmath . Doing so guarantees, by continuity,
    that we will at least find one solution with @xmath , so after this
    step, the algorithm can no longer terminate with a failure to find a
    solution. If @xmath , this step is trivially completed, and
    otherwise we keep doubling @xmath until a solution with positive
    @xmath is found. As in the previous steps, if after 30 iterations no
    acceptable solution is found, the algorithm terminates with a
    failure.

4.  The next step is meant to find values of @xmath bracketing the
    largest value of @xmath for which @xmath . This means that we have
    to search for zeroes between the zero that we already found and some
    large value of @xmath . It is known that for large values of @xmath
    the quark mass increases asymptotically [ 20 ] , so what we do is to
    increase @xmath stepwise until we see this asymptotic behavior.
    These steps need to be small enough so as to not miss zeroes, but
    must also not be too small, as this would slow down the algorithm
    considerably. A good compromise is to take the current highest
    @xmath value, named @xmath , and compute @xmath at @xmath , @xmath
    and @xmath , for an appropriate @xmath . If @xmath changes sign
    between any of these three values, we found a zero, and the @xmath
    -value larger than where the zero is located becomes the new @xmath
    . If @xmath does not change sign, we take @xmath to become the new
    @xmath .

    To completely describe this step, we need two more things, namely
    what to choose for @xmath , and when to terminate the search. At the
    start of this step, @xmath is initialized as

      -- -------- --
         @xmath   
      -- -------- --

    Also, @xmath is updated every time we find a new @xmath . If we
    found a new @xmath because we found a new zero, then we set @xmath
    to the difference between the last found zero and @xmath , where we
    divide by 5 so as not to miss any zeroes. If we found a new @xmath
    without a new zero, i.e. because @xmath has the same sign for @xmath
    , then we construct a parabola through these three points, and look
    at its zeroes. If it has zeroes, @xmath is set to be the difference
    between the two zeroes, if there are no zeroes @xmath is doubled
    from its last value.

    Lastly, the search is terminated if the following three requirements
    are met at the same time:

    -   @xmath has not decreased in the last iteration.

    -   @xmath .

    -   @xmath is more than 100 times larger than the largest @xmath
        found in all previous iterations.

    These three conditions correspond to the ones described in [ 19 ] .
    Sometimes, however, this never terminates, so for these cases I have
    added the condition that the search is also terminated if @xmath ,
    which is large enough that the search can be safely terminated.

5.  Now that we have found values of @xmath which bracket the largest
    zero of @xmath , it is possible to iteratively find the zero. For
    this, [ 19 ] uses Brent’s method, which combines the best properties
    of Newton’s method, which doesn’t always converge, but converges
    fast if it does, and the bisection method, which is guaranteed to
    find a zero, but does so more slowly. In [ 132 ] , we improved this
    algorithm slightly. Instead of using Brent’s method to reach some
    small enough value of @xmath , we use Brent’s method to reach a much
    larger interval. We then compute at 10 intermediate values within
    this interval, and perform a least square fit to a linear function,
    of which we can then find the zero analytically. This enables us to
    not only obtain the desired zero of @xmath , but also obtain an
    error estimate for quantities like @xmath and @xmath . We shall see
    in the rest of this section that this is crucial to obtain
    quantities like the speed of sound numerically.

With the above discussion, one can obtain a solution satisfying the
boundary condition @xmath , either by setting @xmath to find a chirally
symmetric solution, or by following the algorithm described above to
obtain a chirally broken solution. To conclude this section, let us go
yet one level of abstraction higher, and view the result of the
discussion above as two functions (one for chirally symmetric and
another for chirally broken solutions) which take in @xmath , @xmath ,
@xmath and either @xmath or @xmath , and output the desired observables
for a solution which satisfies @xmath . The discussion below will
explain how we can iteratively call these functions to fix @xmath or
@xmath to some specified value by fine-tuning @xmath and @xmath ,
respectively. As the algorithm works the same for both chirally
symmetric and chirally broken solutions, I will not distinguish between
the two.

The algorithm is similar in setup, albeit simpler, than the one
described above. One starts by finding two values of the input
parameters which bound the desired solution. This is simpler than the
procedure for finding @xmath such that @xmath , as generically @xmath
and @xmath are single-valued functions. For @xmath , this is done by
starting from @xmath , then @xmath , and then doubling until two values
bracketing the desired solution are found. For @xmath , one starts from
@xmath , and increments @xmath by 0.1 until either one finds values
bracketing the solution. For both these cases, a @xmath or @xmath for
which no solution exists will be interpreted as potentially bracketing
the true solution if its ‘neighbor’ in the algorithm does exist.
Empirically, it turns out that this scheme usually is able to find
values bracketing the true solution.

Once two values which potentially bracket the true solution are found,
one once again uses Brent’s method to shrink the size of these brackets.
¹⁰ ¹⁰ 10 Note that due to missing values being interpreted as
potentially bracketing the true solution, there may be multiple such
brackets per requested solution. As soon as Brent’s method has shrunk
the brackets to a small enough size, we once again perform a fit over
intermediate values in this interval, and this is where the value of
being able to compute an error bar on observables in determining @xmath
shows its value. As it turns out, the accuracy of observables varies by
as much as an order of magnitude for different values of @xmath and
@xmath or @xmath . This also means that the accuracy of observables
obtained from the fit to @xmath can vary by an order of magnitude. Now,
having error bars, one can perform a weighted fit, in which the ‘bad’
points will receive a lower weight, enabling us to obtain a more
accurate result. This turns out to be crucial to determine quantities
like the speed of sound, which ultimately depend on quantities like
@xmath . For such an observable to not be completely dominated by
numerical noise, one needs to be able to determine @xmath and other such
observables to as high an accuracy as possible.

#### 2.1.6 Obtaining a phase diagram

The above discussion enables us to construct both chirally symmetric
solutions and chirally broken solutions, both satisfying all the
required boundary conditions. We are also able to constrain either
@xmath or @xmath to have a specified value, and we can extract all the
required observables from the solutions. Only one thing remains now in
order for us to determine what the observables are as functions of
@xmath , @xmath , @xmath and @xmath , which together parameterize the
phase diagram of the theory. In principle, this is an easy task; one
just has to evaluate the grand potential of every solution, and if there
are multiple solutions with the same @xmath , @xmath , @xmath and @xmath
, choose the one with the smallest grand potential.

In practice, however, this is more complicated. The grand potential
diverges like @xmath near the boundary. In principle one could try to
perform holographic renormalization like one does for the magnetic
field, but this turns out to be very hard to do numerically. What works
better numerically is to use the first law of thermodynamics

  -- -------- --
     @xmath   
  -- -------- --

and integrate along a family of solutions where one is able to
continuously vary the input parameters. Of course, this brings with it
an integration constant, which we choose such that the thermal gas
geometry has grand potential equal to zero. This thermal gas geometry is
obtained by taking @xmath , which makes the horizon shrink to zero size.
¹¹ ¹¹ 11 This limit of taking @xmath is well-defined because for any
@xmath this corresponds to the same solution. For different @xmath and
@xmath , the solution is not the same, but in those cases the
holographic renormalization of @xmath and @xmath , respectively, are
defined with respect to these different horizonless solutions, which
hence defines the grand potentials of these solutions to be the same.
This corresponds to a horizonless geometry with a ‘good singularity’, as
discussed in [ 123 ] .

By integrating the first law in this way, one can obtain the grand
potential for every solution. Note that this is a non-trivial statement,
as it requires the whole parameter space to be connected, and in
particular it requires that the chirally broken solutions have a limit
in which they approach a corresponding chirally symmetric solution. Both
of these statements turn out to be correct [ 20 ] .

After one has computed the grand potential throughout the parameter
space in this way, one knows which geometry is the dominant one for
every @xmath , @xmath , @xmath and @xmath . To then label the resulting
phase diagram appropriately, in this chapter we will use the following
order parameters:

-   Chiral condensate @xmath : this distinguishes chirally symmetric
    from chirally broken solutions.

-   Confinement: this is defined in this chapter as the quark-antiquark
    potential having a linear branch. Usually this is equivalent with
    the geometry being horizonless. In section 2.4 , we will find that
    in the presence of anisotropy this is no longer always true. This
    has some interesting consequences, which will be explored there.

This concludes the introduction into the computations needed throughout
the rest of this chapter. In the next sections, we will explore various
limits of the general model described so far, starting with one where we
have only a magnetic field, and hence set @xmath and @xmath .

### 2.2 Inverse magnetic catalysis due to a magnetic field

In the beginning of this chapter, the puzzle of inverse magnetic
catalysis (IMC) was introduced. An interesting possible explanation was
put forward in [ 67 , 68 ] , namely that there are two competing effects
at work, called ‘valence’ and ‘sea’ quark contributions. The valence
quark contribution corresponds to the @xmath operators appearing in the
path integral. This effect is found to increase the condensate as @xmath
increases. The sea quark contribution, instead, arises from the quark
determinant. This contribution tends to decrease the condensate as
@xmath increases. The appearance of magnetic catalysis or its opposite
are then explained as follows: in regions of the phase diagram where
valence quark effects are dominant, one finds magnetic catalysis,
whereas in regions where the sea quark effects dominate, one finds
inverse magnetic catalysis. Note that the sea quark contribution is a
backreaction effect. To see that this is true, consider the quenched
approximation, or the approximation of infinitely massive quarks. In
this approximation, the quark determinant becomes a constant, and hence
the sea quark contribution vanishes. In other words, when one takes the
quarks as non-dynamical probes, there is no sea quark contribution.

In this section, which is based on [ 130 ] , we study this problem in
the holographic model introduced in section 2.1 . The aim of this study
is twofold: to reproduce IMC in holography, and to investigate whether
in holography one can similarly isolate two competing effects in analogy
to the findings in [ 67 , 68 ] . In earlier studies, holographic gauge
theories in the presence of a magnetic field have been investigated
either in the absence of flavors, or with @xmath [ 260 , 108 , 104 , 209
, 189 , 96 , 225 , 107 ] , or with smeared backreacted flavor branes in
the Veneziano limit, which leads to a different flavor global symmetry
group [ 163 ] . In our model, we have the correct flavor symmetry group,
as well as a fully backreacted flavor sector in the Veneziano limit. The
model can be obtained from the ‘master’ model introduced in section 2.1
by setting @xmath . The baryon chemical potential can be set to zero by
choosing @xmath .

#### 2.2.1 Varying the @xmath potential

An important ingredient to reproduce IMC is the choice of potentials. As
briefly mentioned in section 2.1 , the potentials used in this chapter
can be found in appendix A.1 . These potentials are to a large extent
the same as the ones used in [ 19 ] , with one important difference. The
coupling of the magnetic field to the flavor sector depends on the
@xmath -potential. In [ 19 ] , the choice is made that @xmath . This is
a natural choice, as it is expected that @xmath and @xmath have similar
asymptotics in both the UV and the IR. Indeed, this assumption is
consistent with the flavor vector current two point function and the
asymptotics of the meson spectra [ 153 , 28 ] . Also, QGP conductivity
and its diffusion constant [ 155 ] , as well as thermal photon emission
during the QGP phase of heavy ion collisions [ 154 ] , are well
described by assuming this assumption. A simple modification to @xmath
is to insert a multiplicative constant @xmath such that @xmath . Looking
at the appearance of @xmath in the action ( 2.4 ) however, such a
modification would just lead to a trivial redefinition of @xmath .
Another simple modification which keeps the asymptotics of @xmath and
@xmath the same is the one we will use, namely

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a constant.

A first interesting question is then how various observables depend on
@xmath . In figure 2.2 , the magnetic field dependence of both the
deconfinement transition temperature and the chiral transition
temperature is shown for different choices of @xmath .

Here we have kept the number of flavors constant by setting @xmath . An
interesting observation here is that both phase transition temperatures
decrease with @xmath for smaller values of @xmath , whereas for @xmath
the transition temperatures generally grow with @xmath . Given that the
chiral transition is second order in this model, this means that for
smaller values of @xmath and temperatures slightly below the chiral
transition, the chiral condensate must continuously decrease to zero,
signaling inverse magnetic catalysis. ¹² ¹² 12 We assume massless
quarks, which implies that the condensate must vanish at the chiral
transition. An interesting sidenote is that larger values of @xmath ,
which correspond to smaller values of @xmath in our model, also match
better the electric conductivity of the QGP in the absence of a magnetic
field [ 154 ] .

The appearance of inverse magnetic catalysis can be seen more explicitly
in figure 2.3 .

Here @xmath is shown as a function of @xmath and @xmath for @xmath and
@xmath . ¹³ ¹³ 13 Note that @xmath is labeled @xmath in the figure.
Between the two phase transitions for small enough values of the
magnetic field, it can indeed be seen that the chiral condensate
decreases with increasing values of the magnetic field. In the low
temperature thermal gas phase however, the condensate increases with the
magnetic field. These two observations show good agreement with the
discussion at the beginning of this chapter. In the left panel of figure
2.4 , the same chiral condensate is shown in a different way, namely by
computing the renormalization group invariant

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

and subsequently looking at the difference

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

By looking specifically at this quantity, it is possible to compare to
lattice results, and indeed we find qualitative agreement [ 37 ] . At
small temperatures, the condensate increases monotonically as a function
of @xmath , while at temperatures around the phase transitions the
condensate first increases, then jumps, and then decreases. For even
larger temperatures, the condensate decreases monotonically. This is in
qualitative agreement with [ 37 ] , with the notable exception that real
QCD has no first order deconfinement transition, whereas the holographic
model does. ¹⁴ ¹⁴ 14 This artefact is due to the fact that in the
holographic model we take the large @xmath limit, which leads to a first
order phase transition. In the right panel of figure 2.4 , we show
@xmath at vanishing temperature for different choices of @xmath . It can
be seen that the condensate behaves like

  -- -------- --
     @xmath   
  -- -------- --

where @xmath depends on @xmath . It is clear that @xmath decreases as
@xmath increases.

One final quantity we examine is the magnetic susceptibility at @xmath
as a function of @xmath for different values of @xmath , which is shown
in figure 2.5 .

This is a useful quantity, as it can be used to determine the behavior
of the deconfinement transition around @xmath . This can be seen as
follows: Using the first law of thermodynamics, and using that the
thermal gas has @xmath and @xmath , one can derive that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are now taken to be observables in the
deconfined phase. Together with the observation that

  -- -------- --
     @xmath   
  -- -------- --

this leads to

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

Knowing that the @xmath -potential does not influence the entropy
density for vanishing @xmath , we can determine the dependence on @xmath
of the behavior of the phase transition as a function of @xmath purely
from the dependence of the magnetic susceptibility on @xmath . In this
way, we can conclude that the deconfinement transition will decrease
more sharply with @xmath for small values of @xmath .

#### 2.2.2 Varying the number of flavors

Now that we have established that it is possible to obtain IMC in V-QCD
by setting @xmath , we can further investigate the mechanism behind its
appearance. To do this, we vary the number of flavors by tuning @xmath .
This has the effect of varying the amount of backreaction that the quark
sector has on the gluon sector. Indeed, examining ( 2.4 ), one can see
that @xmath multiplies the entire quark sector of the action, so that
tuning @xmath turns the quark sector into a probe, whereas @xmath allows
for significant backreaction. One of the first things one can
investigate is how the phase structure changes for different values of
@xmath . In figure 2.6 , this phase structure is shown for @xmath ,
where we also go to larger values of @xmath as compared to figure 2.3 .

The phase diagram in figure 2.6 contains the following four phases:

-   A quark-gluon plasma phase at large temperatures. This phase
    exhibits chiral symmetry and is not confining.

-   An intermediate temperature phase, exhibiting chiral symmetry
    breaking, but, like the QGP-like phase, not confining. In real QCD,
    where the phase transition is a crossover, both chiral symmetry
    breaking and confinement set in in a smooth way. In our holographic
    model, since the chiral transition and the deconfinement transition
    are second ¹⁵ ¹⁵ 15 Note that the chiral transition is first order
    whenever it concides with the deconfinement transition. It is only
    second order when it is a distinct phase transition. and first
    order, respectively, these transitions can occur at distinct
    temperatures depending on the choice of potentials.

-   A low temperature thermal gas phase, exhibiting confinement and
    chiral symmetry breaking.

-   At @xmath , another deconfined chirally symmetric phase exists at
    intermediate temperatures, separated from the one mentioned above by
    a first order phase transition. This is the same phase that was
    previously found at @xmath in [ 20 ] .

In addition to the phase structure, it can be seen that around @xmath ,
for all choices of @xmath we see inverse magnetic catalysis,
chararcterized by a decrease in the chiral transition temperature. Also
for all considered values of @xmath , we see that for still larger
values of @xmath , the chiral transition temperature increases,
signaling magnetic catalysis. For small values of @xmath , the behavior
of the chiral transition depends on @xmath , where we see that for
@xmath there is inverse magnetic catalysis, whereas for @xmath there is
only slight inverse magnetic catalysis, and for smaller values of @xmath
the dip in transition temperature decreases to a point that it is no
longer detectable. ¹⁶ ¹⁶ 16 The dip can never really go away, as @xmath
for all deconfined solutions, which by ( 2.24 ) implies @xmath . Since
for @xmath the chiral transition coincides with the deconfinement
transition, this implies that there sould always be slight inverse
magnetic catalysis. Another interesting feature is the reappearance of
the chirally broken deconfined plasma phase at large @xmath , which
seems to appear for all considered @xmath , but for @xmath this could
not be shown conclusively due to numerical inaccuracies.

In figure 2.7 , the magnetic susceptibility for @xmath for the same
values of @xmath considered in figure 2.6 is shown.

Because in this case the entropy density at the deconfinement transition
is not the same for all @xmath , as opposed to the situation for figure
2.5 , we can not conclude anything about the behavior of the
deconfinement transition from the magnetic susceptibility. Nevertheless,
interesting features can be discerned. Firstly, the susceptibility
becomes larger as @xmath is increased. This reflects the observation
that the coupling between the magnetic field and the gluon sector
becomes stronger as @xmath is increased. Also, as one decreases @xmath ,
an inflection point can be seen to appear, which eventually forms a
first order phase transition somewhere between @xmath and @xmath .

The last observable we will discuss is the chiral condensate. It turns
out that by examining the @xmath -dependence of the chiral condensate,
we can isolate two competing effects in analogy to [ 67 , 68 ] . The
‘valence’ quark effect will be identified with the direct coupling of
the magnetic field to the tachyon field, which is dual to the chiral
condensate. The ‘sea’ quark effect, in contrast, is identified with the
indirect coupling of the magnetic field to the tachyon field through the
metric. To investigate what effect these two contributions have on the
chiral condensate, we need to find a way to change their relative
contributions. Looking at the tachyon equation of motion ( 2.8 ), one
can see that the magnetic field only enters through @xmath , which, for
large @xmath , behaves as @xmath . One can then check that the explicit
dependence of ( 2.8 ) on @xmath vanishes for large @xmath . In other
words, the ‘valence’ quark effect becomes constant for large @xmath . On
the other hand, we can tune the magnitude of the ‘sea’ quark effect by
changing the amount of backreaction of the flavor sector onto the gluon
sector. This can easily be achieved by changing @xmath . With this in
mind, in the left panel of figure 2.8 , we examine @xmath as defined in
( 2.23 ) as a function of @xmath , for zero temperature, @xmath and
different values of @xmath .

Interestingly, for large @xmath , we can see that even though the
condensate is larger than for @xmath , the difference @xmath is smaller
for larger @xmath than for smaller @xmath . This can be seen more
clearly in the right panel of figure 2.8 , where @xmath is shown for
different @xmath , @xmath , @xmath , with @xmath . Since at large @xmath
the ‘valence’ quark contribution is constant, we find that indeed the
‘sea’ quark effect, which we control through @xmath , tends to lower the
condensate. This corroborates the findings of [ 67 , 68 ] .

To conclude this section, we find that we can indeed reproduce inverse
magnetic catalysis in a holographic model, provided that we take
backreaction of the flavor sector onto the gluon sector into account.
Furthermore, we find, similarly to the lattice QCD studies [ 67 , 68 ] ,
that there are two competing effects that influence the chiral
condensate. Of these, the backreaction effect associated with ‘sea’
quarks, tends to decrease the condensate, whereas the direct ‘valence’
quark, increases it. In the next section, we will discuss what happens
to IMC in the presence of a finite baryon chemical potential, which, due
to the sign problem, is a hard problem to address with lattice QCD.

### 2.3 Inverse magnetic catalysis in the presence of a nonzero chemical
potential

In this section, which is based on [ 132 ] , we extend the analysis of
the previous section to also include a finite baryon chemical potential.
There are several reasons why such an extension is interesting. Of
these, the most important one is that this region of the phase diagram
is explored by the two systems mentioned at the beginning of this
chapter. Indeed, low-energy heavy ion collisions such as those performed
at RHIC occur in a region of both non-negligible baryon chemical
potential [ 156 ] and magnetic field [ 134 ] , whereas neutron stars
occupy the low temperature, high baryon density region of the phase
diagram, and in particular magnetars have substantial magnetic fields.
¹⁷ ¹⁷ 17 Even for magnetars the magnetic field is still small in
comparison to the relevant energy scales of QCD, but nevertheless
observables can perhaps be defined which are sensitive to such effects.
Additionally, it is of theoretical interest what effect the chemical
potential can have on inverse magnetic catalysis [ 24 ] . The latter is
a question that cannot be addressed using lattice QCD, due to the sign
problem [ 7 ] . Because of this, attempts to explore this question have
been made both with effective models [ 193 ] and using holography [ 188
, 39 , 160 , 94 , 163 , 96 , 189 , 107 ] .

Both the results of the previous section, as well as lattice studies [
67 , 68 ] , show that the effects of backreaction are important to
capture the physics behind inverse magnetic catalysis. Therefore, we
choose to study this problem in the same setup as in the previous
section, with the addition of the baryon chemical potential. In terms of
the ‘master’ model introduced in section 2.1 , this amounts to setting
@xmath . As in the rest of this chapter, we will use the potentials from
appendix A.1 . Throughout this section, we will additionally fix @xmath
, and we keep the number of flavors fixed to @xmath .

#### 2.3.1 Phase diagram and thermodynamics

As before, we start the discussion of the results by examining the phase
diagram, which is shown in figure 2.9 .

The phases featured in the phase diagram are the same as in section 2.2
, with the exception that the extra chirally symmetric phase that
appears for @xmath is not present, as we fix @xmath in this section. The
phase structure shows an interesting dependence on the magnetic field.
Firstly, the deconfined, chirally symmetric phase can be seen to move
down for small chemical potential values, whereas it increases for
larger @xmath . The behavior of the chiral transition will be examined
in more detail in section 2.3.2 . In contrast to the chiral transition,
the deconfinement transition does not exhibit a large dependence on the
magnetic field, with one notable exception. From section 2.2 , we
already know that in the absence of chemical potential around @xmath ,
the two phase transitions join. As the deconfined, chirally symmetric
phase continues to exist for larger values of @xmath , there is a triple
point. Interestingly, as this triple point forms around @xmath , the
second order transition between both deconfined phases turns first
order. After this, as can be seen in the inset in figure 2.9 , another
triple point forms, after which the first order transition becomes a
transition between two deconfined, chirally broken phases, before ending
in a critical point.

An interesting observable which encodes much of the thermodynamical
information is the speed of sound. In figure 2.10 , we show the speed of
sound in the direction of the magnetic field. ¹⁸ ¹⁸ 18 Due to the
anisotropy induced by the magnetic field the speed of sound can take a
different value perpendicular to @xmath .

The speed of sound @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

Note that since @xmath depends on derivatives of thermodynamic
variables, it is crucial to obtain accurate estimates for these
quantities, as any numerical noise will cause the derivative to be
unusable. For this reason, the fitting procedure described at the end of
section 2.1.5 is essential to obtain the speed of sound, although even
with the improved accuracy obtained from this method the speed of sound
still has some numerical noise, which was removed artificially from the
curves in figure 2.10 . Rather surprisingly, the speed of sound squared
is, for certain values of the chemical potential and magnetic field,
larger than the conformal value of @xmath , which is surprising given [
146 , 73 ] , though it does not contradict their findings. Finally, note
that at large @xmath , outside the range of figure 2.10 , the speed of
sound approaches the conformal value from below, consistent with [ 146 ,
73 ] .

#### 2.3.2 Chiral condensate and inverse magnetic catalysis

As the chiral transition is second order in a large part of the phase
diagram, we can use the behavior of the chiral transition temperature as
a function of chemical potential and magnetic field to study inverse
magnetic catalysis. In the left panel of figure 2.11 , the chiral
transition temperature is shown as a function of @xmath for different
values of @xmath .

For small values of the chemical potential, the chiral transition
temperature decreases as a function of @xmath for the values of @xmath
considered in the left panel of figure 2.11 . This signals inverse
magnetic catalysis, and is in line with expectation from section 2.2 .
Interestingly, for larger values of the chemical potential, the exact
opposite behavior is seen, signaling magnetic catalysis instead.

Looking explicitly at the change in the condensate around @xmath , we
can examine in more detail where we have (inverse) magnetic catalysis.
We do this by looking at the sign of

  -- -------- --
     @xmath   
  -- -------- --

where a positive sign signals magnetic catalysis, a negative sign
signals inverse magnetic catalysis, and zero signals no change. ¹⁹ ¹⁹ 19
The latter mostly happens in the chirally symmetric phase, where the
constant vanishes independently of @xmath . Using this quantity, we
obtain the right panel of figure 2.11 . We can clearly see now that for
temperatures well below the phase transitions, magnetic catalysis
occurs, and that for a small region below the chiral transition inverse
magnetic catalysis occurs, but only for small enough chemical potential.

For larger values of @xmath , this behavior continues. This can be seen
both from the left panel of figure 2.11 and from figure 2.12 , where
@xmath is shown, as defined in ( 2.22 ).

One can see that the chiral condensate always decreases with
temperature, and for most values of @xmath and @xmath , the chiral
condensate increases with @xmath . However, for certain values of @xmath
, @xmath and @xmath , the condensate decreases. One can check that
indeed that for small @xmath this is consistent with the right panel of
figure 2.11 , but also for larger values @xmath , one can find examples
of inverse magnetic catalysis. Indeed, one can see that for example for
@xmath , @xmath , the chiral condensate has a finite value for @xmath ,
whereas the condensate vanishes for @xmath .

In figure 2.13 , we show the magnetization divided by the magnetic field
as a function of temperature for different values of the chemical
potential and magnetic field.

In section 2.2 , we saw that for the first order deconfinement
transition, one can predict the slope of the transition temperature
@xmath from the sign of the jump of the magnetization across the
transition. This was studied in more detail in [ 39 ] . It turns out one
can extend the argument to second order transitions as well. In this
case one looks at the difference in entropy densities @xmath , which
must be zero along the phase transition line. Then by using a Maxwell
relation and using that @xmath is always larger for the higher
temperature phase, one arrives at the following formula,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath approaches zero from above. In other words, from the
direction of the kinks of @xmath , we can infer whether the chiral
transition moves up or down. Indeed, this formula correctly predicts the
behavior of the chiral transition temperature, even though many of the
kinks in figure 2.13 are too small to be visible.

In conclusion, we find that in our holographic model, at finite chemical
potential inverse magnetic catalysis persists up to some value of the
chemical potential, after which magnetic catalysis sets in. Also, the
region of the phase diagram covered by deconfined, chirally broken
matter, grows in size at finite @xmath . In the next section, we will
take a different look at inverse magnetic catalysis. Instead of applying
an external magnetic field, we turn on a different source of anisotropy,
and we examine how different this is from applying a magnetic field.

### 2.4 Inverse anisotropic catalysis due to an anisotropy

When we apply an external magnetic field to a quark-gluon plasma, this
breaks rotational invariance of the system, as the magnetic field is a
vector. It is then an interesting question to what extent phenomena
associated to magnetic fields, like (inverse) magnetic catalysis, are in
fact more general phenomena. In other words, are these phenomena caused
by anisotropy being introduced into the system, or does that anisotropy
need to specifically be a magnetic field in order for these phenomena to
appear? In this section, which is based on [ 131 ] , we will introduce
anisotropy by means of the anisotropy parameter @xmath introduced in
section 2.1 , which is dual to a space-dependent @xmath -term. Note that
this way of introducing anisotropy is very different from a magnetic
field, as @xmath couples to the gluon sector directly, while the
magnetic field couples indirectly through the quark sector.

In terms of the ‘master’ model from section 2.1 , we set the magnetic
field @xmath to zero, while also setting @xmath to ensure a vanishing
chemical potential. In this section, we will not distinguish between
@xmath and @xmath . This is possible because in this section we set the
magnetic field to zero, which means that there is no other source of
anisotropy, and we can choose the @xmath -axis to align with @xmath .
The choice of potentials is the same as in previous sections, namely
those in appendix A.1 . Most of these potentials have been used in
previous sections, and their asymptotics have been motivated in section
1.5.1 . This is not true for the @xmath potential though. We choose it
to be of the same form as what was used in [ 125 , 94 ] , where we have
set the constant term [ 129 ] to 1, as an overall factor can always be
absorbed into @xmath . In the IR, we must have @xmath to ensure a linear
glueball spectrum for the @xmath glueballs [ 125 , 128 , 172 , 135 ] ,
and the choice

  -- -------- --
     @xmath   
  -- -------- --

is the simplest choice that satisfies these constraints. We subsequently
choose @xmath [ 30 ] .

Before discussing physical observables, will next discuss the IR
asymptotics of the geometry, as the geometry in the presence of @xmath
is drastically different from the geometry at vanishing @xmath . Next,
we will discuss the thermodynamics, and we will conclude by examining
various observables, many of which turn out to have interesting
properties as a consequence of the different geometry at non-zero @xmath
.

#### 2.4.1 IR behavior

To examine the IR behavior of the geometry, we choose @xmath so that
there will not be a horizon capping the geometry off. We also set the
tachyon @xmath to zero, as the tachyon decouples from the other
variables in the IR [ 160 , 28 ] . Before continuing, it is also
convenient to define @xmath , @xmath , and @xmath . In terms of these
quantities, the equations of motion become

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

It is not difficult to see that these equations admit fixed point
solutions provided that

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

with @xmath a constant which we can set to zero, as it can be absorbed
into @xmath . First note that this solution describes an @xmath
solution, as @xmath and @xmath is constant. Also, this solution turns
out to be unstable. This can be seen from the second order dilaton EoM:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The term in the second square brackets vanishes at the fixed point, but
the term in the first square brackets does not. Because of this a small
@xmath will cause @xmath to be non-zero as well, which implies an
instability. The stability can be restored by requiring

  -- -------- --
     @xmath   
  -- -------- --

in addition to ( 2.25 ), which can only be satisfied for specific @xmath
. It turns out that this fixed point is realized by a chirally symmetric
vacuum that exists for @xmath , as we will see later. Note that in this
case one has to replace @xmath in the analysis by @xmath , where @xmath
[ 160 ] .

To find the IR behavior satisfied by the chirally broken vacuum, we need
to generalize the fixed point to a ‘slow roll’ solution around the fixed
point. In other words, we assume that deviations from the fixed point
solution are small and linear in @xmath . To do this, we set all second
derivatives to zero, which, from the argument above, requires that
@xmath , which, for our choice potentials, holds to good enough
precision. Under these assumptions, one can obtain that

  -- -------- -------- -- --------
     @xmath   @xmath      (2.26)
     @xmath   @xmath      (2.27)
     @xmath   @xmath      (2.28)
     @xmath   @xmath      (2.29)
     @xmath               (2.30)
  -- -------- -------- -- --------

where

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, by substituting the asymptotic behavior of the potentials
@xmath , @xmath , we can obtain analytically that

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (2.32)
  -- -------- -- --------

This has been investigavted for more generic potentials in [ 31 ] .
Indeed, the above asymptotics describe an approximately @xmath metric.

To check that these asymptotics indeed describe the IR behavior
displayed by the model, we compare the solutions of ( 2.26 – 2.30 ) to
the full numerical solution of the equations of motion given in section
2.1.2 . In the left panel of figure 2.14 , this comparison is shown for
different values of @xmath , and for @xmath .

One can see that far enough into the IR, the solution of ( 2.26 – 2.30 )
agrees well with the exact numerical solution of the equations of motion
given in section 2.1.2 . In the right panel of figure 2.14 , the
solution of ( 2.26 – 2.30 ) is compared to the analytical asymptotics
obtained in ( 2.31 – 2.32 ). These can be seen to eventually agree, but
only for extremely large values of @xmath .

#### 2.4.2 Thermodynamics

We will continue the discussion by examining various thermodynamical
properties of the system at different values of @xmath . As was
mentioned before, some of these properties are substantially altered by
the modifications to the IR geometry discussed in section 2.4.1 . In
figure 2.15 , we show the free energy as a function of temperature for
various values of @xmath , and for @xmath .

As different values of @xmath show the same qualitative behavior, we
will show only the result for @xmath . One can see that generally there
are three branches of black hole solutions: one small black hole branch
(labeled @xmath in figure 2.15 ), one big black hole branch (labeled
@xmath in figure 2.15 ), and an unstable branch (unlabeled). If the
anisotropy parameter @xmath vanishes, the result qualitatively agrees
with earlier results [ 126 , 127 ] . ²⁰ ²⁰ 20 The result is not exactly
the same because the potentials are different. In this case, the small
black hole branch in fact has infinitesimal area, and corresponds to the
horizonless thermal gas solution. As one turns on a non-trivial @xmath ,
however, the behavior is qualitatively different, as a black hole
solution now always dominates in region @xmath . This is due to the
@xmath geometry in the IR.

In figure 2.16 , we show the phase diagram as a function of temperature
and anisotropy parameter for different values of @xmath .

In this figure, as in the rest of this section, we define a phase to be
confining if the quark-antiquark potential has a linear branch. As the
system is anisotropic, this need not happen in every direction. This
leads to a phase with anisotropic confinement, which is confining in the
direction parallel to the magnetic field, and deconfined perpendicular
to it. Also note that with this definition of confinement, the
transition between a confining geometry and a deconfined geometry is a
crossover. We will discuss the confinement properties of the system in
more detail in section 2.4.3 , but it can already be seen using this
definition that for @xmath , the geometries become deconfined, i.e. the
quark-antiquark potential has no linear branch.

Another interesting observation is that the first order phase
transitions which exist at @xmath disappear at sufficiently large @xmath
for @xmath . In the cases of @xmath and @xmath , the first order
transition turns into a second order one, while for @xmath the first
order transition ends in a critical point. For large values of @xmath ,
in the case of @xmath , a first order transition reappears. The numerics
were not stable enough to determine whether this also happens for the
other values of @xmath considered. Also, note that for @xmath , the
chiral transition decreases to zero temperature around @xmath , and at
some larger @xmath the chiral transition reappears. In between these two
values, the vacuum is the chirally symmetric vacuum mentioned above.

The last feature that can be seen in figure 2.16 is the behavior of the
chiral transition. Comparing to figure 2.6 , we can see that in both
cases the chiral transition temperature first decreases as a function of
@xmath and @xmath , respectively. After this decrease, an increase
follows in both cases. This tells us that a magnetic field and an
anisotropy have similar effects on the resulting chiral transition
temperature. We will examine the chiral condensate explicitly in section
2.4.3 .

Lastly, in figure 2.17 we show the ‘anisotropic susceptibility’ @xmath ,
which we define by

  -- -------- --
     @xmath   
  -- -------- --

with @xmath as defined in section 2.1.4 . This definition agrees with
the standard definition of a susceptibility in the limit where @xmath .
In the same way as what we did in the previous two sections, we can
derive for the first order transition that

  -- -------- --
     @xmath   
  -- -------- --

Noting that the higher temperature phase at the phase transition always
has the largest entropy, we can read off from the jump of @xmath whether
@xmath is increasing or decreasing with @xmath . Indeed, this agrees
between figures 2.16 and 2.17 .

#### 2.4.3 Observables

Next, we examine in some more detail the chiral condensate, after which
we will look at some more consequences of the IR geometry. The chiral
condensate is shown in figure 2.18 .

Just as in the previous sections, the chiral condensate decreases with
temperature. Also, at @xmath the condensate always decreases with @xmath
, while for larger @xmath , the condensate first decreases as a function
of @xmath , and then increases again. The latter behavior can be studied
in more detail by defining

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

in analogy with ( 2.22 – 2.23 ). This quantity is shown as a function of
@xmath for various fixed temperatures in figure 2.19 , where we keep
@xmath .

For all values shown, one can see first a decrease in @xmath , which is
then followed by an increase. In particular, the decrease in @xmath is
greatest for temperatures just below the chiral transition. This gives
evidence that indeed an anisotropy as introduced in this section leads
to similar physical consequences for the chiral condensate, leading to
the claim that indeed the cause of inverse magnetic catalysis may be the
presence of anisotropy induced by the magnetic field.

Next, we will investigate the spectrum of helicity 2 glueballs. As was
mentioned in section 2.1.4 , we can infer from the Schrödinger potential
( 2.21 ) whether the spectrum is discrete or continuous. For the
geometry without the anisotropy, the Schrödinger potential diverges
towards the IR, creating a discrete spectrum. In the presence of @xmath
though, we have @xmath due to the @xmath geometry, leading to a
continuous spectrum. Such a dissociation of mesons due to anistropy has
been studied earlier in holographic models in [ 76 , 32 ] . In the left
panel of figure 2.20 , the resulting spectral density is shown for
@xmath , normalized by @xmath .

It can be seen that for small @xmath , the glueballs have small but
finite widths, whereas they would be described by delta functions at
@xmath . As one increases @xmath , the widths grow larger, and the peaks
melt. Still, the mass gap which is exact at @xmath is still
approximately present even at @xmath . Note that the peak appearing
around @xmath arises because due to the @xmath geometry changing the
power law behavior around the origin to @xmath . In the right panel of
figure 2.20 , the widths of the first glueball peak are shown for
different values of @xmath and @xmath . The widths can be seen to be
getting wider with a power-law dependence on @xmath .

Since the helicity 2 glueballs are not stable for @xmath , it is
interesting to examine another quantity related to the stability of
mesons, namely the quark-antiquark potential @xmath . This observable
quantifies the potential energy of a quark-antiquark pair at some
distance, where we assume the quarks to be infinitely heavy. If the
quark-antiquark potential grows infinitely with distance, it is
impossible to pull the quarks apart, and in this case they are confined
into mesons. ²¹ ²¹ 21 In reality, a new quark-antiquark pair will
nucleate between the original quarks, and one ends up with two mesons.
However, if we assume that no light enough quarks exist for this to
happen, it is impossible to pull the heavy quarks apart. However, if the
potential is bounded from above, at some distance the force between the
quarks will vanish, and in this case it is possible to pull the quarks
apart.

In [ 128 , 171 ] , a simple criterion was found to describe whether
there is a linearly growing branch of the quark-antiquark potential
which, in figure 2.16 , is used as the criterion to label confinement.
In our case, this implies that if @xmath has a local minimum, then the
quark-antiquark in the direction perpendicular to the anistropy @xmath
will have a linear branch. Similarly, if @xmath has a local minimum,
then the quark-antiquark potential in the direction of the anisotropy
@xmath will have a linear branch. In figure 2.21 , we show the entire
quark-antiquark potential for different values of @xmath and with @xmath
.

One can see that in both the parallel and perpendicular cases, the
solutions have multiple branches, with in particular the perpendicular
case showing multiple swallowtail structures. Of these branches, we are
supposed to pick the smallest one, which is stable. A consequence of
this is that even if @xmath resp. @xmath have local minima, the linear
branch which is then guaranteed to exist may not be stable. As with the
previous quantities we examined, the reason behind this is the @xmath
geometry, which causes the @xmath minimum to be only a local one.
However, even if the linear branch is not stable, for small enough
@xmath there is still a large potential barrier for the string to decay
to the stable configuration. This may indicate that the decay is not
very fast, in line with the observations from the glueball spectrum that
the glueballs are stable but long-lived.

The last observable we will examine is the entanglement entropy of
regions @xmath and @xmath as defined in section 2.1.4 . The result is
shown in figure 2.22 .

First, note that there are multiple branches, the lowest of which is the
stable one. Up to about @xmath , the results are similar to isotropic
results [ 173 , 98 ] . For large values of @xmath , the result depends
strongly on the orientation of the entangling region even when @xmath is
small. Specifically, for @xmath , the curve of the connected surfaces
always goes to @xmath , where the branch of disconnected solutions with
@xmath connects. However, for @xmath the point @xmath is never reached.
Instead, the swallowtail structure present without anisotropy quickly
gets smaller, and then vanishes.

As @xmath , the result becomes very different for the different
entangling regions. @xmath crosses zero for a smaller value of @xmath ,
whereas @xmath moves in the opposite direction. Such behavior has also
been observed for a magnetic field [ 97 ] . Overall, the dependence of
the entanglement entropy on the anisotropy is less pronounced than that
of the quark-antiquark potential. A possible explanation for this is
that the characteristic scale of the entanglement entropy is @xmath ,
causing the Ryu-Takayanagi surface to remain relatively close to the
boundary, whereas the characteristic scale of the quark-antiquark
potential is roughly @xmath . As the modification to the geometry due to
the anisotropy is most pronounced in the IR, this implies that the
quark-antiquark is more drastically modified even for small @xmath ,
while the entanglement entropy needs rather large values of @xmath for a
modification to become pronounced.

### 2.5 Interplay between magnetic field and anisotropy

In the final section of this chapter, we will investigate the interplay
of both sources of anisotropy introduced before. From the discussion in
section 2.1 , this gives us two options, namely to have @xmath parallel
to @xmath , or to have it perpendicular to @xmath . Recall that we were
unable to put the two anisotropies at an arbitrary angle, but this is
likely not an issue, as one expects to be able to already infer a lot of
information from these two cases.

In terms of the ‘master’ model introduced in section 2.1 , we set @xmath
to ensure @xmath , and we allow @xmath , @xmath and @xmath to be
non-zero. However, @xmath and @xmath can not both be non-zero at the
same time. We also set @xmath throughout this section. The potentials
will be kept the same as in the previous sections, i.e. the ones from
appendix A.1 . We do re-examine the @xmath -parameter from the @xmath
-potential again though. In the previous sections, we took @xmath as
this matches lattice results for the chiral transition reasonably well,
while keeping @xmath . Even lower values match the chiral transition
results better, but this may result in too large of a departure from
@xmath .

To determine whether lower values of @xmath match other lattice results
better as well, let us first examine the quark-antiquark potential at
zero temperature for @xmath , @xmath and @xmath , which is shown in the
left panel of figure 2.23 .

Firstly note that since we put @xmath , the linear branch exists for any
@xmath , and is always the stable branch. One can see that in this case,
at @xmath , the quark-antiquark potential gets steeper perpendicular to
the magnetic field, while parallel to it the potential gets slightly
shallower. For larger values of @xmath the quark-antiquark potential
gets steeper in both directions.

As the quark-antiquark potential has a linear branch in all the cases
considered here, one can also compute the slope of the asymptotic linear
behavior. This slope is called the ‘string tension’, and is shown in the
right panel of figure 2.23 , again for @xmath , @xmath and @xmath , but
now as a function of @xmath and for different values of @xmath . One can
see that as @xmath decreases, the perpendicular string tension increases
faster as a function of @xmath , whereas the parallel string tension
increases more slowly, and even decreases as a function of @xmath for a
part of the range of magnetic field shown for @xmath , and for all of
the range shown for @xmath . In [ 61 ] , it was found on the lattice
that the perpendicular string tension increases as a function of @xmath
, while the parallel string tension decreases. This is most in line with
the result for the holographic model for @xmath , and therefore in the
rest of the section, we will show results for both @xmath and @xmath .

Next, in figure 2.24 , we will examine the behavior of the chiral
transition temperature as a function of @xmath for different values of
@xmath , where we show the result for both @xmath and @xmath .

At the values of @xmath shown in figure 2.24 , the chiral transition is
the only feature in the phase diagram. Therefore we do not show a
separate phase diagram. We can see several qualitative features from the
chiral transitions. Firstly, we observe that around @xmath , there is
equality between @xmath and @xmath . Also, @xmath seems to effectively
decrease the value of @xmath for @xmath , which seems to be most
pronounced for @xmath .

In conclusion, in this chapter we constructed a bottom-up holographic
theory based on V-QCD which includes two different sources of
anisotropy, namely the magnetic field @xmath and the axion @xmath . We
were able to show that in this theory at zero chemical potential and
zero @xmath , it is possible to obtain inverse magnetic catalysis.
Furthermore, here are two contributions to the chiral condensate which
have competing effects, in support of the analysis done on the lattice
in [ 67 , 68 ] , namely that inverse magnetic catalysis is caused by
‘sea’ quark effects, which in our model correspond to the backreaction
of the gluon sector onto the flavor sector. Next, we generalized the
discussion to finite chemical potential, thereby for the first time
giving insight into the fate of inverse magnetic catalysis at finite
@xmath . Also, we found evidence to support the claim first made in [
112 ] that IMC is a more general effect caused by the anisotropy induced
by the magnetic field. Lastly, we investigated the interplay between
both sources of anisotropy, yielding interesting dependence on the angle
between both sources.

## Chapter 3 Holographic Baryons and Neutron Stars

In the study of neutron stars, some of the most basic questions are the
following:

-   Given the mass, what is the radius of the star?

-   What is the maximum mass?

-   How large is the tidal deformability?

-   What is the post-merger gravitational wave spectrum?

-   Do neutron stars contain deconfined quark matter cores?

As was discussed in the introduction, these quantities depend on two
things. The first is general relativity, which we understand well, and
of which we believe it holds in the regime of neutron stars to a high
degree of confidence. The second is the neutron star equation of state,
something we cannot compute from first principles in a controlled way.
This provides us with both a challenge and an opportunity. On the one
hand we are obviously challenged to find what the true EoS is. On the
other hand, neutron stars provide us with a novel laboratory to learn
something about QCD. As more data will be collected in the future, some
candidate equations of state will be ruled out, while others will remain
compatible with observations. Subsequently one can start looking into
the assumptions that went into these equations of state, to hopefully
learn something about which of these assumptions are viable, and which
are not. For this to work however, it is important that a wide range of
such models become available.

In this chapter, we will construct such an equation of state from
holography, which hence takes non-perturbative effects into account. In
[ 25 , 162 , 77 ] , holography has been used to model the deconfined
phase which one expects at extreme densities, while these models have
continued to rely on more traditional approaches for the nuclear matter
phase, which is expected to make up the bulk of the neutron star. In
this chapter, we in addition also model most of the nuclear matter phase
using holography. The holographic model we will use for this purpose is,
as in the previous chapter, V-QCD. For the choice of potentials,
however, we make a different choice from the previous chapter. In [ 162
] , observables at vanishing baryon chemical potential were compared to
lattice data, and the potentials were tuned to reach a good agreement.
Recall also from the introduction that various qualitative features of
QCD are matched by a judicious choice of asymptotic behavior of the
potentials, such as that chosen in V-QCD. This means that by choosing a
set of potentials from [ 162 ] , we can do the computations in this
chapter with a holographic model of QCD which matches real QCD to the
largest extent possible at the time of this writing.

In particular, we will use potentials 7a from [ 162 ] , which for
convenience can be found in appendix A.2 . In upcoming work which is not
part of this thesis, the analysis from this chapter will be repeated for
several other possible choices to investigate to what extent our
prediction from this chapter is a generic prediction from V-QCD as
opposed to one for this specific set of potentials.

By the procedure outlined in this chapter it turns out to indeed be
possible to construct an equation of state, which, in some sense, one
can then see as a sort of ‘extrapolation’ of lattice data to the neutron
star regime. Moreover, it turns out that the EoS one obtains in this way
is compatible with all presently known constraints, and is hence a
viable candidate. One thing that should also be emphasised though, is
that constructing this EoS can not yet be done from the V-QCD action
plus the chosen potentials without making approximations. Wherever these
approximations occur they will be pointed out, but the task of improving
the approximations further will be left for future work.

In the first section of this chapter, which is based on [ 158 ] , we
will obtain the holographic equation of state directly from the V-QCD
action. This EoS will, for reasons we will see below, be assumed to
approximate the true EoS best in the regime of high density, and is
expected to not work very well in the low density regime. In the second
section, based on [ 101 ] , we will introduce a matching procedure
between the EoS from holography, and a nuclear matter equation of state
coming from an effective Skyrme nucleon-nucleon interaction which is
expected to work better in the low density regime [ 140 , 93 ] . We will
then conclude this chapter by exploring the observational consequences
of the resulting hybrid equation of state. For completeness, note that
section 3 of [ 158 ] will not be covered, as it does not lead to
reasonable neutron star physics.

### 3.1 Baryons in V-QCD

As was discussed in the introduction, baryons arise in holography as
solitonic objects living in the bulk. In V-QCD, the fields responsible
for this are the gauge fields @xmath and @xmath , where the @xmath and
@xmath are flavor indices. These fields are dual to the globally
conserved currents

  -- -------- --
     @xmath   
  -- -------- --

In the previous chapter, the trace part of @xmath has already been used
as the source for the conserved total baryon number, i.e. the baryon
chemical potential. In that analysis however, the other components of
@xmath were set to zero. In this section, we do need to take those
components into account.

Before moving on to a brief summary of the steps required for performing
this analysis, let us first fix a few conventions that will be used
throughout this section. This is to keep notational consistency with [
158 ] . Firstly, we will denote spacetime indices with capital latin
characters, and we keep the following convention for the field strength
tensors:

  -- -------- --
     @xmath   
  -- -------- --

Also, note that when refering to an expression which applies to both
left and right handed gauge fields, we will use @xmath to denote this.
Furthermore, since the @xmath and @xmath labels are indeed just labels,
we will not be consistent in putting them up or down. Instead they will
be put in whichever place is visually convenient for a given formula.
Lastly note that since we use capital latin characters for spacetime
indices, the labels for left and right handed gauge fields will be
denoted with brackets as @xmath and @xmath whenever there is a
possibility for confusion.

In the following subsections, we will first expand the non-Abelian part
of the DBI action to first order in the gauge fields, after which we
will examine the Chern-Simons terms. After that, we will introduce a
homogeneous approximation, which reduces the degrees of freedom to a
single field @xmath . This field is discontinuous at some point in the
bulk, where the discontinuity can be related to the baryon number
density. To treat the discontinuity properly, one it is therefore hard
to perform the computation in the grand canonical ensemble where we
derive the action. For this reason we proceed to take a Legendre
transform, and we finally derive an action involving @xmath which, when
integrated on-shell, gives one the free energy density (in the canonical
ensemble). We will briefly discuss how this is done numerically, and
finally the result is Legendre transformed back into the grand canonical
ensemble, hence giving us the phase diagram and the equation of state.
The last subsection will then be devoted to a discussion of these
results.

#### 3.1.1 Expansion of the DBI action

The starting point for this subsection is the full flavored DBI action (
1.12 ) introduced in section 1.5.1 , which we repeat here for
convenience:

  -- -------- -------- -- -------
     @xmath   @xmath      (3.1)
              @xmath      
  -- -------- -------- -- -------

where we have

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (3.2)
  -- -------- -------- -- -------

and the covariant derivative for @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

Note that the non-Abelian part of this action is in principle ambiguous
because the order of the gauge fields is not specified, and its full
form is not completely known. The first few terms as a series in @xmath
are known precisely though [ 221 , 174 , 117 , 169 ] , and hence we will
here also use a series expansion in @xmath . In fact, we will consider
only the first non-Abelian correction on top of an Abelian background.
Using this restriction, the ambiguities are absent, and the trace in 3.1
does not require a special prescription, and can be taken to be an
ordinary trace. Obviously, using an expansion in the non-Abelian field
strengths assumes implicitly that these fields are small. This is one of
the points where the present analysis could potentially be improved in
the future, as it would be interesting to take the next order in the
expansion into account to see by how much the result changes. An
additional simplifying assumption we make is to take the tachyon to be
flavor independent

  -- -------- --
     @xmath   
  -- -------- --

just as what was done in the diagonalized DBI action used in chapter 2 .

The first step towards expanding in the non-Abelian part of the gauge
field is to split up @xmath into an Abelian part, which contains the
@xmath field familiar from chapter 2 , and a non-Abelian part. To do
this, we employ a slight abuse of notation and substitute

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

where we treat @xmath as small perturbations, while @xmath is kept to
all orders. This split is artificial, however, and to make the following
well-defined we have to impose the following condition on the
non-Abelian part of the gauge field:

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

After performing the substitution ( 3.3 ) into ( 3.2 ) and expanding for
small @xmath , we obtain

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (3.5)
  -- -------- -------- -- -------

where we define @xmath . ¹ ¹ 1 In this chapter, the prime always denotes
a derivative with respect to @xmath . One can obtain a similar
expression for @xmath . One next has to substitute this last expression
into ( 3.1 ) to obtain an action quadratic in the non-Abelian gauge
fields. To do this, it is convenient to define the ‘effective metric’:

  -- -------- --
     @xmath   
  -- -------- --

which leads to the following two identities:

  -- -------- -------- --
     @xmath   @xmath   
                       
     @xmath   @xmath   
  -- -------- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

This subsequently leads to the following expression, where we keep all
terms quadratic in @xmath and @xmath :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where we define the diagonal part of the effective metric as

  -- -------- --
     @xmath   
  -- -------- --

with the indices ordered as @xmath .

Putting this all together, including the analogous term for @xmath , one
obtains

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (3.6)
     @xmath   @xmath      
              @xmath      (3.7)
  -- -------- -------- -- -------

where the terms involving @xmath cancel due to ( 3.4 ), and where we
split up the zeroth and first order in the expansion. With the last
expression we have found the first part of the action for the
non-Abelian gauge fields. In the next subsection, we will discuss the
terms coming from the Chern-Simons section of V-QCD.

#### 3.1.2 Obtaining baryon number from the Chern-Simons action

Before stating the Chern-Simons (CS) action, let us first discuss why
this part of the V-QCD action is important for describing baryons. In
the approximations that follow, we will not attempt to backreact the
baryons onto the background geometry, which is taken to be a thermal
gas. In particular, this means that @xmath will be taken to be zero
throughout the bulk in the computation of the background geometry. This
would mean that the gauge fields don’t respond to a change in chemical
potential, which is something they should do since they carry the
correct charge. The Chern-Simons action provide such a coupling, and
indeed coupling @xmath to @xmath is entirely appropriate, as we will see
that the baryon number one can derive from the Chern-Simons action is a
total derivative, and hence counts solitons, which is exactly how
baryons arise.

We will now state the Chern-Simons action itself, which depends on a
CP-odd potential @xmath [ 30 ] . This dependence is highly non-trivial
though, as the explicit form of the Chern-Simons action changes with
different choices of @xmath . The reason for this is that as one changes
@xmath in a non-trivial way, gauge invariance and other essential
properties are usually spoiled. In this chapter, we choose a string
motivated ansatz, namely

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

where the constant @xmath is introduced with the motivation that if one
is to have regular IR solutions at a finite QCD @xmath -angle, the
contributions from the DBI action need to dominate over those coming
from the CS action, which is achieved provided that @xmath [ 30 ] . We
will now set @xmath for notational simplicity. Later we will restore
@xmath by rescaling @xmath . ² ² 2 Note that this rescaling happens only
in the CS action. The CS action is now given by [ 71 ] :

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Now, to extract the coupling between @xmath and the non-Abelian terms in
@xmath , we make the same substitution ( 3.3 ) as in the previous
subsection, and collect all terms involving @xmath . To do this, it
turns out to be useful to first modify @xmath by a total derivative,
since @xmath is only defined up to total derivatives. The modification
made is the following:

  -- -------- -------- -- -------
     @xmath   @xmath      
                          
              @xmath      (3.9)
  -- -------- -------- -- -------

Now one can check that

  -- -------- --
     @xmath   
  -- -------- --

with ³ ³ 3 Note that one has to use that @xmath and @xmath both only
depend on the bulk coordinate, and hence @xmath .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Using a variation of the action with respect to @xmath just as in
section 2.1.4 , one obtains the number density

  -- -------- --
     @xmath   
  -- -------- --

where we have used the @xmath equation of motion in the last equality.
The baryon number is therefore now given by:

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

where @xmath is the total baryon number. To conclude this discussion of
the CS action, note that indeed, as was mentioned at the start of this
subsection, that @xmath is indeed exact:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (3.11)
  -- -------- -------- -- --------

In the next subsection, we will take the next step towards including a
holographic treatment of baryons in V-QCD, namely the introduction of a
homogeneous approximation. This will reduce the degrees of freedom to
one single field @xmath .

#### 3.1.3 The homogeneous approximation

In principle, we could now attempt to construct a soliton dual to a
baryon in V-QCD by solving the action defined by ( 3.6 ) and ( 3.7 ),
while using ( 3.10 ) as a boundary condition to impose a fixed baryon
number. One could subsequently put many such solitons together to
achieve a finite baryon number density. While this has been successfully
done using approximate methods in for example the Witten-Sakai-Sugimoto
(WSS) model [ 258 , 229 , 230 ] , this is very challenging. The reason
for this is that the required solutions have non-trivial spatial
profiles, and hence to obtain them one needs to solve PDEs, and not only
that, the requirement of imposing a fixed number of baryons turns the
problem into a particularly hard one.

To make progress, we once again look to the WSS model for inspiration,
as approximations have been developed there in a controlled setup [ 147
, 142 , 148 , 141 , 170 , 74 , 75 , 60 , 227 , 164 , 82 , 165 , 210 , 58
, 50 , 226 , 111 , 180 , 102 ] . The particular approach we will follow
is a homogeneous approach [ 226 , 180 ] , and as the name suggests, this
reduces the problem to a spatially homogeneous one, which simplifies the
problem to the solving of ODEs, for which we can use standard
techniques. This is not the only possible way forward though. A similar
approach to the one we will follow was developed in the WSS model in [
102 ] , and this approach can also be adapted for V-QCD using similar
techniques to the ones that will be described below, but doing so is
beyond the scope of this thesis.

The idea behind our homogeneous approach is to assume a high density of
baryons. These will energetically prefer to be located at some
coordinate distance @xmath in the bulk. ⁴ ⁴ 4 Note that this is
non-trivial. It could well happen that there exists no such @xmath , and
in that case the baryonic phase is unstable. As we shall see, in our
setup the baryons are stable, and only in the region in the phase
diagram where one would expect this to happen. At @xmath , there will
therefore be a very non-trivial and highly inhomogeneous configuration
of gauge fields. Far enough away from this region, however, one can
approximate the gauge fields as being homogeneous, just as when
describing an electrically charged plate one does not have to worry that
the plate is made up out of atoms if one is solely interested in the
electric field far enough away.

The assumption we will now make is to divide the bulk into three
regions: two regions away from @xmath where the gauge field is
homogeneous, and a region around @xmath which we ignore, and which we
take to be infinitesimally thin. We replace instead this region around
@xmath by a discontinuity in @xmath at @xmath . If one once again looks
at the electric plate analogy, this means that if asked what for example
the total energy stored in the electric field is, we choose to only
include the field outside the plate, which we assume to be homogeneous,
and we ignore the fields inside the plate, which we cannot easily
describe. Of course this approach is not perfect, but it is expected
that one does obtain a qualitatively correct description. In the same
way, we will likely not obtain the correct on-shell action in this
manner, but we can still hope that the dependence of the on-shell action
on the baryon chemical potential is captured. Of course we have no way
of checking whether this actually happens without doing the full
calculation, but if this happens we can already learn valuable
information about the equation of state this way. In particular, while
the equation of state would only be reliable up to an overall factor,
the speed of sound would be unaffected by such a deviation. Indeed, in
section 3.2 , we will make precisely this assumption, and take the speed
of sound as input from the holographic model.

Concretely, the discussion from the previous chapter means that we set
@xmath and hence take

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

with @xmath the Pauli matrices. Here it is important to note that ( 3.12
) respects chiral symmetry and parity [ 206 , 207 ] . We take all
integrals to mean

  -- -------- --
     @xmath   
  -- -------- --

Specifically, this means that there are no delta function contributions
at @xmath , which would otherwise come from various derivatives
appearing in equations of motion.

Now that the prescription is known, we can start substituting ( 3.12 )
into ( 3.7 ) and ( 3.11 ). Doing this yields

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.13)
  -- -------- -------- -- --------

and

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

respectively. Before collecting these two results into the complete
action for @xmath , note that, were it not for the discontinuity at
@xmath , ( 3.14 ) would always evaluate to zero due to the asymptotic
behavior of the tachyon, which diverges towards the IR, and @xmath ,
which should vanish on the boundary because we do not want to introduce
a source for the baryon charge. This is not surprising given that @xmath
is exact, but it does show that the baryon number in the solutions is
indeed sourced at the discontinuity, as is appropriate in this
approximation.

We conclude this subsection by substituting ( 3.14 ) into ( 3.10 ), and
then combining this result with ( 3.6 ) and ( 3.13 ). This results in
the action for the homogeneous gauge field @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (3.15)
  -- -------- -------- -- --------

This puts the action for the non-Abelian gauge fields in a relatively
simple form, containing just a single field @xmath . In the next
subsection, we will continue the analysis by examining the
discontinuity, as we will need to decide by how much @xmath should be
discontinuous.

#### 3.1.4 The Legendre transformed action

In this subsection, we will derive a condition that needs to be
satisfied at the discontinuity. In fact, this condition will completely
fix the available freedom at the discontinuity, except for its location,
which we’ll get back to in the next subsection. We will also see that
this condition relates the jump in @xmath at the discontinuity to the
baryon number density. This makes it hard to perform the calculation in
the grand canonical ensemble, as we would need to extract the baryon
number density from the solution, and simultaneously also impose it as a
condition at the discontinuity. The solution to this will be to perform
a Legendre transform, after which we eliminate @xmath in favor of the
baryon number density. This gives us a different action, namely one in
the canonical ensemble, which we will then solve in the next subsection.

To start, we derive the baryon number density from ( 3.15 ) in the same
way as before:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.16)
              @xmath      
  -- -------- -------- -- --------

where we recall that @xmath depends on @xmath . Here we also introduced
the abbreviation

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

From the @xmath equation of motion, we can obtain the following:

  -- -------- --
     @xmath   
  -- -------- --

Since we can ignore any delta function contributions at @xmath , @xmath
is continuous, and we can then derive

  -- -- -- --------
           (3.18)
  -- -- -- --------

where we can immediately read off @xmath as the baryon number density on
the boundary, which is the physical baryon number density. Since @xmath
is continuous, this implies that @xmath is discontinuous, and from the
above equation one can derive that

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

where we define the discontinuity as

  -- -------- --
     @xmath   
  -- -------- --

Next, we perform the Legendre transformation to the action @xmath ,
whose on-shell value will correspond to the free energy, as follows:

  -- -------- --
     @xmath   
  -- -------- --

where we notice that

  -- -------- --
     @xmath   
  -- -------- --

Putting these two equations together, one obtains

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

To arrive at the final Legendre transformed action, there is one last
non-trivial step. We need to eliminate @xmath from the action. The way
to do this is to solve ( 3.16 ) for @xmath . This cannot be done
analytically, but one can obtain @xmath as a series expansion, where
higher order terms correspond to higher powers of @xmath , which can by
our assumptions be ignored. Performing this calculation leads to

  -- -------- -------- -- --------
     @xmath   @xmath      (3.21)
              @xmath      
  -- -------- -------- -- --------

with

  -- -------- --
     @xmath   
  -- -------- --

as in chapter 2 . Finally, we can substitute ( 3.21 ) into ( 3.20 ) to
obtain the Legendre transformed action:

  -- -------- -------- -- --------
     @xmath   @xmath      (3.22)
              @xmath      
  -- -------- -------- -- --------

We have now arrived at the action that we will solve numerically. In the
next section, some important points regarding how this should be done
will be given.

#### 3.1.5 Numerical method

With ( 3.22 ), we now have an action for @xmath , which, by substituting
( 3.18 ), we can solve. In this subsection, we will discuss step by step
how this is done, and how one can finally obtain the grand potential
density of the baryonic phase as a function of the baryon chemical
potential. Using this, one can construct the phase diagram and compute
the equation of state.

We start the process by computing a background metric and profiles for
@xmath , @xmath and @xmath in the same way as done in chapter 2 . For
this background we will use the thermal gas background, as this is
expected to be the only type of solution that will be dominant in the
phase diagram. ⁵ ⁵ 5 Note that this means that @xmath . Recall that we
will not backreact the non-Abelian gauge fields onto these background
fields, which means that we will use the same pre-computed background
for all the solutions for @xmath that we will generate in the rest of
this subsection.

The general idea for computing the solutions for @xmath is that we want
to minimize the baryon action ( 3.22 ) while keeping @xmath fixed in (
3.18 ). In the continuous sections of the bulk, this means that we
simply have to satisfy the equations of motion, but this also means that
we have to minimize other free parameters other than @xmath . In
particular, @xmath has boundary conditions at the boundary and in the
deep IR. Another remaining free parameter appears to be the location of
the discontinuity. The location, however, is completely fixed by the two
boundary conditions for @xmath and ( 3.19 ).

At the boundary, the equations of motion imply that

  -- -------- --
     @xmath   
  -- -------- --

However a non-vanishing @xmath would imply a source for the non-Abelian
gauge field, and hence we set @xmath . This leaves us with a boundary
condition at the boundary parameterized by @xmath . In the deep IR, it
turns out that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a constant that can be expressed in terms of the
potentials. This in principle gives us a second boundary condition
@xmath . However, such solutions will be left out of the remainder of
the discussion, as we have numerically checked that the value of @xmath
which minimizes the action is consistent with zero. Hence, for
simplicity, we will just set @xmath for @xmath . If desired, the
discussion below can be easily extended to reinstate @xmath . With
@xmath set to zero, ( 3.19 ) reduces to

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

This means that in order to find @xmath , we just monitor ( 3.23 ) as we
solve for @xmath by shooting from the boundary, and when we detect a
sign change, we iterate to find the @xmath where ( 3.23 ) is satisfied.

Summarizing the previous discussion, we now need to shoot from the
boundary, solving the equations of motion for @xmath until we find
@xmath by means of ( 3.23 ). All of this we have to do for different
@xmath , where in the end we must minimize the on-shell action with
respect to @xmath . For this, there is one hurdle remaining, namely that
the action diverges towards the boundary, implying that we need
holographic renormalization to evaluate it. There is a natural choice to
use for the subtraction, and that is to subtract the on-shell action for
@xmath . This corresponds to the on-shell action of a solution without
baryons, namely the thermal gas. In this way, by subtracting the action
with @xmath set to zero from the on-shell action with non-zero @xmath ,
we find exactly the difference in free energy density between the
baryonic solutions and the thermal gas solution. ⁶ ⁶ 6 Note that this
subtraction, as it does not depend on @xmath , does not alter any of the
above discussion.

Using all of the steps above, one is able to compute the free energy
@xmath for any desired @xmath and @xmath . In the final step towards
minimizing the free energy, one performs this computation for a wide
range of values for @xmath given a fixed @xmath . The minimal value
found in this way then yields the true free energy @xmath , where we
note that this minimal value is a stable minimum. Finally, performing a
Legendre transform on this last result enables one to obtain the grand
potential, or equivalently, the pressure @xmath , as desired.

#### 3.1.6 Results

We are now ready to discuss the results. For this, we will fill in the
value of @xmath corresponding to potentials 7a from [ 162 ] , and we
will also set @xmath . Note though that our value for @xmath is not
entirely consistent between the backgrounds, which are used also for the
deconfined phase, and the baryonic solutions. For the baryonic solutions
we use @xmath , while the backgrounds use @xmath , which is the most
appropriate given that the potentials were fitted to lattice data. This
is another source of uncertainty, that ultimately ends up modifying the
overall normalization of the pressure. Lastly, note that for all the
results in this section, we use @xmath for the parameter introduced in (
3.8 ).

As a first step in examining the consequences of including baryons into
V-QCD, let us examine the resulting phase diagram, which is shown in
figure 3.1 .

Note that only the baryonic phase in this phase diagram was computed
using the methods described in this chapter. The other phases were
computed using the methods described in chapter 2 . The phase diagram
itself contains three phases:

-   A thermal gas phase at small temperatures and chemical potentials.
    This phase features confinement and chiral symmetry breaking,
    similar to the vacuum of real QCD. This phase does not feature any
    temperature dependence though, as this is suppressed by powers of
    @xmath [ 21 ] , and hence doesn’t appear in the large @xmath limit.

-   A baryonic phase at small temperatures and intermediate chemical
    potentials. This phase shares the features of the thermal gas phase
    that were mentioned above, and in addition also has condensed
    baryons.

-   A deconfined, chirally symmetric phase at large temperatures and/or
    large chemical potentials. This phase is akin to the quark-gluon
    plasma phase found in real QCD. Due to the construction of the
    potentials, this phase also has an equation of state at vanishing
    chemical potential which is fitted to that of real QCD.

The resulting appears to be qualitatively reasonable within the
limitations of the approach, such as the large @xmath limit. The
baryonic phase appears in the right place in the phase diagram, and
importantly, the baryonic phase eventually yields to a deconfined phase
at some large chemical potential. This is in contrast to a similar
approach in the WSS model [ 180 ] .

Before moving on to the equation of state, it is a good check to look at
the location of the discontinuity. This is shown in figure 3.2 .

One can see that the discontinuity sits at a ‘natural’ location, as in
units of @xmath , which was introduced in chapter 2 , this distance is
@xmath .

To conclude this section, we will examine the equation of state at zero
temperature. The pressure as a function of chemical potential is shown
in figure 3.3 .

The phase transitions can clearly be seen, and the latent heat
associated to the vacuum to baryon transition is @xmath , while the
latent heat for the baryonic to deconfined phase transition is @xmath .
In figure 3.4 , we show the isothermal speed of sound at zero
temperature, given by

  -- -------- --
     @xmath   
  -- -------- --

with @xmath and @xmath the pressure and energy density, respectively.

While this is equivalent to figure 3.3 up to an integration constant,
this is a convenient additional way of visualizing the equation of
state. In the thermal gas phase, the pressure and energy density are
both zero, so the speed of sound vanishes. In the baryonic and
deconfined phases, it can be seen that the speed of sound exceeds the
conformal value in two places. This indicates a very stiff equation of
state. As it turns out, a stiff equation of state is likely needed to
pass astrophysical constraints [ 48 , 244 ] .

Summarizing, in this section we have constructed baryonic solutions in
V-QCD using a homogeneous approximation. In the next section, we will
use the resulting equation of state to compute neutron star properties,
and thereby investigate the potentially observable consequences from
such a strongly coupled approach.

### 3.2 Hybrid neutron star equations of state

In the previous section, we constructed an equation of state in V-QCD
using a homogeneous approach. This equation of state is likely to be
most accurate in the regime of large chemical potential, as the
homogeneous ansatz assumes a large baryon density. Also, we reasoned
that because the homogeneous ansatz only really looks at the tails of
the soltions, the on-shell action, and hence the pressure, is probably
not correct by an overall factor. Motivated by this, in this section,
based on [ 101 ] , we will construct a hybrid equation of state, which
is equal to a nuclear matter model at low densities, and has speed of
sound equal to the one constructed in the previous section at high
densities. We will then examine the potentially observable consequences
from this hybrid equation of state, namely the mass-radius relation, the
tidal deformability, and post-merger gravitational waveforms resulting
from a binary neutron star merger.

#### 3.2.1 Matching procedure

As briefly mentioned above, there are two ingredients that go into the
hybrid equation of state, namely a low density nuclear matter model, and
V-QCD. For the nuclear matter model, we will use the SLy equation of
state [ 140 , 93 ] . This EoS is based on effective Skyrme interactions
between nucleons. For the V-QCD part of the EoS, we develop a family of
solutions, parameterized by varying the parameter @xmath as defined in (
3.8 ).

To perform the matching, we take the two equations of state,

  -- -------- --
     @xmath   
  -- -------- --

with @xmath fixed. We then multiply the pressure belonging to the
baryonic phase ⁷ ⁷ 7 Note that we do not modify the pressure of the
deconfined phase, as this has been matched to lattice data in [ 162 ] .
in V-QCD with a constant @xmath to reflect that we take only the speed
of sound as input from V-QCD, and then we demand that

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

by choosing appropriate @xmath and @xmath . These two conditions
together guarantee that the phase transition between the SLy and V-QCD
parts of the equation of state is second order. The final equation of
state is then given by

  -- -------- --
     @xmath   
  -- -------- --

Of course, these two parts should both just be different descriptions of
the same phase, so ideally there would be no phase transition at all.
However, a second order phase transition is the best one can do if one
is only allowed to change the location of the matching @xmath and the
normalization @xmath . One could probably make the transition even
smoother, but that would require more ad hoc modifications of both EoS
ingredients, for which we have no justification.

In this way, for every chosen value of @xmath , one obtains a hybrid
EoS. This resulting hybrid EoS is shown for several choices of @xmath in
figure 3.5 .

At low densities, one can see that the hybrid EoS agrees with
constraints coming from effective low-density methods, indicated by the
blue band. This is of course true by construction, as this part of the
EoS is equal to the SLy EoS, which is itself constrained to satisfy this
constraint. At high densities, the hybrid EoS can be seen to agree with
constraints from perturbative QCD at extremely large densities,
indicated by the orange band. This is also true by construction, because
the asymptotics of the V-QCD potentials are constrained such that the
deconfined phase of V-QCD satisfies this constraint. Another interesting
feature that one can see is that as @xmath increases, the matching
chemical potential @xmath increases as well. This effectively means that
as @xmath increases, the proportion of the neutron stars described by
SLy increases, and equations of state with smaller @xmath describe
neutron stars with a relatively larger part described by holography.

#### 3.2.2 Mass-radius relation and tidal deformability

Now that we have a family of equations of state with input from
holography, one can start computing its observable consequences to
compare how well the equations of state compare to presently known
constraints. One of these observables is the mass-radius relation. Given
an equation of state, the Tolman-Oppenheimer-Volkov equations can be
solved to yield a relation between the mass and radius of a non-rotating
neutron star. This mass-radius relation is shown for the hybrid
equations of state in figure 3.6 .

At some central density, the matter inside the neutron star undergoes a
transition to deconfined matter, corresponding to the horizontal lines
in figure 3.5 . The kink that is visible in figure 3.6 corresponds to
the central density at which this happens, and the solutions to the left
of this kink have a deconfined quark matter core. The negative slope of
the @xmath – @xmath relation for these neutron stars with quark matter
cores implies that these solutions are unstable though, so the family of
hybrid equations of state does not allow for stable quark matter cores.

One observable that can be read off from the mass-radius relation is the
maximum mass of neutron stars, which for our family of equations of
state decreases with increasing @xmath . This is an important
observable, as the mass of a neutron star is a quantity that can be
experimentally measured with a reasonably good accuracy. Indeed, [ 27 ]
measured the mass of the pulsar J0348+0432 to be @xmath . This
immediately implies that any equation of state that does not permit a
stable neutron star of at least about @xmath is incompatible with this
observation. Of course, due to the uncertainty in the measurement of [
27 ] it is not precisely clear where one should draw the line, but for
our equations of state this means that the EoS corresponding to @xmath
is near the edge of exclusion at @xmath . In 2019, [ 79 ] measured a
potentially even heavier neutron star, J0740+6620, at @xmath . Including
this measurement, the hybrid EoS for @xmath is about one standard
deviation lighter than the one measured in [ 79 ] , so we will take
@xmath as our upper bound for @xmath .

As it turns out, we can also obtain a lower bound for @xmath . The
reason for this is that using the equation of state one can also compute
the tidal deformability @xmath . ⁸ ⁸ 8 This is not the same lambda as
the one used in chapter 2 . The tidal deformability is a dimensionless
number, which for our family of hybrid equations of state decreases as a
function of @xmath . The tidal deformability, as the name suggests,
describes how easy it is for another object to gravitationally deform
the star, and in fact this quantity has an influence on the
gravitational wave signal of the inspiral phase of binary neutron star
mergers. From GW170817 as measured by LIGO/VIRGO, it was not possible to
measure the magnitude of @xmath , but it was possible to extract an
upper bound of @xmath at 90% confidence level for a neutron star of mass
@xmath [ 11 ] . For the hybrid equations of state, it turns out the
@xmath corresponds to @xmath for such a neutron star, which would be
ruled out, but @xmath has @xmath .

In this way we obtain a family of equations of state with input from
holography with @xmath which are compatible with current (2020)
observational data. It is possible that future observations can
constrain these values further though. In particular, future results
from NICER, which recently published its first results [ 212 ] , could
potentially constrain the radius, thereby putting another constraint on
the equation of state. Also, with more data, it is possible that the
maximum mass constraint becomes more stringent, and also tighter
constraints on @xmath could potentially rule out more, or even perhaps
all, values of @xmath .

#### 3.2.3 Holographic neutron star mergers

We saw in the previous subsection that the hybrid EoS does not exhibit
quark matter cores. ⁹ ⁹ 9 This is not expected to change for rotating
neutron stars. An interesting question is whether there are any
circumstances in which the phase transition would lead to observable
consequences. As there are no static solutions with deconfined matter,
such circumstances would have to be fleeting moments in a dynamical
process. One such process is a binary neutron star merger. The
gravitational waves from such a merger can be detected in LIGO/VIRGO,
and as these detectors are upgraded, and as new ones are built,
detection capabilities continue to grow. The gravitational waveform
contains information about the equation of state, both in the inspiral,
as in the post-merger signal. In the inspiral part of the waveform, the
equation of state manifests itself mainly through the tidal
deformability @xmath , which in fact we have already used to constrain
the parameter @xmath . Right after the merger, the single object is in a
highly excited state, and vibrates with characteristic frequencies,
which depend on the equation of state. These frequencies can in
principle be detected in the corresponding part of the waveform, though
as of 2020 the post-merger signal has not been detected.

In this subsection, we will perform simulations of equal mass neutron
star mergers, with the aim of extracting observable consequences of the
hybrid EoS from the resulting waveforms. We will restrict ourselves to
equal mass mergers, and the stars will be initialized on quasi-circular
orbits with a diameter of 45 km. Here the reason why the orbits are only
quasi-circular instead of circular is that the system continuously loses
energy due to gravitational wave emission, and the reason to assume
vanishing eccentricity is that the same gravitational wave emission
tends to have circularized the orbits well before the merger takes place
[ 213 , 12 ] . To generate these initial conditions, we will use the
publicly available LORENE pseudospectral code [ 116 ] . As explained in
the introduction, the subsequent merger is described by general
relativity plus general relativistic hydrodynamics [ 223 ] . To solve
these equations, we use the Einstein Toolkit [ 234 , 245 , 115 ] , where
we use the high-order, high-resolution shock-capturing code WhiskyTHC [
217 , 214 , 215 , 216 , 218 ] , which solves the ideal general
relativistic hydrodynamics equations in conservative form [ 41 ] . For
the solution of the Einstein equations themselves, we use the
fourth-order finite differencing McLachlan code [ 66 , 182 ] , which
solves the Einstein equations in the CCZ4 formulation [ 22 ] . Here we
use a “ @xmath ” slicing condition, and a “Gamma-driver” shift condition
[ 17 , 205 ] .

In figure 3.7 , one can see the result of such a simulation for a binary
neutron star merger where the two stars have mass equal to @xmath .

The equation of state used for this simulation is the hybrid EoS with
@xmath . One can see that the signal starts with an inspiral phase where
the stars get increasingly close together as they radiate away energy in
the form of gravitational waves. Subsequently, when the stars touch, a
highly excited object forms, which continues to emit gravitational waves
until it settles down to a stable state. In this simulation, 40 ms after
the merger no horizon has yet formed, but it is unclear whether this
simulation would eventually collapse to a black hole. To investigate
this, one would have to continue the simulation for much longer past 40
ms, which is computationally very expensive. For this reason, it is not
clear whether the final state of this merger simulation would be a
neutron star or a black hole.

If the initial neutron stars are taken to be much heavier, an event
horizon will form immediately after the stars touch, and in this case
the gravitational wave signal dies down quickly after that. For the
hybrid equation of state with @xmath , we see this happening when the
stars both have mass @xmath . In the intermediate case, something very
interesting happens. In figure 3.8 , the result of a simulation of two
neutron stars with masses equal to @xmath is shown, again with @xmath .

In this case, after the merger a highly excited object forms just as
with the lighter stars, but now at @xmath , some of the matter in the
middle of the resulting object reaches densities large enough to cross
the phase transition into quark matter, which immediately causes a
collapse to a black hole. This is an example of phase transition
triggered collapse [ 252 ] .

Together, these three cases describe the possible outcomes from a
neutron star merger for the hybrid equations of state. ¹⁰ ¹⁰ 10 In [ 252
] there are also options which form remnants with quark matter cores,
but this is not possible for our equations of state, as these remnants
would be unstable. A quantity which contains a lot of information is the
power spectral density (PSD) [ 242 ] :

  -- -------- --
     @xmath   
  -- -------- --

where the integrations are performed from @xmath to @xmath around the
merger, where @xmath is defined as the maximum of the gravitational wave
amplitude. In figure 3.9 , the PSD is shown for the three possible cases
discussed above, each with the hybrid equation of state with @xmath .

Generically, the post-merger signal contains three characteristic
frequencies, labeled @xmath , @xmath and @xmath [ 33 ] . Here @xmath is
a universal value which is determined by the compactness @xmath [ 242 ]
. This implies that from @xmath no information from the equation of
state can be obtained that couldn’t already be obtained from the
mass-radius relation. The other frequencies @xmath and @xmath depend on
the equation of state in a more non-trivial way, and therefore these
frequencies would in principle allow one to obtain additional
information regarding the EoS. Note also that the @xmath case does not
contain the characteristic frequencies in its PSD. The reason for this
is that the characteristic frequencies are caused by oscillations of the
dense matter, which are absent in this case, because the configuration
promptly collapses to a black hole.

A final interesting thing one can do, is to compare mergers of equal
mass neutron stars where one keeps the mass fixed at @xmath , while
changing the equation of state. In figure 3.10 , the resulting PSD of
such a comparison is shown.

Here we show the resulting PSD for the hybrid equations of state with
@xmath and @xmath , as well as the SLy equation of state for comparison,
so that we can clearly see what the impact is of including input from
holography into the equation of state. The resulting @xmath frequencies
lie on the universal curve proposed in [ 242 ] . The @xmath peak shifts
to significantly lower frequencies for the hybrid equation of state.
Note that this shift is larger for the @xmath case, which has a smaller
matching density, and therefore contains more input from holography.
Also, the @xmath peak has a smaller amplitude for the hybrid equations
of state as compared to the pure SLy case.

In conclusion, the hybrid equation of state makes testable predictions
for various neutron star observables. The interesting aspect of this is
that holography gives us for the first time an approach to the EoS which
is inherently strongly coupled. In the future, one could refine the
analysis from both sections of this chapter to perhaps improve the
reliability of the result.

## Chapter 4 Simulation of Heavy Ion Collisions with Trajectum

In the last chapter, we studied the low-temperature, large chemical
potential region of the phase diagram using holography. This gave us
insights on how an explicitly strongly coupled framework such as
holography can yield observationally testable predictions. In this
chapter, we will focus on another region in the phase diagram, namely
that of high temperature and close to vanishing chemical potential,
where a quark-gluon plasma (QGP) exists (see [ 143 ] and references
therein). To be precise, we will take the chemical potential to be zero,
but a small chemical potential could in principle be added to the
analysis presented here in the future. QCD matter in this region of the
phase diagram can be created in heavy ion collisions, such as the ones
performed at RHIC and LHC. At the LHC, the collisions are performed at
@xmath and @xmath , using lead-208 and xenon-129 nuclei, as well as
protons. In the future it is considered to collide oxygen-16 and
argon-40 as well, but as of 2020 no decision has been made.

Heavy ion collisions are able to provide us a unique insight into QCD,
and many quantities of theoretical interest can in principle be observed
in this way. Examples of these are the following questions:

-   What does the initial state of a heavy ion collision look like?

-   How can the dynamics of the matter created at the collision be
    described before it can be described by hydrodynamics? After which
    time does hydrodynamics apply?

-   What are the values of QGP transport coefficients like the shear
    viscosity @xmath and the bulk viscosity @xmath ? Can higher order
    transport coefficients and relaxation times like @xmath and @xmath
    be measured?

One first thing to note is that the question as to the nature of the
equation of state at vanishing chemical potential is not included. The
reason for this is that the finite temperature equation of state is well
known from lattice QCD computations [ 62 , 46 ] . While it is true that
the dependence of the EoS on the chemical potential is less well known,
¹ ¹ 1 This is only known on the lattice for relatively small values of
the chemical potential [ 84 , 63 ] . this is beyond the scope of this
chapter, since we will not consider finite chemical potential. A second
thing to note is that out of equilibrium properties, like how the
initial state reaches local equilibrium, and even near-equilibrium
properties like transport coefficients, are very difficult to compute on
the lattice. In holography, however, many of these quantities can be
computed, and often give surprising results. A famous example of this is
the prediction that the ratio of the shear viscosity over the entropy
density of the QGP is given by [ 203 , 175 , 70 , 188 ]

  -- -------- --
     @xmath   
  -- -------- --

Another result from holography is that the matter created in the
collision can be described using hydrodynamics a very short time after
the collision [ 248 ] . However, all of these results are computed under
the assumption of infinite coupling and infinite number of colors, so it
is an interesting question how well these results match the properties
of an actual QGP.

Measuring these quantities of interest, however, is not as easy as it
may seem. Most observables in the final state of a heavy ion collision
depend on more than just one of the quantities of interest, making it
difficult to measure an observable and subsequently inferring something
about the quantity of interest. What is possible though is to create a
detailed model which simulates heavy ion collisions for different
choices of the quantities of interest, which we will from now on call
‘input parameters’. Such a model can then produce predictions for many
different observables for each particular set of input parameters. By
using such a model in a Bayesian analysis, it is then possible to fit
the input parameters to real experimental data, allowing one to learn
something about which input parameters fit the data best [ 51 , 168 , 52
, 197 , 44 , 167 , 195 , 196 , 53 ] .

In this chapter, we will construct such a model, called Trajectum ,
which also includes code to analyze the results. ² ² 2 Trajectum is the
Roman name for the city of Utrecht, where this code was developed. It
also means bridge, which is appropriate, as the aim of Trajectum is to
bridge the gap between theory and experiment. While it will not perform
any computations using holography, many of its inputs will be inspired
by holographic results of which we would like to test the validity in
experiments. The actual Bayesian analysis will not be performed in this
chapter, but the results will be compared to section 5.3 of [ 54 ] as a
check that Trajectum is able to reproduce known results. In the next
section, we will explain the overall design of Trajectum , after which
we will explain the various components that work together to create the
simulation of the heavy ion collisions. Finally, we will explain the
observables which can be extracted from the resulting collisions, and
compare them to previous work.

### 4.1 Overall design of Trajectum

Of course, Trajectum is not the first code to perform the tasks
described above. Many codes exist which perform parts of the computation
necessary to simulate a collision [ 236 , 231 , 233 , 201 , 192 , 42 ,
184 , 64 , 255 , 254 , 194 , 232 , 109 , 106 , 95 , 86 , 139 , 150 , 78
, 65 , 100 , 243 , 208 , 54 , 43 , 59 , 253 ] . These codes then need to
made to work together though, where care must be taken to hand over the
result of each step to the next step in the computation in the right
format. ³ ³ 3 Recently, a framework [ 211 , 177 ] has been developed
which automates this process, but this was not known to the author
during the development of Trajectum . The aim of Trajectum is to collect
all of these steps and to reimplement them into a framework which
provides a standard interface between the various required components.
In this way, one ends up with two executables, collide and analyze . The
first of these computes some desired number of heavy ion collisions with
input parameters according to the user’s preference. At the time of
writing, collide does not provide a hadronic afterburner, but the output
of collide is in the correct format for use in UrQMD [ 43 , 59 ] . The
output of UrQMD can subsequently be used in analyze , which is able to
compute a range of observables, which will be discussed below.

The advantage of enforcing a standard interface between the components
has one very clear advantage. For each component required for the
simulation, several choices are available. As an example, the simulation
requires initial conditions, for which several models exist. Of these,
the following are implemented in collide :

-   Monte Carlo Glauber [ 192 , 42 , 184 , 64 ] ,

-   Ohio State University [ 255 , 254 ] ,

-   T R ENTo [ 194 ] ,

-   Gubser flow [ 124 , 122 , 190 ] .

When using collide , the user can choose which of these to use, and as
they adhere to the standard interface, they are guaranteed to work
together correctly with the other components. Similarly, all the other
components of collide can be interchanged for various different options.
The standard interface is implemented in C++ using polymorphism.

As was mentioned above, many of the components implemented in Trajectum
are reimplementations of existing earlier work. In the sections below,
we will discuss each of the various components in detail. In certain
places, the original works have been extended or modified in order to
address some of the holography-inspired questions posed above. Wherever
the implementation of an algorithm in Trajectum differs significantly
from the one in the corresponding earlier work, this will be clearly
stated.

### 4.2 collide executable

As was mentioned in the introduction, a heavy ion collision is simulated
in several stages. This consists of a pre-equilibrium stage which
provides initial conditions for the hydrodynamical simulation of the
QGP, followed by a hydrodynamical evolution. From the hydrodynamical
evolution a freeze-out surface is computed, which is defined as an
isotherm called @xmath . At this freeze-out surface, the code translates
from a continuous fluid description to a discrete particle description.
The particles must subsequently be written to a file, so that they can
be further processed by the hadronic afterburner UrQMD, which simulates
interactions between the particles produced up to the point in time
where they can be taken to be non-interacting. The afterburner also
simulates the decay of unstable particles.

These stages each translate into one or more components in collide . An
event is simulated in collide as follows: The component responsible for
the pre-equilibrium stage (called ‘initial conditions’) generates
initial conditions for the hydrodynamical evolution. This is then passed
to the component for the hydrodynamical evolution. The component for the
hydrodynamical evolution (called ‘hydrodynamics model’) then evolves the
evolution in time step by step. For this it depends on two auxiliary
components:

-   A component (called ‘transport coefficients’) containing the
    equation of state, as well as first and (if needed) second order
    transport coefficients. ⁴ ⁴ 4 Note the slight abuse of terminology
    here. Usually the equation of state is not considered a transport
    coefficient, but for all purposes one could consider it a 0th order
    transport coefficient, and we will do so throughout this chapter.

-   A component (called ‘PDE solver’) which implements an algorithm for
    solving partial differential equations.

By splitting off these components from the hydrodynamical evolution
itself, it becomes easier to alter the simulation, as one can easily
implement a new solver or set of transport coefficients. In principle,
to do this it is not even necessary to understand how each of the other
components works. One only needs to know how for example the transport
coefficients should interface with the framework provided by collide ,
which then guarantees that the new set of transport coefficients
correctly works together with the other components.

After each time step is computed, the hydrodynamics model hands the new
state of the fluid over to the last component (called ‘hadronizer’),
which is responsible for computing the freeze-out surface and generating
particles from the fluid. When the hadronizer determines that after the
last computed time step there is no new addition to the freeze-out
surface, the hadronizer causes the entire computation to terminate, and
collide will move on to the next event. An important note here is that
even though the wording in the last sentence may suggest that collide
waits for each event to be completed before moving on to the next event,
collide is actually multithreaded, and will compute 20 simulations
simultaneously. ⁵ ⁵ 5 If desired, multithreading can be turned off when
compiling Trajectum .

Summarizing, we have 5 different components which together simulate a
collision:

-   Initial conditions,

-   Hydrodynamics models,

-   Transport coefficients,

-   PDE solvers,

-   Hadronizers.

In the following subsections, each of these components will be
explained. In particular, all currently available options that the user
can choose from will be covered. Also, an important point to mention at
this point is that we will assume boost invariance, i.e. we solve
hydrodynamics in @xmath D. This is done by taking the following metric
(called the Milne metric):

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

which is related to the Minkowski metric by the coordinate
transformation

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the proper time, and @xmath the pseudorapidity. With this
metric, boosts correspond to shifts in @xmath , and we can implement
boost invariance by assuming that all of the variables constituting the
fluid have no @xmath -dependence. Also, for the rest of this section, we
define the canonical order of variables @xmath .

#### 4.2.1 Initial conditions

As was briefly mentioned before, the aim of the initial conditions
component is to provide initial conditions to the hydrodynamical
evolution. In collide , there are four different sets of initial
conditions implemented:

-   Monte Carlo Glauber [ 192 , 42 , 184 , 64 ] ,

-   Ohio State University [ 255 , 254 ] ,

-   T R ENTo [ 194 ] ,

-   Gubser flow [ 124 , 122 , 190 ] .

In [ 124 , 122 ] , an analytical solution of viscous hydrodynamics was
derived under the assumption of a conformal equation of state, constant
@xmath and @xmath . Gubser flow initial conditions implement initial
conditions as a time slice of this analytical solution. This provides a
good non-trivial check on the implementation of the numerical code to
solve the hydrodynamical evolution [ 190 ] . The other three initial
conditions are phenomenological models attempting to describe the
initial state of a heavy ion collision as well as possible. They also
include a model of the evolution from the proper time of collision (
@xmath ) to the moment that the hydrodynamical evolution is initiated
(denoted @xmath ). In the remaining paragraphs of this subsection, we
will discuss the various steps involved in all of these models. As the
models are rather similar in setup, this will be done for all three
models simultaneously, where we point out the differences where they
occur.

The first step in all three remaining models is to determine the
positions of nucleons in both nuclei. For protons, this is simple. As
there is only one nucleon inside the nucleus, the single nucleon just
sits in the center of the nucleus. For the other nuclei impemented in
collide , we assume that the nucleons are distributed according to a
Saxon-Woods distribution [ 183 , 237 ] : ⁶ ⁶ 6 Note that this is a
probability density in Cartesian coordinates. When sampling from the
distribution, one can either sample @xmath , @xmath , @xmath , then
covert to @xmath , @xmath , @xmath and accept with a probability given
by ( 4.2 ), or one can introduce a Jacobian to ( 4.2 ) and sample from
it directly.

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

where @xmath is the probability density to find a nucleon at radial
distance @xmath , polar angle @xmath and azimuthal angle @xmath , @xmath
is a normalization factor, @xmath and @xmath are parameters, and

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath , @xmath and @xmath are more parameters, and @xmath are
spherical harmonics. The values for these parameters for the nuclei
implemented in collide are given in table 4.1 .

The nucleons constituting the two nuclei are sampled from the
corresponding Saxon-Woods distribution. In doing this care must be taken
that the axis of symmetry of the non-spherically symmetric nuclei needs
to point in a random direction. In T R ENTo initial conditions, the
nucleons also have to satisfy the property that the distance between two
nucleons has to be larger than a minimal distance @xmath . This is
enforced as follows: One samples coordinates @xmath , @xmath and @xmath
according to ( 4.2 ). Then, starting from the nucleons with the smallest
@xmath , @xmath is resampled in such a way that the nucleon satisfies
the minimal distance requirement with respect to all nucleons with
smaller @xmath than itself. For all initial conditions, the sampled
nucleons are subsequently converted into Cartesian coordinates, where
the @xmath -coordinate which points along the beam is discarded. The
remaining coordinates are given a random offset, reflecting the fact
that the nuclei collide with a random impact parameter.

The next step is to determine the locations of the constituents of each
nucleon. Here there is a difference between the initial conditions
models we are considering, as the Monte Carlo glauber model does not
have nuclear substructure, the Ohio State University model has
substructure with 3 constituents per nucleon, and the T R ENTo model
only optionally has substructure, but with an arbitrary number of
nucleons @xmath . For the initial conditions without substructure, one
can simply skip this step, and consider a single constituent of each
nucleon, located at the location of the corresponding nucleon which was
computed in the previous step. The procedure below describes how
constituents are sampled in the T R ENTo model for initial conditions.
The procedure for Ohio State University initial conditions is
parameterized differently, but is physically equivalent. In the T R ENTo
model without substructure, nucleons are modelled as Gaussian blobs of
density with width @xmath . ⁷ ⁷ 7 This is the standard notation. Note
that this @xmath is not the same as the one appearing in the Saxon-Woods
distribution. In the version with substructure, there are @xmath
constituents, which are modelled as Gaussians blobs of density with
width @xmath , sampled from a Gaussian distribution around the center of
the nucleon, with width @xmath . As it is convenient that the width
parameter @xmath from the model without substructure corresponds roughly
to the one with substructure, the model with substructure is
parameterized in terms of @xmath and @xmath , where @xmath . The width
of the distribution of constituents @xmath is then chosen as

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

For each constituent in each nucleon, the position is sampled from a
gaussian with width @xmath around the center of the corresponding
nucleon. However, the average of these sampled constituents does not
necessarily correspond to the center of the corresponding nucleon.
Therefore, the constituents are moved by such an amount so that the
center does coincide with the center of the corresponding nucleon. Then,
because of the choice of @xmath from ( 4.3 ), the nucleons will on
average have width @xmath . ⁸ ⁸ 8 Here width is taken to be the RMS of
the nucleon. This is not the same RMS of the deposited energy in the
fluid though, as we will later fluctuate how much density each
constituent deposits according to a Gamma distribution.

Now that we have the positions of all the nucleons and (depending on the
choice of initial conditions) their constituents, we have to determine
which nucleons become ‘wounded’. Wounded nucleons are precisely the
nucleons that participate in the collision. To determine which nucleons
participate, we examine all pairs of nucleons, where we take the first
nucleon (nucleon A) from the first nucleus (which we will call nucleus
A), and the second nucleon (nucleon B)) from the second nucleus (which
we will call nucleus B). For each such pair, we then compute the overlap
function

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are the @xmath -coordinates of the constituents of nucleon
A, @xmath the @xmath -coordinates of the constituents of nucleon A, and
similarly for @xmath and @xmath . For the initial conditions without
substructure, this overlap function is to be interpreted to have a
single constituent for each nucleon, where we also have to replace
@xmath by @xmath . Now that we have the overlap function, the
probability that these two nucleons participate in the collision is

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a constant. In accordance with this probability, the
nucleons are both marked as being ‘wounded’ with probability @xmath . ⁹
⁹ 9 Note that they are either both marked as wounded, or both not. They
are not separately marked with probability @xmath . If the two nucleons
are marked as wounded, the corresponding nucleon pair is also marked as
being a ‘binary collision pair’. We have here introduced the parameter
@xmath . In principle, we could leave this as a parameter to be
determined by the user. Instead of this, however, we choose @xmath
precisely such that the average cross-section of proton-proton
collisions is the same as the parameter @xmath , which is available to
the user to specify.

Knowing which nucleons participate in the collision, we can start
constructing a ‘density’ to initialize the plasma. Note that this
density is just a function @xmath . Depending on the model, it can be
interpreted as an entropy density, energy density, or specific component
of the stress-energy tensor. How exactly the different models interpret
@xmath will be discussed towards the end of this section. To compute
@xmath , let us first define the ‘thickness functions’ @xmath , @xmath
and @xmath :

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , and @xmath denote the @xmath and @xmath -coordinates of
constituent @xmath of nucleon @xmath , and the outer sum goes over all
wounded nucleons in nucleus A. What the weight @xmath is, depends on the
initial conditions. For the Monte Carlo Glauber model, it is equal to 1,
whereas for both the Ohio State University model and the T R ENTo model
it is a random number, which for each constituent is drawn from a Gamma
distribution with mean equal to 1, and standard deviation equal to a
parameter called @xmath . An analogous expression holds for @xmath in
terms of the wounded nucleons in nucleus B. The last function, @xmath ,
is not determined in terms of the wounded nucleons, but in terms of the
binary collision pairs. As @xmath will only be used by the Monte Carlo
Glauber, and since this model does not have constituents, the expression
below is given in terms of the nucleon positions themselves:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are the coordinates of the nucleon from nucleus A
participating in the binary collision, and @xmath are the coordinates of
the nucleon from nucleus B. In words, the wounded nucleons deposit
density into the thickness functions @xmath and @xmath at the location
of the constituents, and each binary collision pair deposits density
into the thickness function @xmath .

How the three thickness functions are subsequently combined into one
density @xmath again depends on the specific model. In the Monte Carlo
Glauber model, we have

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a parameter. In the Ohio State University model, the @xmath
-contribution is ignored, and we have

  -- -------- --
     @xmath   
  -- -------- --

In the T R ENTo model, we have

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a parameter. Note that in the limit @xmath , this reduces to
the geometric mean

  -- -------- --
     @xmath   
  -- -------- --

At this point, for all models considered, we have a function @xmath with
the dimension of inverse area. We now have several options for how to
interpret this function. In both the Monte Carlo Glauber and Ohio State
University models, @xmath is interpreted as an entropy density as
follows:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a dimensionless number called the norm, and @xmath is
the proper time at which the hydrodynamical evolution is initialized.
Using the equation of state, this can then be used to determine energy
density and pressure. This does not completely fix the initial condition
for the hydrodynamical evolution though, as the stress-energy tensor has
7 independent components, and fixing the energy density only fixes one.
¹⁰ ¹⁰ 10 Note that assuming boost invariance reduces the number of
components by 3, as @xmath for @xmath . In collide , there are two
options to determine the other coefficients. The first sets the
velocities to @xmath , sets bulk pressure @xmath , and subsequently
computes the shear tensor as ¹¹ ¹¹ 11 Note that in Milne coordinates (
4.1 ), @xmath can be non-zero even if @xmath .

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

where the code gets the shear viscosity @xmath from the transport
coefficients model chosen by the user, and @xmath is defined as in
equation 1.5 . The second option sets @xmath , @xmath , and [ 248 ] :

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the energy density, @xmath and @xmath .

In the T R ENTo model, a different approach is taken. Here, the
stress-energy tensor is initialized as [ 54 ] :

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

where @xmath is now a parameter, also called the norm, with dimension of
inverse length. For @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

where the rows and columns of the matrix correspond to @xmath . At this
point, we deviate from the original implementation of T R ENTo. In the
original implementation, the parameter we call @xmath is set to 1, in
which case ( 4.5 ) corresponds some density of massless particles
determined by @xmath free streaming from time @xmath to @xmath . Indeed,
this reflects in the name of the initialization time, where the fs
stands for free streaming. The parameter @xmath , which we call the free
streaming velocity, generalizes this ansatz by allowing free streaming
to occur with a speed lower than that of the speed of light.

Another deviation from the original T R ENTo is in the initialization of
the shear tensor and bulk pressure. In [ 248 ] , it was observed that
using holography to model the initial stage leads to a smooth transition
to hydrodynamics. The energy density and velocity profile is identical
to first order in proper time to that obtained by free streaming, but
the shear tensor obtained from holography is given by ( 4.4 ). ¹² ¹² 12
The model in [ 248 ] is conformal, and therefore has no bulk pressure.
In order so that a future Bayesian analysis can potentially be used to
decide whether free streaming or holography fits experimental data best,
we introduce a parameter @xmath with which we can interpolate between
free streaming and holography.

The procedure to obtain the stress tensor then becomes the following. We
first construct the stress tensor as given by free streaming ( 4.5 ),
and decompose the stress tensor in terms of @xmath , @xmath , @xmath and
@xmath . We then compute @xmath and @xmath as

  -- -------- --
     @xmath   
  -- -------- --

We subsequently compute

  -- -------- --
     @xmath   
  -- -------- --

and reconstruct @xmath using @xmath , @xmath , @xmath and @xmath . In
this way, by choosing @xmath , we can interpolate between weakly coupled
initial conditions ( @xmath ) and strongly coupled initial conditions (
@xmath ).

A final feature that is new in collide , which is available for all
initial conditions models discussed above, is the ability to optionally
bias the distribution of events generated by the initial conditions. To
illustrate what this is and why one would want this, consider
proton-lead collisions. Typically, for such collisions, we are
interested in collisions which generate a lot of particles in the final
state. These events correlate fairly well with the initial entropy
deposited in the plasma by the initial conditions. ¹³ ¹³ 13 The
correlation is not as good as for lead-lead collisions because the total
number of particles produced is lower, and therefore statistical
fluctuations from Poisson statistics make the correlation less
pronounced. However, events which generate a lot of particles in the
final state are rare. This leads to the inconvenient situation that to
get a good amount of data to be able to achieve small statistical
uncertainties for the observables one is interested in, one has to
generate even more events, the vast majority of which will not be
useful. The bias that we introduce now is based on the following idea.
Of the entire collision simulation, the initial conditions are by far
computationally the cheapest to compute. Since the initial entropy
correlates well with the number of particles in the final state, we can
compute the initial conditions for the hydrodynamical evolution, and
then accept the event for further computation with a probability @xmath
, which depends on its initial entropy. By choosing the acceptance
function @xmath appropriately, we can selectively compute events which
will have a large amount of particles in the final state, thereby
improving statistics for observables relating to such events without
needing to spend much more in computation time. Of course, when
computing these observables, we need to be careful that our bias in the
events that we generate does not translate into a bias in the final
computed observable. This can easily be achieved by making sure that
each event analyzed by analyze is weighted with weight @xmath . Also,
care has to be taken when computing centrality classes, as these weights
also have to be taken into account when determining them.

#### 4.2.2 Hydrodynamics models

The next component we will describe is the hydrodynamics model itself.
In collide , two models are available:

-   First order hydrodynamics, which solves the first order
    Israel-Stewart equations with only first order transport
    coefficients [ 159 , 198 , 144 , 240 ] ,

-   Second order hydrodynamics, which also includes some second order
    coefficients.

Of course, one can just obtain the first order hydrodynamics equations
by setting all the second order coefficients to zero. However, there is
still a good reason to have two separate classes, namely that setting
the second order coefficients to zero when running the code is a lot
slower than explicitly leaving those coefficients out of the code to be
evaluated, and solving the simplified equations. Since the equations
which determine the hydrodynamical evolution are used by the solver
every time step at every grid point, their speed of execution greatly
impacts the overall execution time of the whole program. However, to
explain how these two models work, we will just explain how the second
order hydrodynamics model works, as the workings of the first order
model can be easily determined by setting the second order coefficients
to zero.

In hydrodynamics, one of the first things we have to decide when solving
the equations numerically is which variables to choose. To illustrate
this, one could imagine solving for each of the 7 components of the
stress-energy tensor. However, one could equivalently solve for the
energy density @xmath , two velocities @xmath and @xmath , the bulk
pressure @xmath and the components @xmath , @xmath , @xmath . ¹⁴ ¹⁴ 14
Note that by tracelessness and orthogonality one can reconstruct @xmath
completely from these components. A convenient choice of variables turns
out to be [ 240 ]

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

where we define @xmath , and @xmath , with @xmath for the other
components. Just by counting, one can see that this number of variables
is larger than the number of independent variables, as we are evolving
every non-zero component of the shear tensor. It turns out however, that
for the first step of solving the hydrodynamical equations, which will
be discussed below, it is easier if these redundant components are
evolved as well, so that they can be used in that step. Another question
one might ask is why certain variables are defined by incorporating a
factor @xmath into their definition. The reason for this is twofold. On
the one hand, it reduces the number of Christoffel symbols entering the
equations, and on the other hand it removes some general behavior of the
variables. To see what is meant by this, consider @xmath . By
energy-momentum conservation, @xmath will behave roughly like @xmath .
By instead evolving @xmath , this dependence is removed, making it
easier to obtain a good accuracy in the numerics.

Solving the hydrodynamical equations themselves involves two steps. The
second step depends for its computation on quantities like the velocity
and the energy density, which are quantities that are not listed in (
4.6 ). This immediately explains the need for the first step, which is
to reconstruct these quantities, which we will call ‘auxiliary
variables’ from now on, from the variables in ( 4.6 ), which we will
call the ‘primary variables’. What the second step does depends on which
solver is used. The finite difference solver requires for its algorithm
a function which takes in all current values of the primary variables,
as well as the auxiliary variables mentioned above, and outputs the
proper time derivatives of the primary variables. The MUSCL solver
instead requires the equations to be put in the form

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

where @xmath is an array of all variables in ( 4.6 ), @xmath and @xmath
are the fluid velocities in the @xmath and @xmath directions, and where
we call @xmath the source term. What the MUSCL solver then needs for its
evaluation is the function @xmath . The hydrodynamics models hence
expose three functions to the collide framework: one function which
reconstructs the auxiliary variables from the primary variables, and two
functions which compute the the time derivative, and the source term,
respectively. In the remainder of the discussion of the hydrodynamics
model, we will only discuss the equations for source terms, as the
equations for the proper time derivatives can be easily obtained from
these.

As mentioned above, the first function necessary to solve the
hydrodynamical evolution is one that takes in the primary variables and
computes from them the auxiliary variables. To do this, we define [ 236
]

  -- -------- --
     @xmath   
  -- -------- --

Using the decomposition of the stress tensor 1.3 , we can then obtain

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (4.8)
     @xmath   @xmath      
  -- -------- -------- -- -------

where @xmath is the pressure. These equations can be rearranged to give

  -- -------- --
     @xmath   
  -- -------- --

This equation can be solved iteratively for @xmath as follows. The
function

  -- -------- --
     @xmath   
  -- -------- --

has the property that @xmath , whereas @xmath . The physical solution
for @xmath corresponds to the solution of @xmath , which lies between
those values, and can be solved by an algorithm like Brent’s method,
which was also used in chapter 2 . Subsequently, once @xmath is known,
one can derive from ( 4.8 ) that

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath , completing the task of computing the energy
density and the velocity. Note that during both the iterative solving of
@xmath and the computation of @xmath requires the pressure to be known
as a function of the energy density, which is a task which is performed
by the transport coefficients component.

Next, we describe the computation of the source terms. For @xmath , we
have [ 240 ]

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

For the bulk pressure @xmath , we have used not all the second order
expressions, but just the ones also kept by [ 54 ] (The full second
order expressions can be found in [ 89 , 90 , 88 ] ):

  -- -------- --
     @xmath   
  -- -------- --

where @xmath , with @xmath for the other components similar to the
definition of @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

Lastly, for the shear tensor, we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

Here the second order coefficients, which are set to zero for the first
order model, are the coefficients @xmath , @xmath , @xmath , @xmath ,
@xmath and @xmath .

#### 4.2.3 Transport coefficients

The task of the transport coefficients model is twofold. It needs to
compute the pressure by means of an equation of state, and it should
compute the transport coefficients appearing at the end of the last
subsection. In collide , there are three available transport coefficient
models:

-   Ideal gas equation of state with ‘constant’ transport coefficients.

-   Lattice QCD equation of state with ‘constant’ transport
    coefficients.

-   Lattice QCD equation of state with temperature dependence in some of
    the transport coefficients.

Here ‘constant’ means that the transport coefficients are described by a
single parameter. For example, for the shear viscosity @xmath ,
‘constant’ transport coefficients do not imply that @xmath itself is
constant as a function of temperature, but rather that @xmath is, where
@xmath is the entropy density specified by the equation of state. We
will now describe each of the available models in some detail, starting
with the ideal gas equations of state with ‘constant’ transport
coefficients.

For the ideal gas equation of state, we assume an equation of state of
the form

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the pressure, and @xmath a constant which can be specified
by the user. Additionally, the shear and bulk viscosities can be
specified by the user by means the following constant combinations:

  -- -------- --
     @xmath   
  -- -------- --

The shear and bulk relaxation times @xmath and @xmath , respectively,
are specified as the following constant combinations:

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

The second order coefficients are given by the following constant
combinations: ¹⁵ ¹⁵ 15 If the user specified that the first order
hydrodynamics model should be used, collide does not request the second
order coefficients of the user.

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

with @xmath the pressure. Note that if one specifies @xmath , @xmath
small enough, and all other coefficients zero, one can use this model
for transport coefficients in combination with the Gubser flow initial
conditions to obtain the analytical solution [ 124 , 122 , 190 ] , with
which one can check the accuracy of the numerical solution.

For both models which use a lattice QCD equations of state, we actually
use a hybrid of a hadron resonance gas (HRG) for temperatures below
@xmath , an analytical fit to a numerically constructed lattice QCD
equation of state for temperatures above @xmath , and a polynomial
interpolation of the trace anomaly in the intermediate temperature
regime [ 54 , 151 ] . The polynomial interpolation is taken such that at
the matching points, @xmath and @xmath , the trace anomaly, as well as
its first 4 derivatives, is continuous. The hadron resonance gas
equation of state can be computed from

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

with the @xmath for fermions, and the @xmath for bosons. Also, @xmath ,
where @xmath and @xmath are the mass ¹⁶ ¹⁶ 16 In the actual
implementation, the particle masses of the unstable particles are taken
from a modified Breit-Wigner distribution, and quantities like the
energy density and the pressure are averaged over all masses, where the
average is weighted according to the distribution. This is implemented
properly in collide , but to simplify the discussion, we leave this
detail out of the discussion. An excellent explanation can be found in
section 3.4 of [ 54 ] . and number of degrees of freedom of species
@xmath , respectively. The species used in the sum are precisely the
particle content of UrQMD, which is necessary for consistency between
the different stages of both collide and UrQMD itself.

The lattice QCD part of the equation of state is described by the
following parameterization [ 46 ] :

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

and the fit coefficients

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

The discussion so far fixes the equation of state of the two lattice EoS
based transport coefficient models. Let us next discuss the first and
second order transport coefficients, where we start with the shear and
bulk viscosities. These two transport coefficients are the only
difference between the two lattice EoS based models. In the model
without temperature dependence, the two viscosities are given by the
same constant combinations as for the ideal gas based model:

  -- -------- --
     @xmath   
  -- -------- --

In the model with temperature dependence, we have [ 54 ] :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

with @xmath as given in ( 4.11 ), and

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

parameters to be specified by the user. The shear and bulk relaxation
times are defined by the following constants [ 88 ] : ¹⁷ ¹⁷ 17 To ensure
the stability of the numerics, it is important that timescales, like
@xmath and @xmath , are larger (with some margin) than the time step
size @xmath used by the PDE solver. To ensure this, collide always
enforces @xmath and @xmath .

  -- -------- --
     @xmath   
  -- -------- --

which differ slightly from those in ( 4.9 ). The second order
coefficients are then specified by the following constants [ 88 ] :

  -- -------- --
     @xmath   
  -- -------- --

which again differ slightly from those in ( 4.10 ).

#### 4.2.4 PDE solvers

The PDE solver performs the task of solving the hydrodynamics equations.
To do this it interfaces with the hydrodynamics model, which provides
the necessary functions, as discussed above. The PDE solver then updates
the state of the fluid from proper time @xmath to @xmath , where the
size of @xmath can be chosen by the user. In collide , there are two
main types of PDE solvers:

-   Finite difference solver,

-   MUSCL solver.

Both of these solvers have slight variations implemented, which allow
the user even more flexibility. Each of the solvers has their advantages
and disadvantages, so one should pick carefully when using collide on a
problem. The finite difference solver uses a very simple algorithm, as
we will see below. This has the advantage that, due to its low
complexity, it is faster by about a factor 2 as compared to the MUSCL
solver. The disadvantage of the finite difference solver is that it is
not guaranteed to be stable. Under certain circumstances, like the
presence of shocks or when using transport coefficients with extremely
small viscosities, numerical instabilities may appear, which grow
exponentially. The MUSCL solver, instead, is guaranteed to be stable.
Indeed, the algorithm that it uses is stable by construction, as it was
designed with stability in mind. For this reason, one can use MUSCL even
for an ideal fluid, with all viscosities set to zero. The disadvantage
that accompanies this stability, however, is increased execution time.
Depending on the type of problem, one can choose which of these benifits
outweigh the associated costs. In the following few paragraphs, we will
discuss both of these solvers, pointing out the available variations
along the way.

Now let us first discuss the finite difference solver. One can write the
hydrodynamics equations for the ‘primary variables’ defined in section
4.2.2 as follows:

  -- -------- --
     @xmath   
  -- -------- --

with @xmath a function, and where @xmath is the collection of primary
variables at grid site @xmath . Here the first entry corresponds to the
@xmath -coordinate, and the second corresponds to the @xmath
-coordinate. One can then perform the following discretization [ 186 ] :

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath is the spacing between grid points. In other words, one
simply replaces the spatial derivatives by the second order accurate
discrete derivatives, and one replaces the time derivative by a linear
approximation. While this may seem a little naive, this works quite well
under most circumstances, and as mentioned before, due to its
simplicity, is very fast. In collide there are also variations
implemented which replace the second order accurate spatial derivatives
with fourth or even eighth order accurate ones. This is however slightly
smaller, and seems to be less numerically stable than the second order
spatial derivatives, so one should not use it.

The MUSCL solver has a more sophisticated algorithm, which is based on
the idea that the equations can ‘almost’ be written as a set of
conservation equations ( 4.7 ). A remarks are in order here. First of
all, it may seem a bit strange to write for example @xmath , while we
know that @xmath . However, the latter equation is a tensor conservation
equation. Numerically, it is simpler to implement the first option,
because this guarantees that the same velocities @xmath can be used for
all primary variables. How the algorithm updates the primary variables
is only different from how the finite difference solver performs the
update is in the @xmath and @xmath terms. The source term is added in
the same way as for the finite difference solver, where when needed, we
also replace derivatives by their second order accurate approximations.
The two terms mentioned are replaced following the Kurganov-Tadmor (KT)
algorithm [ 47 , 95 ] : ¹⁸ ¹⁸ 18 An alternative to KT, known as the HLL
two-state formula, is also available in collide [ 86 ] .

  -- -------- --
     @xmath   
  -- -------- --

with a similar expression for the @xmath -derivative term. We will
continue the discussion only for the @xmath -derivative term, the
formulas for @xmath are analogously defined. In the above expression,
@xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is equal to @xmath , and where @xmath is the flux of @xmath
at the cell’s interface. At this point, an optional shortcut is
available in collide . To properly evaluate the flux for a specific set
of primary variables, one needs to find @xmath and @xmath , which
implies that one has to find the auxiliary variables, which is
numerically expensive. The shortcut taken is that we compute @xmath and
@xmath in an analogous way to the computation of @xmath and @xmath ,
thereby limiting the amount of times one has to solve for auxiliary
variables. ¹⁹ ¹⁹ 19 We checked that neither the accuracy nor the
stability is negatively impacted by this trick. For @xmath and @xmath ,
we have:

  -- -------- --
     @xmath   
  -- -------- --

with the quantity @xmath being roughly equal to the second order
accurate derivative with respect to @xmath . If one would take this
rough equality to be exact, the algorithm would become identical to the
finite difference method described above. This would then however also
inherit the stability issues of that method. It turns out that the
crucial element to achieve stability is the addition of a flux limiter.
In the MUSCL implementation in collide , we use the minmod flux limiter:

  -- -------- --
     @xmath   
  -- -------- --

where the minmod flux limiter function is defined as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Finally, note that in collide , one has the option to either integrate
the time derivatives using the forward Euler algorithm, which is first
order accurate, or with the midpoint method, which is second order
accurate. In the results shown in section 4.3 , we used the KT solver
with the shortcut for the solving of auxiliary variables.

#### 4.2.5 Hadronizers

After each update that the PDE solver makes to the fluid, the
hydrodynamics model hands the new fluid state to the hadronizer. The
hadronizer is then tasked with generating particles, which are output in
a format compatible with UrQMD. In collide , at the time of writing,
only one hadronizer is available, namely Cooper-Frye [ 78 ] . The
hadronization procedure consists of several steps. First, the hadronizer
computes a freeze-out surface. Subsequently, particles are produced at
the freeze-out surface according to a modified thermal distribution,
where the modifications encode the presence of shear stress and bulk
pressure into the final state particles. In the paragraphs below, we
will explain each of these steps in more detail.

The first step to turn the fluid into particles is to compute the
freeze-out surface. This is an isotherm of a specific temperature @xmath
that the user can specify. At the freeze-out surface, a number of
particles are produced according to a Poisson distribution, which has
the property that the sum of Poisson distributed processes again follows
a Poisson distribution. As a consequence of this, we can subdivide the
freeze-out surface into triangles, and sample particles from each
triangle individually. After this, we can even discard the freeze-out
surface from which particles have already been sampled, as it is no
longer necessary. This is exactly how collide tackles the problem. When
the hydrodynamics model computes the state of the fluid at proper time
@xmath , it gives the state of the fluid to the Cooper-Frye hadronizer,
which still has in its memory the state of the fluid at proper time
@xmath . Using the Cornelius algorithm, it then computes a triangulation
of the freeze-out surface [ 150 ] . ²⁰ ²⁰ 20 Note that for a @xmath D
description like the one in collide , freeze-out surface elements are
triangles. A more general treatment for @xmath D can be found in [ 150 ]
. For each triangle, it also computes a surface normal @xmath [ 54 ] .

The next step is to generate particles for each triangle. This is done
using the Cooper-Frye formula [ 78 ] :

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

where @xmath is the number of degrees of freedom for species @xmath .
The idea behind this formula is that the hadronization procedure should
be not a change in physical process, but rather a change in description
of that process. The particle species used in the formula are precisely
the ones that are used in the HRG equation of state which describes the
fluid, and because they are sampled from a thermal distribution, they
indeed describe precisely the HRG. ²¹ ²¹ 21 The freeze-out temperature
is required to be below @xmath , i.e. in a temperature regime where the
equation of state is that of the hadron resonance gas. This ensures
that, in the absence of shear stress or bulk pressure, the stress energy
tensor of the fluid will be on average the same as that of the sampled
particles. ²² ²² 22 The sampled particles are, of course, subject to
Poisson statistics. In this sense, the sampled particles form a
different description of the fluid, and when one then only keeps
particles which move out of the fluid, one thereby obtains a consistent
transition between the fluid and the HRG.

Everything described so far assumes that @xmath and @xmath . If this is
not the case, the sampling of the particles needs to be adjusted so that
the stress-energy tensor of the fluid still matches the average
stress-energy tensor of the sampled particles. The way this is done in
collide is by rescaling the momentum of each sampled particle in the
fluid rest frame [ 54 ] :

  -- -------- --
     @xmath   
  -- -------- --

where @xmath with a proportionality constant that can be computed by a
hadron resonance gas computation, and @xmath depends in a non-trivial
way on @xmath . ²³ ²³ 23 For details on how to obtain the
proportionality constant for @xmath as well as for how precisely to
obtain @xmath , see [ 54 ] . For bulk corrections, also the particle
density obtained from the Cooper-Frye formula ( 4.12 ) needs to be
modified, as with the rescaling of the particle momenta described above
the energy density is also modified. The way to correct this is to
modify the number density [ 54 ] .

We now have produced particles in a way such that the stress-energy
tensor is on average continuous across the freeze-out surface. There is
one final step, however, namely decaying the @xmath particle. This
particle is not treated by UrQMD, but given its light mass is produced
in large quantities during an event [ 202 , 54 ] . In collide , the
@xmath can be optionally taken into account when compiling Trajectum .
If the user includes the @xmath , it is immediately decayed into pions,
which is justified given its short lifetime.

### 4.3 analyze executable

The analyze executable is tasked with computing the observables
according to their proper definitions from the result of the hadronic
afterburner. Additionally, it obtains from the output of collide each
event’s weight. The executable does this in two passes over the data
file. The first pass reads every event, and computes quantities that
will allow us to group the particles into centrality and @xmath bins
during the second pass. During the second pass, each event is read
again, and based on its @xmath value is placed in a bin together with
similar events, after which each event is analyzed by the observables
that the user requested. In the next few paragraphs, each of these two
passes will be described in some more detail, after which a selection of
observables will be shown.

The first pass over the data has the task to determine the centrality
classes. This is done by counting @xmath for each event, which is a
measure of the number of particles produced in the event. The definition
of @xmath differs from experiment to experiment, and is usually defined
in such a way that only particles are counted which are charged, and
have kinematics such that the detector is able to detect them
efficiently. Of course, in the output of collide and UrQMD, we are able
to detect any particle whatsoever with 100% efficiency, but for
comparison with the experiments it is still important to make the same
cuts, so that we are comparing the exact same observable. This will be a
recurring theme throughout this section. As briefly mentioned already,
@xmath is defined by the number of charged particles in an event, and
the kinematic cuts usually require that for a particle to be counted,
the transverse momentum @xmath needs to be between a certain lower bound
and a certain upper bound, and that the pseudorapidity @xmath needs to
have an absolute value below some upper bound. For example, the cuts
used in this section are

  -- -------- --
     @xmath   
  -- -------- --

After @xmath has been counted for each event, the events are sorted from
the largest @xmath to the smallest. This ordering then determines the
centrality bins, and for each centrality bin, analyze then saves between
which values @xmath should be such that the event is within that
particular bin. Of course, when events are weighted according to their
initial entropy, it is important to take these weights into account when
computing the centrality bins, so as not to bias the binning. For
example, 5% central would no longer mean that 5% of the events have a
larger @xmath , but instead it means that 5% of the total weights belong
to events with a larger @xmath .

After the centrality bins ²⁴ ²⁴ 24 In analyze it is also possible to bin
particles based on @xmath directly. For notational convenience, we will
just refer to both of these binning options as ‘centrality’ bins, as for
the remainder of the discussion the distinction is not important. have
been determined, a second pass over all events is made, in which each
observable that the user requested can examine each event. Each
observable again, typically, makes some cuts on which particles it
counts. All of these cuts, namely cuts on transverse momentum,
pseudorapidity, but also which type of particles to count, can be set by
the user, where different settings can be chosen per observable. This
may seem like a lot of flexibility, but this is necessary, as different
experimental measurements often have different cuts, and as was
mentioned before, to be able to compare to experimental values it is
extremely important to use the exact same cuts as the experiment in
question. In this way, the flexibility given to the user allows to
compute a large number of observables at the same time, where each
observable is precisely defined, by a single use of analyze ,i.e. there
is no need to run the executable multiple times. Another advantage of
this flexibility is that the cuts on which types of particles to count
makes it possible to compute observables defined in terms of ‘identified
particles’, i.e. one can compute for example the mean transverse
momentum of only charged pions, or of only protons.

In the framework provided by analyze during the second pass, each
observable is allowed to output an array of what we will define
‘intermediate quantities’, along with a weight for each such quantity.
The framework provided by analyze will then compute a weighted average
for each element in the array, where not only the weights provided by
the observable are taken into account, but also the weights for each
event based on its initial entropy. The weighted averages are then given
back to the observable, along with errors and correlations between the
elements in the array, which provide the observable with all the
information it needs to compute its final outputs. Also, the individual
values for each event are given, which allows to, for example, compute
event-by-event @xmath distributions [ 5 ] . To illustrate this, let us
take the quantities @xmath and @xmath as examples [ 15 ] . These are
both computed by the ‘v2’ component in analyze . For each event, ‘v2’
computes quantities known as @xmath and @xmath , which come with weights
@xmath and @xmath , respectively, where @xmath is the number of
particles which satisfy the various cuts. ²⁵ ²⁵ 25 Precise definitions
of @xmath and @xmath will be given in section 4.3.3 . After each event
has been computed, analyze computes the averages

  -- -------- --
     @xmath   
  -- -------- --

along with the standard deviations of the averages and correlations
between the two measured averages. Here @xmath stands for the event
weight of event @xmath based on its initial entropy, i.e. @xmath . The
averages are then given back to the ‘v2’ component, which computes the
final outputs

  -- -------- --
     @xmath   
  -- -------- --

where care is taken to estimate the final errors by standard error
propagation methods.

In the remainder of this section, we will use analyze to compute a
selection of available observables, which we will compare to available
experimental data. ²⁶ ²⁶ 26 At the time of writing, there are 3132
observables available in analyze . This may seem like a very large
number, but this is mainly due to the fact that many observables have a
large number of possible variations. However, this large number does
mean that not all observables can be shown here. The aim of this is
twofold. Firstly, as Trajectum is a new code, checking its predictions
against known results is a good check that the code is relatively free
of serious mistakes. For this purpose, we choose the maximum a
posteriori (MAP) values obtained for @xmath in [ 54 ] . For certain
choices of parameters of collide , the predictions of Trajectum should
be the same as, or at least compatible with, to the result from [ 54 ] .
As we will see below, this is the case. The MAP values we are using for
the computation have been obtained by means of a Bayesian fit to
experimental data, and as such represent some of the most
state-of-the-art knowledge concerning which inputs to the simulation fit
the data best. However, we would like to improve this analysis further
by adding additional experimental data to the analysis. This brings us
to the second aim of the remainder of this section.

Any additional experimental data should have the following properties to
be useful in the Bayesian analysis, where by useful we mean that the
additional observable provides an additional constraint to data.
Firstly, the observable should have small statistical uncertainties for
the number of events that we can feasibly generate for each set of input
parameters to collide . The results shown below have been generated
using 10000 minimal-bias events, and with limited computation time
available it is not feasible to perform the Bayesian analysis with
significantly more events. This means that the error bars shown in the
plots below are what we can reasonably expect to achieve in the Bayesian
analysis. In such an analysis, we need to be able to decide whether a
particular observable is well-described by a particular set of inputs to
collide , or whether there is enough tension to exclude a particular
parameter set. If the error bars are too large, this can not be
achieved, and hence the particular observable will not give an
additional constraint.

Another requirement for an observable to be useful in the Bayesian
analysis is that the constraints it gives on the input parameters should
not coincide with the constraints which are already given by other
observables. To give an obvious example of this, imagine we would like
to use the mean transverse momentum of positive pions in the analysis.
This gives a constraint on the input parameters. In particular, it will
constrain the bulk viscosity @xmath . However, given that the mean
transverse momentum of all pions is already being used in the fit, and
since there is no significant difference in particles and their
antiparticles in collisions at @xmath , the constraint given by the
positive pions will completely coincide with the constraint from all
pions. With regards to this requirement, the most interesting outcome of
the analysis of the MAP values would be to find an observable which is
completely incompatible with the prediction from [ 54 ] . Such an
outcome could mean two things. Either there is a subset of input
parameters to collide which is compatible with the data used in [ 54 ] ,
or the model used to simulate the events is missing an ingredient which
is essential to describe the new variable.

#### 4.3.1 Charged particle multiplicities and spectra

Let us now start with the comparison of Trajectum to experimental data.
In figure 4.1 , the charged particle multiplicity is shown, where we
only include particles which satisfy @xmath .

The resulting multiplicity is then divided by the size of this
pseudorapidity range, so that we arrive at a quantity which is
relatively independent of the particular pseudorapidity cut. In figure
4.1 , also the experimental result from ALICE is shown [ 6 ] . One can
see that Trajectum underestimates the experimental result by about
5–10%. This is no cause for alarm though, as [ 54 ] shows a compatible
underestimation.

An observable which was not used in [ 54 ] is the transverse momentum
spectrum, which is shown in figure 4.2 for events in the 0–5% centrality
interval.

Note that this figure shows the transverse momentum spectrum of
identified particles, which reflects in the fact that not a cut in
pseudorapidity, but in rapidity (see ( 1.10 )) has been made. Also, in
order to define the spectrum in such a way that it does not scale
significantly with the size of the transverse momentum bins and the
rapidity cut, the multiplicity in each bin has been divided by both the
bin size and the rapidity range. Even though we don’t compare the
transverse momentum spectrum with experimental data, one can see that
for heavier masses the momenta shift to higher values, something we will
see quantatively in the next subsection. Also, one can clearly see that
even for rare particles like @xmath or maybe even @xmath , it is
possible to obtain reasonable statistics for the transverse momentum
spectra of identified particles.

#### 4.3.2 Mean transverse momentum

In figure 4.3 , we show the mean transverse momentum of charged
identified particles, where we have a rapidity cut of @xmath .

The mean transverse momentum is quite simply defined as the mean of the
transverse momentum of all particles satisfying the cuts in all events.
To mold this definition into a weighted average over events, we define
for each event

  -- -------- --
     @xmath   
  -- -------- --

with @xmath the weight associated to the event, and @xmath the number of
particles in the event which satisfy the cuts. This definition
guarantees that if we then average @xmath over all events with the given
weights, the method agrees with the experimental one. Figure 4.3 shows
excellent agreement with [ 14 ] . This is no surprise however, as the
result from [ 54 ] agrees with the experimental data equally well,
because @xmath was used in their Bayesian analysis.

Another observable we will examine is the mean transverse momentum
fluctuations, which is shown in figure 4.4 , where we include only
charged particles with pseudorapidity @xmath .

The mean transverse momentum fluctuations are defined as [ 13 ] :

  -- -------- --
     @xmath   
  -- -------- --

where we average over all particle pairs @xmath occuring in the same
event. To write this in the form required by analyze , we define the
following two quantities for each event, in addition to the mean
transverse momentum:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where each of these quantities have weight @xmath and where @xmath is
the number of particles in the event which satisfy the cuts. ²⁷ ²⁷ 27
Note that while it may seem that @xmath , the weighting for @xmath is
different compared to that of the mean transverse momentum, invalidating
this equality. With these definitions, we now have that

  -- -------- --
     @xmath   
  -- -------- --

where the angle brackets are the properly weighted averages of @xmath
and @xmath over all events. The result from Trajectum shown in figure
4.4 is in good agreement with [ 13 ] , which is again unsurprising,
because this observable was also used in the Bayesian analysis of [ 54 ]
, with good results.

#### 4.3.3 Anisotropic flow

The anisotropic flow measures how anisotropic the azimuthal distribution
of particles emitted from an event is. As this can vary substantially on
an event-by-event basis, one usually defines observables as an average
over a large number of events in a centrality class. Additional
observables look at the amount of variation of anisotropic flow within a
centrality class, which will be covered in the next subsection. In this
section, we define the flow coefficients @xmath . Several of these are
shown in figure 4.5 for charged particles with @xmath and @xmath .

To define the flow coefficients, let us first define for each event the
cumulants [ 57 ] :

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

where @xmath is again the number of particles in the event which satisfy
the cuts, and @xmath is the azimuthal angle of particle @xmath . We
subsequently define for each @xmath :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

and we also define the weights

  -- -------- --
     @xmath   
  -- -------- --

If we now average @xmath and @xmath with these weights, then for each
@xmath we obtain @xmath and @xmath , in terms of which are defined

  -- -------- --
     @xmath   
  -- -------- --

In figure 4.5 , one can see that, as with the previous observables,
there is excellent agreement between Trajectum and experimental data [
15 ] . Again, this is in agreement with [ 54 ] as well, who used exactly
these experimental findings in their analysis.

#### 4.3.4 Event-by-event anisotropic flow

As briefly mentioned above, one can also look at the amount by which the
anisotropic flow, in this case specifically @xmath , fluctuates event by
event. This event-by-event @xmath is shown in figure 4.6 for charged
particles with @xmath for events in the 30–35% centrality interval.

The method used in this figure for computing the @xmath of a single
event is called the single particle method [ 5 ] . It can be defined in
terms of the cumulants ( 4.13 ) as

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

where @xmath is again the number of particles in the event which satisfy
the cuts. We can then store the @xmath values for each event, and then
compute a probability distribution around the average value as in figure
4.6 . As can be seen, even though this observable was not used in the
Bayesian fit in [ 54 ] , there is agreement with the experimental value
[ 5 ] , but the error bars are quite large. Also, the tail of the
distribution is expected to be the most constraining [ 200 ] ,
especially to the initial condition, but this is entirely missing from
the Trajectum prediction, and would require more events to compute.
Maybe one could still achieve a non-trivial constraint on the inputs by
choosing larger centrality bins though.

Another potential issue with this observable is that the experimental
value [ 5 ] has been modified using an unfolding procedure, which
attempts to remove the bias inherent in defining @xmath through ( 4.14
). This implies that the two observables shown in figure 4.6 are not the
same, and should not be compared. However, in the limit of the number of
particles per event going to infinity, this mentioned bias in defining
@xmath through ( 4.14 ) vanishes. Therefore, by studying the dependence
of the Trajectum result shown in figure 4.6 on the acceptance cuts,
particularly on the pseudorapidity, it may be possible to extrapolate
the result to this desired limit. This would allow the comparison to the
ATLAS data, but we leave this for future work.

## Chapter 5 Discussion and Outlook

In this thesis, we have studied QCD from three different angles,
corresponding to the three main chapters. A recurring theme throughout
this has been the idea to use holography to study QCD-like theories in a
genuinely strongly coupled setup. We saw that this works rather well in
many cases. In the case of observables at zero chemical potential, one
can obtain qualitatively reasonable results which match results from
lattice QCD, in which case holography can be used to try to understand
the mechanisms behind those phenomena seen on the lattice. In the case
of finite chemical potential, one can use holography in a regime where
no results from other strongly coupled methods exist. This also gives
qualitatively reasonable results, which do not directly contradict known
experimental results. In this chapter, we will briefly summarize the
main results, and provide an outlook for how the work in this thesis
could be improved or extended in the future.

### 5.1 (Inverse) magnetic catalysis in holographic QCD

In chapter 2 , we studied the V-QCD model in the presence of a magnetic
field @xmath and anisotropy @xmath , which could be either parallel or
perpendicular to @xmath . This model is constructed such that it matches
qualitative features of QCD, like the running of certain coupling
constants in the UV, glueball spectra, and the phase structure at finite
temperature. In particular, V-QCD displays confinement and spontaneous
chiral symmetry breaking at low temperatures, while these features are
lacking at high temperatures. This makes V-QCD a good tool to study the
behavior of the chiral condensate associated to chiral symmetry breaking
in the presence of a magnetic field. At zero temperature in a
perturbative setting, one expects the chiral condensate to increase as a
function of @xmath . However, in lattice QCD studies, the opposite
effect was seen, called inverse magnetic catalysis.

In section 2.2 , we saw that with a judicious choice of the parameter
@xmath occuring in the @xmath -potential of V-QCD, it is possible to
obtain the same behavior of the chiral condensate as seen on the
lattice. Indeed, we saw that at small temperatures, the condensate
increases as a function of @xmath , whereas in a region between the
chiral phase transition and the deconfinement transition, the condensate
decreases as a function of @xmath . We also saw that at larger values of
@xmath , eventually inverse magnetic catalysis disappears, and the
condensate starts increasing again. Furthermore, we were able to
identify two competing effects, namely a direct effect of @xmath on the
condensate which tends to increase the condensate, and an indirect
effect which tends to decrease it. This was in agreement with earlier
studies on the lattice.

We subsequently extended the analysis to include a finite baryon
chemical potential @xmath in section 2.3 . In this region of the phase
diagram, lattice QCD is affected by the sign problem. In holography,
however, there are no major technical issues preventing us from
exploring this region. We found that the region of chirally broken
deconfined plasma which exists at zero @xmath extends in seze at finite
@xmath , particularly at large values of the chemical potential. In
contrast, in the region between the chiral transition and the
deconfinement transition, the condensate decreases as seen earlier in
section 2.2 , but now we can also conclude that this region of inverse
magnetic catalysis only extends to a finite @xmath , after which the
region of inverse magnetic catalysis disappears.

Section 2.4 explores a different approach, by adding an anisotropy
@xmath , which is dual to a space-dependent theta term. This way we can
examine the effects that anisotropy has on QCD, without that anisotropy
being a magnetic field. In other words, we can investigate whether the
effects that a magnetic field has on the plasma are due to the magnetic
field specifically, or whether they apply more generally for other
sources of anisotropy. We saw several interesting effects. The chiral
condensate behaved in much the same way as it did in the presence of a
magnetic field, giving evidence for the conjecture first proposed in [
112 ] that inverse magnetic catalysis is caused by the anisotropy
induced by the magnetic field. We named this conjectured effect ‘inverse
anisotropic catalysis’.

Finally in section 2.5 , we explored the interplay between a magnetic
field @xmath and anisotropy @xmath , where we considered both the @xmath
and @xmath cases. We find that the presence of @xmath seems to
effectively decrease the value of @xmath , especially for the parallel
case. We also see that the chiral transition temperature for @xmath
seems to cross that of @xmath roughly where @xmath .

In the future it would be very interesting to determine whether it is
possible to find an explanation for the observed behavior in section 2.5
. Another interesting avenue of research would be to see if other
sources of anisotropy can be added to lattice studies, thereby testing
the conjecture of ‘inverse anisotropic catalysis’. Additionally, the
holographic model itself can be improved. For the studies presented in
this thesis, the quark flavors are assumed to all be identical. In
particular, the baryon number is assumed to be equal to the electric
charge. In the future, one could attempt to couple the magnetic field to
the quarks in a different way for different flavors, thereby getting
closer to a model for QCD. This is however likely a very challenging
extension. A future study which is simpler to achieve is to use the
existing model to study transport coefficients in the presence of a
magnetic field. In [ 120 , 145 ] , the complete set of hydrodynamic
transport coefficients for relativistic magnetohydrodynamics was derived
to first order, but the values that these coefficients take are
model-dependent. In principle, by studying perturbations around the
background space-times constructed in section 2.1 , one can derive the
values for the transport coefficients in V-QCD.

### 5.2 Holographic baryons and neutron stars

In neutron star physics, one of the most basic questions is one of the
biggest question marks. This question is what the neutron star equation
of state is. The equation of state governs observables like the maximum
possible mass of a neutron star, the mass to radius relation and tidal
deformability, and the post-merger spectrum of a binary neutron star
merger. On the other hand the answer to the question what the equation
of state is would give us valuable information about QCD, including
potentially the density at which a phase transition to deconfined matter
occurs. Many models exist which derive an equation of state, but none so
far have used explicitly strongly coupled methods. For this reason, in
chapter 3 , we used holography to study the equation of state and the
resulting model for neutron stars.

In the Witten-Sakai-Sugimoto model, several approximations exist to
incorporate baryons into the holographic model. In section 3.1 , we
adapted one such approximation into V-QCD. As it turns out, this gives a
qualitatively reasonable phase diagram, with baryons condensing in the
region in the phase diagram where one would expect this to happen. We
also saw that the distance into the holographic direction where the
baryons are located is @xmath , giving confidence that indeed the
approximation is reasonable. Looking at the zero temperature equation of
state itself, we see that it exceeds the conformal value for the speed
of sound in two places, a feature that is difficult to obtain in weakly
coupled theories. This lends confidence to the idea that the assumption
of strong coupling leads to genuinely different predictions for the
equation of state as compared to weak coupling.

In section 3.2 , we used the speed of sound of the resulting equation of
state, and used it as the high-density part of a hybrid equation of
state, the low density part coming from the SLy equation of state. This
hybrid equation of state was shown to be compatible with currently
existing constraints, including the maximum mass, mass to radius
relation, and tidal deformability. Subsequently a merger simulation
using the hybrid equation of state was shown, which included an example
of phase transition induced collapse. We also examined the post-merger
spectrum, finding a value for the frequency @xmath which is compatible
with a universal relation, and a value for @xmath which shifts to lower
frequencies as the hybrid equation of state is changed to incorporate
the holographic part of the equation of state up to lower densities.

There are many opportunities in the future to improve the analysis from
chapter 3 . One example is ongoing work to repeat the analysis for
different choices of potentials for V-QCD, where the potentials are
taken from [ 162 ] . This analysis will also include different choices
for the part of the equation of state used for the low-density part.
Another extension already being done is to extend the analysis to the
presence of a magnetic field, to see whether the equation of state
changes as a function of @xmath . Further in the future, it is important
to investigate how good the various approximations made in section 3.1
are and, where possible, to improve them. This will likely be a large
effort, but this is worth doing if it increases the reliability of the
results. The merger simulation can also be improved, for example by
including neutrinos and increasing the resolution. One particular effect
which is very important for the outcome of a merger simulation is the
temperature dependence of the equation of state. This is hard to do in
bottom-up holographic models such as V-QCD since this requires stringy
corrections, which are hard to obtain in a bottom-up model. It may be
possible though to obtain a reasonable approximation, which can then be
used in a merger simulation.

### 5.3 Simulation of heavy ion collisions with Trajectum

In chapter 4 , the new Trajectum framework was introduce, which provides
a consistent interface between the various components necessary to
simulate heavy ion collisions. This framework consists of two
executables, collide and analyze , to simulate collisions and to analyze
the result, respectively. Also, several examples of components which fit
into the Trajectum framework. Most of these are reimplementations of
existing models, but some have been modified in non-trivial ways. The
aim of these extensions is to incorporate results from AdS/CFT, such as
the way the fluid should be initialized at the start of the
hydrodynamical evolution. Subsequently, a Bayesian analysis will be
performed to attempt to infer whether experimental data shows a
preference for AdS/CFT, or whether it points into another direction.

We then tested the code using the maximum a posteriori (MAP) values
obtained from a Bayesian analysis in [ 54 ] . This yielded excellent
agreement. We also added new observables, which were not used in the
analysis of [ 54 ] . This therefore potentially adds new constraints to
the Bayesian analysis to be performed, which can then be used to learn
something about the various parameters used in the simulation in collide
.

In the future, there are several ways in which Trajectum can be
improved. An interesting option is to include thermal photon emission by
the fluid. This could give interesting new constraints, as it is
directly sensitive to fluid quantities in the center of the collision,
in contrast to the quantities we are using now, which are all produced
at the edge of the quark-gluon plasma. Other obvious extensions are to
extend the code to optionally work in @xmath D, which provides a better
physical description of the collisions, as well as adding conserved
quantities other than the stress-energy tensor. The latter include
baryon number density and electric charge. With the inclusion of
electric charge, it would also become possible to further extend the
hydrodynamics into full magnetohydrodynamics, which could be used for
various interesting problems [ 134 , 133 , 157 ] . A final interesting
possibility is to include critical fluctuations which occur around a
potential critical point [ 181 , 219 ] . This would allow us to study
what the effect of a critical point on observables is, and these
observables could then also be used in a future Bayesian analysis.

Throughout these chapters, the overarching theme has been that
holography can be used as a tool to gain qualitative insight into
strongly coupled theories such as QCD. This results both in new
explanations of existing observations and in new qualitative predictions
in areas where holography is so far the only way to gain insight in an
explicitly strongly coupled setting. Furthermore, by simulating neutron
star mergers and heavy ion collisions, the ideas coming from holography
can be compared to experimental observations. All of these avenues taken
together have taught us a lot about strongly coupled physics, and will
surely teach us much more in the future.

## Acknowledgements

First of all, I would like to thank my supervisors, Raimond and Umut,
for hiring me and giving me this great opportunity to conduct research
in so many different areas. You have both helped a lot whenever I was
stuck at something, provided interesting projects, but you also allowed
me to work in other collaborations, something I’ve learned a lot from.
You’ve also always been encouraging to go to conferences and summer
schools to present our work and learn new things.

My supervisors were not the only people I have had the pleasure to work
with during my time as a PhD. Therefore I would also like to thank my
other collaborators, Ioannis, Matti, Juan, Takaaki, Christian and Wilke.
Without you, the work presented in this thesis could not have been done.

I would also like to thank my officemates, Bernardo and Sonja, for
insightful discussions both within and outside physics. I’ve had a good
time in our office the past four years, and I think that you’ve always
made sure there is a good atmosphere inside the office.

Also the entire string group has been great to discuss both physics and
non-physics related topics with, so I’d like to give thanks to Brice,
Chongchuo, Chris, Damian, Domingo, Eric, Huibert, Kilian, Koen, Miguel,
Natale, Nava, Phil, Pierre, Ronnie, Sebastian, Stefan and Thomas.

Moving outside of physics itself, I would like to thank my two
paranymphs, Lotte and Stephanie, both for the support they’ve given me
during the writing of this thesis, and for the invaluable support they
will give me during the promotion ceremony itself. Of my two paranymphs,
I would like to especially thank my girlfriend Lotte, who has supported
me throughout my time as a PhD. She has encouraged me to never give up
when things went less well, and I thank her enormously for her support.

Also my parents plus their spouses, Annelies, Arie, Jacobien and
Eveline, I would like to thank for their support. In addition, I’d like
to thank the rest of my family, my in-laws, and my friends in Ceros,
USBC and SUF. Lastly, let me thank two very special friends that Lotte
and I have made, namely Domingo and Danna. We have both very much
enjoyed our dinner and board game evenings together, and we hope to come
and visit you in your new home.

## Samenvatting

In dit proefschrift wordt QCD bestudeerd uit drie verschillende
richtingen, met één overkoepelend thema: holografie. De holografische
dualiteit maakt dat sommige sterk gekoppelde kwantumveldentheoriën
beschreven kunnen worden in termen van veel eenvoudigere klassieke
zwaartekracht in één dimensie extra. De eerste richting van waaruit QCD
bestudeerd wordt in dit proefschrift is door de effecten van een extern
magnetisch veld op een specifiek holografisch model van QCD te
bestuderen, wat interessant kwalitatief inzicht geeft. De tweede
richting bestudeert hoe, in hetzelfde model, het mogelijk is om
baryonische configuraties met grote dichtheid te beschrijven, wat een
nieuwe manier oplevert om de materie te bestuderen waar neutronensterren
uit bestaan. De toestandsvergelijking die op deze manier verkregen wordt
wordt vervolgens inderdaad gebruikt om verscheidene eigenschappen van
neutronensterren te berekenen die geobserveerd kunnen worden, of
geobserveerd zullen kunnen worden in de nabije toekomst. De laatste
richting bevat op zichzelf geen holografische berekeningen, maar bevat
wel verscheidene kwalitatieve inzichten vanuit holografie die worden
toegepast in een nieuwe zware-ionen code genaamd Trajectum . Dit zal in
de nabije toekomst gebruikt worden om een Bayesiaanse analyse te doen,
waar gehoopt wordt dat deze kwalitatieve inzichten uit holografie getest
kunnen worden op experimentele data, om te zien hoe goed de ideeën uit
holografie met het experiment in overeenstemming zijn.

## Appendix A V-QCD potentials

In this appendix, we discuss the potentials which appear in the V-QCD
action defined by ( 1.11 ) and ( 1.12 ). Furthermore, we will discuss
the various constants [ 20 ] which appear in the near-boundary
expansions discussed in 2.1.2 . First, we will discuss some general
statements which apply to both of the sets of potentials that will be
considered here, before moving on two the two specific cases used in
chapters 2 and 3 .

In V-QCD, there are 5 potentials which enter the action, namely @xmath ,
@xmath , @xmath , @xmath and @xmath . Firstly, let us restrict ourselves
to @xmath of the form

  -- -------- --
     @xmath   
  -- -------- --

Using this, we then define

  -- -------- --
     @xmath   
  -- -------- --

and we obtain the following expansion:

  -- -------- --
     @xmath   
  -- -------- --

which defines the constants @xmath , @xmath and @xmath . In terms of
these constants, one can also define

  -- -------- --
     @xmath   
  -- -------- --

Another expansion we can obtain is:

  -- -- --
        
  -- -- --

from which we can obtain

  -- -------- --
     @xmath   
  -- -------- --

For both of the sets of potentials considered below, we will have

  -- -------- --
     @xmath   
  -- -------- --

which matches the perturbative QCD beta function, as well as the
perturbative anomalous dimension of the quark mass in QCD. Since the
potentials from section A.2 are only meant to be used for @xmath , these
potentials only satisfy these properties at this precise value of @xmath
.

### a.1 Inverse magnetic catalysis

In chapter 2 , we use the following potentials [ 20 , 19 , 130 , 131 ] :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

and @xmath is a free constant which has different values in different
parts of chapter 2 .

### a.2 Baryons

In chapter 3 , we use the potential which were fitted to lattice data in
[ 162 ] . In particular, we use potentials 7a, where the notation ‘7a’
follows [ 162 ] . As we will not use the @xmath potential in chapter 3 ,
we will also not define it. The potentials are: ¹ ¹ 1 Note that there is
a factor @xmath difference in the definition of @xmath with respect to [
162 ] .

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Compared to the potentials from appendix A.1 , @xmath , @xmath and
@xmath are unchanged, provided we compare at @xmath . However, we have

  -- -------- --
     @xmath   
  -- -------- --

These potentials will be used in a setting where the planck mass @xmath
enters non-trivially into the computation through ( 3.17 ). For these
potentials, we have

  -- -------- --
     @xmath   
  -- -------- --