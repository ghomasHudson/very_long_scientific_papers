##### Contents

-    1 Introduction
-    2 Introduction to game theory
    -    2.1 History
    -    2.2 Fundamental concepts
    -    2.3 Examples of games
        -    2.3.1 Prisoners’ Dilemma
        -    2.3.2 Matching Pennies
        -    2.3.3 Model of Entry
-    3 Quantum mechanics
    -    3.1 Mathematical preliminaries
    -    3.2 Tensor products
    -    3.3 The qubit
    -    3.4 Postulates of quantum mechanics
    -    3.5 Einstein-Podolsky-Rosen paradox
    -    3.6 Quantum entanglement
        -    3.6.1 Entanglement in @xmath systems
    -    3.7 Bell’s inequality
        -    3.7.1 Violation of Bell’s inequality
        -    3.7.2 Local realism and the violation of Bell’s inequality
-    4 Quantum games
    -    4.1 Introduction
    -    4.2 Earlier works
    -    4.3 Quantum penny-flip game
    -    4.4 Quantum Prisoners’ Dilemma
    -    4.5 Review of recent literature
        -    4.5.1 Specially-designed games
        -    4.5.2 Quantum games based on Eisert et al.’s formalism
        -    4.5.3 Related work
    -    4.6 Criticism of quantum games
        -    4.6.1 Enk’s comment on quantum penny-flip game
        -    4.6.2 Criticism of Eisert et al.’s quantum Prisoners’
            Dilemma
-    5 Quantum correlation games
    -    5.1 Introduction
    -    5.2 Matrix games and payoffs
    -    5.3 EPR-type setting of matrix games
    -    5.4 Correlation games
        -    5.4.1 Classical correlation games
        -    5.4.2 Quantum correlation games
    -    5.5 Nash equilibria of quantum correlation games
    -    5.6 Discussion
-    6 Hidden variables and negative probabilities in quantum games
    -    6.1 Introduction
    -    6.2 Physical implementation of playing a two-player game
    -    6.3 Two-player games with four coins
    -    6.4 Games with perfectly correlated particles
-    7 Summary and Future Perspectives

Dedication

Dedicated to my wife Ayesha whose encouragement and support was
essential in the writing of this thesis.

    

The research presented in this thesis is drawn from the following
publications:

-   Azhar Iqbal and Stefan Weigert, Quantum correlation games. J. Phys.
    A: Math. Gen. 37, 5873-5885 (2004).

-   Azhar Iqbal, Playing games with EPR-type experiments. J. Phys. A:
    Math. Gen. 38, 9551-9564 (2005).

## Chapter 1 Introduction

Information processing [ 1 ] has been traditionally considered a purely
mathematical task that is independent of the carriers of the
information. This view underwent dramatic revision and change in the
1990s with the finding that highly efficient ways of processing exist
for certain problems if information is stored and processed quantum
mechanically. Identifying a marked object in a database [ 2 ] and
factorization of large integer numbers [ 3 ] were recognized to have
more efficient solutions than are possible classically. This finding
gave birth to the new field of quantum information and computation [ 4 ,
5 ] , in which classical bits are generalized to qubits which allow
linear combination of classically incompatible states. the use of qubits
as carriers makes possible much faster processing of information, at
least for certain problems.

In contrast to the recently developed studies of quantum information and
computation, game theory [ 6 , 7 ] is an established branch of
mathematics which helps players participating in games to take decisions
rationally. The finding that information theory can benefit from a
quantum-mechanical implementation has motivated the proposal [ 8 , 9 ]
that game theory is another promising candidate to gain a similar
benefit. The roots of this suggestion can perhaps be traced back to the
understanding that information is a central element of any game. The
outcome of a game is often decided by what (and how much) information
players possess at different times during the course of playing the
game. With information given a central place in the playing of a game,
the possibility of efficient information processing has consequences for
the solutions of the game when it is played using qubits. That is, the
solutions/outcomes of a game are dependent on the nature of the physical
objects used in its playing.

Players playing classical games share coins or dice and select from a
set of available strategies by performing moves, or actions, on the
coins or dice. Rational players select strategies that maximize their
payoffs. Using this analogy, the players in a quantum game are endowed
with the capacity to make quantum mechanical moves, or actions, on the
qubits which they share.

The following are some of the stated reasons [ 9 ] why it is interesting
to play games in quantum regime:

-   Game theory involves concepts and methods of probability theory [ 10
    ] to analyze games, in the process of finding their solutions.
    Playing quantum games provides an opportunity to generalize
    conventional probability to quantum probability [ 11 ] .

-   Playing games has an intimate connection with quantum communication
    concepts [ 12 ] . For example, the quantum-mechanical protocols for
    eavesdropping [ 13 , 14 ] and optimal cloning [ 15 ] can readily be
    formulated as games between players.

-   It is possible to re-formulate certain quantum algorithms as games
    between classical and quantum players [ 16 ] . Because only a few
    quantum algorithms are known to date, it has been suggested that
    quantum games may shed new light on the working of quantum
    algorithms, possibly helping to find new ones.

-   Quantum mechanics has been shown to assure fairness in remote
    gambling [ 17 ] . Gambling and playing games are related, thus
    making quantum mechanics relevant for the latter.

-   Molecular level interactions are dictated by quantum mechanics. If
    Dawkins’ dictum of the ‘Selfish Gene’ [ 18 ] is a reality then the
    games of survival are already being played in such interactions.
    Quantum mechanics naturally becomes relevant for those games.

-   It has been suggested [ 19 ] that games can provide a useful set of
    tools in giving a semantics to quantum logic and can be brought to
    bear on questions concerning the interpretation and the nature of
    the concept of uncertainty in the foundations of quantum theory.

Research in quantum games has seen noticeable growth [ 20 ] during
recent years. Though game-like descriptions of surprising
quantum-mechanical situations can be found in the literature dating back
many decades ¹ ¹ 1 Refer to the literature review of quantum games in
the Section ( @xmath ). , quantum games emerged as a new field of
research with Meyer’s publication of a quantum penny-flip game [ 8 ] .
Meyer’s game demonstrated the advantage that quantum strategies can
attain over classical ones. Shortly afterwards, Eisert et al. [ 9 ] put
forward a quantum version of the well-known game of Prisoners’ Dilemma.
Other suggestions and schemes include a proposal for multi-player
quantum games [ 21 ] , the quantization of Battle of Sexes [ 22 ] , a
study of evolutionary stability in quantum games [ 23 ] , the
experimental realization of quantum games on a quantum computer [ 24 ] ,
the quantum Monty Hall problem [ 25 ] , the quantum Parrondo’s game [ 26
] and a discussion of quantum advantage in the presence of a corrupt
source [ 27 ] . The list is by no means exhaustive and can easily be
extended considerably by a more detailed literature review. However, it
demonstrates the rapidly growing research interest in the new field.

There have been many developments in quantum games during recent years [
20 ] but opinion remains divided [ 28 , 29 , 30 , 31 , 32 ] about their
‘true’ quantum character. For example, one argument [ 32 ] considers
quantum games only as ‘disguised’ classical games. The argument says
that to quantize a game is equivalent to replacing the original game by
a different classical game.

The present thesis defends quantum games by presenting a reply to the
criticisms surrounding this emerging field. It is argued that the
possibility of constructing a classical game which is able to reproduce
the overall effect of a quantum game cannot be used to deny the quantum
content [ 28 ] of quantum games. The question which quantum game theory
asks is how the quantum aspects of distributed physical systems which
are used to physically implement games can leave their mark on
game-theoretical solutions. The possibility of classical constructions
which can describe the overall situation of quantum games does not make
the question disappear.

The Einstein-Podolsky-Rosen (EPR) paradox [ 33 ] is widely believed to
provide an example of a phenomenon having a truly quantum character and
content. The paradox involves two spatially-separated observers making
local measurements on singlet states. The paradox motivated the EPR
experiments [ 33 , 34 , 37 , 38 ] whose set-up provides an almost
natural arrangement for playing two-player games. This thesis argues
that questions about the quantum content of quantum games can be
addressed by using the EPR-type experiments to play two-player games.
The thesis puts forward two proposals to play quantum games. In both the
proposals the set-up of EPR-type experiments is used in playing
two-player games.

In the first proposal, a two-player classical game is firstly
re-expressed in terms of EPR-type experiments, when they are performed
on classical, but anti-correlated, pairs of particles [ 39 ] . In the
next step the experiments are performed using anti-correlated quantum
mechanical pairs of particles. The resulting effects on the players’
payoff functions, and on the solutions of the game, are then explored in
relation to the quantum correlations existing between the parts of the
pairs used in the experiments.

The second proposal follows a different line and is based on the
analysis of probabilities involved in a simple two-player game, written
as a bimatrix, when it is physically implemented by tossing four biased
coins. In each turn both players receive two coins; selecting one coin
to toss is a player’s strategy. Players’ payoffs are obtained after
repeating the tosses in large number. The construction allows us to
consider the impact on the solutions of the game of the feature that
certain probability measures can assume negative values [ 40 , 41 ] .
Essentially, the motivation of the argument arises from the recent
results [ 42 , 43 , 44 ] reporting that the requirement that certain
hidden variable models should predict the outcomes of EPR-type
experiments forces the conclusion that some of the involved probability
measures must have negative values. In this approach, for obvious
reasons, it is required that the existence of a hidden variable model
leading to positive-definite probabilities [ 42 ] always result in the
corresponding classical game.

The concluding chapter summarizes the results and suggests future
directions of research.

## Chapter 2 Introduction to game theory

Game theory [ 6 , 7 ] is an established discipline of mathematics. It is
a vast subject having a rich history and content. Only recently have its
concepts and methods been brought into the realm of quantum mechanics,
thus giving rise to the new field of quantum games. In the following
review some of the fundamental concepts are described. The review is not
meant to be an exhaustive introduction to the field of game theory; a
selection of topics from the theory is made in order to serve as a
background for later chapters of this thesis.

### 2.1 History

Games such as chess, warfare and politics have been played throughout
history. Whenever individuals meet who have conflicting desires and
priorities then games are likely to be played. The analysis and
understanding of games has existed for a long time but the emergence of
game theory as a formal study of games is a relatively recent event.
Roughly speaking, game theory is the analysis of rational behavior when
participants’ actions are strategically interdependent and when a
participant’s strategy depends on what his opponents do. This situation
appears quite similar to the typical scenario in decision theory [ 45 ]
. There is a difference, however. A decision maker in decision theory
chooses among a set of alternatives in the light of their possible
consequences, whereas decisions in game theory are made in an
environment where various players interact strategically.

The roots of game theory, as a formal discipline, can be traced back to
the year 1713 when James Waldegrave and Pierre-Rémond de Montmort [ 46 ]
provided the first known minimax mixed strategy solution to a two-player
game. During the 1920s Émile Borel made investigations on strategic
games and defined what is known as the normal form of a game. It is a
matrix representation of a game in which a player can work out the best
strategy without considering the sequence of moves.

In 1928 John von Neumann [ 47 ] gave the first formal proof of the
minimax theorem for two-player games. Essentially, the theorem states
that for each player in a zero-sum game a unique mixed strategy exists
such that payoffs are equalized regardless of the other player’s
actions. In 1944 Neumann and Morgenstern [ 6 ] published their
pioneering book “The Theory of Games and Economic Behaviour”. As well as
expounding two-person zero-sum games this book is considered the seminal
work in cooperative games. The book presented the account of axiomatic
utility that led to its widespread adoption within economics. The book
established game theory as a field of investigation in economics and
mathematics.

Minimax theory finds the best strategy for a player in a zero-sum game,
independently of the strategies played by other players. Most often a
player’s best strategy does depend on what strategies the other players
play. In 1950 John Nash [ 48 ] extended the minimax theory to @xmath
-player noncooperative games and introduced the concept of a Nash
equilibrium [ 49 ] . The Nash equilibrium theory states that a set of
strategies can be found such that no player is left with a motivation to
deviate unilaterally from it.

The 1970s saw game theory being successfully applied to problems of
evolutionary biology. The concept of utility from economics was given an
interpretation in terms of Darwinian fitness. Players were dissociated
from their capacity to act rationally and the concept of evolutionary
stability was born. In 1973 John Maynard Smith and G. R. Price [ 50 ]
introduced the concept of evolutionarily stable strategy [ 51 ] as a
strategy that cannot be invaded if a population adapts it.

During recent times, Reinhard Selten further refined the concept of a
Nash equilibrium with his concept of trembling hand perfect and subgame
perfect equilibria. Also, John Harsanyi developed the analysis of games
with incomplete information. In 1994, John Nash, Reinhard Selten and
John Harsanyi [ 52 ] won the Nobel Prize [ 53 ] in Economics for their
work on game theory.

### 2.2 Fundamental concepts

To describe a situation in which decision-makers interact we need to
specify who the decision-makers are, what each decision-maker can do, as
well as each decision-maker’s payoff from each possible outcome. A game
consists of a set of players , a set of actions (sometimes called
strategies ) for each player, and a payoff function that gives the
player’s payoff to each list of the players’ possible actions. An
essential feature of this definition is that each player’s payoff
depends on the list of all the other players’ actions. In particular, a
player’s payoff does not depend only on her own action.

There are two distinct but related ways of describing a game
mathematically. The first one is known as the normal or strategic form
which is representation of a game consisting of

-   A finite set of players: @xmath

-   Strategy spaces of players, denoted by @xmath etc.

-   Payoff functions of players. For example for the player it is the
    function @xmath

A strategy is a complete plan of action for every stage of the game,
regardless of whether that stage actually arises in play. Each player is
given a set of strategies. A strategy space for a player is the set of
all strategies available to that player. A pure strategy refers to a
situation when a player chooses to take one action with probability
@xmath . A mixed strategy describes a strategy involving a probability
distribution which corresponds to how frequently each move is chosen.
For example, a mixed strategy of player @xmath is a convex combination
of pure strategies:

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath are @xmath ’s pure strategies and @xmath are real constants
with @xmath . A totally mixed strategy is a mixed strategy in which the
player assigns strictly positive probability to every pure strategy. The
concept of strategy is sometimes (wrongly) confused with that of a move
. A move is an action taken by a player during some moment in a game
(e.g., in chess, moving white’s Bishop from a2 to b3). A strategy on the
other hand is a complete algorithm for playing the game, implicitly
listing all moves and counter-moves for every possible situation
throughout the game.

An extensive form of a game specifies the players of a game, every
opportunity each player has to move, what each player can do at each
move, what each player knows for every move, and the payoffs received by
every player for every possible combination of moves. In comparison to
the normal form, the extensive form of a game captures the order of play
and reveals how equilibria are determined. The extensive form is the
most detailed way of describing a game. A game tree represents a game in
such a way that each node (called a decision node ) represents every
possible stage of the game as it is played.

A payoff function for a player is a mapping from the cross-product of
players’ strategy spaces to the player’s set of payoffs, which is
normally within the set of real numbers.

A game is zero-sum if the total payoff to all players in the game, for
every combination of strategies, always adds up to zero. That is, a
player gains only at the expense of others. Two-person zero-sum games
are sometimes called strictly competitive games. A game is non-zero-sum
when gain by one player does not necessarily correspond to a loss by
another.

A payoff matrix for a two-player game is an @xmath matrix of real
numbers:

  -- -- -- -------
           (2.2)
  -- -- -- -------

The matrix shows what payoff each player will receive at the outcome of
the game. The payoff for each player depends, of course, on the combined
actions of both players. In the matrix ( 2.2 ) player @xmath ’s
strategies are designated down the left hand column and player @xmath ’s
strategies are designated along the top row.

A cooperative game is a game in which two or more players do not compete
but rather strive toward a unique objective and therefore win or lose as
a group. In a non-cooperative game no outside authority assures that
players stick to the same predetermined rules, and so binding agreements
are not feasible. In these games players may cooperate but any
cooperation must be self-enforcing. In a game of complete information
the knowledge about other players is available to all participants i.e.
every player knows the payoff functions and the strategies available to
other players.

Best response is any strategy that yields the highest possible payoff in
response to the strategy of other players. Dominant strategy equilibrium
is a strategy profile in which each player plays best-response that does
not depend on the strategies of other players.

In a zero-sum game between players @xmath and @xmath player @xmath
should attempt to minimize player @xmath ’s maximum payoff while player
@xmath attempts to maximize his own minimum payoff. When they do so a
surprising conclusion comes out i.e. the minimum of the maximum
(mini-max) payoffs equals the maximum of the minimum (max-min) payoffs.
Neither player can improve his position, and so these strategies form an
equilibrium of the game.

The minimax theorem states that for every two-person, zero-sum game,
there always exists a mixed strategy for each player such that the
expected payoff for one player is the same as the expected cost for the
other. In other words, there is always a rational solution to a
precisely defined conflict between two people whose interests are
completely opposite. It is a rational solution in that both parties can
convince themselves that they cannot expect to do any better, given the
nature of the conflict.

Now consider a game in which each player chooses the action that is best
for her, given her beliefs about the other players’ actions. How do
players form beliefs about each other? We consider here the case in
which every player is experienced i.e. she has played the game so many
times that she knows the actions the other players will choose. Thus we
assume that every player’s belief about the other players’ actions is
correct. The notion of equilibrium that embodies these two principles is
called a Nash equilibrium [ 48 , 49 ] (after John Nash, who suggested it
in the early 1950s).

For a Nash equilibrium we need the concept of a strategy profile . It is
a set of strategies for each player which fully specifies all the
actions in a game. A strategy profile must include one and only one
strategy for every player. For example, @xmath is a strategy profile for
a three-player game in which @xmath and @xmath are strategies for the
players @xmath and @xmath , respectively. The payoff to player @xmath ,
with this strategy profile, is denoted by @xmath .

Consider a set of players @xmath playing a game. A strategy profile
@xmath is said to be a Nash equilibrium if and only if for any player
@xmath we have

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

for all @xmath and @xmath etc. In other words, a Nash equilibrium is a
strategy profile such that no player has an incentive to unilaterally
change her action. Players are in equilibrium if a change in strategy by
any one of them would lead that player to earn less than if she remained
with her current strategy. Note that nothing in the definition suggests
that a strategic game necessarily has a Nash equilibrium or that, if it
does, it has only a single Nash equilibrium. A strategic game may have
no Nash equilibrium, may have a single Nash equilibrium, or may have
many Nash equilibria. A strategy profile is a strict Nash equilibrium if
for it the inequalities ( 2.3 ) hold strictly. An outcome of a game is
Pareto optimal [ 7 ] if there is no other outcome that makes every
player at least as well off and at least one player strictly better off.
That is, a Pareto optimal outcome cannot be improved upon without
hurting at least one player. Often, a Nash equilibrium is not Pareto
optimal, implying that the players’ payoffs can all be increased.

### 2.3 Examples of games

In the following sections three games and their solutions are given. Two
of the games, Prisoners’ Dilemma and Matching Pennies, are selected
because the earliest proposals [ 8 , 9 ] of quantization were made for
those games. In both of these games players’ moves are performed
simultaneously and they belong to the class of non-cooperative games.
The third game, Model of Entry, has a somewhat different information
structure, with players’ making sequential moves, which is reminiscent
of what happens in the game of chess.

#### 2.3.1 Prisoners’ Dilemma

Prisoners’ Dilemma [ 7 ] is a widely known noncooperative game. Its name
comes from the following situation: two criminals are arrested after
having committed a crime together. Each suspect is placed in a separate
cell and may choose between two strategies, namely confessing @xmath and
not confessing @xmath , where @xmath and @xmath stand for cooperation
and defection. If neither suspect confesses, i.e. @xmath , they go free;
this is represented by @xmath units of payoff for each suspect. When one
prisoner confesses ( @xmath ) and the other does not @xmath , the
prisoner who confesses gets @xmath units of payoff, while the prisoner
who did not confess gets @xmath , represented by his ending up in the
prison. When both prisoners confess, i.e. @xmath , both are given a
reduced term, but both are convicted, which we represent by giving each
@xmath unit of payoff, better than getting @xmath if the other prisoner
confesses, but not so good as going free i.e. a payoff of @xmath . The
game has the normal-form representation:

  -- -- -- -------
           (2.4)
  -- -- -- -------

where Alice and Bob are the prisoners and the first and the second
entries in parentheses correspond to Alice’s and Bob’s payoff,
respectively. The origin of the dilemma stems from the fact that for
either choice of the opponent it is advantageous to defect @xmath . But
when both defect, i.e. @xmath , the payoff remains less than in the case
when both cooperate @xmath . In its generalized form the PD is
represented as:

  -- -- -- -------
           (2.5)
  -- -- -- -------

where @xmath . PD has @xmath as the pure-strategy equilibrium.

#### 2.3.2 Matching Pennies

Player @xmath chooses “heads” @xmath or “tails” @xmath . Without knowing
player @xmath ’s choice, player @xmath also chooses “heads” or “tails”.
If the two choices are alike, then player @xmath wins a penny from
player @xmath ; otherwise, player @xmath wins a penny from player @xmath
. The normal form of this game is the matrix

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

where each row represents player @xmath ’s strategy, and each column a
strategy of player @xmath . Fig. ( @xmath - @xmath ) shows the game tree
of this game with terminal vertices representing the players’ payoffs.

[]

Figure @xmath - @xmath : Game tree of Matching Pennies. The terminal
vertices represent the players’ payoffs.

The game has no pure strategy equilibrium. To find the mixed strategy
equilibrium suppose @xmath and @xmath are the probabilities with which
players @xmath and @xmath play the strategy @xmath , respectively. Let
@xmath be an equilibrium:

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (2.7)
  -- -------- -------- -- -------

giving @xmath .

#### 2.3.3 Model of Entry

Firm @xmath is an incumbent monopolist in an industry. Firm @xmath has
the opportunity to enter the industry. After firm @xmath makes the
decision to enter, firm @xmath will have the chance to choose a pricing
strategy. It can choose either to Fight the entrant or to Accommodate it
with higher prices.

[]

Figure @xmath - @xmath : Game tree of Model of Entry.

Fig. ( @xmath - @xmath ) is the game tree for Model of Entry and its
normal form has the representation:

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

The game has two pure-strategy equilibria i.e. @xmath Fight, Out @xmath
and @xmath Accommodate, In @xmath .

## Chapter 3 Quantum mechanics

Being one of the pillars of modern physics, quantum mechanics [ 39 ] has
an impressive amount of supporting experiments, and many technological
applications are based on it. Quantum mechanics can be approached from
several directions and viewpoints. Below, some of the basic concepts and
definitions of quantum mechanics are described, to give a necessary
background for the topics in quantum games which are discussed in later
chapters of this thesis.

### 3.1 Mathematical preliminaries

The most popular approach uses the concept of a vector space . In Dirac
notation, a complex vector space is a set @xmath consisting of elements
of the form @xmath called kets. It is a set in which

-   A vector @xmath can be associated with each pair of vectors @xmath .
    This association satisfies the following axioms:

1.  For all @xmath we have @xmath

2.  There is a null vector @xmath such that @xmath for all @xmath

3.  For each @xmath there exists an inverse vector denoted by @xmath
    such that @xmath

4.  For all @xmath we have @xmath

-   A vector @xmath can be associated with each @xmath and @xmath ,
    where @xmath is the field of complex numbers. For all @xmath and
    @xmath this association satisfies the following axioms:

1.  @xmath

2.  @xmath

3.  @xmath

4.  @xmath

5.  @xmath

The vector space provides the arena for doing mathematical actions on
ket vectors. Its structure guarantees that such actions do not result in
yielding a ket that does not reside in the vector space under
consideration.

An operator @xmath maps each vector @xmath into another vector @xmath :

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

The operator @xmath is linear if, for any vectors @xmath and for any
@xmath , the property

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

is true. A spanning set for a vector space @xmath is a set of vectors
@xmath such that any vector @xmath in @xmath can be written as a linear
combination @xmath of vectors in that set. A set of vectors @xmath is
said to be linearly independent if the relation

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

holds if and only if @xmath . It can be shown that any two sets of
linearly independent vectors which span @xmath contain the same number
of elements. Such a set is called a basis for @xmath . The number of
elements in a basis is defined to be the dimension of @xmath .

To any vector @xmath a dual vector can be associated; this is written as
@xmath and is called a bra . The bra vector @xmath is a linear operator
from the vector space @xmath to the field @xmath , defined by @xmath .
For any @xmath the inner product @xmath is defined to be a complex
number with the following properties:

1.  @xmath where @xmath denotes complex conjugate

2.  @xmath where @xmath and @xmath

3.  @xmath for any @xmath , with equality if and only if @xmath is a
    zero vector

From these properties it follows that

  -- -- -- -------
           (3.4)
  -- -- -- -------

The norm of a vector @xmath is defined by

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

Any non-zero vector @xmath can be normalized by dividing it by its norm.
The normalized vector @xmath has unit norm and is therefore called a
unit vector . Vectors @xmath and @xmath are called orthogonal if their
inner product is zero. A vector space equipped with an inner product is
called an inner product space .

In quantum mechanics states of physical systems are represented by unit
vectors in Hilbert space . As is the case with quantum computation and
information [ 4 ] , the field of quantum games mostly deals with finite
dimensional complex vector spaces for which a Hilbert space becomes the
same as an inner product space.

Let @xmath @xmath be a basis for an @xmath -dimensional Hilbert space
@xmath . A vector @xmath in @xmath can be written as

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

where @xmath . Thus @xmath and we have the completeness relation

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

where @xmath is the identity operator defined by @xmath .

Let @xmath @xmath be a unit vector. An operator is called a projector if
it projects a vector @xmath along the direction @xmath . For example
@xmath is a one-dimensional projector that acts on the vector @xmath as
follows:

  -- -- -- -------
           (3.8)
  -- -- -- -------

From the definition it follows that @xmath .

Consider a linear operator @xmath that acts on a non-zero vector @xmath
such that

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

where @xmath and is called the eigenvalue of @xmath corresponding to the
eigenvector @xmath . Eq. ( 3.9 ) is called an eigenvalue equation . It
is found that an eigenvalue equation always has a solution.

For any linear operator @xmath on a Hilbert space @xmath a unique linear
operator @xmath on @xmath can be found which is called the adjoint or
Hermitian conjugate of @xmath . It is defined as follows. For any @xmath

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

from which it follows that @xmath . The operator @xmath is Hermitian or
self-adjoint if

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Consider the scalar product @xmath when @xmath is Hermitian. Because
@xmath so the eigenvalues of a Hermitian operator are real.

An important class of operators in Hilbert space consists of unitary
operators . An operator @xmath is unitary if

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

From this definition it follows that @xmath i.e. the adjoint of a
unitary operator is the same as its inverse. The action of unitary
operators in Hilbert space is similar to that of rotations in Euclidean
space; it preserves both the length of a vector and the angle between
two vectors. It can be seen by considering two vectors @xmath . Consider
the inner product

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

which in the case @xmath shows that a unitary operator does not change
the norm of a vector.

In quantum games three unitary and Hermitian operators @xmath and @xmath
are important. These are the Pauli matrices defined as follows:

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

The Pauli matrices have two well-known properties. The first property is
@xmath , where @xmath is the identity matrix. The second property is

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

### 3.2 Tensor products

Quantum mechanics offers the method of Tensor products [ 39 ] to combine
together two Hilbert spaces to form a bigger Hilbert space. It is an
important concept for the understanding of the multiparticle quantum
systems which are fundamental for playing quantum games. Quantum games
are most often played while players share multiparticle quantum systems.

Consider two Hilbert spaces @xmath and @xmath , having dimensions @xmath
and @xmath , respectively. The tensor product between these Hilbert
spaces is written as @xmath . The space @xmath is defined as follows.
Suppose @xmath and @xmath . These two vectors can be associated with a
vector @xmath which is the tensor product between the vectors @xmath and
@xmath . The product @xmath has the following properties:

a) For any @xmath , @xmath and @xmath

  -- -- -- --------
           (3.16)
  -- -- -- --------

b) For any @xmath and @xmath

  -- -- -- --------
           (3.17)
  -- -- -- --------

c) For any @xmath and @xmath

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

The tensor product @xmath is often simply written as @xmath .

### 3.3 The qubit

A system with two states is called a bit in classical information theory
[ 1 ] . These states are usually denoted by @xmath and @xmath . The name
qubit [ 39 ] comes from quantum bit and its role in quantum information
theory [ 54 , 4 ] is the same as that of the bit in classical
information theory [ 1 ] . A qubit is the simplest nontrivial quantum
system whose state can be described by a vector in two-dimensional
complex Hilbert space. An example of such a system is a spin- @xmath
particle, for instance the electron. Measurement of the @xmath
-component of its spin always gives either up or down ( @xmath ) as the
result. The state of the electron becomes an eigenstate of the
observable after the measurement. In binary notation the two eigenstates
can be denoted by @xmath and @xmath , representing spins parallel (
@xmath ) and anti-parallel ( @xmath ) to the @xmath -axis. These are
orthogonal states and are taken as the basis vectors of the
two-dimensional spin Hilbert space. A general spin state vector can be a
superposition of the eigenstates i.e.

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

where @xmath satisfy @xmath . For an electron in this state the outcomes
@xmath and @xmath appear with probabilities @xmath and @xmath ,
respectively, when the spin is measured along the @xmath -axis.

The state ( 3.19 ) is often represented as

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

where only the phase difference between @xmath and @xmath is considered
and @xmath is chosen real. For the range @xmath and @xmath of the
parameters the state ( 3.20 ) can describe any state of the qubit.
Although a qubit can exist in a continuum of superpositions between the
states @xmath and @xmath only a single bit of information can be
extracted from a single qubit. Apart from the spin- @xmath particles,
the polarization states of a photon and the energy levels of a two-level
system can also represent a qubit.

In quantum games the concept of qubit helps in finding a quantum version
of a classical game. It is because many, if not all, classical games can
be played when participating players share the carriers of classical
information, i.e. bits. Replacing bits with qubits, with players having
the capacity to do actions on their qubits, allows one to construct a
quantum version of the classical game.

Some classical games can be more easily played when players share dice
instead of coins. Likewise, for certain quantum games it is helpful if
they are played when players share higher-dimensional quantum systems.
For example, a quantum version of the two-player game of the rock,
scissors and paper can be more easily played [ 55 ] when the players
share two qutrits ( @xmath -dimensional quantum system), instead of two
qubits.

### 3.4 Postulates of quantum mechanics

The physical set-up for playing quantum games is a quantum mechanical
system. Like it is the case with usual quantum systems, the physical
set-up is assumed isolated from its surrounding environment with its
behaviour controlled externally. That is, the system is not disturbed by
events which are unrelated to the control procedures. In quantum
mechanics such a system can be modelled by the following postulates [ 54
, 39 ] .

##### Postulate I

A Hilbert space @xmath is associated with a quantum system. The system
is completely described by its state vector @xmath , which is a unit
vector in the system’s state space.

##### Postulate II

The evolution of an isolated quantum system is described by unitary
transformations . The states @xmath and @xmath of the system at times
@xmath and @xmath , respectively, are related by a unitary
transformation @xmath , which depends only on @xmath and @xmath , such
that @xmath .

##### Postulate III

A measurement of a quantum system consists of a set @xmath of linear
operators on @xmath , such that

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

The measurement results in one of the indices @xmath . If the system is
in the state @xmath then the probability that @xmath is observed is

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

If @xmath is observed then the state @xmath transforms to

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

It can be noticed from ( 3.21 ) that @xmath is a probability measure,
since

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

Postulate III relates to a generalized measurement. Usually the special
type of measurement is considered, for which @xmath is self-adjoint and
@xmath for all @xmath and @xmath for @xmath . Such measurement is called
the projective measurement . In the case of a projective measurement
there are mutually orthogonal subspaces @xmath of @xmath such that
@xmath and @xmath for some orthogonal basis @xmath of @xmath . Then
@xmath becomes a projection onto @xmath .

For an ensemble of quantum states @xmath the density operator [ 39 , 54
, 4 ] is defined as

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

where @xmath is the probability of finding the quantum system in state
@xmath . The ensemble evolves unitarily in time as

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

which is described by the following evolution of the density operator:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (3.27)
  -- -------- -------- -- --------

The expectation value of an operator @xmath , denoted by @xmath , gives
the average value of the physical observable @xmath as obtained after an
infinite number of measurements of @xmath on a system in the same state
@xmath . If @xmath is the density operator corresponding to the state
@xmath then

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

### 3.5 Einstein-Podolsky-Rosen paradox

In a famous paper [ 33 ] entitled “Can The Quantum Mechanical
Description of Physical Reality Be Considered Complete?” published in
1935, Einstein, Podolsky and Rosen (EPR) pointed out a paradox that now
carries their initials. EPR defined their elements of physical reality
by the criterion: “If, without in any way disturbing a system, we can
predict with certainty … the value of a physical quantity, then there
exists an element of physical reality corresponding to this physical
quantity.” EPR argued [ 33 ] that the quantum mechanical description of
physical reality cannot be considered as complete , because their
criterion gives rather strange predictions when applied to a composite
system consisting of two particles that have interacted once but are now
separate from one another and do not interact.

In 1951 Bohm [ 56 ] suggested a simpler version of the original paradox,
which can be described as follows. A particle decays, producing two
spin- @xmath particles whose total spin angular momentum is zero. These
particles move away from each other in opposite directions. Two
observers, call them @xmath and @xmath , measure the components of their
spins along various directions. Because the total spin is zero, the
measurement results will be opposite for @xmath and @xmath along a
particular direction. Such anti-correlations are not difficult to
imagine in the context of classical physics, given the fact that both
particles possess their anti-correlated values of the angular momentum.

What quantum theory says about this situation is quite different.
Consider the quantum state corresponding to a total spin of zero for the
two particles,

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

For this state suppose that @xmath measures the spin of his particle
along the @xmath -axis and finds it to be @xmath ; he can immediately
conclude that the result will be @xmath if @xmath measures the spin of
the other particle. From a realistic view the obvious question is: how
is @xmath ’s result immediately communicated to the other particle so as
to guarantee that @xmath will always obtain an exactly opposite result
to that of @xmath ? The paradox deepens on noting that ( 3.29 ) is a
singlet state; i.e. @xmath can chose any other direction he may like and
still @xmath ’s measurement will always yield a result opposite to that
of @xmath .

Though EPR concluded that the quantum description of physical reality is
not complete, they left open the question of whether or not a complete
description exists. In later years the so-called hidden variables
theories (HVTs) [ 57 ] were developed. HVTs suggested that deterministic
theories can describe nature, with the exact values of all observables
of a physical system being fixed by hidden variables which are not
directly accessible to measurement. The HVTs were meant to construct
deeper levels of description of quantum phenomena in which the
properties of individual systems do have preexisting values revealed by
the act of measurement. In this approach quantum mechanics becomes only
a statistical approximation to a HVT.

### 3.6 Quantum entanglement

The phenomenon of quantum entanglement is widely considered to be
central to the field of quantum computation and information [ 4 ] . It
is the phenomenon considered responsible for faster quantum algorithms,
though with some disagreements. For example [ 58 ] , Grover’s database
search algorithm [ 2 ] , although discovered in the context of quantum
computation, can be implemented using any system that allows a
superposition of states. In similar vein, much of the recent research in
quantum games uses entanglement for game-theoretical ends, although its
exact role is not clear. Certain quantum games [ 59 ] have been
suggested which involve no entanglement but still outperform the
corresponding classical games. Even in Meyer’s quantum penny-flip game [
8 ] , widely believed to have started the field of quantum games,
entanglement is not generated at any stage of the game.

Mathematically, the entanglement is described as follows. For a system
that can be divided into two subsystems quantum mechanics associates two
Hilbert spaces @xmath and @xmath to the subsystems. Assume that @xmath
and @xmath @xmath where @xmath are two complete orthonormal basis sets
for the Hilbert spaces @xmath and @xmath , respectively. The tensor
product @xmath is another Hilbert space that quantum mechanics
associates with the system consisting of the two subsystems. The tensor
product states @xmath (often written as @xmath ) span the space @xmath .
Any state @xmath of the composite system made of the two subsystems is a
linear combination of the product basis states @xmath i.e.

  -- -------- -- --------
     @xmath      (3.30)
  -- -------- -- --------

where @xmath . The normalization condition of the state @xmath is @xmath
. The state @xmath is called direct product ( or separable ) state if it
is possible to factor it into two normalized states from the Hilbert
spaces @xmath and @xmath . Assume that @xmath and @xmath are the two
normalized states from @xmath and @xmath , respectively. The state
@xmath is a direct product state when

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

Now a state in @xmath is called entangled if it is not a direct product
state. In words, entanglement describes the situation when the state of
‘whole’ cannot be written in terms of the states of its constituent
‘parts’.

#### 3.6.1 Entanglement in @xmath systems

The @xmath -dimensional quantum systems are of particular interest and
importance to the study of quantum games. In particular, such systems
are considered as the natural requirement for playing two-player quantum
games. Eisert et. al [ 9 ] used a @xmath system to investigate the
impact of entanglement on a Nash equilibrium in Prisoners’ Dilemma.

Let @xmath and @xmath be two-dimensional Hilbert spaces with bases
@xmath and @xmath , respectively. Then a basis for the Hilbert space
@xmath is given by

  -- -------- -- --------
     @xmath      (3.32)
  -- -------- -- --------

The most general state in the Hilbert space @xmath can be written as

  -- -------- -- --------
     @xmath      (3.33)
  -- -------- -- --------

which is usually written as @xmath . Here the indices @xmath and @xmath
refer to states in the Hilbert spaces @xmath and @xmath , respectively.
The general normalized states in @xmath and @xmath are @xmath and @xmath
, respectively. The state @xmath is a product state when

  -- -- -- --------
           (3.34)
  -- -- -- --------

where @xmath and @xmath .

For example, consider the state

  -- -------- -- --------
     @xmath      (3.35)
  -- -------- -- --------

For this state the criterion ( 3.34 ) implies the results

  -- -------- -- --------
     @xmath      (3.36)
  -- -------- -- --------

These equations cannot be true simultaneously. The state ( 3.35 ) is,
therefore, entangled.

### 3.7 Bell’s inequality

Starting from the assumptions of realism and locality, in 1964 Bell [ 34
] derived an inequality which was shown [ 38 ] later to be violated by
the quantum mechanical predictions for entangled states of a composite
system. Bell’s theorem [ 39 ] is the collective name for a family of
results, all showing the impossibility of local realistic interpretation
of quantum mechanics. Later work [ 60 ] has produced many different
types of Bell-type inequalities.

Entangled states are closely related to Bell’s inequalities. The
relationship is described by Gisin’s theorem [ 61 ] which says that pure
entangled states of @xmath -dimensional quantum systems (two qubits)
always violate a Bell-type inequality. Recently, Gisin’s theorem has
been extended [ 62 ] to @xmath -dimensional quantum systems (three
qubits), making stronger the relationship between entanglement and
Bell’s inequalities.

Let @xmath and @xmath be the two observables for observer @xmath in the
an EPR experiment. Similarly, let @xmath and @xmath be the two
observables for the observer @xmath . In general, the observables @xmath
and @xmath are incompatible and cannot be measured at the same time, and
the same holds for @xmath and @xmath .

It is assumed that the two particles that reach observers @xmath and
@xmath in EPR experiments possess hidden variables which fix the outcome
of all possible measurements. These hidden variables are collectively
represented by @xmath , assumed to belong to a set @xmath with a
probability density @xmath . The normalization implies

  -- -------- -- --------
     @xmath      (3.37)
  -- -------- -- --------

Because a given @xmath makes the four dichotomic observables assume
definite values, we can write

  -- -------- -- --------
     @xmath      (3.38)
  -- -------- -- --------

That is, the physical reality is marked by the variable @xmath . Now
introduce a correlation function @xmath between two dichotomic
observables @xmath and @xmath , defined by

  -- -------- -- --------
     @xmath      (3.39)
  -- -------- -- --------

For a linear combination of four correlation functions, define Bell’s
measurable quantity @xmath as

  -- -------- -- --------
     @xmath      (3.40)
  -- -------- -- --------

Only four correlation functions, out of a total of sixteen, enter into
the definition of @xmath . We can write

  -- -------- -- --------
     @xmath      
     @xmath      (3.41)
  -- -------- -- --------

Since

  -- -------- -- --------
     @xmath      (3.42)
  -- -------- -- --------

we have

  -- -------- -- --------
     @xmath      
     @xmath      (3.43)
  -- -------- -- --------

Also @xmath , so that

  -- -------- -- --------
     @xmath      (3.44)
  -- -------- -- --------

and the inequality ( 3.43 ) reduces to

  -- -------- -- --------
     @xmath      (3.45)
  -- -------- -- --------

which is called CHSH form [ 35 , 36 ] of Bell’s inequality.

#### 3.7.1 Violation of Bell’s inequality

It can be shown that Bell’s inequality is violated if the observers
@xmath and @xmath have appropriate observables. In Ref. [ 63 ] an
illustrative example is discussed showing the violation of the
inequality for certain observables. For completeness of this section the
example is reproduced below.

Let @xmath and @xmath be the spin observables for an entangled state

  -- -------- -- --------
     @xmath      (3.46)
  -- -------- -- --------

where @xmath and @xmath are real. Assume that the observers @xmath and
@xmath measure along the directions @xmath and @xmath , respectively.
Consider the quantum-mechanical mean value of the correlation:

  -- -------- -- --------
     @xmath      (3.47)
  -- -------- -- --------

where @xmath . To evaluate ( 3.47 ) for the entangled state ( 3.46 ) the
following matrix elements can be found [ 63 ] for @xmath

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (3.48)
  -- -------- -------- -- --------

Take @xmath and @xmath . Using ( 3.48 ) the correlation @xmath is given
as [ 63 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (3.49)
  -- -------- -------- -- --------

Consider now a set of directions @xmath @xmath @xmath and @xmath . For
these directions we obtain

  -- -------- -- --------
     @xmath      (3.50)
  -- -------- -- --------

Bell’s inequality is violated if @xmath . Assume that @xmath is a small
angle between @xmath and the @xmath -axis; then @xmath and @xmath which
gives the result

  -- -------- -- --------
     @xmath      (3.51)
  -- -------- -- --------

The inequality, therefore, is violated with small @xmath , when both
@xmath and @xmath are real and @xmath .

#### 3.7.2 Local realism and the violation of Bell’s inequality

Several experiments [ 38 , 64 ] have shown that Bell’s inequality can be
violated by quantum observables. The violation is often interpreted [ 39
] as the decisive argument against hypothesis of the existence of local
objective reality in quantum physics. Though that remains the majority
view, it is not a conclusion supported by general agreement; several
authors have disagreed that violation of Bell inequalities necessarily
leads to conclusions about local realism. In the following we briefly
describe the arguments of Fine [ 65 , 66 ] , Pitowsky [ 67 ] , DeBaere [
68 ] , Malley [ 69 , 70 ] and Fivel [ 71 , 72 ] .

A description of the local realism and violation of Bell’s inequality is
included here, firstly because it touches on the questions about the
true quantum content/character of a quantum game and secondly because
such a description is intimately connected to recent suggestions for
non-local games [ 73 , 74 ] .

##### Works of Fine, Pitowsky, DeBaere, Malley, Fivel, Gustafson and
Atkinson

Two mathematical theorems due to Arthur Fine [ 65 , 66 ] and Itamar
Pitowsky [ 67 ] are considered important in the continuing debate about
what are the real lessons to be learned from the violation of the Bell
inequalities. The theorems link the violation of Bell’s inequalities to
certain facts about probability theory. One of the influential arguments
is due to Fine [ 65 , 66 ] who showed that in a correlation experiment [
39 ] which is used to test Bell’s inequalities the following statements
are mutually equivalent.

1.  There is a deterministic hidden variable model for the experiment.

2.  There is a factorizable, stochastic model.

3.  There is one joint distribution for all observables of the
    experiment, such that it yields the experimental probabilities.

4.  There are well-defined, compatible joint distributions for all pairs
    and triples of commuting and non-commuting observables.

5.  Bell’s inequalities hold.

The equivalence of these statements means that violation of Bell’s
inequalities has a lot to do with the absence of joint probability
distributions for incompatible observables in correlation experiments.
In similar vein, Pitowsky [ 67 ] showed that one can view an eight-tuple
of real numbers from the interval @xmath , associated with the
experiments used to test Bell’s inequalities, as a set of four single
and four joint probabilities defined on a single classical probability
space if and only if the eight-tuple satisfies Bell’s inequalities. In
Pitowsky’s analysis the probabilities in Bell experiments are not
defined on a single probability space because non-commuting observables
are involved. These probabilities are, in fact, defined on four
different probability spaces. Because the experimental results cannot be
embedded in a single probability space it follows that violation of
Bell’s inequalities is not unusual. Non-commutativity of quantum
observables pertaining to a single system appears to play a crucial role
[ 68 ] in the violation of Bell’s inequalities.

On analyzing the geometry underlying no-hidden-variable theorems, Fivel
[ 71 ] also came to similar conclusions. He showed that a hidden
variable measure determines a metric on the homogeneous space consisting
of the set of orientations of a measuring device (e.g., a Stern-Gerlach
magnet) when these are regarded as being produced by the action of a Lie
group. For this metric the corresponding triangle inequality becomes one
of Bell’s inequalities. He then makes an important observation that when
the homogeneous space is identified with Hilbert space projectors this
identification induces another metric on the space which is locally
convex. Now EPR’s definition of element of physical reality [ 33 ]
forces the square of the locally convex metric equal to the metric
determined by the hidden variable measure. But, in fact, it is
impossible because the square of a locally convex metric cannot be a
metric.

Recently, Fine and Malley [ 69 , 70 ] have argued that violations of
local realism can be found in all those situations where non-commutative
observables are involved, without the necessity of sophisticated
correlation experiments.

The above arguments imply that one cannot argue [ 75 , 76 ] either
locality or non-locality on the basis of satisfaction or violation of
Bell’s inequality. Bell’s claim that his formulation of a “locality
condition” is an essential assumption for the validity of his inequality
has, therefore, been put under scrutiny and has sometimes even been
rejected [ 77 ] . Apart from the implications for local realism, Bell’s
inequalities have been shown to be closely related to entanglement. For
example, Gisin [ 61 ] showed that any pure entangled state of two
particles violates a Bell inequality for two-particle correlations.

## Chapter 4 Quantum games

### 4.1 Introduction

Speaking roughly, a quantum game can be thought of as strategic
manoeuvring of a quantum system by participating parties who are
identified as players. The players have the necessary means to perform
actions on the quantum system and knowledge is shared among them about
what constitutes a strategy. Often the strategy space is the set of
possible actions that players can take on the quantum system. The
players’ payoff functions, or utilities, are associated with their
strategies. Payoffs are obtained from the results of measurements
performed on the quantum system.

A two-player quantum game, for example, is a set [ 78 ] :

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

consisting of an underlying Hilbert space @xmath of the physical system,
the initial state @xmath , the sets @xmath and @xmath of allowed quantum
operations for two players, and the payoff functions @xmath and @xmath .
In most of the existing set-ups to play quantum games the initial state
@xmath is the state of one or more qubits, or qutrits [ 55 ] , or
possibly qudits.

### 4.2 Earlier works

Several situations in quantum theory can be found which have connections
to game theory. To find the roots of quantum games some of the earlier
works are enlisted below which appear as the underpinning to many
illustrative examples designed to show extraordinary features of quantum
theory. The list is not exhaustive and many others works can be found.

##### Blaquiere: “Wave mechanics as a two-player game”

Perhaps Blaquiere’s article [ 79 ] entitled “Wave mechanics as a
two-player game” is one of the earliest ones where game-theoretical
ideas are discussed in the context of quantum physics. Blaquiere
addresses a question concerned with a connection between dynamic
programming and the theory of differential games, on the one hand, and
wave mechanics on the other. The author argues that wave mechanics is
born of a dynamic programming equation which Louis de Broglie obtained
in 1923. He then expresses the stationarity principle in the form of a
min-max principle, which he writes in the form of sufficiency conditions
for the optimality of strategies in a two-player zero-sum differential
game. Blaquiere finds that the saddle-point condition, on which
optimality of strategies is based, is an extension of Hamilton’s
principle of least action.

##### Wiesner: “Quantum money”

Wiesner’s work on quantum money [ 80 ] is widely believed [ 81 ] to have
started the field of quantum cryptography. Because cryptographic
protocols can be written in the language of game theory; it then seems
reasonable to argue that, apart from originating quantum cryptography,
Wiesner’s work provided a motivation for quantum games. Wiesner
suggested using the uncertainty principle for creating:

1.  a means of transmitting two messages, either but not both of which
    may be received.

2.  money that it is physically impossible to counterfeit.

Wiesner’s proposal, though made much earlier, remained unpublished until
1983.

##### Mermin: “@xmath-player quantum game”

In 1990 Mermin [ 82 , 83 ] presented an @xmath -player quantum game that
can be won with certainty when it involves @xmath spin half particles in
a Greenberger-Horne-Zeilinger (GHZ) state [ 84 ] ; no classical strategy
can win the game with a probability greater than @xmath .

### 4.3 Quantum penny-flip game

As described above, many earlier works in quantum physics can be found
which have links to game theory in one way or the other. Nevertheless,
the credit for the emergence of quantum games as an independent domain
of research is usually (and justifiably) reserved for D. Meyer. Meyer [
8 ] suggested a quantum version of a penny-flip game played between
Picard and Q, the two well-known characters from the famous American
science fiction serial Star Trek. Meyer suggested [ 16 ] the game in the
hope that game theory might be helpful in understanding the working of
quantum algorithms and perhaps even in finding new ones, a task
generally considered hard because only a few quantum algorithms are
known to date.

Meyer [ 8 ] describes his game as follows. The starship Enterprise is
facing some imminent catastrophe when Q appears on the bridge and offers
to rescue the ship if Captain Picard ¹ ¹ 1 Meyer considered the initials
and abilities of Picard and Q ideal for his illustration. can beat him
at a simple game: Q produces a penny and asks Picard to place it in a
small box, head up. Then Q, followed by Picard, followed by Q, reaches
into the box, without looking at the penny, and either flips it over or
leaves it as it is. After Q’s second turn they open the box and Q wins
if the penny is head up. Q wins every time they play, using the
following strategy:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Here @xmath denotes ‘head’ and @xmath denotes ‘tail’, @xmath is the
Hadamard transformation [ 4 ] , @xmath means leaving the penny alone and
the action with @xmath flips the penny over. Q’s quantum strategy of
putting the penny into the equal superposition of ‘head’ and ‘tail’, on
his first turn, means that whether Picard flips the penny over or not,
it remains in an equal superposition which Q can rotate back to ‘head’
by applying @xmath again since @xmath . So Q always wins when they open
the box.

Q’s classical strategy consists of implementing @xmath or @xmath on his
turn. When Q is restricted to play only classically, flipping the penny
over or not on each turn with equal probability becomes an optimal
strategy for both the players. By adapting this classical strategy Q
wins only with probability @xmath . By using a quantum strategy Q can,
therefore, win with probability @xmath .

### 4.4 Quantum Prisoners’ Dilemma

Meyer’s paper attracted immediate attention and soon afterwards Eisert,
Wilkens, and Lewenstein [ 9 ] formulated a quantization scheme for the
famous game of Prisoners’ Dilemma. Eisert et al.’s scheme suggests a
quantum version of a two-player game by assigning two basis vectors
@xmath and @xmath in the Hilbert space of a qubit. States of the two
qubits belong to the two-dimensional Hilbert spaces @xmath and @xmath
respectively. A state of the game is defined by a vector residing in the
tensor-product space @xmath , spanned by the basis @xmath and @xmath .
The game’s initial state is @xmath where @xmath is a unitary operator
known to both the players. Let Alice and Bob be the two prisoners.
Alice’s and Bob’s strategies are unitary operations @xmath and @xmath ,
respectively, chosen from a strategic space Ş. The state of the game
changes to @xmath after the players’ actions. Finally, the measurement
consists of applying the reverse unitary operator @xmath , followed by a
pair of Stern-Gerlach type detectors. Before detection the final state
of the game is @xmath . The players’ expected payoffs can then be
written as the projections of the state @xmath onto the basis vectors of
the tensor-product space @xmath , weighted by the constants appearing in
the matrix representation of the two-player game. For example, Alice’s
payoff function reads

  -- -- -- -------
           (4.2)
  -- -- -- -------

Bob’s payoff function is then obtained by the transformation @xmath in
Eq. ( 4.2 ). Eisert et al. [ 9 , 78 ] allowed the players’ actions to be
chosen from the space Ş of unitary operators of the form

  -- -- -- -------
           (4.3)
  -- -- -- -------

where

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

They defined their unitary operator @xmath with @xmath representing a
measure of the game’s entanglement. At @xmath the game reduces to its
classical form. Eisert et al. found that for maximally entangled game
(i.e. @xmath ) the game has a unique Pareto optimal equilibrium @xmath
where @xmath .

### 4.5 Review of recent literature

Meyer’s [ 8 ] and Eisert et al.’s work [ 9 , 78 ] is often cited as
having started the field of quantum games, though many game-like
examples can be found in the quantum physics literature. In many cases
these examples are ‘tailored’ to illustrate extraordinary correlations
that may exist among spatially-separated quantum objects. The
contribution of Meyer’s work consists in providing the basis for a
systematic discussion of an explicitly game-theoretical problem when it
is implemented quantum mechanically. Eisert et al. carried this theme
further by proposing an experimental set-up using quantum-correlated
pairs of objects to play a quantum version of Prisoners’ Dilemma. In
contrast to several earlier proposals of game-like examples in quantum
physics, Meyer’s and Eisert. et al.’s work brought game theory right
into the domain of quantum information and computation. The era of
proposing tailored games to demonstrate the advantages of quantum
strategies over classical ones was left behind after suggestions of
general procedures to quantize known and understood games began to
arise. The focus of discussion shifted from specially-designed games to
general procedures and schemes for implementing quantum versions of
games which were already well-known from courses in game theory.

Below we present a literature review of the recent work on quantum
games, divided into three categories: specially-designed quantum games;
quantum games based on Meyer’s and Eisert et al.’s schemes; and other
work related to quantum games.

#### 4.5.1 Specially-designed games

As it is described above, certain quantum games are designed in such a
way so as to give advantage to quantum players against the classical
players. Sometimes, these appear as the games motivated by quantum
mechanical situations with their winning conditions tailored such that
only quantum players can be the winners. Following are some of the
examples.

##### Meyer: penny-flip quantum game

See the section ( 4.3 ).

##### Brassard, Broadbent and Tapp: “Quantum pseudo-telepathy”

In classical computer science, communication complexity theory is an
area that aims at quantifying the amount of communication necessary to
solve distributed computational problems. Quantum communication
complexity theory uses quantum mechanics to reduce the amount of
communication below that which would be classically required. Brassard,
Broadbent and Tapp [ 73 , 74 ] called ‘pseudo-telepathy’ the situation
in which two or more quantum players can accomplish a distributed task
with no need for communication whatsoever. The situation would be an
impossible feat for classical players, but entanglement allows its
possibility. Using Mermin’s @xmath -player game (see section ( 4.2 )),
that exploits multi-party entanglement, Brassard, Broadbent and Tapp
recast the game in terms of pseudo-telepathy. They derived an upper
bound on the best possible classical strategy for attempting to play the
game. It allowed them to find how well an imperfect quantum-mechanical
apparatus must perform in order to exhibit a behaviour that would be
classically impossible to explain.

##### Mermin: “@xmath-player quantum game”

See the section ( 4.2 ).

##### Vaidman: “Three-player quantum game”

In 1999 Vaidman [ 85 , 86 ] illustrated the GHZ paradox [ 84 ] by using
a game among three players. A team of three players is allowed to make
any preparations before they are separately taken to three different
remote locations. Then, at a certain time each player is asked one of
two possible questions: “What is @xmath ?” or “What is @xmath ?” to
which they must quickly give one of the answers: “ @xmath ” or “ @xmath
”. According to the rules of the game, either all players are asked the
@xmath question, or only one player is asked the @xmath question and the
other two are asked the @xmath question. The team wins if the product of
their three answers is @xmath in the case of three @xmath questions and
is @xmath in the case of one @xmath and two @xmath questions. It can
easily be shown that if the answer of each player is determined by some
local hidden variable (LHV) theory then the best strategy of the team
will lead to a @xmath probability to win. However, a quantum team
equipped with ideal devices can win with certainty. Each player performs
a spin measurement of a spin- @xmath particle (a @xmath measurement for
the @xmath question and a @xmath measurement for the @xmath question)
and gives the answer @xmath for spin “up” and @xmath for spin “down”.
Quantum theory ensures that if the players have particles prepared in
the GHZ state [ 84 ] , the team always wins. In Vaidman’s opinion [ 86 ]
, constructing such devices and seeing that quantum teams indeed win the
game with a probability significantly larger than @xmath will be a very
convincing proof of Bell-type inequalities.

It is to be pointed out that the algebraic contradiction, which is
obtained by comparing the four equations describing the team’s winning
condition, assumes that all the equations hold simultaneously. In fact,
the four equations represent four incompatible situations. In other
words, with reference to Fine’s theorem [ 65 , 66 ] , the description of
each player’s answer by an LHV theory is strictly equivalent to the
assumption of a joint probability distribution for incompatible
observables whose rejection, in Fine’s words [ 65 ] , is the “very
essence of quantum mechanics”.

##### Grib and Parfionov: “Macroscopic quantum game”

Using a new approach to quantum games, Grib and Parfionov [ 87 , 88 ]
considered a game in which the acts of the participants do not have an
adequate description in terms of Boolean logic and the classical theory
of probabilities. They constructed a model of the game interaction using
a non-distributive ortho-complemented lattice. They proposed a
quantization scheme for the game and developed an algorithm to search
for a Nash equilibrium. They showed that, in contrast with the classical
case, a discrete set of equilibria is possible in the quantum situation.

In [ 89 ] Grib and Parfionov presented examples of two-player
macroscopic quantum games in which special rules become responsible for
breaking the distributive property of a lattice of yes-no questions.
They discussed examples of games using spin- @xmath particles and found
new Nash equilibria.

##### Other games

In [ 86 ] Vaidman lists several proposals where bizarre features of
quantum mechanics have been explained through various games. It includes
a variation of the GHZ game given by Steane and van Dam [ 90 ] , a game
based on the original Bell proof by Tsirelson [ 91 ] , the “quantum
cakes” game using non-maximally entangled state by Kwiat and Hardy [ 92
] and Cabello’s proposal [ 93 ] for a two-party Bell-inequality proof
which can be put into the form of a game. In [ 86 ] Vaidman also
presented a game which he called “impossible necklace”.

#### 4.5.2 Quantum games based on Eisert et al.’s formalism

Eisert et al.’s quantum Prisoners’ Dilemma gives a general scheme to
quantize the two-player noncooperative games. Following works on quantum
games are based on their scheme.

##### Benjamin and Hayden: “Multi-player quantum games”

Generalizing the scheme of Eisert et al., Benjamin and Hayden [ 21 ]
presented their first study of quantum games with more than two players.
They found that such games can possess a new form of equilibrium
strategy, one which has no analogue either in traditional games or even
in two-player quantum games. They showed that in such games, because of
a sharing of entanglement among many players, there may exist ‘pure’
coherent equilibria enabling new kinds of cooperative behaviour. It is a
cooperative behaviour that prevents players from successfully betraying
one-another.

Benjamin and Hayden’s work provides a means to analyze multi-party
entanglement by using game theory.

##### Marinatto and Weber: “A quantum approach to static games of
complete information”

Marinatto and Weber [ 22 ] extended the concept of a classical
two-person static game to the quantum domain by giving a Hilbert space
structure to the space of classical strategies. They studied the game of
Battle of the Sexes, showing that entangled strategies did lead to a
unique solution of the game. Building up from Eisert et al.’s
quantization of Prisoners’ Dilemma [ 9 , 78 ] they proposed a scheme in
which a strategy is a state in a @xmath – dimensional Hilbert space. At
the start of the game the players are supplied with this strategy. In
the next phase players manipulate the strategy by their actions,
identified as ‘tactics’. Finally, the quantum state (strategy) is
measured and the payoffs which are awarded depend on the results of the
measurement.

The players’ actions are within a two-dimensional subspace in this
scheme and ‘tactics’ are local actions on players’ qubits. A final
measurement is made independently on each qubit, so that it takes into
consideration the local nature of the players’ manipulations. It is
achieved by selecting a measurement basis that respects the division of
the Hilbert space into two equal parts. In a comment, Benjamin [ 94 ]
observed that, overall, Marinatto and Weber’s quantization scheme is
fundamentally very similar to Eisert et al.’s previously proposed scheme
[ 9 ] . Benjamin argued that in the quantum Battle of Sexes the players
are still faced with the dilemma, just as they are in the classical
game. He noted that their quantum Battle of Sexes does not have a unique
solution, though it may be easier to resolve this dilemma in the quantum
version of the game.

##### Du et al.: “Experimental realization of quantum games on a quantum
computer”

Du et al. [ 24 ] generalized the quantum Prisoner’s Dilemma to the case
in which players share non maximally entangled states. They showed that
the game exhibits an intriguing structure as a function of the amount of
entanglement. They identified two thresholds, separating a classical
region, an intermediate region and a fully quantum region. Moreover,
they realized their quantum game experimentally on a nuclear magnetic
resonance quantum computer.

##### Flitney and Abbot: “Quantum Monty Hall problem”, “Quantum Parrondo
Paradox”

Flitney and Abbott [ 25 , 95 ] presented a version of the Monty Hall
problem where the players are permitted to select quantum strategies. If
the initial state involves no entanglement the Nash equilibrium in the
quantum game offers the players nothing more than can be obtained with a
classical mixed strategy. However, if the initial state involves
entanglement of the qubits belonging to the two players, it is
advantageous for one player to have access to a quantum strategy while
the other does not. When both players have access to quantum strategies
there is no Nash equilibrium in pure strategies but there is a Nash
equilibrium in quantum mixed strategies that gives the same average
payoff as the classical game.

Parrondo’s Paradox is an interesting situation arising when two losing
games are combined to produce a winning one. Flitney and Abbott [ 26 ,
95 ] studied a history-dependent quantum Parrondo game where the
rotation operators, representing the toss of a classical biased coin,
are replaced by general SU( @xmath ) operators to transform the game
into the quantum domain. They showed that, in the initial state of the
qubits, superposition can be used to couple the games to produce
interference effects leading to quite different payoffs from the ones in
the classical case.

##### Iqbal and Toor: “Evolutionarily stable strategies in quantum
games”

Using Marinatto and Weber’s quantization scheme [ 22 ] , Iqbal and Toor
[ 23 ] investigated a refinement of the Nash equilibrium concept within
the context of quantum games. The refinement, called an evolutionarily
stable strategy (ESS), was originally introduced in 1970s by
mathematical biologists to model an evolving population using
game-theoretical techniques. They considered situations where
quantization changes ESSs without affecting the corresponding Nash
equilibria.

##### Kawakami: “Communication and computation by quantum games”

Kawakami [ 96 ] argued that in the classical Prisoners’ Dilemma a
certain degree of communication between the two prisoners is performed
at the moment the payoff is given to them by the jailer. Motivated by
this view, Kawakami studied communication and information carriers in
quantum games. He showed, quite surprisingly, that communications in
special quantum games can be used to solve problems that cannot be
solved by using communications in classical games.

##### Lee and Johnson: “General theory of quantum games”

Presenting a general theory of quantum games, Lee and Johnson [ 97 ]
showed that quantum games are more efficient than classical games and
can provide a saturated upper bound for efficiency. They demonstrated
that the set of finite classical games is a strict subset of the set of
finite quantum games. They deduced a quantum version of the minimax
theorem and the Nash equilibrium theorem. In [ 98 ] Johnson showed that
the quantum advantage arising in a simplified multi-player quantum game
becomes a disadvantage when the game’s qubit-source is corrupted by a
noisy “demon”. Above a critical value of the corruption-rate, or
noise-level, the coherent quantum effects impede the players to such an
extent that the optimal choice of game changes from quantum to
classical.

##### Cheon and Tsutsui: “Classical and quantum contents of solvable
game theory on Hilbert space”

Cheon and Tsutsui [ 99 ] presented a general formulation of the quantum
game theory that accommodates, for the first time, all possible
strategies in the Hilbert space. Their theory is solvable for
two-strategy quantum games. They showed that their quantum games are
equivalent to a family of classical games supplemented by quantum
interference. Their formulation extends Eisert et al.’s formalism,
giving a perspective on why quantum strategies outmaneuvre classical
strategies.

##### Shimamura et al.: “Quantum and classical correlations between
players in game theory”

Shimamura, Özdemir, Morikoshi and Imoto [ 100 ] studied the effects of
quantum and classical correlations on game theory. They compared the
quantum correlation present in a maximally entangled state with the
classical correlation generated through phase damping processes on the
maximally entangled state. Their study sheds light on the behaviour of
games under the influence of noisy sources. They observed that the
quantum correlation can always resolve the dilemmas in non-zero sum
games and attain the maximum sum of both players’ payoffs, while the
classical correlation cannot necessarily resolve the dilemmas.

#### 4.5.3 Related work

In the following, work is described which is closely related to the
field of quantum games. It is the work that has motivated quantum games
and, in certain cases, has been motivated by the developments in quantum
games.

##### Deutsch: “Quantum theory of probability and decisions”

The probabilistic predictions of quantum theory are conventionally
obtained from a special probabilistic axiom. Deutsch [ 101 ] argued that
all the practical consequences of the probabilistic predictions of
quantum theory can also be made to follow from the non-probabilistic
axioms of quantum theory together with the non-probabilistic part of
classical decision theory.

##### Blaquiere: “Wave mechanics as a two-player game”

See section ( 4.2 ).

##### Wiesner: “Quantum money”

See section ( 4.2 ).

##### Piotrowski and Sladkowski: “Quantum-like description of markets
and economics”

Piotrowski and Sladkowski [ 102 ] proposed quantum-like description of
markets and economics. Their approach has roots in the developments in
quantum game theory. In [ 103 ] they investigated quantum bargaining
games that are a special class of quantum market games without
institutionalized clearing houses. In [ 104 ] they showed the
possibility of defining a risk inclination operator, acting in Hilbert
space, that has similarities with the quantum description of the
harmonic oscillator. They also formulated a quantum anthropic principle
.

##### Pietarinen: “Game-theoretic perspective of quantum logic and
quantum theory”

Doubts have been expressed about any ‘substantial’ insight that quantum
logic can provide into the nature of composite quantum systems. In order
to neutralize such pessimistic views, Pietarinen [ 19 ] suggested that
games (especially extensive games of imperfect information) can provide
a useful set of tools for giving a semantics to quantum logic. He
suggested that game theory can be brought to bear on questions
concerning the interpretation and nature of uncertainty in the
foundations of quantum theory. He also suggested [ 19 ] that the kinship
between game theory and quantum logic implies that the propositional
logic of informational independence is useful in understanding
non-locality and EPR-type paradoxes.

##### Lassig: “Game theory from statistical mechanics”

Looking at game theory from the viewpoint of statistical mechanics,
Lassig [ 105 ] presented a systematic theory of stochastic effects in
game theory, including the effects of fluctuations. In a biological
context, such effects are relevant for the evolution of finite
populations with frequency-dependent selection. The states of the
populations are also time-dependent and are defined by a probability
distribution over mixed strategies. Lassig found that stochastic effects
make the equation governing the evolutionary dynamics take the form of a
Schrödinger equation in imaginary time, thus justifying the use of the
name ‘quantum game theory’.

Although ostensibly dealing with quantum games, Lassig’s approach to
quantum games appears significantly different from the one presented
within the framework of quantum computation and information theory.

##### Boukas: “Quantum formulation of classical two-person zero-sum
games”

In a relatively less known paper, Boukas [ 106 ] extended the concept of
a classical player, corresponding to a simple random variable on a
probability space of finite cardinality, to that of a quantum player,
corresponding to a self-adjoint operator on a quantum probability
Hilbert space. Boukas proved quantum versions of von Neumann’s minimax
theorem.

### 4.6 Criticism of quantum games

Quantum games have been put under close scrutiny since their earliest
suggestions were put forward. The debate is continuing to date [ 107 ,
108 , 109 , 99 ] . In the following are described some of the well-known
critical comments and the replies made to those.

#### 4.6.1 Enk’s comment on quantum penny-flip game

Meyer’s quantum penny-flip game can be played using one qubit. Enk [ 28
] commented that the game involves no entanglement and can therefore be
simulated classically, though Meyer had reached a correct conclusion.
Enk argued that neither Bell’s inequalities nor the Kochen-Specker
theorem [ 110 ] exist for the game and thus the quantum game shows only
a rather unsurprising result i.e. the superiority of an extended set of
strategies over a restricted one.

Meyer replied [ 29 ] that the issue is not whether there exists a
classical simulation or not but rather how the complexity of that
classical simulation would scale if the size of the game increases.
Disagreeing with Enk’s claim that Q’s strategy is not quantum (because a
classical model exists for it) he indicated that Enk’s reasoning implies
that P’s strategy is also not classical, because quantum models exist
for flipping a two-state system. Meyer referred to Lloyd’s [ 111 ]
result that Grover’s algorithm [ 2 ] , well-known in quantum computation
and information theory, can be implemented without entanglement by using
a system allowing the superposition of states [ 58 ] , despite claims [
112 ] that the power of quantum computing derives from entanglement.

In 1964 Bell [ 34 ] constructed a hidden variable model of spin
measurements on a single particle, reproducing the quantum mechanical
predictions for expectation value of the spin in any direction. In spite
of Bell’s construction the question about how far a two-dimensional
quantum system of a qubit can be claimed to have a ‘true’ quantum
character has remained a matter of active debate. For example, Fivel [
72 ] reported an alleged ambiguity in Bell’s claim that the distinction
between quantum mechanics and hidden variable theories cannot be found
in the behaviour of single particle beams; Khrennikov [ 113 ] indicated
that a realistic pre-quantum model does not exist even for the
two-dimensional Hilbert space.

#### 4.6.2 Criticism of Eisert et al.’s quantum Prisoners’ Dilemma

Eisert et al.’s quantum Prisoners’ Dilemma (PD) has been criticized
twice; from Benjamin and Hayden, and from Enk and Pike.

##### Benjamin and Hayden

Eisert et al. obtained @xmath as the new quantum equilibrium in
Prisoners’ Dilemma, when both players have access to a two-parameter set
( 4.3 ) of unitary @xmath operators. Benjamin and Hayden [ 30 ] observed
that when their two-parameter set is extended to include all local
unitary operations (i.e. all of @xmath ) the strategy @xmath does not
remain an equilibrium. They showed that in the full space of
deterministic quantum strategies there exists no equilibrium for the
quantum Prisoners’ Dilemma. Also, they observed that the set ( 4.3 ) of
two-parameter quantum strategies is not closed under composition,
although this closure appears to be a necessary requirement for any set
of quantum strategies. It can be explained as follows. Eisert et al.
permitted both players the same strategy set but introduced an arbitrary
constraint into that set. This amounts to permitting a certain strategy
while forbidding the logical counter strategy which one would
intuitively expect to be equally allowed. Benjamin and Hayden argued
that @xmath emerges as the ideal strategy only because of restricting
the strategy set arbitrarily.

Agreeing with the factual content of Benjamin and Hayden’s comment [ 30
] , Eisert et al. nevertheless replied [ 31 ] that in order to prove the
existence of a quantum extension for which @xmath is a Pareto-optimal
Nash equilibrium, it is indeed sufficient to explicate just one set of
strategies for which this is the case; they asserted that the strategy
set introduced by them does just this. They indicated that nowhere in
their proposal had they claimed that @xmath was a Pareto-optimal Nash
equilibrium under all circumstances; if analyzed in a different
strategic space the game’s solution acquires a different character.

##### Enk and Pike

Enk and Pike [ 32 ] commented that the quantum solutions of PD, found by
Eisert et al. [ 9 ] , are neither quantum mechanical nor do they solve
the classical game. They argued that it is possible to capture the
‘essence’ of quantized PD by simply extending the payoff matrix of the
classical game. That is done by including an additional purely classical
move corresponding to @xmath , which in Eisert et al.’s scheme appears
as a new quantum-mechanical ‘solution-move’ removing the dilemma
inherent in the game. Enk and Pike maintained that, since Eisert’s
quantum solution to PD can be reconstructed in such a classical way, the
only defence that remains for the quantum solution is its efficiency,
which unfortunately does not have a role in PD because of its being a
one-shot game.

In the same paper Enk and Pike [ 32 ] also suggested that a quantum game
exploiting non-classical correlations in entangled states, similar to
those that violate Bell’s inequality, should be investigated. They
indicated that the non-classical correlations have no role in Eisert et
al.’s set-up, and in other quantization procedures derived from it,
although entangled states may be present. This is because various
qubits, after their local unitary manipulations, are brought together,
during the final stage of the game to make the measurement which
produces the payoffs.

## Chapter 5 Quantum correlation games

### 5.1 Introduction

Quantum games have attracted significant research interest during the
last few years. However, opinions about the true quantum character and
content of quantum games still remains divided, as it is discussed in
the section ( 4.6 ).

The statistical predictions of quantum mechanics are different from the
predictions of a local realistic theory and the Bell inequalities
express the constraints on dichotomic variables imposed by the principle
of local causality. The most explicit way of showing that a game can
give different solutions depending on whether it is played quantum
mechanically or classically is to design an experimental set-up,
statistical in nature, in which the constraints expressed by Bell
inequalities, when satisfied, always result in the classical game.
EPR-type experiments [ 38 ] provide such a realization. This gives rise
to the immediate problem of how to transform the EPR-type experiments
into an arrangement for playing a two-player game. In this arrangement
the spatially separated measurements in the EPR-type experiments are
associated with two players when they retain their freedom to choose
their strategies.

In the present chapter, motivated by this suggestion of using the
EPR-type set-up to play a two-player game, we associate a quantum game
to a classical game in a way that addresses the above mentioned
criticism on quantum games. We suggest that the following two
constraints should be imposed on this association.

1.  The players choose their moves (or actions) from the same set in
    both the classical and the quantized game.

2.  The players agree on explicit expressions for their payoffs which
    must not be modified when switching between the classical and the
    quantized version of the game.

Games with these properties are expected to be immune to the criticism
raised above. In the new setting the only ‘parameter’ is the input state
on which the players act; its nature will determine the classical or
quantum character of the game. Our approach to quantum games, tailored
to satisfy both (c1) and (c2), is inspired by Bell’s work [ 34 ] :
correlations of measurement outcomes are essential. Effectively, we will
define payoff relations in terms of correlations – these payoffs will
become sensitive to the classical or quantum nature of the input, thus
allowing for the existence of modified Nash equilibria.

### 5.2 Matrix games and payoffs

Consider a matrix game for two players, called Alice and Bob. A large
set of identical objects are prepared in definite states, which are not
necessarily known to the players. Each object splits into two equivalent
‘halves’ which are handed over to Alice and Bob simultaneously. Let the
players agree beforehand on the following rules:

1.  Alice and Bob may either play the identity move @xmath or perform
    (unitary) actions @xmath and @xmath , respectively. The moves @xmath
    (and @xmath ) consist of unique actions such as flipping a coin (or
    not) and possibly reading it.

2.  The players agree upon payoff relations @xmath which determine their
    rewards as functions of their strategies , that is, the moves with
    probabilities @xmath assigned to them.

3.  The players fix their strategies for repeated runs of the game. In a
    mixed strategy Alice plays the identity move @xmath with probability
    @xmath , say, while she plays @xmath with probability @xmath , and
    similarly for Bob. In a pure strategy, each player performs the same
    action in each run.

4.  Whenever the players receive their part of the system, they perform
    a move consistent with their strategy.

5.  The players inform an arbiter about their actions taken in each
    individual run. After a large number of runs, they are rewarded
    according to the agreed payoff relations @xmath . The existence of
    the arbiter is for clarity only: alternatively, the players can get
    together to decide on their payoffs.

These conventions are sufficient to play a classical game. As an
example, consider the class of symmetric bimatrix games with payoff
relations

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (5.1)
  -- -------- -------- -- -------

where @xmath and @xmath are real numbers. Being functions of two real
variables, with @xmath , the payoff relations @xmath reflect the fact
that each player may chose a strategy from a continuous one-parameter
set. The game is symmetric since

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

Now consider pure strategies with @xmath or @xmath in Eq. ( 5.1 ): we
have

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (5.3)
  -- -------- -------- -- -------

leading to the payoff matrix for this game

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

In words: If both Alice and Bob play the identity @xmath , they are paid
@xmath units; Alice playing the identity @xmath and Bob playing @xmath
pays @xmath and @xmath units to them, respectively; etc. Knowledge of
the payoff matrix ( 5.4 ) and the probabilities @xmath is, in fact,
equivalent to ( 5.1 ), since the expected payoffs @xmath are obtained by
averaging ( 5.4 ) over many runs.

Let Alice and Bob act rationally: they will try to maximize their
payoffs by an appropriate strategy. If the entries of the matrix ( 5.4 )
satisfy @xmath , the Prisoners’ Dilemma arises: the players opt for
strategies in which unilateral deviations are disadvantageous;
nevertheless, the resulting solution of the game, a Nash equilibrium,
does not maximize their payoffs.

In view of the conditions (c1) and (c2), the form of the payoff
relations @xmath in ( 5.1 ) seems to leave no room to introduce quantum
games which would differ from classical ones. In the following we will
introduce payoff relations which are sensitive to whether a game is
played on classical or quantum objects. With a classical input they will
reproduce the classical game and the conditions (c1) and (c2) will be
respected throughout.

### 5.3 EPR-type setting of matrix games

Correlation games will be defined in a setting which is inspired by
EPR-type experiments. Alice and Bob are spatially separated, and they
share information about a Cartesian coordinate system with axes @xmath .
The physical input used in a correlation game is a large number of
identical systems with zero angular momentum, @xmath . Each system
decomposes into a pair of objects which carry perfectly anti-correlated
angular momenta @xmath , i.e. @xmath .

In each run, Alice and Bob will measure the dichotomic variable @xmath
of their halves along the common @xmath -axis ( @xmath ) or along
specific directions @xmath and @xmath in two planes @xmath and @xmath ,
respectively, each containing the @xmath -axis, as shown in Fig. ( 5.3
). The vectors @xmath and @xmath are characterized by the angles @xmath
and @xmath which they enclose with the @xmath -axis:

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

In principle, Alice and Bob could be given the choice of both the
directions @xmath and the probabilities @xmath . However, in traditional
matrix games each player has access to one continuous variable only,
namely @xmath . To remain within this framework, we impose a relation
between the probabilities @xmath , and the angles @xmath :

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

The function @xmath maps the interval @xmath to @xmath , and it is
specified before the game begins. This function is, in general, not
required to be invertible or continuous. Relation ( 5.6 ) says that
Alice must play the identity with probability @xmath if she decides to
select the direction @xmath as her alternative to @xmath ; furthermore,
she measures with probability @xmath along @xmath . For an invertible
function @xmath , Alice can choose either a probability @xmath or a
direction @xmath and find the other variable from Eq. ( 5.6 ). If the
function @xmath is not invertible, some values of probability are
associated with more than one angle, and it is more natural to have the
players choose a direction first. For simplicity we will assume the
function @xmath to be invertible, if not specified otherwise.

According to her chosen strategy, Alice will measure the quantity @xmath
with probability @xmath along the @xmath -axis, and with probability
@xmath along the direction @xmath . Similarly, Bob can play a mixed
strategy, measuring along the directions @xmath or @xmath with
probabilities @xmath and @xmath , respectively. Hence, Alice’s moves
consist of either @xmath (rotating a Stern-Gerlach type apparatus from
@xmath to @xmath , followed by a measurement) or of @xmath (a
measurement along @xmath with no previous rotation). Bob’s moves @xmath
and @xmath are defined similarly. It is convenient to denote the
outcomes of measurements along the directions @xmath , and @xmath by
@xmath and @xmath , respectively. It is emphasized that the move @xmath
is not the same as the identity operation @xmath because measurements
are always performed along @xmath or @xmath .

After each run, the players inform the arbiter about the chosen
directions and the result of their measurements. After @xmath runs of
the game, the arbiter possesses a list @xmath indicating the directions
of the measurements selected by the players and the measured values of
the quantity @xmath . The arbiter uses the list to determine the
strategies played by Alice and Bob by simply counting the number of
times ( @xmath , say) that Alice measured along @xmath , giving @xmath ,
etc. Finally, the players are rewarded according to the payoff relations
( 5.1 ).

[]

Figure @xmath - @xmath : The players’ strategies consist of defining
angles @xmath which the directions @xmath make with the @xmath -axis;
for simplicity the planes @xmath are chosen as the @xmath - @xmath and
@xmath - @xmath planes, respectively.

### 5.4 Correlation games

We now develop a new perspective on matrix games in the EPR-type
setting. The basic idea is to define payoffs @xmath which depend
explicitly on the correlations of the actual measurements performed by
Alice and Bob. The arbiter will extract the numerical values of the
correlations @xmath etc. from the list @xmath in the usual way.
Consider, for example, all cases with Alice measuring along @xmath and
Bob along @xmath . If there are @xmath such runs, the correlation of the
measurements is defined by

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

where @xmath and @xmath take the values @xmath . The correlations @xmath
and @xmath are defined similarly.

A symmetric bimatrix correlation game is determined by a function @xmath
in ( 5.6 ) and by the relations

  -- -------- -- -- -------
     @xmath         
     @xmath         (5.8)
  -- -------- -- -- -------

where, in view of later developments, the function @xmath is taken to be

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

As they stand, the payoff relations ( 5.8 ) refer to neither a classical
nor a quantum mechanical input. Hence, condition (c2) from the section (
@xmath ) is satisfied: the payoff relations used in the classical and
the quantum version of the game are identical , as given by Eqs. ( 5.8
). Furthermore, Alice and Bob choose from the same set of moves in both
versions of the game: they select directions @xmath and @xmath (with
probabilities @xmath associated with @xmath via ( 5.6 )) so that
condition (c1) from the section ( @xmath ) is satisfied. Nevertheless,
the solutions of the correlation game ( 5.8 ) will depend on the input
being either a classical or a quantum mechanical anti-correlated state.

#### 5.4.1 Classical correlation games

Alice and Bob play a classical correlation game if they receive
classically anti-correlated pairs and use the payoff relations ( 5.8 ).
In this case, the payoffs turn into

  -- -- -- --------
           (5.10)
  -- -- -- --------

where the correlations, characteristic for classically anti-correlated
systems, are given by

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.11)
  -- -------- -------- -- --------

We use the definition of the function @xmath in ( 5.9 ) and the link (
5.6 ) between probabilities @xmath and angles @xmath to obtain

  -- -------- -------- -- --------
     @xmath   @xmath      (5.12)
     @xmath   @xmath      (5.13)
  -- -------- -------- -- --------

Hence for classical input Eqs. ( 5.8 ) reproduce the payoffs of a
symmetric bimatrix game ( 5.1 ),

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.14)
  -- -------- -------- -- --------

The game-theoretic analysis of the classical correlation game is now
straightforward – for example, appropriate values of the parameters
@xmath lead to the Prisoners’ Dilemma, for any invertible function
@xmath .

#### 5.4.2 Quantum correlation games

Imagine now that Alice and Bob receive quantum mechanical
anti-correlated singlet states

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

They are said to play a quantum correlation game if again they use the
payoff relations ( 5.8 ), which in this case give

  -- -- -- --------
           (5.16)
  -- -- -- --------

As before, Alice and Bob transmit the results of their measurements (on
their quantum halves) to the arbiter who, after a large number of runs,
determines the correlations @xmath and @xmath by the formula ( 5.7 )

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.17)
  -- -------- -------- -- --------

in contrast to ( 5.11 ).

The inverse of relation ( 5.6 ) links the probabilities and correlations
as follows:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.18)
  -- -------- -------- -- --------

Inserting these expressions into the right-hand-side of ( 5.16 ), we
obtain the quantum payoffs:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.19)
  -- -------- -------- -- --------

where

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

The payoffs @xmath turn out to be non-linear functions of the
probabilities @xmath , while the payoffs @xmath of the classical
correlation game are bi-linear . This modification has an impact on the
solutions of the game, as shown in the following section.

### 5.5 Nash equilibria of quantum correlation games

What are the properties of the quantum payoffs @xmath as compared to the
classical ones @xmath ? The standard approach to ‘solving games’
consists of studying Nash equilibria. For a bimatrix game a pair of
strategies @xmath is a Nash equilibrium if each player’s payoff does not
increase upon unilateral deviation from her strategy,

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.21)
  -- -------- -------- -- --------

In the following, we will study the differences between the classical
and quantum correlation games which are associated with two paradigmatic
games: the Prisoners’ Dilemma (PD) and the Battle of Sexes (BoS).

The payoff matrix of the PD has been introduced in ( 5.4 ). It will be
convenient to use the notation of game theory: @xmath corresponds to
Cooperation, while @xmath is the strategy of Defection. A characteristic
feature of this game is that the condition @xmath guarantees that the
strategy @xmath dominates the strategy @xmath for both players and that
the unique equilibrium at @xmath is not Pareto optimal. An outcome of a
game is Pareto optimal if there is no other outcome that makes one or
more players better off and no player worse off. This can be seen in the
following way. The conditions ( 5.21 ) give

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.22)
  -- -------- -------- -- --------

with @xmath and @xmath from ( 5.3 ). The inequalities have only one
solution

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

which corresponds to @xmath , a pure strategy for both players. The PD
is said to have a pure Nash equilibrium.

The BoS is defined by the following payoff matrix:

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

where @xmath and @xmath are pure strategies and @xmath . Three Nash
equilibria arise in the classical BoS, two of which are pure: @xmath and
@xmath . The third one is a mixed equilibrium where Alice and Bob play
@xmath with probabilities

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

For the quantum correlation game associated with the generalized PD the
conditions ( 5.21 ) turn into

  -- -------- -------- -- --------
     @xmath   @xmath      (5.26)
     @xmath   @xmath      (5.27)
  -- -------- -------- -- --------

where the range of @xmath has been defined in ( 5.20 ). Thus, the
conditions for a Nash equilibrium of a quantum correlation game are
structurally similar to those of the classical game except for
non-linear dependence on the probabilities @xmath . The only solutions
of ( 5.27 ) therefore read

  -- -------- -- --------
     @xmath      (5.28)
  -- -------- -- --------

generating upon inversion a Nash equilibrium at

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

where the transformed probabilities now come with a subscript @xmath
indicating the presence of quantum correlations. The location of this
new equilibrium depends on the actual choice of the function @xmath , as
is shown below.

Similar arguments apply to the pure Nash equilibria of the BoS game
while the mixed classical equilibrium ( 5.25 ) is transformed into

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (5.30)
  -- -------- -------- -- --------

When defining a quantum correlation game we need to specify a function
@xmath which establishes the link between the probabilities @xmath and
the angles @xmath . We will study the properties of quantum correlation
games for @xmath -functions of increasing complexity. In the simplest
case, the function @xmath is ( @xmath ) continuous and invertible; next,
we chose a function @xmath being ( @xmath ) invertible and discontinuous
or ( @xmath ) non-invertible and discontinuous. For simplicity, all
examples are worked out for piecewise linear @xmath -functions. The
generalization to smooth @xmath -functions turns out to be
straightforward and the results do not change qualitatively as long as
the @xmath -function preserves its characteristic features.

##### (@xmath) Continuous and invertible @xmath-functions

Consider the function @xmath defined for @xmath . We have @xmath or
@xmath , and the classical and quantum correlations coincide at @xmath
and @xmath . In view of ( 5.29 ) the function @xmath can have no effect
on pure Nash equilibria and the classical solution of PD is not modified
in the quantum game. Fig. ( 5.5 ) shows the function @xmath .

[]

Figure @xmath - @xmath : The invertible and continuous @xmath -function
@xmath .

However, solutions @xmath correspond to a mixed classical equilibrium,
which will be modified if @xmath i.e. when the angle associated with
@xmath is different from @xmath . For example with the function @xmath
the probabilities of the mixed equilibrium of the quantum correlation
BoS are @xmath and @xmath . A similar result holds for the function
@xmath .

##### (@xmath) Invertible and discontinuous @xmath-functions

For simplicity we consider invertible functions that are discontinuous
at one point only. Piecewise linear functions are typical examples. One
such function, shown in Fig. ( 5.5 ), is

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

The classical solution of PD @xmath disappears; the new quantum solution
is found at

  -- -------- -- --------
     @xmath      (5.32)
  -- -------- -- --------

If, for example, @xmath and @xmath we obtain a mixed equilibrium at
@xmath The appearance of a mixed equilibrium in a quantum correlation PD
game is an entirely non-classical feature.

[]

Figure @xmath - @xmath : Invertible and discontinuous function @xmath .

The presence of a mixed equilibrium in the quantum correlation PD gives
rise to an interesting question: is there a Pareto-optimal solution of
@xmath in a quantum correlation PD with some invertible and
discontinuous @xmath -function? No such solution exists for invertible
and continuous @xmath -functions. Also, the @xmath equilibrium in PD
cannot appear in a quantum correlation game played with the function (
5.31 ): one has @xmath which cannot be equal to @xmath when @xmath is
invertible. As a matter of fact, the solution @xmath for PD can be
realized in a quantum correlation PD if one considers @xmath from ( 5.32
) with @xmath :

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

where @xmath , depicted in Fig. ( 5.5 ).

[]

Figure @xmath - @xmath : Invertible and discontinuous function @xmath .

This function satisfies @xmath . Therefore, one has @xmath , which is
the condition for @xmath to be an equilibrium in PD. Cooperation @xmath
will also be an equilibrium in PD if the @xmath -function is defined as

  -- -- -- --------
           (5.34)
  -- -- -- --------

where @xmath . Fig. ( 5.5 ) shows this function.

[]

Figure @xmath - @xmath : Invertible and discontinuous function @xmath .

In both cases ( 5.33 , 5.34 ), the @xmath -function has a discontinuity
at @xmath . With these functions both the pure and mixed classical
equilibria of BoS will also be susceptible to change. The shifts in the
pure equilibria in BoS will be similar to those of PD but the mixed
equilibrium of BoS will move, depending on the location of @xmath .

Another example of an invertible and discontinuous function is given by

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

where @xmath and @xmath and it is drawn in Fig. ( 5.5 ).

[]

Figure @xmath - @xmath : Invertible and discontinuous function @xmath .

With this function the pure classical equilibria @xmath of PD as well as
of BoS remain unaffected because these equilibria require @xmath and the
function is not discontinuous at @xmath . One notices that if the angle
corresponding to a classical equilibrium is @xmath or @xmath , and there
is no discontinuity at @xmath , then the quantum correlation game cannot
change that equilibrium. With the function ( 5.35 ) in both PD or BoS
the pure equilibrium with @xmath corresponds to the angle @xmath where
classical and quantum correlations are different (for @xmath ).
Consequently, the equilibrium @xmath will be shifted and the new
equilibrium depends on the angle @xmath . The mixed equilibrium of BoS
will also be shifted by the function ( 5.35 ). Therefore, one of the
pure equilibria and the mixed equilibrium may shift if the @xmath
-function ( 5.35 ) is chosen. The following function

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

where @xmath and @xmath cannot change the pure equilibrium at @xmath .
However, it can affect the equilibrium @xmath , both in PD and BoS, and
it can shift the mixed equilibrium of BoS. Fig. ( 5.5 ) shows this
function.

[]

Figure @xmath - @xmath : Invertible and discontinuous function @xmath .

##### (@xmath) Non-invertible and discontinuous @xmath-functions

A simple case of a continuous and non-invertible function (cf. Fig, (
5.5 )) is given by

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

Consider a classical pure equilibrium with @xmath . Because @xmath or
@xmath two equilibria with @xmath are generated in the quantum
correlation game, but these coincide and turn out to be same as the
classical ones. Similarly, the function ( 5.37 ) does not shift the pure
classical equilibrium at @xmath . However, if @xmath corresponds to a
mixed equilibrium such that @xmath then in the quantum correlation game,
@xmath will not only shift but will also bifurcate. The resulting values
will differ from @xmath .

[]

Figure @xmath - @xmath : Non-invertible and continuous function @xmath .

We now ask whether the equilibria in a classical correlation game
already (without quantum effects) show a similar sensitivity in the
presence of a non-invertible and continuous @xmath -function like ( 5.37
)? When the players receive the classical pairs of objects the angles
@xmath are mapped to themselves, resulting in the same probability
@xmath , obtained now using the non-invertible and continuous @xmath
-function ( 5.37 ). Therefore, in a classical correlation game played
with the function ( 5.37 ) the bifurcation observed in the quantum
correlation game does not show up, in spite of the fact that there are
two angles associated with one probability.

### 5.6 Discussion

In this chapter, we propose a new approach to the introduction of a
quantum mechanical version of two-player games. One of our main
objectives has been to find a way to respect two constraints when
‘quantizing’: on the one hand, no new moves should emerge in the quantum
game (c1) and, on the other hand, the payoff relations should remain
unchanged (c2). The constraints c1 and c2 have been introduced in the
section @xmath . In this way, we hope to circumvent objections [ 32 ]
which have been raised against the existing procedures [ 9 ] used to
quantize games. It has been pointed out in the literature that new
quantum moves or modified payoff relations do not necessarily indicate a
true quantum character of a game since their emergence can be understood
in terms of a modified classical game. Our intention is to avoid this
type of criticism.

Correlation games are based on payoff relations which are sensitive to
whether the input is anti-correlated classically or quantum
mechanically. The players’ allowed moves are fixed once and for all, and
a setting inspired by EPR-type experiments is used. Alice and Bob are
both free to select a direction in prescribed planes @xmath ;
subsequently they individually measure, on their respective halves of
the supplied system, the value of a dichotomic variable either along the
selected axis or along the @xmath -axis. When playing mixed strategies
they must use probabilities which are related to the angles by a
function @xmath which is made public in the beginning. After many runs
the arbiter establishes the correlations between the measurement
outcomes and rewards the players according to fixed payoff relations
@xmath . The rewards depend only on the numerical values of the
correlations – by definition, they do not make reference to classical or
quantum mechanics.

If the incoming states are classical, correlation games reproduce
classical bimatrix games. The payoffs @xmath and @xmath correspond to
one single game, since both expressions emerge from the same payoff
relation @xmath . If the input consists of quantum mechanical singlet
states, however, the correlations turn quantum and the solutions of the
correlation game change. For example, in a generalized Prisoners’
Dilemma a mixed Nash equilibrium can be found. This is due to an
effective non-linear dependence of the payoff relations on the
probabilities, since the comparison of Eqs. ( 5.14 ) and ( 5.19 ) shows
that ‘quantization’ leads to the substitution

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

As the payoffs of traditional bimatrix games are bi-linear in the
probabilities, it is difficult, if not impossible, to argue that the
quantum features of the quantum correlation game would arise from a
disguised classical game: there is no obvious method to let the payoffs
of a classical matrix game depend non-linearly on the strategies of the
players.

Our analysis of the Prisoners’ Dilemma and the Battle of Sexes as
quantum correlation games shows that, typically, both the structure and
the location of classical Nash equilibria are modified. The location of
the quantum equilibria depends sensitively on the properties of the
function @xmath but, apart from exceptional cases, the modifications are
structurally stable. It is not possible to create any desired type of
solution for a bimatrix game by a smart choice of the function @xmath .

Finally, we would like to comment on the link between correlation games
and Bell’s inequality. In spite of their similarity to an EPR-type
experiment, it is not obvious how correlation games can directly exploit
Bell’s inequality. Actually, violation of the inequality is not crucial
for the emergence of the modifications in the quantum correlation game,
as one can see from the following argument. Consider a correlation game
played on a mixture of quantum mechanical anti-correlated product
states,

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

where the integration is over the unit sphere. The vectors @xmath are of
unit length, and @xmath denote the eigenstates of the spin component
@xmath with eigenvalues @xmath , respectively. The correlations in this
entangled mixture are weaker than for the singlet state @xmath ,

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

The factor @xmath makes a violation of Bell’s inequality impossible.
Nevertheless, a classical bimatrix game is modified as before if @xmath
is chosen as the input state of the correlation game. To put this
observation differently: the payoffs introduced in Eq. ( 5.8 ) depend on
the two correlations @xmath and @xmath only, not on the third one @xmath
which is present in Bell’s inequality.

## Chapter 6 Hidden variables and negative probabilities in quantum
games

### 6.1 Introduction

Quantum mechanical predictions are non-deterministic i.e. the theory
generally does not predict outcome of any measurement with certainty.
Quantum theory merely tells what the probabilities of the outcomes are.
This sometimes leads to the strange situation in which measurements of a
certain property done on two identical systems can give different
answers. The question naturally arises whether there might be some
‘deeper objective reality’ which is hidden beneath quantum mechanics and
which can be described by a more fundamental theory that can always
predict the outcome of each measurement with certainty.

The search for more fundamental theories led physicists to the Hidden
Variable Theories (HVTs) [ 57 ] which assume that the probabilistic
features of quantum mechanical predictions are due to the complicated
random behaviour of a classical substructure. That is, the outcome of
measurements are statistical averages over hidden variables. The
variables are hidden in the sense that we don’t know anything about
them, although no fundamental principle forbids us from knowing them.

In the early 1980s, while pointing to a deep link existing between
hidden variables and probabilistic relations, Fine [ 65 ] observed that
the existence of a deterministic hidden variables model is strictly
equivalent to the existence of a joint probability distribution function
for the four observables involved in a correlation experiment, like the
EPR-type experiment. The joint probability is such that it returns the
probabilities of the experiments as marginals.

Apart from Fine’s indication ¹ ¹ 1 In the later part of his paper Fine [
65 ] commented “ hidden variables and Bell inequalities are all about
imposing requirements to make well defined precisely those probability
distributions for non-commuting observables whose rejection is the very
essence of quantum mechanics ”. of the close relationship between hidden
variables models and the existence of joint probability distributions,
there is also another viewpoint on the EPR paradox. During recent years,
some authors [ 43 , 44 , 42 ] have provided explicit proofs showing how
the assumption of hidden variables forces certain probability measures
(involved in the EPR paradox) to assume negative values. Negative
probability is indeed a stark departure from Kolmogorov’s axioms of
probability, invoked in an attempt to explain the EPR paradox.

Interestingly, even negative probability is not the only possible way in
which quantum mechanics has been shown to depart from the classical
world. Atkinson [ 76 ] has identified two other ways in which quantum
mechanics can depart from Kolmogorov’s axioms:

1.  By allowing that @xmath although @xmath .

2.  By allowing @xmath although @xmath and @xmath are physically
    independent.

The first way was proclaimed by Dirac and Feynman as the most striking
feature of quantum mechanics [ 76 ] . In [ 114 ] Atkinson discussed the
second way.

Historically, Mückenheim [ 115 ] used negative probability in 1982 in an
attempt to resolve the EPR paradox. It is, of course, impossible to give
physical meaning to a negative probability within relative frequency
interpretation of probability. But negative probabilities always come
together with positive probabilities, to which they are added in such a
way that final predictions are always positive in the relative-frequency
interpretation of probability. Quoting Mückenheim [ 116 ] : “
Kolmogorov’s axiom may hold or not; the probability for the existence of
negative probabilities is not negative. ” Mückenheim is not alone in
this approach to the EPR paradox. For example, Feynman [ 40 , 41 ] once
cleverly anticipated [ 44 , 42 ] that “ The only difference between the
classical and quantum cases is that in the former we assume that the
probabilities are positive-definite. ” For obvious reasons, this
particular approach to resolve the EPR paradox is taken [ 117 ] to be “
as unattractive as all others.” .

In the present chapter we adapt the positive attitude towards negative
probabilities by observing that, in spite of their unattractiveness,
they seem to have undisputed value in terms of providing an indication
as to what can perhaps be taken as the “true quantum character” in
certain quantum mechanical experiments. Secondly, the negative
probabilities, though labelled ‘unattractive’, seem to have the
potential to provide alternative (and perhaps much shorter) routes to
the construction of simple examples of quantum games. These
constructions, designed for the physical implementation and realization
of quantum games, will, of course, again have the EPR experiments as
their underlying physical structure.

The approach towards quantum games which is developed in this chapter
can be divided into two steps. In the first step elementary probability
theory is used to analyze a hypothetical physical implementation of a
two-player game. The implementation is motivated by, and has close
similarities with, the experimental set-up of the EPR experiments. From
an alternative viewpoint this approach can also be taken as a procedure
that re-defines the classical game in a way that justifies and
facilitates the next step in the present approach. In the second step
the peculiar probabilities arising out of the EPR-type experiments are
introduced in order to see their resulting effects on players’ payoff
functions and on the solutions of the game.

Apart from being a short-cut towards the demonstration and construction
of simple quantum games, this approach seems to us to be presently
needed both in game theory and in economics [ 104 ] . Recent years have
witnessed serious efforts to introduce the methods and notation of
quantum mechanics into these domains. In our view, in spite of these
developments, it remains a fact that, in these domains, the concepts of
a wavefunction, of the ket bra notation, and of Hermitian operators
still have an “alien” appearance, with quantum mechanics being believed
to be their only rightful place. The present chapter tries to fill this
gap by looking at how quantum games can also be understood by using the
peculiar probabilities that appear in certain well-known quantum
mechanical experiments, without recourse to the mathematical tools of
quantum mechanics. In other words, we try to show how the unusual
probabilities arising in the EPR paradox have a potential to leave their
mark on game theory.

We compare the playing of a two-player game with the setting of EPR-type
experiments in order to motivate a four-coin physical implementation of
the game. We then develop such a hypothetical physical implementation.
Building on this construction we look at how the game is affected when,
instead of four coins, two correlated particles are used to play the
game.

### 6.2 Physical implementation of playing a two-player game

We consider a two-player two-strategy non-cooperative game that is given
as a bimatrix. Two players Alice and Bob are not allowed to communicate
and each player has to go for one of the two available strategies. A
usual physical implementation of this game consists of giving two coins
to Alice and Bob, each receiving one. Both receive the coin in a “head”
state. Each player plays his/her strategy, which consists of
flipping/not flopping the coin. The players then return their coins to a
referee. The referee observes the coins and rewards the players
according to the strategies that they have played and the game under
consideration.

Consider now the well-known setting of EPR experiments. Once again,
Alice and Bob are spatially separated and are unable to communicate with
each other. Both receive one half of a pair of particles that originate
from a common source. In an individual run both choose one from the two
options (strategies) available to him/her. The strategies are usually
two directions in space along which measurements can be made. Each
measurement generates @xmath or @xmath as the outcome, which can be
associated with the head and tail states of a coin, respectively.
Experimental results are recorded for a large number of individual runs
of the experiment.

Apparent similarities between the two-coin physical implementation of a
two-player game and EPR experiments can immediately be noticed. The
similarities hint at the possibility of using the EPR experiments to
play two-player games. However, before moving further along that
direction, we can make the following observations:

1.  In a two-coin implementation of a bimatrix game a player knows the
    head or tail state of his/her coin after he/she has played his/her
    strategy.

2.  In an EPR experiment when a player decides his/her strategy as one
    of two available directions along which a measurement is to be made,
    he/she does not know whether the measurement is going to result in
    @xmath or @xmath until the measurement has actually been made.

This shows that a two-coin physical implementation of a two-player game
is not strictly analogous to an EPR experiment. In an individual run of
the EPR experiment each player has to chose from one of two available
directions. After the player makes a choice between the two directions
the measurement generates @xmath or @xmath as outcome. This suggests a
four-coin implementation of the game.

### 6.3 Two-player games with four coins

A two-player game can also be played using four coins instead of the two
used in the game described above. A procedure that physically implements
the game with four coins is suggested as follows. Its motivation comes
from the EPR experiments and it serves to make possible, in the next
step, a smoother transition towards a situation in which the same game
is played using those experiments.

The players Alice and Bob are given two coins each. It is not known, and
it does not matter, whether the given coins are in head or tail states.
Before the game starts the referee announces that a player’s strategy is
to choose one out of the two coins in his/her possession. After playing
their strategies, the players give the two chosen coins, representing
their strategies, to the referee. The referee tosses both the coins
together and records the outcomes. The tossing of the coins is repeated
a large number of times, while each player plays his/her move each time
he/she is asked to choose one of the two coins in his/her possession.
After a large number of individual runs the referee rewards the players
according to the strategies they have played and the probability
distributions followed by the four coins during their tossing.

After stating the general idea, we consider in the following an example
of a symmetric game.

  -- -- -- -------
           (6.1)
  -- -- -- -------

where @xmath , @xmath , @xmath and @xmath are the players’ strategies.
Entries in parentheses are Alice’s and Bob’s payoffs, respectively.

We want to physically implement the game ( 6.1 ) using repeated tossing
of four coins which follows the following probability distribution

  -- -- -- -------
           (6.2)
  -- -- -- -------

where, for example, @xmath is Alice’s pure strategy to “always select
the coin @xmath ” etc. The pure strategies @xmath and @xmath can be
interpreted similarly. Also, @xmath Head and @xmath Tail and, for
obvious reasons, we have

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

In the construction of the four-coin statistics ( 6.2 ) the following
points should be taken into consideration.

1.  The statistics ( 6.2 ) may convey the impression that in an
    individual run both players forward both of their coins to the
    referee, who then tosses the four coins together. In fact, in an
    individual run the referee tosses only two coins. The statistics (
    6.2 ) are generated under the assumption that there is randomness
    involved in the players’ strategies to go for one or the other coin.

2.  Associated with the above impression is the fact that in every
    individual run the statistics ( 6.2 ) assign head or tail states to
    the two coins that have not been tossed. Thus, in each individual
    run two tosses are counterfactual [ 39 ] .

With reference to our coin game, being counterfactual means that two
coins out of four are not tossed in each individual turn, but these
untossed coins are still assigned head or tail states in the
mathematical steps used in the derivation of Bell-CHSH inequality. This
assignment is often justified by an argument which goes under the label
of realism .

To play the game ( 6.1 ) with four-coin statistics ( 6.2 ), we assume
that the referee uses the following recipe ² ² 2 The recipe ( 6.4 ) is
not unique and others may be suggested. Any recipe is justified if it is
able to reproduce the game under consideration within the description of
the statistical experiment involved. to reward the players:

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

Here @xmath , for example, is Alice’s payoff when she plays @xmath and
Bob plays @xmath . The corresponding payoff expressions for Bob can be
found by the transformation @xmath in Eqs. ( 6.4 ). The recipe, of
course, makes sense if repeated tosses are made with four coins. @xmath
and @xmath are taken as players’ pure strategies; a mixed strategy for
Alice, for example, is a convex linear combination of @xmath and @xmath
.

We now find constraints on the four-coin statistics ( 6.2 ) such that
each equation in ( 6.4 ) represents a mixed strategy payoff function for
the bimatrix game ( 6.1 ) and that can be written in a bi-linear form.
To allow this interpretation for the payoff functions ( 6.4 ) four
probabilities @xmath @xmath @xmath and @xmath are required that can give
a bi-linear representation to the payoff functions ( 6.4 ) i.e.

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

This then allows us to make the association

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

where @xmath and @xmath are the probabilities of heads for coins @xmath
and @xmath , respectively. If a consistent set of these four
probabilities can be found, as is always the case, then each equation in
( 6.4 ) can be interpreted in terms of a mixed strategy game between the
two players. Thus the four pairs

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

represent the four possible situations that may result when each player
has two strategies to choose from. For example, the strategy pair @xmath
is associated with the pair @xmath and it corresponds to the mixed
strategy game given as

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

In this game Alice plays @xmath with probability of heads @xmath , and
Bob plays @xmath with probability of heads @xmath . The other equations
in ( 6.5 ) can be given similar interpretation.

We now find constraints on the four-coin statistics ( 6.2 ) that make
the payoff functions ( 6.4 ) identical to the bi-linear payoff functions
( 6.5 ), for any real numbers @xmath and @xmath . A comparison of these
equations shows that this happens when @xmath and @xmath depend on
@xmath , for @xmath , as follows:

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

The probabilities @xmath and @xmath can be extracted from ( 6.9 ) as
follows:

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

provided that the @xmath satisfy the relations

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

With the defining relations ( 6.10 ), and the constraints ( 6.11 ) on
the four-coin statistics, each pair in @xmath and @xmath has an
interpretation as a mixed strategy game. The correspondence ( 6.6 )
means that, for example, Alice’s payoff functions become

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

Now, suppose that @xmath is a Nash equilibrium (NE) i.e.

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

Using Eqs. ( 6.5 ) one gets

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

Consider the game of Prisoners’ Dilemma which is produced when @xmath in
the matrix ( 6.1 ). We select our first representation of PD by taking

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

and the inequalities ( 6.14 ) are then reduced to

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

Now from ( 6.14 ) the pair @xmath is a NE when both inequalities in (
6.16 ) are true for all @xmath . Because @xmath and @xmath , @xmath is
the equilibrium. In the present set-up, to play PD this equilibrium
appears if, apart from the constraints of Eqs. ( 6.10 , 6.11 ), we also
have

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

which are other constraints on the four-coins statistics ( 6.2 ) to hold
true if the PD produces the NE @xmath .

The above analysis can be reproduced for other probability pairs in (
6.7 ). For example, when @xmath is NE i.e.

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

we again get @xmath . However, the relations ( 6.10 ) now say that it
will exist as a NE when

  -- -------- -- --------
     @xmath      (6.19)
  -- -------- -- --------

which should, of course, be true along with the relations ( 6.11 ). That
is, in order to reproduce a particular NE in the two-player game the
probabilities of heads of the four coins representing the game need to
be fixed. Also, from the bi-linear payoff functions ( 6.5 ) it is clear
that at the equilibria @xmath and @xmath the reward for both the players
is @xmath .

Summarizing, we have shown that when the four-coin statistics ( 6.2 )
satisfy the constraints of Eqs. ( 6.3 , 6.11 ), the payoff functions (
6.4 ) can be interpreted in terms of a mixed strategy version of a
bimatrix game. In this setting four strategies @xmath and @xmath
available to the players are associated with the probabilities @xmath
and @xmath , respectively. This association allows us to interpret the
payoff recipe of Eq. ( 6.4 ) in terms of a mixed strategy game. We
showed that when @xmath and @xmath are expressed in terms of the
probabilities @xmath for @xmath (as is the case in the Eqs. ( 6.10 ))
the bi-linear payoff functions ( 6.5 ) become identical to the payoff
functions ( 6.4 ). This procedure is designed to re-express the playing
of a two-player game with four coins in such a way that choosing which
coin to toss is part of a player’s strategy.

### 6.4 Games with perfectly correlated particles

The re-expression of the playing of a two-player game in terms of a
four-coin tossing experiment opens the way to seeing what happens when
the four-coin statistics become correlated, particularly what if the
correlations go beyond what is achievable with the so-called classical
‘coins’.

At present there exists general agreement in the quantum physics
community that the EPR-type experiments, when performed on correlated
pairs of particles, violate the predictions of LHV models. Negative
probabilities are found to emerge when certain LHV models are forced to
predict the experimental outcomes of EPR-type experiments. For example,
Han, Hwang and Koh [ 43 ] showed the need for negative probabilities
when explicit solutions for probability measures can reproduce quantum
mechanical predictions for some spin-measurement directions and for all
entangled states. In their analysis a special basis is used to show the
appearance of negative probabilities for a class of LHV models.

Rothman and Sudarshan [ 42 ] demonstrated that quantum mechanics does
predict a set of probabilities that violate the Bell-CHSH inequality.
The predicted probabilities, however, are not positive-definite but are
physically meaningful in that they give the usual quantum-mechanical
predictions in physical situations. Rothman and Sudarshan observed that
all derivations of Bell’s inequalities assume that LHV theories produce
a set of positive-definite probabilities for detecting a particle with a
given spin orientation.

Using a similar approach, Cereceda [ 44 ] proved independently the
necessity of negative probabilities in all instances where the
predictions of the LHV model violate the Bell-CHSH inequality.
Interestingly, Cereceda’s proof does not rely on any particular basis
states or measurement directions. In the concluding section of his paper
Cereceda analyzes the case of pairs of particles that have perfect
correlation between them and proceeds to show the necessity of negative
probabilities for those pairs.

The necessity of involving negative probability measures in order to
explain the experimental outcomes in EPR-type experiments motivates
questions about the consequences that these may have for the solutions
of a game which is physically implemented using such experiments. This
question can be expressed as follows. What happens to the players’
payoff functions and the solutions of a game that is physically
implemented by using pairs of perfectly correlated particles? It seems
quite reasonable to demand that when the predictions of an LHV model
agree with the Bell-CHSH inequality then the game attains a classical
interpretation.

One clear advantage of the above approach towards quantum games appears
to be that it is possible to see, without using the machinery of quantum
mechanics, how game-theoretical solutions are affected when a game is
physically implemented using quantum-mechanically correlated pairs of
particles.

We follow Cereceda’s notation [ 44 ] for probabilities in EPR-type
experiments which are designed to test Bell-CHSH inequality. Two
correlated particles @xmath and @xmath are emitted in opposite
directions from a common source. Afterwards, each of the particles
enters its own measuring apparatus which can measure either one of two
different physical variables at a time. We denote these variables @xmath
or @xmath for particle @xmath and @xmath or @xmath for particle @xmath .
These variables can take possible values of @xmath and @xmath . The
source emits a very large number of particle pairs.

To describe this experiment Cereceda [ 44 ] considers a deterministic
hidden variable model as follows. The model assumes that there exists a
hidden variable @xmath for every pair of particles emitted by the
source. @xmath has a domain of variation @xmath and it determines
locally (for example, at the common source) the response of the particle
to each of the measurements to which it can be subjected. It is possible
to partition the set of all @xmath into @xmath disjoint subsets @xmath
(with respect to a probability measure @xmath ) according to the
outcomes of the four possible measurements, @xmath or @xmath for
particle @xmath and @xmath or @xmath for particle @xmath . Table @xmath
is reproduced from [ 44 ] . It shows the @xmath rows characterizing the
subsets @xmath . The @xmath -th row gives the outcome of different
measurements when the particle pair is described by a hidden variable
pertaining to the subset @xmath .

Table @xmath : The set @xmath is partitioned into @xmath possible
subsets. The hidden variables in each subset @xmath uniquely determine
the outcomes for each of the four possible single measurements @xmath
and @xmath . The table is reproduced from Ref. [ 44 ] .

  -- -- --
        
  -- -- --

The probabilities @xmath are given below in obvious notation [ 44 ] .

  -- -------- -------- -- --------
     @xmath   @xmath      (6.20)
     @xmath   @xmath      (6.21)
     @xmath   @xmath      (6.22)
     @xmath   @xmath      (6.23)
     @xmath   @xmath      (6.24)
     @xmath   @xmath      (6.25)
     @xmath   @xmath      (6.26)
     @xmath   @xmath      (6.27)
     @xmath   @xmath      (6.28)
     @xmath   @xmath      (6.29)
     @xmath   @xmath      (6.30)
     @xmath   @xmath      (6.31)
     @xmath   @xmath      (6.32)
     @xmath   @xmath      (6.33)
     @xmath   @xmath      (6.34)
     @xmath   @xmath      (6.35)
  -- -------- -------- -- --------

Combining Eqs. ( 6.3 ) with Table @xmath gives

  -- -------- -- --------
     @xmath      (6.36)
  -- -------- -- --------

Continuing with Cereceda’s description [ 44 ] , an example is now
considered. Suppose that the particle pair is described by a given
@xmath ; then the particles must behave as follows. If @xmath is
measured on particle @xmath the result will be @xmath , if @xmath is
measured on particle @xmath the result will be @xmath , if @xmath is
measured on particle @xmath the result will be @xmath , if @xmath is
measured on particle @xmath the result will be @xmath . Also for each of
the plans the results of measurements made on particle @xmath are
independent of the results of measurements made on particle @xmath .

For perfectly correlated particles two of the probabilities @xmath and
@xmath can be set equal to zero. Physically this means that the results
for the joint measurement of two observables, one for each particle,
must both be either @xmath or @xmath . From a physical point of view, it
is reasonable to suppose that, for the case in which @xmath and @xmath ,
the probability measures @xmath and @xmath also vanish. This can be
verified from Eqs. ( 6.21 , 6.22 ). If this is not the case then joint
detection events will be generated by the LHV model which do not happen,
according to the assumptions made. Cereceda showed that in this case,
when the predictions of the LHV model violate the Bell-CHSH inequality,
the negativity of either @xmath or @xmath can be proved.

We assume now that the probabilities @xmath appearing in Eqs. ( 6.4 )
correspond to the LHV model of the EPR-type experiments performed on
perfectly correlated particles to test the Bell-CHSH inequality. As is
the case with the four-coin tossing experiment, the payoff functions (
6.4 ) can be interpreted as bi-linear payoff functions. To do this we
use the Eqs. ( 6.10 , 6.11 ) to get

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

But @xmath , so that from the first Eq. of ( 6.9 ) we have @xmath which
gives @xmath or @xmath because @xmath from ( 6.37 ). We select ³ ³ 3
Selecting @xmath makes @xmath because @xmath . It will result in
different but analogous expressions for @xmath and @xmath given in terms
of @xmath without affecting the present argument. @xmath . Now, from
Eqs. ( 6.24 , 6.25 ) we have @xmath and because @xmath from Eq. ( 6.36 )
and @xmath for @xmath we get

  -- -------- -- --------
     @xmath      (6.38)
  -- -------- -- --------

With these relations the bi-linear payoff functions ( 6.5 ) are written
as

  -- -------- -------- -- --------
     @xmath   @xmath      (6.39)
     @xmath   @xmath      (6.40)
     @xmath   @xmath      (6.41)
  -- -------- -------- -- --------

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

Each of the correlated payoff functions ( 6.40 , 6.41 , 6.42 ) can be
split into two parts i.e.

  -- -------- -- --------
     @xmath      (6.43)
  -- -------- -- --------

where

  -- -------- -------- -- --------
     @xmath   @xmath      (6.44)
     @xmath   @xmath      (6.45)
     @xmath   @xmath      (6.46)
     @xmath   @xmath      (6.47)
  -- -------- -------- -- --------

  -- -------- -- --------
     @xmath      (6.48)
  -- -------- -- --------

  -- -------- -- --------
     @xmath      (6.49)
  -- -------- -- --------

The significance of this splitting is that components @xmath @xmath and
@xmath of Alice’s payoffs in Eqs. ( 6.43 ) become zero when the
predictions of the LHV model agree with the Bell-CHSH inequality. Cheon
and Tsutsui [ 99 ] have also shown a similar splitting, using correlated
payoff operators whose expectation values are the players’ payoffs.

Consider again the PD with the selection of the constants given in (
6.15 ). Let the game be played using perfectly correlated particles, for
which substitutions can be made from ( 6.38 ) into the Nash equilibrium
condition ( 6.16 ). This gives

  -- -------- -- --------
     @xmath      (6.50)
  -- -------- -- --------

where

  -- -------- -------- -- --------
     @xmath   @xmath      (6.51)
     @xmath   @xmath      (6.52)
  -- -------- -------- -- --------

It can be noticed that:

-   The predictions of the LHV model agree with the Bell-CHSH
    inequality. It makes @xmath for all @xmath . Combining it with (
    6.38 ), i.e. @xmath gives

      -- -------- -- --------
         @xmath      (6.53)
      -- -------- -- --------

so that @xmath and @xmath in ( 6.51 , 6.52 ) are reduced to

  -- -------- -- --------
     @xmath      (6.54)
  -- -------- -- --------

-   The requirement @xmath says that when the predictions of the LHV
    model agree with the Bell-CHSH inequality then the pair @xmath is a
    NE. Eq. ( 6.54 ) gives

  -- -------- -- --------
     @xmath      (6.55)
  -- -------- -- --------

Before proceeding with a further question we make following
observations:

1.  Eqs. ( 6.20 ) to ( 6.35 ) give the probabilities @xmath in terms of
    @xmath , for @xmath , corresponding to the EPR-type experiments.
    These probabilities satisfy the constraints ( 6.11 ) which emerge
    when Eqs. ( 6.4 ) are interpreted in terms of bi-linear payoffs of
    Eqs. ( 6.5 ).

2.  The expressions ( 6.38 ) for @xmath and @xmath are obtained from the
    corresponding expressions for the coin tossing case ( 6.10 ), while
    taking into consideration the constraints on the probabilities for
    perfectly correlated particles.

3.  The Eqs. ( 6.53 , 6.55 ) together make @xmath in the definitions (
    6.51 , 6.52 ). These definitions correspond to the representation (
    6.15 ) of PD, for which the constraints ( 6.17 ) should be true in
    the case that @xmath is a NE when the game is played with coins. It
    is observed that both @xmath and @xmath become zero from the
    definitions of @xmath in terms of @xmath given in Table @xmath ,
    when Eqs. ( 6.53 , 6.55 ) are both true. It means that when PD gives
    @xmath as an equilibrium the constraints on the probabilities become
    identical in the following two cases:

    a) The game is played using repeated tosses with four coins.

    b) The game is played with perfectly correlated particles such that
    the predictions of the LHV model agree with the Bell-CHSH
    inequality.

Two-player games other than PD, presumably with different Nash
equilibria, would give rise to different but analogous constraints on
the probabilities @xmath and @xmath . In the light of these observations
the following question immediately arises. What happens to the Nash
conditions ( 6.50 ) when the predictions of the LHV model disagree with
the Bell-CHSH inequality? To answer this question we consider the Nash
conditions ( 6.50 ) with a substitution from ( 6.55 ), thus obtaining

  -- -------- -- --------
     @xmath      (6.56)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.57)
  -- -------- -- --------

We recall that in Cereceda’s analysis @xmath can take a negative value
when the predictions of the LHV model disagree with the Bell-CHSH
inequality. Both @xmath and @xmath in ( 6.56 ) remain negative whether
@xmath is positive or negative. Similarly, both @xmath and @xmath remain
positive whether @xmath is positive or negative. Therefore, the Nash
conditions ( 6.56 ), which correspond to the representation ( 6.15 ) of
PD, are not violated whether the predictions of the LHV model agree or
disagree with the Bell-CHSH inequality.

The players’ payoffs at the equilibrium @xmath can be found from Eq. (
6.49 ) as

  -- -------- -- --------
     @xmath      (6.58)
  -- -------- -- --------

where @xmath and @xmath are found from ( 6.57 ). For example, with the
PD representation ( 6.15 ), the players’ payoffs are obtained from Eqs.
( 6.48 , 6.49 ) as

  -- -------- -- --------
     @xmath      (6.59)
  -- -------- -- --------

The NE @xmath in Eqs. ( 6.57 ) becomes a solution when the predictions
of LHV model disagree with the Bell-CHSH inequality. Its defining
inequalities ( 6.56 ) show that the NE exists even when either @xmath or
@xmath take negative values, which can be realized when @xmath is
negative. Accordingly, the NE in the PD representation ( 6.15 ) can be
‘displaced’ when the predictions of LHV model disagree with the
Bell-CHSH inequality. Here ‘displacement’ means that either @xmath or
@xmath can take negative values. However, this extra freedom of assuming
negative values does not disqualify @xmath from existing as a NE. From
Eq. ( 6.59 ) it can be seen that @xmath and @xmath cannot be greater
than @xmath when both @xmath and @xmath take negative values.

We now show that this may not be the case with another representation of
PD. That is, the extra freedom for @xmath and @xmath to take negative
values, which is granted when the predictions of the LHV model disagree
with Bell-CHSH inequality, leads to the disqualification of @xmath as a
possible NE in that representation of PD.

Consider the PD again, but with a slightly different value assigned to
the constant @xmath of the game [ 99 ] :

  -- -------- -- --------
     @xmath      (6.60)
  -- -------- -- --------

In this representation the inequalities ( 6.14 ) are reduced to

  -- -------- -- --------
     @xmath      (6.61)
  -- -------- -- --------

The substitution of @xmath from ( 6.38 ) and then the addition of both
the inequalities gives

  -- -------- -- --------
     @xmath      (6.62)
  -- -------- -- --------

Suppose that the predictions of the LHV model disagree the Bell-CHSH
inequality i.e. both @xmath and @xmath are to be replaced by @xmath and
@xmath in ( 6.62 ):

  -- -------- -- --------
     @xmath      (6.63)
  -- -------- -- --------

where @xmath and @xmath are given by ( 6.57 ). Interestingly, it is
observed that the inequality ( 6.63 ) is violated if @xmath and the NE
of Eq. ( 6.57 ) then ceases to exist. Of course, this applies to the
representation of PD given by ( 6.60 ). The players’ payoffs are given
as

  -- -------- -- --------
     @xmath      (6.64)
  -- -------- -- --------

As it is the case with the first representation of PD, the payoffs
@xmath cannot be greater than @xmath when both @xmath and @xmath take
negative values.

This shows that in the physical implementation of PD, using perfectly
correlated particles, the two representations ( 6.15 , 6.60 ) behave
differently from each other. In representation ( 6.15 ) the disagreement
of the predictions of the LHV model with the Bell-CHSH inequality leads
to displacement of the NE @xmath such that @xmath and @xmath can assume
negative values. Displacement occurs but @xmath continues to exist as a
NE.

On the other hand, in the representation ( 6.60 ) the disagreement of
the predictions of the LHV model with the Bell-CHSH inequality leads to
the disappearance of the NE @xmath when both @xmath and @xmath assume
negative values and their sum becomes less than @xmath .

A ‘minimalist’ interpretation of the present approach can also be given
as follows. Constraints ( 6.11 , 6.17 ) are required on the four-coin
statistics ( 6.2 ) to make @xmath a NE when the PD is played in
representation ( 6.15 ) with repeated tosses of four coins. When the
same game is played with pairs of perfectly correlated particles and the
predictions of the LHV model disagree with the Bell-CHSH inequality, we
can have @xmath or @xmath becoming negative, which contradicts ( 6.17 ).
If it affects the solution of the game then one can say that this is
because of the change in the underlying probabilities of our physical
system. The present approach can be defended by observing that it is not
the question of changing the underlying probabilities which has been
addressed here. On the other hand, we have introduced a new procedure
which addresses the problem of finding the true ‘quantum content’ of a
quantum game in the following two steps:

1.  For perfectly correlated particles, developing an association such
    that the results are guaranteed to be those of the classical game
    when the predictions of the LHV model agree with the Bell-CHSH
    inequality.

2.  With the above association retained, finding how solutions of a game
    are affected when the predictions of the LHV model disagree with the
    Bell-CHSH inequality.

When these steps are taken into consideration, the possibility of the
construction of a classical game which is able to reproduce the overall
effect of a quantum game cannot be taken to support the argument that
quantum games have no quantum content [ 28 ] . In our opinion, the
question which quantum game theory asks is: How the quantum mechanical
aspects of a physical system can leave their mark on game-theoretic
solutions? The possibility of a classical construction of a quantum game
does not make this question disappear.

## Chapter 7 Summary and Future Perspectives

Using entanglement to obtain new solutions of games has come out to be
the general theme of the new field of quantum game theory. The
Einstein-Podolsky-Rosen (EPR) paradox occupies the central position in
the phenomenon of quantum entanglement. The paradox motivated the EPR
experiments which confirmed the departure of quantum mechanical
predictions from the hidden variable models. These experiments are
widely believed in the quantum physics community to provide the
strongest evidence of the ‘true quantum character’, even though what
lessons such experiments teach about local realism continues to attract
active debate.

Both of the two suggestions developed in chapters 5 and 6 use EPR-type
experiments to play quantum games. These suggestions, however, are
distinct from each another in the following sense. Firstly, the
suggestions use two different definitions of players’ strategies.
Secondly, these suggestions are motivated by two different expressions
of the true quantum character, even though both suggestions use EPR
experiments for their physical implementation. The suggestion of chapter
5 exploits the explicitly different classical and quantum correlations
for anti-correlated pairs of objects. The suggestion of the chapter 6
exploits the recently reported results that some LHV models from the
outcome of EPR experiments predict the assignment of negative values to
certain probability measures that are involved in such experiments.

In chapter 5 a quantization scheme for two-player games is proposed,
using different mathematical forms of the correlations corresponding to
entangled and product states, respectively, for anti-correlated pairs of
objects. The set-up uses EPR-type experiments such that players’
strategies are defined by unit vectors in the @xmath - @xmath and @xmath
- @xmath planes. Experimental measurements are performed in EPR-type
setting along the players’ two chosen directions and the @xmath -axis.
Players’ strategies, represented by unit vectors, appear in the
experimentally measured correlations, allowing players’ strategies to be
obtained from the experimental outcomes. In effect, this opens the way
to re-express the playing of a two-player game in terms of the
experimental outcomes of EPR-type experiments. In such a re-expression,
the explicit form of the payoff relations remain exactly the same,
whether the game is played using classical or quantum correlated pairs
of objects. Also, in both the classical and quantum version of a game
the players’ strategies remain the same, i.e. rotations given to unit
vectors. The set-up of a correlation game makes it very difficult to
argue that the quantum version of a game consists of ‘another’ classical
game.

The following steps can be identified in the set-up for defining a
correlation game:

1.  Making available a large number of anti-correlated objects, such
    that each player has access to one half of the objects.

2.  Devise the players’ strategies consisting of the rotations which
    they may give to their respective unit vectors @xmath and @xmath
    residing in the @xmath - @xmath and @xmath - @xmath planes,
    respectively. The @xmath -axis is shared between the players as the
    common direction.

3.  Referee uses an invertible function @xmath that translates players’
    rotations to probabilities @xmath .

4.  After the players have played their strategies, the referee measures
    the correlation @xmath and @xmath .

5.  To give a meaning to the experimental results the referee uses a
    function @xmath that translates the experimentally measured
    correlations into angles. This function is set to be @xmath ,
    independently of the nature of any correlations which may exist
    between the anti-correlated pairs.

6.  The referee uses the function @xmath to get new probabilities @xmath
    , which now depend on the correlations.

7.  Referee finds payoffs from the new probabilities @xmath by using the
    classical payoff relations for a two-player game.

Clearly when the players receive classically correlated objects the step
S5 becomes an identity operation and @xmath , which means that the
correlation game will produce payoffs identical to those in a classical
matrix game. For quantum correlated objects we have @xmath and the
players’ payoffs do not remain classical. The question of interest now
becomes whether the new payoffs can lead to new game-theoretical
equilibria. We showed that this indeed happens for the game of
Prisoners’ Dilemma. We found that the new equilibria depend sensitively
not only on the correlations but also on the form of the invertible
@xmath -function, which is used in playing the game. A careful selection
of the @xmath -function can result in some equilibria in a game that has
no classical analogue.

We now look at the quantization procedure suggested for a correlation
game as developed in this thesis, from the viewpoint of what
quantization means for a given classical system. For such a system in
some specific state @xmath , a physical quantity can be associated with
a (Borel) function ¹ ¹ 1 A Borel function is measurable function, with
respect to the Borel @xmath -algebras, from one topological space to
another. @xmath , where @xmath is the set of real numbers.
‘Quantization’ can then be viewed [ 119 ] as a map @xmath associating to
each such function @xmath a self-adjoint operator @xmath on the quantum
state space @xmath (Hilbert space). A quantum game can then be viewed as
a triple @xmath where @xmath is a quantum state in @xmath , @xmath is a
self-adjoint operator and @xmath is a function from the spectrum of
@xmath to @xmath . That is, the function @xmath determines the payoffs
in the quantum game.

Within this view of quantization a triple @xmath can be associated to a
quantum correlation game proposed in chapter 5 as follows. A classical
correlation game redefines a classical game using EPR-type experiments.
The quantum correlation game retains the essential structure of the
corresponding classical correlation game, except that:

1.  the state of an anti-correlated pair is in Hilbert space @xmath

2.  the correlations @xmath are obtained as eigenvalues of self-adjoint
    operators

Thus in a quantum correlation game the step S5 finds the correlations
@xmath as eigenvalues of self-adjoint operators. All the other steps
remain the same both for classical and quantum correlation games. It
leads to the players obtaining payoffs, which are different from those
of the classical payoffs, when the pairs of objects they receive are
quantum correlated. Essentially this is because in both the classical
and quantum games the function @xmath is used to find angles from their
experimentally determined correlations @xmath . The function guarantees
that players are rewarded classically whenever the correlations @xmath
become classical, because then @xmath become identical to @xmath . It is
to be noticed that the function @xmath , mapping correlations into
payoffs, remains the same for both the classical and quantum correlation
games.

A possible extension of the proposal of chapter 5 is to the case in
which a player’s strategy involves choosing any direction in space,
instead of one which is confined to the @xmath - @xmath or @xmath -
@xmath planes. That is, with players having freedom on their choice of
directions, the payoffs of a correlation game are defined in such a way
that they become sensitive to a violation of Bell’s inequality. In this
case, the construction would ensure that the game involves non-classical
probabilities, which are impossible to obtain by any classical game.

It appears that three-player games can be more appropriate for the
proposed extension of correlation games. For example, consider three
players @xmath and @xmath , whose strategies are given by the unit
vectors @xmath and @xmath , respectively. Let a
Greenberger-Horne-Zeilinger (GHZ) state:

  -- -- -- -------
           (7.1)
  -- -- -- -------

be shared among the players, where @xmath is the @xmath -th state of the
@xmath -th qubit. Each player measures the dichotomic observable @xmath
where @xmath and @xmath is a vector, the components of which are the
standard Pauli matrices. The family of observables @xmath covers all
possible dichotomic observables for a qubit system. Kaszlikowski and
Żukowski [ 120 ] have reported that the probability of obtaining the
result @xmath for the player @xmath when he plays the strategy @xmath ,
the result @xmath for the player @xmath , when she plays the strategy
@xmath and the result @xmath for the player @xmath when she plays the
strategy @xmath is equal to

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

where @xmath , @xmath , @xmath are components of vectors @xmath and
where the nonzero elements of the tensor @xmath are @xmath @xmath @xmath
@xmath . Now, from Eq. ( 7.2 ) it can be observed that in the absence of
three-qubit correlations the third components of the players’ strategies
can be expressed in terms of the experimentally measured probabilities
on the left of ( 7.2 ) corresponding to a selection of values for the
triples @xmath . Assume that a classical game is re-expressed so that
the players’ strategies are the third components of the unit vectors
which they chose and their payoffs are functions of their strategies and
of the experimental probabilities on the left of ( 7.2 ). Such a
re-expression will then allow the three qubit correlations to reveal
themselves in the solutions of the game when the game is played with a
GHZ state ( 7.1 ) of three qubits. Analysis along these lines seems to
be a natural extension of the approach developed in chapter 5 . It
appears that this extension will be free from the weakness of the
proposal made in the chapter 5 , namely that solutions different from
classical ones can emerge even when input states do not violate the Bell
inequality. This feature can be regarded as a weakness, because the
emergence of a completely classical game when input states do not
violate the Bell inequality is a natural requirement.

In contrast to defining strategies in terms of directions, a different
definition of strategy is adopted in chapter 6 . The argument derives
from the reported results that, when perfect correlations exist between
the two particles that are forwarded to the two players, the violation
of the Bell-CHSH inequality by the predictions of a class of LHV models
forces certain probability measures to take negative values. We
investigated how can this affects the solution of a two-player game
which is physically implemented using an EPR-type set-up. To establish
better comparison with EPR-type experiments, a hypothetical physical
implementation of a two-player game is developed that uses repeated
tosses with four coins. This opens the way to directly incorporate the
peculiar probabilities which are involved in the EPR-type experiments
designed to test the Bell-CHSH inequality.

In the proposed set-up, two choices are made available to each player;
each player then decides on a strategy. The players’ payoffs depend on
the outcomes of repeated measurements and on the constants defining the
game. It is required that a classical game results whenever a LHV model
does not predict negative probability.

We find that a consistent set of probabilities can be obtained, given in
terms of the statistics involved in the four-coin tossing experiment,
such that the game between the players is interpretable as a classical
two-player noncooperative game allowing mixed strategies. The proposal
is designed in a way that allows, in the next step, the introduction of
the peculiar probabilities emerging in the EPR-type experiments.

We find that when the game is played with perfectly correlated pairs of
particles the players’ payoffs are observed to split into two parts,
corresponding to the two situations arising when the predictions of the
class of LHV models do and do not violate the Bell-CHSH inequality,
respectively.

Apart from the splitting of the payoffs, we showed that the
implementation using perfectly correlated particles distinguishes
between two representations of the game that are completely equivalent
in the classical context. In general there is a linkage between the
game’s solutions and the determination of whether the predictions of the
LHV model do or do not violate the Bell-CHSH inequality. We found that
the degree of this linkage is sensitive to the particular representation
used for the game.

A possible extension of the approach presented in chapter 6 is to
analyze three-player two-strategy games in the same set-up. For such
games, interestingly, instead of negative probabilities, HVTs predict
algebraic contradictions such as those appearing in the CHSH version of
the Bell theorem without inequalities [ 35 , 36 , 37 ] . It appears that
such games will present a stronger departure of their quantum solutions
from the classical ones.

Another possible line of investigation to extend the approach developed
in chapter 6 is to use Fine’s results which link the absence of a joint
probability distribution with the violation of the Bell inequalities.
That involves looking at the solutions of a game when it is implemented
by players sharing a physical system for which there is no joint
probability distribution able to produce the measurement outcomes as
marginals. It appears that, once again, three-player games will offer
more convincing constructions.

Here it seems appropriate to mention that GHZ [ 84 ] used a so-called
deterministic hidden variable model in their approach to the GHZ
paradox. Khrennikov [ 121 ] has presented a probabilistic analysis in
the contextualist framework, namely under the assumption that the
distributions of hidden variables depend on the settings of measurement
devices. Khrennikov has found that in the contextualist framework, there
exist classes of probability distributions of hidden variables such that
the GHZ scheme does not imply a contradiction between local realism and
the quantum formalism. It seems that Khrennikov’s results may have a
direct relevance for those proposals of three player games in which the
mentioned contradiction shows itself in the game-theoretical solutions.

In this thesis we have referred to the continuing debate about the
lessons regarding local realism that arise from a violation of the Bell
inequalities, because it might have a bearing on the understanding of
what constitutes the true quantum character and content of quantum
games. For example, one view [ 28 , 73 ] interprets their ‘true’ quantum
character as being their non-local aspect, which in the majority view [
39 ] stands as the unavoidable conclusion of the violation of the Bell
inequalities. However, another view [ 65 , 69 , 75 , 68 ] says that
non-locality is not the sole or principal feature in deciding quantum
character. Even the presence of entanglement has been claimed as not
describing everything that may be called a true quantum character.
Interestingly, entanglement and non-locality, widely believed to be
closely inter-linked, have now been claimed [ 122 ] to be different
resources.

###### Acknowledgement 1

During work on this thesis I was supported by a research scholarship
from the University of Hull (UoH). Also, the Department of Mathematics
(DoM) at the UoH provided its support. I gratefully acknowledge supports
from the UoH and the DoM. I am thankful to the staff members at the DoM
for providing both help and a friendly environment.