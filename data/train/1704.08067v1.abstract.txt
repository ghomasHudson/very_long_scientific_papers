Within machine learning, the supervised learning field aims at modeling
the input-output relationship of a system, from past observations of its
behavior. Decision trees characterize the input-output relationship
through a series of nested @xmath questions, the testing nodes, leading
to a set of predictions, the leaf nodes. Several of such trees are often
combined together for state-of-the-art performance: random forest
ensembles average the predictions of randomized decision trees trained
independently in parallel, while tree boosting ensembles train decision
trees sequentially to refine the predictions made by the previous ones.

The emergence of new applications requires scalable supervised learning
algorithms in terms of computational power and memory space with respect
to the number of inputs, outputs, and observations without sacrificing
accuracy. In this thesis, we identify three main areas where decision
tree methods could be improved for which we provide and evaluate
original algorithmic solutions: (i) learning over high dimensional
output spaces, (ii) learning with large sample datasets and stringent
memory constraints at prediction time and (iii) learning over high
dimensional sparse input spaces.

A first approach to solve learning tasks with a high dimensional output
space , called binary relevance or single target, is to train one
decision tree ensemble per output. However, it completely neglects the
potential correlations existing between the outputs. An alternative
approach called multi-output decision trees fits a single decision tree
ensemble targeting simultaneously all the outputs, assuming that all
outputs are correlated. Nevertheless, both approaches have (i) exactly
the same computational complexity and (ii) target extreme output
correlation structures. In our first contribution, we show how to
combine random projection of the output space, a dimensionality
reduction method, with the random forest algorithm decreasing the
learning time complexity. The accuracy is preserved, and may even be
improved by reaching a different bias-variance tradeoff. In our second
contribution, we first formally adapt the gradient boosting ensemble
method to multi-output supervised learning tasks such as multi-output
regression and multi-label classification. We then propose to combine
single random projections of the output space with gradient boosting on
such tasks to adapt automatically to the output correlation structure.

The random forest algorithm often generates large ensembles of complex
models thanks to the availability of a large number of observations.
However, the space complexity of such models, proportional to their
total number of nodes, is often prohibitive, and therefore these modes
are not well suited under stringent memory constraints at prediction
time . In our third contribution, we propose to compress these ensembles
by solving a @xmath -based regularization problem over the set of
indicator functions defined by all their nodes.

Some supervised learning tasks have a high dimensional but sparse input
space , where each observation has only a few of the input variables
that have non zero values. Standard decision tree implementations are
not well adapted to treat sparse input spaces, unlike other supervised
learning techniques such as support vector machines or linear models. In
our fourth contribution, we show how to exploit algorithmically the
input space sparsity within decision tree methods. Our implementation
yields a significant speed up both on synthetic and real datasets, while
leading to exactly the same model. It also reduces the required memory
to grow such models by exploiting sparse instead of dense memory storage
for the input matrix.

\pdfbookmark

[1]RésuméRésumé
