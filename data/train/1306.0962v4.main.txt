##### Contents

-    1 Introduction
    -    1.1 Integrable equations
    -    1.2 Discrete integrable equations
    -    1.3 Ultra-discrete integrable equations
    -    1.4 Arithmetic dynamical systems
    -    1.5 Purpose of our research and main results
-    2 The space of initial conditions of one-dimensional systems
    -    2.1 Space of initial conditions of dP @xmath equation
    -    2.2 Combinatorial construction of the initial value space
-    3 One-dimensional systems over a local field and their reduction
    modulo a prime
    -    3.1 Almost good reduction
    -    3.2 Refined Almost Good Reduction
    -    3.3 Time evolution over finite fields
    -    3.4 Discrete Painlevé II equation over finite fields and its
        special solutions
    -    3.5 @xmath -discrete Painlevé equations over finite fields
    -    3.6 Hietarinta-Viallet equation
    -    3.7 The @xmath -adic singularity confinement
    -    3.8 Relation to the ‘Diophantine integrability’
    -    3.9 Systems over the extended fields
-    4 Two-dimensional systems over finite fields
    -    4.1 Discrete KdV equation over the field of rational functions
    -    4.2 Soliton solutions of the (generalized) discrete KdV
        equations over the field of rational functions
    -    4.3 Discrete KdV equation over the field of @xmath -adic
        numbers

## Chapter 1 Introduction

### 1.1 Integrable equations

As an introduction we briefly review the theory of integrable systems
and give an overview of the preceding research. There exist various
distinct notions referred to under the name of ‘integrable’ systems in
mathematics and mathematical physics. However, we can state without
accuracy that the differential equations are ‘integrable’ if they are
highly symmetric and have sufficiently ‘many’ first integrals (conserved
quantities) so that the integration of them is possible.

In the middle of the 19th century, J. Liouville first defined the notion
of ‘exact integrability’ of Hamiltonian systems of classical mechanics
in terms of Poisson commuting invariants [ 5 , 6 ] . Let us consider a
Hamiltonian @xmath with @xmath -degree of freedom which is analytic in
@xmath . The Hamilton equations are

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 1.1.1

The Hamiltonian @xmath is Liouville integrable if there exist @xmath
independent analytic first integrals @xmath in involution @xmath i.e.
@xmath .

In the late 1960s, the localized solutions of partial differential
equations have been found to be understood by viewing these equations as
infinite dimensional integrable systems. These localized solutions are
called solitons. The classical example of solitons is a solution of the
Korteweg-de Vries equation (KdV equation) which describes shallow water
wave phenomena [ 7 , 8 , 9 ] . The discovery of solitary wave solutions
dates back to the 1830s. In 1834, Scott Russell discovered a solitary
wave phenomenon while observing the motion of a boat in a canal. He
noticed that the speed of the waves depends on their size, and that
these waves will never merge—a large wave overtakes a small one [ 10 ,
11 ] . Later in 1895, Korteweg and de Vries proved that these waves can
be simulated by the solutions of the following partial differential
equation which is now called the KdV equation:

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

The KdV equation became increasingly important when it was discovered
that the equation can simulate many physical phenomena such as plasma
physics and internal waves. Zabusky and Kruskal found that the KdV
equation was the governing equation of the Fermi-Pasta-Ulam lattice
equation, and that the solutions of the KdV equation pass through one
another and subsequently retain their characteristic form and velocity [
12 ] . It has later been discovered that these soliton equations can be
understood from a broader perspective. In 1980s, M. Sato and Y. Sato
discovered that wide class of nonlinear integrable equations and their
solutions can be treated uniformly by considering them on an infinite
dimensional Grassmannian [ 13 ] . This is the notable ‘Sato theory’, in
which the Sato equation is a ‘master’ equation that produces an infinite
series of nonlinear partial differential equations. The theory is also
called the theory of the KP hierarchies, since one of the simplest
equations among those series of equations is the Kadomtsev-Petviashvili
equation (KP equation), which describes shallow water waves of dimension
two:

  -- -------- --
     @xmath   
  -- -------- --

The KdV equation and its soliton solutions are proved to be obtained
from the reduction of the KP equation and its soliton solutions.

Next we review another important class of integrable differential
equations: the Painlevé equations. The Painlevé equations were
originally discovered by P. Painlevé and B. Gambier as second order
ordinary differential equations whose solutions do not have movable
singularities other than poles. [ 14 , 15 , 16 , 17 , 18 , 19 , 20 ] .

###### Proposition 1.1.1

Let us consider the differential equation

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath is a rational function of @xmath whose coefficients are
analytic functions of @xmath defined on some domain @xmath . If the
equation ( 1.2 ) does not have movable singular points, then it falls
into one of the following cases:

-    Linear equations.

-    Equations of the form

      -- -------- --
         @xmath   
      -- -------- --

    Their solutions are written by the Weierstraß  elliptic function.

-    Solvable equations.

-    One of the six Painlevé equations (P @xmath , P @xmath , P @xmath ,
    P @xmath , P @xmath , P @xmath ). We just present the first two of
    the Painlevé equations:

    -    Painlevé I equation (P @xmath )

          -- -------- --
             @xmath   
          -- -------- --

    -    Painlevé II equation (P @xmath )

          -- -------- --
             @xmath   
          -- -------- --

        @xmath

In the 1970s, it has been found that the correlation function of the
two-dimensional Ising model are related to the Painlevé III equation [
21 ] , and since then the Painlevé equations have been investigated
eagerly as one of the classes of integrable equations by K. Okamoto and
many other researchers. Also, the Painlevé equations can be obtained via
similarity reduction of some soliton equations.

### 1.2 Discrete integrable equations

We review some of the topics on the integrability of discretized
equations. Roughly speaking, the discrete integrable systems have ‘many’
conserved quantities and soliton solutions. If the discretization is
chosen appropriately, the discrete system preserves the essential
properties that the corresponding continuous system possesses.

A discrete version of the KP equation is derived via the Miwa
transformation from the KP hierarchy. The Miwa transformation is the
following transformation that changes the variables @xmath to @xmath :

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are distinct constants. Let us suppose that the
variables @xmath take only integer values, and consider a function
@xmath , which is a Miwa transformation of the @xmath -function solution
@xmath of the Sato’s bilinear identity. Then we obtain the following
bilinear relation for distinct @xmath :

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

The equation ( 1.3 ) is the discrete KP equation, and is also called
‘Hirota-Miwa equation’. The discrete KdV equation is obtained by
imposing a restriction

  -- -------- --
     @xmath   
  -- -------- --

to the Hirota-Miwa equation. This kind of restriction on the independent
variables (imposing shift invariance, omitting some of the variables,
e.t.c.) to construct simpler classes of equations is called the
‘reduction’. It gives the following bilinear form of the discrete KdV
equation:

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

Here @xmath . (Note that, in this paper, the word ‘reduction’ is also
used to indicate other process: the projection modulo a maximal ideal.)
By introducing a new variable

  -- -------- --
     @xmath   
  -- -------- --

we obtain the discrete KdV equation as the following nonlinear partial
difference equation:

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

In 1990, the discrete versions of the Painlevé equations have been
discovered by A. Ramani, B. Grammaticos and J. Hietarinta [ 22 ] . They
are considered to be integrable in the sense that they pass the
singularity confinement test. The singularity confinement test judges
whether the spontaneously appearing singularities disappear after a few
iteration steps of the systems. For example, let us consider the
following mapping related to the discrete Painlevé I equation:

  -- -------- --
     @xmath   
  -- -------- --

If we evolve the equation from @xmath and @xmath , then we have

  -- -------- --
     @xmath   
  -- -------- --

thus @xmath is indeterminate. However, if we introduce a small positive
parameter @xmath and take @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

By taking the limit @xmath , we obtain the time evolution as follows:

  -- -------- --
     @xmath   
  -- -------- --

In this case we can see that, by introducing a parameter @xmath in the
initial value, the indeterminacy resulting from the singularity at
@xmath is ‘confined’ within finite time steps and then the initial value
@xmath reappears. Most integrable discrete systems have been proved to
pass the test [ 23 ] . We will treat some of the discrete Painlevé
equations in the following sections. Note that, although the singularity
confinement test is a very powerful tool to detect the integrability of
many discrete equations, it is not easy to apply the test to partial
difference equations. In 2014, after this thesis is submitted, the
author and his collaborators invented a new integrability criterion
called ‘co-primeness’ condition, which can be considered as one type of
generalization of the singularity confinement test. The benefit of the
co-primeness is that it is applicable also to the partial difference
equations, however, we do not treat this topic in this article and leave
the details to other papers.

### 1.3 Ultra-discrete integrable equations

The ultra-discrete integrable systems are obtained from the discrete
integrable ones through a limiting procedure called
‘ultra-discretization’. Both the dependent and independent variables of
the ultra-discrete systems take discrete values, usually the integers.
Therefore they are considered as cellular automata. The cellular
automaton is a discrete computational model which consists of a regular
grid of cells. Each cell has a finite number of states, corresponding to
the value of the independent variable of the ultra-discrete system. It
is studied not only in mathematical physics, but also in many fields in
natural and social sciences such as computability theory, theoretical
biology and jamology.

One of the most famous cellular automata may be the Elementary Cellular
Automata (ECA) [ 24 ] . It is one-dimensional and the time evolution of
a cell depends only on its two neighboring cells. We give an ECA with
‘rule @xmath ’, which is the ‘simplest non-trivial’ ECA as an example [
25 ] . Let the values of one-dimensional cells at time step @xmath be
@xmath where each cell satisfies @xmath . The next step @xmath is
defined as the exclusive disjunction of @xmath and @xmath , and
therefore be expressed as @xmath . The time evolution on a large scale
gives the shape of the Sierpiński gasket, a fractal. See the figure 1.1
.

We are also interested in more complex cellular automata whose solutions
behave analogous to those of some discrete integrable systems. We
present one way to ultradiscretize the discrete KdV equation and explain
how this limiting procedure gives the Box Ball Systems (BBS). The BBS is
one of the typical soliton cellular automata discovered by D. Takahashi
and J. Satsuma, and has been investigated extensively by T. Tokihiro et.
al. [ 26 , 27 , 28 ] . To simplify the process, we use the following
lemma:

###### Lemma 1.3.1

Under the boundary condition @xmath , the discrete KdV equation ( 1.5 )
takes the following form:

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

To ultradiscretize the equation ( 1.6 ), we first introduce an auxiliary
variable @xmath and change variables as

  -- -------- --
     @xmath   
  -- -------- --

By taking the logarithms of the both sides of ( 1.6 ), we have

  -- -------- --
     @xmath   
  -- -------- --

By taking the limit @xmath , and by using the identities

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

which are true for all @xmath , we obtain the evolution equation of the
BBS:

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

Here the parameter @xmath is called the ‘capacity of the box’. In
particular, if @xmath the BBS ( 1.7 ) evolves inside of @xmath . We give
an example of the time evolution in the figure 1.2 .

This solution corresponds to the three-soliton solution of the
(continuous and discrete) KdV equation. The origin of the name ‘Box
Ball’ system is that the solution of BBS can be seen as moving balls
@xmath ’s @xmath in an infinite array of empty boxes @xmath ’s @xmath .

Note that taking the ultra-discrete limit is closely related to taking
the @xmath -adic valuation of the given discrete equations as pointed
out by S. Matsutani [ 29 ] . We will look into this approach in more
detail at the end of the paper.

Finally let us note on another topic on ultra-discrete equations. The
ultra-discrete analogs of the Painlevé equation have been studied
recently. For example, an ultra-discrete version of the @xmath -Painlevé
II equation has been obtained through ‘ultra-discretization with parity
variables’ [ 30 ] , which is a generalized method of
ultra-discretization, and its special solution has been obtained. In
connection with this theory of extended ultra-discretization procedure,
N. Mimura et. al. proposed an ultra-discrete version of the singularity
confinement test [ 31 ] . Another type of singularity confinement test
for ultra-discrete equation has been proposed by N. Joshi and S.
Lafortune, where the ‘singularities’ for the max-plus equations have
been introduced as the non-differentiable points of the piecewise linear
functions [ 32 ] .

### 1.4 Arithmetic dynamical systems

In this section let us summarize the definition of the field of @xmath
-adic numbers and briefly explain the ‘good’ reduction. Let @xmath be a
prime number. A non-zero rational number @xmath ( @xmath ) can be
written uniquely as @xmath where @xmath and @xmath and @xmath are
coprime integers neither of which is divisible by @xmath . We call
@xmath the @xmath -adic valuation of @xmath . The @xmath -adic norm
@xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

The local field @xmath is a completion of @xmath with respect to the
@xmath -adic norm. It is called the field of @xmath -adic numbers, and
its subring

  -- -------- --
     @xmath   
  -- -------- --

is called the ring of @xmath -adic integers [ 33 ] . The @xmath -adic
norm satisfies a special inequality

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 1.4.1

The absolute value @xmath of a valued field @xmath is non-archimedean
(or also called ultrametric) if the following estimate is satisfied for
all @xmath :

  -- -------- --
     @xmath   
  -- -------- --

The @xmath -adic norm @xmath of @xmath is thus non-archimedean, and the
field @xmath is a non-archimedean field. Let @xmath be the maximal ideal
of @xmath . We define the reduction of @xmath modulo @xmath as

  -- -------- --
     @xmath   
  -- -------- --

We write @xmath as @xmath for simplicity. Note that the reduction is a
ring homomorphism:

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

The element @xmath is uniquely written as the @xmath -adic polynomial
series:

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath . The reduction is naturally computed as @xmath . The
reduction map @xmath is generalized to @xmath :

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

which is no longer homomorphic. The element @xmath is uniquely expanded
as the Laurent series using @xmath :

  -- -------- --
     @xmath   
  -- -------- --

where each @xmath and @xmath . In this case, the reduction is @xmath .
For a dynamical system @xmath consisting of two rational mappings
defined over @xmath :

  -- -------- --
     @xmath   
  -- -------- --

the ‘reduced’ system

  -- -------- --
     @xmath   
  -- -------- --

is defined as the system whose coefficients are all reduced to @xmath :

  -- -------- --
     @xmath   
  -- -------- --

We define the notion of ‘good reduction’, which basically means that the
time evolution of the system and the reduction modulo @xmath commutes.

###### Definition 1.4.2

The rational system @xmath has a good reduction modulo @xmath on the
domain @xmath if we have @xmath for any @xmath .

It is equivalent for the diagram in the figure 1.3 to be commutative.
Originally, the good reduction was defined for a rational mapping with
one variable [ 34 ] .

###### Definition 1.4.3 ([34])

A rational map @xmath defined over the valued field @xmath is said to
have good reduction modulo @xmath if @xmath .

A map with a good reduction satisfies the following proposition.

###### Proposition 1.4.1 ([34])

Let @xmath be a rational map that has good reduction. Then the map
@xmath satisfies @xmath for all @xmath .

With this property in mind, we define the good reduction for the
dynamical systems with two variables as satisfying @xmath (Definition
1.4.2 ).

### 1.5 Purpose of our research and main results

The purpose of our research is to define and investigate the discrete
integrable equations over finite fields. We wish to study the
implication of integrability over finite fields. We also expect to
construct cellular automata directly from the discrete systems over
finite fields.

In the case of linear discrete equations, for example, we can
well-define the equations over finite fields just by changing the field
on which the equations are defined to finite fields. However, in the
case of nonlinear equations, since the systems are usually formulated by
rational functions, the division by @xmath mod @xmath and some
indeterminacies such as @xmath and @xmath frequently appear. These
points makes it difficult for us to well-define the equations over
finite fields. Thus there has been few studies on the nonlinear discrete
integrable equations defined over finite fields.

There are mainly three approaches to overcome this difficulty. (a) The
first one is to study the equation that does not contain division terms.
Santini et. al. studied cellular automata constructed from one type of
the Scrödinger equations which is free from division [ 35 ] . Bilinear
form of the discrete KP and KdV equations ( 1.3 ), ( 1.4 ) have been
treated over the finite field @xmath and their soliton solutions over
@xmath are obtained [ 36 , 37 , 38 ] . (b) The second one is to restrict
the domain of definition of the system so that the indeterminacies do
not appear. The discrete Toda equation over finite fields and its
graphical structures have been obtained [ 39 ] . Roberts and Vivaldi
studied the integrability over finite fields in terms of the lengths of
the periodic orbits [ 40 , 41 , 42 ] . (c) The third one is to extend
the space of initial conditions to make the mapping well-defined. We
investigate this third approach in this paper and try two different
schemes.

(c-i) The first scheme is to apply the Sakai’s theory on discrete
Painlevé equations to the case of finite domains. According to the
theory developed by K. Okamoto and H. Sakai, the space of initial
conditions for the discrete Painlevé equation becomes a birational
surface as we extend the domain @xmath by blowing-up at each singular
point [ 43 , 44 ] . We show, in chapter 2 , that this procedure is still
valid if applied to the finite domain of definition @xmath . We in
particular treated the discrete Painlevé II equation, and presented the
extended domain of initial conditions for @xmath and @xmath . What is
more, we have shown that the size of the extended domain we construct is
smaller than that made by the Sakai theory. Since the domain over the
finite field has a discrete topology, the extended domain need not to be
birational, but needs only to be bijective.

(c-ii) The second scheme of extension is to define the equations over
the field of @xmath -adic numbers @xmath and then reduce them to the
finite field @xmath . Through this approach, we wish to establish the
significance of ‘integrability’ of the systems over finite fields. For
example, if we try to define the discrete Painlevé equations over the
field @xmath , the initial value space is a finite set @xmath . Since
the system consists of transitions between just @xmath points, it is not
clear how we can formulate the integrability of the system from the
integrability of the original system defined over @xmath or @xmath . To
resolve this problem we consider a pair of fields @xmath in chapter 3 .
We can say that the system over @xmath is ‘integrable’ if it is
integrable over @xmath and its reduction to the finite field @xmath has
an ‘almost good reduction’ property. We prove that, although the
integrable mappings generally do not have a good reduction modulo a
prime, they do have an almost good reduction (AGR), which is a
generalized notion of good reduction. We demonstrate that AGR can be
used as an integrability detector over finite fields, by proving that dP
@xmath , @xmath P @xmath , @xmath P @xmath , @xmath P @xmath , @xmath P
@xmath and @xmath P @xmath equations have AGR over appropriate domains.
We also prove that one of the chaotic system, the Hietarinta-Viallet
equation, has AGR and conclude that AGR is an arithmetic analog of the
singularity confinement method. We then discuss the relation of our
approach to the Diophantine integrability proposed by R. Halburd [ 45 ]
. We also propose a way to reduce the systems defined over the extended
field of @xmath , and then apply the procedure to obtain the cellular
automaton from the complex-valued equations.

Lastly, in chapter 4 , we apply our methods to the soliton systems, in
particular the discrete KdV equation and one of its generalized forms [
4 ] . We present two methods of extension: first one is to use a field
of rational functions whose coefficients are in the finite field, and
the second one is to use the field of @xmath -adic numbers just like we
have done in the previous sections. The soliton solutions obtained
through both two methods are introduced and their periodicity is
discussed. Special types of solitary waves that appear only over the
finite fields are presented and their nature is studied. The reduction
properties of the two-dimensional lattice systems are discussed.

Let us summarize the main results of this paper. The key definition is
definition 3.1.1 , in which almost good reduction property for
non-autonomous discrete dynamical systems is formulated. The main
theorems of this paper are the followings: theorem 2.1.1 on the space of
initial conditions, and theorems 3.1.1 , 3.4.1 , 3.5.1 , 3.5.2 , 3.5.3 ,
3.5.4 , 3.5.5 , 3.6.1 on the almost good reduction property for discrete
Painlevé equations.

## Chapter 2 The space of initial conditions of one-dimensional systems

A discrete Painlevé equation is a non-autonomous and nonlinear second
order ordinary difference equation with several parameters. When it is
defined over a finite field, the dependent variable takes only a finite
number of values and its time evolution will attain an indeterminate
state in many cases for generic values of the parameters and initial
conditions.

### 2.1 Space of initial conditions of dP@xmathequation

For example, the discrete Painlevé II equation (dP @xmath equation) is
defined as

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath and @xmath are constant parameters [ 46 ] . Let @xmath for
a prime @xmath and a positive integer @xmath . When ( 2.1 ) is defined
over a finite field @xmath , the dependent variable @xmath will
eventually take values @xmath for generic parameters and initial values
@xmath , and we cannot proceed to evolve it. If we extend the domain
from @xmath to @xmath , @xmath is not a field and we cannot define
arithmetic operation in ( 2.1 ). To determine its time evolution
consistently, we have two choices: One is to restrict the parameters and
the initial values to a smaller domain so that the singularities do not
appear. The other is to extend the domain on which the equation is
defined. In this article, we will adopt the latter approach. It is
convenient to rewrite ( 2.1 ) as:

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where @xmath . Then we can regard ( 2.2 ) as a mapping defined on the
domain @xmath . To resolve the indeterminacy at @xmath , we apply the
theory of the state of initial conditions developed by H. Sakai [ 44 ] .
First we extend the domain to @xmath , and then blow it up at four
points @xmath to obtain the space of initial conditions:

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

where @xmath is the space obtained from the two dimensional affine space
@xmath by blowing up twice as

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Similarly,

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The bi-rational map ( 2.2 ) is extended to the bijection @xmath which
decomposes as @xmath . Here @xmath is a natural isomorphism which gives
@xmath , that is, on @xmath for instance, @xmath is expressed as

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

The automorphism @xmath on @xmath is induced from ( 2.2 ) and gives the
mapping

  -- -------- --
     @xmath   
  -- -------- --

Under the map @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath , @xmath , @xmath and @xmath are the exceptional curves in
@xmath obtained by the first blowing up and the second blowing up
respectively at the point p @xmath . Similarly under the map @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The mapping on the other points are defined in a similar manner. Note
that @xmath is well-defined in the case @xmath or @xmath . In fact, for
@xmath , @xmath and @xmath can be identified with the lines @xmath and
@xmath respectively. Therefore we have found that, through the
construction of the space of initial conditions, the dP @xmath equation
can be well-defined over finite fields. However there are some
unnecessary elements in the space of initial conditions when we consider
a finite field, because we are working on a discrete topology and do not
need continuity of the map. Let @xmath be the space of initial
conditions and @xmath be the number of elements of it. For the dP @xmath
equation, we obtain @xmath , since @xmath contains @xmath elements.
However an exceptional curve @xmath is transferred to another
exceptional curve @xmath , and @xmath to @xmath or to a point in @xmath
. Hence we can reduce the space of initial conditions @xmath to the
minimal space of initial conditions @xmath which is the minimal subset
of @xmath including @xmath , closed under the time evolution. By
subtracting unnecessary elements we find @xmath . In summary, we obtain
the following theorem:

###### Theorem 2.1.1

The domain of the dP @xmath equation over @xmath can be extended to the
minimal domain @xmath on which the time evolution at time step @xmath is
well defined. Moreover @xmath .

In figure 2.1 , we show a schematic diagram of the map @xmath on @xmath
, and its restriction map @xmath on @xmath with @xmath , @xmath and
@xmath . We can also say that figure 2.1 is a diagram for the autonomous
version of the equation ( 2.2 ) when @xmath . In the case of @xmath , we
have @xmath and @xmath .

The above approach is equally valid for other discrete Painlevé
equations and we can define them over finite fields by constructing
isomorphisms on the spaces of initial conditions. Thus we conclude that
a discrete Painlevé equation can be well defined over a finite field by
redefining the initial domain properly. Note that, for a general
nonlinear equation, explicit construction of the space of initial
conditions over a finite field is not so straightforward (see [ 47 ] or
a higher order lattice system) and it will not help us to obtain the
explicit solutions. We will return to this topic in chapter 4 .

### 2.2 Combinatorial construction of the initial value space

In the previous section, we investigated the space of initial conditions
of the dP @xmath equation by considering a finite field analog of the
Sakai theory. In this section we introduce another method to construct
the space of initial conditions over finite fields by directly and
intuitively adding finite number of points to the original space @xmath
. We take @xmath , @xmath , @xmath and @xmath (autonomization) in dP
@xmath equation. The mapping over @xmath is

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

First we formally set a division @xmath . We extend the space @xmath to
@xmath , and the map @xmath to @xmath , so that @xmath is a bijective
mapping and that @xmath . Since,

  -- -------- --
     @xmath   
  -- -------- --

the mapping @xmath is not injective. We want @xmath to be bijective,
therefore we set

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

where @xmath , @xmath denote distinct points in the extended space
@xmath . In the same manner, the point @xmath is divided into three
distinct points @xmath , @xmath , @xmath in @xmath . Next, since @xmath
and @xmath , both the points @xmath and @xmath must be divided into
three distinct points in @xmath in order to assure the bijectivity of
@xmath . Lastly, @xmath (and therefore @xmath for @xmath ) are not
well-defined because @xmath is indeterminable. Since we have @xmath , we
have no choice but to define @xmath in order for the map @xmath to be
well-defined and bijective. Here, @xmath and @xmath . Note that @xmath
since @xmath has already appeared as the image of the point @xmath . The
same discussion applies to the image of the point @xmath . Summing up
the discussions above, we obtain all transitions inside the newly
constructed initial value space @xmath .

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath and the order of three numbers of each set is not determined
with the method in this section. To uniquely determine the
correspondences, we need to use singularity confinement method. Note
that, apart from the ambiguity above, @xmath exactly corresponds to the
space @xmath constructed in the previous section and we have @xmath .
See the figure 2.1 , and 2.2 for comparison.

## Chapter 3 One-dimensional systems over a local field and their
reduction modulo a prime

We define a generalized notion of good reduction and explain how the
notion can be used to detect the integrability of several dynamical
systems.

### 3.1 Almost good reduction

###### Definition 3.1.1 ([2])

A non-autonomous rational system

  -- -------- --
     @xmath   
  -- -------- --

has an almost good reduction modulo @xmath on the domain @xmath , if
there exists a positive integer @xmath for any @xmath and time step
@xmath such that

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath .

In this chapter, we take @xmath and explain that having almost good
reduction on @xmath is equivalent for the mapping to be integrable. If
@xmath does not depend on @xmath , we simply write @xmath . The almost
good reduction property is equivalent for the diagram in figure 3.1 to
be commutative. Note that if we can take @xmath , the system has a good
reduction. Let us first see the significance of the notion of almost
good reduction . Let us consider the mapping @xmath :

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

where @xmath ( @xmath ) and @xmath are parameters. The map ( 3.2 ) is
known to be integrable if and only if @xmath . When @xmath , ( 3.2 )
belongs to the QRT family [ 48 ] and is integrable in the sense that it
has a conserved quantity. We also note that when @xmath , ( 3.2 ) is an
autonomous version of the @xmath -discrete Painlevé I equation.

###### Theorem 3.1.1

The rational mapping ( 3.2 ) with @xmath and @xmath has an almost good
reduction modulo @xmath on the domain @xmath if and only if @xmath .
Here @xmath . If @xmath then @xmath . If @xmath then @xmath .

Proof (i) First note that

  -- -------- --
     @xmath   
  -- -------- --

since @xmath in this case.

(ii) For @xmath with @xmath and @xmath , we find that @xmath is not
defined for @xmath , however it is defined if @xmath and we have

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is equivalent to @xmath , the calculation is done by taking
@xmath where @xmath and @xmath , and iterating the mapping.

(iii-a) If @xmath and @xmath and @xmath then, by a similar calculation
to (ii), we obtain

  -- -------- --
     @xmath   
  -- -------- --

(iii-b) If @xmath and @xmath and @xmath then, the apparent singularity
is canceled, since @xmath is finite. Then we have,

  -- -------- --
     @xmath   
  -- -------- --

(iv) Finally, if @xmath , we find that @xmath is not defined for @xmath
, however

  -- -------- --
     @xmath   
  -- -------- --

In the case (iv), we have an exceptional case just like (iii-b):
numerator @xmath may become @xmath modulo @xmath during the time
evolution. The singularity is also confined in this exceptional case,
because we just arrive at non-infinite values with fewer iterations than
(iv) in this case.

Hence the map @xmath has almost good reduction modulo @xmath on @xmath .
In a similar manner, we find that @xmath ( @xmath ) also has almost good
reduction modulo @xmath on @xmath . On the other hand, for @xmath and
@xmath , we easily find that

  -- -------- --
     @xmath   
  -- -------- --

since the order of @xmath diverges as we iterate the mapping from @xmath
where @xmath . Thus we have proved the theorem. @xmath In this theorem
we omitted the case of @xmath . However we can also treat this case. In
the case @xmath and @xmath , for example, if we take

  -- -------- --
     @xmath   
  -- -------- --

( 3.2 ) turns into the trivial linear mapping @xmath which has
apparently good reduction modulo @xmath . Note that having an almost
good reduction is equivalent to the integrability of the equation in
these examples.

### 3.2 Refined Almost Good Reduction

Next, we introduce another generalization of the good reduction
property, which can be used as a ‘refined’ almost good reduction. We
decompose the domain @xmath of the system @xmath into three disjoint
parts, so that we have the following three types of points ¹ ¹ 1 Another
way to define @xmath is to take @xmath . The results are essentially the
same in this way, however, the computation becomes more complicated. :

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

For example, in the case of @xmath in the previous section,

  -- -------- --
     @xmath   
  -- -------- --

###### Definition 3.2.1

The mapping @xmath has the refined AGR, if, for every point @xmath ,
there exists an integer @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

Here the domain @xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

We call the domain @xmath the ‘normal’ domain.

###### Proposition 3.2.1

The system @xmath has a refined AGR.

Proof First let us fix the initial condition @xmath ( @xmath ).

(i) If @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

Therefore we have @xmath . We can take @xmath in this case.

(ii) If @xmath , then we have @xmath ( @xmath ). Thus @xmath .
Continuing the iterations, we obtain @xmath , @xmath , @xmath .
Therefore,

  -- -------- --
     @xmath   
  -- -------- --

Finally when @xmath , we have @xmath , and

  -- -------- --
     @xmath   
  -- -------- --

By an assumption that @xmath , we have @xmath . @xmath We can prove by
an argument similar to that in section 3.1 that the mapping @xmath
@xmath does not have a refine AGR. We can apply refine AGR to
non-autonomous systems with minor modifications. The AGR and the refined
AGR are both effective as integrability detectors of dynamical systems
over @xmath , as we will explain in the following sections. The refined
AGR can be more suitable than AGR when we investigate in detail the
behaviors around the singularities and zeros of the mapping over @xmath
. On the other hand we have to note that refined AGR requires heavier
computation than AGR does to be proved, in particular for non-autonomous
systems. Also note that refined AGR and AGR are not equivalent, nor is
one of them stronger/weaker than the other one. In the case of the
discrete Painlevé equations, we have basically the same results for both
of the criteria. Therefore we will mainly explain the results regarding
the AGR property in the following sections for simplicity.

### 3.3 Time evolution over finite fields

We explain how to define the time evolution of discrete dynamical
systems over finite fields. Of course, we cannot determine the time
evolution solely from the information over finite fields, however, we
can propose one reasonable way of evolution by applying the refined AGR.
Let @xmath be a dynamical system with refine AGR property. Let us fix
the initial condition @xmath .

(i) In the case of @xmath : We define @xmath . By the refined AGR
property we have a positive integer @xmath such that

  -- -------- --
     @xmath   
  -- -------- --

We define @xmath . By an assumption, we do not encounter indeterminacies
in this calculation. We also define the intermediate states as @xmath ,
for @xmath . Since @xmath again, we can continue the time evolution.

(ii) In the case of @xmath : We cannot define the time evolution by the
refined AGR. In this case, we encounter the indeterminate points @xmath
for some @xmath . We can determine one path of evolution by considering
@xmath for some @xmath and @xmath . However, we have an ambiguity with
respect to the choice of the inverse image of @xmath . If the mapping
@xmath has the ordinary AGR in section 3.1 , it helps us to define the
time evolution for a few steps, however, @xmath is not necessarily in
@xmath . When we need to know all the trajectories, we may return to the
chapter 2 and extend the space of initial conditions.

### 3.4 Discrete Painlevé II equation over finite fields and its special
solutions

Now let us examine the dP @xmath ( 2.2 ) over @xmath . We suppose that
@xmath , and redefine the coefficients @xmath and @xmath so that they
are periodic with period @xmath :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where the integer @xmath ( @xmath ) is chosen such that @xmath @xmath .
As a result, we have @xmath , @xmath and @xmath for any integer @xmath .

###### Theorem 3.4.1

Let @xmath . Under the above assumptions, the dP @xmath equation has an
almost good reduction modulo @xmath on @xmath .

Proof We put @xmath .

When @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Hence @xmath .

When @xmath , we can write @xmath @xmath . We have to consider four
cases ² ² 2 Precisely speaking, there are some special cases for @xmath
where we have to consider the fact @xmath or @xmath . In these cases the
map does not have an almost good reduction on @xmath . They are treated
later in this section. :
(i) For @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Hence we have @xmath .
(ii) In the case @xmath and @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Thus we have

  -- -------- --
     @xmath   
  -- -------- --

and @xmath .
(iii) In the case @xmath , @xmath and @xmath , we have to calculate up
to @xmath . After a lengthy calculation we find

  -- -------- --
     @xmath   
  -- -------- --

and we obtain @xmath .
(iv) Finally, in the case @xmath , @xmath and @xmath we have to
calculate up to @xmath . The result is

  -- -------- --
     @xmath   
  -- -------- --

and we obtain @xmath . Hence we have proved that the dP @xmath equation
has almost good reduction modulo @xmath at @xmath .

We can proceed in the case @xmath in an exactly similar manner and find;
(v) For @xmath , we have @xmath . Therefore we have @xmath .
(vi) In the case @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(vii) In the case @xmath , @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(viii) In the case @xmath , @xmath and @xmath ,

  -- -- --
        
  -- -- --

From this theorem, the evolution of the dP @xmath equation ( 2.1 ) over
@xmath can be constructed from the following seven cases which determine
@xmath from the initial values @xmath and @xmath . Note that we can
assume that @xmath because all the cases in which the dependent variable
@xmath becomes @xmath are included below ³ ³ 3 For @xmath , there are
some exceptional cases as shown in the proof of theorem 3.4.1 . . Here
@xmath .

1.  For @xmath , or @xmath and @xmath , or @xmath and @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

2.  For @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

3.  For @xmath , @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
         @xmath   
      -- -------- --

4.  For @xmath , @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
         @xmath   
      -- -------- --

5.  For @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

6.  For @xmath , @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
      -- -------- --

7.  For @xmath , @xmath , @xmath and @xmath ,

      -- -------- --
         @xmath   
         @xmath   
      -- -------- --

#### 3.4.1 Exceptional cases where @xmath and @xmath.

Now we study the exceptional cases: @xmath and @xmath . In these cases,
the almost good reduction property does not hold for all points in
@xmath . The situations change depending on the value ‘ @xmath ’. Here
@xmath for a @xmath -adic integer @xmath is defined as @xmath from the
@xmath -adic expansion

  -- -------- --
     @xmath   
  -- -------- --

of @xmath where each @xmath . Let us first consider the case of @xmath .
We explain the details via an example when @xmath , @xmath and @xmath .
The dP @xmath equation in this case takes the following three forms
periodically:

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

where @xmath is an integer. Unfortunately, the dP @xmath equation over
@xmath with @xmath , @xmath and @xmath does not have an almost good
reduction. However, it has a somewhat weaker property than the almost
good reduction on the following domain @xmath :

  -- -------- --
     @xmath   
  -- -------- --

###### Proposition 3.4.1

Let @xmath as above. For every @xmath , there exists a positive integer
@xmath such that

  -- -------- --
     @xmath   
  -- -------- --

holds. @xmath We will call this property ‘weak’ almost good reduction.
@xmath

If @xmath , then the solution modulo @xmath goes into the periodic
orbit:

  -- -------- --
     @xmath   
  -- -------- --

for @xmath .

If @xmath , then the solution goes into the periodic orbit:

  -- -------- --
     @xmath   
  -- -------- --

for @xmath .

Proof

(i) If @xmath then we have @xmath .

(ii) If @xmath then we have three cases to consider:

(ii-a) If ( @xmath and @xmath ) or ( @xmath and @xmath ) then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-b) If ( @xmath and @xmath ) or ( @xmath and @xmath ) then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-c) If ( @xmath and @xmath ) or ( @xmath and @xmath ) then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-d) If @xmath then, both the reduced mappings and the reduced
coordinates return to the original position after iterating the mappings
@xmath times from the lemma 3.4.1 .

(iii) If @xmath then we have three points to consider: @xmath , @xmath
and @xmath . The proof is much the same as in the case of (ii). @xmath

###### Lemma 3.4.1

For the initial value @xmath , with @xmath and @xmath , we have @xmath
and @xmath for

  -- -------- --
     @xmath   
  -- -------- --

Proof We can write @xmath and @xmath with @xmath and @xmath . By
iterating the mappings we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath denotes a polynomial whose coefficients are multiples of
three. Therefore we obtain @xmath and @xmath . @xmath

In the case of @xmath , we have a similar result. Let us consider the dP
@xmath equations with the same parameters as in the case of @xmath :
@xmath , @xmath and @xmath . Then the dP @xmath equation is expressed as
the following five maps.

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

where @xmath is an integer.

###### Proposition 3.4.2

The dP @xmath equation above have ‘weak’ almost good reduction on the
following domain @xmath :

  -- -------- --
     @xmath   
  -- -------- --

If @xmath then, the time evolution goes into a periodic orbit:

  -- -------- --
     @xmath   
  -- -------- --

Proof

(i) If @xmath then we have @xmath .

(ii) If @xmath then, the time evolution depends on @xmath or @xmath . If
@xmath then, the orbit is periodic with a period @xmath . We classify
other four cases below.

(ii-a) If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-b) If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-c) If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

(ii-d) If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

(iii) If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

In the case of (iii), the time evolution up to the third iteration does
not depend on @xmath , but depends only on @xmath . @xmath Note that in
this case, the singularities are confined if @xmath , unlike the result
in the case of @xmath .

#### 3.4.2 Its Special solutions

Next we consider special solutions to ( 2.1 ) over @xmath . For the dP
@xmath equation over @xmath , rational function solutions have already
been obtained [ 49 ] . Let @xmath be a positive integer and @xmath be a
constant. Suppose that @xmath , @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

Then a rational function solution of the dP @xmath equation is given by

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

If we deal with the terms in ( 3.6 ) and ( 3.7 ) by arithmetic
operations over @xmath , we encounter terms such as @xmath or @xmath and
( 3.7 ) is not well-defined. However, from theorem 3.4.1 , we find that
( 3.7 ) gives a solution to the dP @xmath equation over @xmath by the
reduction from @xmath , as long as the solution avoids the points @xmath
and @xmath , which is equivalent to the solution satisfying

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

where the superscripts are considered modulo @xmath . Note that @xmath
for all integers @xmath and @xmath . In the table below, we give several
rational solutions to the dP @xmath equation with @xmath and @xmath over
@xmath for @xmath and @xmath . We see that the period of the solution is
@xmath .

  -- -------- --
     @xmath   
  -- -------- --

We see from the case of @xmath that we may have an appropriate solution
even if the condition ( 3.8 ) is not satisfied, although this is not
always true. The dP @xmath equation has linearized solutions also for
@xmath [ 50 ] . With our new method, we can obtain the corresponding
solutions without difficulty.

### 3.5 @xmath-discrete Painlevé equations over finite fields

#### 3.5.1 @xmath-discrete Painlevé I equation

One of the forms of the @xmath -discrete analogs of the Painlevé I
equation is as follows:

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

where @xmath and @xmath are parameters [ 44 ] . We rewrite ( 3.9 ) for
our convenience as a form of dynamical system with two variables:

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

We can prove the AGR property for this equation:

###### Theorem 3.5.1

Suppose that @xmath are integers not divisible by @xmath , then the
mapping ( 3.10 ) has an almost good reduction modulo @xmath on the
domain @xmath .

proof

Let @xmath . Just like we have done before, we have only to examine the
cases @xmath , and @xmath . We use the abbreviation @xmath for
simplicity. By direct computation we obtain;

(i) If @xmath and @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

(ii) If @xmath and @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

(iii) If @xmath and @xmath , then

  -- -- --
        
  -- -- --

The same is true for a refined AGR property.

###### Proposition 3.5.1

Suppose that @xmath are integers not divisible by @xmath , then the
mapping ( 3.10 ) has a refined almost good reduction. Here the normal
domain is @xmath .

Proof First let us fix the initial condition @xmath ( @xmath ).

(i) If @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

Therefore we have @xmath . We can take @xmath in this case.

(ii) If @xmath , then we have @xmath ( @xmath ). Thus @xmath .
Continuing the iterations, we obtain @xmath , @xmath and @xmath .
Therefore,

  -- -------- --
     @xmath   
  -- -------- --

At the next step,

  -- -------- --
     @xmath   
  -- -------- --

(ii-1) If @xmath then

  -- -------- --
     @xmath   
  -- -------- --

(ii-2) If @xmath then we have to continue the iterations further until
we obtain

  -- -------- --
     @xmath   
  -- -------- --

Here note that @xmath is equivalent to @xmath , which is in turn
equivalent to @xmath . Therefore by the assumption, we have @xmath .
Thus we have proved that

  -- -- --
        
  -- -- --

#### 3.5.2 @xmath-discrete Painlevé II equation

We study the @xmath -discrete analog of the Painlevé II equation (
@xmath P @xmath equation):

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

where @xmath and @xmath are parameters [ 51 ] . It is also convenient to
rewrite ( 3.11 ) as

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

where @xmath . Similarly to the dP @xmath equation, we can prove the
following theorem:

###### Theorem 3.5.2

Suppose that @xmath are integers not divisible by @xmath , then the
mapping ( 3.12 ) has an almost good reduction modulo @xmath on the
domain @xmath .

Proof Let @xmath . Just like the proof of theorem 3.4.1 , we have only
to examine the cases @xmath and @xmath . We use the abbreviation @xmath
for simplicity. By direct computation, we obtain;
(i) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(ii) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(iii) If @xmath and @xmath ,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

(iv) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(v) If @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Thus we complete the proof. @xmath Note that the ‘refined’ AGR is not
properly defined for the @xmath P @xmath equation, since we have the
term @xmath in the denominator of @xmath , which prevents the definition
of the normal domain @xmath . We can overcome this problem if we are to
define the normal domain @xmath to be non-autonomous, however, the
computation becomes heavier.

#### 3.5.3 Special solutions of @xmathP@xmathequation

From the previous theorem, we can define the time evolution of the
@xmath P @xmath equation explicitly just like the dP @xmath equation in
the previous section. We consider special solutions for @xmath P @xmath
equation ( 3.11 ) over @xmath . In [ 52 ] it has been proved that ( 3.11
) over @xmath with @xmath @xmath is solved by the functions given by

  -- -------- -------- -- --------
     @xmath   @xmath      (3.13)
     @xmath   @xmath      (3.14)
  -- -------- -------- -- --------

where @xmath is a solution of the @xmath -discrete Airy equation:

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

As in the case of the dP @xmath equation, we can obtain the
corresponding solutions to ( 3.13 ) over @xmath by reduction modulo
@xmath according to the theorem 3.5.2 . For that purpose, we have only
to solve ( 3.15 ) over @xmath . By elementary computation we obtain:

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

where @xmath are arbitrary constants and @xmath is defined by the
tridiagonal determinant:

  -- -------- --
     @xmath   
  -- -------- --

The function @xmath is the polynomial of @xmath th order in @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are polynomials in @xmath . If we let @xmath denotes @xmath
, and @xmath then, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Therefore the solution of @xmath P @xmath equation over @xmath is
obtained by reduction modulo @xmath from ( 3.13 ), ( 3.14 ) and ( 3.16 )
over @xmath or @xmath .

#### 3.5.4 @xmath-discrete Painlevé III equation

The @xmath -discrete analog of the Painlevé III equation has the
following form

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are parameters [ 22 ] . It is convenient to
rewrite it as the following coupled form

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

###### Theorem 3.5.3

Suppose that @xmath are parameters in @xmath and that @xmath are
distinct and we also suppose that @xmath , then the mapping ( 3.17 ) has
an almost good reduction modulo @xmath on the domain @xmath .

Proof Let @xmath . In the case when @xmath and @xmath , we have

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

from the relation ( 1.8 ). Hence @xmath . We have to examine the other
cases. From here we sometimes abbreviate @xmath as @xmath , @xmath as
@xmath for simplicity.

(i) If @xmath and @xmath , neither @xmath nor @xmath is well-defined.
However, @xmath is well-defined and we have,

  -- -- -------- -------- --
                 @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

(ii) If @xmath and @xmath , none of @xmath is well-defined for @xmath .
However, @xmath is well-defined and we have,

  -- -------- --
     @xmath   
  -- -------- --

(iii) If @xmath and @xmath ,

  -- -- -------- -------- --
                 @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

(iv) If @xmath and @xmath , we have,

  -- -------- --
     @xmath   
  -- -------- --

(v) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(vi) If @xmath and @xmath ,

  -- -- --
        
  -- -- --

#### 3.5.5 @xmath-discrete Painlevé IV equation

The @xmath -discrete analog of the Painlevé IV equation has the
following form:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are parameters [ 22 , 53 ] . It can be rewritten
as follows:

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

where @xmath . Here we took @xmath and redefined @xmath as @xmath and
@xmath .

###### Theorem 3.5.4

Suppose that @xmath , then the mapping ( 3.19 ) has an almost good
reduction modulo @xmath on the domain @xmath , on the condition that
@xmath and @xmath .

Proof In the proof we use the abbreviation as @xmath .

(i) If @xmath and @xmath ,

  -- -- -------- -------- --
                 @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

(ii) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where we assumed that @xmath .

(iii) If @xmath and @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Here we assumed @xmath .

(iv) If @xmath and @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(v) If @xmath ,

  -- -- --
        
  -- -- --

#### 3.5.6 @xmath-discrete Painlevé V equation

The @xmath -discrete analog of the Painlevé V equation has the following
form:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath are parameters [ 22 ] . It can be rewritten as
the following form:

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

###### Theorem 3.5.5

Suppose that @xmath are in @xmath and @xmath are distinct from each
other, then the mapping ( 3.20 ) has almost good reduction modulo @xmath
on the domain @xmath .

Proof The calculation is extremely lengthy and we need about 13
gigabytes of memory. We deal with @xmath for simplicity. (Since ord
@xmath , the same argument applies to other cases.)

(i) If @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(ii) If @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

(iii) If @xmath ,

  -- -- --
        
  -- -- --

### 3.6 Hietarinta-Viallet equation

The Hietarinta-Viallet equation [ 54 ] is the following difference
equation:

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

with @xmath as a parameter. The equation ( 3.21 ) passes the singularity
confinement test [ 23 ] , which is a notable test for integrability of
equations, but yet is not integrable in the sense that its algebraic
entropy is positive and that the orbits display chaotic behaviors. We
prove that the AGR is satisfied for this Hietarinta-Viallet equation. We
again rewrite ( 3.21 ) as the following coupled form:

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

###### Theorem 3.6.1

Suppose that @xmath , then the mapping ( 3.22 ) has an almost good
reduction modulo @xmath on the domain @xmath .

Proof If @xmath ,

  -- -- --
        
  -- -- --

###### Proposition 3.6.1

Suppose that @xmath , then the mapping ( 3.22 ) has a refined almost
good reduction. Here the normal domain is @xmath . Other domains are
defined as @xmath , @xmath .

Proof First let us fix the initial condition @xmath , @xmath .

(i) If @xmath then, we have @xmath . Thus

  -- -------- --
     @xmath   
  -- -------- --

(ii) If @xmath then, we have @xmath , therefore

  -- -------- --
     @xmath   
  -- -------- --

By iterating further, we obtain the followings: @xmath , @xmath , @xmath
. Therefore,

  -- -- --
        
  -- -- --

Therefore we learn that the AGR and refined AGR work similarly to the
singularity confinement test in distinguishing the integrable systems
from the non-integrable ones. In fact, the AGR and refined AGR can be
seen as an arithmetic analog of the singularity confinement test.

### 3.7 The @xmath-adic singularity confinement

The above approach is closely related to the singularity confinement
method which is an effective test to judge the integrability of the
given equations [ 23 ] . In the proof of the theorem 3.4.1 , we have
taken

  -- -------- --
     @xmath   
  -- -------- --

instead of taking @xmath and showed that the limit

  -- -------- --
     @xmath   
  -- -------- --

is well defined for some positive integer @xmath . Here @xmath is an
alternative in @xmath for the infinitesimal parameter @xmath in the
singularity confinement test in @xmath . Note that @xmath is a ‘small’
number in terms of the @xmath -adic metric @xmath . In fact, in most
cases, we may just replace @xmath for @xmath in order to test the @xmath
-adic singularity confinement. From this observation and previous
theorems, we postulate that having almost good reduction in arithmetic
mappings is similar to passing the singularity confinement test.

### 3.8 Relation to the ‘Diophantine integrability’

Lastly we discuss a relationship between the systems over finite fields
and the algebraic entropies of the systems. Let @xmath be a difference
equation and let the degree of the map @xmath be @xmath . We define the
degree of the iterates @xmath as @xmath . The naïve composition suggests
@xmath , however, common factors can be eliminated, lowering the degree
of the iterates. Algebraic entropy @xmath of @xmath is the following
well-defined quantity [ 55 ] .

  -- -------- --
     @xmath   
  -- -------- --

The existence of @xmath We can postulate from a lot of examples that the
mapping @xmath is integrable if and only if @xmath , that is, @xmath has
a polynomial growth. We can construct an arithmetic analog of the
algebraic entropy which has first been introduced in [ 45 ] . If we
consider the map with rational numbers as coefficients, and choose
initial values to be rational numbers, then we have @xmath for all
@xmath . The arithmetic complexity of rational numbers can be expressed
by the height function @xmath :

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath and @xmath are integers without common factors.
( @xmath .) The map @xmath is said to be ‘Diophantine integrable’ if and
only if @xmath grows as slowly as some polynomial. Thus we define the
arithmetic analog of algebraic entropy, which may be called as a
‘Diophantine entropy’ as

  -- -------- --
     @xmath   
  -- -------- --

Precisely speaking, the value @xmath depends on the choice of initial
data of the systems, however, we conjecture that the value @xmath is
independent of that choice for most of the initial conditions. We
conjecture that for most of the dynamical systems with rational numbers
as coefficients, two values @xmath and @xmath is the same. We have the
following two conjectures from numerical observations:

##### (i)

The Hietarinta-Viallet equation ( 3.21 ) has @xmath , which is exactly
equal to the original algebraic entropy @xmath obtained in [ 47 , 54 ,
55 ] .

##### (ii)

In the case of the equation ( 3.2 ), @xmath for @xmath , while, for
@xmath , we have @xmath and @xmath has a polynomial growth of second
degree for generic initial conditions.

Therefore, in these cases, the Diophantine entropy @xmath motivated by
the Diophantine integrability is expected to be equivalent to the
(original) algebraic entropy @xmath . We do not explain the proof of
these conjectures, some part of which is incomplete. We give some
numerical examples which support (i) and (ii).

##### (i)

Let us suppose that @xmath , @xmath and that the parameter @xmath in the
Hietarinta-Viallet equation ( 3.21 ). Then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Here we only displayed the integer part of the values. We can see
numerically that

  -- -------- --
     @xmath   
  -- -------- --

##### (ii)

In the case of the equation ( 3.2 ), we give two examples. First let us
suppose that @xmath , @xmath , @xmath , and that the parameter in the
equation ( 3.2 ) is @xmath . Then,

  -- -------- --
     @xmath   
  -- -------- --

Therefore we see numerically that

  -- -------- --
     @xmath   
  -- -------- --

On the other hand, if @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

Therefore we see numerically that

  -- -------- --
     @xmath   
  -- -------- --

The rate of growth of @xmath is quadratic: if we estimate @xmath using a
cubic polynomial, we obtain

  -- -------- --
     @xmath   
  -- -------- --

which indicates a quadratic growth.

In the case of original algebraic entropy @xmath , we can rigorously
obtain the recurrence relation for the sequence @xmath of degrees of
rational functions with several methods. However, in the case of
‘Diophantine entropy’, it is not easy in many cases to exactly estimate
the elimination of common factor @xmath between the numerator and the
denominator. This idea is essentially equivalent to studying the growth
of the number of digits of the numerator (or denominator) of @xmath when
expressed as @xmath -adic expansions. Therefore the procedure can be
seen as an analog of algebraic entropy of a system over a finite field
@xmath . As a technique of the numerical simulations, instead of the
height @xmath , we can also use only the denominator @xmath or the
numerator @xmath of @xmath : i.e., both of the values

  -- -------- --
     @xmath   
  -- -------- --

should give the same value as @xmath due to a result by Silverman [ 56 ]
. The biggest benefit of this ‘Diophantine’ approach might be that the
time of computation is greatly reduced by using rational numbers instead
of the using formal variables. This allows us to obtain a conjecture for
the integrability, and a conjecture for the value of algebraic entropy
with comparably short time. In 2014, after the thesis is submitted, a
series of generalized versions of the Hietarinta-Viallet equation

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is under investigation by the author and his collaborators.
They numerically computed an approximation to the Diophantine entropy
@xmath of this system for @xmath and conjectured the exact values of
algebraic entropy @xmath from these approximations. We have found that
the situation depends on the parity of the integer @xmath . This topic
will be dealt with in other papers.

### 3.9 Systems over the extended fields

In the preceding subsections we have successfully defined the dynamical
systems over the finite field @xmath through the extensions to /
reductions from the field of @xmath -adic numbers @xmath . In this
subsection we generalize this result to the systems over a larger finite
field @xmath where @xmath , and then study the ways of reduction to some
finite field from the field of complex values @xmath . Since a field
extension @xmath of the degree @xmath over @xmath is a simple extension,
there exist an element @xmath such that @xmath . The reduction from
@xmath to the set @xmath is defined naturally using the reduction map (
1.9 ) in the previous sections:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

For example let us define dynamical systems over @xmath and discuss the
properties of the reductions. Let @xmath be a generator of @xmath over
@xmath . Then we have @xmath and @xmath and @xmath .

###### Lemma 3.9.1

The field @xmath is the extension field of @xmath of degree two.

Proof We can see @xmath as an element of @xmath . Since @xmath is not a
square element in @xmath , @xmath is not a square in @xmath either.
Therefore @xmath in not in @xmath . @xmath We define the reduction map
@xmath from @xmath to @xmath as follows:

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

Note that @xmath is a ring homomorphism. We define the almost good
reduction in a similar manner to the case of systems over @xmath .

###### Definition 3.9.1

A non-autonomous rational system @xmath : @xmath @xmath has an almost
good reduction modulo @xmath on the domain @xmath , if there exists a
positive integer @xmath for any @xmath and time step @xmath such that

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

where @xmath .

Next we apply these results to the field @xmath . Note that we already
have a method to obtain cellular automata from the discrete systems via
extended ultra-discretization [ 57 ] . We take a different approach,
which is based on the arithmetic of @xmath -adic numbers. We use without
proof the following fact in the number theory.

###### Lemma 3.9.2

The field @xmath has a square root of @xmath if and only if @xmath .

From this fact we consider the following two cases:

-   If @xmath or @xmath , then the lemma 3.9.1 holds for @xmath . Thus
    we obtain the following reduction mapping @xmath :

      -- -------- -- --------
         @xmath      (3.25)
      -- -------- -- --------

-   If @xmath , on the other hand, @xmath holds. Therefore, the
    reduction mapping @xmath takes values in @xmath .

The values of the form @xmath , @xmath can be reduced to either @xmath
or @xmath . Note that we cannot apply this method if @xmath are not
rational numbers. By using this approach to the equations with complex
variables such as a discrete version of the nonlinear Schrödinger
equation (dNLS) and a discrete sine-Gordon equation, we expect to obtain
the cellular automata related to the equations. One of the future
problems is to investigate the cellular automata (ultra-discrete)
analogs of the breather solutions of dNLS.

## Chapter 4 Two-dimensional systems over finite fields

In chapter 2 , we have successfully determined the time evolution of the
discrete Painlevé equations through the construction of their space of
initial conditions by blowing-up twice at each of the singular points so
that the mapping becomes bijective. However, for a general nonlinear
equation, explicit construction of the space of initial conditions over
a finite field is not so straightforward (for example see [ 47 ] or
consider the higher dimensional lattice systems). Therefore it does not
help us to obtain the explicit solutions. In this section we study the
soliton equations evolving as a two-dimensional lattice over finite
fields by following the discussions made in [ 4 ] .

### 4.1 Discrete KdV equation over the field of rational functions

Let us consider the discrete KdV equation ( 1.5 ) over a finite field
@xmath where @xmath , @xmath is a prime number and @xmath . Let us
reproduce the discrete KdV equation here:

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath and @xmath is a parameter. If we take

  -- -------- --
     @xmath   
  -- -------- --

we obtain equivalent coupled equations

  -- -- -- -------
           (4.1)
  -- -- -- -------

Clearly ( 4.1 ) does not determine the time evolution when @xmath . Over
a field of characteristic 0 such as @xmath , the time evolution of
@xmath will not hit this exceptional line for generic initial
conditions, but on the contrary, the evolution comes to this exceptional
line in many cases over a finite field as a division by @xmath appears.
The mapping, @xmath , is lifted to an automorphism of the surface @xmath
, where @xmath is obtained from @xmath by blowing up twice at @xmath and
@xmath respectively:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath            
              @xmath   
     @xmath            
              @xmath   
  -- -------- -------- --

where @xmath denotes a set of homogeneous coordinates for @xmath . To
define the time evolution of the system with @xmath lattice points from
( 4.1 ), however, we have to consider the mapping

  -- -------- --
     @xmath   
  -- -------- --

Since there seems no reasonable decomposition of @xmath into a direct
product of two independent spaces, successive use of ( 4.1 ) becomes
impossible. Note that if we blow down @xmath to @xmath , the information
of the initial values is lost in general. If we intend to construct an
automorphism of a space of initial conditions, it will be inevitable to
start from @xmath and blow-up to some huge manifold, which is beyond the
scope of the present paper. There should be so many exceptional
hyperplanes in the space of initial conditions if it does exist, and it
is practically impossible to check all the “singular” patterns in the
naïve extension of the singularity confinement test. Another difficulty
is that, in high dimensional lattice systems, we cannot properly impose
the boundary conditions to be compatible with the extension of the
spaces. These difficulties seem to be some of the reasons why the
singularity confinement method has not been used for construction of
integrable partial difference equations or judgment for their
integrability, though some attempts have been proposed in the bilinear
form [ 58 ] . On the other hand, when we fix the initial condition for a
partial difference equation, the number of singular patterns is
restricted in general and we have only to enlarge the domain so that the
mapping becomes well defined. This is the strategy that we will adopt in
this section.

Suppose that @xmath , then we have

  -- -------- --
     @xmath   
  -- -------- --

With further calculation we have

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath and @xmath are not defined over @xmath , we now extend
@xmath to @xmath and take @xmath for @xmath . However, at the next time
step, we have

  -- -------- --
     @xmath   
  -- -------- --

and reach a deadlock.

The first idea to overcome this problem is to consider the equation over
the field of rational functions [ 4 ] . We try the following two
procedures:

(I) we keep @xmath as a parameter for the same initial condition, and
obtain as a system over @xmath ,

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

(II) Then we put @xmath to have a system over @xmath as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Thus all the values are uniquely determined over @xmath . Figures 4.1
and 4.2 show a time evolution pattern of the discrete KdV equation ( 4.1
) over @xmath for the initial conditions @xmath and @xmath .

This example suggests that the equation ( 4.1 ) should be understood as
evolving over the field @xmath , the rational function field with
indeterminate @xmath over @xmath . To obtain the time evolution pattern
over @xmath , we have to substitute @xmath with a suitable value @xmath
( @xmath in the example above). This substitution can be expressed as
the following reduction map:

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

where @xmath , @xmath are co-prime polynomials and @xmath . With this
prescription, we know that @xmath does not appear and we can uniquely
determine the time evolution for generic initial conditions defined over
@xmath . Of course we can also overcome the indeterminacy by using the
filed of @xmath -adic numbers as we have done in previous sections. This
approach is introduced in section 4.3 .

### 4.2 Soliton solutions of the (generalized) discrete KdV equations
over the field of rational functions

First we consider the @xmath -soliton solutions to ( 1.5 ) over @xmath .
It is well-known that the @xmath -soliton solution is given as

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

where @xmath @xmath are arbitrary parameters but @xmath for @xmath .
When @xmath are chosen in @xmath , @xmath becomes a rational function in
@xmath . Hence we obtain soliton solutions over @xmath by substituting
@xmath with a value in @xmath .

The figure 4.3 shows one and two soliton solutions for the discrete KdV
equation ( 1.5 ) over the finite fields @xmath and @xmath . Here we have
chosen the values @xmath and @xmath so that their reduction by the
reduction map ( 4.2 ) is neither @xmath nor @xmath . In this case, the
reduced soliton solutions exhibit periodicity with periods @xmath as in
figure 4.3 . The corresponding time evolutionary patterns over the field
@xmath are also presented for comparison. Note that, if some of the
reduced values of @xmath or @xmath take @xmath or @xmath , the reduced
soliton solutions do not exhibit periodicity in general: they might
become stationary, vanish after a few time steps, or look like the
normal solitary waves. These phenomena are described in detail in
section 4.3 .

Next we consider the generalized form of the discrete KdV equation. We
introduce the following discrete integrable system:

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

with arbitrary parameters @xmath and @xmath . This is a natural and
important generalization of the discrete KdV equation, partly because it
becomes the generalized version of the BBS called ‘Box Ball Systems with
a Carrier’ (BBSC) through ultra-discretization. The parameter @xmath
corresponds to the capacity of the box, and @xmath to the capacity of
the carrier. The equation ( 4.4 ) are known to have soliton solutions
whose speeds and widths are intuitively understood from the BBSC [ 59 ]
. We consider soliton solutions to the generalized discrete KdV equation
( 4.4 ). Note that by putting @xmath , we obtain

  -- -------- --
     @xmath   
  -- -------- --

Hence ( 4.4 ) is essentially equivalent to the ‘consistency of the
discrete potential KdV equation around a @xmath -cube’ [ 60 ] : @xmath ,
as

  -- -------- --
     @xmath   
  -- -------- --

The map is also obtained from discrete BKP equation [ 61 ] . We will
obtain @xmath -soliton solutions to ( 4.4 ) from the @xmath -soliton
solutions to the discrete KP equation by a reduction similar to the one
adopted in [ 61 ] .

Let us consider the four-component discrete KP equation:

  -- -------- -- -------
     @xmath      (4.5)
     @xmath      (4.6)
  -- -------- -- -------

Here @xmath is the @xmath -function of integer variables @xmath , and
@xmath , @xmath , @xmath and @xmath are arbitrary parameters. We express
the shift operations by subscripts: @xmath and so on. If we shift @xmath
in ( 4.6 ), we have

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

Then, by imposing the reduction condition:

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

the equation ( 4.7 ) turns to

  -- -------- --
     @xmath   
  -- -------- --

Hence, putting @xmath , we obtain

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Now we denote

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

From the equality

  -- -------- --
     @xmath   
  -- -------- --

we find that @xmath defined in ( 4.9 ) satisfy the equation ( 4.4 ) by
defining @xmath .

The @xmath -soliton solution to ( 4.5 ) and ( 4.6 ) is known as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath are distinct parameters from each other and @xmath are
arbitrary parameters [ 62 ] . The reduction condition ( 4.8 ) gives the
constraint,

  -- -------- --
     @xmath   
  -- -------- --

to the parameters @xmath . Since @xmath , the restriction is equivalent
to @xmath . By rewriting @xmath , @xmath , defining @xmath and taking
@xmath we have

  -- -------- -------- -- --------
     @xmath   @xmath      (4.10)
     @xmath   @xmath      (4.11)
  -- -------- -------- -- --------

Thus we obtain the @xmath -soliton solution of ( 4.4 ) by ( 4.9 ), (
4.10 ) and ( 4.11 ).

Although the generalized discrete KdV equation has more than one
parameters @xmath and @xmath , we can do the same approach of using the
field of rational function as in the case of ( 4.1 ). If we want to
consider the equation at @xmath @xmath , then we substitute @xmath using
a new parameter @xmath , which will be considered as a variable. Then we
can construct soliton solutions in @xmath by a reduction for suitable
values of @xmath and @xmath . The reduced solutions defined in @xmath
are obtained by putting @xmath and are expressed as @xmath and @xmath .
Lastly, let us comment on the periodicity of the soliton solutions over
@xmath . We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

for all @xmath since we have @xmath for all @xmath . Thus the functions
@xmath and @xmath have periods @xmath over @xmath . However we cannot
conclude that @xmath and @xmath are also periodic with periods @xmath ,
unlike the case in the discrete KdV equation. The values of @xmath may
not be periodic when @xmath and @xmath (See ( 4.9 )). First we write
@xmath and @xmath as follows:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath and @xmath . We also write @xmath in the same manner. Let
us write down the reduction map again:

  -- -------- --
     @xmath   
  -- -------- --

In the case when @xmath and @xmath , @xmath and @xmath may have
different reductions with respect to @xmath , since @xmath is not
necessarily equal to @xmath , and neither is @xmath equal to @xmath .
The left part of figure 4.4 shows a gray-tone plot of a two-soliton
solution. In some points @xmath does not have period 12 (for example
@xmath ) while almost all other points do have this periodicity.

If we want to recover full periodicity, there is another reduction to
obtain the reduced variables from @xmath and @xmath . This time, we
define another reduction to the finite field @xmath as

  -- -------- --
     @xmath   
  -- -------- --

The right part of figure 4.4 shows the same two-soliton solution as in
the left part but calculated with this new method. We see that all
points have periods 12. It is important to determine how to reduce
values in @xmath to values in @xmath , depending on the properties one
wishes the soliton solutions to possess.

### 4.3 Discrete KdV equation over the field of @xmath-adic numbers

Instead of dealing with the systems over the field of rational
functions, we can consider them over the field of @xmath -adic numbers
just like we have done for discrete Painlevé equations. The calculation
of soliton solutions and its reduction to the finite field can be done
exactly the same as in section 4.1 . We can define the time evolution of
the discrete KdV equation over the field of @xmath -adic numbers @xmath
, and then obtain the time evolution of the equation over @xmath by
reducing it. One of the good thing about this approach is the efficiency
in numerical calculations. One of the weakness is that we have to limit
ourselves to @xmath of @xmath . (This is not a problem if we consider
the extended field of @xmath .) The example with the same initial
conditions as in figure 4.1 is presented in figure 4.5 .

The values @xmath and @xmath in the figure 4.5 are different from those
( @xmath ) reduced from the field @xmath in figure 4.1 . The two systems
do not present the same singularities for the same initial conditions in
general because of the structural difference in the addition between the
fields @xmath and @xmath . However, the overall appearance of soliton
solutions are unchanged. We add some examples of the soliton solutions
we have missed in the section 4.2 . We describe the behavior of
solutions of the discrete KdV equation ( 4.3 ). We consider the @xmath
-adic valuations of the parameter values @xmath and @xmath . First, note
that if we take @xmath satisfying @xmath and @xmath then the soliton
solutions of the discrete KdV equation ( 4.1 ) over @xmath is always
periodic with respect to @xmath and @xmath with a period @xmath just
like in figure 4.3 . Second, if we have @xmath or @xmath then, at least
one of the reductions of @xmath by the reduction map ( 1.9 ) are either
@xmath or @xmath . We have two cases:

(i) If @xmath and @xmath , then the soliton solution over @xmath looks
similar to that over the field @xmath . The solitary waves which include
the value @xmath move both to the left and to the right, over the
background arrays of @xmath ’s. We introduce two examples where @xmath
and @xmath respectively. The first example concerns the @xmath -soliton
solution over @xmath of the form @xmath , where

  -- -------- --
     @xmath   
  -- -------- --

Note that all values concerning the speed of solitons ( @xmath , @xmath
, @xmath , @xmath ) are non-zero. The second one is the @xmath -soliton
solution over @xmath , written as

  -- -- --
        
  -- -- --

See the figures 4.6 and 4.7 for their solitonic shapes.

(ii) If just one of the values @xmath and @xmath is zero, the speed of
solitary waves is either @xmath or @xmath . In the figure 4.8 , we
present the example of the @xmath -soliton solution over @xmath with the
speed of solitons @xmath and @xmath respectively.

We can prove that the case (i) occurs if and only if @xmath .

###### Proposition 4.3.1

We obtain @xmath and @xmath for some @xmath if and only if the parameter
@xmath satisfies @xmath or @xmath . The solitary waves over @xmath go to
the right if @xmath , and to the left if @xmath .

Proof Let us rewrite @xmath . We have @xmath if and only if

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

or

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

In the case of ( 4.12 ),

  -- -------- --
     @xmath   
  -- -------- --

Therefore, @xmath if and only if ( @xmath and @xmath ) or @xmath .

In the case of ( 4.13 ),

  -- -------- --
     @xmath   
  -- -------- --

Therefore, @xmath if and only if ( @xmath and @xmath ) or @xmath .
@xmath Note that if @xmath or @xmath , the discrete KdV equation ( 1.5 )
is reduced to the linear difference equations

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

respectively. These equations have trivial waves with speed @xmath , and
do not have soliton solutions. What we are observing in this section is
the reduction of the soliton solution of the discrete KdV equation ( 1.5
) over @xmath , not the solutions of the ‘reduced’ discrete KdV
equations ( 4.14 ). Through our methods, we successfully extract the
solitonic structure of solutions over the finite field.

#### 4.3.1 Relation to the cellular automata

In this section, we study how the discrete KdV equation over @xmath is
related to the Box and Ball System (BBS) by taking the @xmath -adic
valuations. The BBS is a famous cellular automaton obtained by taking
the ultra-discrete limit of the discrete KdV equation (section 1.3 ).
Let us fix @xmath for the discrete KdV equation ( 4.1 ). We define the
new system @xmath from @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where Round @xmath denotes the closest integer to @xmath . Then the
system @xmath goes to the time evolution of the BBS in the limit @xmath
, or @xmath . Note that if @xmath then we have @xmath , and that if
@xmath we have @xmath . Here is an example where @xmath and @xmath . We
start from the initial condition of the equation ( 4.1 ):

  -- -------- --
     @xmath   
  -- -------- --

Then the evolution of @xmath is as in figure 4.9 .

The time evolution obtained here is almost the same as the three soliton
interaction of BBS in figure 4.2 . The block of @xmath ’s in the initial
condition of ( 4.1 ) is a @xmath -adic analog of a BBS soliton (array of
@xmath ’s) in the system @xmath . The underlying fact is that the
ultra-discrete limit is a super-exponential estimate, whose @xmath -adic
analog is taking @xmath -adic valuations of the variables.

### Concluding remarks and future problems

We studied the discrete dynamical systems over finite fields. We
investigated how to define them without indeterminacies, how to judge
their integrability by a simple test similar to the singularity
confinement method, and how to obtain the special solutions of them, in
particular the solitary wave solutions. In the first part of the paper,
we constructed the space of initial conditions for discrete Painlevé
equations defined over a finite field via the application of the Sakai
theory. In particular, we defined the time evolution graph for the
discrete Painlevé II equation over finite field @xmath . We have found
out that, in case of the systems over the finite field, the space of
initial conditions can be minimized compared to those obtained through
Sakai theory, because of the discrete topology of the space. The second
part concerns the extension of the value spaces to local fields, in
particular, to the field of @xmath -adic numbers. Our idea is to define
the equations over the field of @xmath -adic numbers @xmath and then
reduce them to the finite field @xmath . We generalized good reduction
in order to be applied to integrable mappings, in particular, to the
discrete Painlevé equations. We called this generalized notion an
‘almost good reduction’ (AGR). It has been proved that AGR is satisfied
for discrete Painlevé II equation and for @xmath -discrete Painlevé I,
II, III, IV and V equations. We have found out that AGR was satisfied
for the Hietarinta-Viallet equation, and hence was an integrability
detector which worked as an arithmetic analog of the singularity
confinement test. In the third part, we applied our methods to the
two-dimensional lattice systems, in particular, to the discrete KdV
equation and its generalized equation. We obtained the solitary wave
solutions defined over finite fields and showed that they have periods
@xmath in generic cases. Other special solitary wave solutions which
only appear over finite fields have also been presented and their
properties have been studied. One of the future problems is to construct
a theory to solve the initial value problems over the non-archimedean
valued fields. We also wish to study further the properties of the
reduction modulo a prime of the higher dimensional lattice integrable
equations. In this paper, we have not dealt with the theory of
continuous integrable equations over the field of @xmath -adic numbers
and over the finite fields. For example, @xmath -adic soliton theory has
been investigated by G. W. Anderson [ 63 ] . The continuous Painlevé
equations over finite fields have been studied in terms of their
symmetric solutions by K. Okamoto and S. Okumura. We also wish to study
the relation of our methods to these approaches.

### Acknowledgments

The author would particularly like to thank his advisor, Professor
Tetsuji Tokihiro for generous support and advice throughout his Ph.D
course studies. He has greatly benefited from Professors Jun Mada and K.
M. Tamizhmani who collaborated in the research and jointly published
several papers. He would like to thank Professor Ralph Willox for
carefully reading the papers and making insightful suggestions. He would
like to thank Professors Shinsuke Iwao, Nalini Joshi, Saburo Kakei,
Shigeo Kusuoka, Kenichi Maruno, Yousuke Ohyama, Hidetaka Sakai, Junkichi
Satsuma, Junichi Shiraishi, for valuable discussions and comments. This
work is partially supported by Grant-in-Aid for JSPS Fellows 24-1379.