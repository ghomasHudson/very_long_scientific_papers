##### Contents

-    1 Introduction
    -    1.1 Field Theory Introduction
        -    1.1.1 Lagrangian
        -    1.1.2 Perturbation Theory
    -    1.2 The Standard Model
        -    1.2.1 Particle Content
        -    1.2.2 Higgs Mechanism
        -    1.2.3 Running Coupling
        -    1.2.4 Asymptotic Freedom
    -    1.3 Event Generation
        -    1.3.1 Monte Carlo Approach
            -    1.3.1.1 Simple Monte Carlo Integration
            -    1.3.1.2 Non-Uniform Sampling for Monte Carlo
                Integration
        -    1.3.2 Hard Process
        -    1.3.3 Parton Distribution Functions
        -    1.3.4 The Parton Shower
        -    1.3.5 Hadronization
        -    1.3.6 Decays
-    2 New formalism for QCD parton showers
    -    2.1 Introduction
    -    2.2 New variables for parton branching
        -    2.2.1 Final-state quark branching
            -    2.2.1.1 Kinematics
            -    2.2.1.2 Running coupling
            -    2.2.1.3 Evolution variable
            -    2.2.1.4 Branching probability
        -    2.2.2 Gluon splitting
        -    2.2.3 Initial-state branching
        -    2.2.4 Allowed regions and termination of branching
        -    2.2.5 Treatment of colour flows
    -    2.3 Final-final colour connection
        -    2.3.1 Phase space variables
        -    2.3.2 Soft gluon region
        -    2.3.3 Example: @xmath
            -    2.3.3.1 Exact matrix element
            -    2.3.3.2 Soft gluon distribution
            -    2.3.3.3 Dead region contribution
    -    2.4 Initial-initial colour connection
        -    2.4.1 Phase space variables
        -    2.4.2 Example: Drell-Yan process
    -    2.5 Initial-final colour connection
        -    2.5.1 Initial-state branching
        -    2.5.2 Final-state branching
        -    2.5.3 Phase space variables
        -    2.5.4 Example: deep inelastic scattering
        -    2.5.5 Example: @xmath
    -    2.6 Decay colour connection
        -    2.6.1 Initial-state branching
        -    2.6.2 Final-state branching
        -    2.6.3 Phase space variables
        -    2.6.4 Example: top decay
    -    2.7 Conclusions
-    3 Hadronization
    -    3.1 Cluster Formation
        -    3.1.1 Gluon Splitting
        -    3.1.2 Cluster Formation
        -    3.1.3 Cluster Fission
    -    3.2 Cluster Decays
        -    3.2.1 HERWIG 6.5
        -    3.2.2 Kupco Method
    -    3.3 Herwig++
        -    3.3.1 Herwig++ Cluster Decay Algorithm
        -    3.3.2 Results
-    4 Herwig++
    -    4.1 Hard Subprocess
    -    4.2 PDF
    -    4.3 Parton Shower
        -    4.3.1 Hard Matrix Element Corrections
        -    4.3.2 Initial Conditions
        -    4.3.3 Initial-State Shower
        -    4.3.4 Final-State Shower
        -    4.3.5 Soft Matrix Element Corrections
        -    4.3.6 Parameterization of @xmath
    -    4.4 Hadronization
    -    4.5 Decays
-    5 Results
    -    5.1 Introduction
        -    5.1.1 Main features of the code
            -    5.1.1.1 Parton shower
            -    5.1.1.2 Hadronization and decay
    -    5.2 @xmath Annihilation
        -    5.2.1 Strategy
        -    5.2.2 Hadron multiplicities
        -    5.2.3 Jet multiplicity
        -    5.2.4 Jet fractions and @xmath
        -    5.2.5 Event shapes
        -    5.2.6 Four jet angles
        -    5.2.7 Single particle distributions
        -    5.2.8 Identified hadron spectra
        -    5.2.9 B fragmentation function
        -    5.2.10 Overall results of @xmath annihilation
    -    5.3 Conclusions
-    6 Effective Potential Analysis: Effective
    -    6.1 Supersymmetry
        -    6.1.1 Superpotential
        -    6.1.2 Minimal Supersymmetric Standard Model
            -    6.1.2.1 Soft Breaking
    -    6.2 Effective Potential
        -    6.2.1 Generating Functionals
        -    6.2.2 One-Loop Potential
    -    6.3 Mass Matrices
        -    6.3.1 Scalar One-Loop Corrections
        -    6.3.2 Vector One-Loop Corrections
        -    6.3.3 Fermion One-Loop Corrections
    -    6.4 Renormalization Group Equations
    -    6.5 Effective
        -    6.5.1 Model Definition
        -    6.5.2 Mass Matrices
        -    6.5.3 Effective Potential
        -    6.5.4 Renormalization Group Equations
        -    6.5.5 Future Extensions of Effective
-    A Herwig++
    -    A.1 Counting Pions
    -    A.2 Repository
    -    A.3 Matrix Element Development
-    B Effective
    -    B.1 MSSM
    -    B.2 Plotting Effective Potential and Running Couplings of MSSM
    -    B.3 Entering a New Group
    -    B.4 Defining a Diagram

###### List of Figures

-    1.1 The contour taken to find the retarded Green’s function. For
    @xmath we can close the contour below. For @xmath we can close the
    contour above, giving zero.
-    1.2 The contour for the Feynman prescription. When @xmath the
    contour can be closed below and when @xmath the contour can be
    closed above.
-    1.3 The effective potential of the Standard Model as @xmath is
    varied. The three lines are the tree level potential, the 1-Loop
    correction only with the Electroweak particles (leptons, W,Z, @xmath
    ,Higgs boson) and the one-loop correction for all Standard Model
    particles. These are all for the combination @xmath
-    1.4 Graphs which contribute to the QCD @xmath function in the
    one-loop approximation (in a physical gauge).
-    1.5 Virtual @xmath pairs are effectively dipoles that screen the
    bare charge of the electron.
-    1.6 This shows the randomly distributed points in a square of
    area 1. The value of the integral is the percentage of points under
    the function
-    1.7 This shows the random numbers sampled under a known function,
    @xmath . The area of the integral is now @xmath , the integral under
    @xmath , times the percent of points under @xmath .
-    1.8 The electron emits a virtual photon which probes the structure
    of the proton.
-    2.1 Final-state parton branching. The blob represents the hard
    subprocess.
-    2.2 Initial-state parton branching. The blob represents the hard
    subprocess.
-    2.3 Phase space for @xmath for @xmath GeV, @xmath , with symmetric
    definition of quark and antiquark jets.
-    2.4 Phase space for @xmath for @xmath GeV, @xmath , with maximal
    region for the quark jet.
-    2.5 The function @xmath giving the gluon angular distribution in
    the soft limit, for @xmath GeV, @xmath . The exact result (), solid
    curve, and shower approximation (), dashed, are not distinguishable
    on this scale.
-    2.6 The function @xmath giving the contribution of the dead region
    to the cross section, for @xmath GeV, @xmath . Solid: vector
    current. Dashed: axial current.
-    2.7 The soft region, with jet boundaries (solid) and mapped region
    (dashed), for @xmath GeV, @xmath .
-    2.8 Beam jets (B,C) and dead region (D) in initial-state branching.
-    2.9 Beam jet (B), outgoing jet (C) and dead region (D) in
    initial-final state branching: @xmath , @xmath , @xmath .
-    2.10 Beam jet (B), outgoing jet (C) and dead region (D) in
    initial-final state branching: @xmath , @xmath , @xmath .
-    2.11 Phase space for decay @xmath , with symmetric choice of
    emission regions for the @xmath ( @xmath ) and the @xmath ( @xmath ,
    @xmath ), and the dead region ( @xmath ).
-    2.12 Phase space for decay @xmath , with maximal region ( @xmath )
    for emission from the @xmath , together with complementary regions
    of emission from the @xmath ( @xmath , @xmath ) and the dead region
    ( @xmath ).
-    3.1 Primary cluster mass distribution in the @xmath annihilation at
    various centre-of-mass energies, @xmath , for clusters containing
    only light quarks (left) and a @xmath quark (right).
-    3.2 Cluster Fission. Cluster of mass @xmath decays into two new
    clusters of masses @xmath and @xmath by drawing a pair from the
    vacuum.
-    3.3 The distribution of given in ( 3.5 ) (blue, dash-dotted) and
    the actual correlated distributions (black/red, solid) when ( 3.4 )
    are applied. This is for a cluster mass of 1 GeV, @xmath and all
    three constituent masses @xmath GeV.
-    3.4 The ratio of @xmath to @xmath as the cluster mass is increased
    and with different number of hadrons in the @xmath list. The
    vertical bars indicate the threshold for a new set of hadrons to be
    produced.
-    3.5 The ratio of @xmath to @xmath as the cluster mass is increased.
    When new hadrons become accessible the ratios differ from one,
    sometimes drastically.
-    3.6 The cluster mass distribution after cluster fission. This is
    using the default parameter set. It can be seen that the heavy
    clusters no longer exist and are instead folded into the lighter
    part of the distribution.
-    3.7 Plot of @xmath for all flavours. Data from OPAL collaboration.
-    3.8 Plot of @xmath for @xmath flavours. Data from OPAL
    collaboration.
-    3.9 Plot of @xmath for @xmath . Data from OPAL collaboration.
-    3.10 Plot of @xmath for @xmath . Data from OPAL collaboration.
-    3.11 Plot of @xmath for @xmath . Data from OPAL collaboration.
-    4.1 This figure shows a function being integrated which has been
    divided into two regions, @xmath and @xmath .
-    4.2 Available phase space of light (left) and @xmath –quarks
    (right) for @xmath splitting for various values of @xmath and
    depending on the parameterization in terms of @xmath , eq. ( 4.40 ).
    The dashed lines on the right correspond to a @xmath which is not
    mass dependent, obtained by setting @xmath in ( 4.40 ).
-    5.1 The distribution of the charged particle multiplicity.
-    5.2 Jet multiplicities for different values of the cutoff parameter
    @xmath and different centre-of-mass energies.
-    5.3 Jet rates in the Durham algorithm for different values of the
    cutoff @xmath .
-    5.4 Durham @xmath distributions for different values of the cutoff
    @xmath .
-    5.5 Thrust without (top left) and with (top right) matrix element
    corrections switched on, thrust major and thrust minor (bottom).
-    5.6 @xmath parameter and @xmath parameter distribution.
-    5.7 Sphericity, planarity, and aplanarity parameter distribution.
-    5.8 The wide and narrow jet broadening measures @xmath and @xmath .
-    5.9 The high and low hemisphere masses.
-    5.10 Four jet angle distributions. The points are from preliminary
    DELPHI data.
-    5.11 Momentum distributions of charged particles with respect to
    the thrust axis, @xmath (with and without matrix element
    corrections), @xmath and @xmath .
-    5.12 The scaled momentum distribution @xmath of charged particles
    for all events as well as for @xmath , @xmath and @xmath events
    separately.
-    5.13 The scaled momentum distribution @xmath of protons, shown
    separately for all events as well as for @xmath , @xmath and @xmath
    events.
-    5.14 Distribution of scaled Kaon momentum and @xmath momentum.
-    5.15 The @xmath –hadron fragmentation function. For different
    values of the cutoff @xmath .
-    6.1 These diagrams are the one loop corrections to the Higgs mass
    for fermions and scalars.
-    6.2 The different diagrams that contribute to the one-loop
    correction of the scalar mass matrix element @xmath .
-    6.3 The different diagrams that contribute to the one-loop
    correction of the vector mass matrix element @xmath .
-    6.4 The different diagrams that contribute to the one-loop
    correction of the fermion mass matrix element @xmath .
-    6.5 The scale dependence of the different gauge couplings. The
    black (solid) lines are for the EW model with one fermion
    generation. The red (dashed) lines are for the SM with all three
    fermion generations. The blue (dot-dashed) lines show the the
    couplings for the set of particles in the MSSM.
-    6.6 The three- and four-point diagrams that must have their 1PI
    diagrams computed to define the complete set of @xmath functions for
    a theory.
-    6.7 The effective potential of the MSSM for the parameter set
    @xmath plotted in terms of @xmath . This potential can be minimized
    in Effective over the parameters, @xmath and @xmath .
-    6.8 The running of the @xmath mass. This is given by the @xmath
    function of the Yukawa coupling.

###### List of Tables

-    1.1 The fermionic fields of the Standard Model and their charges.
    There are left handed @xmath doublets, @xmath and @xmath , and right
    handed @xmath singlets, @xmath , @xmath and @xmath . There is also
    three families of each type of fermion.
-    3.1 The parameters for Herwig++ . The first group are shower
    parameters, the second are all of the hadronization parameters. The
    meaning of all the parameters is given in chapter 4 .
-    3.2 Multiplicities per event at 91.2 GeV. We show results from
    Herwig++ with the implementation of the old cluster hadronization
    model (Old Model) and the new model ( Herwig++ ), and from HERWIG
    6.5 shower and hadronization (Fortran). Experiments are ALEPH(A),
    DELPHI(D), L3(L), OPAL(O), MK2(M) and SLD(S). The @xmath indicates a
    prediction that differs from the measured value by more than three
    standard deviations.
-    3.3 @xmath results for the different cluster decay methods.
-    4.1 This is a table of all of the relevant hadronization
    parameters. Most of the parameters are discussed in chapter 3 and
    the rest are discussed in this section.
-    5.1 The parameters for Herwig++ used in this study. The first group
    are shower parameters, the second are all of the hadronization
    parameters. In the third column we show initial values of our study,
    taken from HERWIG .
-    5.2 @xmath values for all observables we studied and a relevant
    subset of parameters.
-    6.1 The interaction states of MSSM and the respective gauge
    charges. There are also three generations of (s)quarks and
    (s)leptons.
-    6.2 The interaction states that mix and yield the mass states. The
    mass states are given by name.

## Chapter 1 Introduction

### 1.1 Field Theory Introduction

This section briefly introduces a few key ideas that are used throughout
high energy physics for calculating predictions of physics. I start by
introducing the Klein-Gordon and Dirac field equations. This is followed
by a discussion of the Lagrangian for both Abelian and non-Abelian gauge
groups. Lastly I explain how calculations are performed in perturbation
theory .

We start by introducing the Klein-Gordon field. This field obeys Bose
statistics and is used to describe all bosons: scalars and vectors. Free
fields of this form obey the Klein-Gordon equation

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

The propagator of a field is the Green’s function of the field equation.
In this case it is the Green’s function of the Klein-Gordon equation. In
order to find this function we must introduce a pole prescription for
the integral. Figure 1.1 shows the contour used for the integral over
@xmath . When the contour is closed below we find the Green’s function
only over the range @xmath . This is called the retarded Green’s
function. For @xmath it is

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

and zero for @xmath .

Using the Feynman prescription of pole contours we find the propagator,
known as the Feynman propagator , for bosonic fields over all @xmath and
@xmath is

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

This can be written as

  -- -- -- -------
           (1.4)
  -- -- -- -------

We now want to see how fields that obey Fermi statistics behave. The
Dirac Equation is the field equation for spin 1/2 fermions. We first
start by introducing the Dirac matrices @xmath . These are in
four-dimensional Minkowski space and are given in a popular
representation by

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

where @xmath is the @xmath identity matrix and @xmath are the Pauli
sigma matrices. Using these matrices we define the following notation:
@xmath and @xmath . The Dirac equation is then

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

Doing the same as for the Klein-Gordon equation, we can find that the
retarded Green’s function, in momentum space, of a Dirac field is

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

Along with the anti-commuting nature of fermions this leads to the
Feynman propagator

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

which is

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

#### 1.1.1 Lagrangian

In classical mechanics, the fundamental quantity is the action, @xmath .
This is the time integral of the Lagrangian @xmath . The quantity @xmath
can be written as a spatial integration of a Lagrangian density, @xmath
. It is @xmath that is generally referred to as the Lagrangian in field
theory. This is also done so throughout this thesis.

The Lagrangian contains the information about all of the fields and
interactions of a theory. The different types of interactions are
mediated by particles which transform according to the adjoint
representation of a gauge group. In the Standard Model (SM), these
particles are gauge bosons; spin 1 particles. The kinetic term for a
gauge boson, @xmath , is

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

In equation ( 1.11 ) the indices @xmath and @xmath are the indices in
the adjoint representation of the group and the indices @xmath and
@xmath are Lorentz indices. @xmath is known as a coupling constant .
These define the relative scale of the term in the Lagrangian when
compared to other terms. The terms @xmath are the structure constants of
the gauge group. Each group has a set of generators @xmath . The
structure constants for the gauge group are given by the relation

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

When @xmath is equal to 0 for all indices the group is called an Abelian
group. When they are non-zero it is called a non-Abelian group. From (
1.11 ) it can be seen that for an Abelian group the gauge fields don’t
interact with themselves. For quantum electrodynamics (QED) the group is
@xmath which is an Abelian group. The gauge field of QED is the photon
and therefore we can see that photons don’t interact with themselves.
For quantum chromodynamics (QCD) this group is @xmath , which is
non-Abelian. It is the non-Abelian nature of this group that gives rise
to the triplet and quartic gluon self-interaction terms which complicate
QCD calculations.

In order for the symmetries of a gauge group to be preserved, all the
terms in the Lagrangian must be invariant under the local gauge
transformations of that group. The Lagrangian is composed of gauge
fields, matter fields and derivatives of both. As the Lagrangian needs
to be invariant under these transformations, only certain combinations
of these fields are possible.

The matter fields furnish the fundamental representation of the group.
In the Standard Model these are fermions or scalars; spin @xmath or spin
0 particles. For a set of local transformations, @xmath , we have the
transformation

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

Here, the indices @xmath and @xmath indicate the fundamental indices and
the index @xmath is the index of the adjoint representation of the
group. In @xmath the adjoint representation runs from @xmath to @xmath
and @xmath is the number of fundamental indices. In @xmath the adjoint
indices run from @xmath to @xmath . For example in @xmath there are 3
adjoint index values and 2 fundamental index values. Likewise in @xmath
there are 8 adjoint index values and 3 fundamental index values.

We now define the covariant derivative for a local transformation. This
is

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

Here @xmath is the coupling constant of the group. As mentioned before,
these govern the relative strength the interactions of one group have
when compared with the other groups. In order to use the Klein-Gordon
and Dirac field equations in the Lagrangian we must replace the partial
derivate @xmath by the covariant derivative @xmath . We also require the
covariant derivative to transform in the same way as the matter fields.
This is the requirement

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

We can use these transformations to define the transformation of the
gauge fields. In the Abelian case this is

  -- -------- -- --------
     @xmath      (1.16)
  -- -------- -- --------

while the non-Abelian case the transformation is more complicated. It is
given by

  -- -------- -- --------
     @xmath      (1.17)
  -- -------- -- --------

This requirement prevents the addition of a term like @xmath to give the
field mass. Instead this must be done by the Higgs mechanism, which is
described in section 1.2.2 .

The coupling constants entered into the Lagrangian are known as bare
couplings . Due to higher order corrections, these are not the same as
the physically observed couplings. Instead the physical coupling is a
renormalized coupling . This means that the higher order corrections
introduce a shift in the coupling.

At first it may seem that there are an infinite number of possible terms
in the Lagrangian that can satisfy gauge invariance. It will be shown in
Section 1.1.2 that higher order terms in perturbation theory will
involve integrals over 4-momenta of virtual particles. These are
divergent integrals. In order to do the calculations these must have
some cutoff imposed at finite momentum, @xmath . Theories where the
observables, expressed in terms of the suitably renormalized parameters,
have values which are independent on @xmath are known as renormalizable
theories. Using this it can be shown that theories which contain a
coupling constant of mass to the negative power are not renormalizable.

The last constraint on the Lagrangian is that it must have dimension
@xmath . Using the constraints of gauge invariance, renormalizability
and the correct dimension of the Lagrangian the only allowable terms in
the Lagrangian, for spinors @xmath , scalars @xmath and vectors @xmath ,
are

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

All of these terms can have some relevant coupling that has mass
dimension larger than or equal to 0. For a more thorough discussion of
gauge invariance, renormalizability and Lagrangian formalism see [ 1 , 2
, 3 , 4 , 5 , 6 ] .

#### 1.1.2 Perturbation Theory

Earlier we found the Feynman propagator for a field that obeys the
Klein-Gordon equation. This can be written as

  -- -------- -- --------
     @xmath      (1.18)
  -- -------- -- --------

where @xmath indicates the time-ordering property of the Feynman
propagator. This propagator describes the free field theory. Physical
predictions can only be made on theories that interact, however. To do
so we work in the interaction picture . We now define a unitary
operator, @xmath , that takes a field at time @xmath to time @xmath in
the presence of an interaction. This is known as the interaction picture
propagator and is defined as

  -- -------- -- --------
     @xmath      (1.19)
  -- -------- -- --------

where we have divided the Hamiltonian into the free field part, @xmath
and the interaction part @xmath . We find @xmath obeys the Schrödinger
equation

  -- -------- -- --------
     @xmath      (1.20)
  -- -------- -- --------

@xmath is the interaction Hamiltonian written in the interaction
picture. This has the form

  -- -------- -- --------
     @xmath      (1.21)
  -- -------- -- --------

Solving this differential equation with the initial condition @xmath we
can find the solution as

  -- -------- -- --------
     @xmath      (1.22)
  -- -------- -- --------

where the time-ordering of an exponential is the Taylor series with each
term time ordered. It is this Taylor series that is used when doing
perturbative calculations. Before we can define these perturbative
calculations we must introduce Wick’s Theorem .

In the interaction picture we can decompose the field @xmath into its
positive and negative energy parts

  -- -------- -- --------
     @xmath      (1.23)
  -- -------- -- --------

The contraction of two fields is defined as

  -- -------- -- --------
     @xmath      (1.24)
  -- -------- -- --------

This is exactly the Feynman propagator that was encountered before

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

This allows us to write the time-ordering of fields as

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

where @xmath indicates the normal ordering . This is just the ordering
of having all creation operators to the right of all annihilation
operators. The identity in ( 1.26 ) is Wick’s theorem.

When computing the vacuum expectation value of a time-ordered product
any uncontracted operators from applying Wick’s theorem give zero (
@xmath ) and the contracted operators are simply Feynman propagators! It
is this decomposition of the time ordered products that leads to Feynman
diagrams.

When we wish to construct higher order terms we will have states that
are created and destroyed and never produce observable particles. These
are known as virtual particles. When computing observables, the
contributions due to these particles must be integrated over their
momenta. As we can see from ( 1.3 ) and ( 1.8 ), these integrals contain
@xmath for each virtual particle and @xmath for the integrals over these
particles. Using power counting it can be shown that some diagrams will
contain integrals like

  -- -------- -- --------
     @xmath      (1.27)
  -- -------- -- --------

These integrals need to be bound above ^(a) ^(a) a These also need to be
bound below, known as an infrared cutoff. This is another problem that
is not related to renormalizability. by an ultra-violet cutoff, @xmath ,
in order to be computed. Observables must be independent of this cutoff
and this condition is what leads to renormalizability, as discussed
previously.

The power of perturbation theory is fully exploited when the coupling
constants are small. This allows us to write ( 1.22 ) as a Taylor series
in order of the coupling constant. Using Wick’s theorem, we can then
decompose the terms of the Taylor series into normal ordered products.
This allows us to use Feynman diagrams to describe each of the normal
ordered products. Where perturbation theory is a good approximation we
only need to evaluate the first few terms of the series in order to
approximately describe the physics. Unfortunately, the magnitude of the
higher order terms cannot be predicted beforehand. Only by calculating
them can one decide how accurate the initial calculation really is.

### 1.2 The Standard Model

The Standard Model (SM) is well established as a model that describes
the particles and all the interactions, except gravity. The predictions
of the model have been tested to high accuracy by the series of LEP
experiments. Recent experimental evidence [ 7 ] shows that neutrino
flavours oscillate which means they must have mass. This is in direct
contradiction to the SM and is the first evidence of physics beyond the
SM. Apart from the incorrect description of the neutrino flavour
oscillation, the model also predicts the existence of the Higgs boson.
This has not been experimentally confirmed to date. This section
explains the particle content of the model, the Higgs mechanism and
properties of QCD.

There are theoretical reasons to believe that at higher energies the
Standard Model will also break down. In section 6.1 I discuss what
shortcomings there are believed to be and a theoretical solution to
these shortcomings, known as supersymmetry (SUSY).

#### 1.2.1 Particle Content

The Standard Model is composed of the @xmath and the @xmath gauge
groups. Properties of the interaction eigenstates are governed by these
groups. The weak and and electromagnetic interactions are not directly
governed by @xmath and @xmath groups, however. Instead the mass
eigenstates are given by the symmetry breaking of these two groups. This
will be discussed in section 1.2.2 .

The gauge fields for these groups are @xmath , @xmath and @xmath . The
field @xmath is known as the gluon field. As mentioned earlier, these
gluons have self-interaction terms. That means a gluon, unlike the
neutral photon, carries a (colour) charge. These terms make calculations
with QCD much more complex than with QED. The @xmath and @xmath bosons
mix through the Higgs mechanism (see section 1.2.2 ) to form the @xmath
, @xmath bosons and the photon, @xmath ^(b) ^(b) b Note the different
font between the gluon field and the photon field. . It is the photon
that mediates the electromagnetic interaction we observe. For each field
we have a term in the Lagrangian given by ( 1.11 ).

The matter content of the Standard Model can be summarized quite simply.
There are leptons, quarks and the Higgs boson. Leptons have @xmath and
@xmath charges and the quarks have @xmath , @xmath and @xmath charges.
The @xmath subscript of the @xmath gauge means that it only couples to
left handed particles. We can see from table 1.1 that there are right
and left handed charged leptons, up-type quarks and down-type quarks but
there are no right handed neutrinos. This means that the left handed
leptons interact with the @xmath and @xmath bosons, but not with the
gluons, @xmath , while the right handed leptons only interact with the
@xmath boson. The left and right handed quarks interact with the gluons
and the @xmath boson. The left handed quarks also interact with the
@xmath bosons while the right handed quarks don’t. Table 1.1 shows the
charges of the fields in each gauge. As will be discussed later, the
Higgs boson has @xmath and @xmath charges.

The strength of the different interactions (QED, Weak, QCD) are dictated
by the relative size of their coupling constants. In QED this constant
is @xmath which is related to the @xmath coupling, @xmath and the @xmath
coupling, @xmath . In weak interactions the @xmath symmetry is broken
and the coupling depends on whether we are coupling to the @xmath bosons
or the @xmath boson. Either way this coupling is smaller then @xmath ,
thus the weak interaction is weaker than the electromagnetic one. The
coupling constant for QCD is @xmath . This is larger than @xmath ; for
fields that interact with gluons the QCD terms are most often the
dominant ones.

There is more to this picture than the couplings being constant,
however. In fact these terms are scale dependent. This is known as the
running of the couplings and will be discussed in section 1.2.3 . It is
believed that at some large scale, the couplings of all the
interactions, including gravity, will be of the same size, thus unifying
the theories.

It is known from experiments that these particles have mass. In the SM
the fermions have right and left handed components which have different
charges under the groups. Due to gauge invariance, a term like @xmath
cannot be added to the Lagrangian to give these fields mass as they have
different @xmath and @xmath charges. Instead, the Higgs mechanism is
used again to define a Yukawa coupling. This will also be explained in
the next section.

#### 1.2.2 Higgs Mechanism

The Higgs mechanism is a mechanism for generating the masses of the
Standard Model particles while keeping the Lagrangian gauge invariant.
The idea hinges on a scalar field being added to the model which has a
non-zero vacuum expectation value (VEV). The scalar can then couple to
the particles in the Standard Model and by doing so defines their
masses. Because the SM Higgs boson has charges under @xmath and @xmath
the non-zero VEV breaks the gauge invariance. This is why the @xmath
boson of the @xmath group is not the mediator of the electromagnetic
interaction. Instead the photon is, which is composed of both the @xmath
boson and the @xmath boson.

The SM Higgs boson field, @xmath , is a @xmath doublet and carries
@xmath charge. This means that it couples to the @xmath bosons and the
@xmath boson through the covariant derivative. The field can be defined
as

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

where @xmath is a unitary operator in @xmath with three degrees of
freedom. These three degrees of freedom are known as the Goldstone
bosons. It is these bosons that are ‘eaten’ in order to give the @xmath
and @xmath bosons mass. Though these terms do not appear as physical
particles they do play a role in calculations depending on the choice of
gauge fixing term, @xmath . @xmath is a real scalar field which has a
zero VEV and is interpreted as the physical Higgs boson field.

The potential of the Higgs boson is given by a linear combination of
@xmath term and a @xmath term. The result is added to the Lagrangian in
the SM. The Lagrangian for the Higgs boson is

  -- -------- -- --------
     @xmath      (1.29)
  -- -------- -- --------

The positive sign in front of the @xmath is different from the standard
mass term in a Lagrangian. Therefore, when the parameters @xmath this
gives the potential a minimum at @xmath . The @xmath and @xmath
parameters also dictate what the VEV of the field is that minimizes the
potential. The particular combination

  -- -------- -- --------
     @xmath      (1.30)
  -- -------- -- --------

defines the value of the VEV that minimizes the potential. Figure 1.3
shows the potential as the VEV is varied for a choice of @xmath . It can
be seen that at @xmath GeV this potential is a minimum. Also in the
figure is the 1-loop effective potential including only the electroweak
(EW) particles and the 1-loop effective potential when all the SM
particles are included. These are also minimized at the same value of
the VEV. This figure was generated by putting the model into the
software Effective , which will be explained in Chapter 6 .

The covariant derivative term, @xmath from ( 1.29 ), when expanded out
is

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

From this term we find that the @xmath boson and the @xmath boson mix.
This is known as spontaneous symmetry breaking as the exact symmetries
@xmath and @xmath are broken down to @xmath and a broken @xmath . We can
see the @xmath is broken as the @xmath bosons and the @xmath have
different masses. The mixing between @xmath and @xmath produces mass
eigenstates with mass squared @xmath and 0. These are then interpreted
as the @xmath boson and the photon, @xmath , respectively. This means
that the mass eigenstates are defined as

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

where @xmath and @xmath . Here @xmath is known as the Weinberg angle.
The mass squared of the @xmath boson is @xmath , where the @xmath bosons
is the combination

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

and @xmath is the complex conjugate.

The electric charge, @xmath , of a field is then given by @xmath .
@xmath is the eigenvalue of the third generator of the @xmath group. For
a @xmath doublet this is @xmath for the first component of the doublet
and @xmath for the second component. @xmath is given as @xmath . We can
see from table 1.1 that the charged leptons have charge @xmath ,
neutrinos have charge 0, up-type quarks have charge @xmath and down-type
quarks have charge @xmath .

The value of the VEV can be determined from the Fermi constant, @xmath .
This is measured as @xmath . It is defined as

  -- -------- -- --------
     @xmath      (1.34)
  -- -------- -- --------

and yields the value @xmath GeV. This value, along with the value of
@xmath then correctly predicts the mass of the @xmath boson as well. The
fact that this mechanism predicts the masses of the @xmath and @xmath
bosons as well as the fact that the photon is massless, in a gauge
invariant way, has led to the belief that the Higgs boson must exist.
Fortunately, even though the particle hasn’t been found yet its mass is
given by @xmath . Since @xmath is only restricted by loop corrections it
gives bounds of the Higgs mass [ 8 ] between 117 GeV and 251 GeV with
95% confidence; experimentally this ceiling has not yet been reached.
Finding the Higgs boson is one of the main goals of the upcoming Large
Hadron Collider (LHC).

The Higgs boson also allows a gauge invariant way to introduce fermion
masses as well. Instead of having a term @xmath for each fermionic field
@xmath we introduce instead a Yukawa matrix @xmath for each fermionic
family (leptons and quarks). The Yukawa term in the Lagrangian is

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

where the subscript @xmath and @xmath denote the left and right handed
fields. The VEV of @xmath then generates the mass terms for all the
fermions and the mixing between families. Of course, we still have
independent parameters to define the mass of the fields.

The most general gauge invariant term that can be added for the quark
masses is

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

The Yukawa matrices are not necessarily symmetric or Hermitian. In fact,
there is no principle that even requires that they are real valued!
However, if @xmath is conserved, this would be true. We can simplify the
form of ( 1.36 ) by diagonalizing the matrices obtained from squaring
the Yukawa matrices, @xmath . Each one defines two unitary matrices,
@xmath and @xmath , for @xmath by

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

where @xmath is the diagonal matrix with elements which are the positive
square roots of the eigenvalues. The Yukawa matrices can then be defined
as

  -- -------- -- --------
     @xmath      (1.38)
  -- -------- -- --------

If we now make a chiral rotation of the right handed fields by @xmath
and the left handed fields by @xmath , these transformations don’t
affect the couplings of these particles to the Higgs field. In this
basis, we also find that @xmath , @xmath and @xmath are conserved.

Since all the up and down type quarks have the identical couplings in
QCD the @xmath matrices commute with the covariant derivative of QCD.
This transformation, however, mixes @xmath and @xmath and does affect
the @xmath couplings. If we now neglect the QCD interactions and write
the Lagrangian in the basis of the @xmath , @xmath and @xmath , rather
than the @xmath ’s and @xmath , we have

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.39)
                                @xmath   
  -- -------- -------- -------- -------- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (1.40)
  -- -------- -------- -------- -- --------

These currents contain an abundance of information. For example, the
first two show that the @xmath couple up-type quarks to down-type quarks
and neutrinos to charged leptons. From the electromagnetic current one
can directly read off the electric charges of the different particles.

We can now see how these currents change when the chiral
transformations, @xmath and @xmath , are applied. We can see that in the
electromagnetic current, @xmath , the transformation matrices cancel out

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

This is also true for @xmath . The current that couples to the @xmath ,
however, does change. This is

  -- -------- -- --------
     @xmath      (1.42)
  -- -------- -- --------

This defines a new matrix

  -- -------- -- --------
     @xmath      (1.43)
  -- -------- -- --------

which is known as the Cabibbo-Kobayashi-Maskawa (CKM) mixing matrix.
This explains why strange quarks enter into weak interactions. The
@xmath boson is able to not only turn up-type quarks into down-type
quarks but also change the generation in the process.

The same arguments that were just given can also be applied to the
lepton families. Since the neutrinos don’t interact in any way except by
the weak interactions we can by convention choose to label the mass
eigenstates of the neutrinos according to the charged lepton partner it
is formed with. Unlike the case of the quarks, there is no way to
distinguish these states in another way. This way a @xmath boson only
couples the neutrinos of one generation to a charged lepton of the same
generation.

#### 1.2.3 Running Coupling

We start by defining @xmath for a theory as @xmath . In QED @xmath is
the electric charge of the positron and the @xmath is the fine structure
constant and is denoted simply by @xmath . In QCD @xmath is @xmath and
the @xmath is labelled @xmath . In order to remove the ultra-violet
divergences in the perturbative series a renormalization procedure is
used. This procedure introduces a mass scale @xmath . Therefore, when we
want to calculate a dimensionless physical observable at mass scale
@xmath , it can only depend on the ratio @xmath , which is not constant.
The choice of @xmath is arbitrary and therefore if we were to hold the
bare coupling of the Lagrangian fixed a physical quantity, @xmath ,
cannot depend on @xmath . Instead it must depend only on @xmath and the
renormalized couplings. We will consider first the running of @xmath ,
as it plays an important role in QCD. In QCD this can all be expressed
as

  -- -------- -- --------
     @xmath      (1.44)
  -- -------- -- --------

Identifying

  -- -------- -- --------
     @xmath      (1.45)
  -- -------- -- --------

the @xmath independence of the observable @xmath for massless particles
can be expressed as

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

It is from this that we define the running coupling @xmath as

  -- -------- -- --------
     @xmath      (1.47)
  -- -------- -- --------

We can then see that

  -- -------- -- --------
     @xmath      (1.48)
  -- -------- -- --------

A solution to ( 1.46 ) is @xmath . Therefore, the scale dependence of
@xmath is due solely to the running of the coupling. By the same means
we can find the running coupling of @xmath for QED interactions.

The running coupling constants are then determined by the
renormalization group equation (RGE),

  -- -------- -- --------
     @xmath      (1.49)
  -- -------- -- --------

These always have at least @xmath dependence as they are extracted from
higher-order loop corrections to the bare vertices of a theory. Fig. 1.4
shows contributions to the @xmath function for QCD at one-loop. Figure
1.4 b shows a new interaction due to the non-Abelian nature of QCD. The
@xmath function in QCD then has the perturbative expansion

  -- -------- -- --------
     @xmath      (1.50)
  -- -------- -- --------

The coefficient @xmath depends on the renormalization scheme. @xmath and
@xmath don’t, however, and are given by

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (1.51)
  -- -------- -------- -------- -- --------

where @xmath , @xmath and @xmath is the number of active flavours. From
this we see that in order for @xmath to be negative (which corresponds
to the leading term of the expansion being positive) we must have @xmath
. For @xmath this is @xmath . If we look at the QED @xmath function

  -- -------- -- --------
     @xmath      (1.52)
  -- -------- -- --------

The leading term of this @xmath is always positive. This is where we can
see the difference the non-Abelian interactions (triplet and quartic
gluon vertices) of QCD makes. QCD is known as an asymptotically free
theory. This means that @xmath becomes smaller as @xmath increases,
corresponding to the opposite sign of the @xmath function.

A fuller discussion of RGEs is given in chapter 6 as a part of the
development of the software Effective .

#### 1.2.4 Asymptotic Freedom

We start first by explaining why the observed charge of the electron
decreases with distance. Referring back to our previous discussion of
the running coupling we see that as @xmath increases the QED coupling
increases. This corresponds to it growing at small distances. This can
be easily explained as follows. The larger the distance between the
observer and the charge means that more electron-positron pairs will be
temporarily created out of the vacuum. These can be considered temporary
electric dipoles which are preferentially aligned with the positive end
towards the electron and the negative end away. Fig. 1.5 shows this
situation. This effectively screens the bare charge of the electron and
it appears to have a smaller charge the further away from the electron
you are.

In QCD, the picture is not quite so clear. We now have three degrees of
colour charge, as opposed to one in QED, and non-Abelian interactions.
There are two ways of describing the difference: either as a dielectric
effect or as a paramagnetic effect.

We start by giving the dielectric effect argument. We can define a
running charge at scale @xmath in terms of the charge at an ultra-violet
cutoff @xmath and a scale-dependent dielectric constant, @xmath . This
is

  -- -------- -- --------
     @xmath      (1.53)
  -- -------- -- --------

and from the previous discussion we find

  -- -------- -- --------
     @xmath      (1.54)
  -- -------- -- --------

This implies that the running charge satisfies the equation

  -- -------- -- --------
     @xmath      (1.55)
  -- -------- -- --------

We see that in QED @xmath is positive meaning the dielectric constant is
greater than one. This corresponds to a screening of the charge. In QCD
we have the opposite case. Here the dielectric constant is smaller than
one. This is an antiscreening of the charge.

If we now assume the vacuum of a relativistic quantum field theory can
be treated as a polarizable medium we can define a magnetic
permeability, @xmath that due to Lorentz invariance must satisfy the
equation

  -- -------- -- --------
     @xmath      (1.56)
  -- -------- -- --------

for all @xmath . We can now analyze the behavour of the magnetic
susceptibility, @xmath . From ( 1.54 ) we have

  -- -------- -- --------
     @xmath      (1.57)
  -- -------- -- --------

This can be broken up into two parts. The first term, known as Pauli
paramagnetism, describes how the spins interact with the magnetic field
and the second term, known as the Landau diamagnetism, describes how the
orbital motion of the particles interacts with the magnetic field. When
the Pauli paramagnetic term is larger then the Landau diamagnetic term
the system is considered a paramagnetic system, otherwise it is
diamagnetic. In QCD the Pauli paramagnetism term has some dependence on
both spin @xmath quarks and spin 1 gluons. The higher spin gluons make a
larger contribution than the quarks. The permeability is given by ( 1.57
) when

  -- -------- -- --------
     @xmath      (1.58)
  -- -------- -- --------

In QCD a contribution from a particle with spin @xmath to @xmath is
given by

  -- -------- -- --------
     @xmath      (1.59)
  -- -------- -- --------

This gives a total @xmath term in QCD of

  -- -------- -- --------
     @xmath      (1.60)
  -- -------- -- --------

From this we can see that the permeability can only be negative (making
it a diamagnetic system) when @xmath . This shows that QCD is
asymptotically free due to the colour charge carrying spin 1 gluons.

QCD is an asymptotically free theory. It also has a coupling which runs.
The running decreases @xmath as @xmath increases and therefore high
energy QCD allows the methods of perturbation theory to be applied.

This is by no means an exhaustive reference of the Standard Model and
more complete descriptions are readily available [ 1 , 2 , 3 , 9 , 10 ]
. This section has, however, described the basics of the particle
content, the Higgs mechanism and two topics of importance in QCD:
running couplings and asymptotic freedom. The existence of the Higgs
boson is taken as an assumption for the development of SUSY, and will be
done so for the remainder of this thesis.

### 1.3 Event Generation

We now move into the discussion of Monte Carlo Event Generators.
Chapters 2 through 5 are all discussions on the development of the event
generator Herwig++ . In this section I start by introducing the Monte
Carlo integration technique and explain why this is so useful for
high-energy particle physics simulations. I then introduce all the
various parts of an event: hard process, parton shower, hadronization
and hadron decays.

#### 1.3.1 Monte Carlo Approach

The idea of the Monte Carlo approach is that the value of an integral
can be calculated using random numbers. The same ideas are also
applicable to sampling based on a distribution. Many calculations of
quantum field theory involve matrix elements where the amplitude squared
is interpreted as a probability; the Monte Carlo approach is an
excellent fit for computer simulations due to these probability
distributions. This is because points can be drawn according to a
distribution, thus simulating a physical event with the correct
probabilities. A more thorough discussion of Monte Carlo integration is
given in [ 11 ] .

##### 1.3.1.1 Simple Monte Carlo Integration

If we pick @xmath random points which are uniformly distributed in a
multidimensional volume @xmath , the basic theorem of Monte Carlo
integration is that the integral of a function @xmath over the
multidimensional volume can be approximated by

  -- -------- -- --------
     @xmath      (1.61)
  -- -------- -- --------

The angle brackets indicate the arithmetic mean over the @xmath points
in @xmath space,

  -- -------- -- --------
     @xmath      (1.62)
  -- -------- -- --------

The “plus-minus” term in ( 1.61 ) indicates an estimation of one
standard deviation of the integral.

To calculate the value of the integral using ( 1.61 ), one simply
generates a set of @xmath values in the volume @xmath which are the
argument of @xmath . Using the two parts of ( 1.62 ) and the set of
values generated the approximate value of the integral is given.

There is also an algorithm known as the rejection algorithm which is
useful when generating values according to a distribution. In this case
we don’t want to calculate the integral but rather generate a point
according to the distribution. This can be done by simply generating the
points uniformly in a volume which is @xmath plus an extra dimension
bounded by the function. If the point generated lies inside the function
we accept the point. Otherwise we reject it and generate a new one. If
we wanted to take the integral, this would then be the percentage of
accepted points times the volume sampled over. If we consider a function
of one variable, @xmath , we would generate @xmath pairs of points,
@xmath . We find the ratio of points where @xmath , and multiply this
ratio by the area the points are generated in. Figure 1.6 shows an
example of this technique. This technique is called integration by
rejection. In the example above the points are generated in an
unweighted manner. It is also possible to make the algorithm more
efficient or add some more information by generating points in a
weighted manner as well.

The method can easily be expanded to integrate over regions with an
unknown volume. Say we want to integrate over a strange region, @xmath ,
of which we do not know the volume. This can also be easily done with
the Monte Carlo technique. Simply expand the region the points are
generated in to a simpler region, @xmath , which contains @xmath , and
the multi-dimensional volume of @xmath is known. When the point lies
outside of the desired region, set the value of the function to 0.

##### 1.3.1.2 Non-Uniform Sampling for Monte Carlo Integration

When working with probability distributions, we will be using the points
that lie inside of the function to be a physical quantity. Therefore, in
the simple approach, there may be many points that are generated, that
aren’t used in the simulation. In particle physics, many of this
distributions have very sharp peaks and valleys. These peaks and valleys
cause a large number of points to be generated which aren’t used. This
is a large waste of CPU time and we would like to optimize this.

Fortunately, this can be done. If we instead generate our points
according to some other distribution, rather than a uniform one, we can
reduce the number of unused points. Optimally, we would want to generate
them according to the function being integrated, but this would require
that we know the value of the integral beforehand! Instead, we find
another function that we can integrate, that is always larger than the
function we would like to integrate. We want to choose this function so
that the sharp peaks and valleys of our unknown integral are also,
approximately, present in our known function. But, in order to sample
according to our new function, it must be invertible.

The evaluation of the integral with this new distribution is not much
different than for a uniform distribution. Again, we will consider a
function of one variable, @xmath . Our known function is @xmath with
integral @xmath . Now we randomly generate the @xmath ’s and evaluate
both @xmath and @xmath . A random number, @xmath between 0 and 1 is also
generated. If @xmath is is less than the ratio @xmath , then the point
is under the function. Otherwise it is not. The value of the integral is
then just @xmath times the percentage of the points under the function.
This technique can greatly reduce the number of unused points that are
generated. The improvement is dependent on how well the known function,
@xmath , estimates @xmath . An example of this is shown in Figure 1.7 .

Luckily, there are some general features for QCD matrix elements that
can be used to take advantage of non-uniform sampling. These are well
known [ 12 , 13 ] and general algorithms have been developed to improve
the efficiency of generating points for these matrix elements.

There are also some other optimizations that can be performed, such as
stratified sampling. One program that is particularly useful for
particle physics integrals is VEGAS [ 14 ] . More detail on these
optimizations is also given in [ 11 ] .

#### 1.3.2 Hard Process

There are two separate momentum regimes that different methods of high
energy physics can be used at. The first is the perturbative regime.
This regime is for high momentum transfer, short distances. In this
regime calculations can be approximated by truncating the time-ordered
series at any order and applying Wick’s theorem. Calculations are
usually calculated in orders of @xmath (couplings). The hard process
fits into this regime. There is also the non-perturbative regime. In
this regime calculations are complicated to perform because as we saw in
Section 1.1.2 calculations depend on a time-ordered exponential and each
term is itself a complicated expression. As was shown earlier, the value
of @xmath is largest in the low momentum transfer regime. This means the
calculations would need to be performed to many orders of @xmath .
Currently calculations to next-to-next-to leading order (leading order +
2 more orders) are state-of-the-art. In fact, in the low momentum
transfer regime one of the tools of perturbative physics, the free field
propagator is not valid anymore. Since non-perturbative calculations are
so difficult, models of physics are usually used instead of trying exact
calculations. The process of hadronization is an example of this.

The hard process is the underlying process that occurs when two beams of
particles are collided. The description of what happens is divided into
two different parts, the actual hard process and the Parton Distribution
Functions (PDFs). A similar division in this discussion is used. Here I
discuss the hard process and in the next section explain the PDFs and
how they affect the hard process.

The hard process of an event is what describes the interaction of high
energy particles that ‘collide’. There are numerous processes for a
given set of incoming particles. For example, in an @xmath collision we
could produce another @xmath pair through a @xmath or a @xmath process.
We could also produce a @xmath pair in similar fashion. In fact, there
is an infinite number of possible final states as any number of photons
or gluons can be emitted by an electrically or colour charged particle.
The higher order terms fall off rapidly however and contribute only a
fraction of the total cross section. The actual process that occurs is
proportional to the fraction of the total cross section for a given
process.

In event generators a specific set of hard processes can be used,
without considering all possibilities. This way different properties
particular to certain hard process can be studied. Given a set of
processes, one is chosen based on the ratio of each cross section to the
total cross sections in the allowable set. At the lowest order of
perturbation theory, there are relatively few processes to calculate for
a given pair of incoming particles. As the next order of perturbation
will contain a new factor of the coupling, these processes are
suppressed. It is impossible to know beforehand what the cross section
for the next order will be; it must be calculated. In particular regions
of phase space (soft and collinear) there is a formalism for the
splitting of a particle, @xmath , into particles @xmath . These can then
be used to generate approximations to higher order diagrams. More detail
on this is given in Section 1.3.4 . These splitting functions are then
used to generate the QED and QCD emissions from a parton. This process
is known as the parton shower .

The development of matrix elements for a given process is a complete
discussion in itself [ 10 , 9 , 3 ] . Here we only give the results of
the main processes studied in this thesis. The first is @xmath [ 4 ] .
The differential cross section for this process with either a @xmath or
@xmath in the @xmath -channel and @xmath the center-of-mass scattering
angle of the outgoing fermions is

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.63)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (1.64)
  -- -------- -------- -------- -- --------

@xmath is the centre-of-mass energy and @xmath and @xmath are the vector
and axial couplings of fermion @xmath to the @xmath boson. These are

  -- -------- -- --------
     @xmath      (1.65)
  -- -------- -- --------

The functions @xmath and @xmath are the contributions from the @xmath -
@xmath interference and the @xmath -exchange, respectively. This process
is of particular importance when comparing the simulations to data taken
at LEP. For center-of-mass energies well below the @xmath peak, the two
functions @xmath can be ignored yielding a differential cross section of

  -- -------- -- --------
     @xmath      (1.66)
  -- -------- -- --------

Integrating over @xmath gives a total cross section of

  -- -------- -- --------
     @xmath      (1.67)
  -- -------- -- --------

Around the @xmath pole, the @xmath term dominates and the cross section
is approximately

  -- -------- -- --------
     @xmath      (1.68)
  -- -------- -- --------

To use simulations for hadron-hadron events another set of matrix
elements is used. Below are the matrix elements squared that have been
spin and colour averaged (summed) over the initial (final) states for
massless partons [ 4 ] .

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (1.69)
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

where @xmath is the spin averaged sum and @xmath are the usual
Mandelstam variables for the process @xmath : @xmath , @xmath and @xmath
.

#### 1.3.3 Parton Distribution Functions

Hadrons are composed of quarks. This means that when two hadrons are
collided, it is some components of the hadrons that interact
fundamentally. Determining which part of the hadrons are the ones that
interact is a complex issue. This is defined by the Parton Distribution
Functions . These are developed from the data of deep inelastic
scattering (DIS) experiments. This section provides a brief discussion
of these functions. For a more detailed discussion, see [ 4 , 15 , 16 ]
. We also discuss how the remaining parts of the hadrons are handled in
a Monte Carlo event generator. These are called the beam remnants .

The factorization theorem allows the study of the parton constituents to
be factorized into a non-perturbative part and a perturbative part. The
non-perturbative part is determined from experiments, while the
perturbative part can be calculated as a perturbation series ordered in
the strong coupling constant, @xmath .

We start by considering the DIS process @xmath . Figure 1.8 shows this
process with the relavant momenta @xmath and @xmath .

We start by introducing the variables

  -- -------- -- --------
     @xmath      (1.70)
  -- -------- -- --------

We now define the hadronic tensor, @xmath . This defines how the hadron
will interact with the photon. This is given by

  -- -------- -- --------
     @xmath      (1.71)
  -- -------- -- --------

where @xmath is the electromagnetic current and @xmath is the spin of
the proton. The variable @xmath is summed over all of the possible final
products of the process. If we require that this tensor conserves parity
and we have unpolarized protons, we find that we can decompose this
unknown tensor into two independent amplitudes, @xmath and @xmath ,
called structure functions. We now write this tensor as

  -- -------- -- --------
     @xmath      (1.72)
  -- -------- -- --------

The total differential cross section for this process in terms of these
structure functions is

  -- -------- -- --------
     @xmath      (1.73)
  -- -------- -- --------

The Bjorken limit is defined as @xmath with @xmath fixed. In this limit
the structure functions depend, approximately, only on @xmath . This
implies the photons scatter off pointlike constituents . If we work in
the ‘infinite momentum frame’ we can ignore the mass of the proton.
Comparing ( 1.73 ) to the spin averaged matrix element for the process
@xmath yields the relation

  -- -------- -- --------
     @xmath      (1.74)
  -- -------- -- --------

where the hat indicates that the stucture function refers to a quark,
not a proton and the @xmath in this context is the fraction of the
protons momentum that the quark constituent carries. Measurements show
that the momentum is not given by a delta function but by a
distribution. This means that the quarks carry a range of momentum
fractions.

The ideas generated by studying the structure functions in the Bjorken
limit are incorporated into the ‘naive parton model’. In this model the
following assumptions are made:

-   @xmath is the probability that quark of flavour @xmath carries a
    momentum fraction between @xmath and @xmath ,

-   the photon scatters incoherently off the quark constituents.

( 1.74 ) can then be written as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.75)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Beyond leading order the ‘naive’ parton model is broken in QCD by
logarithms of @xmath . In the Bjorken limit the transverse momentum is
assumed to be small. The higher order contributions show that is is not
the case though. A quark is able to emit a gluon with large transverse
momentum with probability @xmath at large @xmath . These contributions
give terms proportional to @xmath . It is these terms that break
scaling. When @xmath is large enough, these terms compensate for the
small value of @xmath . The approximation where these terms are summed
to all orders is known as the leading-log approximation (LLA). It is
this approximation that the parton shower is developed at.

The breaking of the scaling means that the functions @xmath gain a scale
dependence and are instead @xmath . These can be written at some
renormalization scale @xmath as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.76)
                                @xmath   
  -- -------- -------- -------- -------- --------

where @xmath is an infrared cutoff and @xmath is a new function, similar
to @xmath but describing a gluon rather than a quark. @xmath is a
splitting function in the case of a quark emitting a gluon before
scattering off the virtual photon, whereas the @xmath is a splitting
function for the case of a gluon splitting into a @xmath pair and the
@xmath scattering off the virtual photon. @xmath is an unmeasurable,
bare distribution. This distribution absorbs all of the collinear
singularities at a ‘factorization scale’ @xmath . @xmath can then be
written in terms of ( 1.76 ) by

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.77)
                                @xmath   
  -- -------- -------- -------- -------- --------

This has absorbed all of the finite contribution, @xmath , into the
parton distributions. It is possible to factor out an arbitrary finite
term from the distributions which leaves behind an additional finite
contribution. This depends on the ‘factorization scheme’. A common
choice is the @xmath scheme in which ( 1.77 ) is expressed as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.78)
                                @xmath   
  -- -------- -------- -------- -------- --------

The functions @xmath and @xmath are called the coefficient functions and
they depend on the factorization and renormalization schemes. These are
the perturbative part of the PDFs. The functions @xmath contain all the
non-perturbative physics.

Though the parton distributions are not derivable in the scope of
perturbation theory, we can see from ( 1.77 ) that the right side cannot
be dependent on @xmath . Taking the partial derivative of both sides
with respect to @xmath , and ignoring the gluon part for simplicity,
yields the DGLAP equation [ 17 , 18 , 19 , 20 ]

  -- -------- -- --------
     @xmath      (1.79)
  -- -------- -- --------

This equation is analogous to the @xmath functions which describe the
variation of @xmath with @xmath . Including all the terms this can more
generally be written as a @xmath –dimensional matrix equation in the
space of the quarks, antiquarks and gluons. This equation is a
fundamental equation for the parton distribution functions as well as
the parton shower.

When developing an event simulation, the PDFs will define which parton
is drawn from the hadron for the interaction. The remaining part of the
hadron is known as the beam remnant. Since the way that hadrons are
formed and stay bound lies in the non-perturbative regime of QCD and is
therefore not well understood, the only way to describe the remnants is
through phenomenological models.

The beam remnant carries a portion of the beam hadron’s momentum and
often will travel straight down the beam pipe, leading to undetectable
physics. This isn’t always the case, however, and these remnants can
lead to some detectable physical results and as such are worth studying.
There are very simple models, such as the UA5 model [ 21 ] that can be
used. This model is simply a parameterization of the data and does not
scale to higher energies. These simple models lack the adequate ability
to describe all the effects of the remnants. Instead there is evidence
to suggest that these remnant can and do interact again within one
event. These models are known as multiple interaction models [ 22 , 23 ]
and are currently still an interesting point of research. The whole
process of the beam remnants and their interactions is known as the
Underlying Event .

#### 1.3.4 The Parton Shower

The hard process will generate a set of final-state particles for a
given set of incoming particles. As the hard process is only accurate up
to a given order, it isn’t able to describe events with high parton
multiplicity. As colliders are able to achieve higher energies, these
high multiplicity events begin to play a larger role in the events.
There is a need to generate these higher multiplicity final states to
some approximation. The Parton Shower is able to generate these states
in the soft and collinear regions of phase space to all orders. It is
also in these soft and collinear regions which the higher order matrix
elements are enhanced.

In this section I explain the parton shower and how it describes the
enhanced soft and collinear regions [ 4 ] . The parton shower is an
approximate perturbative treatment of QCD at momentum transfer-squared
@xmath greater than some infra-red cutoff @xmath . This treatment is
then easy to integrate with a hadronization model which begins at the
cutoff, @xmath , and turns the partonic final state into hadronic
states.

In order to generate the higher multiplicity states we must split a
parton @xmath into two partons @xmath . We start by assuming

  -- -------- -- --------
     @xmath      (1.80)
  -- -------- -- --------

If we have @xmath as an outgoing parton, this corresponds to a timelike
shower ( @xmath ). If it is an incoming parton, this is a spacelike
shower. For the following introduction we will consider the timelike
shower. It can be shown that the spacelike shower retains the same
formulation, it just requires different kinematics.

We can define the energy fraction as

  -- -------- -- --------
     @xmath      (1.81)
  -- -------- -- --------

Now in the region of small angles, which is the region where the matrix
element is enhanced, we have

  -- -------- -- --------
     @xmath      (1.82)
  -- -------- -- --------

and using transverse momentum conservation

  -- -------- -- --------
     @xmath      (1.83)
  -- -------- -- --------

We then find that the matrix element squared for @xmath partons, from a
@xmath splitting in the small angle approximation, is

  -- -------- -- --------
     @xmath      (1.84)
  -- -------- -- --------

where @xmath comes from @xmath and the function @xmath is the helicity
dependent splittings. If we average this over the incoming gluon spins
and sum it over the outgoing gluon spins we get

  -- -------- -- --------
     @xmath      (1.85)
  -- -------- -- --------

This is the unregularized gluon splitting function related to the
Altarelli-Parisi kernel [ 3 ] . If we do the same thing for @xmath and
@xmath we find the unregularized splitting functions

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (1.86)
     @xmath   @xmath   @xmath      (1.87)
  -- -------- -------- -------- -- --------

Here @xmath and @xmath . Therefore we generally find

  -- -------- -- --------
     @xmath      (1.88)
  -- -------- -- --------

We then find the new differential cross section for the @xmath state is

  -- -------- -- --------
     @xmath      (1.89)
  -- -------- -- --------

where @xmath is the appropriate splitting function to generate the new
state.

The parton shower doesn’t just emit one gluon in the soft or collinear
region. It is capable of multiple branchings. We start by introducing
the Sudakov form factor

  -- -------- -- --------
     @xmath      (1.90)
  -- -------- -- --------

Doing this we can write the DGLAP evolution equation ( 1.79 ) as

  -- -------- -- --------
     @xmath      (1.91)
  -- -------- -- --------

which is equivalent to

  -- -------- -- --------
     @xmath      (1.92)
  -- -------- -- --------

This has the solution

  -- -------- -- --------
     @xmath      (1.93)
  -- -------- -- --------

From this equation, the Sudakov form factor is interpreted as the
probability of evolving from @xmath to @xmath without branching. The
infra-red singularity of the splitting function is still not handled,
however, so we must impose an upper limit on @xmath such that @xmath .
The branching for values of @xmath above this are interpreted as
unresolvable . These are emissions of gluons that are so soft they are
undetectable. With the cutoff, the form factor is interpreted as the
probability of not having any resolvable branchings from @xmath to
@xmath .

This idea of the Sudakov form factors easily integrates into the Monte
Carlo method. From the interpretation of the form factors we find that
the probability of evolving from @xmath to @xmath without (resolvable)
branching is @xmath . For time-like branchings we can find the
distibution of @xmath by solving

  -- -------- -- --------
     @xmath      (1.94)
  -- -------- -- --------

where @xmath is a random number in the interval @xmath .

When evolving space-like partons the structure of the hadron must be
maintained. We can see from ( 1.92 ) that this requires using the ratio
@xmath . This means we must find the distribution of @xmath by solving

  -- -------- -- --------
     @xmath      (1.95)
  -- -------- -- --------

In either case if the value of @xmath is higher than the hard
subprocess, @xmath , then we have reached the no branching condition for
that parton.

In the timelike case, if a branching does occur, we then need to
calculate the momentum fraction, @xmath . This is done by solving

  -- -------- -- --------
     @xmath      (1.96)
  -- -------- -- --------

where @xmath is another random number in the interval @xmath . To
construct the momentum of the products of the emission we simply need to
generate an azimuthal angle in the interval @xmath . If polarization
correlations are taken into account, then this angle won’t be uniform.

The spacelike case isn’t very different. In this case we are evolving
backwards and trying to maintain the structure of the beam particle
which is known from the PDF. This requires the modification to the
distribution of @xmath of

  -- -------- -- --------
     @xmath      (1.97)
  -- -------- -- --------

Another important aspect of these branchings is angular ordering [ 4 ] .
Coherent parton branching shows that each successive emission must lie
within a cone with half angle given by the previous emission. This
effect is also present in QED radiation. In this case it is easier to
explain the angular ordering effect. Since the charge partner is created
with angle, @xmath , an emission outside of this angle would effectly
appear to be an emission from a chargeless object. In a sense, it can’t
be determined which particle this emission came from, making it an
incoherent emission. Therefore a coherent emission from a particle must
be emitted within the half angle of the previous emission. A similar
logic can be applied to QCD radiation, though it is not as
straightforward due to the three degrees of colour charge but yields the
same result. This means that each emission is restricted to have a
smaller angle then the previous emission.

In order to have a coherent parton branching, the shower needs to evolve
with a variable related to @xmath , rather then one related to the
virtuality. This is given by

  -- -------- -- --------
     @xmath      (1.98)
  -- -------- -- --------

In HERWIG [ 24 ] the variable used, which ensures angular ordering, is

  -- -------- -- --------
     @xmath      (1.99)
  -- -------- -- --------

In Pythia [ 25 ] an angular ordered variable is not used. Instead, a
virtuality ordered shower is used and emissions that violate angular
ordering are vetoed. Part of my research has been into a new set of
evolution variables. This new work is discussed in Chapter 2 .

The shower does have some more complications, however. It is possible to
calculate matrix elements to higher order. It is desirable to use these
matrix elements as they contain all of the terms at a particular order,
whereas the shower includes some of the terms at next-to-leading log
(NLL). As these higher order matrix elements are enhanced in the soft
and collinear regions it is desirable to use the shower in these regions
and the matrix element in the hard regions. In order to do so properly,
over- and under-counting must be prevented. This process is called the
matrix element corrections .

There are two types of corrections, hard and soft. The soft corrections
are when the shower approximation is corrected so that it is closer to
the hard matrix element. This means that a gluon from the shower is
prevented from occuring as it has already been properly considered in
the matrix element. The hard corrections are when the first gluon
emitted is determined to come from the matrix element, rather than the
shower. The region where the matrix element is used and the region where
the shower is used need to match smoothly in order to correctly describe
the physics and these corrections ensure the smooth matching of the two.

The matching of the parton shower and the higher order matrix elements
is important for generating useful results and ensuring that the
simulations describe the theory as accurately as it can. There are two
different problems with matching higher order diagrams. The first is in
ensuring that all of phase space is properly covered by the
next-to-leading order matrix element [ 26 ] . There is also a need to
ensure the shower and matrix element match at next-to-leading log (NLL)
without double counting [ 27 ] . The decays of heavy quarks and other
heavy coloured particles (such as SUSY particles) can also involve the
parton shower. The showering of these processes and the matrix element
corrections to them have also been studied [ 28 ] .

#### 1.3.5 Hadronization

After the parton shower, we are left with a set of partons that are of
the same order in virtuality as the cutoff on the parton shower, @xmath
. At this stage the interactions between the partons become heavily
influenced by non-perturbative effects in the low momentum-transfer,
long distance regime.

A hadronization model must take the partons from virtuality @xmath down
into stable and unstable hadrons. We would expect that there would be
more hadrons created when @xmath is larger, as they have a higher
virtuality. Likewise we would expect there to be more partons at the
initial stage of hadronization if @xmath is smaller.

Since hadronization models aren’t that well understood, it turns out
that carefully letting the parton shower run to lower scales produces
better results. This implies that though the parton shower only contains
perturbative results, these are often still more valid than
hadronization models. Quarks and gluons are not observed in collider
experiments, hadrons are; therefore in the end we must use a
hadronization model to study collider physics.

The simplest model is to assume that each parton produces hadrons
independently of the other partons. This is known as the Independent
Fragmentation Model . This was originally designed by Field and Feynman
[ 29 ] to approximate scaling of energy distributions observed in quark
jets in @xmath events at moderate energy. This model takes a quark and
pairs it with an anti-quark in a @xmath pair drawn from the vacuum. This
forms a meson and the remaining quark fragments the same way. This
continues until the leftover energy falls below a threshold. In this
model the gluon is split into @xmath pairs. The momentum can be
distributed in many ways. All the momentum can be given to one of the
pair so a gluon behaves just like a quark in this model. The momentum
could also be given by the @xmath Altarelli-Parisi splitting function.
This model has several problems. As the final partons are supposed to be
on mass-shell it can lead to momentum conservation problems. Since there
are low energy quarks remaining in this model, there is also a problem
of colour flow.

Another model is the String Model . This model assumes that two colour
connected partons have some colour field between them that grows with
seperation. It is usually assumed to have a uniform energy per length.
This amounts to a linear quark confining potential. When this “string”
between the two quarks contains too much energy it breaks and a @xmath
pair fill each side of the break. This continues until each string is
considered “stable”. At this point each part forms hadrons from the
flavours that are colour connected. Gluons in this model form kinks in
the strings because they carry a localized energy and momentum. It is
the hadronization of these kinked strings that generates results that
match experiments better than the independent fragmentation model. This
is the model that is implemented in Pythia [ 25 ] .

The model that is implemented in HERWIG is the the cluster hadronization
model . This model tries to cluster quarks together to form hadrons. The
cluster model of hadronization relies on the colour preconfinement
property of parton branching [ 30 ] . This property implies that pairs
of colour-connected neighbouring partons have a mass distribution that
falls off rapidly at high masses. It then makes sense to cluster these
partons into colour-singlet clusters that can decay into observable
hadrons.

The gluons in a cluster model must be split in order to form clusters.
This is done non-perturbatively as we are in the non-perturbative
regime. This means that the gluons are just split as a two body decay.
This allows the colour connected quarks to form colour singlet clusters.
It is important to note that in order to do the non-perturbative
splitting, the gluons have to be given an effective mass. The value of
this mass dictates the available flavours for the splitting. A common
value of 750 MeV is used and this allows the gluon to split into @xmath
and @xmath flavours. A new cluster model [ 31 ] is also used in the new
event generator SHERPA [ 32 ] .

I have developed a new model based on the old HERWIG cluster model. This
new model and the improvements it provides are discussed in Chapter 3 .

#### 1.3.6 Decays

The last part to using the Monte Carlo method in collider simulations is
the decays of the hadrons. There are thousands of decay modes of hadrons
and unstable particles from the Particle Data Group [ 33 ] . Some of
these modes are quite rare, others quite common. Since there are so many
modes, and most of them are for hadrons, calculating a distribution for
the decay particles is not easy, or even always possible.

Though exact calculations aren’t always possible, there may be simple
distributions that are better fits to reality based on certain
properties, such as parity violation. In Herwig++ a few of these simple
matrix elements have been included, in much the same way that they were
included in HERWIG . The two commonly used decay matrix elements are for
three-body decays with the decaying particle of mass @xmath decaying
into particles of masses @xmath and @xmath . For free particles that
decay weakly the free massive @xmath matrix elements is used. The decay
momenta, @xmath are generated in the three body phase space with the
weight @xmath given by

  -- -------- -- ---------
     @xmath      (1.100)
  -- -------- -- ---------

where @xmath is @xmath and is given by

  -- -------- -- ---------
     @xmath      (1.101)
  -- -------- -- ---------

For bound particles that decay weakly this same matrix element is used
but it has a veto placed on it. This veto is to ensure that the decay
products are moving away from each other fast enough to no longer be
bound.

Decays aren’t always confined to happening after hadronization, however.
In the SM, for example, the top quark will decay before it ever
hadronizes. Also the @xmath will decay before it leaves the detector. In
fact in SUSY there are many more particles that decay before they
hadronize. Often these particles are fermions and so spin correlations
can play an important part in the distributions. I present here a method
which can be integrated into Monte Carlo simulations to provide the full
spin correlations to these particles [ 34 ] .

This algorithm is difficult to explain in a completely abstract manner.
Instead an example will be presented here. Consider a @xmath hard
subprocess. Here we label the incoming particles @xmath and @xmath and
the outgoing particles @xmath to @xmath . The momenta of these particles
are given by the matrix element

  -- -------- -- ---------
     @xmath      (1.102)
  -- -------- -- ---------

where @xmath is the spin density matrix of the incoming particles,
@xmath are the incoming particles helicity, @xmath is the matrix element
of the @xmath process, @xmath is the helicity of the @xmath and @xmath
is the decay matrix for the @xmath . Initially all the @xmath are just
@xmath and the spin density matrices are given as @xmath for unpolarized
incoming particles and

  -- -------- -- ---------
     @xmath      (1.103)
  -- -------- -- ---------

for longitudinally polarized spin @xmath incoming particles. Here @xmath
is the component of the polarization parallel to the beam axis.

Next a @xmath is chosen at random. The spin density for this particle is
given by

  -- -------- -- ---------
     @xmath      (1.104)
  -- -------- -- ---------

where the normalization @xmath is chosen so the trace of the spin
density matrix is one. The decay mode of this particle is selected based
on the branching ratios. This produces particles @xmath to @xmath with
helicity @xmath . The momentum of these particles is given by the matrix
element

  -- -------- -- ---------
     @xmath      (1.105)
  -- -------- -- ---------

Another randomly selected decay product, @xmath , is chosen from the
decay of @xmath . The spin density for this new decay product is

  -- -------- -- ---------
     @xmath      (1.106)
  -- -------- -- ---------

where again the normalization is chosen so the trace of the spin density
matrix is one.

This process of decaying the products continues all the way up the decay
chain until a stable particle is reached. Once this occurs the decay
matrix is fixed as an identity matrix (i.e. @xmath ). Once all of the
decay products of a particle have been handled the decay matrix for the
particle is calculated. Returning to our example, assume that the
particle @xmath has had all of its decay products generated. Its decay
matrix would be

  -- -------- -- ---------
     @xmath      (1.107)
  -- -------- -- ---------

where this too is normalized so the trace is one.

This whole process continues for all @xmath until all the decay products
have had their spin density matrices and there decay matrices
calculated. Since all the spin information is passed up the chain via
the spin density matrices and then passed back down the chain via the
decay matrices, the whole event has the complete spin correlations built
into the decay products. For a more thorough discussion and examples of
the spin correlation effects see [ 34 ] .

There are many packages available that perform selected decays using
more advanced algorithms. These can almost always be implemented into
the Monte Carlo simulations at this point. One example of this is EvtGen
[ 35 ] . This package uses decay amplitudes, rather than probabilities,
so it can correctly generate the angular correlations in a decay chain.
Many of the decay modes in this package have been developed from
experimental data and therefore, match data much better than the simple
model built into Herwig++ .

## Chapter 2 New formalism for QCD parton showers

### 2.1 Introduction

The parton shower approximation has become an important component of a
wide range of comparisons between theory and experiment in particle
physics. Calculations of observables that are asymptotically insensitive
to soft physics are known as infrared safe observables. These can be
performed in fixed-order perturbation theory, but the resulting final
states consist of a few isolated partons, quite different from the
multihadron final states observed experimentally. One can attempt to
identify isolated partons with hadronic jets, but then the energy flows
within and between jets are not well represented.

Currently, the only means of connecting few-parton states with the real
world is via parton showers, which generate high-multiplicity partonic
final states in an approximation that retains enhanced collinear and
soft contributions to all orders. Such multiparton states can be
interfaced to a hadronization model which does not require large
momentum transfers in order to produce a realistic hadronic final state.
Hadronization and detector corrections to the fixed-order predictions
can then be computed, and the results have generally been found to be in
satisfactory agreement with the data. Infrared-sensitive quantities such
as hadron spectra and multiplicities have also been described
successfully using parton showers. This has strengthened the belief that
similar techniques can be used to predict new physics signals and
backgrounds in future experiments.

This chapter presents a new shower evolution formalism [ 36 ] , based on
an angular variable related to transverse momentum [ 37 , 38 , 39 , 40 ]
. The main aim of these new variables is to retain the direct angular
ordering of the shower while improving the Lorentz invariance of the
evolution and simplifying the coverage of phase space, especially in the
soft region. The old shower variables used in HERWIG used massless
splitting functions which created an artificial lower bound for the
transverse momentum. This created an artificial “dead cone” in the
emission from heavier quarks in which no emissions could lie. By
allowing evolution down to zero transverse momentum and the use of
mass-dependent splitting functions, the new shower variables permit a
better treatment of heavy quark fragmentation which eliminates these the
sharply-defined collinear “dead cones”.

In the following section the new shower variables and their associated
kinematics and dynamics are defined. The appropriate argument of the
running coupling, the mass-dependent parton branching probability, and
the shower evolution cutoff are also given. The variables are defined
slightly differently for initial- and final-state parton branching, and
depend on the colour connection of the evolving parton, so in subsequent
sections the various possible configurations of colour flow between
initial and final jets are considered.

The formalism presented here is implemented in the new Monte Carlo event
generator Herwig++ [ 41 ] which is described in detail in Chapter 4 .
Results for @xmath annihilation and comparisons with LEP data have been
presented in a separate publication [ 42 ] and are also given in Chapter
5 . The formulae in this chapter could also be used to construct a
matching scheme for next-to-leading order (NLO) QCD calculations and
Herwig++ parton showers, similar to that developed for HERWIG showers in
[ 43 , 44 ] and implemented in the MC@NLO event generator [ 45 ] .

### 2.2 New variables for parton branching

As mentioned in Chapter 1 there are two types of shower evolutions. When
a parton is space-like ( @xmath ) it is an initial-state parton and is
described here as part of the initial-state shower. When a parton is
time-like ( @xmath ) it is a final-state parton and is described as part
of the final-state shower. Each individual splitting of a parton is
referred to as a branching. The complete branching history of a given
parton is called its evolution and the collection of all the evolutions
of all the final- (initial-) state partons is referred to as the final-
(initial-) state shower.

#### 2.2.1 Final-state quark branching

##### 2.2.1.1 Kinematics

Consider parton branching in an outgoing (heavy) quark jet. Define the
quark momentum after the @xmath th gluon emission @xmath (see figure 2.1
) in the Sudakov basis as

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath is the jet’s “parent parton” momentum ( @xmath , the
on-shell quark mass-squared), @xmath is a lightlike “backward” 4-vector
( @xmath ), and @xmath is the transverse momentum ( @xmath , @xmath ).
Then

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

The momentum fraction and relative transverse momentum are now defined
as

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

Then we have

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

##### 2.2.1.2 Running coupling

As mentioned in Chapter 1 the QCD coupling constant, @xmath is scale
dependent. This means that we need to decide what the right scale of a
branching is. To find the optimal argument of @xmath , we consider the
branching of a quark of virtuality @xmath into an on-shell quark and an
off-shell gluon of virtuality @xmath [ 46 ] . From ( 2.4 ), the
propagator denominator is

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

The dispersion relation for the running coupling is supposed to be

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

where @xmath is the discontinuity of @xmath . The first term on the
right-hand side comes from cutting through the on-shell gluon, the
second from cutting through the gluon self-energy. In our case we have
@xmath in place of @xmath . We are interested in soft gluon resummation
( @xmath ) [ 40 ] and so we ignore the factor of @xmath here. Thus the
suggested argument of @xmath is @xmath . In practice a minimum
virtuality is imposed on light quarks and gluons in the parton shower,
and therefore the actual argument is slightly more complicated (see
below).

##### 2.2.1.3 Evolution variable

The evolution variable is not simply @xmath since this would ignore
angular ordering. To have angular ordering, for massless parton
branching, the evolution variable should be @xmath [ 47 ] . For gluon
emission by a massive quark we assume this generalizes to @xmath . To
define a resolvable emission we also need to introduce a minimum
virtuality @xmath for gluons and light quarks. Therefore from ( 2.5 )
the evolution variable is

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

where @xmath . For the argument of the running coupling we use

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

The @xmath term allows for massive quarks to evolve down to @xmath ,
i.e. inside the dead cone [ 48 , 49 ] .

Angular ordering of the branching @xmath is defined by

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

The factor of @xmath enters because the angle at each branching is
inversely proportional to the momentum fraction of the parent. Similarly
for branching on the gluon, @xmath , we require

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

##### 2.2.1.4 Branching probability

For the parton branching probability we use the mass-dependent splitting
functions given in ref. [ 39 ] . These are derived in the
quasi-collinear limit , in which @xmath and @xmath are treated as small
(compared to @xmath ) but @xmath is not necessarily small. In this limit
the @xmath splitting function is

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

It is the second term of this equation which differs from the splitting
functions used in HERWIG . Note that at @xmath the factor in square
brackets is just @xmath , i.e. the soft singularity at @xmath becomes a
zero in the collinear direction. The minimum virtuality @xmath serves
only to define a resolvable emission, and therefore we omit it when
defining the branching probability in terms of the evolution variable (
2.7 ) as

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

#### 2.2.2 Gluon splitting

In the case of a final-state gluon splitting into a pair of heavy quarks
of mass @xmath , the quasi-collinear splitting function derived in [ 39
] is

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

We note that this splitting function is bounded above by its value
@xmath at the phase space boundary @xmath , and below by @xmath . By
analogy with ( 2.7 ), in this case the evolution variable @xmath is
related to the virtuality of the gluon or the relative transverse
momentum of the splitting by

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

In terms of the variables @xmath , the @xmath branching probability then
reads

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

In the case of gluon splitting into gluons, the branching probability
takes the familiar form

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

Since we introduce a minimum virtuality @xmath for gluons, the
relationship between the evolution variable and the relative transverse
momentum for this splitting is as in ( 2.14 ) but with the heavy quark
mass @xmath replaced by @xmath . Similarly, for gluon splitting to light
quarks we use ( 2.14 ) with @xmath in place of @xmath .

#### 2.2.3 Initial-state branching

Consider the initial-state (spacelike) branching of a partonic
constituent of an incoming hadron that undergoes some hard collisions
subprocess such as deep inelastic lepton scattering. The momenta are
defined as in ( 2.1 ), with the reference vector @xmath along the beam
direction. In this case the evolution is performed backwards from the
hard sub-process to the incoming hadron, as shown in figure 2.2 .

Thus we now define in place of ( 2.3 )

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

Then

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

We assume a massless variable-flavour-number evolution scheme [ 50 , 51
] for constituent parton branching, setting @xmath and putting all
emitted gluons at the minimum virtuality, @xmath . The angular evolution
variable now relates only to the angle of the emitted gluon and
therefore we choose

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

with ordering condition simply @xmath . Correspondingly, for the
argument of the running coupling we now use @xmath .

A different type of initial-state branching occurs in the decay of
heavy, quasi-stable coloured objects like the top quark. Here the
momentum of the incoming heavy object is fixed and evolution is
performed forwards to the hard decay process. In this case we cannot
neglect the mass of the parton and ( 2.19 ) becomes

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

while the branching probability ( 2.12 ) is replaced by

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

#### 2.2.4 Allowed regions and termination of branching

The allowed phase space for each branching is given by requiring a real
relative transverse momentum, @xmath . In final-state @xmath branching,
we have from ( 2.8 )

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

This yields a rather complicated boundary in the @xmath plane. However,
since

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

we see that the phase space lies inside the region

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

and approaches these limits for large values of @xmath . The precise
phase space can therefore be filled efficiently by generating values of
@xmath between these limits and rejecting those that violate the
inequality ( 2.22 ). The resulting threshold for @xmath is slightly
larger than but of the order of @xmath .

In gluon splitting, we obtain the allowed phase space range from ( 2.14
) as

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

where @xmath for splitting into heavy quarks, or @xmath more generally.
Therefore, analogously to ( 2.24 ), the phase space lies within the
range

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

Schematically, the parton shower corresponds to selecting a sequence of
@xmath values by solving the equations

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.27)
  -- -------- -------- -------- -- --------

where @xmath are uniform pseudorandom numbers. Whenever the algorithm
selects a value of @xmath below the threshold, branching of that parton
is terminated. The minimum virtuality @xmath thus determines the scale
at which soft or collinear parton emission becomes unresolvable. In the
absence of such a scale one eventually reaches a region where the
perturbative expression for the running coupling is divergent.

One may wish to use a parameterization of @xmath at low scales such that
@xmath is finite. However, a cutoff @xmath is still needed to avoid
divergence of the @xmath and @xmath branching probabilities.
Alternatively one could consider parameterizing @xmath such that @xmath
, e.g.

  -- -------- -- --------
     @xmath      (2.28)
  -- -------- -- --------

where @xmath . Then the total branching probability below @xmath is (for
massless quarks)

  -- -------- -- --------
     @xmath      (2.29)
  -- -------- -- --------

and no explicit cutoff is required, although of course @xmath is
essentially playing the same rôle.

After branching has terminated, the outgoing partons are put on
mass-shell (or given the virtual mass @xmath if lighter) and the
relative transverse momenta of the branchings in the shower are
computed. For final-state gluon splitting we have

  -- -------- -- --------
     @xmath      (2.30)
  -- -------- -- --------

or else, if the parent is a quark,

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

The virtualities of the internal lines of the shower can now be computed
backwards according to ( 2.4 ). Finally, the azimuthal directions of the
@xmath ’s can be chosen [ 34 ] and the full 4-momenta reconstructed
using eqs. ( 2.1 ) and ( 2.2 ).

In initial-state constituent parton branching the evolution is “guided”
by the parton distribution functions (PDFs) of the incoming parent
hadron. Since PDFs are often not tabulated below some scale @xmath , one
may wish to terminate branching whenever @xmath is selected. In that
case the incoming parton is assigned virtuality @xmath and the spacelike
virtualities of internal lines are then reconstructed back from @xmath
to @xmath using the transverse momenta deduced from ( 2.19 ) inserted in
( 2.18 ).

For initial-state branching in the decay of a heavy, quasi-stable
coloured object, the branching proceeds in the opposite direction but
the reconstruction of momenta is similar, using ( 2.20 ) instead of (
2.19 ).

#### 2.2.5 Treatment of colour flows

The remaining sections of this chapter present a detailed treatment of
the colour flows which depend on the choice of the “backward” vector
@xmath and on which quantities are to be held fixed during jet
evolution. Normally @xmath should be taken along the colour-connected
partner of the radiating parton, and the 4-momentum of the
colour-connected system should be preserved. The upper limits on the
evolution variable @xmath for the colour-connected jets should be chosen
so as to cover the phase space in the soft limit, with the best possible
approximation to the correct angular distribution. In setting these
limits we neglect the minimum virtuality @xmath , which is a good
approximation at high energies. In the remaining sections we consider
separately the four cases that the colour connection is between two
final-state jets, two initial-state (beam) jets, a beam jet and a
final-state jet, or a decaying heavy parton and a decay-product jet.

### 2.3 Final-final colour connection

Consider the process @xmath where @xmath is a colour singlet and @xmath
and @xmath are colour-connected. Examples are @xmath and @xmath . We
need to preserve the 4-momentum of @xmath and therefore we work in its
rest-frame,

  -- -------- -- --------
     @xmath      (2.32)
  -- -------- -- --------

where @xmath , @xmath , @xmath and

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

For emission of a gluon @xmath from @xmath we write

  -- -------- -- --------
     @xmath      (2.34)
  -- -------- -- --------

where @xmath , @xmath , @xmath and we choose

  -- -------- -- --------
     @xmath      (2.35)
  -- -------- -- --------

Notice that, if @xmath is massive, the alignment of @xmath along @xmath
is exact only in a certain class of Lorentz frames. However, if we try
to use a massive “backward” vector the kinematics become too
complicated.

To preserve @xmath we require

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

whereas the mass-shell conditions give

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.37)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

where @xmath . Our new variables are

  -- -------- -- --------
     @xmath      (2.38)
  -- -------- -- --------

where from ( 2.7 ) we have

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

and so @xmath . From eqs.( 2.36 )-( 2.39 ) we find

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.40)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

with the @xmath ’s given by ( 2.3 ).

#### 2.3.1 Phase space variables

It is convenient to express the phase space in terms of the Dalitz plot
variables

  -- -------- -- --------
     @xmath      (2.41)
  -- -------- -- --------

Substituting from eqs. ( 2.3 ) and ( 2.3 ), we find

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.42)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.43)
  -- -------- -- --------

The Jacobian factor is thus simply

  -- -------- -- --------
     @xmath      (2.44)
  -- -------- -- --------

and the quasi-collinear branching probability ( 2.12 ) translates to

  -- -------- -- --------
     @xmath      (2.45)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.46)
  -- -------- -- --------

@xmath being the function of @xmath given in ( 2.43 ).

For emission from parton @xmath we write

  -- -------- -- --------
     @xmath      (2.47)
  -- -------- -- --------

where now we choose

  -- -------- -- --------
     @xmath      (2.48)
  -- -------- -- --------

Clearly, the region covered and the branching probability will be as for
emission from parton @xmath , but with @xmath and @xmath , @xmath and
@xmath interchanged.

#### 2.3.2 Soft gluon region

For emission from parton @xmath in the soft region @xmath we have

  -- -------- -- --------
     @xmath      (2.49)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.50)
  -- -------- -- --------

Since @xmath is an angular variable, we can express it in terms of the
angle @xmath between the directions of the emitting parton @xmath and
the emitted gluon in the rest frame of @xmath . In the soft region we
find

  -- -------- -- --------
     @xmath      (2.51)
  -- -------- -- --------

Thus @xmath at @xmath and @xmath as @xmath .

For soft emission from parton @xmath , the roles of @xmath and @xmath ,
@xmath and @xmath are interchanged. To cover the whole angular region in
the soft limit, we therefore require @xmath in jet @xmath and @xmath in
jet @xmath . We also want the slope of the boundaries to match as they
approach the soft limit, while still covering the divergence. In this
case this gives the condition

  -- -------- -- --------
     @xmath      (2.52)
  -- -------- -- --------

and hence

  -- -------- -- --------
     @xmath      (2.53)
  -- -------- -- --------

In particular, the most symmetric choice is

  -- -------- -- --------
     @xmath      (2.54)
  -- -------- -- --------

The largest region that can be covered by one jet corresponds to the
maximal value of @xmath allowed in ( 2.3 ) for real @xmath , i.e. for
the maximal @xmath jet

  -- -------- -- --------
     @xmath      (2.55)
  -- -------- -- --------

#### 2.3.3 Example: @xmath

Here we have @xmath , @xmath , the quark velocity in the Born process
@xmath . The phase space and the two jet regions for the symmetrical
choice ( 2.54 ) are shown in figure 2.3 . The region D, corresponding to
hard non-collinear gluon emission, is not included in either jet and
must be filled using the @xmath matrix element (see below).

For the maximal quark jet we get from ( 2.55 )

  -- -------- -- --------
     @xmath      (2.56)
  -- -------- -- --------

as shown in figure 2.4 together with the complementary antiquark jet
region given by ( 2.53 ).

##### 2.3.3.1 Exact matrix element

The @xmath differential cross section, where @xmath represents a vector
current such as a virtual photon, is given to first order in @xmath by [
52 , 53 ]

  -- -------- -- --------
     @xmath      (2.57)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.58)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (2.59)
  -- -------- -- --------

is the Born cross section for heavy quark production by a vector
current, @xmath being the massless quark Born cross section.

In the case of the axial current contribution @xmath , instead of ( 2.57
) we have

  -- -------- -- --------
     @xmath      (2.60)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (2.61)
  -- -------- -- --------

@xmath being the Born cross section for heavy quark production by the
axial current:

  -- -------- -- --------
     @xmath      (2.62)
  -- -------- -- --------

##### 2.3.3.2 Soft gluon distribution

In the soft gluon region @xmath the branching probability ( 2.45 )
becomes

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.63)
  -- -------- -------- -------- -- --------

In this limit, the exact vector and axial current matrix elements,
eqs. ( 2.57 ) and ( 2.60 ) respectively, give identical distributions:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            
     @xmath   @xmath   @xmath            (2.64)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Since from ( 2.50 )

  -- -------- -- --------
     @xmath      (2.65)
  -- -------- -- --------

the parton shower approximation ( 2.3.3.2 ) always overestimates the
true result in the soft limit, and so correction by the rejection method
is straightforward. For small values of @xmath we have

  -- -------- -- --------
     @xmath      (2.66)
  -- -------- -- --------

Since @xmath we see that the error in the approximation ( 2.3.3.2 ) is
at most @xmath , for any value of @xmath (figure 2.5 ).

##### 2.3.3.3 Dead region contribution

The integral over the dead region may be expressed as

  -- -------- -- --------
     @xmath      (2.67)
  -- -------- -- --------

where @xmath parameterizes the boundary of the quark jet. As shown in
figure 2.6 , this is actually maximal, but still small, at the symmetric
point given by ( 2.54 ).

Although the integral in ( 2.67 ) is finite, the integrand diverges as
one approaches the soft limit @xmath via the narrow “neck” of the dead
region in figure 2.3 or 2.4 . This could cause problems in generating
@xmath configurations in the dead region in order to apply a matrix
element correction [ 54 ] . To avoid such problems, one can map the
region @xmath into a region whose width vanishes quadratically as @xmath
, as illustrated in figure 2.7 .

The mapping shown is

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.68)
  -- -------- -------- -------- -- --------

when @xmath . Within the mapped region, the integrand then has an extra
weight factor of @xmath which regularizes the soft divergence. When
@xmath , @xmath and @xmath are interchanged in both the mapping and the
weight.

### 2.4 Initial-initial colour connection

Here we consider the inverse process @xmath where @xmath is a colour
singlet of invariant mass @xmath and @xmath are beam jets. The
kinematics are simple because we take beam jets to be massless: in the
c.m. frame

  -- -------- -- --------
     @xmath      (2.69)
  -- -------- -- --------

For emission of a gluon @xmath from @xmath we write

  -- -------- -- --------
     @xmath      (2.70)
  -- -------- -- --------

where @xmath , @xmath , @xmath . Notice that in this case the recoil
transverse momentum is taken by the colour singlet @xmath so we cannot
preserve its 4-momentum. We choose to preserve its mass and rapidity, so
that

  -- -------- -- --------
     @xmath      (2.71)
  -- -------- -- --------

where as before @xmath . Now we have

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.72)
  -- -------- -------- -------- -- --------

and our new variables in this case are

  -- -------- -- --------
     @xmath      (2.73)
  -- -------- -- --------

Thus we find

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.74)
  -- -------- -------- -------- -- --------

#### 2.4.1 Phase space variables

It is convenient to express the kinematics in terms of the “reduced”
Mandelstam invariants:

  -- -------- -- --------
     @xmath      (2.75)
  -- -------- -- --------

The phase space limits are

  -- -------- -- --------
     @xmath      (2.76)
  -- -------- -- --------

where @xmath is the beam-beam c.m. energy squared. In terms of the
shower variables for beam jet @xmath , we have

  -- -------- -- --------
     @xmath      (2.77)
  -- -------- -- --------

Thus curves of constant @xmath in the @xmath plane are given by

  -- -------- -- --------
     @xmath      (2.78)
  -- -------- -- --------

and the Jacobian factor for conversion of the shower variables to the
Mandelstam invariants is

  -- -------- -- --------
     @xmath      (2.79)
  -- -------- -- --------

For the other beam jet @xmath we have @xmath and thus

  -- -------- -- --------
     @xmath      (2.80)
  -- -------- -- --------

We see that in order for the jet regions to touch without overlapping in
the soft limit @xmath , @xmath , we need @xmath in jet @xmath and @xmath
in jet @xmath , where @xmath . The most symmetrical choice is @xmath ,
as shown in figure 2.8 , but we can take @xmath or @xmath as large as we
like.

#### 2.4.2 Example: Drell-Yan process

Consider radiation from the quark in the Drell-Yan process, @xmath . In
the laboratory frame we have

  -- -------- -- --------
     @xmath      (2.81)
  -- -------- -- --------

where @xmath is the beam momentum. If we generated the initial hard
process @xmath with momentum fractions @xmath , @xmath and we want to
preserve the mass and rapidity of the @xmath we require

  -- -------- -- --------
     @xmath      (2.82)
  -- -------- -- --------

where @xmath and @xmath are given by eqs ( 2.4 ).

The branching probability in the parton shower approximation is

  -- -------- -- --------
     @xmath      (2.83)
  -- -------- -- --------

which gives a differential cross section ( @xmath , etc.)

  -- -------- -- --------
     @xmath      (2.84)
  -- -------- -- --------

where @xmath is the Born cross section. The functions @xmath etc. are
parton distribution functions in the incoming hadrons; these factors
take account of the change of kinematics @xmath discussed above.

The exact differential cross section for @xmath to order @xmath is

  -- -------- -- --------
     @xmath      (2.85)
  -- -------- -- --------

Since @xmath and @xmath , we see that the parton shower approximation (
2.84 ) overestimates the exact expression, becoming exact in the
collinear or soft limit @xmath . Therefore the gluon distribution in the
jet regions can be corrected efficiently by the rejection method, and
the dead region can be filled using the matrix element, as was done in [
55 ] . The benefit of the new variables is that the angular distribution
of soft gluon emission requires no correction, provided the jet regions
touch without overlapping in the soft region. As shown above, this will
be the case if the upper limits on @xmath satisfy @xmath .

### 2.5 Initial-final colour connection

Consider the process @xmath where @xmath is a colour singlet and the
beam parton @xmath and outgoing parton @xmath are colour-connected. An
example is deep inelastic scattering, where @xmath is a (charged or
neutral) virtual gauge boson. We need to preserve the 4-momentum of
@xmath and therefore we work in the Breit frame:

  -- -------- -- --------
     @xmath      (2.86)
  -- -------- -- --------

where @xmath , @xmath , and @xmath . Notice that the beam parton @xmath
is always taken to be massless, but the outgoing parton @xmath can be
massive (e.g. in @xmath ).

#### 2.5.1 Initial-state branching

For emission of a gluon @xmath from the incoming parton @xmath we write

  -- -------- -- --------
     @xmath      (2.87)
  -- -------- -- --------

where @xmath , @xmath , @xmath and we choose

  -- -------- -- --------
     @xmath      (2.88)
  -- -------- -- --------

To preserve @xmath we now require

  -- -------- -- --------
     @xmath      (2.89)
  -- -------- -- --------

whereas the mass-shell condition is

  -- -------- -- --------
     @xmath      (2.90)
  -- -------- -- --------

which gives

  -- -------- -- --------
     @xmath      (2.91)
  -- -------- -- --------

The new variables for emission from the beam jet are as in ( 2.73 ).
Substituting in ( 2.91 ), we find

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.92)
  -- -------- -------- -------- -- --------

#### 2.5.2 Final-state branching

Next consider emission from the outgoing parton @xmath . In this case we
write

  -- -------- -- --------
     @xmath      (2.93)
  -- -------- -- --------

To preserve @xmath we require

  -- -------- -- --------
     @xmath      (2.94)
  -- -------- -- --------

whereas the mass-shell condition is now

  -- -------- -- --------
     @xmath      (2.95)
  -- -------- -- --------

The new variables for emission from an outgoing parton are as in eqs. (
2.38 , 2.39 ) with @xmath replaced by @xmath :

  -- -------- -- --------
     @xmath      (2.96)
  -- -------- -- --------

Thus in this case we find

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.97)
  -- -------- -------- -------- -- --------

#### 2.5.3 Phase space variables

In this process the invariant phase space variables are usually taken to
be

  -- -------- -- --------
     @xmath      (2.98)
  -- -------- -- --------

In terms of the new variables for emission from the beam parton, we have

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.99)
     @xmath   @xmath   @xmath      (2.100)
  -- -------- -------- -------- -- ---------

with the Jacobian

  -- -------- -- ---------
     @xmath      (2.101)
  -- -------- -- ---------

In the soft limit @xmath we therefore find for the beam jet

  -- -------- -- ---------
     @xmath      (2.102)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (2.103)
  -- -------- -- ---------

In terms of the variables for emission from the outgoing parton,

  -- -------- -- ---------
     @xmath      (2.104)
  -- -------- -- ---------

so the Jacobian is simply

  -- -------- -- ---------
     @xmath      (2.105)
  -- -------- -- ---------

and in the soft limit

  -- -------- -- ---------
     @xmath      (2.106)
  -- -------- -- ---------

with the Jacobian again given by ( 2.103 ). For full coverage of phase
space in the soft limit we require @xmath in jet @xmath and @xmath in
jet @xmath , where

  -- -------- -- ---------
     @xmath      (2.107)
  -- -------- -- ---------

Thus the most symmetrical choice is @xmath , @xmath , as shown in figure
2.9 . On the other hand, any larger or smaller combination satisfying (
2.107 ) is allowed, as illustrated in figure 2.10 for @xmath .

#### 2.5.4 Example: deep inelastic scattering

Consider deep inelastic scattering on a hadron of momentum @xmath by
exchange of a virtual photon of momentum @xmath . If the contribution to
the Born cross section from scattering on a quark of momentum fraction
@xmath is represented by @xmath (a function of @xmath and @xmath ), then
the correction due to single gluon emission is given by

  -- -------- -- ---------
     @xmath      (2.108)
  -- -------- -- ---------

In the soft limit @xmath we have, from eqs. ( 2.102 , 2.106 ) with
@xmath ,

  -- -------- -- ---------
     @xmath      (2.109)
  -- -------- -- ---------

and so

  -- -------- -- ---------
     @xmath      (2.110)
  -- -------- -- ---------

whereas the parton shower approximation gives

  -- -------- -- ---------
     @xmath      (2.111)
  -- -------- -- ---------

Since the Jacobian factor ( 2.101 ) or ( 2.105 ) in this limit is simply
@xmath , the shower approximation is exact in the soft limit.

#### 2.5.5 Example: @xmath

We denote the momenta in this process by @xmath and the @xmath
invariants by

  -- -------- -- ---------
     @xmath      (2.112)
  -- -------- -- ---------

so that @xmath . Colour flows from @xmath to @xmath and anticolour from
@xmath to @xmath . Therefore the momentum transfer @xmath is carried by
a colour singlet and we preserve this 4-momentum during showering.

For emission from the incoming light quark or the outgoing top quark, we
work in the Breit frame for this system, where

  -- -------- -- ---------
     @xmath      (2.113)
  -- -------- -- ---------

with @xmath and @xmath . Then the treatment of sects. 2.5.1 and 2.5.2
can be applied directly, with the substitution @xmath since the emitting
system is now @xmath rather than @xmath . However, the phase space
variables are no longer those of sect. 2.5.3 since they involve the
momenta of the @xmath and @xmath , which in the frame ( 2.113 ) take the
general form

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.114)
  -- -------- -------- -------- -- ---------

where @xmath is related to the @xmath invariants:

  -- -------- -- ---------
     @xmath      (2.115)
  -- -------- -- ---------

and so

  -- -------- -- ---------
     @xmath      (2.116)
  -- -------- -- ---------

For emission from the incoming light quark we define as in sect. 2.5.1

  -- -------- -- ---------
     @xmath      (2.117)
  -- -------- -- ---------

for @xmath , where @xmath , @xmath , @xmath , and @xmath is as in ( 2.88
). Then the @xmath ’s and @xmath ’s are given by eqs. ( 2.5.1 ) with the
substitution @xmath . The light antiquark and the antitop are not
affected and therefore @xmath , @xmath . This allows the complete
kinematics of the @xmath process to be reconstructed. The @xmath
invariants can be defined as in ref. [ 44 ] :

  -- -------- -- ---------
     @xmath      (2.118)
  -- -------- -- ---------

It is convenient to express @xmath so that (for @xmath )

  -- -------- -- ---------
     @xmath      (2.119)
  -- -------- -- ---------

Then we find

  -- -------- -- ---------
     @xmath      (2.120)
  -- -------- -- ---------

For emission from the outgoing top we use the results of sect. 2.5.2 ,
again with the substitution @xmath . Thus we now have for @xmath

  -- -------- -- ---------
     @xmath      (2.121)
  -- -------- -- ---------

where the @xmath ’s and @xmath ’s are given by eqs. ( 2.5.2 ) with
@xmath , and we find that

  -- -------- -- ---------
     @xmath      (2.122)
  -- -------- -- ---------

Similar formulae to eqs. ( 2.120 ) and ( 2.122 ), with the replacements
@xmath and @xmath , will hold for the case of gluon emission from the
colour-connected @xmath system. Using these relations, one can study the
distribution of gluon radiation in the parton shower approximation and
compare it with the exact @xmath matrix element. Agreement will be good
in the soft and/or collinear regions but there will be regions of hard,
wide-angle gluon emission in which matrix element corrections should be
applied. Alternatively, the above equations can be used to formulate a
modified subtraction scheme for combining fixed-order and parton-shower
results, as was done in ref. [ 44 ] for a different parton-shower
algorithm.

### 2.6 Decay colour connection

Consider the process @xmath where @xmath is a colour singlet and the
decaying parton @xmath and outgoing parton @xmath are colour-connected.
Examples are bottom quark decay, @xmath , and top decay, @xmath . Here
we have to preserve the 4-momentum of the decaying parton @xmath and
therefore we work in its rest frame,

  -- -------- -- ---------
     @xmath      (2.123)
  -- -------- -- ---------

where @xmath , @xmath and now

  -- -------- -- ---------
     @xmath      (2.124)
  -- -------- -- ---------

#### 2.6.1 Initial-state branching

For emission of a gluon @xmath from the decaying parton @xmath we write

  -- -------- -- ---------
     @xmath      (2.125)
  -- -------- -- ---------

where @xmath , @xmath , @xmath and we choose

  -- -------- -- ---------
     @xmath      (2.126)
  -- -------- -- ---------

i.e. aligned along @xmath in the rest frame of @xmath . The mass-shell
conditions give

  -- -------- -- ---------
     @xmath      (2.127)
  -- -------- -- ---------

with @xmath . From momentum conservation

  -- -------- -- ---------
     @xmath      (2.128)
  -- -------- -- ---------

Recall that in initial-state branching of a heavy object our new
evolution variable is given by ( 2.20 ), so we have

  -- -------- -- ---------
     @xmath      (2.129)
  -- -------- -- ---------

where @xmath . Introducing for brevity the notation

  -- -------- -- ---------
     @xmath      (2.130)
  -- -------- -- ---------

from ( 2.128 ) we find

  -- -------- -- ---------
     @xmath      (2.131)
  -- -------- -- ---------

#### 2.6.2 Final-state branching

For radiation from the outgoing parton @xmath we write

  -- -------- -- ---------
     @xmath      (2.132)
  -- -------- -- ---------

where @xmath is given by ( 2.123 ). Since the colour-connected parton
@xmath is at rest in our working frame of reference, the choice of the
light-like vector @xmath in this case is somewhat arbitrary. By analogy
with the cases treated earlier, we choose it to be opposite to that used
for the radiation from @xmath , i.e. along the direction of the colour
singlet @xmath :

  -- -------- -- ---------
     @xmath      (2.133)
  -- -------- -- ---------

The kinematics are then identical with those for final-final connection
(sect. 2.3 ), with the replacement @xmath , @xmath .

#### 2.6.3 Phase space variables

As in sect. 2.3 , it is convenient to use the Dalitz plot variables,
which in this case are

  -- -------- -- ---------
     @xmath      (2.134)
  -- -------- -- ---------

For emission from the decaying parton @xmath we have @xmath and hence,
from ( 2.131 ),

  -- -------- -- ---------
     @xmath      (2.135)
  -- -------- -- ---------

with the Jacobian factor

  -- -------- -- ---------
     @xmath      (2.136)
  -- -------- -- ---------

In the soft limit @xmath we find

  -- -------- -- ---------
     @xmath      (2.137)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.138)
  -- -------- -- ---------

For emission from the outgoing parton @xmath we have, from ( 2.3.1 )
with the replacement @xmath , @xmath :

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.139)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.140)
  -- -------- -- ---------

In the soft limit we have from ( 2.50 )

  -- -------- -- ---------
     @xmath      (2.141)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.142)
  -- -------- -- ---------

For full coverage of the soft region we require

  -- -------- -- ---------
     @xmath      (2.143)
  -- -------- -- ---------

which gives in this case

  -- -------- -- ---------
     @xmath      (2.144)
  -- -------- -- ---------

Note that, while there is no upper limit on @xmath , the largest value
that can be chosen for @xmath is given by the equivalent of ( 2.55 ),

  -- -------- -- ---------
     @xmath      (2.145)
  -- -------- -- ---------

#### 2.6.4 Example: top decay

In the decay @xmath we have @xmath and @xmath , so for simplicity we
neglect @xmath . Then for radiation from the top we have from ( 2.135 )

  -- -------- -- ---------
     @xmath      (2.146)
  -- -------- -- ---------

where @xmath are given by eqs. ( 2.130 ) with @xmath . The phase space
is the region

  -- -------- -- ---------
     @xmath      (2.147)
  -- -------- -- ---------

Notice that for real @xmath we require @xmath , i.e.

  -- -------- -- ---------
     @xmath      (2.148)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (2.149)
  -- -------- -- ---------

Thus there is no upper limit on @xmath , but the range of @xmath becomes
more limited as @xmath increases.

For radiation from the @xmath we have from ( 2.6.3 )

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.150)
  -- -------- -------- -------- -- ---------

To cover the soft region we require @xmath for emission from the top
quark and @xmath for that from the bottom, where ( 2.144 ) gives

  -- -------- -- ---------
     @xmath      (2.151)
  -- -------- -- ---------

The most symmetrical choice would therefore appear to be @xmath , as
illustrated in figure 2.11 .

As mentioned above, there is no upper limit on @xmath . Thus the region
covered by gluon emission from the top quark can be as large as we like.
However, ( 2.145 ) tells us that the upper limit for radiation from the
@xmath is

  -- -------- -- ---------
     @xmath      (2.152)
  -- -------- -- ---------

and correspondingly @xmath . Figure 2.12 shows this maximal region that
can be covered by emission from the @xmath , together with the
complementary regions of emission from the @xmath .

We note from figs. 2.11 and 2.12 that, for any value of @xmath , the
region for emission from the top quark consists of two distinct parts
that touch at the point @xmath , @xmath , where the @xmath boson is at
rest: a subregion @xmath which includes the soft limit @xmath and a hard
gluon region @xmath .

The exact @xmath differential decay rate to first order in @xmath is
given in [ 56 ] :

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (2.153)
                                @xmath   
  -- -------- -------- -------- -------- ---------

where @xmath is the lowest-order decay rate. In the soft region @xmath ,
@xmath this becomes

  -- -------- -- ---------
     @xmath      (2.154)
  -- -------- -- ---------

For soft gluon emission ( @xmath ) from the top quark we have from
eqs. ( 2.137 , 2.138 )

  -- -------- -- ---------
     @xmath      (2.155)
  -- -------- -- ---------

and so the exact form of the soft gluon distribution is

  -- -------- -- ---------
     @xmath      (2.156)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.157)
  -- -------- -- ---------

In the same region the parton shower approximation ( 2.12 ) gives

  -- -------- -- ---------
     @xmath      (2.158)
  -- -------- -- ---------

Thus we see that, for emission from the top quark, the shower
approximation is exact in the soft limit. At higher gluon energies,
inside the region @xmath the parton shower overestimates the exact
matrix element and can therefore be corrected easily by the rejection
method. In the hard gluon region @xmath , which contributes only a small
finite correction to the cross section, the parton shower overestimates
the matrix element at lower values of @xmath but underestimates it at
the highest values. Therefore a combination of rejection and matrix
element correction is needed in this region.

For emission from the bottom quark in the soft limit, we use the results
of sect. 2.3.2 with the substitution @xmath , @xmath to obtain

  -- -------- -- ---------
     @xmath      (2.159)
  -- -------- -- ---------

Therefore the exact soft gluon distribution in the @xmath jet should be

  -- -------- -- ---------
     @xmath      (2.160)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (2.161)
  -- -------- -- ---------

On the other hand the parton shower approximation in this case gives
simply

  -- -------- -- ---------
     @xmath      (2.162)
  -- -------- -- ---------

Thus the soft gluon distribution in the @xmath jet region is
overestimated by a factor of

  -- -------- -- ---------
     @xmath      (2.163)
  -- -------- -- ---------

which can be corrected by the rejection method. This factor varies from
1 to 5.2 for the symmetric choice of the @xmath jet region @xmath
depicted in figure 2.11 . For the maximal @xmath jet shown in figure
2.12 , it rises to 8.3. Since the shower approximation is exact in the
soft limit for emission from the top, one can reduce the amount of soft
correction required by decreasing the @xmath jet region and increasing
that for top emission, in accordance with ( 2.151 ). However, for large
values of @xmath the dead region moves near to the collinear singularity
at @xmath and a large hard matrix element correction becomes necessary.

### 2.7 Conclusions

A new formulation of the parton-shower approximation to QCD matrix
elements has been presented. This formalism offers a number of
advantages over previous ones. Direct angular ordering of the shower
ensures a good emulation of important QCD coherence effects, while the
connection between the shower variables and the Sudakov-like
representation of momenta ( 2.1 ) simplifies the kinematics and their
relation to phase space invariants. The use of mass-dependent splitting
functions with the new variables allows an accurate description of soft
gluon emission from heavy quarks over a wide angular region, including
the collinear direction. The separation of showering into contributions
from pairs of colour-connected hard partons permits a general treatment
of coherence effects, which should be reliable at least to leading order
in the number of colours. Since the formulation is slightly different
for initial- and final-state showering, formulae for all
colour-connected combinations of incoming and outgoing partons have been
given.

This new shower formulation is a key element of the event generator
Herwig++ [ 41 ] . Chapter 4 and 5 describe how this new formalism is
implemented and complete results for @xmath annihilation are presented.

## Chapter 3 Hadronization

Hadronization is the process in which the perturbative partons (quarks
and gluons) from the shower enter the non-perturbative phase and are
converted into the observed hadrons. This is not well understood and
instead is modelled by a hadronization model. As discussed earlier there
are a few different types of hadronization models. Pythia [ 25 ] uses a
string fragmentation model whereas HERWIG 6.5 [ 24 ] uses a cluster
hadronization model. Here I describe this cluster model and the
modifications that have been made in the new Herwig++ hadronization
model.

### 3.1 Cluster Formation

The shower terminates and leaves colour connected pairs with low
virtuality. These partons need to combine to form hadrons. The first
step of the cluster hadronization is to form clusters out of these
colour connected particles. These clusters are made up of
quark–anti-quark pairs or (anti-)diquark– (anti-)quark pairs. This
section presents each step of the process of cluster formation up until
the decay of the clusters into hadrons.

#### 3.1.1 Gluon Splitting

The initial step of the cluster hadronization is to split the gluons
into quark–anti-quark pairs. Since at the end of the shower the gluons
are put on-shell, they must be given a mass, @xmath , in order to decay
into a quark–anti-quark pair. The default value of this mass is @xmath
GeV. This is then high enough to isotropically decay into @xmath and
@xmath pairs. Each gluon is randomly assigned a decay into either @xmath
quarks or @xmath quarks and is decayed uniformly in @xmath and @xmath .
After the isotropic decays the event is left with only colour connected
(di)quarks and anti-(di)quarks.

#### 3.1.2 Cluster Formation

Clusters are themselves colour-singlets. They can be made up of either
two partons (quark–anti-quark pair) or of three partons (quarks or
anti-quarks all of different colours). In the cluster model of Herwig++
a three parton cluster will occur in baryon non-conserving events, which
have colour sources or sinks, and in events where a beam particle is a
baryon. This can be seen because a cluster composed of three partons has
baryon number @xmath . Since drawing from the vacuum doesn’t change the
baryon number, the decay of these clusters must have baryon number
@xmath . Unless the cluster is derived from a beam baryon, these types
of clusters must only occur in baryon non-conserving events.

A cluster is formed simply by finding a colour-singlet pair (or triplet)
of partons. The 4-momentum of the cluster is just the sum of the momenta
of the partons. Clusters are created for all sets of colour singlets. If
a quark or anti-quark is created from a colour source or sink
(baryon-violating) it forms a three parton cluster with its colour
neighbours. Two of these partons are randomly combined into a diquark
for the purpose of the cluster decay.

The principle of colour-preconfinement says that the invariant mass
distribution of the clusters is independent of the centre-of-mass
energy. This idea is needed to fully separate the perturbative regime
from the non-perturbative regime. Figure 3.1 shows this distribution for
Herwig++ . The first plot in figure 3.1 shows the distribution for the
light clusters. The second plot in figure 3.1 shows the distribution for
the @xmath quarks only. This shows that the fall off of the
distributions is similar for each flavour.

#### 3.1.3 Cluster Fission

The mass of a cluster is given by @xmath of the cluster. In order for
the shower to combine more smoothly with the hadronization, clusters of
a large mass are decayed into two new clusters. If the shower were to be
cut off at a larger scale then there would be fewer more energetic
partons. On the other hand if it were to be cut off at a smaller scale
it would produce many lower energy partons. Splitting the clusters with
large mass into two clusters with smaller mass allows the hadron
multiplicity to be much less variable with the shower cutoff. In turn
this allows the tuning of the shower to not be as dependant on the
hadron multiplicity, making for more consistent results.

A cluster is split into two clusters if the mass does not satisfy the
condition

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath and @xmath are parameters and @xmath is the sum of the
masses of the constituents that make up the cluster.

If a cluster is to be split a @xmath pair is chosen from the vacuum.
Only @xmath or @xmath flavours are chosen with probabilities given by
the parameters @xmath with @xmath being the flavour. Once a pair is
chosen from the vacuum the cluster is decayed into two new clusters with
one of the original partons in each cluster. A schematic of this decay
is shown in figure 3.2 . In the case where the partons are not beam
remnants, the mass distribution of the new clusters are given by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (3.2)
     @xmath   @xmath   @xmath      (3.3)
  -- -------- -------- -------- -- -------

where @xmath and @xmath are the two components of the original cluster,
@xmath is the mass of the parton drawn from the vacuum, @xmath , @xmath
are the new cluster masses and @xmath are random numbers in the interval
@xmath . @xmath is another parameter of the model. If the parton is not
a @xmath quark then @xmath is otherwise it is (see table 4.1 ). Points
are only chosen in the range confined by

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

The corresponding probability density is

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

where @xmath is an arbitrary normalization term. It is important to note
that because of the constraint in ( 3.4 ) the distributions of the two
clusters are correlated and therefore do not exactly follow ( 3.5 ). An
example of this is shown in fig. 3.3

If parton @xmath is from the beam remnant and there is no underlying
event model being used, the cluster fissions with a different
distribution. This distribution has one parameter @xmath , which is set
to 1.0 GeV by default. This is used to define @xmath which gives

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

where @xmath . The mass distribution is then defined by

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

@xmath and @xmath are two flatly distributed random numbers. This mass
distribution is designed to decrease rapidly to avoid splitting the
cluster many times which would produce large transverse energies. This
would not be desired as the beam remnant process is meant to be a soft
process.

### 3.2 Cluster Decays

The last stage of the cluster hadronization model is the cluster decays.
Here the clusters of a given flavour @xmath draw a (di)quark
anti-(di)quark pair @xmath from the vacuum and form a pair of hadrons
with the combination @xmath and @xmath . The possible hadrons are
selected based on spin, flavour and phase space. The exact way of
accepting and rejecting these combinations are described in three
variants: HERWIG 6.5 [ 24 ] , Kupco’s method [ 57 ] and Herwig++ . The
method of Herwig++ is described in the next section.

#### 3.2.1 Herwig 6.5

The method of cluster decays implemented in HERWIG is described here.
Before the software runs, it initialized a list of data for each type of
hadron. This list contains two weights,

-   @xmath : a spin weight for the hadron. This is @xmath where @xmath
    is @xmath for the largest spin of a flavour group. There are three
    of these groups which contain all the hadrons of a given flavor
    combination: (1) @xmath and @xmath , (2) @xmath and (3) all the
    remaining flavours.

-   @xmath : this is a phase space correction weight which is normally
    set to unity.

HERWIG 6.5 chooses a mode in several phases. First a flavour is drawn
out of the vacuum based on the probability

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

The values of @xmath are just parameters for @xmath and @xmath . For the
diquarks, however, the weight is

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

where @xmath is the diquark parameter.

The flavour combinations, @xmath and @xmath , have the possibility of
forming @xmath and @xmath different hadrons, respectively. Hadrons
@xmath and @xmath are chosen randomly from this list. These hadrons have
spin weight @xmath and @xmath and are rejected based on these weights.

Lastly, the resulting pair @xmath are accepted or rejected based on
phase space. The probability is given as

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

where @xmath and @xmath are phase space adjusting parameters and @xmath
is the @xmath value for the lightest hadron pair of the flavours @xmath
. @xmath for a two-body decay is the c.m. momentum in the decay @xmath
and is given by

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

in the region of valid phase space, @xmath . It is set to zero
otherwise.

In the end all of this gives (approximately) the probability of choosing
hadrons @xmath and @xmath as

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

Technically this isn’t the probability because of the rejection scheme
used in the algorithm but it is close and is able to illustrate the main
advantages and disadvantages of the algorithm.

The problem with this method, as described by Kupco [ 57 ] , is that as
more hadrons are added to the list then the particular flavour content
of the new hadrons is suppressed by the growing factor @xmath . In
effect, the probability of choosing a hadron of a given flavour is
proportional to the average of all the @xmath ’s of the flavour. In most
cases a majority of hadrons are inaccessible due to mass contraints.
This leads to a suppression of the lighter hadrons of that flavour, even
for clusters which are too light to decay into the new heavier states.

To look at this further we analyze the result of isospin symmetric
clusters @xmath and @xmath . For a cluster with mass just above
threshold for the production of @xmath and @xmath these should be
produced with the ratio @xmath . It is easy to see that the ratio
between the states generated by @xmath and @xmath are @xmath . Instead
we look here at just the part of the ratio which differs from unity,
@xmath and @xmath . Using ( 3.13 ) we find (after assuming @xmath and
@xmath )

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.14)
     @xmath   @xmath   @xmath      (3.15)
     @xmath   @xmath   @xmath      (3.16)
     @xmath   @xmath   @xmath      (3.17)
  -- -------- -------- -------- -- --------

The @xmath ’s for @xmath and @xmath are equal and the @xmath ’s for
@xmath and @xmath are equal. We can also set the flavour probabilities
to unity. Lastly, the spin weights of the @xmath and @xmath are equal.
We now find the ratio of pions as

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

Obviously, these ratios are dominated by the number of hadrons of a
particular flavour content. It just happens that in HERWIG 6.5 there was
the right number of @xmath and @xmath hadrons in the list to give
approximately the correct ratios. Figure 3.4 shows the ratio for @xmath
as the cluster mass increases for @xmath and @xmath clusters. It can be
seen that the ratios are dictated by the number of @xmath hadrons that
are in the list.

#### 3.2.2 Kupco Method

Kupco [ 57 ] was the first person to point out the problem of
suppression of hadrons when new modes of the same flavours were added.
He realized that the problem was that the probabilities were
proportional to an average of the @xmath ’s of a particular flavour
content.

In order to remedy the problem a new set of probabilities for choosing a
decay mode was used. Instead of splitting the probability into
independant parts, as was done in the original version, one weight was
created for each hadronic mode.

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

The probability is then

  -- -------- -- --------
     @xmath      (3.20)
  -- -------- -- --------

The addition of new hadrons to the list now increases the probability of
choosing that particular flavour. Because a majority of the hadrons are
quite heavy the @xmath for any mode with the new hadron is zero in many
cases. Therefore, this new hadron has no effect on the choice of mode
for lighter clusters.

Again, lets look at the example of decaying @xmath and @xmath clusters
with a cluster mass just above threshold for a @xmath decay.

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.21)
     @xmath   @xmath   @xmath      (3.22)
     @xmath   @xmath   @xmath      (3.23)
     @xmath   @xmath   @xmath      (3.24)
  -- -------- -------- -------- -- --------

With the same assumptions as before ( @xmath ) we get

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.25)
     @xmath   @xmath   @xmath      (3.26)
  -- -------- -------- -------- -- --------

Finally this gives us the ratio

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

and as the @xmath ’s are static a priori weights, we can choose them to
be @xmath which will give the correct ratio of @xmath .

Now if we allow the cluster mass to increase so that the @xmath mode is
accessible, we get the same weights for the @xmath and the @xmath modes
and the new @xmath mode has a weight of

  -- -------- -- --------
     @xmath      (3.28)
  -- -------- -- --------

and similarly for the @xmath cluster. The sum of the weights, without
some common factors and using the same assumptions, is

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

This is the same for both the @xmath and @xmath clusters. Therefore the
probabilities are now

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.30)
     @xmath   @xmath   @xmath      (3.31)
     @xmath   @xmath   @xmath      (3.32)
  -- -------- -------- -------- -- --------

To find the ratio we need to make sure we count the particles correctly.
Doing so we find

  -- -------- -- --------
     @xmath      (3.33)
  -- -------- -- --------

After forcing the right ratio near the @xmath threshold by setting the
@xmath ’s, we now don’t have the right ratio after the @xmath threshold.

Figure 3.5 shows the ratio of @xmath as the cluster mass is increased.
After a new production threshold is reached the ratio changes. The
change can become quite dramatic and the average ratio between
thresholds differs from unity.

Though the ratios vary as the cluster mass changes, this seems overall
to be an improvement from the original cluster decays. We no longer have
the problem that the addition of new hadrons to the lists causes
decreased probability. We now have increased the probability of choosing
a flavour content when new hadrons of that content are added. In doing
so, however, we have created a new problem. In baryon-conserving
processes, we only have clusters with a quark–antiquark pair, rather
then some diquark–quark combination. This means two baryons must be
created at a time by drawing a diquark–antidiquark pair out of the
vacuum. Doing so requires a cluster with a high mass, which in turn
means a new meson added to the list is likely to be available. Consider
a @xmath cluster with high mass. If we have 5 hadrons with @xmath
flavour and 2 baryons with @xmath flavour we will have only 4 possible
combinations of the @xmath flavour baryons but 25 modes of the @xmath
flavour. If all the modes are accessible this makes the baryon
probabilities lower, as they are all normalized by the sum of all
accessible modes. If we then add a 6th hadron to the @xmath list, we now
have 36 combinations. If, again, these are all accessible that decreases
the probability of creating a baryon even more. This problem is
addressed and solved in the new method implemented in Herwig++ and
described in the next section.

### 3.3 Herwig++

The nonperturbative splitting, cluster formation and cluster fission
described in section 3.1 has been implemented in Herwig++ . The method
for decaying clusters is similar to the Kupco method described in
section 3.2.2 but has been changed to account for the lack of baryon
production. Results of the hadronization process in Herwig++ are given
in this section. Also the changes to the cluster decay model are
presented here.

The concept of colour preconfinement says that the mass distribution of
the colour singlet systems, after the parton shower, are independent of
the centre-of-mass energy of the hard process. Figure 3.1 shows the
cluster mass distribution generated from Herwig++ using the default
parameter set. It can be seen that this distribution is indeed
independent of @xmath , the c.m. energy of the hard process.

The cluster fission stage described in section 3.1.3 truncates this
distribution by breaking apart clusters that are above the threshold in
( 3.1 ). Figure 3.6 shows the new distribution after this process. The
two bumps around 2 GeV and 5.5 GeV are from the charm and bottom
clusters. This figure is for the default parameter set ( @xmath GeV). As
can be seen, the heavier part of the distribution is folded into the
lighter part.

#### 3.3.1 Herwig++ Cluster Decay Algorithm

The algorithm used in Herwig++ for cluster decays is very similar to the
method proposed by Kupco. The weights of a particular decay mode is
given by ( 3.19 ). As discussed previously, the problem with Kupco’s
method is that there are not enough baryons produced. This is because of
the quantity of possible decay modes in the meson sector compared to the
quantity of modes in the baryon sector. To fix this problem a way to
separate the two sectors was needed.

The new algorithm separates the meson sector from the baryon sector. The
weights from ( 3.19 ) are still used, but the sum of weights used for
normalizing is only summed over modes in either the meson or baryon
sector. If a cluster mass is high enough to decay into the lightest
baryon pair then the parameter @xmath is used to decide whether to use
the baryon sector or meson sector. There is a @xmath probability of
using the meson sector and a @xmath probability of using the baryon
sector. This change not only allows for more baryons to be created but
also gives more direct control of how many baryons are produced through
the diquark parameter @xmath .

#### 3.3.2 Results

In this section the results of the different hadronization schemes of
Herwig++ for @xmath events at 91.2 GeV are presented. The values of the
parameters in Herwig++ used for this study are given in table 3.1 . This
section presents only a few results related to the new hadronization
method. Full results of Herwig++ including event shapes and jet physics
are given in chapter 5 .

Table 3.2 shows the results of the new cluster hadronization algorithm
in comparison to the old algorithm. The column labeled ‘Old Model’ is
the result of using the old algorithm with the new parton shower in
Herwig++ . The column Herwig++ is the result of using the new cluster
hadronization model with the new parton shower variables. The last
column, labeled Fortran, is the data generated using the Fortran HERWIG
program, version 6.5. The data in this table are combined and updated
from a variety of sources, see ref. [ 58 ] .

Neither of the Herwig++ implementations in the table have been tuned but
the results in the Fortran column are the result of tuning. 10000 events
were used for the ‘Old Model’ data and the Herwig++ results are for
100000 events. As the models are different a new set of parameters are
needed. The parameters for this are also shown in table 3.1 . The
results given in the last column, Fortran, are taken from [ 59 ] .

As we can see from the multiplicity results Herwig++ is able to obtain
multiplicities that are as good as, if not better than, the old HERWIG
6.5 results. The @xmath of the data sets are given in table 3.3 .

We also want to make sure that the momentum distributions of the hadrons
match those from the data. @xmath is defined as

  -- -------- -- --------
     @xmath      (3.34)
  -- -------- -- --------

where @xmath is the centre-of-mass energy. Presented here are the
results for @xmath for all charged particles and @xmath for all charged
particles in uds events. Also the momentum distributions of @xmath ,
@xmath and @xmath are shown. All results are compared to data from the
OPAL collaboration [ 60 , 61 ] . Again we can see that the results from
Herwig++ are in good agreement with the data. More detailed results are
given in chapter 5 .

## Chapter 4 Herwig++

The new generation of high energy colliders such as the Large Hadron
Collider (LHC) or a future linear collider (NLC) require new tools for
the simulation of signals and backgrounds. The widely used event
generators HERWIG [ 62 ] and PYTHIA [ 25 ] underwent tremendous
development during the LEP era and have reached the limit of reasonable
maintenance. Therefore these programs ( Pythia7 ) [ 63 ] as well as new
projects, like SHERPA [ 32 ] , are being completely (re-)developed in
the object-oriented programming language C++.

Chapters 2 and 3 introduced two new theoretical improvements to the
original HERWIG [ 24 ] Monte Carlo event generator. In this chapter I
present the implementation of these two improvements in the new Herwig++
[ 41 ] event generator as well as the implementation of the various
other parts of the event generator. The Herwig++ event generator is
built on top of ThePEG [ 64 ] . ThePEG is an administrative library
which defines tools and data structures which are commonly used by Monte
Carlo event generators. ThePEG and Herwig++ also use CLHEP [ 65 ] . This
is a package that provides general HEP functions.

This chapter will contain some discussions about object-oriented
programming. As this thesis is not intended to be a discussion of
object-oriented programming and design, detailed discussion of these
matters is given only as a reference [ 66 ] . For the purposes of this
chapter a few keywords and very simple conceptual definitions of these
terms are given here. Again, this is not intended as a complete
description, just a guide for understanding the text of this chapter.

Classes are the main components of an object-oriented program. A very
simplistic view of a class is as a function or algorithm (with
accompanying data). In a sense a class just serves to implement some
functionality or apply some algorithm. A class is much more complex and
diverse than this, but for the current purposes this should suffice.

A class can be a particular type of another class. For example, a class
could define how a particle behaves. It could contain all the data as
well as some special functions, such as boosts, that are useful when
working with a particle. During the shower more information is needed
for a particle, such as the Sudakov basis quantities @xmath and @xmath
in ( 2.1 ). Rather then completely redefining a ShowerParticle to behave
almost identically to a regular Particle, except for the new data, we
can instead inherit the old Particle class into the new ShowerParticle
class. This means that all of the original data and functionality of the
Particle class is also present in the ShowerParticle class, but we can
now add the new data and functions for the ShowerParticle. This is
useful because in the code we can just pass all the Particles and
ShowerParticles around together as one set of Particles. Then if we want
to perform special functions on the ShowerParticles we can identify
which of the Particles is really a ShowerParticle and apply our
operations.

A function in a class can be defined as a virtual function. Classes that
inherit a class with a virtual function can redefine that function.
These functions can actually be defined to be non-existent. If this is
done the class is known as an abstract class. This allows for the
definition of an interface without defining the implementation. For
example, there are many things that all matrix elements must have; all
matrix elements must have a set of incoming and outgoing particles. But
the actual values of the matrix elements, for a given set of incoming
and outgoing particles with momenta, are different. This is a perfect
candidate for abstraction. A class ME can be defined that provides the
definition of a function double me2(incoming,outgoing) but does not
define it. Then any class that inherits ME can implement the function.
If we now think about an algorithm that uses a matrix element, such as
computing a cross section, we can define this algorithm independent of
what matrix element we want to use. It just needs to know that the
matrix element class will return a double when given a set of incoming
and outgoing particles (or momenta).

This brief discussion of a few terms from object-oriented programming
should be adequate to comprehend the rest of this thesis. The rest of
this chapter describes the implementation of the various parts of the
Monte Carlo event generator: hard subprocess, PDFs, parton shower,
underlying event, hadronization, and decays.

### 4.1 Hard Subprocess

As discussed in the first chapter, there is only a small set of matrix
elements currently implemented into Herwig++ . For @xmath annihilation
there is just one. It is the @xmath matrix element. Though this is not
itself a QCD matrix element it inherits the ME2to2QCD class from ThePEG
. This is because the ME2to2QCD class has a function which returns the
number of accessible flavours for a given scale, which is needed for the
matrix element at a given scale.

There is a much larger set of matrix elements for @xmath collisions. All
of these inherit the ME2to2QCD class. Provided with ThePEG is the set of
matrix elements: MEqq2qq , MEQG2QG , MEGG2GG , MEQQ2QQ , MEGG2QQ ,
MEQQ2qq , MEQQ2GG and MEQq2Qq . The lower and upper case @xmath are used
to decipher processes that have different flavours. Also implemented
with Herwig++ is a Drell-Yan matrix element @xmath . This type of
process is particularly useful for studying the initial-state shower.

Implementation of the hard subprocess requires both a matrix element and
a phase space sampler. The method of sampling phase space is important
for the efficiency of the Monte Carlo. As discussed before, matrix
elements ^(a) ^(a) a By ‘matrix element’ we actually mean ‘square
modulus of the matrix element’ can have several peaks and valleys. Using
a uniform sampling for this is extremely inefficient and advanced
samplers can improve the efficiency drastically. The default sampler
used in Herwig++ is known as the ACDC sampler. This is a component of
ThePEG . ACDC is an acronym of Auto-Compensating Divide-and-Conquer
Phase Space Generator [ 67 ] . This algorithm uses a divide-and-conquer
scheme to divide the phase space into uniform sections which have
different maxima. Figure 4.1 shows an example of a function which has
been divided into two sections, each of which is sampled uniformly.

The way the algorithm works is to generate points uniformly in
phase-space. When a point is generated in which the matrix element is
larger than the value being sampled under, @xmath , the space is divided
into two regions. A region is found in which the function is larger than
@xmath and this region is then sampled under @xmath . The
auto-compensating part of the the algorithm compensates for the fact
that the peak has been undersampled and oversamples the new region until
it is consistent. The shaded region of fig. 4.1 shows this new region
which is auto-compensated.

### 4.2 Pdf

Chapter 1 introduced the concept of the parton distribution functions.
As mentioned earlier there are different ways to parameterize the
non-perturbative component of the PDF. Two such implementations are the
Glück-Reya-Vogt (GRV) [ 68 ] PDFs and the Martin-Roberts-Stirling-Thorne
(MRST) [ 69 ] PDFs. Both of these have been implemented in Herwig++ .

The implementation of the PDFs requires the implementation of four
virtual functions inherited from the PDFBase class. These functions are:

-    bool canHandleParticle(tcPDPtr particle) const ; this function is
    used to specify what hadrons this PDF can work with.

-    cPDVector partons(tcPDPtr particle) const ; this function is used
    to specify what partons can be extracted from the given hadron.

-    ApproxMap approx(tcPDPtr particle, const PDFCuts &) const ; this
    function is used to specify, approximately, the upper limits of the
    parton densities, of each parton, for the given hadron. The PDFCuts
    class is used to give as input the kinematical region that the PDF
    will be used in.

-    double xfl(tcPDPtr particle, tcPDPtr parton, Energy2 partonScale,
    double l, Energy2 particleScale = 0.0*GeV2) const ; this function is
    the actual implementation of the PDF. This function returns the
    momentum fraction as @xmath .

Optionally, the PDF can also be specified with the functions:

-    double xfx(tcPDPtr particle, tcPDPtr parton, Energy2 partonScale,
    double x, double eps = 0.0, Energy2 particleScale = 0.0*GeV2) const
    ;
    this function is used to specify the PDF and return the momentum
    fraction as @xmath . By default, this just returns @xmath .

-    double xfvl(tcPDPtr particle, tcPDPtr parton, Energy2 partonScale,
    double l, Energy2 particleScale = 0.0*GeV2) const ;
    this function returns just the valence part of the PDF with momentum
    fraction @xmath . By default this just returns 0.

-    double xfvx(tcPDPtr particle, tcPDPtr parton, Energy2 partonScale,
    double x, double eps = 0.0, Energy2 particleScale = 0.0*GeV2) const
    ;
    this function is the same as xfvl except it returns the momentum
    fraction as @xmath instead of @xmath . It also returns 0 by default.

The GRV PDFs have been implemented as part of ThePEG . The GRV94L and
GRV94M PDFs have been implemented. These are two implementations of the
GRV method where optimal fits of the distributions of the partons have
been made to different data.

The MRST PDFs have also been implemented as part of Herwig++ . This
implementation is a wrapper to a previous C++ implementation [ 70 ] .
The original implementation was able to read in the data from a file.
The files are standardized and when new data is analyzed and integrated
into the distribution, new data files are created. The new versions are
easily integrated into the event generator by simply reading in these
data files.

In order for the event generator to function correctly something must be
done with the remnant of the incoming hadron left behind when a parton
interacts. These are handled by RemnantHandler s. ThePEG has a default
remnant handler, BaryonRemnant , but this is designed to be integrated
with the Pythia7 string fragmentation model. This remnant handler works
in two ways. If a valence parton is chosen by the PDF then the only
remnant is the colour connected diquark remaining in the beam particle.
If a sea parton is used in the hard subprocess then a colour connected
parton is produced along with a colourless hadron. The implementation of
BaryonRemnant in ThePEG requires a @xmath -generator and a @xmath
-generator. Though the @xmath -generator can be designed to work with
other hadronization models, it is really a feature of the string
fragmentation model and isn’t something that is needed in Herwig++ .

Instead, since Herwig++ uses a cluster hadronization model, we use a
different remnant handler. This remnant handler, also called
BaryonRemnant , is really nothing more than a place-holder in Herwig++ ;
the initial-state shower in Herwig++ is designed to evolve back to a
valence parton. This class simply generates a diquark, with either spin
1 or spin 0, with a flavour depending on the parton drawn by the PDF.
This remnant is often wrong because the initial-state shower evolves
backwards to a valence parton but the generation of this valence parton
is not known at the time the remnant is created. Correctly handling the
remnant is instead implemented as part of the backwards evolution and
the original remnant created by BaryonRemnant is replaced ^(b) ^(b) b
BaryonRemnant is only implemented as it is a requirement of ThePEG .

### 4.3 Parton Shower

In chapter 1 I have developed the theoretical background of the parton
shower and how it takes the matrix elements calculated perturbatively
and evolves down to a stage where hadronization models are valid.
Chapter 2 presented the development of a set of evolution variables used
in the Herwig++ shower. In this section I present the implementation
specific features of the Herwig++ shower. This includes how the shower
is initialized, how it terminates and how the momenta of the particles
are set.

#### 4.3.1 Hard Matrix Element Corrections

Given an @xmath –jet process it is sometimes possible to calculate the
matrix element for @xmath jets and this matrix element can be used in
the Monte Carlo. There are already soft and collinear jets of order
@xmath from the shower of the @xmath -jet matrix element and these jets
must be matched with the @xmath -jet matrix element to avoid double
counting. This matching is known as hard matrix element corrections .

Hard matrix element corrections have only been implemented for the
process @xmath . To make a hard correction a pair of three-body phase
space variables, @xmath are generated according to the original two-jet
matrix element. Emissions in the dead region of fig. 2.3 are only
accepted according to the three-jet matrix element. In the case of
@xmath only 3% of the events are corrected by the hard matrix element.

If a hard emission is added the @xmath -final state is replaced by a
@xmath -final state and the orientation of either the quark or the
anti-quark is kept with weights @xmath and @xmath , respectively. This
results in properly oriented three-jet events, apart from finite mass
effects [ 71 ] . This procedure takes into account the most important
subleading higher-order corrections that are not given by the parton
shower.

The ShowerVariables class has a variable, MECorrMode , which sets
whether the hard matrix elements are on or off.

#### 4.3.2 Initial Conditions

As we saw in chapter 1 there is an angular ordering principle that
restrict the showering to occur only in the cone of half angle between
two colour connected partons. Since the shower is restricted to a cone
in relation to one of its colour partners, the first step of the shower
is to determine which colour partners the soft and collinear showers
will occur between. There is a flag, Approach , used in the
PartnerFinder class that sets the way the shower partner is chosen. If
this flag is zero, then the partner is set completely randomly amongst
the partons that are colour-connected to it and the partners of all
partons are set independently of each other. This means if we have
particle @xmath , which chooses its shower partner to be particle @xmath
, particle @xmath does not have to choose @xmath as its shower partner.
Instead, if it had colour partners @xmath and @xmath it would randomly
choose between these. On the other hand, if Approach is set to 1 then it
randomly selects a shower partner and sets both particles to be shower
partners with each other.

A partner is chosen for each gauge ‘charge’ of the parton. For example,
a quark has a QED charge and a QCD charge. A colour partner and an
electric charge partner are both set. This allows the QED showers to
compete directly with QCD ones.

As shown in chapter 2 , the evolution of a particle is carried out in
the Sudakov basis,

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

where @xmath is the momentum of the particle which is evolving and
@xmath is a lightlike ( @xmath ) vector with 3-momentum in the
‘backwards’ direction, which is conventionally set to that of the colour
partner of the particle in their c.m. frame. @xmath is in the transverse
direction and satisfies @xmath .

Once the partner is chosen the initial value of the evolution variable,
@xmath , is set. The value of this variable depends on whether both
partners are initial-state, final-state or a combination. If one parton
is initial-state and one is final-state the values are

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (4.2)
     @xmath   @xmath   @xmath      (4.3)
  -- -------- -------- -------- -- -------

where @xmath is the momentum of the initial-state parton and @xmath is
the momentum of the final-state parton. This corresponds to ( 2.107 )
for the most symmetrical choice, where @xmath . For final-final shower
partners the initial conditions are

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (4.4)
     @xmath   @xmath   @xmath      (4.5)
  -- -------- -------- -------- -- -------

where @xmath and @xmath are the momenta of the incoming partons. @xmath
has three momentum equal to @xmath in the c.m. frame and @xmath ;
similarly for @xmath . This corresponds to ( 2.54 ) for the symmetric
choice. Lastly, for the choice of two initial-state particles the
initial conditions are

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

This corresponds to the symmetric case of @xmath , shown in fig. 2.8 .

#### 4.3.3 Initial-State Shower

The initial-state shower evolution begins with the two incoming partons
that have been chosen from the PDF. These partons are considered as
on-shell partons in the hard matrix element calculation and the initial
@xmath are set as described in the previous section.

Once the initial value is set for the evolution variable, each parton
then evolves independently of each other. The evolution of one parton
proceeds using the veto algorithm. For each possible type of branching,
@xmath , a new @xmath and a @xmath are generated based on ratios of the
Sudakov form factor

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

with @xmath the PDF and @xmath the Sudakov form factor

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

@xmath is the lower cutoff and by default is set to be the
non-perturbative gluon mass, @xmath MeV. The running coupling, @xmath ,
depends on the evolution scale and the momentum fraction. The argument
is @xmath for reasons given in chapter 2 . The @xmath are the
quasi-collinear splitting functions for the massive partons [ 72 ] . For
QCD branchings these are

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.9)
     @xmath   @xmath   @xmath      (4.10)
     @xmath   @xmath   @xmath      (4.11)
     @xmath   @xmath   @xmath      (4.12)
  -- -------- -------- -------- -- --------

and @xmath for initial-state radiation. For the QED case, we change
@xmath to the fine structure constant @xmath and use the branching for
@xmath . Ignoring the parton mass this is

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

where @xmath is the electric charge of the parton, in units of
elementary charge.

The @xmath function in ( 4.8 ) is used to ensure that it is possible to
reconstruct transverse momentum, @xmath , from the evolution variables.
@xmath determines the relative transverse momentum. For quark branching
this is

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

For the gluon branching, in the initial state shower, this is

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

Eqn. ( 4.7 ) gives the probability of no branching above the scale
@xmath . @xmath is therefore the probability for the next branching to
happen above @xmath . The derivative with respect to @xmath is then the
probability density for the next branching to happen at the scale @xmath
.

Since ( 4.7 ) is not directly solvable, the veto algorithm is used. In
this algorithm each part of the distribution is sampled independently by
a function which is always greater than the desired one, and a veto is
placed on the emission if the ratio of the actual function to the
approximated function is larger then some random number. This gives
several veto points

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (4.17)
     @xmath      (4.18)
     @xmath      (4.19)
     @xmath      (4.20)
     @xmath      (4.21)
  -- -------- -- --------

The trick to the veto algorithm, to ensure that things are correctly
sampled, is that first a @xmath is generated according to

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

with @xmath the current scale, @xmath and @xmath the upper and lower
bounds on @xmath , respectively and @xmath the value of @xmath
integrated over @xmath and from zero to @xmath . A @xmath is then
generated according to the approximate functions, @xmath between @xmath
and @xmath . Each veto is then tested. If a veto fails a new @xmath is
generated. This time, however, instead of @xmath in ( 4.22 ) it is equal
to the @xmath that was vetoed. If this @xmath is smaller than @xmath
then there is no more branchings. The largest value of @xmath generated
from each of the branchings decides which of the branchings to use.

Once a splitting has been chosen a new initial state parton and a new
final state parton are created. The final state parton is taken as an
on-shell parton. This will be put off-shell during the final-state
evolution. The momentum fraction, @xmath , from the Sudakov form factor
and the new scale @xmath are passed to the new initial state parton so
it can split. This process is repeated until no new scale is chosen
below @xmath for any of the branchings. From the interpretation of the
Sudakov form factor, this means that there is no more branching and the
evolution of this parton has terminated.

As discussed before, beam remnants aren’t handled properly by the
remnant handler. Instead they are handled here. When the initial-state
evolution of a parton terminates a set of forced branchings are imposed.
There are three types of termination points: a valence quark, a gluon,
or a sea quark. If the evolution terminates on a valence quark, then a
diquark ^(c) ^(c) c If a beam particle was a meson this would just be a
(anti-)quark of the appropriate flavours is produced as the beam
remnant. If instead the evolution terminates on a gluon, a forced
splitting of the gluon from a quark of a valence flavour is imposed. The
momentum fraction @xmath is distributed according to the splitting
function. The @xmath is just distributed by @xmath between @xmath and
@xmath . The remnant is again just a (di)quark of the flavour(s) that
remain in the beam particle. The most complex case is when the evolution
terminates on a sea quark. In this case two forced splittings are
imposed. The first is to force a splitting into a gluon. Again the
momentum fraction is distributed according to the appropriate splitting
function. The @xmath is also distributed as @xmath between @xmath and
@xmath . The new gluon is then forced to split into a valence quark in
the same manner described above.

This process is repeated for both incoming partons. Once they have
evolved and their remnants are correctly set the momenta of all the
partons needs to be set. The initial condition is that the beam
particles are coming in with known momenta. The Sudakov variable @xmath
of the first parton is then set to unity, the @xmath is set to zero and
its @xmath is known from the backwards evolution. Each child of the
parton then has its @xmath set to @xmath , for the initial state
particle and @xmath for the final state partner produced during the
backward evolution. The @xmath for the on-shell final state partons is

  -- -------- -- --------
     @xmath      (4.23)
  -- -------- -- --------

The @xmath and @xmath vectors are the Sudakov basis vectors for the
shower and

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Here @xmath is a 2 vector given by @xmath . By default @xmath is
distributed uniformly in the region @xmath but improvements, such as the
spin correlations described in chapter 1 , can be implemented. The
values for the initial-state parton @xmath are

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.25)
     @xmath   @xmath   @xmath      (4.26)
  -- -------- -------- -------- -- --------

All of the @xmath ’s and @xmath are set until the parton involved in the
hard subprocess is reached. This fully defines the momentum of the
partons. Unfortunately, this does not guarantee momentum conservation at
the hard subprocess. Instead the momentum of the partons must be
“shuffled” in order to impose momentum conservation. Rescaling the
momentum of the partons in the hard subprocess, and correspondingly
boosting all the partons involved in the evolution of each initial-state
partons, allows for momentum conservation. This rescaling can affect
other properties, however, and we want to constrain the value of the
rescaling so that certain properties are retained.

In proton-proton collisions we want to conserve the rapidity, @xmath ,
and the c.m. energy squared, @xmath , of the hard process, while
rescaling each incoming parton independently. Each parton has its
momentum shifted by @xmath and @xmath , given in the Sudakov base by

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (4.27)
  -- -------- -------- -------- -- --------

These shifts, @xmath and @xmath , are applied so that the virtuality of
the partons is conserved. Conserving rapidity and the c.m. energy
squared requires

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.28)
     @xmath   @xmath   @xmath      (4.29)
  -- -------- -------- -------- -- --------

Both of these give a quadratic solution for each @xmath value. This
leads to four different combinations of values which must be considered.
Two combinations of these four have negative @xmath ’s. This corresponds
to flipping the event, e.g. the parton which started from the @xmath
direction ends up on the @xmath direction and vice versa. In some cases
the reconstruction of the shower fails. In these cases the shower is
vetoed and started again from the on-shell incoming partons.

#### 4.3.4 Final-State Shower

The final-state shower is similar to the initial state shower. The
partons start as on-shell partons but are taken off shell by the
evolution. The initial scale of a parton is set according to its shower
partner and the partons evolve down to the scale @xmath in the same
manner as the initial-state shower, except the probability of emission
is modified. Instead of @xmath we have

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

This means that the extra veto, @xmath from ( 4.16 ), is not applied to
final-state branchings. Though the generation of the branchings is
similar, the kinematics of the final-state shower is different from that
of the initial-state shower. From the results in chapter 2 we find the
relative transverse momentum as

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.31)
     @xmath   @xmath   @xmath      (4.32)
  -- -------- -------- -------- -- --------

for quark branching and gluon branching respectively and @xmath .

All of the partons created during the evolution also shower starting at
the @xmath that they were produced at. Every parton showers until the
condition of no more branching is met. Once this is reached the parton
is put on its mass shell so that momentum reconstruction can be done.

The partons produced in the hard subprocess have their @xmath set to
unity and their @xmath set to 0. Each of children then have their
Sudakov variable @xmath set to @xmath or @xmath , set by the convention
of the splitting function. The @xmath for the parton corresponding to
the @xmath momentum fraction is

  -- -------- -- --------
     @xmath      (4.33)
  -- -------- -- --------

where @xmath and @xmath are the Sudakov basis vectors of the shower. The
@xmath corresponding to the @xmath momentum fraction is just

  -- -------- -- --------
     @xmath      (4.34)
  -- -------- -- --------

Since the final partons are on their mass shells, the initial partons
aren’t. This means instead of having @xmath they have acquired some
virtuality, @xmath . The original momenta, @xmath in the centre-of-mass
frame, define some properties of the hard subprocess. In the case of
@xmath annihilation we want to preserve the centre-of-mass energy

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

while keeping the sum of momenta equal to zero. This requires momentum
reshuffling. To conserve @xmath we rescale the momentum of each jet by a
common factor, @xmath , that is determined from the equation

  -- -------- -- --------
     @xmath      (4.36)
  -- -------- -- --------

This effectively creates a Lorentz transformation which is applied to
all partons in the final state. For @xmath outgoing particles from the
hard process ( 4.36 ) can be solved for @xmath explicitly. For @xmath
this is done numerically.

#### 4.3.5 Soft Matrix Element Corrections

We saw earlier that a hard correction is added in to populate the ‘dead
region’ of the @xmath –body matrix element. The parton shower can also
be improved in the shower regions of phase space by restricting
relatively hard gluons that are produced in the shower. These gluons are
no longer in the domain of of validity of the quasi-collinear
approximation.

Each of the @xmath values that are generated during the evolution of one
jet is tracked. If a new @xmath is larger than any previously generated
during the evolution a soft matrix element correction is applied to it [
73 ] . This correction assumes all other emissions are infinitely soft
and we can treat the emission as part of a three-body phase space (e.g.
@xmath ). This allows us to compute the three-body variables, @xmath ,
from the parton shower variables @xmath and the respective Jacobian. The
ratio of the hard matrix element and the shower is then compared to a
random number and the emission is vetoed if the ratio is smaller. This
requires that the shower approximation is larger than the matrix element
everywhere in phase space. Otherwise the ratio must have some factor
applied to ensure that the ratio is always less than 1. This has been
studied for several cases in chapter 2 and the relevant ratios have been
derived.

#### 4.3.6 Parameterization of @xmath

The cutoff @xmath is introduced to regularize the soft gluon
singularities in the splitting functions. The relative transverse
momentum, @xmath is related to the Sudakov variables of the parton
branching by

  -- -------- -- --------
     @xmath      (4.37)
  -- -------- -- --------

@xmath is required to correspond to a real value of @xmath . For a gluon
splitting this is explicitly

  -- -------- -- --------
     @xmath      (4.38)
  -- -------- -- --------

with @xmath . For quark splittings @xmath is the solution of a cubic but
is always in the range

  -- -------- -- --------
     @xmath      (4.39)
  -- -------- -- --------

This allows @xmath to be generated within these regions and simply
rejected if it lies outside phase space.

@xmath is parameterized according to

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

where @xmath is the parameter cutoffKinScale in the class
ShowerVariables and @xmath is the mass of the parton splitting. This
cutoff is used to give the gluons a minimum virtuality which ensures
that they are able be put on a mass shell with non-zero mass. As we can
see from figure 4.2 , the form of this function is also to ensure that
@xmath quarks don’t have an extra artificial cutoff that over-restricts
the phase space of splitting @xmath quarks.

### 4.4 Hadronization

Chapter 3 described in detail the hadronization scheme used in Herwig++
. This section will discuss the features of the code and the
implementation of the specific features. Table 4.1 is a table with all
the relevant parameters of the hadronization.

The main driver of the code is the ClusterHadronization class. This
class organizes and directs which classes are used next. This class also
handles the unusual case of a hadronization veto. This can occur during
the light cluster reshuffling, which will be described below. In order
to direct the algorithm this class has references to PartonSplitter ,
ClusterFinder , ColourReconnector , ClusterFissioner , and the two
decayer classes LightClusterDecayer and ClusterDecayer classes. The
class ColourReconnector by default doesn’t do anything. This class is
designed to allow for a different colour configuration in the forming of
the clusters, for example this is done in SHERPA [ 32 ] .

The algorithm begins by taking the gluons, which are on a mass-shell,
and non-perturbatively splitting these into @xmath pairs. The possible
flavours depend on what the mass of the gluon is. This is done for all
final-state gluons produced in the final-state shower (including the
final-state evolution of the gluons produced during the initial-state
shower). The splitting is done by the class PartonSplitter . This class
has a reference to the GlobalParameters object that defines all the
global parameters used throughout Herwig++ .

Once the gluons have all been split into @xmath pairs clusters are
formed out of the colour connected partons. This is done by the
ClusterFinder class. This class simply searches all coloured partons and
creates a colour singlet state out of the colour connected partons.
There is also a feature to work with partons that are created by colour
sources or sinks which stem from baryon violating processes. This
feature has not been tested though and this needs to be done once baryon
violating processes are included into Herwig++ . After the clusters are
formed, if a ColourReconnector class was defined to change things, it
would be called to do so at this stage.

After the ClusterFinder class has created all of the colour singlet
clusters, they are passed to the ClusterFissioner class. As was
described in chapter 3 , the heavy clusters are decayed into lighter
clusters. This occurs in three ways. If the mass drawn for one of the
new clusters in not heavy enough to form the lightest possible pair of
hadrons, given the set of flavours, the decay is instead forced to
@xmath where @xmath is a hadron and @xmath is a new cluster. @xmath is
the lightest hadron of the flavour of the cluster whose mass is too
light. The mass generated for the light cluster is changed to equal the
mass of the lightest hadron. If the mass of the cluster @xmath produced
in the decay would then violate the phase space bounds it is set to have
the largest mass available. The next special case is when both clusters
are too light to form a hadron pair. This decay, @xmath , follows the
same procedure as the previous one. Each hadron is the lightest hadron
of the appropriate flavours and the masses are set to the mass of the
respective hadron. If this violates the phase space bounds, then the
cluster isn’t decayed via this mechanism. In fact, if this still
violates phase space it will be handled by the LightClusterDecayer
later. The last possible way for a heavy cluster to be decayed is
directly into two new clusters, @xmath . In any case, if any of the new
clusters is still too heavy, it also decays via this algorithm.

After the heavy clusters have been handled, the clusters which are too
light are treated. This is done by the LightClusterDecayer . This takes
clusters which are too light to decay into a pair of hadrons and turns
them directly into a single hadron. It may be possible that a cluster
has formed which is even too light to decay directly into the lightest
hadron. In this case the momentum of this cluster is ‘reshuffled’ with a
cluster which is nearby in @xmath -space. The algorithm only ‘borrows’
momentum from a given cluster once during the process. If it is
impossible to find enough momentum to borrow then the event is vetoed
and begun again from the ClusterFissioner stage. In the rare case that
after vetoing several times there is still not a possible configuration
to decay all the clusters then the whole event is vetoed.

The last step of the hadronization is turning the clusters into hadrons.
This is done by the ClusterDecayer class. This has a reference to a
HadronSelector class. The HadronSelector class has been implemented with
a flag, DKMode , which is used to select which of the methods discussed
in chapter 3 to use. By default this flag is set to 2, which is the new
method. If it was changed to 0 the implementation of the HERWIG method
would be used. A value of 1 is for the Kupco method. Once a pair of
hadrons has been selected by one of the methods then the cluster is
decayed. The decay products are generated in the direction of the
constituent quark. This direction can have a Gaussian smearing applied
to it to. If the flag ClDir is set and ClSmr is larger then 0.0001, then
cluster decay is in the direction

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

where @xmath is the @xmath of the original constituent quark and

  -- -------- -- --------
     @xmath      (4.42)
  -- -------- -- --------

with @xmath a random number. The azimuthal angle is distributed
uniformly in @xmath .

### 4.5 Decays

In chapter 1 the general scheme of the decays was presented. Since the
algorithms implemented in Herwig++ are very basic, in this section I
will explain the way to setup the decay modes in Herwig++ and how one
would implement a new set of decay modes.

In Herwig++ the default decays are defined in the file Hw64Decays.in .
In this file all of the decay modes are included. An entry of a decay
mode takes the form

  -- -- --
        
  -- -- --

for the decay @xmath , @xmath is the branching ratio and the 0/1 option
specifies whether to turn this mode off or on, respectively. The last
argument specifies which class to use to perform the decay. By default
Herwig++ has only the HwDecayer class, the HeavyDecayer class and the
QuarkoniumDecayer class. All of these classes use a parameter MECode to
specify the matrix element code to use.

The class HwDecayer is the most common class used in the default
Herwig++ decays. This just implements the decays as described in chapter
1 based on the MECode parameter. A value of 100 uses the free massive
@xmath matrix element, for example @xmath . 101 is the code to use the
bound massive matrix element. This would be used for a decay such as
@xmath . Any other value of the parameter uses an isotropic @xmath -body
decay.

The class HeavyDecayer takes heavy mesons and decays the heavy parton
weakly. The @xmath produced in the decay is also decayed all in one
step. This produces 4 partons, two from the decay of the @xmath , one
from the production of the @xmath and the remaining spectator parton.
For example a chain could look like, @xmath . The decay products have
the colour connections set properly and the administrative class
HwDecayHandler directs the program to reshower and rehadronize these
partons.

The last decayer, the QuarkoniumDecayer , is designed to work with heavy
mesons and baryons that decay into gluons and quarks. Possible modes are
to 3 gluon states, 2 gluons and a photon, just 2 gluons or a @xmath
state. This class handles a MECode of 130 by using a positronium matrix
element. Decays from this class also lead to showering and hadronization
of the partonic decay products. An example of this type of decay is
@xmath .

Implementation of a new decay mode requires the definition of only two
functions. A new decay matrix element must inherit the Decayer class
from ThePEG . The two functions that must be implemented are

-    bool accept(const DecayMode &) const ; this function is used to
    indicate if a particular decay mode can be handled. For example if
    you implemented a decay matrix element for @xmath decays, if the
    incoming particle was not a @xmath , this function would simply
    return false.

-    ParticleVector decay(const DecayMode &, const Particle &) const ;
    this function returns the decay products with their momentum set.
    The input is the decay mode selected based on the branching ratios,
    and the instance of the particle which is decaying.

Improving the decay modes of Herwig++ is currently underway. This is a
lengthy process and as long as experimentalists study the decays of
particles, improving the decay mode matrix elements, as well as the
branching ratios, will always be possible. But as will be shown in the
next chapter, even with the simple decay matrix elements, fits to
particle spectra are good.

## Chapter 5 Results

### 5.1 Introduction

This chapter presents results from the Herwig++ . The results given here
are for @xmath annihilation events, as this is the first step in the
redevelopment of HERWIG . In order to have full control of the basic
physics steps that are simulated, it was thought to be very important to
put the new generator on a firm basis with respect to LEP and SLC
results before upgrading it to be able to deal with initial-state
showers and the other requirements for the simulation of lepton-hadron
and hadron-hadron collisions. Therefore, thorough tests have been
performed on the predictions of the generator against a wide range of
observables that have been measured at LEP and SLC. We have also
explored the sensitivity to the most important parameters and cutoffs.
These results are not the result of a high-precision tuning: the main
aim here is rather to show the results of the program and that it is
able to give results as acceptable as those generated by its predecessor
HERWIG for a reasonable choice of parameters.

#### 5.1.1 Main features of the code

As was discussed in detail in the last three chapters, the main stages
of the simulation of events is the same as in HERWIG [ 62 ] . However,
in comparison to its predecessor, Herwig++ features a new parton shower
and an improved cluster hadronization model. At present, hadronic decays
are implemented in the same fashion as they were in HERWIG .

As discussed in chapter 4 , the program is based on the Toolkit for High
Energy Physics Event Generation ( ThePEG ) [ 64 ] and the Class Library
for High Energy Physics ( CLHEP ) [ 65 ] . They are utilized in order to
take advantage of the extended general functionality they can provide.
The usage of ThePEG unifies the event generation framework with that of
Pythia7 . This will provide benefits for the user, as the user
interface, event storage etc. will appear to be the same. The
implementations of the physics models, however, are completely different
and independent from each other.

The simulation of @xmath annihilation events starts with an initial hard
process @xmath . The final state photons simulate QED radiation from the
initial state, so that a radiative return can be properly simulated. For
these results we are only interested in the details of the QCD parton
shower in the final state. The final-state parton shower starts with a
quark and antiquark that carry momenta @xmath and @xmath , respectively,
and have an invariant mass squared of @xmath . For the @xmath results,
the only detail we are concerned with in relation to initial-state
radiation is that the centre-of-mass frame of the @xmath –pair is
slightly boosted with respect to the collider laboratory frame and that
@xmath may be different from the @xmath centre-of-mass energy. We have
made sure that the applied cuts on the energy of the annihilating @xmath
subsystem are the same as those used in the experimental analyses.

Currently, proton-proton collisions are being studied. These results are
simulated by starting with the Drell-Yan hard process @xmath , with
@xmath a charged lepton. These results concentrate on the effects of the
initial-state radiation from the incoming quarks and gluons.

##### 5.1.1.1 Parton shower

As has been shown in the preceding chapters, the partonic evolution from
the large scale of the hard collision process down to hadronic scales
via the coherent emission of partons, mainly gluons, is simulated on the
basis of the Sudakov form factor. Starting from the hard process scale
@xmath , subsequent emissions at scales @xmath and momentum fractions
@xmath are randomly generated as a Markov chain on the basis of the soft
and collinear approximation to partonic matrix elements. Chapter 2 has
shown that for Herwig++ we have chosen a new framework of variables,
generically called @xmath . Here, @xmath is a scale that appears
naturally in the quasi-collinear approximation of massive partonic
matrix elements and generalizes the evolution variable of HERWIG to the
evolution of massive quarks. @xmath is a relative momentum fraction; the
evolution is carried out in terms of the Sudakov decomposition of
momenta in the frame where the respective colour partners are
back-to-back. As in HERWIG , the use of the new variables allows for an
inherent angular ordering of the parton cascade, which simulates
coherence effects in soft gluon emission. The details of this underlying
formalism have been described in chapter 2 .

The most important parameter of the parton shower that we will be
concerned with in this chapter is the cutoff parameter @xmath , which
regularizes the soft gluon singularity in the splitting functions and
determines the termination of the parton shower. This is set by @xmath
in ( 4.40 ). Less important but relevant in extreme cases is the
treatment of the strong coupling constant at low scales. We have
parametrized @xmath below a small scale @xmath in different ways. We
keep @xmath generally to be of the order of 1 GeV, where we expect
non-perturbative effects to become relevant. Below that scale @xmath can
optionally be

-   set to zero, @xmath ,

-   frozen, @xmath ,

-   linearly interpolated in @xmath , between 0 and @xmath ,

-   quadratically interpolated in @xmath , between 0 and @xmath .

We put the final partons of the shower evolution on their constituent
mass shells, since the non-perturbative cluster hadronization will take
over at this scale, so we usually have kinematical constraints that keep
@xmath above @xmath , in which case the treatment below @xmath is
irrelevant. Typically, @xmath here.

##### 5.1.1.2 Hadronization and decay

As discussed in chapter 3 , the partonic final state is turned into a
hadronic final state within the framework of the cluster hadronization
model of HERWIG [ 74 ] . All three methods of cluster decays have been
implemented in Herwig++ , but the new cluster hadronization model is
used for the results given in this chapter. The emerging hadrons are
possibly unstable and eventually decay. The decay matrix elements and
modes correspond to those in HERWIG .

### 5.2 @xmath Annihilation

This section presents the results for @xmath annihilation events. The
properties of different measurements are discussed and the comparison of
Herwig++ to data is presented. Histograms for all the distributions have
been booked in the same bins as the experimental data. For a given bin
@xmath we then compare the data @xmath value with the Herwig++ Monte
Carlo result @xmath . Given the data errors @xmath (statistical plus
systematic, added in quadrature) and Monte Carlo errors @xmath
(statistical only), we can calculate a @xmath for each observable. We
keep the statistical error of the Monte Carlo generally smaller than the
experimental error. In distributions where the normalization is not
fixed, such as momentum spectra, we allow the normalization of the Monte
Carlo to be free to minimize @xmath . The normalization is then tested
separately against the average multiplicity. In all other cases we
normalize histograms to unity.

As we do not want to put too much emphasis on a single observable or a
particular region in phase space where the data are very precise, in
computing @xmath we set the relative experimental error in each bin to
@xmath . This takes into account the fact that the Monte Carlo is only
an approximation to QCD and agreement with the data within 5% would be
entirely satisfactory. The general trend for the preferred range of a
single parameter was however never altered by this procedure.

After normalization the ratio

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

is computed for each bin in order to see precisely where the model
fails. This ratio as well as the relative experimental error and the
relative contribution of each bin to the @xmath of an observable is
plotted below each histogram.

#### 5.2.1 Strategy

We have taken @xmath values for hadron multiplicities into account in
the same way as we weighted the event shapes. In general the
multiplicities of individual particle species are sensitive to a
completely different set of parameters. The general strategy was to get
a good value for the total number of charged particles with a reasonable
set of values for the parton shower cutoff parameter @xmath and the
maximum cluster mass parameter @xmath . Once this was fixed, the
hadronization parameters that determine the multiplicities of individual
particle species were determined. Following this we compared this
‘preferred’ set of parameters with the ‘default’ set from HERWIG . The
resulting parameter set is shown in Table 5.1 .

A wide range of observables have been tested in order to study the
aspects of the model. Event shape variables and multiplicities are
considered in order to test the dynamical aspects of the parton shower
and hadronization models, which are closely linked at their interface by
the parton shower cutoff parameter, @xmath . Ideally, the models should
combine smoothly at scales where @xmath 1 GeV. Many of the figures shown
in this chapter contain three sets of plots per figure. In order from
top to bottom these are

-   the actual distribution. The Herwig++ result is plotted as a
    histogram together with the experimental data points;

-   the ratio @xmath ( 5.1 ) together with an error band showing the
    relative statistical and systematic errors;

-   the relative contribution of each data point to the total @xmath of
    each plot.

#### 5.2.2 Hadron multiplicities

The charged particle multiplicity distribution and the overall
multiplicities of a wide range of hadron species have been taken to test
the overall flow of quantum numbers through the different stages of the
simulation. This also allows a thorough test of the new hadronization
model, developed in chapter 3 , against the measured observables.

Table 3.2 showed the results of the new cluster hadronization algorithm
in comparison to the old algorithm. Even before systematic tuning, we
can see that the overall results are in better agreement with the data
than those of HERWIG , with fewer results that differ from the data by
more than three standard deviations (indicated by a star in the table).
We can also see from table 3.3 that the difference between the models is
quantified by their @xmath .

A very well measured property, and therefore important to get accurate,
is the distribution of charged particle multiplicity. Figure 5.1 shows
the results of Herwig++ compared to OPAL data [ 75 ] and is found to be
in fairly good agreement. There is an excess of lower multiplicity
events, however. It is also shown that varying @xmath doesn’t greatly
alter this distribution, another confirmation that the interface between
the parton shower and the hadronization is consistent.

#### 5.2.3 Jet multiplicity

This measurement is the multiplicity of (mini-)jets in @xmath
-collisions for different values of the jet resolution @xmath . We use
the Durham– or @xmath –clustering scheme [ 76 ] throughout this chapter
for jet observables. To be specific, for a given final state the jet
measure

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

is calculated for every particle pair @xmath . The particles with
minimal ‘distance’ are clustered such that the momentum of the clustered
pseudo-particle is the sum of the four-momenta of the constituents. The
jet multiplicity is then the number of pseudo-particles remaining when
all @xmath . This inclusive observable has been predicted and measured
at LEP energies and will test the dynamics of the parton shower as well
as the interface between parton shower and hadronization. We use the
KtJet -package [ 77 ] that implements the above jet-finding algorithm in
C++ and have written a simple wrapper around it in order to use it with
the particle record of Herwig++ .

Figure 5.2 shows the average number of jets @xmath at the @xmath –pole,
as a function of the Durham jet resolution, @xmath , for various values
of the cutoff parameter @xmath . At the parton level (top left) the jet
multiplicity varies substantially toward smaller values of @xmath ,
saturating at the number of partons that are present in a single event.
The order of magnitude of the visible saturation scales is characterized
for each flavour by different cutoff values @xmath as @xmath . For
example, at @xmath GeV and @xmath GeV, the saturation scale for light
quarks is of the order @xmath while for @xmath -quarks it is of the
order @xmath .

During hadronization, low parton multiplicities lead to large mass
clusters which, as described before, tend to decay into low mass
clusters below the cutoff mass, @xmath . This has been fixed to its
default value for the results given in this chapter. Figure 5.2 (top
right) shows that the hadronization compensates for lower partonic
multiplicities, giving a result which is insensitive to @xmath at the
hadron level. This means that we have a smooth interface between the
perturbative and non-perturbative dynamics of the lower end of the
parton shower and the cluster hadronization model. On the hadron level
we describe LEP data from OPAL [ 78 ] well.

In order to test the sensitivity of Herwig++ against the variation of
the centre-of-mass energy we calculate the jet multiplicities at PETRA
and LEP II energies as well as LEP I energies ( 5.2 , bottom). The
comparison to JADE [ 79 ] and OPAL [ 78 ] data shows a good agreement.
For the generation of all the Monte Carlo data we applied the same
cutoffs on the energy of the partonic subsystem as was done in the
experiments.

The other curves in figure 5.2 show the prediction for the jet
multiplicity [ 80 ] from the resummation of leading logarithms. Note
that the parameter @xmath in the resummed calculation is not @xmath .
For a value of @xmath MeV we can see that there is good agreement with
the data and the Herwig++ results throughout the perturbative region,
@xmath .

#### 5.2.4 Jet fractions and @xmath

These measures give a closer look ‘into’ the jets. This is done by
considering the rates of jets at a given value of @xmath in the Durham
scheme. The jet fraction is given by

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

for @xmath up to @xmath jets. Presented here are also the distributions
of @xmath , the @xmath -values at which an @xmath –jet event is merged
into an @xmath -jet event in the Durham clustering scheme. The results
are presented here for @xmath up to @xmath , without @xmath . These
distributions will not only probe the dynamics of the parton shower but
also the hadronization model; at the lowest values of @xmath the
dynamics is dominated by the hadronization.

Figure 5.3 compares the results from Herwig++ with LEP data from [ 78 ]
and shows good agreement. On the hadron level these predictions are not
very sensitive to the cutoff parameter @xmath . The results of the
@xmath are not shown here but show similarly good agreement. The @xmath
plot contains all jets @xmath and greater.

The Durham @xmath distributions are given in figure 5.4 . These are
histograms of the @xmath values at which the @xmath –jet event in the
Durham jet clustering scheme is merged into an @xmath –jet event. This
resolved more of the internal structure of the jets than the @xmath –jet
rates alone. Overall, the agreement between the model and the data is
good. There is a tendency to exceed the data at low @xmath . This is a
problem that was also present in HERWIG .

#### 5.2.5 Event shapes

Event shape distributions have been measured to very high accuracy at
LEP and aim at resolving the properties of the parton shower quite
thoroughly. All of the event shapes given here, except @xmath and @xmath
, defined below, are ‘infrared safe’. This means that they can be
computed in perturbation theory. In order to test the dynamics of the
parton shower in Herwig++ in more detail we consider a set of commonly
used event shape variables. Not only the collinear region of the parton
shower is probed in greater detail but also the regions of phase space
which are vetoed as matrix element corrections. We compare all results
to DELPHI data [ 81 ] .

The thrust is a well studied property. The definition of the thrust is
given by

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

Finding the vector @xmath is a computational intensive task. This can
instead be reduced using physical arguments to a simpler procedure. We
start by separating the sum into two different parts: those where @xmath
and those where @xmath . If we first take out the normalization factor

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

we get

  -- -- -- -------
           (5.6)
  -- -- -- -------

The magnitudes of the dot products can be removed and this gives

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

Since the @xmath is independent of the sum it can be taken outside the
summation yielding

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

where @xmath is the sum of all momenta in the same hemisphere as @xmath
and @xmath is the sum of all momenta in the other hemisphere. Momentum
conservation says (in the c.m. frame) that @xmath so the thrust is given
by

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

From this it is obvious that the maximum value for a given @xmath is
when the vector lies parallel to @xmath . Previously, to find the vector
@xmath that maximizes ( 5.4 ) we would have to consider all possible
combinations of momenta, which has complexity of order @xmath . After
deriving ( 5.9 ) this has been reduced to considering all sets of two
vectors which define a plane. This plane divides the space into two
hemispheres from which the thrust can be computed by simply summing all
the momenta in one of the hemispheres and taking the magnitude. Since
the two vectors chosen to define the plane do not unambiguously lie in
either hemisphere, each possibility must be considered. This has reduced
the problem to simply iterating over all sets of two momenta and
recording which set produces the maximum. This is now only order @xmath
.

There are two other measures of the data related to the thrust. One is
called the thrust major and the other the thrust minor. These are
defined as

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.10)
     @xmath   @xmath   @xmath      (5.11)
  -- -------- -------- -------- -- --------

where @xmath is the thrust major, @xmath is the thrust minor and @xmath
.

The thrust is a measure used to describe how ‘pencil-like’ the event is.
High thrust means that the event is more 2-jet like, where as lower
thrust means that the event is much more planar or spherical, thus it
has more than 2 jets. The thrust major is used to describe the major
component of the momentum in a plane perpendicular to the thrust axis.
High values of the thrust major are usually indicative of planar events.
The thrust minor, therefore, is used to describe the remaining degree of
freedom of the momenta. High values of the thrust minor correspond to
spherical events. These are events that have at least 4 jets.

In fig. 5.5 we show the distribution of thrust and thrust-major and
thrust-minor. These variables are all obtained from the equations given
above. The thrust distribution is shown with and without matrix element
corrections switched on. The prediction without matrix element
corrections is very much better than that of HERWIG , owing to the
improved shower algorithm. It is interesting that the matrix element
corrections seem to generate almost too much transverse structure,
leading to event shapes that are less two-jet-like. On the other hand,
there is also a slight excess of events close to the two-jet limit.

Though the thrust describe 2-jet like events quite well, multi-jet
events are less understood in terms of these measurements. The @xmath
and @xmath parameters are used to describe three- and four-jet-like
events. These are given by combinations of the eigenvalues of the linear
momentum tensor

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

The definition of @xmath and @xmath is then

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.13)
     @xmath   @xmath   @xmath      (5.14)
  -- -------- -------- -------- -- --------

where @xmath are the eigenvalues of @xmath and

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

Both of these parameters have a coefficient defined so that the range of
the parameter is @xmath .

It is remarkable how well distributions like @xmath and @xmath parameter
(fig. 5.6 ) which are sensitive to three- and four-jet-like events are
described by our model even though we are limited to three jet matrix
elements plus showers. Here again we have in fact a small excess at high
values.

We show also in fig. 5.7 the distributions which are obtained from a
quadratic momentum tensor

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

The three measures that arise from this are sphericity ( @xmath ),
planarity ( @xmath ) and aplanarity ( @xmath ). These are given by

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.17)
     @xmath   @xmath   @xmath      (5.18)
     @xmath   @xmath   @xmath      (5.19)
  -- -------- -------- -------- -- --------

where @xmath is the @xmath th eigenvalue and they obey the relations

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

These distributions put more emphasis on high momenta. As the names
imply these distributions indicate the events that are spherical, planar
or aplanar. The sphericity axis is just @xmath where @xmath is the
eigenvector of the @xmath th eigenvalue. This is made obvious by seeing
that sphericity is really defined as @xmath . Therefore, events which
have high sphericity have momentum which tend to be along the sphericity
axis, @xmath . As was the case for the thrust-related distributions, we
tend to have slightly wide events.

In addition we consider the jet broadening measures @xmath and @xmath
and the hemisphere jet masses (fig. 5.8 and fig. 5.9 ). The jet
broadening measures are defined as [ 82 , 83 ]

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

where @xmath is the thrust axis and @xmath indicates one of the two
hemispheres defined by the plane normal to @xmath . If @xmath then
@xmath is in hemisphere, @xmath , otherwise it is in hemisphere @xmath .
@xmath is then

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

@xmath measure the scalar momentum transverse to the thrust axis for the
wider and narrower jet hemispheres respectively. We can see from figure
5.8 that there is good agreement between the model and the data. We have
also looked at two other jet broadening measures, @xmath and @xmath .
These are not shown here as they contain the same information as @xmath
and @xmath .

The last jet measure we show here is that of the hemisphere masses.
These also use the same definitions of the two hemispheres with respect
to the thrust axis as the jet broadening measures, but these measure the
total momentum squared within a hemisphere. The high hemisphere mass is

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

and the lower hemisphere mass is

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

where @xmath is the c.m. energy squared. In both cases we can see from
figure 5.9 that the agreement between model and data is good.

#### 5.2.6 Four jet angles

We show the four-jet angles in fig. 5.10 . They are considered only for
events where we have a four-jet event at @xmath . Each of the different
angles measures a property of the four-jet configuration.

If we denote the cosine of the angle between two vectors, @xmath and
@xmath as @xmath , we can define the four different jet angles as

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.25)
     @xmath   @xmath   @xmath      (5.26)
     @xmath   @xmath   @xmath      (5.27)
     @xmath   @xmath   @xmath      (5.28)
  -- -------- -------- -------- -- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.29)
     @xmath   @xmath   @xmath      (5.30)
  -- -------- -------- -------- -- --------

@xmath is the three-momentum of the hardest jet and @xmath is the
three-momentum of the softest jet.

Despite the fact that we do not have any matching to higher order matrix
elements, as was proposed in [ 27 ] and implemented in [ 84 ] , the
agreement between model and data [ 85 ] is remarkably good. We expected
the implementation of hard and soft matrix element corrections in
Herwig++ to improve the description of these observables but we did not
find very significant differences with or without the application of
matrix element corrections.

#### 5.2.7 Single particle distributions

Using the thrust axis defined in ( 5.4 ), one can define the transverse
momentum of a particle with respect to this axis. We can then define a
plane given by the thrust axis and the thrust major axis, @xmath as the
event plane. Therefore, the plane given by the thrust and the thrust
minor, @xmath , is considered out of the event plane. In fig. 5.11 we
have single charged particle distributions. The distributions are of the
transverse momentum within the event plane, @xmath , and the transverse
momentum out of the event plane, @xmath . The momenta in the event plane
are shown with and without matrix element corrections. In contrast to
the thrust distribution we find that the matrix element corrections
actually improve the distribution. Furthermore, @xmath and the rapidity
along the thrust axis, @xmath , are rather well described. A similar
technique can be used to define the transverse momentum with respect to
the sphericity axis @xmath . We do not show these but they have similar
features to the distributions with respect to the thrust axis.

As we saw in chapter 3 , we can consider the distribution of scaled
momentum @xmath of charged particles. The results in chapter 3 were
given to show that the hadronization technique could describe these
distributions quite well. In fig. 5.12 these distributions are given to
show their dependence on the shower cutoff, @xmath . In addition to the
full distribution we also consider the results from light ( @xmath ),
@xmath and @xmath events. ^(a) ^(a) a The flavour of the quark-antiquark
produced in the initial hard process In all cases we compare with data
from SLD [ 86 ] . The charged particle distribution is well described in
all four cases, in fact somewhat better for heavy primary quarks.

#### 5.2.8 Identified hadron spectra

As in the case of all charged particles we can compare identified
particle spectra from events of different flavour to SLD data [ 86 ] .
Data for @xmath (not shown, being almost equivalent to all charged
particles), @xmath and ( @xmath ) is available. In fig. 5.13 we see the
data for ( @xmath ) spectra from events of different flavour. For large
values of @xmath we clearly overshoot the data in light flavoured
events, producing the ‘bump’. This is somewhat compensated by the heavy
quark events which in turn seem to prefer lower values of @xmath . The
origin of the ‘bump’ is not well understood. We believe that this
feature is related to the hadronization, being similar to but smaller
than that seen in HERWIG , but this has not been shown conclusively.

Fig. 5.14 shows distributions for @xmath and @xmath . Both are rather
better described than the proton spectra but the distribution of @xmath
tends to have a similar, though smaller, ‘bump’ in comparison to data
from ALEPH [ 87 ] .

#### 5.2.9 B fragmentation function

The hadron fragmentation function is defined as the distribution of

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

where @xmath is the energy of the hadron. Using this we can look at the
fragmentation function of different flavours or species of hadrons. In
fig. 5.15 we consider the @xmath hadron fragmentation function in
comparison to data from SLD [ 88 ] . This is the fragmentation function
for all weakly decaying @xmath hadrons. We have also considered data
from ALEPH [ 89 ] for comparison, though these are not shown here. We
can describe the data quite well without any additional tuning of the
hadronization model to this data. The parton shower formulation in terms
of the new variables [ 36 ] and taking quark masses in the splitting
functions into account clearly improves the description of heavy quark
events.

From figure 5.15 we tend to bias the fit towards the @xmath of 2.3 GeV,
as the improved treatment of the @xmath quarks was the main motivation
for deriving the new variables and using the massive splitting
functions. HERWIG couldn’t describe the data as well even with the extra
flags added to the hadronization model to parameterize @xmath hadrons
differently.

#### 5.2.10 Overall results of @xmath annihilation

In Tab. 5.2 we show a list of @xmath values for all observables that
were studied during our analysis, including those not shown in the
plots. The most sensitive parameters were the cutoff value @xmath and
the use of (hard plus soft) matrix element corrections. The table shows
three values of @xmath : our preferred value of @xmath GeV as well as
the lowest and highest values that we considered.

The results should be interpreted with care. The overall trend suggests
that we should prefer a large cutoff scale. However, we have just
averaged over all possible observables. Taking a closer look, we may
want to weight different observables in a different way.

In more detail, the general trend is the following: event shapes, jet
rates and differential jet rates prefer a low cutoff. The single
particle distributions along the thrust and sphericity axes prefer a
small cutoff value. The @xmath distributions prefer either a high or a
low cutoff value. The spectra of identified particles tend to prefer the
high cutoff value with some exceptions for light quark events. The
@xmath fragmentation function clearly prefers the intermediate value.

In addition, as indicated in sect. 5.2.1 , we found that the measured
yields of identified particles clearly prefer the value @xmath GeV.

### 5.3 Conclusions

We have achieved a complete event generator for @xmath annihilation into
hadrons. The main physics features, in comparison to the previous
versions of HERWIG , are an improved parton shower, capable of properly
describing the perturbative splitting of heavy quarks, and an improved
cluster hadronization model.

We have tested our model against a wide range of data from @xmath
colliders and are able to give a good general description of the data.

For many observables the description of the data has been improved with
respect to HERWIG . The new parton shower has a number of remarkable
features. The need for matrix element corrections has decreased. The
main reason for this is the use of improved splitting functions, which
give a far better approximation of the matrix elements in the region of
collinear gluon emissions. We can describe observables involving light
or heavy quark splitting with a unique set of parameters. The new
hadronization model also improves the description of identified particle
spectra and multiplicities.

The detailed analysis of our results leaves us with a recommendation :
the set of parameters that is shown in table 5.1 . This set of
parameters is understood as a weighted compromise in order give a good
overall description of the data we have considered so far. We did not
aim at a complete tuning of the model, but rather wanted to study its
ability to describe the broad features of the data, which turned out to
be very successful.

Work is currently under way testing the parton shower on initial state
radiation. A model for the soft underlying event in hadron–hadron
collisions is also under development. The aim is to have the code tested
and debugged so a complete event generator for the simulation of
Tevatron and LHC events is available.

## Chapter 6 Effective Potential Analysis: Effective

### 6.1 Supersymmetry

Though the SM presently describes physical phenomena extremely well
there is reason to believe that it will eventually be insufficient to
describe physics at higher scales. The scale tested to date is of the
order of 100 GeV. The Planck scale, @xmath GeV, is the scale at which
gravitational effects will be of the same order as the other
interactions. This scale is 16 orders of magnitude higher than the
currently observed phenomena. On an intuitive basis this is suggestive
that there must be new phenomena occurring between these scales. This is
commonly referred to as the hierarchy problem.

There is also another problem, known as the fine tuning problem. This is
due to the Higgs boson. The mass of the Higgs boson is restricted to be
of the order @xmath . Figure 6.1 shows the diagrams that correct this
mass at one loop. From fig. 6.1 a we get the correction due to Dirac
fermions with mass @xmath [ 90 ]

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

where @xmath is an ultraviolet momentum cutoff at the scale of new
physics and @xmath is the coupling derived from the term @xmath . This
problem directly affects only the correction to the Higgs scalar boson
@xmath because the fermions and gauge bosons do not have the quadratic
sensitivity to @xmath . If @xmath is of the order of @xmath then this
correction is about 30 orders of magnitude larger than the expected
mass-squared of the Higgs boson. This will indirectly affect the SM
particles and their known masses as corrections to these masses have
some dependence on @xmath . Therefore, this cannot be the case.

The Higgs mass also receives a contribution from fig. 6.1 b from the
scalar particles. For a real scalar field, this contribution takes the
form [ 90 ]

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

Due to the opposite signs in ( 6.2 ) versus ( 6.1 ) there could be a
particular combination of particles and masses that exactly cancel the
divergences. Though plausible, it seems extremely unlikely that all of
the parameters that are currently in the SM plus any particles occurring
with a higher mass are tuned exactly to cancel this.

Instead a systematic cancellation of the divergences can occur. We see
that if we have two complex scalar fields for each fermion field which
couple to the Higgs boson exactly as @xmath then they exactly cancel the
quadratic terms. This symmetry between fermions and bosons is known as
supersymmetry [ 90 , 91 , 92 ] .

Of course this symmetry must be broken because we do not observe bosonic
states of the same mass as a fermion partner. The scale at which it is
broken is @xmath and the SUSY particles will have masses of the order of
@xmath . In SUSY models [ 90 ] this value is expected to be at most 1
TeV in order to allow for a Higgs VEV which will give the correct values
of @xmath and @xmath .

At a scale of 1 TeV, the experiments at LHC should be able to discover
SUSY particles. Research is still ongoing into new ways to use the
general purpose experiments ATLAS [ 93 ] and CMS [ 94 ] to search for
SUSY particles (for example [ 95 , 96 ] ).

#### 6.1.1 Superpotential

The fermion and boson that are supersymmetric partners are combined into
a multiplet called a supermultiplet. There are two kinds of
supermultiplets, a chiral and a gauge supermultiplet. A chiral
supermultiplet is a supermultiplet formed by the matter fields. The
gauge fields and their superpartners form gauge supermultiplets. These
are the objects that enter into the supersymmetric Lagrangian. This in
turn can be written in terms of the superpotential , which will be
described in this section.

It can be shown that the most general set of renormalizable SUSY
interactions for a field @xmath and its SUSY partner can be written as

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

where the @xmath ’s are explained below, the @xmath is an auxiliary term
and the c.c. indicates complex conjugate. The auxiliary terms are used
as a bookkeeping device and are eliminated by the equations of motion.
Doing so shows that @xmath .

We can now define the superpotential as

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

where @xmath is a mass matrix for the fermions and @xmath is a Yukawa
coupling of scalar, @xmath , and fermions @xmath . This is related to
the @xmath ’s in eq. ( 6.3 ) by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (6.5)
     @xmath   @xmath   @xmath      (6.6)
  -- -------- -------- -------- -- -------

By replacing the @xmath terms and adding the kinetic term, we find the
complete Lagrangian for a chiral supermultiplet is

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

where @xmath is the scalar potential and @xmath is the standard kinetic
terms for a fermion and a scalar.

The gauge field interactions also have to be written in terms of their
superpartners. For a gauge boson, @xmath , and its superpartner fermion,
@xmath , this is

  -- -------- -- -------
     @xmath      (6.8)
  -- -------- -- -------

where @xmath is the same term as in the SM and @xmath is another
auxiliary field. @xmath and @xmath are given by

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

and are related to the standard @xmath -matrices by

  -- -------- -- --------
     @xmath      (6.10)
  -- -------- -- --------

It can be shown that there are two other terms that can be added and the
Lagrangian will remain invariant under supersymmetric transformations.
When added to the Lagrangian they give

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

where @xmath is the generator of the group @xmath is a mediator of. It
is from this equation that we can find the equations of motion to remove
@xmath . We find that @xmath and the @xmath from ( 6.8 ) combines with
the last term in ( 6.11 ). Since both @xmath and @xmath can be expressed
purely in terms of scalar fields they can be used to write the complete
scalar potential as

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

#### 6.1.2 Minimal Supersymmetric Standard Model

The Minimal Supersymmetric Standard Model (MSSM) is the model that
contains all of the possible @xmath SUSY interactions and special cases
of this model are generally analyzed phenomenologically. This model has
one superpartner for every SM particle and an extra @xmath Higgs
doublet. The extra Higgs doublet is due to the requirement that the
superpotential be an analytic function. This prevents the addition of a
Yukawa term like @xmath and instead a second Higgs doublet is needed.
Table 6.1 shows the particle content in terms of the interaction
eigenstates. We also introduce the convention that all superpartners of
fermions are names with the letter s preceding the name and all
superpartners of bosons have ino appended to the name. For example the
partner of an electron is a selectron and the partner of a B is a Bino.
Also, by convention the symbol for a superpartner field is to put a
tilde on top of the field symbol, e.g. @xmath . Bosons with a
superscript @xmath are vector bosons, whereas those without are scalar
bosons.

Just like in the SM, several of the interaction states mix to form the
mass states. Table 6.2 shows which interaction states mix to form which
mass states; the mass states are denoted by the word for the physical
particles that are expected to be observed. The mixture of the (s)quarks
given in the table is to signify that the left and right handed
(s)quarks mix, not the up- and down-type (s)quarks. The Higgs sector
isn’t quite as straightforward. Each Higgs doublet contains a charged
part and a neutral part. The real parts of the two neutral Higgs
doublets mix to form the CP even Higgs states, often denoted by @xmath
and @xmath . Here the lower case is the lighter Higgs, the one that is
expected in the SM. The imaginary parts of the neutral Higgs doublets
mix to form the CP odd Higgs, @xmath . The remaining charged parts of
both doublets then mix to form two charged Higgs bosons. Also, often the
convention @xmath and @xmath is used [ 90 ] . By the definitions given
here this is equivalent to @xmath and @xmath . The mass states of the
four neutralinos are denoted by @xmath in order of mass. The four mass
state charginos are denoted by @xmath .

##### 6.1.2.1 Soft Breaking

As none of the superpartners of the SM particles have been observed this
implies that supersymmetry must be a broken symmetry. If we refer back
to the fine tuning argument we see that in order for the quadratically
divergent parts to still cancel, the dimensionless couplings must cancel
(i.e. @xmath ). This leads us to only consider “soft” breaking of
supersymmetry. This means that we can write the Lagrangian as

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

where @xmath are all the terms preserving supersymmetry and @xmath are
all the terms that softly break supersymmetry. To ensure
renormalizability and to maintain the natural cancellation of quadratic
divergences, @xmath must have only mass terms and couplings with
positive mass dimension.

It is the existence of the soft term that allows all of the
superpartners of the SM particles to be heavier than the top quark. In
the absence of electroweak symmetry breaking, all of the SM fields would
be massless. This isn’t true for the superpartners. The scalars can have
a mass term in the Lagrangian of the form @xmath . The gauginos and
Higgsinos also do not require electroweak breaking in order to acquire a
mass due to the fact that they are fermions in a real representation of
their gauge group.

If the largest mass term occurring in @xmath is @xmath . We can see that
the corrections to the Higgs mass-squared, due to the SUSY particles,
must vanish as @xmath . This means that these corrections cannot be
quadratic in @xmath and the corrections must be of the form

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

If we take @xmath of the order 1 and @xmath of order @xmath , we find
that the lightest SUSY particles should be about 1 TeV, as stated
previously. This is what leads to the optimism that SUSY will be
discovered at the LHC.

The actual soft breaking terms added to MSSM are

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

There is another term that could be added without losing the
renormalizability of the theory. This term is @xmath but this is often
not included as it can lead to quadratic divergences in some models. It
is also evident that the terms in ( 6.15 ) do break supersymmetry
because they are not expressions of the supermultiplets. This is because
mass terms for the fermions can be reabsorbed into a redefinition of the
superpotential and the @xmath and @xmath terms.

To complete the definition of the MSSM we must also specify the
superpotential. This is given as

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

Here the fields @xmath are the chiral supermultiplets, not just the SM
fields. We can see the family Yukawa matrices and the Higgs fields which
are used to give the masses. We also see the supersymmetric equivalent
to the @xmath term in the SM.

This section has been a simple introduction to SUSY models, SUSY
Lagrangians and MSSM. For a more detailed discussion of the development
of all these topics see [ 90 , 91 , 92 ] . Next the concept of the
effective potential and its uses is given and finally the software
Effective is discussed which uses the effective potential to study
@xmath SUSY models.

### 6.2 Effective Potential

The effective potential was originally introduced by Euler and
Heisenberg [ 97 ] and further expanded by Schwinger [ 98 ] . This was
later applied to studies of spontaneous symmetry breaking by Goldstone,
Salam and Weinberg [ 99 ] . The development of the effective potential
given in this section, as well as a complete summary of the effective
potential and its uses is given in [ 100 ] .

The effective potential is capable of providing quite a lot of
information about a theory, while working with a simpler expression.
Here is presented the development of the effective potential and in
subsequent sections the various things that can be derived from an
effective potential are given. These are all capabilities of the
software, Effective , which is discussed in the last section.

We start by giving the theoretical derivation of the effective
potential. With this derivation it can be shown that the the one-loop
contribution to the effective potential can be derived in a model
independent way. Unfortunately, the higher order corrections cannot be
developed in a model independent way. Because of the model dependence,
the two-loop effective potential is not implemented in Effective ,
though future extensions of the code could provide this functionality.

#### 6.2.1 Generating Functionals

As an example we start with a theory described by the scalar field
@xmath with a Lagrangian density @xmath . The action is then

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

The generating functional is the vacuum-to-vacuum expectation value
@xmath and is given by the path-integral representation,

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.19)
  -- -------- -- --------

Using ( 6.18 ) we define

  -- -------- -- --------
     @xmath      (6.20)
  -- -------- -- --------

where @xmath is known as the connected generating functional. The
effective action @xmath is just the Legendre transformation of ( 6.20 )
and is given by

  -- -------- -- --------
     @xmath      (6.21)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.22)
  -- -------- -- --------

@xmath is the weighted average of the fluctuations of the field. In a
translationally invariant theory, which are the ones Effective is
designed to deal with, @xmath is a constant

  -- -------- -- --------
     @xmath      (6.23)
  -- -------- -- --------

The effective potential can then be defined as

  -- -------- -- --------
     @xmath      (6.24)
  -- -------- -- --------

which can be written as an expansion as

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

where @xmath are the one-particle irreducible (1PI) Green functions.
Minimizing the effective potential over the constant fields, @xmath ,
gives the vacuum state of the theory [ 3 ] .

#### 6.2.2 One-Loop Potential

The tree-level effective potential is identical to the classical
effective potential. This is simply

  -- -------- -- --------
     @xmath      (6.26)
  -- -------- -- --------

The one-loop contribution can be written in closed form for any theory
containing fields of spin @xmath or @xmath .

We show here the one-loop correction for a model with one
self-interacting scalar field described by the Lagrangian

  -- -------- -- --------
     @xmath      (6.27)
  -- -------- -- --------

where @xmath is the tree-level potential given by

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

As we expressed in ( 6.25 ), the one-loop correction to the tree-level
effective potential is given by the sum of all 1PI diagrams with a
single loop and zero external momenta. The @xmath -th diagram has @xmath
propagators, @xmath vertices and @xmath external legs. The @xmath
propagators contribute a factor of @xmath , as we saw in chapter 1 .
Each pair of the external lines contributes a factor of @xmath and each
vertex a factor of @xmath . There is also a global symmetry factor of
@xmath .

This gives

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.29)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

In ( 6.20 ) we did not include a normalization factor of @xmath . This
is needed to correctly generate ( 6.29 ). Without it a shift is
introduced to the effective potential. After a Wick rotation and using
the unnormalized generating functional we find

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

where the momentum is now in Euclidean space and the mass is the shifted
mass given by

  -- -------- -- --------
     @xmath      (6.31)
  -- -------- -- --------

This is finally

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

in the @xmath renormalization scheme [ 101 ] where @xmath is the
renormalization scale. This result can be trivially generalized to the
case of @xmath complex scalar fields each described by the Lagrangian,

  -- -------- -- --------
     @xmath      (6.33)
  -- -------- -- --------

The one-loop contribution in the @xmath renormalization scheme is

  -- -------- -- --------
     @xmath      (6.34)
  -- -------- -- --------

where @xmath is the mass matrix of the fields given by

  -- -------- -- --------
     @xmath      (6.35)
  -- -------- -- --------

Eq. ( 6.34 ) can be generalized to fermions obeying the Dirac equation
and gauge bosons [ 100 , 102 ] as

  -- -------- -- --------
     @xmath      (6.36)
  -- -------- -- --------

where the sum is over the spins, @xmath and @xmath , and @xmath is the
trace is over the mass matrix of spin, @xmath . Defining the
“Supertrace” as

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

which is the spin-weighted trace, we have the one-loop contribution in
the @xmath renormalization scheme as

  -- -------- -- --------
     @xmath      (6.38)
  -- -------- -- --------

### 6.3 Mass Matrices

The fields defined as representations of the groups in a field theory
are interaction eigenstates of the theory. These are states in which the
interactions are directly governed by the respective couplings. The
particles that are observed are the mass eigenstates of the theory.
These states are a mixture of interaction eigenstates, and thus the
interactions of these states are a mixture of the couplings in the
theory. The interaction states that mix to form the mass states, as well
as the mixing angles, can be derived from the mass matrices. In should
be noted that the mass matrices are not derivable from the effective
potential. Rather, the value of the VEVs chosen from the minimization of
the effective potential determine the mass spectrum of the particles.
Derivation of the masses requires the full potential.

For complex scalars the mass matrix is defined as

  -- -------- -- --------
     @xmath      (6.39)
  -- -------- -- --------

where @xmath is the expectation value of the the scalar field @xmath .
Similarly for vectors the mass matrix is

  -- -------- -- --------
     @xmath      (6.40)
  -- -------- -- --------

The mass matrix for fermions is not defined as a mass squared matrix.
Instead for complex fermions it is given by

  -- -------- -- --------
     @xmath      (6.41)
  -- -------- -- --------

Diagonalizing these mass matrices gives

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

where @xmath and @xmath are unitary matrices which define the mixing
angles of the interaction states. @xmath is the diagonal matrix whose
elements are the masses of the mass eigenstates.

Eqs. ( 6.39 - 6.41 ) don’t indicate whether the potential is to be taken
at tree-level, one-loop or some other order. That is because the masses
also have higher order corrections. If the tree-level potential is used,
it yields the tree-level mass matrices. Likewise, if the one-loop
potential is used it yields the one-loop mass matrix. For the exact mass
term the exact potential would be needed.

As we saw earlier, the one-loop effective potential can be written in
terms of the mass matrices only. The matrices in ( 6.38 ) are the tree
level matrices. From ( 6.39 - 6.41 ) we can see that the one-loop masses
are derived from the full one-loop potential. This would require the
calculation of the full one-loop potential, which is much more
complicated. Instead the one-loop corrections to the mass matrices can
be computed in another way. If we refer back to chapter 1 , the masses
of a field are related to the two-point Green’s function of that field.
In fact, it can be shown that the one-loop correction to the mass is
just the one-loop correction to the two-point Green’s function [ 3 ] .

Before we present the one-loop corrections to the mass matrices, the
idea of a ghost field must be explained. We saw that in chapter 1 that
the propagator for a gauge boson is given as @xmath . This is not quite
true for non-Abelian groups. Instead using the Faddeev-Popov method to
quantize the field and the gauge condition

  -- -------- -- --------
     @xmath      (6.43)
  -- -------- -- --------

where @xmath is a Gaussian weight, we find the propagator is

  -- -------- -- --------
     @xmath      (6.44)
  -- -------- -- --------

The Faddeev-Popov quantization inserts a determinant of the form @xmath
where @xmath is now used to represent the infinitesimal form of the
gauge transformation. This determinant is zero for an Abelian group but
non-zero for a non-Abelian group. Instead Faddeev and Popov showed it
can be expressed as

  -- -------- -- --------
     @xmath      (6.45)
  -- -------- -- --------

where @xmath and @xmath are now anti-commuting fields which are scalars
under Lorentz transformations. These new fields are known as ghost
fields and introduce new Feynman rules that must be considered to ensure
that the value of an @xmath -matrix calculation is gauge-invariant.

For a spontaneously broken symmetry, we impose the gauge condition

  -- -------- -- --------
     @xmath      (6.46)
  -- -------- -- --------

where @xmath is the Goldstone boson associated with the breaking and
@xmath is the VEV of the field which leads to the breaking. Using this
form of the gauge fixing condition gives the massive gauge boson the
propagator

  -- -------- -- --------
     @xmath      (6.47)
  -- -------- -- --------

which is the same value for the gauge boson propagator shown before for
the massless case. This also gives the Goldstone boson, @xmath , a mass
of @xmath where @xmath is the mass of the gauge boson. The ghost also
acquires the same mass, @xmath , and this must be taken into account
when computing Feynman rules of a process.

The one-loop corrections for a field can be given in a gauge independent
form by explicitly keeping @xmath . That has been done for the one-loop
corrections given here. In Effective , the ghost contributions are hard
to automate. Instead we work in the Landau gauge, @xmath where the
masses of the Goldstone bosons remain zero and the ghost terms do not
contribute to the calculations.

The one-loop corrections can be written in terms of the
Passarino-Veltman [ 103 , 104 , 105 ] functions. These are defined by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath ^(a) ^(a) a Not to be confused with @xmath for the Lorentz
index is the renormalization scale and the integrals are regularized in
@xmath dimensions. The first two of these can be integrated and
expressed (expanding to @xmath ) as

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (6.49)
     @xmath   @xmath   @xmath      (6.50)
  -- -------- -------- -------- -- --------

where @xmath ,

  -- -------- -- --------
     @xmath      (6.51)
  -- -------- -- --------

and @xmath . The other Passarino-Veltman functions can be decomposed
into the two scalar functions, @xmath and @xmath [ 104 ] . There are
more functions for higher loop corrections that are not given here.
These can be decomposed into their respective higher-loop scalar
functions (e.g. @xmath , @xmath , …).

The corrections are summed over all internal fields and the couplings
are given from the Lagrangian. There are two ways that the one-loop
corrections can be applied. First one could find the diagonal form of
the tree-level matrix. This defines the mass eigenstates and therefore
the couplings of these states. The corrections can then be directly
applied to the tree-level masses given the couplings defined in this
manner. This is not exactly the one-loop correction, however. This will
give a close approximation to the one-loop masses, but will only give
the tree-level mixings. If instead the one-loop corrections are applied
to the undiagonalized matrix, with corrections to the off-diagonal
elements, then the diagonalization of this corrected matrix will give
the correct one-loop masses and mixings. Both techniques have been
implemented in Effective , but the latter is much more time intensive
and if only the masses are desired, applying the corrections to the mass
eigenstates is a good approximation.

#### 6.3.1 Scalar One-Loop Corrections

We first give the one-loop corrections to the scalar masses. Figure 6.2
shows the corrections to the scalar mass matrix term @xmath . These
diagrams are summed over all possible intermediate states given in the
theory. The results given here have been calculated with the help of the
computer software FeynCalc [ 106 ] and FormCalc [ 107 ] .

The form for the contribution of the scalar four-point vertex, given by
the first diagram in figure 6.2 is

  -- -------- -- --------
     @xmath      (6.52)
  -- -------- -- --------

where @xmath is the four-point coupling of the fields @xmath and @xmath
with an arbitrary scalar field @xmath . The second diagram in figure 6.2
is the contribution of the four-point vertex given with a vector loop.
This correction is

  -- -------- -- --------
     @xmath      (6.53)
  -- -------- -- --------

The diagram given by fig. 6.2 c is of the scalar three-point vertex.
This is given by

  -- -------- -- --------
     @xmath      (6.54)
  -- -------- -- --------

where @xmath is the coupling of field @xmath to the two fields in the
loop and @xmath is the coupling of field @xmath .

There is no fermion four-point diagram as this type of term would have a
mass dimension greater than four in the Lagrangian. Instead there is
only a three-point correction. This term (fig. 6.3 d) is given by the
expression

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.55)
                                @xmath   
  -- -------- -------- -------- -------- --------

The vector three-point term, given by the fifth diagram in figure 6.2 ,
is

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.56)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

where

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (6.57)
  -- -------- -------- -------- -- --------

Remarkably, in the ’t Hooft-Feynman gauge ( @xmath ) this reduces to

  -- -------- -- --------
     @xmath      (6.58)
  -- -------- -- --------

The last one-loop corrections to the scalar mass matrix, @xmath , is
given by the last diagram in figure 6.2 . This is the correction given
by the vector-scalar three-point vertex, given by

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.59)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

where the vector corresponds to loop field 1 in the previous
abbreviations and the scalar field is loop field 2.

#### 6.3.2 Vector One-Loop Corrections

The one-loop corrections to the vector fields can also be generated
using the same two programs FeynCalc and FormCalc . Figure 6.3 shows the
diagrams which give corrections to the vector mass.

The first diagram in figure 6.3 leads to a correction of the form

  -- -------- -- --------
     @xmath      (6.60)
  -- -------- -- --------

The contribution from the fermion loop is gauge independent and is given
by

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.61)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

and fig. 6.3 c shows the scalar four-point correction. This is

  -- -------- -- --------
     @xmath      (6.62)
  -- -------- -- --------

The next two diagrams are of the four-point vector loop and the
three-point vector-scalar loop. These are given by

  -- -------- -- --------
     @xmath      (6.63)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (6.64)
  -- -------- -- --------

where we have used the same abbreviations ( 6.57 ) and the vector
corresponds to field 1 in the notation and the scalar is field 2. The
remaining two diagrams are for the vector three-point correction and the
ghost terms. The vector three-point correction is quite complicated and
is given by

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.65)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

where the abbreviations ( 6.57 ) are used and @xmath , @xmath and @xmath
. In the ’t Hooft-Feynman gauge this reduces to

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.66)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

It must also be noted that the gauge bosons from an unbroken group are
massless. These bosons only couple to themselves and the correction is
proportional to @xmath . The correction is to be evaluated at @xmath ,
which for bosons from an unbroken group is zero.

The remaining one-loop correction to the vector mass matrix is from the
ghost terms. This is the last diagram in figure 6.3 and is given by

  -- -------- -- --------
     @xmath      (6.67)
  -- -------- -- --------

from which it is easy to see that the ghost contribution is zero in the
Landau gauge.

#### 6.3.3 Fermion One-Loop Corrections

There are only two mass corrections to the fermion masses. The diagrams
of these are given in fig. 6.4 . The first one is the correction due to
a scalar-fermion three-point coupling. This is

  -- -------- -- --------
     @xmath      (6.68)
  -- -------- -- --------

The mass correction is given by @xmath . This can be approximated by
@xmath .

Lastly, the correction given by fig. 6.4 b is from a vector boson
three-point coupling. This is

  -- -------- -- --------
     @xmath      (6.69)
  -- -------- -- --------

where the abbreviations given earlier are used and the index 1 refers to
the vector and the index 2 is the fermion.

### 6.4 Renormalization Group Equations

The basic concept of renormalization stems from the observation that the
divergences in the one-loop graphs amount to shifts in the parameters of
the action. For example, as we saw in the last section they change the
mass of a field. Renormalization is the procedure of cancelling the
divergences from these shifts by introducing counterterms into the
Lagrangian. These counter terms are defined such that they exactly
cancel the divergent quantity in the one-loop correction but leave the
finite parts untouched [ 5 ] .

We can first consider the @xmath theory. The Lagrangian is given by

  -- -------- -- --------
     @xmath      (6.70)
  -- -------- -- --------

We can then rescale the field by @xmath , so that in terms of the new
‘renormalized field’ @xmath we have

  -- -------- -- --------
     @xmath      (6.71)
  -- -------- -- --------

We can then write this in terms of the counterterms

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.72)
                                @xmath   
  -- -------- -------- -------- -------- --------

We can see that @xmath , @xmath and @xmath . These counterterms are
adjusted to cancel the divergences of each term.

To renormalize a theory renormalization conditions must be imposed. The
general conditions that are imposed are to set the contributions from
the 1PI diagrams to the two-point Green’s functions and the derivatives
of these diagrams to zero at a spacelike momentum, @xmath . @xmath is
then known as the renormalization scale . The conditions are imposed at
a spacelike momentum in order to avoid threshold singularities.
Similarly, the 1PI contributions to the three- and four-point Green’s
functions are defined such that the coupling at that scale is exactly
the physical coupling (e.g. @xmath from ( 6.72 )).

The renormalization scale is completely arbitrary. The theory can just
as easily be defined at another renormalization scale. This implies that
the theory and the redefined couplings should depend on the scale in
such a way that physical calculations are independent of the scale. For
example if we take an @xmath -point Green’s function we require

  -- -------- -- --------
     @xmath      (6.73)
  -- -------- -- --------

This is for either a massless field or if the mass of the field is
considered as on of the vertices that needs to be renormalized. @xmath
is the counterterm corresponding to the coupling @xmath and @xmath is
the rescaling of the external field in the @xmath -point Green’s
function. Defining

  -- -------- -- --------
     @xmath      (6.74)
  -- -------- -- --------

we can now give the Callan-Symanzik equation [ 108 , 109 ] . This is

  -- -------- -- --------
     @xmath      (6.75)
  -- -------- -- --------

The @xmath and @xmath functions are the same between different Green’s
functions. Knowing this we can find the @xmath function from the 2-point
Green’s function of the field. The 2-point Green’s function can be
expressed in terms of the loop diagrams and the counterterms. Doing so
@xmath can be shown to be

  -- -------- -- --------
     @xmath      (6.76)
  -- -------- -- --------

The counterterm can be written in the form (at lowest order)

  -- -------- -- --------
     @xmath      (6.77)
  -- -------- -- --------

in order to cancel the divergent logarithm in @xmath . This means that
we can find @xmath simply by determining @xmath , the coefficient of the
divergent piece of the 1PI diagrams. Since @xmath is related to the
field renormalization it is known as the anomalous dimension of the
field.

Knowing the anomalous dimensions, the @xmath functions can be derived by
using the appropriate Green’s function ( @xmath for an @xmath -point
coupling). The @xmath -point Green’s function is given by the sum of the
tree-level diagram, the 1PI loop diagrams of the vertex, the vertex
counterterm and the external leg corrections. This can be expressed for
the @xmath -point coupling @xmath , at one-loop order, as

  -- -------- -- --------
     @xmath      (6.78)
  -- -------- -- --------

plus the finite terms. Applying the Callan-Symanzik equation we find

  -- -------- -- --------
     @xmath      (6.79)
  -- -------- -- --------

We can see that the second term on the right is just the sum of the
anomalous dimensions of all the external particles in the Green’s
function. At one-loop, @xmath is given by an expression of the form

  -- -------- -- --------
     @xmath      (6.80)
  -- -------- -- --------

This means that we just have to compute the divergent pieces of the 1PI
corrections to the coupling and @xmath is given by

  -- -------- -- --------
     @xmath      (6.81)
  -- -------- -- --------

Most theories have many couplings and fields associated with them. This
requires the procedure that produced ( 6.75 ) to be applied to a set of
couplings, @xmath , and a set of fields @xmath .

  -- -------- -- --------
     @xmath      (6.82)
  -- -------- -- --------

We saw earlier that using the two-, three- and four-point Green’s
functions, eq. ( 6.82 ) can be applied to determine the form of all
@xmath and all @xmath , known as the renormalization group equations [
110 , 111 , 112 ] . This technique requires the calculation of several
1PI diagrams and is quite computationally intensive. Instead there are
some couplings which can be computed either completely for an arbitrary
theory, or by applying the Callan-Symanzik equation to a different set
of observables.

The running of the gauge group couplings can be computed from many
different vertices. They all require the boson self-energy which is
given by the diagrams in fig. 6.3 . The divergences of these diagrams
define the anomalous dimension of the gauge boson field. These sum to
give

  -- -------- -- --------
     @xmath      (6.83)
  -- -------- -- --------

where @xmath is the sum over fermions, @xmath is the sum over scalars,
@xmath and @xmath . One can then use the fermion-fermion-vector
coupling, as in [ 3 ] , or one could just as easily use the gauge boson
three- or four-point couplings (in non-Abelian theories). The final
result is gauge independent and given in general by the expression

  -- -------- -- --------
     @xmath      (6.84)
  -- -------- -- --------

where again the index @xmath indicates the fermions and @xmath the
scalars. For the case of Weyl spinors, the sum of the fermions has an
additional factor of a half (e.g. @xmath rather than @xmath ), and
similarly for real scalars.

The SM has Yukawa couplings, gauge couplings and couplings of the Higgs
boson ( @xmath and @xmath ). These are all dependent on the scale ^(b)
^(b) b Here @xmath is used instead of @xmath to avoid confusion with the
Higgs coupling, @xmath . , @xmath , at which they are evaluated. A
common argument for beyond standard model (BSM) physics is that given
the particles in the SM, the couplings, @xmath , @xmath and @xmath ,
will never meet at a single ultimate scale, known as the unification
scale. Though there is no proof that indicates these should unify, it is
believed to be a desired and expected result of a theory. Figure 6.5
shows the running of the different @xmath ’s for the particles in the EW
theory with one generation (black, solid), the SM with three generations
(red, dashed) and the MSSM with three generations (blue, dot-dashed). We
can see from this figure that the couplings from the MSSM all meet at a
single scale. The derivation of the @xmath functions and the running of
the couplings in this figure were all done by entering the models into
Effective . In unification theories, the @xmath coupling is multiplied
by @xmath and this is also done here.

In Effective the observable that is used to define some of the couplings
is the effective potential [ 100 , 113 ] . The one-loop effective
potential @xmath , where @xmath is given in ( 6.38 ), can be used to
define the RGEs for all the couplings that appear in the potential. This
is the set of couplings for the fields that may acquire a non-zero VEV.
If we apply the Callan-Symanzik equation to the one-loop effective
potential, where now the derivatives with respect to the fields are
replaced by derivatives with respect to the VEVs, this yields

  -- -------- -- --------
     @xmath      (6.85)
  -- -------- -- --------

Using this one can compare the powers of the VEVs ( @xmath ) on the left
hand side of the equation to those of the right and derive the relations
of the @xmath functions, given the anomalous dimensions, @xmath .

To compute the remaining @xmath functions, we must use ( 6.81 ). This
requires us to compute the 1PI diagrams for the three- and four-point
vertices given in fig. 6.6 . Since we have already derived the @xmath
functions of the gauge group couplings we do not need to consider the
vertices with a gauge boson as an external leg.

### 6.5 Effective

Effective is a computer program that is able to generate the effective
potential, the mass spectrum and the RGEs of a theory. It is originally
based on the work in [ 114 ] and uses the GiNaC [ 115 ] computer algebra
system to do algebraic manipulations. This package provides for
evaluations and simplifications of complex algebraic structures within
the C++ environment. As this is a C++ library, it also allows for
expansion. New functions and objects can be created that can then have
their own set of functions that are used during simplifications and
evaluations. It is the ability to integrate the computer algebra with
the standard C++ functionality and to be able to define new objects that
interact with the computer algebra package that make GiNaC an ideal
library for building Effective on.

My contribution to Effective covers a broad spectrum. I have
restructured and written the code to work with the algebra package,
GiNaC . The original one-loop mass corrections in the code were only for
scalar particles. These were taken from the literature and did not all
use the same gauge and as a complete correction, were wrong. As has been
seen earlier, these have been rederived in an arbitrary gauge for all
different spins and implemented in Effective in the Landau gauge. Also,
I have done the development and implementation of the RGEs in Effective
.

Effective has currently been designed to work with @xmath SUSY.
Effective itself is a package that can be used to define a SUSY model.
Once this model is defined a user can interact with it. It is these
different interactions that are discussed in this section.

#### 6.5.1 Model Definition

A model in Effective is defined by a set of gauge groups, fields and
additional interactions. These are then used to define a Lagrangian and
an effective potential. The Lagrangian can be used to define the
couplings of the theory and the mass matrices. As we saw in the last
section, the effective potential as well as the Green’s functions can
define the RGEs of the theory.

A gauge group is just that. In Effective this is a class that defines
the structure constants and the generators. This also defines the
dimension of the indices in the fundamental and adjoint representations.
It is also possible to have several gauge groups of the same group
structure defined. For example if a user wants to test a theory with two
@xmath groups this can be done. Each gauge group has an extra flag to
indicate the ‘line’ that it is part of. If someone wants to use two
gauges with the same group structure, they just have to define a new
line for the new group. When indices are being contracted, these lines
are compared and only when they are identical will a contraction occur.
Effective currently has the @xmath , @xmath and @xmath groups
implemented, but it is easy to expand and add new groups. An example of
this is given in the appendix.

Once the groups have been defined, the gauge fields can be added. These
are the fields which mediate the interactions. It is possible to create
gauge bosons and their superpartners, gauge fermions. When the fields
are created the relevant terms can be added to the Lagrangian. This is
given in section 6.1 but is repeated here for convenience

  -- -------- -- --------
     @xmath      (6.86)
  -- -------- -- --------

where @xmath is the gauge fermion and @xmath is the standard tensor
formed by a gauge boson. In @xmath SUSY there are no other terms which
depend only on the gauge mediators. It is possible to extend Effective
to provide for @xmath SUSY. If this were done then a new set of terms
will also need to be added to the Lagrangian.

After the gauge groups and the gauge fields are defined the matter
fields can be given. These are fields that can have charges under more
than one group. These fields also define the other gauge invariant
terms. For a given fermion, @xmath , and superpartner scalar, @xmath ,
we have the terms

  -- -------- -- --------
     @xmath      (6.87)
  -- -------- -- --------

where @xmath is again the gauge mediating fermion, @xmath is the
covariant derivative for the groups the fields are charged under, and
@xmath is the coupling of the @xmath -th gauge group. This expression is
summed over all the gauge groups of the matter fields. It is also at
this point that the VEVs of the scalar fields are defined. A set of
parameters can be defined and combinations of these parameters can be
given as the VEVs. For example, in MSSM one often works with the VEVs in
terms of @xmath and @xmath , not the actual VEVs, @xmath and @xmath .
This can also be done in Effective so the set of parameters that one
works with is consistent with the set of parameters given in the
literature. An example of this is given in the appendix. Unfortunately,
some of the routines in Effective require the actual VEVs to be entered.
These include the RGEs and the minimization of the potential. If neither
of these functions is needed, however, then the set of parameters used
in a paper can also be used in Effective .

Once the fields of the model are given, the superpotential can be
defined. In Effective this is not given as a function of superfields, as
the definition of the superpotential is, but the user must specify this
in terms of the relevant fields (scalars, fermions, etc.). This is a
feature of the code that could be improved to provide the appropriate
superfield formalism. Once the superpotential is defined then the
following terms are added to the Lagrangian

  -- -------- -- --------
     @xmath      (6.88)
  -- -------- -- --------

where we saw before that

  -- -------- -- --------
     @xmath      (6.89)
  -- -------- -- --------

After the definition of the superpotential the last remaining ingredient
of a model is the symmetry breaking terms. These are usually the soft
breaking terms of a SUSY model but Effective can be used to work with
non-SUSY models as well. In this type of model one would define any
other gauge invariant terms that are desired for the model but have not
been added up to this point (e.g. the Yukawa terms).

#### 6.5.2 Mass Matrices

Once the VEVs have been defined the code can generate the tree-level
mass matrices. Effective is able to do this and produce the matrices in
analytic form. It is important to note that in Effective the real and
imaginary parts of the fields are treated independently. The separation
of these parts has been implemented to provide a mechanism for studying
CP violating models. This separation causes several complications when
comparing to the literature though.

Often in the literature the states are given as the mass eigenstates.
These are a combination of real and imaginary parts of the the
interaction states. It is these real and imaginary combinations that
must be compared to the results of Effective for a true comparison.
Often this is a tedious task. Instead it is usually more convincing, and
easier, to check the numerical results of Effective against the
literature.

Another complication that arises when implementing formulae in Effective
is that Weyl spinors are used, not Dirac ones which are often used in
literature. This affects the degrees of freedom of the fields in
Effective . Usually one considers a fermionic field to have a spin
factor of @xmath from the spin coefficient @xmath . Instead since
Effective uses Weyl spinors, this has a factor of @xmath attached to it,
giving @xmath . The difference between Dirac spinors and Weyl spinors
must also be taken into account when implementing the one-loop
corrections given in section 6.3 .

As mentioned earlier, Effective uses the Landau gauge ( @xmath ) to
avoid the need for ghost contributions. The one-loop corrections to the
mass matrices have been implemented in Effective in this gauge. These
corrections are given in numerical form only. There are two ways in
which the corrections can be applied. The first is that the tree-level
matrices are diagonalized and the mixing matrices are set. The
corrections are then applied directly to the mass eigenstates. This is
only an approximation to the one-loop corrections and provides only the
tree-level mixing matrices. The other way in which the one-loop
corrections can be applied is to add the one-loop corrections of the
interaction eigenstates to the tree-level mass matrix. This new matrix
is then diagonalized and this process defines the one-loop mixing
matrices and the one-loop masses. Effective produces the tree-level
matrices and the corresponding diagonal form in order to perform all its
other calculations. The full one-loop correction requires performing an
additional diagonalization for each set of parameters one would want to
compute the masses at. Since the diagonalization of the matrices is one
of the most CPU intensive calculations performed by Effective , doing
the full one-loop corrections is very time consuming.

#### 6.5.3 Effective Potential

At this point the model has been completely defined and the tree-level
masses have been computed. It is now possible to find the effective
potential and minimize it over a set of parameters. The analytic
tree-level effective potential is generated by Effective and can be
returned. Effective also provides a function ex
extremizePotential(vector<numeric*>) that goes through the parameters
given in the input vector and minimizes the potential over these
parameters using the Powell [ 11 ] minimization routine. The resulting
minimum potential is returned and the values of the input parameters are
set to the values that give a minimum. For example the tree-level
effective potential of the electroweak model is given in figure 1.3 .
Passing the VEV parameter @xmath into this routine returns @xmath GeV
@xmath for the potential and sets the value of @xmath to 246.0 GeV.

The one-loop potential can also be minimized in Effective . This uses
the last calculation of the mass matrix (whether it is tree-level or
one-loop) to compute the one-loop correction given in ( 6.38 ). This can
then be minimized in the same manner as the tree-level potential.

Figure 6.7 shows a plot of the MSSM potential from Effective with the
given parameter set @xmath and the two gauge group couplings are set
from the SM. In this plot we set @xmath and @xmath . The tree-level
effective potential of this model is derived in Effective and is given
by

  -- -------- -- --------
     @xmath      (6.90)
  -- -------- -- --------

From this equation we can see with the right set of parameters, the
@xmath term will push the potential below zero and require a particular
combination of the VEVs to minimize.

#### 6.5.4 Renormalization Group Equations

The last feature of a model that is generated automatically by Effective
is the RGEs. Each parameter of the model can have its default value set
at its own scale. The RGEs then evolve these parameters so that the
values are all used consistently at any desired scale.

As was shown earlier the @xmath functions for each parameter are
generated using the one-loop effective potential and the two-, three-
and four-point Green’s functions and the anomalous dimension of the
external fields.

The solution to the boundary value problem can be given as follows.
Start with a scale @xmath . The boundary conditions at this scale can be
given by

  -- -------- -- --------
     @xmath      (6.91)
  -- -------- -- --------

where @xmath is the set of parameters which are defined at scale @xmath
. The boundary condition at a new scale, @xmath , is

  -- -------- -- --------
     @xmath      (6.92)
  -- -------- -- --------

and again, @xmath is the set of parameters defined at scale @xmath . The
full set of parameters of the model are given by @xmath where @xmath is
constrained at @xmath and @xmath is constrained at @xmath . The
parameters at the two scales are related by two functions, @xmath and
@xmath by

  -- -------- -- --------
     @xmath      
     @xmath      (6.93)
  -- -------- -- --------

where these functions are determined by the RGEs. Using these equations
we can numerically solve for the different parameters.

There are three numerical methods that have been considered in Effective
[ 114 ] . The first is known as the “shooting” method [ 11 ] . Using
this method one computes @xmath numerically by use of the function
@xmath . This amounts to numerically finding the solution to

  -- -------- -- --------
     @xmath      (6.94)
  -- -------- -- --------

where @xmath is the boundary values of the parameters at scale @xmath .
This just requires solving this equation over the set of parameters
@xmath .

The “shooting” method cannot be used in SUSY, however, as SUSY requires
the input to be given at three scales: @xmath and @xmath . Another
reason that this method cannot be used for SUSY theories is that the
boundary conditions of a SUSY theory cannot be conveniently expressed as
is done in ( 6.92 ).

An alternative method [ 11 ] is the “drift” method. This method is a
modified version of the “shooting” method. Here a guess @xmath is taken
and @xmath is determined from ( 6.91 ). @xmath and @xmath are then given
from ( 6.93 ). The boundary conditions at scale @xmath are imposed to
give @xmath . These are then run back up to the scale @xmath by the
inverse of ( 6.93 ). This gives a new set of values, @xmath and @xmath .
The conditions at scale @xmath are then imposed again. This process
defines a recurrence relation @xmath of which the desired values of
@xmath and @xmath will be a fixed point. The problem with this method is
that the physical values might not be the only fixed point and there is
no guarantee that this fixed point is stable.

A third method, which has been implemented in Effective , handles the
case where the fixed point is not stable. In this case we can instead
numerically solve the equation

  -- -------- -- --------
     @xmath      (6.95)
  -- -------- -- --------

using the Newton-Raphson [ 11 ] method. This method can be rather slow
but if one makes reasonable guesses for some of the less important
parameters the parameter space can be reduced and convergence is
quicker.

We have already seen the running of the gauge group couplings in fig.
6.5 produced by Effective . These were generated by setting the fields
and groups of the model. Effective then computes the contribution to the
@xmath function from each field of the model. The coupling is evolved
according to the @xmath function generated.

Figure 6.8 shows the evolution of the @xmath mass given by the @xmath
function for the Yukawa coupling in the SM. This has been evolved using
@xmath functions produced by Effective and the Runge-Kutta [ 11 ] method
of differential equation evolution. The initial condition for this
figure is @xmath GeV. Again, the @xmath function is generated by
Effective . Each of the anomalous dimensions of the Yukawa coupling are
added together. This is the sum from ( 6.81 ). The @xmath factors have
been calculated from the 1PI contributions of the vertices given in fig.
6.6 .

#### 6.5.5 Future Extensions of Effective

Before we discuss the extensions of Effective we first summarize what it
can already do and how a user could use Effective without any
extensions.

Effective is able to generate the full Lagrangian of a SUSY model based
on the groups, fields, superpotential and SUSY breaking terms. This
Lagrangian is used to generate the effective potential, mass matrices
and RGEs of the model. At this stage a user can input their parameters
over a range of scales and evolve them to the same scale. The mass
spectrum at tree-level or one-loop can be evaluated given the parameter
set. The user could then automate the study of the mass spectrum over a
range of parameters.

The code of Effective allows for several extensions. The most useful one
in producing physical results is allowing additional diagrams to be
coded. The library provides a class Diagram which provides several
useful functions. This class allows a user to pass in the external
fields of a diagram and a set for each of the internal propagators. The
class provides functions which find the couplings of a set of fields
given as either interaction states, mass states or combinations of the
two. This is done by computing the coupling of mass states based on
their mixing matrices. The couplings can then be used in the computation
of a diagram by inheriting the Diagram class and implementing the
virtual function ex function() function. The diagram is then evaluated
by iterating over all the internal propagator fields and summing the
result of each diagram by a call to the ex evaluate() function.
Implementing ones own diagrams would allow Effective to be used to
produce results of physical calculations (like cross-sections) over a
range of parameters.

The implementation of a users own diagrams isn’t the only possible
extension. The classes GaugeField and MatterField implement the set of
expressions given in ( 6.86 , 6.87 ). If someone wanted to consider a
model which needed other terms (such as @xmath SUSY) they would need to
inherit these classes and override the function ex interaction() . They
could then add new terms that depend on the fields. Unfortunately, this
isn’t all that would be needed for @xmath SUSY. There would be a need to
inherit the Model class and change several functions. But this is still
a feasible task.

One may also consider extra dimensional models. These too could be
implemented in Effective . One would have to implement a mechanism for
producing a four dimensional effective Lagrangian from the input
(groups, fields, superpotential, plus any extra interactions) but this
too would be a feasible task. It may be that an implementation such as
this could only be done for a specific type of compactification scheme.
But would still be useful for studying both SUSY and non-SUSY models
derived from an effective four dimensional Lagrangian.

Another extremely useful extension that would be desirable is
implementing a method of deriving the Feynman rules from the Lagrangian.
All of the elements are in place to do such a task but would require
quite a lot of work. These rules could be output in a format suitable
for reading into an matrix element generator, like FormCalc, or one
could even implement a matrix element generator as another extension of
Effective . This would be a very complicated project, however.

Effective in its current form can mainly be used to study the mass
spectrum of a model once the VEVs that minimize the effective potential
are determined. This mass spectrum depends on the input parameter set
which can be given at several scales and the RGEs of the model can be
used to match them at the scale the mass spectrum is desired at. Future
extensions of the software would allow this mass spectrum to be used in
calculations of cross-sections and other properties. More substantial
extensions could allow the software to be used on @xmath SUSY and extra
dimensional models. Finally the development of Feynman rules for a model
could be implemented with an eye towards use in matrix element
generators.

## Conclusion

This thesis has presented two new software packages, Herwig++ and
Effective . Herwig++ is a Monte Carlo event generator. In its current
state, this generator is able to generate @xmath -annihilation events.
Chapter 2 has developed a new set of variables for the parton shower and
chapter 3 has presented an improved hadronization model. A full
discussion of the implementation specific features of Herwig++ have been
given in chapter 4 . Results of the new models and the package as a
whole have been shown in chapter 5 . These results give us great
confidence that the new shower and hadronization are a better
description of the physics.

Currently, we are working on Herwig++ to generate initial-state showers.
This will enable us to describe hadron-hadron and lepton-hadron events.
The aim is to have this fully functional for use with Tevatron and LHC
studies. Once the initial-state shower is fully functional a new
underlying event model can be implemented as well as improving the
hadronic decays. Work is already underway to include spin correlations
into the shower and decays. New matrix elements for various processes
can be implemented and SUSY particles and processes can be included. As
the history of HERWIG has shown, there will continue to be a lot of
potential for future research in Herwig++ .

Effective is a model building program. This program has been designed to
work with @xmath SUSY models but future extensions could move it beyond
just these models. This program automates the process of determining the
mass spectrum of a model for a given parameter set. The mass spectrum
generated with Effective can be read into Herwig++ to define the masses
of the supersymmetric particles in Herwig++ . This would provide an
automated way of studying SUSY at colliders over a range of parameters.
Currently, only special purpose programs, like SOFTSUSY [ 116 ] , are
able to do something similar. Future extensions of Effective may provide
more functionality and make it an extremely powerful and useful tool for
studying models.

## Appendix A Herwig++

This appendix contains a few relevant issues pertaining to the use and
future development of Herwig++ . I first give an example analysis
program to count the number of @xmath in an event. Following that is a
brief discussion of how to change the parameters in Herwig++ . Finally,
I give the skeleton structure of how one would implement one’s own
matrix element.

### a.1 Counting Pions

This section provides a description of the functions needed to run a
simple Herwig++ program. The program given here will simply count the
number of neutral pions in the final state.

Herwig++ can be run inside an exception handling clause. In C++ this is
the statement
try { ...your code here ...}
catch(...) { // do something with the exception }
Herwig++ and ThePEG will throw exceptions to explain why the program has
terminated. If these aren’t caught the message associated with the end
of the program won’t be known and the reason for the termination will
remain a mystery. Therefore, the main program to run Herwig++ will be
enclosed in such a statement and the message from the exception will be
printed. The exact form we use is
try { ...generate events/analyze ...}
catch(std::exception & e) {
cerr << e.what() << endl;
return 1;
} catch(...) {
cerr << "Unknown exception @xmath n";
return 2;
}

We now move on to discussing what is put in the “generate
events/analyze” section. A helper class HerwigRun has been developed for
Herwig++ . This class takes the command line arguments ( int argc, char
**argv ) and sets up Herwig++ to either initialize, read or run. These
different stages are discussed in the next section. The command to
create a HerwigRun class is
Herwig::HerwigRun hw(argc,argv);
Once this class is created generating an event is straightforward. We
first must check the status of the program, given by the functions
isRunMode() and preparedToRun() . We can then iterate over the number of
events to generate given by the function getN() . To generate an event
we simply call generateEvent() . The code to do all of this is
if (hw.isRunMode() && hw.preparedToRun()) {
for(int i = 0; i<hw.getN(); i++) {
hw.generateEvent();

At this point we have now generated an event. This is where the analysis
code must be implemented. The HerwigRun class also offers a function to
retrieve the particles from the last event generated. ThePEG::tPVector
getFinalState(int i) is this function. If i is not given (e.g.
getFinalState() ) then the final state particles of the event are
returned. If the i argument is given this function returns the particles
in the final state given by the step i .

Returning to our example of counting the number of @xmath particles in
the final state we pass the vector of final state particles to a
counting function which we define, int countPions(ThePEG::tPVector
particles) . This function is fairly straightforward and is given by
int countPions(ThePEG::tPVector particles) {
ThePEG::tPVector::iterator it;
int count = 0;
for(it=particles.begin(); it!=particles.end(); it++) {
if((*it)->id() == ThePEG::ParticleID::pi0) count++;
}
return count;
}

This function has relied on the class ThePEG::Particle which defines
several functions of the particle. Here we have used the long id()
function to determine the PDG code of the particle. There are many more
functions that would be useful for analysis. The user is encouraged to
read the documentation of the Particle class for more details.

The HerwigRun class also defines functions which return some of the
elements from ThePEG . These are things like the Step or the
CollisionHandler from which the user is able to obtain all the
information of the event.

### a.2 Repository

The repository is a feature of ThePEG that allows the parameters of the
program to be changed without having to recompile the code. These
parameter files can then be exchanged within collaborations to ensure
that researchers are working with the same parameters.

The repository can be thought of as the input files to Herwig++ . These
are written in a human readable form, though the repository has a simple
syntax of its own. The input files can then be saved in machine readable
form for faster access on subsequent runs. In Herwig++ there is a
default input file, HerwigDefaults.in . This sets up all the relevant
objects and instructs the program to allocate memory for the various
parts of the event generator. This initial setup can be saved in a
machine readable file, HerwigDefaults.rpo . The HerwigRun class reads in
the command line argument init . This instructs the class to create the
.rpo from the .in file. HerwigDefaults.in also reads Shower.in ,
Hadronization.in and Decays.in as well as the particles in
ThePEGParticles.in and HerwigParticles.in and the decay modes from
HwDecays.in .

The HerwigDefaults.in currently defines two types of generators. One for
LHC-like events and another for LEP-like events. These two generators
can then have their parameters changed (such as c.m. energy or various
cuts) by editing the files LHC.in or LEP.in , respectively. These
modifications are read in by the read command line argument. This reads
in the appropriate .in file and produces a .run file. The .run is
checked to ensure that all the relevant objects and links have been set
so that the event generator can run.

The last stage is to actually run some events. Using the command line
argument run reads in the appropriate .run file and generates events.
There is a parameter NumberOfEvents in each generator object that sets
the maximum number of events to run. The HerwigRun class provides for a
new number of events to be given at runtime. This number must be less
than or equal to the parameter given to the NumberOfEvents field. To
instruct the program to use a new number simply use the command line
argument -N # when starting the program.

To summarize there are three ways in which a program that uses a
HerwigRun class can by used. These are given as
Program_name init
Program_name read Generator_file.in
Program_name run Generator_file.run -N #
There are more commands that can be given in the command line but these
mostly change some of the lower level instructions. The full set of
commands is
Program_name init|read|run [-N num-events] [-seed random-generator-seed]
[-d debug-level] [-dHw herwig-debug-level] [-l load-path] [-L
first-load-path] [-r repo-file] [-i initialization file] [run-file]

To change the value of a parameter you find the line in the input file
that this is governed by. For example if we wanted to turn the
initial-state radiation off we would look in the Shower.in file. This
file has the line
set theSplittingGenerator:OnOffISRMode 1
If we simply edit this file and change the 1 into a 0 this will turn the
initial-state radiation off. Most of the commands are straightforward
like this. There are other commands in the repository than set . A
relevant subset is create,set,mkdir,cd,library . The create command is
used to define a new object given by a class. The set command is used to
change one of the parameters of that object. The repository is
structured like a file system. You can create the objects you want in
directories in order to keep things ordered. The mkdir command creates a
new directory and the cd command changes to the given directory. The
last command is the library command. This is used to dynamically load a
library. This must be done to define objects that are in a library that
hasn’t been loaded yet. For example, if we want to define an
AmegicInterface object we would have to load the libHwAmegic.so library
first.

### a.3 Matrix Element Development

In this last section I show how a user would implement their own matrix
element. The class MEBase defines the lowest level of matrix element
abstraction. To implement a matrix element one must at least inherit
this class and define the functions
unsigned int orderInAlphaS() const
unsigned int orderInAlphaEW() const
double me2() const
Energy2 scale() const
generateKinematics(const double r)
CrossSection dSigHatDR() const
void getDiagrams() const
Selector<const ColourLines*> colourGeometries(tcDiagPtr diag) const
This list looks quite daunting. ThePEG has already generated these
functions for special types of matrix elements. For example the class
ME2to2Base as able to define the generateKinematics() , dSigHatDR() as
well as the scale() for all @xmath processes. A further subclass
ME2to2QCD defines orderInAlphaS() and orderInAlphaEW() functions as well
as providing routines for general functions like determining the number
of active flavours at a given scale.

If we take an example to inherit the ME2to2QCD class this means we only
need to define the functions
double me2() const
void getDiagrams() const
Selector<const ColourLines*> colourGeometries(tcDiagPtr diag) const

The function double me2() const is self explanatory. This is just the
value of the matrix element for the set of currently generated points.
To access the set of points there is a function meMomenta() which
returns a vector of Lorentz5Momentum objects. This vector contains the
momentum generated for all the incoming and outgoing particles.

The getDiagrams() const class is used to indicate to the matrix element
what are the diagrams used to produce the matrix element (squared).
There is a function add(DiagPtr) which adds a diagram to the list. There
is a helper method defined to define a diagram. For example
new_ptr((Tree2toNDiagram(2), q, qb, 1, gamma, 3, l, 3, lb, -1))
define a @xmath process where the q and the qb are the incoming
particles. The 1 indicates that the gamma particle is the child of the
first incoming particle. The 3,l,3,lb series indicates that both the l
and lb particles are the children of the gamma particle. The last
argument of -1 indicates that this is the end of the diagram definition.
This is a flag that must be negative but can have different values. The
different values are used to determine the different types of diagrams.
If one wanted to weight the different diagrams they would need to
overload the Selector< DiagramIndex> diagrams(const DiagramVector &)
const function. In this function one can iterate over the diagrams and
add them into the Selector object with a weight. When a diagram is
selected the weights are taken into account.

The last function that must be implemented is the Selector<const
ColourLines *> colourGeometries(tcDiagPtr diag) const function. This
function allows you to set the different colour connections. These can
also be given a weight which the particular colour connection
implemented is chosen from.

Having implemented all of these functions the matrix element is defined
and can be used in Herwig++ . The typical place to use the matrix
element is in the hard subprocess. It is possible to use a matrix
element in other processes, such as in the decays, but that requires
more development and working with the code on a lower level.

## Appendix B Effective

This appendix is devoted to coding issues of Effective . I give here an
example of coding the MSSM model in Effective and how one can use the
model to get the mass of the neutralinos. I also show how to evolve the
RGEs to provide the scale dependence of the parameters. At the end I
give a skeleton outline of how one would implement one’s own groups and
diagrams.

### b.1 Mssm

The main driver of Effective is the class Model . This class is what
directs all the calculations and provides all the components. This class
that must be inherited to implement ones own model. The methods that
need to be defined are
void createGaugeGroups()
void createGaugeFields()
void createMatterFields()
void addOtherTerms()
ex superPotential()

The createGaugeGroups() function specifies what groups are used in the
model. For example in MSSM and the SM we have only the @xmath , @xmath
and @xmath groups. These can be implemented via the function

    void MSSM::createGaugeGroups() {
      addGaugeGroup(new U1Group("U1", "{g’}", this, U1Y));
      addGaugeGroup(new SU2Group("SU2", "{g_W}", this, SU2w));
      addGaugeGroup(new SU3Group("SU3", "{g_3}", this, SU3c));
    }

The objects U1Y , SU2w and SU3c are all integers that define the ‘line’
of the group. The two strings for each group define the name of the
group coupling in the standard text output and the LaTeX output,
respectively. The groups can then be accessed at a later point using the
standard text string (e.g. getGroup("U1") ).

The next function that needs to be implemented is createGaugeFields() .
This function defines the fields that mediate the interactions. In the
MSSM these are the superpartners @xmath , @xmath and @xmath . These are
given by

    void MSSM::createGaugeFields() {
      addField("B",new GaugeField("B","B",Utils::LorentzVector,
                                  getGaugeGroup("U1")));
      addField("Bino",new GaugeField("Bino","\\tilde{B}",Utils::WeylSpinor,
                                  getGaugeGroup("U1"),getGaugeField("B")));
      addField("W",new GaugeField("W","W",Utils::LorentzVector,
                                  getGaugeGroup("SU2")));
      addField("Wino",new GaugeField("Wino","\\tilde{W}",Utils::WeylSpinor,
                                  getGaugeGroup("SU2"),getGaugeField("W")));
      addField("gluon",new GaugeField("A","A",Utils::LorentzVector,
                                  getGaugeGroup("SU3")));
      addField("gluino",new GaugeField("Aino","\\tilde{A}",Utils::WeylSpinor,
                                  getGaugeGroup("SU3"),getGaugeField("gluon")));
    }

The addField() function takes a string as an index for the field and a
pointer to a field. This same function is used to add the MatterField s.
Creating a GaugeField requires two strings. Again the first is the text
output string and the second is the LaTeX output. These strings are
followed by the spin of the particle. This is actually the @xmath
factor. This has been conveniently defined in the class Utils for the
scalar, fermion and vector spin types. The spin is then followed by a
pointer to the gauge group that the field is the mediator of. The last
argument, which is optional, is the SUSY partner of the field. We can
see above that the SUSY partner is set for the fermion but not the
vector. This is because one field must be created first. Once created
the partner can be set. Setting it in the creation of the fermion also
sets it in the vector, so this syntax sets both partners to each other
with only one reference to a partner.

After the addGaugeFields function is defined we implement the
addMatterFields function. This function sets all of the remaining fields
in the model. Again looking at our example from MSSM we can write the
function as

    void MSSM::createMatterFields() {
      numeric half(1,2);
      numeric sixth(1,6);
      numeric third(1,3);
      numeric twothirds(2,3);
      // Adding leptons/sleptons
      addField("leptonL",new MatterField("L","\\ell",Utils::WeylSpinor,famsize,
                                         getGaugeGroup("U1"),-half,
                                         getGaugeGroup("SU2"),1));
      addField("sleptonL",new MatterField("sL","\\tilde{\\ell}",
                                          Utils::Scalar,famsize,
                                          getGaugeGroup("U1"),-half,
                                          getGaugeGroup("SU2"),1,
                                          getMatterField("leptonL")));

      addField("leptonR",new MatterField("eR","e_R",Utils::WeylSpinor,famsize,
                                         getGaugeGroup("U1"),-1));
      addField("sleptonR",new MatterField("seR","\\tilde{e_R}",
                                          Utils::Scalar,famsize,
                                          getGaugeGroup("U1"),-1,
                                          getMatterField("leptonR")));

      // Adding quarks and squarks
      addField("quarkL",new MatterField("Q","Q",Utils::WeylSpinor,famsize,
                                        getGaugeGroup("U1"),sixth,
                                        getGaugeGroup("SU2"),1,
                                        getGaugeGroup("SU3"),1));
      addField("squarkL",new MatterField("sQ","\\tilde{Q}",
                                         Utils::Scalar,famsize,
                                         getGaugeGroup("U1"),sixth,
                                         getGaugeGroup("SU2"),1,
                                         getGaugeGroup("SU3"),1,
                                         getMatterField("quarkL")));

      addField("uR",new MatterField("uR","u_R",Utils::WeylSpinor,famsize,
                                    getGaugeGroup("U1"),twothirds,
                                    getGaugeGroup("SU3"),1));
      addField("suR",new MatterField("suR","\\tilde{u_R}",Utils::Scalar,famsize,
                                     getGaugeGroup("U1"),twothirds,
                                     getGaugeGroup("SU3"),1,
                                     getMatterField("uR")));

      addField("dR",new MatterField("dR","d_R",Utils::WeylSpinor,famsize,
                                    getGaugeGroup("U1"),-third,
                                    getGaugeGroup("SU3"),1));
      addField("sdR",new MatterField("sdR","\\tilde{d_R}",Utils::Scalar,famsize,
                                    getGaugeGroup("U1"),-third,
                                    getGaugeGroup("SU3"),1,
                                    getMatterField("dR")));

      // Higgs fields 1 is upper, 2 is lower
      addField("H1", new MatterField("H1","{H^1}",Utils::Scalar,1,
                                     getGaugeGroup("U1"),-half,
                                     getGaugeGroup("SU2"),1));
      addField("sH1", new MatterField("sH1","\\tilde{H^1}",Utils::WeylSpinor,1,
                                      getGaugeGroup("U1"),-half,
                                      getGaugeGroup("SU2"),1,
                                      getMatterField("H1")));

      addField("H2", new MatterField("H2","{H^2}",Utils::Scalar,1,
                                     getGaugeGroup("U1"),half,
                                     getGaugeGroup("SU2"),1));
      addField("sH2", new MatterField("H2","\\tilde{H^2}",Utils::WeylSpinor,1,
                                      getGaugeGroup("U1"),half,
                                      getGaugeGroup("SU2"),1,
                                      getMatterField("H2")));
      // Now add higgs Vev
      Parameter upsilon1 = addParameter("HiggsVev1","\\upsilon_1",220.0,
                                        Parameter::vev);
      Parameter upsilon2 = addParameter("HiggsVev2","\\upsilon_2",220.0,
                                        Parameter::vev);
      addVev("HiggsVev1",getField("H1"), lst(getIndex("H1","SU2")==1),
             (upsilon1+Model::star));
      addVev("HiggsVev2",getField("H2"), lst(getIndex("H2","SU2")==2),
             (upsilon2+Model::star));
      addVevParameter(upsilon1);
      addVevParameter(upsilon2);

The meaning of this code is easy to see. Again we see the last
(optional) argument in creating a MatterField is the superpartner. We
can see now that there are some new arguments to these fields though.
There is a famsize argument. This is an integer which defines how many
generations the field has. For example in MSSM we would set famsize to
3. Lastly we see that after each gauge group is a number. This is the
‘charge’ of the group. Most groups just have a charge of 1. The @xmath
does not, however. This has fractional charges. The class numeric is one
from GiNaC which defines rational numbers, without rounding errors.
These expressions will be printed in LaTeX as they are (e.g. half =
@xmath ).

In the last part of the code we see that we have created the VEVs. The
class Parameter is used in Effective to represent all of the parameters
of the model. The Parameter class is printed out in symbolic form during
printing but is evaluated to its value during calls to evalf() . The
object Model::star is a placeholder which is where the relevant field is
placed. If we wanted to also add an imaginary VEV would could use a
similar syntax imagVEV+Model::star and in this instance Model::star is
the imaginary part of the field.

As discussed in the text the parameters could be added in a different
way. If we wanted to work with @xmath and @xmath rather than @xmath and
@xmath we could have used the code

    Parameter upsilon = addParameter("HiggsVev","$\backslash\backslash$upsilon",246.0,
                                     Parameter::vev);
    Parameter beta = addParameter("beta","$\backslash\backslash$beta",1.1,
                                  Parameter::vev);
    addVev("HiggsVev1",getField("H1"), lst(getIndex("H1","SU2")==1),
           (upsilon*sin(beta)+Model::star));
    addVev("HiggsVev2",getField("H2"), lst(getIndex("H2","SU2")==2),
           (upsilon*cos(beta)+Model::star));
    addVevParameter(upsilon);
    addVevParameter(beta);

but as discussed in the text, this type of setup will not properly
define the RGEs and the minimization routine may not succeed.

In the MSSM there are many terms which must be added from both the
superpotential and from the soft breaking terms. We won’t give them all
here but instead will present an example of how to add a term. We will
look at how to add the slepton mass term. This is given by

    ex m0LL = addFamilyMatrix("m0LL", "{m^2_L}", famsize);
    vector<idx*> sumIndex;
    idx i = Utils::familyIndex(0,famsize);
    idx j = Utils::familyIndex(1,famsize);
    MatterField *sleptonL = getMatterField("sleptonL");
    ex li = sleptonL->expression();
    ex lj = Utils::conjugate(li);
    lj = lj.subs(sleptonL->familyIndex()==j);
    sumIndex = sleptonL->getIndices();
    sumIndex.push_back(&j);
    ex sleptonLTerm = Utils::real(Utils::sumIndices(m0LL*li*lj,sumIndex));
    add(-sleptonLTerm);

At first this looks quite horrific. But once the different parts are
explained it is obvious what everything means. The first term is used to
define the slepton mass term. Since there are three slepton generations
the mass-squared coupling must be defined as a @xmath matrix of
parameters. The addFamilyMatrix() function provides this. This function
creates a matrix whose elements are parameters. The parameters are
created with the indices appended to the name (e.g. the @xmath element
is given by the parameter m0LL11 ). When the matrix is created it is
created as an identity matrix.

The next line defines a vector in which all the indices which are summed
over are placed. This is followed by defining two family indices. By
default the FamilyMatrix class uses the first two indices from the
Utils::familyIndex() function. The Utils class defines some universal
symbols for different indices. A call to the familyIndex function
returns one of the symbols (given by the first integer) as an index
where the dimension of the index is given by the second argument (e.g.
the number of families). As a note, there is a integer
Utils::max_indices which defines how many symbolic indices are
available.

The definition of the two family indices, i and j , is followed by a
retrieval of the MatterField pointer to the slepton. If we refer back to
our definition of the slepton field we can see that the first string is
“slepton”. This is the tag that is used to retrieve the field at a later
time. There is also a function getGaugeField which behaves in a similar
manner, only it returns a GaugeField pointer. After the retrieval of the
slepton pointer we now get the expression of the slepton. As Effective
seperates the real and imaginary parts of the scalars and fermions, the
expression is @xmath . Also the function expression returns the fields
with each index attached. For example a left-handed quark would have its
family index as well as the @xmath and @xmath indices added. A vector
also has a LorentzIndex attached. The function Utils::conjugate then
replaces all @xmath ’s with @xmath . The default family index of a field
is taken from Utils::familyIndex(0,famsize) . Since we want to contract
the family indices of the mass-squared coupling we must replace this
index with Utils::familyIndex(1,famsize) in the conjugate expression.
This is done via the subs() command. This command takes two forms. The
first is to use the == sign. This sets the argument on the left to be
replaced by the argument on the right. This is useful when making one
substitution. When many substitutions are desired we can instead use the
form subs(lst,lst) . The first lst is replaced by the second. A lst is a
class from GiNaC and is just a sequence of expressions.

After the expression for @xmath and @xmath have been retrieved we want
to contract all the indices and create the expression @xmath . To do
this we store all of the indices given in the slepton into the
sumIndices vector we created earlier. We also realize that this vector
doesn’t contain the extra family index in @xmath , and now in lj , so we
also add the index to the back of the list. Once the sumIndices vector
contains all the indices which we are summing over we can call the
routine Utils::sumIndices(ex,vector<idx*>) . This routine iterates the
list of indices over all permutations and evaluates the ex at each set
of index values. The sum of all these permutations and evaluations is
returned. The last command on this line is the Utils::real . This
returns all the parts of the expression that are not multiplied by
@xmath . In this example we shouldn’t need to call this command as
@xmath should be a real quantity. It is also worth noting that instead
of coding an expression as exp + c.c. it is easier and faster to write
2*Utils::real() .

In the end we call the add() function. This adds the expression to the
Lagrangian. If we were developing terms of the superpotential we would
instead sum all the contributions from all the terms and return it. We
don’t want to call the add() routine with the superpotential.

### b.2 Plotting Effective Potential and Running Couplings of MSSM

Once we have developed the class MSSM with all the relevant groups,
fields and terms, we can work with this program. The following code is
used to create the model and initialize it

    MSSM mssm;
    Model::readCommandLine(argc,argv,&mssm);
    mssm.couplings("mssm.gar");
    mssm.initialize();

The first line creates an MSSM object. The second line calls a static
function from the Model class which reads in standard command line
arguments and sets the relevant parameters of the model. The possible
arguments are

    -p # - Sets the evaluation of the effective potential to tree-level (0)
           or one-loop (1)
    -t # - Sets the evaluation of the tadpoles to tree-level (0) or
           one-loop (1)
    -a # - sets the evaluation of the mass matrices to tree-level (0) or
           one-loop (1)
    -r   - Rederives the couplings from scratch
    -s   - Saves the couplings to the file provided
    -h   - Prints a help message

The third line of code provides the model with a file to read the
couplings in from and save to, depending on what the program has been
specified to do. The last line initializes the model. This means
generate (or read) the couplings, find all the tree level mass matrices
and generate the RGEs. At this stage the model is able to be used.

At this point we will want to read our parameters in from a file. This
is done by the loadParameters() function. The code that would read the
parameters from the file MSSM.dat is

    ifstream parin;
    parin.open("MSSM.dat");
    mssm.loadParameters(parin);
    parin.close();

This file has a simple structure. It is tab delimited where the first
entry is the name of the parameter (the text name given during its
definition) and the value of the parameter. There is also a parameter
defined for every model. This is renormScale and defines the current
renormalization scale. It is defaulted to 91.2 GeV (the @xmath mass) and
when a parameter is read in it is assumed to be entered at the scale
currently given by renormScale . So if one wanted to input parameter a
at 91.2 GeV but parameter b at 200 GeV they would use

    aΨ50.0
    renormScaleΨ200.0
    bΨ20.0

Once the parameters have been read in one may want to evolve the RGEs to
a scale. At first the boundary conditions must be determined at one
scale. This is done by calling mssm.rges().matchScales() . This routine
goes through the boundary conditions entered and uses the Newton-Raphson
method to find a suitable set of parameters that match all the boundary
conditions given. Once that is done the parameters can be evolved to the
scale desired by calling mssm.rges().evolve(scale) .

Once the parameters have been determined at the scale desired the mass
spectrum can be developed. This is done with a call to
mssm.masses().diagonalize() . This will diagonalize all the mass
matrices at either tree-level or one-loop. There is an additional flag,
Model::CorrectMassStates which determines whether the one-loop
corrections are applied directly to the mass eigenstates derived from
the tree-level mass matrices, or if the one-loop corrections are applied
based on the interaction eigenstates. If one wanted to get the mass of a
particle they simply call mssm.masses().massOf(field) where field is the
expression with all the indices evaluated (e.g. instead of looking at
the top quark mass, one would have to look at the left-handed quark,
with @xmath index = 1, family index = 3 and the @xmath index set to any
number between 1 and 3). In the SM, for example, one would fully expect
to find that the mass all of the colour indices of a particular quark
are the same. But it would be possible to develop a theory where this is
not the case.

The last function that would be desired is to find the effective
potential. This can be given as an analytic expression by a call to
mssm.treePotential() or at one-loop order by a call to mssm.potential()
(with the correct value of Model::_potApprox set). Using this we can use
the code

    ofstream potPlot;
    potPlot.open("MSSM_Pot.dat");
    double v1, v2;
    ex pot = mssm.treePotential();
    double v = 246.0;
    double beta;

    for(beta = -3.14; beta < 3.14; beta += 0.01) {
      mssm.getParameter("HiggsVev1") = v*cos(beta);
      mssm.getParameter("HiggsVev2") = v*sin(beta);
      potPlot << beta << "\t" << pot.evalf() << endl;
    }
    potPlot.close();

to generate fig. 6.7 .

### b.3 Entering a New Group

When studying models different symmetries are desired. These are given
by the group governing the interaction. Effective provides a way in
which a new group can be defined. Inheriting the class GaugeGroup is how
this is done. This class requires the user to implement

    constructor(string n, string cn, Model* m, char l);
    ex structureConstant(GaugeIndex&, GaugeIndex&, GaugeIndex&) const;
    ex generator(GaugeIndex&, MatterIndex&, MatterIndex&) const;
    GaugeIndex gaugeIndex(int i=0) const;
    MatterIndex matterIndex(int i=0) const;
    bool isIndex() const;
    ex Cr(bool) const;
    ex C2(bool) const;

The constructor defines the coupling (given by the text name n and the
LaTeX name cn ). The char l is used to define the line of the group. A
constructor is generally of the form ClassName(n,cn,m,l) :
GaugeGroup(n,cn,m,l){} . This just passes all the handling of these
arguments to the GaugeGroup superclass. The functions C2(bool) and
Cr(bool) are used to give the evalation of @xmath and @xmath . If the
boolean passed in is true then the adjoint representation is used. If it
is false then the fundamental representation is used.

Next one must define the indices. This usually amounts to defining a set
of symbols for the adjoint and fundamental indices. The indices are then
just idx classes with the symbol and the correct dimension set. The last
remaining pieces are the structure constants and generators, given by
structureConstant and generator . These require the definition of a
tensor class from GiNaC . An example of an @xmath structure constant is
given here. The definition of the tensor is

    class SU3Structure : public tensor {
      GINAC_DECLARE_REGISTERED_CLASS(SU3Structure,tensor)

     public:
      void print(const print_context &c, unsigned level = 0) const;
      ex eval_indexed(const basic &i) const;
    };

One can then define a helper function SU3_structure which returns the
expression for the structure constant given the indices. This takes the
form

    inline ex SU3_structure(const ex &i1, const ex &i2, const ex &i3) {
      if(!is_a<GaugeIndex>(i1) || !is_a<GaugeIndex>(i2) ||
         !is_a<GaugeIndex>(i3))
        throw(std::invalid_argument(
              "Indices to SU(3) structure must be of type GaugeIndex"));

      if(ex_to<GaugeIndex>(i2).line() !=
         ex_to<GaugeIndex>(i3).line())
        throw(std::invalid_argument(
              "GaugeIndices must be of the same line and type"));

      return indexed(SU3Structure(), sy_anti(), i1, i2, i3);
    }

The structure constant can then be defined by

    GINAC_IMPLEMENT_REGISTERED_CLASS(SU3Structure,tensor)
    DEFAULT_CTORS(SU3Structure)
    DEFAULT_ARCHIVING(SU3Structure)
    DEFAULT_COMPARE(SU3Structure)

and the print and eval_indexed functions are

    void SU3Structure::print(const print_context & c, unsigned level) const {
      if (is_a<print_tree>(c)) inherited::print(c, level);
      else {
        ostream& os = c.s;
        os << "f";
      }
    }

    ex SU3Structure::eval_indexed(const basic &i) const {
      GINAC_ASSERT(is_a<indexed>(i));
      GINAC_ASSERT(i.nops() == 4);
      GINAC_ASSERT(is_a<SU3Structure>(i.op(0)));
      GINAC_ASSERT(is_a<GaugeIndex>(i.op(1)));
      GINAC_ASSERT(is_a<GaugeIndex>(i.op(2)));
      GINAC_ASSERT(is_a<GaugeIndex>(i.op(3)));

      const GaugeIndex& g1 = ex_to<GaugeIndex>(i.op(1));
      const GaugeIndex& g2 = ex_to<GaugeIndex>(i.op(2));
      const GaugeIndex& g3 = ex_to<GaugeIndex>(i.op(3));

      // Numeric Evaluation
      if(static_cast<const indexed &>(i).all_index_values_are(info_flags::integer))
      {
        int i = ex_to<numeric>(g1.get_value()).to_int();
        int j = ex_to<numeric>(g2.get_value()).to_int();
        int k = ex_to<numeric>(g3.get_value()).to_int();
        int ip = i; int jp = j; int kp = k;
        if(ip>jp) Utils::swap(ip,jp);
        if(jp>kp) Utils::swap(jp,kp);
        if(ip>jp) Utils::swap(ip,jp);
        static ex half = numeric(1,2);
        double cyc = Utils::cyclicPermutation(i,j,k);
        if(ip==1) {
          if(jp==2 && kp==3) return cyc;
          else if(jp==4 && kp==7) return half*cyc;
          else if(jp==5 && kp==6) return -half*cyc;
        } else if(ip==2) {
          if(jp==4 && kp==6) return half*cyc;
          else if(jp==5 && kp==7) return half*cyc;
        } else if(ip==3) {
          if(jp==4 && kp==5) return half*cyc;
          else if(jp==6 && kp==7) return -half*cyc;
        } else if(ip==4 && jp==5 && kp==8) return sqrt(numeric(3,4))*cyc;
        else if(ip==6 && jp==7 && kp==8) return sqrt(numeric(3,4))*cyc;
        return 0;
      }
      // No further simplification
      return i.hold();
    }

This then completely defines the behaviour of the structure constants of
the group. A similar thing can be done for the generators.

### b.4 Defining a Diagram

Defining a diagram is a useful way to do computations with Effective .
This is also straightforward. One simply inherits the Diagram class and
implements the constructor

    MyNewDiagram(DElementVec &v, Model *m) : Diagram(v,m) {}

and the function() function. This function is used to evaluate the
diagram at the current set of fields. The DElementVec is used to specify
a set of fields for each external leg and propagator of the diagram.
When the diagram is created the desired choice of fields for each part
is given. For example we want to compute the cross section for @xmath at
tree-level. We simply create some DiagramElements and put the
appropriate fields in.

    DElementVec eeqq(4);
    exvector electrons, quarks;
    electrons.push_back(real_left_electron);
    electrons.push_back(imag_left_electron);
    electrons.push_back(real_right_electron);
    ...
    eeqq[0] = DiagramElement(electrons, true);
    eeqq[1] = DiagramElement(electrons, true);
    eeqq[2] = DiagramElement(quarks, true);
    eeqq[3] = DiagramElement(quarks, true);

This creates the DElementVec object with all the electrons and all the
quarks. This then gets given as input to the diagram ee2qq

    ee2qq myee2qq(eeqq,my_model);
    cout << "My matrix element is " << myee2qq.evaluate() << endl;

The evaluate function goes over every permutation of the fields given in
the four DiagramElement s and computes a contribution to the matrix
element. This contribution is given by the function function. This must
be defined so that each combination of fields contributes the relevant
part. This is done by determining the couplings of the set of fields
given. For example

    ex coup123 = coupling(0,1,2);
    ex coup234 = coupling(1,2,3);
    ex coup134 = coupling(0,2,3);
    ex coup1234 = coupling(0,1,2,3);

The true statement in the definition of the DiagramElement indicates
that the mass state couplings are to be used. If it were false the
interaction couplings would be used.