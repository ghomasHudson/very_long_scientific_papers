###### Contents

-    Notation and list of symbols
-    1 Introduction
    -    1.1 Cryptography
    -    1.2 Quantum information theory
    -    1.3 Quantum cryptography
    -    1.4 Outline
-    2 Preliminaries
    -    2.1 Notation and miscellaneous lemmas
        -    2.1.1 Strings of bits
        -    2.1.2 Cauchy-Schwarz inequality for probabilities
        -    2.1.3 Chernoff bound for the binomial distribution
    -    2.2 Quantum mechanics
        -    2.2.1 Linear algebra
        -    2.2.2 Quantum formalism
        -    2.2.3 Remote state preparation
    -    2.3 Multiplayer games
        -    2.3.1 Classical and quantum strategies
        -    2.3.2 Finite fields
        -    2.3.3 Definition of the game
        -    2.3.4 Relation to multivariate polynomials over finite
            fields
        -    2.3.5 A recursive upper bound on the classical value
    -    2.4 Cryptographic protocols and implementations
    -    2.5 Bit commitment
        -    2.5.1 Formal definition
        -    2.5.2 The Mayers-Lo-Chau impossibility result
-    3 Non-communicating models
    -    3.1 Interactive proof systems
    -    3.2 Applications in cryptography
    -    3.3 Commitment schemes
-    4 Relativistic protocols
    -    4.1 Non-communicating schemes in the relativistic setting
    -    4.2 Explicit analysis of relativistic protocols
        -    4.2.1 Classical players
        -    4.2.2 Quantum players
        -    4.2.3 Quantum relativistic protocols
    -    4.3 Limitations of relativistic cryptography
-    5 Bit commitment by transmitting measurement outcomes
    -    5.1 The original protocol
        -    5.1.1 Correctness
        -    5.1.2 Security for honest Alice
        -    5.1.3 Security for honest Bob
    -    5.2 Modelling imperfect devices
    -    5.3 Protocol with backreporting
        -    5.3.1 Correctness
        -    5.3.2 Security for honest Alice
        -    5.3.3 Security for honest Bob
        -    5.3.4 Requirements on the honest devices
        -    5.3.5 Explicit security calculation
    -    5.4 Experimental implementation
-    6 Multiround relativistic bit commitment protocol
    -    6.1 Two-round protocol
    -    6.2 Multiround protocol
        -    6.2.1 Security for honest Alice
        -    6.2.2 Security for honest Bob
    -    6.3 Experimental implementation
-    7 Conclusions
-    A Classical certification of relativistic bit commitment
    -    A.1 Classical certification of the sBGKW scheme
    -    A.2 Consequences for the canonical construction

## Notation and list of symbols

  Symbol   Meaning
  -------- ----------------------------------------------------------
  @xmath   set of integers from @xmath to @xmath
  @xmath   cardinality of a set or modulus of a number
  @xmath   a Hilbert space
  @xmath   dimension of @xmath
  @xmath   dual space of @xmath
  @xmath   linear operators acting on @xmath
  @xmath   Hermitian operators acting on @xmath
  @xmath   identity matrix
  @xmath   complex conjugate of @xmath
  @xmath   transpose of @xmath (with respect to the standard basis)
  @xmath   Hermitian conjugate of @xmath
  @xmath   pure quantum states
  @xmath   mixed quantum states
  @xmath   maximally entangled state of dimension @xmath
  @xmath   Hadamard matrix
  @xmath   Schatten @xmath -norm
  @xmath   Schatten @xmath -norm
  @xmath   trace
  @xmath   partial trace over @xmath
  @xmath   quantum channel
  @xmath   identity channel
  @xmath   Hamming weight
  @xmath   Hamming distance
  @xmath   exclusive-OR ( XOR )
  @xmath   finite-field multiplication
  @xmath   probability
  @xmath   inner product
  @xmath   finite alphabets
  @xmath   finite field of order @xmath
  @xmath   @xmath player (in a multiplayer game)

## Chapter 1 Introduction

Quantum cryptography lies at the intersection of physics and computer
science. It brings together different communities and makes for a lively
and exciting environment. It demonstrates that the fundamental
principles of quantum physics can be cast and studied using the
operational approach of cryptography. Besides, thanks to recent
technological advances, practical applications are just round the
corner.

Due to the interdisciplinary nature of quantum cryptography the relevant
background knowledge spans multiple fields, which makes it particularly
difficult to provide an introduction which would be both complete and
concise. We have, therefore, chosen to focus on the topics which are
directly related to quantum cryptography and skip over the less relevant
areas.

This chapter starts with a short introduction to cryptography , which is
the study of exchanging and processing information in a secure fashion.
We focus on two-party (or mistrustful ) cryptography, whose goal is to
protect the privacy of an honest party interacting with potentially
dishonest partners. Then, we introduce quantum information theory ,
which studies how quantum systems can be used to store and process
information. We discuss the main features that distinguish it from the
classical information theory and briefly describe the early history of
the field. The next part of this chapter brings the two topics together
under the name of quantum cryptography . We give a brief account of its
early days, again, with a particular focus on two-party cryptography. We
finish by giving a brief outline of this thesis.

### 1.1 Cryptography

Cryptography has been around ever since rulers of ancient tribes
realised the need to send secret (or private) messages. Ideally, such
messages should reveal no information if intercepted by an unauthorised
party. The solution to this problem is known as a cipher , which is
simply a procedure for converting a secret message (called the plaintext
) into another message (called the ciphertext ), which should be
intelligible to a friend (who knows the particular cipher we are using)
but should give no information to an enemy. The first confirmed accounts
of simple ciphers come from ancient Greece and Rome, for example Julius
Caesar used a simple shift cipher (now also known as a Caesar cipher) to
ensure privacy of his correspondence. Until modern times designing
practical (i.e. easy to implement and difficult to break) ciphers was
essentially the only branch of cryptography. One such cipher known as
the one-time pad was invented by Gilbert S. Vernam and Joseph
O. Mauborgne in 1917. ¹ ¹ 1 Note, however, that ideas that the one-time
pad hinges on appeared as early as 1882 in a book by Frank Miller. For
details consult an interesting survey on the state of cryptography at
the turn of the century by Bellovin [ Bel11 ] . While the one-time pad
guarantees (provably) secure communication it requires the two parties
to share a random string of bits, known as a key , which is as long as
the message they want to send. This quickly becomes impractical if the
parties want to exchange large amounts of data.

A report presented by Claude Shannon in 1945 marks the birth of modern
cryptography [ Sha49 ] . ² ² 2 This work, presented in 1945 as a
classified report at Bell Telephone Labs, was declassified and published
in 1949. Shannon proposed a formal definition of a (perfectly) secure
cipher and proved that one-time pad satisfies such a stringent
requirement. Moreover, he proved that any cipher that guarantees perfect
security requires the key to be as long as the message (which
essentially means that the one-time pad cannot be improved). But the
contributions of this work go well beyond encryption and the analysis of
one-time pad, as it was the first time that cryptography was phrased in
the rigorous language of mathematics. This put cryptography on equal
footing with other established sciences and set the stage for
information theory (discovered by Shannon a couple of years later).

Nowadays cryptography is a mature field within which hundreds of
cryptographic tasks (or primitives ) have been defined and studied (and
encryption, while obviously very important, is just one of them). Except
for purely practical reasons for studying these tasks there is also a
deeper motivation. Certain questions in cryptography (e.g. finding
sufficient assumptions to perform a given task or proving impossibility
results) give us valuable and operational insight into the underlying
information theory. While classical information theory is relatively
well understood, its quantum counterpart is not. That is why studying
quantum cryptography is an important pursuit and contributes towards our
understanding of the quantum world we (probably) live in.

In this thesis we only consider a branch of cryptography known as
two-party or mistrustful cryptography, in which two parties, usually
referred to as Alice and Bob, want to perform a certain task together
but since they do not fully trust each other they want to minimise the
amount of information revealed during the protocol. A simple example of
such a scenario is the millionaires’ problem introduced by Andrew Yao [
Yao82 ] , in which two millionaires want to find out who is richer
without revealing their actual wealth. This is certainly an interesting
problem and, in fact, one that we often face in our everyday lives.
Below we present and motivate some other natural two-party tasks.

-    Example 1: Alice uses an online movie service called Bob, which
    charges separately for every downloaded movie. Alice has paid for
    one movie and wants to download it but being paranoid about privacy
    she is reluctant to reveal her choice to Bob. On the other hand, Bob
    wants to make sure that Alice only downloads one movie (and not
    more) so he is not keen on giving her access to the entire database.
    This problem, called oblivious transfer ³ ³ 3 Oblivious transfer
    comes in multiple flavours and the one described above is called
    @xmath -out-of- @xmath oblivious transfer, where @xmath is the total
    number of movies offered by Bob. Since we are only interested in
    fundamental possibility or impossibility results, studying the case
    of @xmath is sufficient (it is known how to interconvert these
    primitives including even more exotic variants like Rabin oblivious
    transfer [ Cré88 ] ). , turns out to be a convenient building block
    for two-party cryptography. In fact, it can be used to construct any
    other two-party primitive [ Kil88 ] .

-    Example 2: Alice has supernatural powers that allow her to predict
    the future, for example the results of tomorrow’s draw of the
    national lottery. She wants to impress Bob (she likes to be admired)
    but she does not want him to get rich (she knows that money does not
    bring happiness). Hence, the goal is to commit to a message without
    actually revealing it until some later time. Such primitives are
    known as commitment schemes [ Blu81 , BCC88 ] ⁴ ⁴ 4 Blum [ Blu81 ]
    only implicitly mentions commitment schemes while Brassard, Chaum
    and Crépeau [ BCC88 ] define them explicitly. See an encyclopedia
    entry on commitment schemes for more details [ Cré11 ] . and the
    simplest one, in which the committed message is just one bit, is
    called bit commitment and constitutes one of the main topics of this
    thesis.

-    Example 3: Alice is a quantum hacker and throughout the years she
    has exposed dozens of improperly formulated security proofs and
    misguided calculations. Having realised the damage done to the
    quantum community she has contacted a law enforcement agency
    represented by Bob to negotiate turning herself in. Alice and Bob
    want to schedule a secret meeting but for obvious security reasons
    they want to make sure that the location is chosen in a truly random
    fashion. In other words, Alice and Bob want to agree on a random
    choice, which neither of them can bias (or predict it in advance).
    This primitive known as coin tossing (or coin flipping ) was
    introduced by Blum [ Blu81 ] .

All these tasks produce conflicting interests between Alice and Bob. It
is clear that security for either party can be ensured at the cost of
leaving the other party completely unprotected. In case of oblivious
transfer, for example, Alice could give up her privacy and simply
announce which movie she wants to watch. Alternatively, Bob could
provide Alice with the entire database, hoping that she will not abuse
his trust.

The goal of two-party cryptography is to first come up with the right
mathematical definition of these primitives and then find in what
circumstances and under what assumptions they can (or cannot) be
implemented. It is also interesting to study reductions between
different primitives, i.e. how to use one primitive to implement another
one, which leads to a resource theory for cryptography. For example,
oblivious transfer can be used to implement commitment schemes because
choosing a particular message can be interpreted as committing to its
label. Commitment schemes, on the other hand, can be used to generate
trusted randomness. For example, in order to generate one trusted bit we
use a commitment scheme with two possible values (such a primitive is
known as bit commitment ). Alice commits to a bit @xmath , then Bob
announces bit @xmath and finally Alice reveals @xmath and the outcome of
the coin toss is declared to be @xmath . As long as at least one of the
parties is honest the resulting bit is uniform. The use of a commitment
scheme ensures that @xmath does not depend on @xmath (which would allow
Bob to cheat).

The holy grail of the field is the so-called information-theoretic
security ⁵ ⁵ 5 Some authors prefer to use the term unconditional
security instead. The name is motivated by the fact that the security
proof assumes nothing about the adversary. However, this has been
criticised as every security model contains assumptions and no security
statement can be proven without referring to them. . There, the basic
assumption is that the dishonest party is restricted by the underlying
information theory, which is arguably the weakest assumption that one
needs to perform security analysis. The term information-theoretic
security goes back to Shannon (e.g. see his definition of secure
encryption [ Sha49 ] ).

Unfortunately, it turns out that two-party primitives cannot be
implemented with information-theoretic security (for both parties)
unless we make some further assumptions. ⁶ ⁶ 6 While the impossibility
is usually intuitive showing it formally requires some effort. As an
example we present an informal argument why oblivious transfer is not
possible with information-theoretic security. Consider the situation at
the end of the protocol. If Bob is not able to deduce which movie Alice
chose to download, it must be the case that the knowledge contained in
the interaction is sufficient to reconstruct at least two different
movies and nothing can stop Alice from doing that. Below we give a brief
overview of various (reasonable) assumptions that make
information-theoretically secure two-party cryptography possible.

-    Trusted third-party : The trivial solution is to introduce a
    trusted third-party, which implements the primitive for Alice and
    Bob. In the paranoid world, in which Alice and Bob trust nobody but
    themselves, this is not a satisfactory solution. Moreover, it makes
    all tasks trivially possible.

-    Pre-shared resources : Another solution that allows for two-party
    cryptography is to equip Alice and Bob with some shared
    correlations. This could be either shared randomness [ Riv99 ] or
    access to a source of inherent and unpredictable noise that allows
    to generate such correlations during the protocol [ Cré97 , WNI03 ]
    . ⁷ ⁷ 7 Even for tasks whose only purpose is to generate trusted
    randomness like coin tossing this is still a non-trivial scenario
    because the correlations initially shared between Alice and Bob
    might be different from the ones we want to generate.

-    Technological limitations : The standard real-world solution to the
    commitment task is for Alice to lock her message in a safe box,
    which she then hands over to Bob while keeping the key. Whenever
    Alice wants to reveal the message, she gives the key to Bob, who
    opens the safe box and reads the message. This is secure as long as
    Alice has no way of remotely modifying the message and Bob has no
    tools to open the safe box, i.e. we must assume that they are
    subject to certain technological limitations. One can also assume
    that their ‘‘digital technology’’ is limited, e.g. by restricting
    their computational power or storage capabilities, which again makes
    secure two-party cryptography possible. The former leads to the rich
    and practically important field of computational security ⁸ ⁸ 8
    Computational security relies on the assumption that the adversary
    cannot solve a certain mathematical problem and let us mention two
    problematic aspects of this assumption. First of all, our belief
    that some mathematical problems are difficult is based mainly on the
    fact that many bright people have tried to solve them and failed (or
    maybe the successful ones prefer to keep a low profile). An
    efficient algorithm for solving such problems might be announced
    tomorrow and render all the currently used cryptographic protocols
    insecure. Secondly, most such schemes are vulnerable to retroactive
    attacks. If a message sent today is required to remain secret for
    the next twenty years, the mathematical problem must resist new
    algorithms and improved computing power that might be developed in
    these twenty years. This is why we would like to ultimately drop
    such assumptions and find more solid foundations for our
    cryptographic systems. , while the latter leads to the bounded
    storage model [ Mau91 ] .

-    Communication constraints : It is well-known that interrogating
    suspects one by one leads to better results than dealing with the
    whole group at the same time. In the cryptographic language this
    corresponds to forcing one (or more) parties to delegate agents, who
    perform certain parts of the protocol without communicating. Such
    setting was originally introduced in complexity theory under the
    name of multiprover models ⁹ ⁹ 9 To avoid confusion we talk about
    multiprover models in the context of complexity theory but use the
    term multiagent in case of cryptographic protocols. to evade certain
    impossibility results [ BGKW88 ] . These models are interesting from
    the cryptographic point of view but we must be explicit how they are
    adjusted to fit the framework of standard two-party cryptography (in
    which there are only two parties interacting and not more). On the
    bright side some types of non-communicating models can (with subtle
    adjustments) be implemented by requiring multiple agents to interact
    simultaneously at multiple locations (under the assumption that the
    speed of light is finite). The first explicit examples of such
    relativistic protocols came from Adrian Kent [ Ken99 , Ken05 ] .
    This field, now known as relativistic cryptography , constitutes the
    main topic of this thesis.

### 1.2 Quantum information theory

As mentioned before the report written by Shannon in 1945 marks the
beginning of modern cryptography [ Sha49 ] . Thinking about encryption
and the one-time pad led him to questions about the nature of
information. Shannon’s next paper investigating fundamental limits of
compression and transmission [ Sha48 ] is considered the beginning of
(classical) information theory , which became an active field of
research with a wide range of practical implications. While the basic
framework of quantum mechanics already existed at the time (introduced
in the 1920s and 30s by Bohr, Born, de Broglie, Dirac, Einstein,
Heisenberg, Planck, Schrödinger and others), rigorous connections
between the two were not established until much later.

In 1935 Einstein, Podolsky and Rosen wrote a paper in which they argue
that quantum mechanics cannot be considered a complete theory [ EPR35 ]
. They postulate that for every measurement whose outcome is certain
there exists an ‘‘element of reality’’ and deduce that due to the
uncertainty principle incompatible observables cannot have simultaneous
elements of reality. On the other hand, they note that in case of
entangled ¹⁰ ¹⁰ 10 The term Verschränkung used “to describe the
correlations between two particles that interact and then separate, as
in the Einstein-Podolsky-Rosen experiment” first appeared in a letter
written by Schrödinger who also proposed the English translation:
entanglement . particles the elements of reality of one system depend on
the measurements performed on the other. Since they perceive the
elements of reality as something objective, independent of any
measurement process, they conclude that the quantum-mechanical
description must be incomplete. This idea was further developed by John
Bell [ Bel64 ] who realised that the assumptions of Einstein, Podolsky
and Rosen boil down to the existence of local hidden variables , which
completely determine the outcome of all possible measurements. Bell
showed that any theory satisfying these requirements (like the classical
theory) is subject to certain restrictions (now known as Bell
inequalities ) and demonstrated that quantum mechanics violates such
restrictions. The first explicit Bell inequality proposed by Clauser,
Horne, Shimony and Holt [ CHSH69 ] is a clear-cut evidence that the set
of quantum correlations is strictly bigger than its classical
counterpart. Realising that quantum mechanics gives rise to an
information theory which is qualitatively different that the classical
version, opened a new, fruitful research direction. Questions concerning
storing or transmitting information using quantum systems have the
appealing feature of being operational and fundamental at the same time.
In the 1970s Holevo proved how many classical bits can be reliably
stored in a quantum system [ Hol73 ] and Helstrom showed how to
optimally distinguish two quantum states [ Hel76 ] .

In 1980 Boris Tsirelson published a breakthrough paper, which exactly
characterises the set of correlations achievable using quantum systems
(in a restricted class of scenarios) [ Tsi80 ] . Another important
result concerning quantum correlations comes from Reinhard Werner, who
showed that entanglement, while necessary, is not a sufficient condition
for observing stronger-than-classical correlations [ Wer89 ] . In 1982
Wootters and Żurek proved the celebrated no-cloning theorem, which
states that given a single copy of an unknown quantum state, there does
not exist a physical procedure that produces two (perfect) copies [ WŻ82
] . While the result itself is rather simple (including the proof), it
has far-reaching consequences and shows that one should be rather
careful when applying the classical intuition to quantum systems. Around
the same time the first ideas to use quantum systems to perform
computation came about. Richard Feynman proposed the concept of quantum
simulation , i.e. using one quantum system to simulate another [ Fey82 ]
while David Deutsch initiated the study of quantum computation by
introducing the concept of a quantum Turing machine and presenting a
simple problem which can be solved more efficiently using quantum
systems [ Deu85 ] . While the problem introduced by Deutsch is of little
practical use, it is important as the first demonstration that quantum
computing is strictly more powerful than its classical counterpart.

In 1994 Peter Shor published a paper that changed the status of quantum
computation from an exercise in linear algebra to a field of potentially
enormous practical impact [ Sho94 ] . Shor proposed an algorithm that
can efficiently factor large numbers and solve the discrete logarithm
problem, which, as a consequence, allows to break all commonly used
public cryptography systems. In 1996 Lov Grover published an algorithm
that gives a quadratic speed-up while searching an unstructured database
[ Gro96 ] . ¹¹ ¹¹ 11 Note that the speed-up of Grover’s algorithm is
provable, i.e. it is quadratically faster than any classical algorithm.
Shor’s algorithm, on the other hand, is exponentially faster than the
best known classical algorithm. These two results sparked enormous
interest as they showed that quantum computation might be important from
the practical point of view. Since then the task of finding new quantum
algorithms and building an actual quantum computer has been a full-time
job of hundreds of computer scientists, physicists and engineers.

It seems fair to say that it is the breakthroughs in quantum computation
that gave the whole field a significant push and encouraged many
brilliant researchers to work on quantum information. Since then the
field has developed rapidly and this includes aspects closely related to
quantum computation like quantum error-correction or quantum computer
architecture but also areas which are not directly relevant like quantum
correlations, quantum foundations, quantum Shannon theory or quantum
cryptography. For more information we refer to a brief survey on early
quantum information written by Bennett and Shor in 1998 [ BS98 ] or to a
book by Nielsen and Chuang [ NC00 ] , which became the primary textbook
in the field (in particular for quantum computation). For a detailed
introduction to the information-theoretic aspects (the quantum Shannon
theory) see Chapter 1 of Mark M. Wilde’s book [ Wil13 ] .

### 1.3 Quantum cryptography

In the late 1960s Stephen Wiesner wrote a paper on how to use quantum
particles of spin- @xmath to produce money that is “physically
impossible to counterfeit”. The paper got rejected from a journal and
ended up in Wiesner’s drawer (the paper was eventually published in ACM
SIGACT News [ Wie83 ] about fifteen years later). These ideas were
further pursued by Bennett, Brassard, Breidbart and Wiesner [ BBBW83 ]
and led to a groundbreaking paper proposing the first quantum key
distribution protocol, which allows two distant parties to communicate
securely through an insecure quantum channel [ BB84 ] . In 1991 Artur
Ekert proposed a quantum key distribution protocol that relied on
entanglement and Bell’s theorem [ Eke91 ] . Another protocol (which
relies on entanglement but not Bell’s theorem) was presented in Ref. [
BBM92 ] and soon the first experimental demonstration of quantum key
distribution was reported together with concrete solutions for the
classical post-processing phase and explicit security estimates [ BBB
@xmath 92 ] . Since then an enormous amount of progress has been made in
both theoretical and practical aspects of quantum key distribution and
it is well beyond the scope of this introduction to discuss it. A recent
article by Ekert and Renner is an excellent account of the current state
of quantum key distribution [ ER14 ] .

Before we go into the details let us state very clearly that throughout
this thesis we work under the (implicit) assumption that Alice and Bob
trust their own devices. In other words, if the protocol requires Alice
to generate a certain quantum state, she is capable of constructing a
device that does just that and she may rest assured that the source does
not accumulate information about the previous uses or leak secret data
through extra degrees of freedom. While this assumption seems natural
and easy to ensure in the classical world, it becomes more of a
challenge in the quantum world simply because our understanding and
expertise in quantum technologies are limited. These considerations gave
rise to the field of device-independent cryptography which aims to
design protocols which remain secure even if executed using faulty or
malicious devices. The fact that such strong security guarantees are
even possible is clearly remarkable and this topic has received a lot of
interest in the last couple of years. Due to a large volume of works on
this topic we do not attempt to list the relevant references and point
the interested reader at comprehensible and accessible lectures notes by
Valerio Scarani [ Sca12 ] as well as Sections IV.C and IV.D of a recent
review on Bell nonlocality [ BCP @xmath 14 ] .

While quantum key distribution was and still remains the predominant
area of research in quantum cryptography, other applications have been
present from the very beginning as exemplified by Wiesner’s unforgeable
quantum money. The original paper of Bennett and Brassard contains a
bit-commitment-based coin tossing protocol [ BB84 ] . As pointed out by
the authors the protocol is insecure if one of the parties leaves the
quantum states untouched (instead of performing the prescribed
measurements) but they consider it a “merely theoretical threat” due to
the technological difficulty of implementing such a strategy. In 1991
Brassard and Crépeau proposed a different quantum bit commitment
protocol [ BC91 ] , which does not suffer from the previous problem but
is vulnerable against an adversary who can perform coherent measurements
, i.e. joint measurements on multiple quantum particles, which, again,
is considered difficult. By combining the two quantum bit commitment
protocols they obtain a coin tossing protocol which can only be broken
by an adversary who can both keep entanglement and perform coherent
measurements. In the meantime a quantum protocol for oblivious transfer
was proposed whose security, again, relies on the adversary being
technologically limited [ BBCS92 ] . In 1993 Brassard, Crépeau, Jozsa
and Langlois [ BCJL93 ] proposed a new bit commitment protocol which
comes with a complete security proof that does not rely on any
technological assumptions. In other words, the protocol is claimed to be
secure against all attacks compatible with quantum physics. In 1992
Bennett et al. suggested how bit commitment and quantum communication
can be used to construct oblivious transfer [ BBCS92 ] . This
construction was formalised and proven secure by Yao [ Yao95 ] , who
refers to it as the ‘‘canonical construction’’, which gave the
optimistic impression that quantum mechanics allows for secure two-party
cryptography without any extra assumptions. ¹² ¹² 12 This construction
shows that in the quantum world bit commitment and oblivious transfer
are equivalent, which is believed not to be true classically.
Unfortunately, it was later discovered that the protocol proposed in
Ref. [ BCJL93 ] is insecure, which soon led to a complete impossibility
result [ May97 , LC97 ] . For a detailed account of quantum cryptography
until that point please consult Refs. [ BC96 , Cré96 , BCMS97 ] .

The initial results of Mayers, Lo and Chau began a sequence of negative
results. Impossibility of bit commitment immediately rules out oblivious
transfer and, in fact, the same techniques can be used to rule out any
one-sided two-party computation (i.e. a primitive in which inputs from
two parties produce output which is only given to one of them) [ Lo97 ]
. The more complicated case of two-sided computation was first
considered by Colbeck (for a restricted class of functions) [ Col07 ]
while the general impossibility result was proven by Buhrman, Christandl
and Schaffner [ BCS12 ] . In case of string commitment (i.e. when we
simultaneously commit to multiple bits) it is clear that the perfect
primitive cannot be implemented but the situation becomes slightly more
involved when it comes to imperfect primitives as the results depend on
the exact security criteria used [ BCH @xmath 06 , BCH @xmath 08 ] . For
more recent impossibility proofs of bit commitment see Refs. [ DKSW07 ,
WTHR11 , CDP @xmath 13 ] .

While perfect quantum bit commitment is not possible, it is interesting
to know what security trade-offs are permitted by quantum mechanics. In
the classical case the trade-offs are trivial: in any classical protocol
at least one of the parties can cheat with certainty. Preliminary
results on the quantum security trade-offs were proven by Spekkens and
Rudolph [ SR01 ] , while the optimal trade-off curve was found by
Chailloux and Kerenidis [ CK11 ] . Interestingly enough, the
achievability is argued through a construction that uses a complicated
and rather poorly understood weak coin flipping protocol by Mochon [
Moc07 ] .

Another direction (similar to what was done previously in the classical
world) is to identify the minimal assumptions that would make two-party
cryptography possible in the quantum world.

One solution available in the classical world is to give Alice and Bob
access to some trusted randomness. The quantum generalisation of this
assumption would be to give Alice and Bob access to quantum systems or
some other source of stronger-than-classical correlations [ BCU @xmath
06 , WWW11 ] . Such correlations indeed allow us to implement secure bit
commitment. The advantage of this assumption over the classical
counterpart is that in the classical case we had to trust whoever
distributed the randomness (in the original paper referred to as the
trusted initialiser [ Riv99 ] ). On the other hand,
stronger-than-classical correlations guarantee security regardless of
where they came from.

A natural quantum extension of the bounded storage model proposed by
Maurer [ Mau91 ] is the quantum bounded storage model [ DFSS05 , DFR
@xmath 07 , Sch10 ] and its generalisation to the case of noisy quantum
storage [ WST08 , KWW12 , BFW14 ] . While storing classical information
seems easy and cheap (which makes the assumption of the adversary’s
bounded storage not particularly convincing), reliable storage of
quantum information continues to pose a significant challenge and,
hence, makes for a reasonable assumption. Another technological
limitation that leads to secure bit commitment is the restriction on the
class of quantum measurements that the dishonest party can perform [
Sal98 ] .

The proposal to combine quantum mechanics with relativistic ¹³ ¹³ 13
Throughout this thesis the term relativity always refers to special
relativity. communication constraints (attributed to Louis Salvail) was
already mentioned in 1996 [ BC96 , Cré96 ] . The early papers of Kent [
Ken99 , Ken05 ] consider security against quantum adversaries but the
actual protocols are completely classical. To the best of our knowledge,
the first quantum relativistic protocol was proposed by Colbeck and Kent
for a certain variant of coin tossing [ CK06 ] . This marks the
beginning of quantum relativistic cryptography .

### 1.4 Outline

The main theme of this thesis is relativistic quantum cryptography with
a particular focus on commitment schemes. Chapter 2 contains the
necessary background in quantum information theory and cryptography.

In Chapter 3 we introduce non-communicating models as they originally
appeared in the context of interactive proofs. We show why they are
useful in cryptography and determine the exact communication constraints
that might allow for secure commitment schemes. For each of these models
we present a provably secure bit commitment protocol.

Chapter 4 introduces the framework for relativistic protocols. We start
with a couple of simple examples and then present a procedure which maps
a relativistic protocol onto a model with partial communication
constraints. We show that at least in some scenarios the analysis of
such models is tractable.

In Chapter 5 we focus on a particular quantum bit commitment protocol.
We analyse its security by mapping it onto a simple quantum guessing
game. Moreover, we adapt the original protocol to make it robust against
experimental errors and we extend the security analysis appropriately.
We briefly report on an implementation of the protocol done in
collaboration with an experimental group at the University of Geneva.

In Chapter 6 we propose a new, classical multiround bit commitment
protocol and analyse its security against classical adversaries. The
multiround protocol allows to achieve arbitrarily long commitments (at
the cost of growing resources) with explicit and easily-computable
security guarantees. Again, we briefly discuss an experiment performed
in collaboration with the Geneva group.

Chapter 7 summarises the content of this thesis and outlines a couple of
interesting direction for future research in quantum relativistic
cryptography.

## Chapter 2 Preliminaries

In this chapter we establish the notation, nomenclature and some basic
concepts used throughout this thesis.

### 2.1 Notation and miscellaneous lemmas

#### 2.1.1 Strings of bits

Given two bits @xmath we use “ @xmath ” to denote their exclusive-OR (
XOR )

  -- -------- --
     @xmath   
  -- -------- --

For an @xmath -bit string @xmath , let @xmath be the @xmath bit of
@xmath and the XOR of two strings (of equal length) is defined bitwise.
The fractional Hamming weight of @xmath is the fraction of ones in the
string

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the cardinality of the set. The fractional Hamming
distance between @xmath and @xmath is the fraction of positions at which
the two strings differ

  -- -------- --
     @xmath   
  -- -------- --

Note that the Hamming weight can be interpreted as the distance from the
string of all zeroes @xmath : @xmath . For @xmath , we use @xmath to
denote the substring of @xmath specified by the indices in @xmath . If
@xmath is a bit, we define

  -- -------- --
     @xmath   
  -- -------- --

#### 2.1.2 Cauchy-Schwarz inequality for probabilities

When dealing with probabilities we use uppercase letters to denote
random variables and lowercase letters to denote values they might take,
e.g. @xmath . For @xmath we use @xmath as a shorthand notation for
@xmath .

###### Lemma 2.1.

Let @xmath be a uniform random variable over @xmath , i.e. @xmath for
all @xmath , and let @xmath be a family of events defined on @xmath .
Let @xmath be the average probability (of these events)

  -- -------- --
     @xmath   
  -- -------- --

and @xmath be the cumulative size of the pairwise intersections

  -- -------- --
     @xmath   
  -- -------- --

Then the following inequality holds

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Each event can be represented by a vector in @xmath whose entries are
labelled by integers from @xmath . If a particular outcome belongs to
the event, we set the corresponding component to @xmath and if it does
not we set it to @xmath

  -- -------- --
     @xmath   
  -- -------- --

Moreover, let @xmath be the normalised, uniform vector: @xmath for all
@xmath . It is straightforward to check that with these definitions we
have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the standard inner product on @xmath and since the
vectors are non-negative we have @xmath . Since the inner product is
linear we have

  -- -------- --
     @xmath   
  -- -------- --

which can be upper bounded using the Cauchy-Schwarz inequality. Since
@xmath we have

  -- -------- --
     @xmath   
  -- -------- --

which gives the following quadratic constraint

  -- -------- --
     @xmath   
  -- -------- --

Solving for @xmath gives the desired bound.

#### 2.1.3 Chernoff bound for the binomial distribution

###### Lemma 2.2 ([Che52]).

Let @xmath be independent random variables taking on values 0 or 1. Let
@xmath and @xmath be the expectation value of @xmath . Then for any
@xmath the following inequality holds

  -- -------- --
     @xmath   
  -- -------- --

Alternatively, setting @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

### 2.2 Quantum mechanics

Quantum mechanics despite its mysterious nature admits a relatively
simple mathematical description. While it is an interesting question to
ask why quantum mechanics is as it is, instead of being more (or less)
powerful (and indeed such questions constitute the main topic of quantum
foundations), we take a more hands-on approach. Namely, we accept the
standard textbook formulation of quantum mechanics as it is and
investigate its consequences. Section 2.2.1 defines the basic notions of
linear algebra (and, hence, can be skipped by most readers), which will
be necessary to describe the quantum formalism in Section 2.2.2 .

#### 2.2.1 Linear algebra

The following section contains the bare minimum of linear algebra
necessary to understand this thesis and serves primarily the purpose of
establishing consistent notation and nomenclature. For a complete and
detailed introduction to linear algebra we refer to the excellent
textbooks by Rajendra Bhatia [ Bha97 , Bha09 ] .

In this thesis we restrict our attention to finite-dimensional systems.
Let @xmath be a Hilbert space of finite dimension @xmath over complex
numbers. Let @xmath denote the dual space of @xmath , i.e. the space of
linear functionals on @xmath . We employ the bra-ket notation proposed
by Paul Dirac [ Dir39 ] , in which elements of @xmath are written as
kets @xmath and each ket has an associated bra , denoted by @xmath ,
such that applying the linear functional @xmath to an arbitrary vector
@xmath , written as a bra-ket @xmath , corresponds exactly to evaluating
the inner product between @xmath and @xmath . A set of @xmath vectors
@xmath constitutes an orthonormal basis if the vectors are orthogonal
and normalised, i.e. @xmath , where @xmath is the Kronecker delta.

Let @xmath be the set of linear operators acting on @xmath . The
identity operator , denoted by @xmath , is the unique operator that
satisfies

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . Writing a linear operator @xmath in a particular basis
@xmath leads to a @xmath (complex) matrix whose entries equal

  -- -------- --
     @xmath   
  -- -------- --

where the expression @xmath should be understood as @xmath . Note that
while the operator and its matrix representation are not the same object
(the former is basis-independent, while the latter corresponds to a
particular basis) for the purpose of this thesis this distinction may be
ignored and we will use the two terms interchangeably. The trace of a
square matrix @xmath is the sum of its diagonal entries

  -- -- --
        
  -- -- --

The Hermitian conjugate of an operator @xmath , denoted by @xmath , is
defined to satisfy

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the complex conjugate. An operator satisfying
@xmath is called Hermitian (or self-adjoint ) and we denote the set of
Hermitian operators acting on @xmath by @xmath . Operators satisfying
@xmath are called unitary operators or unitaries.

It is easy to verify that for a Hermitian operator @xmath we have @xmath
for all vectors @xmath . A Hermitian operator is called positive
semidefinite if

  -- -------- --
     @xmath   
  -- -------- --

for all vectors @xmath , which is often written as @xmath .

Every linear operator @xmath admits a singular value decomposition ,
i.e. it can be written in the form @xmath , where @xmath and @xmath are
unitary operators and @xmath is a diagonal matrix of real, non-negative
entries known as the singular values of @xmath . Let @xmath be the
vector of singular values. For @xmath the Schatten @xmath -norm of
@xmath , denoted by @xmath , is defined as the vector @xmath -norm of
@xmath

  -- -------- --
     @xmath   
  -- -------- --

For the purpose of this thesis we will only need the limit @xmath so let
us define

  -- -------- --
     @xmath   
  -- -------- --

#### 2.2.2 Quantum formalism

A pure state of a quantum system is described by a normalised vector,
i.e. @xmath such that @xmath . We adopt the convention that every @xmath
-dimensional Hilbert space @xmath is equipped with an orthonormal basis
@xmath , which we call the computational (or standard ) basis. Writing
@xmath in this basis

  -- -------- --
     @xmath   
  -- -------- --

allows us to interpret it as a @xmath -dimensional complex unit vector.
The global phase of a state is inconsequential, i.e. quantum mechanics
tells us that vectors @xmath and @xmath (for @xmath ) correspond to the
same physical state. The smallest non-trivial quantum system corresponds
to @xmath and is called a qubit (a term coined by Schumacher and
Wootters [ Sch95 ] ). The Hadamard operator is defined as

  -- -------- --
     @xmath   
  -- -------- --

or

  -- -------- --
     @xmath   
  -- -------- --

It is easy to verify that @xmath is simultaneously Hermitian ( @xmath )
and unitary ( @xmath ). Define @xmath , @xmath and let us call @xmath
the Hadamard (or diagonal ) basis. The computational and Hadamard bases
are widely used in cryptography because they are an example of mutually
unbiased bases (for @xmath ), i.e. they satisfy

  -- -- --
        
  -- -- --

which captures the notion of being maximally incompatible.

A mixed quantum state on @xmath is a Hermitian operator, which is
positive semidefinite and of unit trace. We define the set of (mixed)
quantum states on @xmath

  -- -- --
        
  -- -- --

The operator @xmath describing a mixed state is called the density
matrix . Mixed states are a generalisation of pure states: an arbitrary
pure state @xmath can be represented as a density matrix @xmath . Mixed
states arise naturally when dealing with composite systems.

Suppose we have two systems (or registers) @xmath and @xmath described
by Hilbert spaces @xmath and @xmath , respectively, and we want to
describe the global state of the system. What are the allowed states on
@xmath and @xmath taken together? In case of pure states, quantum
mechanics tells us to take the tensor product of the two Hilbert spaces,
i.e. @xmath . Therefore, an arbitrary pure bipartite state can be
written as

  -- -- --
        
  -- -- --

where @xmath should be understood as @xmath (the tensor product symbol
is commonly omitted to avoid notational clutter). Given a bipartite
system one might wonder what can be said about the marginal states on
@xmath and @xmath (similar to the concept of the marginals of a
probability distribution). In particular, one would expect that if we
restrict ourselves to measurements on @xmath alone then it should be
possible to “truncate” @xmath to @xmath by disregarding any information
about @xmath . This intuition leads the concept of reduced states . Let
us first write the density matrix corresponding to @xmath

  -- -------- --
     @xmath   
  -- -------- --

Given an operator acting on multiple registers we define the operation
of partial trace which “traces out” a particular register, e.g.

  -- -- --
        
  -- -- --

Note that the standard trace operation corresponds to tracing all the
registers. It is easy to verify that partial traces commute so we can
without ambiguity write @xmath . Tracing out the @xmath register from
the density matrix @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

which is easily verified to be a valid quantum state @xmath and which we
call the reduced state on @xmath . It is easy to verify that the
knowledge of @xmath suffices to make all possible predictions about
operations or measurements that act solely upon subsystem @xmath . In
cryptography reduced states are important because they allow us to
quantify the amount of knowledge that a particular subsystem provides to
its holder.

Once we know how to describe the state of a quantum system we would like
to know how we can interact with it. To extract any information from a
quantum state one needs to measure it. Note that this is one of the
aspects in which quantum theory differs significantly from its classical
counterpart. In the classical world the object and its (complete)
description are operationally equivalent : given the description one can
construct the object and given the object one can determine (to an
arbitrary precision) its description. In the quantum world a single copy
of an object gives us significantly less information than its complete
description as demonstrated by the no-cloning theorem [ WŻ82 ] . In
contrast to the classical world, every quantum system can be measured in
multiple ways, which means that the measurement process must be
described explicitly. A measurement ¹ ¹ 1 We implicitly assume that we
are only interested in the classical outcome of the measurement and
ignore the post-measurement state. on a @xmath -dimensional quantum
state which yields outcomes from a finite alphabet @xmath is a
collection of positive semidefinite operators @xmath ² ² 2 To avoid
confusion whenever describing the set of measurement operators we
explicitly state the index that must be summed over to obtain identity.
that add up to ( @xmath -dimensional) identity

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

Quantum mechanics is a probabilistic theory, i.e. it only allows us to
calculate probabilities of observing different outcomes. According to
Born’s rule [ Bor26 ] measuring the state @xmath yields outcome @xmath
with probability

  -- -------- --
     @xmath   
  -- -------- --

It is easy to see that the condition ( 2.1 ) is imposed to ensure that
the resulting probability distribution is non-negative and normalised
for every state . Note that such an information-theoretic formulation of
the measurement process does not necessarily coincide with the notion of
measuring a physical quantity, e.g. the outcome might not be a number so
one cannot talk about the expectation value or the standard deviation of
the measurement.

The process of measuring a quantum state can be seen as a map that takes
a quantum state and outputs a probability distribution. This naturally
generalises to maps in which the output remains quantum and such maps
are known as quantum channels . The identity channel (i.e. the unique
channel that leaves every state unaffected) is denoted by @xmath ³ ³ 3
Note that it is common in quantum information to use the same symbol for
the identity channel and the identity operator since it is usually clear
from the context which one is meant. To avoid confusion we prefer to use
different symbols. . Generally, a map @xmath is a quantum channel iff:

1.  @xmath is linear, i.e. for any @xmath and @xmath

      -- -------- --
         @xmath   
      -- -------- --

2.  @xmath is completely positive, i.e. for any @xmath , where @xmath is
    an auxiliary Hilbert space of arbitrary dimension,

      -- -------- --
         @xmath   
      -- -------- --

3.  @xmath is trace-preserving, i.e. for any @xmath

      -- -------- --
         @xmath   
      -- -------- --

These properties can be rigorously derived from the assumption that a
channel is a result of a unitary evolution acting on a larger Hilbert
space. On a more pragmatic level, these rules ensure that the channel is
a linear map that takes quantum states on @xmath into valid quantum
states on @xmath . When dealing with multipartite states it might be
useful to explicitly write out the input and output registers, e.g.
@xmath .

#### 2.2.3 Remote state preparation

A state of the form

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

is called classical-quantum (cq) since the first register represents a
classical random variable @xmath while the second is a general quantum
system. Such states describe how a quantum system can be correlated with
some classical data. One way of obtaining such a state is to sample the
classical random variable @xmath and prepare subsystem @xmath in a
particular state conditional on the outcome. Here, we show how to use
entanglement to remotely prepare a certain class of such states, a
phenomenon also known as steering .

Define the maximally entangled state of dimension @xmath as

  -- -- --
        
  -- -- --

It is easy to verify that in this case both marginals are maximally
mixed , i.e. proportional to the identity matrix

  -- -- --
        
  -- -- --

Moreover, for an arbitrary linear operator @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the transpose with respect to the computational
basis

  -- -- --
        
  -- -- --

If we replace @xmath with a measurement operator this implies that
observing a particular outcome on @xmath results in a particular
subnormalised quantum state on @xmath . Hence, we have remotely prepared
a state on @xmath by performing a measurement on @xmath . It is easy to
see that any cq-state of the form ( 2.2 ) which satisfies

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

can be obtained by performing the right measurement on one half of the
@xmath -dimensional maximally entangled state. More specifically, the
appropriate measurement @xmath is described by measurement operators
@xmath . The restriction ( 2.3 ) expresses the rule that the reduced
state on @xmath must remain unchanged, i.e. it must remain maximally
mixed. This phenomenon turns out to be important in quantum
cryptography.

An essential feature of quantum information is the ability to encode
information in two (or more) incompatible bases. The most common example
was originally introduced by Wiesner [ Wie83 ] but goes under the name
of BB84 states (after Bennett and Brassard who popularised the term [
BB84 ] ). In this case Alice uses either computational or Hadamard basis
to encode a logical bit @xmath in a qubit which she later sends to Bob.
If the logical bit is uniform the two encodings lead to

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

respectively. It is easy to verify that both of these satisfy relation (
2.3 ) with @xmath . This leads to an important observation (in this
particular cryptographic context due to Bennett, Brassard and Mermin [
BBM92 ] ) that such states can be prepared by first generating the
maximally entangled state of two qubits @xmath and then measuring
subsystem @xmath in the right basis. In fact, Alice simply makes a
measurement in either computational or Hadamard basis.

Since measurements on Alice’s side commute with any operations on Bob’s
side, they can be delayed until some later point in the protocol, which
means that now Alice and Bob share entanglement during the protocol. In
other words, we have turned a prepare-and-measure scheme (Alice prepares
a state and sends it to Bob, who performs a measurement), in which there
is no entanglement between Alice and Bob, into an equivalent (from the
security point of view) entanglement-based scheme (Alice and Bob
simultaneously perform measurements on a shared entangled state). Often
the entanglement-based schemes are easier to analyse, which we we will
take advantage of to prove security of a quantum relativistic bit
commitment protocol in Chapter 5 .

### 2.3 Multiplayer games

For the purpose of this thesis, a game is an interaction between a
referee and one or more players . The referee asks each player a
question and the player must give an answer. In most cases the players
are not allowed to communicate during the game. A strategy is a
procedure that the players follow to generate their answers. At the end
of the game, the referee decides whether the game is won or lost.

#### 2.3.1 Classical and quantum strategies

For concreteness, we consider a game of @xmath non-communicating
players. Each player receives an input from @xmath and is required to
output a symbol from @xmath ( @xmath and @xmath are arbitrary finite
alphabets). A game is defined by the input distribution

  -- -------- --
     @xmath   
  -- -------- --

and a predicate function

  -- -------- --
     @xmath   
  -- -------- --

which specifies whether the players win or lose for a particular
combination of inputs and outputs. ⁵ ⁵ 5 Clearly, this generalises in a
straightforward manner to the case where the range of @xmath is @xmath .
Then @xmath assigns a particular score to every combination of inputs
and outputs. However, in this thesis we only consider games in which the
players either win or lose.

Every strategy available to classical players can be written as a convex
combination of deterministic strategies. Hence, the maximum winning
probability, denoted by @xmath and referred to as the classical value of
the game, can be achieved by a deterministic strategy. A deterministic
strategy is a collection of @xmath functions @xmath , @xmath , which
determine each player’s response. Therefore,

  -- -------- --
     @xmath   
  -- -------- --

where the maximum is taken over all combinations of functions.

Quantum players, in turn, are allowed to share a quantum state and
perform measurements that depend on the inputs. For simplicity in the
quantum setting we only describe two-player games ( @xmath ) but these
concepts extend in a straightforward way to an arbitrary number of
players (see for example Ref. [ Vid13 ] ). A quantum strategy consists
of a bipartite pure quantum state (of finite dimension) @xmath ⁶ ⁶ 6 It
is sufficient to consider pure states since a mixed state can be written
as a convex combination of pure states. and measurements that each
player will perform for every possible input @xmath , denoted by @xmath
. The maximum winning probability achievable by quantum players denoted
by @xmath is called the quantum value

  -- -------- --
     @xmath   
  -- -------- --

where the optimisation is taken over all quantum strategies.

Calculating the classical value of a game can be done by iterating over
all possible strategies. While this is clearly not efficient (the number
of strategies to check is exponential in the number of inputs), at least
in principle it can be done. ⁷ ⁷ 7 In fact, finding the classical value
of a general game is NP-hard, i.e. we believe it cannot be done
efficiently. On the other hand, computing the quantum value is a more
difficult problem and no generic procedure is known. ⁸ ⁸ 8 The quantum
value of an XOR game can be calculated using semidefinite programming
techniques [ Weh06 ] . For general games there exist hierarchies by
Navascués, Pironio, Acín [ NPA07 ] and Doherty, Liang, Toner, Wehner [
DLTW08 ] , which give increasingly tighter approximations on the correct
value. While these hierarchies ultimately converge to the correct value,
the rate of convergence is not well-understood. Moreover, calculating
the higher level approximations becomes a difficult task from the
computational point of view. The problem stems from the fact that we do
not have a convenient description of the quantum set of correlations
(i.e. there is no efficient procedure to decide whether a given point
belongs to the set or not). To establish an upper bound on the quantum
value of a game it is common to consider a larger set of correlations
known as the no-signalling correlations, which does admit a simple
description. Intuitively, this is the largest set of correlations that
does not allow to send messages between different parties and the
simplest example is the so-called Popescu-Rohrlich box [ PR94 ] .
Because the no-signalling set is a polytope (i.e. the convex hull of a
finite set of extreme points) we know how to optimise over it (at least
in principle, efficiency considerations apply as before). For a detailed
characterisation of different sets of correlations refer to a recent
review paper on Bell nonlocality [ BCP @xmath 14 ] .

#### 2.3.2 Finite fields

A field is a set with two operations: addition and multiplication, which
satisfy the usual properties as listed below.

-   The field is closed under multiplication and addition.

-   Both operations are associative.

-   Both operations are commutative.

-   There exist additive and multiplicative identity elements.

-   There exist additive and multiplicative inverses (except for the
    additive identity which does not have a multiplicative inverse).

-   Multiplication is distributive over addition.

It is easy to see that real or complex numbers form with the standard
addition and multiplication are fields. We call a field finite (the name
Galois field is also used after Évariste Galois) if the set of elements
is finite. The order of a finite field is the number of elements in the
set and a finite field of order @xmath exists iff @xmath is a prime
power, i.e. @xmath for some prime @xmath and integer @xmath . Since all
finite fields of a given order are isomorphic (i.e. they are identical
up to relabelling of the elements), we speak of the finite field of
order @xmath denoted by @xmath . For a thorough introduction to finite
fields please consult an excellent book by Mullen and Mummert [ MM07 ] .

Finite fields appear often in coding theory and cryptography since they
are finite sets closed under (appropriately defined) addition,
multiplication and their inverses. Moreover, all these operations can be
implemented efficiently on a computer. Fields corresponding to @xmath
are a common choice since their elements have a natural representation
as strings of bits. The protocol proposed in Chapter 6 uses finite-field
arithmetic and its security hinges on the difficulty of a certain family
of multiplayer games. In this section we prove upper bounds on the
classical value of such games and discuss the connection to a natural
algebraic problem concerning multivariate polynomials over finite
fields.

#### 2.3.3 Definition of the game

Buhrman and Massar [ BM05 ] proposed a generalisation of the CHSH game [
CHSH69 ] , which was further studied by Bavarian and Shor [ BS15 ] . A
natural multiplayer generalisation of this game arises in the security
analysis of the multiround bit commitment protocol in Chapter 6 . Since
the analysis does not require familiarity with the actual actual bit
commitment protocol and might be of independent interest, we have
decided to make it a stand-alone component of the Preliminaries (rather
than incorporating it in Chapter 6 ).

Consider a game with @xmath players, denoted by @xmath , and let @xmath
be random variables drawn independently, uniformly at random from @xmath

  -- -------- --
     @xmath   
  -- -------- --

We use @xmath to denote the set of integers between @xmath and @xmath ,
@xmath . In the “Number on the Forehead” model [ CFL83 ] @xmath receives
all the random variables except for the @xmath one , which we denote by
@xmath , and is required to output an element of @xmath , which we
denote by @xmath (see Fig. 2.1 ). The game is won if the sum of the
outputs equals the product of the inputs (all the operations are
performed in the finite field), i.e. the predicate function is

  -- -- --
        
  -- -- --

If the player @xmath employs a deterministic strategy described by
@xmath , i.e. he outputs @xmath , then the winning probability equals

  -- -------- --
     @xmath   
  -- -------- --

As described in Section 2.3 the classical value of the game equals

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where the maximisation is taken over all combinations of functions from
@xmath to @xmath . ⁹ ⁹ 9 Clearly, this is a function of both @xmath and
@xmath but we have decided not to mention the dependence on @xmath
explicitly (to avoid overcrowding the symbol with sub- or superscripts).
This is justified because in our application @xmath is a parameter that
has to be chosen before the protocol begins, whereas @xmath can be
decided upon at some later point. Our goal is to find an upper bound on
@xmath as a function of @xmath and @xmath .

#### 2.3.4 Relation to multivariate polynomials over finite fields

As the probability distribution of inputs is uniform the winning
probability of a particular deterministic strategy (defined by a
collection of functions @xmath ) is proportional to the number of inputs
@xmath on which the following equality holds

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

Alternatively, we can count the zeroes of the following function

  -- -------- --
     @xmath   
  -- -------- --

By the Lagrange interpolation method every function from @xmath to
@xmath (for arbitrary @xmath ) can be written as a polynomial.
Therefore, the question concerns the number of zeroes of the polynomial
@xmath . Different strategies employed by the players give rise to
different polynomials and we need to characterise what polynomials are
“reachable” in this scenario. The output of @xmath is an arbitrary
polynomial of @xmath , hence, it only contains terms that depend on at
most @xmath variables . This means that the part of @xmath that depends
on all @xmath variables comes solely from the first term and equals
@xmath . Therefore, finding the classical value of the game is
equivalent to finding the polynomial with the largest number of zeroes,
whose only term that depends on all @xmath variables equals @xmath .
This shows that the optimal strategy for our game is closely related to
purely algebraic properties of polynomials over finite fields.

#### 2.3.5 A recursive upper bound on the classical value

Here, we find explicit upper bounds on @xmath through an induction
argument. First, note that for @xmath there is only one term on the
right-hand side of Eq. ( 2.5 ) and since this term takes no arguments it
is actually a constant. Since @xmath is uniform we have

  -- -------- --
     @xmath   
  -- -------- --

Now, we derive an upper bound on @xmath in terms of @xmath . For a fixed
strategy @xmath the winning probability can be written as

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
  -- -------- -------- --

Conditioning on a particular value of @xmath leads to events that only
depend on @xmath . In particular, setting @xmath defines the event
@xmath

  -- -------- --
     @xmath   
  -- -------- --

which satisfies

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

We can use Lemma 2.1 to find a bound on @xmath as long as we are given
bounds on @xmath for @xmath .

###### Proposition 2.1.

For @xmath we have @xmath .

###### Proof.

Eq. ( 2.6 ) defines @xmath through a certain equation in the finite
field. If the equations corresponding to @xmath and @xmath are satisfied
simultaneously then any linear combination of these equations is also
satisfied. More specifically, we define a new event

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

and since @xmath we are guaranteed that @xmath . To find an upper bound
on @xmath we give the players more power by allowing a more general
expression on the right-hand side. In Eq. ( 2.7 ) the @xmath term is a
particular function of @xmath and @xmath , so let us replace it by an
arbitrary function of these variables

  -- -------- --
     @xmath   
  -- -------- --

Under this relaxation, we arrive at the following equality

  -- -------- --
     @xmath   
  -- -------- --

Clearly, @xmath is a constant, non-zero multiplicative factor known to
each player. Dividing the equation through by @xmath leads to the same
game as considered before but one player has been eliminated (there are
only @xmath players now). Therefore,

  -- -------- --
     @xmath   
  -- -------- --

∎

This allows us to prove the main technical result.

###### Proposition 2.2.

The classical value of the game defined in Section 2.3.3 satisfies the
following recursive relation

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

###### Proof.

The statement follows directly from combining Lemma 2.1 with Proposition
2.1 . ∎

Since we know that @xmath , we can obtain a bound on @xmath by recursive
evaluation of Eq. ( 2.8 ). More precisely, we get @xmath for

  -- -------- --
     @xmath   
  -- -------- --

Note that this bound is always non trivial, i.e. @xmath for all values
of @xmath and @xmath . To obtain a slightly weaker but simpler form
presented in Eq. ( 6.9 ) in Chapter 6 we note that @xmath and set @xmath
.

### 2.4 Cryptographic protocols and implementations

Cryptography is a field is driven by applications, i.e. the starting
point is a particular task that two (or more) parties want to perform.
Formulating a task in a rigorous, mathematical language gives rise to a
cryptographic primitive . In case of two-party cryptography two aspects
must be specified.

-    Correctness: The expected behaviour when executed by honest
    parties.

-    Security: A list of behaviours that are forbidden regardless of the
    strategies that the dishonest parties might employ.

Defining correctness is straightforward because what we want to achieve
is clear from the beginning. Finding the right definition of security,
on the other hand, might be a challenging task. Converting our intuition
about what the primitive should not allow for into a mathematical
statement is not always straightforward and often multiple security
definitions are simultaneously in use depending on the exact context.
Sometimes security is perfect (cf. the hiding property of bit commitment
in Definition 2.2 ), but more often it is quantified by a (small) number
usually denoted by @xmath (cf. the binding property in Definition 2.3 ),
which can be (usually) understood as an upper bound on the probability
that a cheating attempt is successful.

It is worth emphasising that no meaningful statements can be made if all
involved parties decide to cheat simply because if they collectively
deviate in the “right” way they can produce any imaginable output. If
all the dishonest parties form a coalition whose only goal is to enforce
a certain output, nothing can stop them from achieving it. In
particular, in the two-party case Alice and Bob could, instead of
executing the protocol, decide to play a game of chess and then the
output of the interaction would be a complete account of a chess game.
Clearly, no cryptographic statements can be made about a chess game.
Therefore, we only consider scenarios in which at least one party is
honest and that is why in the two-party setting we prefer to talk about
security for honest Alice (Bob) instead of security against dishonest
Bob (Alice) .

Once the primitive has been defined we propose a protocol (i.e. a
sequence of interactions between the players) that implements it.
Verifying the correctness of a cryptographic protocol is simple since
the honest parties behave in a well-defined manner. Showing security, on
the other hand, is more complicated because we need to characterise all
possible ways in which the dishonest parties might deviate from the
protocol and argue that none of them violates the security requirements
of the primitive. In a protocol that does not achieve perfect security,
the final outcome of a security proof is an upper bound on how well the
dishonest party can cheat. Since the level of security that we are happy
to accept depends on the precise circumstances, protocols usually come
in families parametrised by an integer @xmath and the security guarantee
is a function of @xmath ideally satisfying @xmath as @xmath . Increasing
the value of @xmath leads to protocols that use more resources
(e.g. computation, communication or randomness) but achieve better
security. Ideally, we would like @xmath to decay exponentially but
inverse polynomial decay might also be acceptable. Security analysis of
such a family of protocols aims to find the tightest bound, i.e. lowest
@xmath , as a function of @xmath .

Having performed the theoretical analysis of a protocol, the last step
is to actually implement it. In case of mature technologies (e.g. modern
digital devices) fault-tolerance (capability of terminating correctly
even in the presence of errors) is ensured at the hardware level so
there is no need to introduce any extra measures in the actual protocol.
The multiround classical relativistic bit commitment protocol discussed
in Chapter 6 is a prime example: the simplest theoretical protocol is
already suitable for implementation and no modifications are necessary.
On the other hand, in case of less developed fields like quantum
technologies the situation is a bit more complicated. Since we have not
yet found a way to (generically) eliminate all the errors, we must
consider how they will affect our protocol. What happens when honest
parties follow the protocol but their communication or storage suffers
from noise? Depending on how severe the errors are, the protocol either
terminates with the wrong output or it aborts. To prevent such an
undesirable outcome the protocol must be modified to become
fault-tolerant. The exact modifications that need to be made depend on
what type of noise we want to protect ourselves against. More
specifically, we need to have a model of noise that is simple enough to
analyse but remains a reasonably faithful description of the
experimental setup. As a consequence, turning a theoretical protocol
into an experimental proposal is not so straightforward and usually
requires multiple rounds of communication between the theoretician and
the experimentalist. The new fault-tolerant protocol admits a couple of
parameters, which determine its error tolerance, and these should be
chosen to ensure that the protocol terminates successfully (with high
probability) when performed by the honest parties. In this case
asymptotic analysis is sufficient, since it is the actual experiment
that demonstrates correctness (while calculations simply give us an
indication whether the experiment is worth setting up).

Having modified our protocol we need to reassess its security and it is
clear that introducing fault-tolerant features makes a protocol more
vulnerable to cheating. Moreover, since the security analysis is
supposed to please the most paranoid cryptographers, we must make
minimal assumptions about the adversary. In particular, we do not want
to impose on him any technological restrictions. Our devices are
imperfect due to our lack of skills and knowledge but we do not want to
assume that about the adversary. The standard approach to quantum
cryptography is to assume that the devices used by the honest party are
trusted (i.e. their precise description including potential
imperfections is known) but the devices used by the adversary might be
arbitrary (i.e. they are only limited by the laws of physics). ¹⁰ ¹⁰ 10
As mentioned before the trust assumption can in fact be dropped. See
Section 1.3 for references.

Clearly, requiring that our protocol is correct for honest parties with
imperfect devices and remains secure against an all-powerful adversary
puts us in a difficult situation. As mentioned before, the
fault-tolerant protocol takes a couple of parameters which we can try
adjusting but we might nevertheless reach the conclusion that
guaranteeing correctness and security simultaneously is not possible.
This means that the quality of the devices available to the honest
parties is not sufficient to allow for a secure execution of the
protocol.

We can turn this statement around and ask about the minimal requirements
on the honest devices. How much noise can we tolerate before the
protocol becomes insecure? Note that now this is a property of the
protocol alone and we should aim to design protocols with the highest
possible noise tolerance. In case of quantum technologies a successful
implementation of a cryptographic protocol often requires a collective
effort of the experimentalist (who attempts to reduce the experimental
noise to the absolute minimum) and the theoretician (who improves the
theoretical security analysis). An example of such an analysis for a
quantum bit commitment protocol is presented in Chapter 5 .

### 2.5 Bit commitment

Recall Example 2 from Section 1.1 , in which Alice wants to commit to a
certain message without actually revealing it. Commitment schemes have
multiple applications, for example they allow us to prove that we know
something or that we are able to predict some future event without
revealing any information in advance. They are also a useful tool to
force different parties to act simultaneously, even if the communication
model is inherently sequential. Consider two bidders who want to take
part in an auction but there is no trusted auctioneer at hand. In the
usual, sequential communication model one of them has to announce his
bid first, which gives an unfair advantage to the other bidder. This can
be rectified if the first bidder commits to his bid (instead of
announcing it) and opens it only after the second bidder has announced
his price. Hence, given access to a commitment functionality, one can
perform a fair auction without a trusted third party. Moreover,
commitment schemes are often used in reductions to construct other
cryptographic primitives. For the purpose of this section we restrict
ourselves to schemes in which the committed message is just one bit.

As explained in Section 2.4 the protocol should be correct (it should
succeed if executed by honest parties) and secure (the honest party
should be protected even if the other party deviates arbitrarily from
the protocol). ¹¹ ¹¹ 11 One can also design cheat-sensitive protocols [
ATVY00 , HK04 ] , in which one party constantly monitors the other
party’s action and might abort the protocol in the middle if they
believe that the other party is cheating, but we do not consider them
here. Similarly, cheat-sensitive coin flipping protocols have been
proposed [ SR02 ] . To make precise mathematical statements, we need a
formal description of the protocol in the quantum language.

#### 2.5.1 Formal definition

The primitive of bit commitment is usually split into two phases: the
commit phase and the open phase. In the commit phase Alice interacts
with Bob and at the end of the commit phase she should be committed,
i.e. she should no longer have the freedom to choose (or change) her
commitment. Nevertheless, Bob should remain ignorant about Alice’s
commitment. In the open phase Alice sends to Bob the bit she has
committed to, along with a proof of her commitment, which he examines to
decide whether to accept the opening or not.

While this description is sufficient for most purposes, it has some
undesirable features. First of all, since it does not explicitly mention
the period in between the two phases, it might create the impression
that there is no interval in between, i.e. it might lead to the false
conclusion that the end of the commit phase and the beginning of the
open phase correspond to the same point of time. This is clearly
misleading as the whole point of a commitment scheme is to obtain a
finite interval between the two, i.e. a period in which Alice is
committed to a message which Bob remains ignorant about. The distinction
is usually not made explicit because in most protocols nothing happens
in between the two phases (Alice and Bob just savour the moment of being
securely committed), which means that the two points are operationally
equivalent (e.g. any information that Bob might extract about Alice’s
commitment just before the open phase he might also extract immediately
after the commit phase). This is not true for protocols in which
communication continues in between the two phases and there the
distinction is important. Therefore, we explicitly introduce the sustain
phase, i.e. the period during which the commitment is valid. For reasons
which will become clear soon, we call the beginning of the sustain phase
the commitment point and the end the opening point . We also split up
what is usually called the open phase into two separate parts: in the
open phase Alice unveils @xmath to Bob and sends him a proof of her
commitment (which we assume to be a single message ¹² ¹² 12 The
assumption that the open phase consists of a single message from Alice
to Bob might seem restrictive but it does not rule out any interesting
protocols. Any interaction between Alice and Bob in the open phase can
be simulated locally by Bob given that Alice provides him with all the
relevant information. Since there is no need to protect Alice’s privacy
any more, the security of the protocol is not affected. In fact, we
could consider an extreme case in which Alice does not even extract a
proof and instead passes all the (possibly quantum) information in her
possession to Bob. Again, this would not affect security but might
unnecessarily increase the size of the message. Note that while this
simulation argument does not change the situation of honest Alice, it
might change (to worse) the situation of dishonest Alice but this shall
not concern us. ), while in the verify phase Bob decides whether to
accept the opening or not. The phase structure is shown in Fig. 2.2 .

We use @xmath and @xmath to denote the subsystems of Alice and Bob,
respectively. We use @xmath to denote the proof, which is generated (in
the open phase) by Alice and sent to Bob. We implicitly assume that
@xmath contains the information about the value @xmath that Alice is
trying to unveil. Since the commit and sustain phases are interactive
they do not admit a compact description in the quantum formalism. The
open phase can be described as a quantum channel @xmath , which acts on
Alice’s subsystem ( @xmath ) to produce a proof ( @xmath ). Bob’s
decision whether to accept or reject the commitment in the verify phase
can be described by a binary measurement @xmath performed jointly on
subsystems @xmath and @xmath .

The honest scenario is relatively straightforward to analyse. The
protocol specifies uniquely (for each value of Alice’s commitment @xmath
) the state shared between Alice and Bob at every stage of the protocol
and finding it explicitly is a matter of simple calculation.

###### Definition 2.1.

Let @xmath be the state shared between Alice and Bob at the opening
point, @xmath be the opening map and @xmath be the final measurement. A
bit commitment protocol is @xmath -correct if for @xmath we have

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

In the dishonest scenario the situation becomes a bit more complicated
because the state shared between Alice and Bob is no longer uniquely
specified. For example, if Alice is dishonest then the state of her
subsystem might be completely arbitrary. For the purpose of defining
security it is convenient to talk about the set of states that dishonest
Alice (or Bob) can enforce during the protocol and we will use @xmath to
denote such states (to distinguish them from the honest states denoted
by @xmath ). ¹³ ¹³ 13 Note that for a generic, multiround protocol
characterising such sets might be a difficult task. Nevertheless, these
sets are always well-defined and allow us to define security in a
convenient way. These sets are then used to quantify security.

As discussed before, coming up with the right security definition is not
trivial because it requires us to turn the intuitive notion of security
into a mathematical statement. It is useful to realise that the
dishonest scenario is operationally equivalent to a game between the
honest party (acting as a referee since their behaviour is determined by
the protocol) and the dishonest party (a player who is allowed to adopt
an arbitrary strategy). Thus, defining security is equivalent to
specifying the exact rules of such a “cheating game”.

To look at a concrete example let us start with the case of honest Alice
and dishonest Bob. Bob’s goal is to find out the value of Alice’s
commitment before the open phase begins, i.e. at the opening point, and
to achieve this he might deviate arbitrarily from the protocol. This
admits a natural formulation as a game in which Alice (the referee)
chooses @xmath uniformly at random and follows the honest protocol until
the opening point. Then, Bob is challenged to guess @xmath at the
opening point and the probability of guessing @xmath correctly is a
natural measure of his cheating abilities. To phrase this in terms of
quantum states, let @xmath be the state at the opening point and note
that a particular strategy of dishonest Bob enforces two distinct states
@xmath .

###### Definition 2.2.

A bit commitment protocol is hiding if all pairs of states @xmath that
Bob can enforce at the opening point satisfy

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

where @xmath .

This definition implies that whatever strategy Bob employs, he obtains
no information about Alice’s commitment. ¹⁴ ¹⁴ 14 Note that this implies
that the equality ( 2.9 ) holds not just at at the opening point but at
all times until that point. If at any point the two reduced states were
not equal Bob could simply store his system until the opening time
(possibly sending Alice some freshly prepared states if necessary). Note
that this property is sometimes referred to as being perfectly hiding ,
in contrast to schemes that only guarantee Alice partial security. Since
all protocols considered in this thesis are perfectly hiding, we always
use hiding to mean perfect security.

The case of dishonest Alice and honest Bob is a bit more complex. In
order to claim that Alice’s commitment begins at the commitment point,
we must show that at that point she no longer has the freedom to unveil
both values, regardless of the strategy adopted prior to that. In other
words, the dishonest behaviour of Alice can be seen as two distinct
strategies (corresponding to @xmath and @xmath ) which are identical
until the commitment point and let us call such strategies compatible .
Intuitively, this means that she can delay the choice which strategy to
follow until the commitment point.

###### Definition 2.3.

Let @xmath be a pair of states that Alice can enforce at the opening
point using compatible strategies and let @xmath be opening maps. Define
@xmath to be the probability that Alice’s attempt to unveil @xmath is
accepted by Bob

  -- -------- --
     @xmath   
  -- -------- --

A bit commitment protocol is called @xmath -binding if for all states
@xmath and for all opening maps @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Note that finding the optimal opening map for a particular intermediate
state @xmath is a semidefinite program so it can be solved efficiently.
Therefore, the cheating strategy is essentially specified by a pair of
compatible strategies.

It is clear that the restriction that the two strategies are compatible
is crucial. Clearly, Alice can enforce the honest pair of states @xmath
, which leads to @xmath (as long as the protocol is correct), but this
cannot be achieved using compatible strategies (if it was possible, the
protocol would be completely insecure).

Note that this formulation is equivalent to a game in which Alice
employs some generic strategy until the commitment point and is
immediately after challenged to open either @xmath or @xmath chosen
uniformly at random. ¹⁵ ¹⁵ 15 Note that this challenge must come from an
external source like the referee. It is not convincing for Alice to
unveil a bit chosen by herself. A strategy that wins such a game with
probability @xmath is equivalent to a cheating strategy which achieves
@xmath . Thinking of the cheating scenario as a game often allows a more
intuitive understanding of what the dishonest party is trying to
achieve.

Note that it might seem natural to demand that there is only one value
that Alice might successfully open. However, this requirement is too
strong because we cannot prevent Alice from committing to a random bit
which leads to @xmath . This idea can be developed further to produce a
reachable notion of security [ DFSS05 , WST08 ] , which has the
advantage of being composable , i.e. security is guaranteed even if the
primitive is used as a subroutine in a longer procedure [ Can01 ] .
However, it is known that this stronger notion of security cannot be
reached in the relativistic setting (see Appendix A for details).
Therefore, in this thesis we only consider the weaker, non-composable
Definition 2.3 .

#### 2.5.2 The Mayers-Lo-Chau impossibility result

As explained in Section 1.3 , in the early 1990s a significant effort
went into investigating whether various two-party tasks can be solved
using quantum protocols. Unfortunately, most of such tasks were
ultimately shown to be impossible even in the quantum world. In this
section we sketch out the impossibility proof for quantum bit commitment
discovered independently by Mayers [ May97 ] and Lo and Chau [ LC97 ] .

Before going into the details of the quantum no-go argument let us
sketch out the classical one. Consider a protocol which is correct and
hiding and suppose Alice follows the honest strategy for @xmath until
the commitment point. Since the protocol is correct Alice can proceed
with the honest strategy and successfully unveil @xmath . What if she
wants to cheat and unveil @xmath instead? The protocol is hiding, which
means that Bob does not know the value of her commitment. This implies
that there exists a particular strategy for Alice after the commitment
point that will make him accept @xmath (otherwise he could eliminate
this possibility). The existence of such a strategy implies that Alice
can unveil either value (with certainty), i.e. achieve @xmath . This
argument can be extended to show that in every classical protocol (which
is correct) at least one of the parties can cheat with certainty. Such
arguments are formalised using the notion of a transcript, which is
simply the complete list of messages exchanged by Alice and Bob. It is
clear that in the classical world each party can produce a transcript by
copying all the messages to a private, auxiliary register. In the
quantum world one cannot simply copy messages so it is not meaningful to
talk about the transcript of a quantum protocol. That is why this simple
classical argument does not apply to quantum protocols.

The quantum impossibility argument hinges on the fact that, without loss
of generality, we can assume that Alice and Bob keep the entire quantum
state pure until the commitment point. Since Alice and Bob share no
correlations (these would count as a resource) and private randomness
can be purified locally, we can assume that Alice and Bob start in a
pure, product state. Then, all the measurements can be performed
coherently (also known as keeping the measurements quantum , see Section
1.3 of Ref. [ Col06 ] for an explanation). This requires us to replace
all the classical channels in the protocol by quantum channels. Since
this might open up new, inherently quantum cheating strategies we must
instruct each party to measure (coherently) each incoming message. This
gives rise to a new (but equivalent from the security point of view)
protocol, in which all the interactions happen at the quantum level and
at the commitment point Alice and Bob share a pure state, which we
denote by @xmath . ¹⁶ ¹⁶ 16 This is one way of dealing with classical
communication known as the indirect approach . For more details on the
indirect approach and also the alternative direct approach see Ref. [
BCMS97 ] . According to Definition 2.2 the protocol is hiding if @xmath
. Unfortunately, due to Uhlmann’s theorem [ Uhl76 ] this implies that
there exists a unitary @xmath acting on subsystem @xmath alone such that

  -- -------- --
     @xmath   
  -- -------- --

In other words, Alice can switch between the two honest states by acting
on her system alone, which allows her to unveil either bit (with
certainty) and, therefore, renders the protocol completely insecure.
Formally the impossibility can be stated in the following manner.

###### Theorem 2.1.

Any protocol which is perfectly correct and hiding allows Alice to cheat
perfectly. In other words, there exists a cheating strategy for Alice
which achieves @xmath .

This simple argument applies only to the exact case where @xmath but it
is easy to show that if @xmath is close to @xmath (i.e. Bob finds it
difficult to distinguish them) then Alice can cheat with high
probability and trade-offs based on this idea were derived by Spekkens
and Rudolph [ SR01 ] . Optimal bounds on quantum bit commitment have
been found by Chailloux and Kerenidis [ CK11 ] .

While quantum mechanics does not allow for perfect bit commitment, it
still beats classical protocols. As mentioned before every classical
protocol is completely insecure against one of the parties. Quantum
protocols, on the other hand, allow us to achieve some intermediate
points, in which security is in some sense “distributed” between Alice
and Bob. ∎

## Chapter 3 Non-communicating models

This chapter (excluding Section 3.1) is based on

-    Secure bit commitment from relativistic constraints [ arXiv:
    1206.1740 ]
    J. Kaniewski, M. Tomamichel, E. Hänggi and S. Wehner
    IEEE Transactions on Information Theory 59 , 7 (2013).
    (presented at QCrypt ’12 )

It is well-known that interrogating suspects is more fruitful if they
cannot communicate during the process, simply because coming up with two
reasonable stories is more difficult than with one. ¹ ¹ 1 This only
holds if the interrogation is an interactive and unpredictable process.
If the suspects can predict all the possible questions in advance,
nothing prohibits them from producing consistent answers. This intuition
was first made rigorous in the context of complexity theory but similar
features can be seen in cryptography, in which non-communicating models
allow us to implement primitives which would be otherwise forbidden.
Care has to be taken, however, since the primitive implemented in the
non-communicating model is usually subtly different (weaker) than the
original one and, hence, might not be suitable for all applications.

Non-communicating models can be formalised using the concept of agents .
For example, if in the standard protocol Alice interacts with Bob, in
the multiagent variant she might be required to interact with two
distinct agents of Bob. In this case we think of Bob as being the main
party, who decides on the strategy and briefs all his agents beforehand
but steps back as soon as the protocol begins. During the protocol the
agents follow the instructions but are not allowed to communicate with
each other (or the main party). In this chapter we adopt the convention
that if Alice (Bob) only needs to delegate one agent we do not make an
explicit distinction between the main party and the agent. If more
agents are involved we make a distinction by calling the agents Alice
@xmath and Alice @xmath (Bob @xmath and Bob @xmath ).

While it is entirely possible to discuss multiagent commitment schemes
without any reference to complexity theory, we feel it is beneficial to
explain where the idea of employing multiple agents originally came
from. We explain how such models arose in the context of interactive
proofs [ Bab85 , GMR85 , BGKW88 ] and we discuss connections between
zero-knowledge proofs and cryptography [ GMW86 , BGKW88 , Gol08 ] . We
also consider a multiagent variant of oblivious transfer and present a
(trivial) protocol that implements it. This serves as a useful example
to demonstrate that the functionality implemented in the multiagent
scenario might differ significantly from the original primitive.

When it comes to analysing multiagent commitment schemes one of the
major conceptual challenges is to establish a framework which
encompasses all interesting schemes without being overly complicated.
While for a particular scheme it is fairly straightforward to come up
with an ad hoc treatment and security definition (which is often left
implicit), a general framework is necessary for comparing various
schemes. We propose such a framework based largely on results published
in Ref. [ KTHW13 ] .

Outline: We start by explaining the concept of an interactive proof
system and why employing multiple agents makes the model significantly
more powerful. Then we discuss how such models can be used in the
context of cryptography using distributed oblivious transfer [ NP00 ] as
an example. The last section of the chapter is dedicated to multiagent
commitment schemes. We explain what kind of arrangements of agents are
useful for the purpose of commitment schemes and propose how to quantify
security in these new, multiagent models.

### 3.1 Interactive proof systems

The purpose of this section is to give a brief, non-technical
introduction to the field of interactive proof systems. We are
particularly interested in multiprover models ² ² 2 In the context of
complexity theory, it is always the prover (one of the involved parties)
who is required to delegate multiple agents. , zero-knowledge proofs and
their relation to cryptography. The notes of Oded Goldreich [ Gol08 ]
provide a thorough and accessible introduction to interactive proof
systems. Readers interested in the early history of interactive proofs
are referred to a wonderfully entertaining essay by László Babai [ Bab90
] .

Let us start with a motivating story. Suppose that Bob wants to be
convinced that a certain statement is true. His own computational powers
are limited (so he cannot simply verify the statement on his own) but he
has access to an all-powerful computer called Alice. Unfortunately,
Alice is a malicious machine and she will always assert that the
statement is true (even if it is actually false). To make things worse
she will even provide an incorrect proof, hoping that Bob will fall for
it. Bob wants to interact with Alice in such a way that if she is honest
and the proof is correct he accepts it, but if she misbehaves and
outputs an incorrect proof her misconduct should be noticed. On a more
fundamental level, we are asking whether it is possible to verify
computations that are, by assumption, beyond our own capabilities.

Since we always assume that Alice knows the statement that Bob wants to
be convinced of, she might simply produce a proof and send it to Bob.
This coincides with the way we usually think of proofs as static,
non-interactive objects, e.g. something that can be published in a book.
This is a valid solution but we know from everyday experience that the
process of learning and understanding is often facilitated by the
possibility of asking questions and receiving answers. The same
phenomenon occurs in case of proofs and gives rise to the concept of an
interactive proof , which cannot be published in a book but can be
explained in class. It turns out that allowing Alice and Bob to interact
might significantly simplify certain proofs. Moreover, as
counter-intuitive as it sounds it allows Alice to prove a statement
without revealing anything about the actual proof. In complexity theory
the setting described above is known as an interactive proof system ,
with Alice being the prover and Bob the verifier , and was introduced
independently by Babai [ Bab85 ] and Goldwasser, Micali and Rackoff [
GMR85 ] .

To demonstrate the advantage of interactive proofs we need some concrete
statements, which we will then construct (interactive) proofs for. It
turns out that graph theory is a good source of intuitive and
interesting examples. Given two graphs @xmath and @xmath we say that
they are isomorphic if we can map @xmath onto @xmath by simply
relabelling the vertices. The problem of deciding whether two graphs are
isomorphic is known as the graph isomorphism problem and we do not know
how to solve it efficiently. ³ ³ 3 In fact, it is one of the few
interesting problems that seem to sit in the middle between the “easy
problems” (i.e. the ones that can be solved efficiently) and the really
hard ones (i.e. the ones that we do not think can be solved efficiently,
like the travelling salesman problem). Interested readers are encouraged
to read a survey by Scott Aaronson on the distinction between the easy
and the hard problems and how they relate to physical reality [ Aar05 ]
.

This is exactly the setting we want to look at: Bob has two graphs
@xmath and @xmath and he wants to know whether they are isomorphic.
Since he is unable to solve this problem on his own, he asks Alice for
help. If the graphs are isomorphic Alice simply sends Bob a valid
relabelling (of vertices) and he verifies that it indeed maps @xmath
onto @xmath . This is an efficient, non-interactive proof. The problem
becomes a bit more complex if the graphs are not isomorphic. Alice
could, of course, write down all possible relabellings and show that
none of them achieves the goal but this does not really save Bob any
computational effort. Verifying such a brute-force “proof” is not any
easier than producing it. As of today, we do not know how to
(generically) construct a non-interactive, efficient proof that two
graphs are not isomorphic.

On the other hand, a beautifully simple solution exists if Alice and Bob
are allowed to interact [ GMW86 ] . Bob picks a random bit @xmath ,
applies a random relabelling to @xmath and sends it to Alice, whose task
is to guess @xmath . If the graphs are not isomorphic then Alice can
always correctly identify the original graph (she is all-powerful so she
can simply try all possible relabellings) and successfully answer Bob’s
challenge. On the other hand, if the graphs are isomorphic then by
applying a random relabelling Bob made the message that Alice receives
independent of @xmath . ⁴ ⁴ 4 More precisely, the probability
distributions over graphs sent to Alice are identical for @xmath and
@xmath . Hence, her probability of guessing @xmath correctly is exactly
@xmath . If we repeat this game multiple times the probability of
correctly answering all the challenges decays exponentially. If Alice
can reliably tell the two graphs apart, then Bob should be convinced
that the two graphs are not isomorphic (except for exponentially small
probability).

The connection between interactive proofs and cryptography appears when
we impose an additional requirement that the proof should carry no
information beyond the validity of the statement . This concept
introduced by Goldwasser, Micali and Wigderson goes under the name of a
zero-knowledge proof [ GMW86 ] . Note that this formulation sounds
suspiciously similar to our initial motivation for commitment schemes in
Section 1.1 , in which Alice wants to prove to Bob that she knows
something without revealing any additional information.

Let us go back to the problem of proving that two graphs are isomorphic.
The obvious solution presented before is to provide a valid relabelling
explicitly. Unfortunately, this reveals much more information than
necessary: we want to prove the existence of a relabelling rather to
exhibit a particular one. Can we prove that two graphs are isomorphic in
a zero-knowledge manner? Clearly, this cannot be done using a static
proof but adding interactions helps as demonstrated below. ⁵ ⁵ 5
Requiring a static proof to be zero-knowledge reduces it to a trivial
assertion “this statement is true”, which the verifier will not find too
convincing.

Again, we assume that Alice knows both graphs @xmath and @xmath . She
applies a random relabelling to @xmath and sends it to Bob as @xmath .
Bob chooses a random bit @xmath and challenges Alice to reveal the
relabelling that maps @xmath onto @xmath . Clearly, if @xmath and @xmath
are isomorphic Alice can always produce a valid answer. However, if they
are not, she can find a valid answer to at most one of the two
challenges (regardless of how she chose @xmath ). Again, by repeating
this test a number of times Bob can be convinced that the two graphs are
indeed isomorphic. Why is this proof zero-knowledge? This is clear if
Bob acts honestly (i.e. he chooses the bit @xmath at random), because
then at the end of the protocol we can see @xmath as a random
relabelling of @xmath . This is something that Bob could have generated
himself, hence, he has obtained no extra knowledge. The situation
becomes more complex if we consider malicious Bob who might choose
@xmath based on the graph @xmath he receives. A rigorous proof that this
protocol remains zero-knowledge in this adversarial scenario is
significantly more involved [ GMW86 ] .

Once we know how to prove that two graphs are isomorphic in a
zero-knowledge manner it is natural to ask what other statements can be
proven in such a way. If we are happy to accept an extra computational
assumption then it turns out that any statement that can be proven using
a static proof can also be proven in a zero-knowledge fashion [ GMW86 ]
. Ben-Or, Goldwasser, Kilian and Wigderson realised that the
computational assumption can be dropped by introducing an extra prover
(who is not allowed to communicate with the first one during the
protocol) and, in fact, their solution is quite simple [ BGKW88 ] .
Before the protocol begins the provers generate a long, random string.
During the protocol all the work is done by Prover @xmath , while Prover
@xmath simply outputs segments of the shared randomness (randomly chosen
by the verifier). Essentially, the goal is to convince the verifier that
Prover @xmath is using genuine, pre-existing randomness rather than
generating (faking?) it on the spot. As a crucial step in the proof they
propose a bit commitment scheme in the two-prover model and prove its
security. They also present a construction for a particular flavour of
distributed oblivious transfer.

The observation that computational security in Ref. [ GMW86 ] is used to
provide commitment-like functionality is made explicit in Construction
2.4 from Goldreich’s lecture notes [ Gol08 ] , in which a generic
zero-knowledge proof is constructed under the assumption that commitment
functionality is available for free. This shows that the primitive of
bit commitment establishes a connection between zero-knowledge proofs
and multiprover models.

Multiprover models were introduced to remove computational assumptions
in the context of zero-knowledge proofs but have since become an
independent object of study in complexity theory. In fact, they have
been shown to be significantly more powerful than the single-prover
class [ FRS94 , BFL91 ] . The quantum versions of these complexity
classes have been proposed by allowing the provers to share entanglement
either with [ KM02 ] or without [ CHTW04 ] quantum communication (with
the verifier). The two classes have recently been shown to be equal [
RUV13 ] .

### 3.2 Applications in cryptography

We have seen that introducing multiple provers is useful in the context
of interactive proofs and now we would like to see what can be gained in
cryptography. Here, we consider a simple example and our main goal is to
convince the reader that such models are not subject to the usual
impossibility arguments and explain why that is the case.

Let us go back to the primitive of oblivious transfer explained by the
example of an online movie service in Section 1.1 . Alice has paid for
one movie and wants to download it without revealing her choice to the
company (Bob). In spirit of the previous section we consider a
multiagent model in which Bob is required to delegate two agents, who
interact with Alice but cannot communicate with each other. In the
original primitive Bob should never find out which movie Alice chose to
download. However, in the multiprover setting an interesting question
arises: what happens to the agents after the protocol ends? Since it is
hard to envision keeping them isolated until the end of time, we may
first lean towards a model in which they are allowed to communicate
after the protocol is finished. However, as pointed out in Appendix A.2
of Ref. [ BGKW88 ] in that case secure oblivious transfer is not
possible. Temporary communication constraints are not sufficient as the
standard no-go argument applies whenever the agents meet: if their
combined knowledge does not allow them to deduce which message was
retrieved, both messages must have leaked out to Alice. ⁶ ⁶ 6 It is
possible to retain some security if we assume that the amount of
communication between the provers is bounded [ BGKW88 ] .

This encourages us to investigate the other extreme case in which the
provers are not allowed to ever communicate again. ⁷ ⁷ 7 Note, however,
a certain conceptual weakness of this model. The only manner in which
Alice can ensure that the two agents never communicate again is to keep
at least one of them isolated forever. But in that case it should not
matter if that particular agent finds out which movie she wants to
watch, hence, no cryptography is necessary. Note that keeping an agent
isolated forever sounds morally wrong if we think of him as a human
being but becomes more socially acceptable if we replace him by a
disposable electronic device. Unfortunately, while in case of a human
agent the assumption that he will only allow Alice to retrieve one movie
is natural (an agent is capable of protecting the integrity of his
laboratory), in case of an inanimate device this becomes essentially a
technological assumption. Such devices have been proposed under the name
of one-time memories [ GKR08 ] . Such a primitive is known as
distributed oblivious transfer [ NP00 ] (or symmetrically-private
information retrieval if we focus on the limit of a large number of
messages [ GIKM00 , Mal00 , Gas04 , KdW04 ] ) and it admits the
following simple solution based on secret sharing ⁸ ⁸ 8 We only use the
simplest type of secret sharing in which an unknown string @xmath is
split up into two shares: @xmath and @xmath , where @xmath is a string
chosen uniformly at random. The two shares together allow us to
reconstruct the string but it is easy to verify that having just one
share conveys no information about @xmath . . For simplicity let us
consider the case of Bob having only two messages @xmath .

Protocol 1: Distributed oblivious transfer

1.  (prepare) Bob generates an @xmath -bit string @xmath uniformly at
    random and sends @xmath to Bob @xmath and @xmath to Bob @xmath .

2.  (execute) Alice chooses a random bit @xmath and requests @xmath from
    Bob @xmath . To retrieve @xmath she requests @xmath from Bob @xmath
    and computes the message as @xmath .

This protocol is secure because both Bob @xmath and Bob @xmath see Alice
asking for a random message so neither of them obtains any knowledge
about her choice. Moreover, it is easy to verify that no information is
leaked about the message that Alice did not choose. Hence, this
constitutes a secure multiagent implementation of oblivious transfer.
However, as discussed in Section 4.1 we do not know how to usefully
implement this protocol in a relativistic setting.

Why does such a protocol evade the standard no-go result ⁹ ⁹ 9 The
intuition behind the standard no-go argument in the classical case is as
follows. If at the end of the protocol Bob cannot tell which message
Alice has decided to retrieve it must mean that through the interaction
he has leaked both of them. In a world split only between Alice and Bob
whatever Bob leaks becomes immediately available to Alice, which implies
that she must have learnt both messages. ? It is important to realise
that the no-go implicitly assumes that the whole world is split between
Alice and Bob and there are no third parties: Alice can only be sure
about the systems in her possession and everything else is fully
controlled by Bob (this is equivalent to the assumption that the state
shared between Alice and Bob is pure). In the multiagent model this must
be modified as the state is now shared between Alice, Bob @xmath and Bob
@xmath . Since Bob @xmath and Bob @xmath cannot communicate (their
knowledge cannot be combined), the usual impossibility argument does not
apply.

### 3.3 Commitment schemes

The original zero-knowledge interactive proof proposed by Ben-Or et
al. relies on a multiagent bit commitment scheme [ BGKW88 ] . The
proposed scheme is correct, hiding and @xmath -binding for @xmath . On
the other hand, in Section 2.5.2 we have argued that in the standard
two-party model such schemes cannot exist.

Again, we must realise that the standard notion of a commitment scheme
implicitly assumes that the protocol is executed by two parties only (no
additional agents) and the impossibility result only holds for that
case. Multiagent schemes require new security definitions and in general
the usual limitations (proven in the standard two-party model) will not
apply. While it is usually clear how security definitions should be
extended to multiagent protocols, it is important to do it explicitly,
as it helps to understand the exact nature of the primitives under
consideration.

Requiring a party to delegate agents who are not allowed to communicate
(which we also refer to as splitting ) restricts the range of actions
available to that party. Clearly, this might only be useful for security
purposes if communication constraints apply during the relevant party’s
“turn to cheat”. According to the phase structure discussed in Section
2.5 , this leads to either splitting Bob until the opening point (which
we call @xmath -split) or splitting Alice from the commitment point (
@xmath -split). ¹⁰ ¹⁰ 10 Note that these are the minimal splits,
i.e. they are necessary to evade the impossibility result. Later we will
consider models which impose more than the minimal splits. The two
different splits are shown in Fig. 3.1 . Since we are interested in the
fundamental possibilities and limitations, we will discuss protocols for
both splits (and we will find that the resulting bit commitment
primitives exhibit subtle differences).

Before proposing particular protocols, let us first adapt the security
definitions to such multiagent scenarios. Since security requirements
state what the dishonest party should not be able to achieve, it is
clear that we need a new definition of the hiding property in the @xmath
-split and a new definition of the binding property in the @xmath
-split.

A commitment scheme is hiding if at the opening point Bob remains
ignorant about Alice’s commitment. In the @xmath -split model at the
opening point there are two agents Bob @xmath and Bob @xmath , who are
not allowed to communicate. Similarly to the case of distributed
oblivious transfer if we require that even their combined knowledge does
not allow them to learn the commitment, then the standard no-go applies
(i.e. Alice can cheat with certainty). However, we can instead require
that neither Bob @xmath nor Bob @xmath can guess the commitment, which
leads to a natural condition closely resembling Definition 2.2 .

###### Definition 3.1.

A multiagent bit commitment protocol is hiding if all pairs of states
@xmath that Bob @xmath and Bob @xmath can enforce at the opening point
satisfy

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

This definition means that neither of the agents has learnt anything
about Alice’s commitment but it says nothing about their combined
knowledge. This naturally leads to the following protocol based on
secret sharing. For bit commitment protocols we adopt the convention
that @xmath ( @xmath ) denotes to the private randomness of Alice (Bob)
while @xmath ( @xmath ) are the messages sent during the protocol by
Alice (Bob). Note that the labels @xmath and @xmath are used regardless
of whether the parties are honest or not.

Protocol 2: Bit commitment from secret sharing

1.  (commit) Alice generates a random bit @xmath , sends @xmath to Bob
    @xmath and @xmath to Bob @xmath .

2.  (open and verify) Bob @xmath and Bob @xmath get together and compute
    the commitment as @xmath .

This protocol is so simple that neither party can even attempt to cheat!
In the commit phase whatever combination of messages Alice decides to
produce, it will correspond to an honest commitment, which she has no
influence over once the messages are received by Bob @xmath and Bob
@xmath (i.e. this is exactly the commitment point of the protocol). On
the other hand, if Alice is honest then both Bob @xmath and Bob @xmath
receive a uniform bit (regardless of the value of @xmath ) so the
protocol is hiding according to Definition 3.1 .

A potential drawback of this protocol is that in certain scenarios, we
might want to give Alice the right to refuse opening a commitment.
Clearly, in this protocol this could only be done if Bob @xmath and Bob
@xmath were never allowed to communicate again, which is a problematic
assumption (cf. footnote 7 in Section 3.2 ).

It turns out that this feature (of allowing Alice to keep the commitment
value hidden forever) is much easier to achieve in the @xmath -split
model. As explained in Section 2.5.1 security for honest Bob can be
quantified through a game in which Alice performs some generic strategy
until the commitment point and is then challenged (by an external
referee) to open either @xmath or @xmath with equal probabilities. The
commitment is considered secure if she is not able to win this game with
probability significantly exceeding @xmath (an honest commitment
achieves at least @xmath as long as the scheme is correct). In case of
Alice @xmath and Alice @xmath performing the open phase in a
non-communicating fashion, we need to specify who actually receives the
challenge. Is it both Alice @xmath and Alice @xmath or just, say, Alice
@xmath ? The former scenario might arise if Alice @xmath and Alice
@xmath despite not being able to communicate with each other might still
receive messages from an external source (it might be easier to isolate
the agents from each other than from the external world). For example,
what they attempt to unveil might depend on the latest stock market
news. It turns out that this distinction is important and gives rise to
two different models, which we call global and local command ,
respectively. This choice does not affect Alice @xmath : in both cases
her cheating behaviour is determined by two compatible strategies ¹¹ ¹¹
11 See Section 2.5.1 for an explanation what it means for two strategies
to be compatible. , just like in the standard single-agent model.
However, the allowed behaviour of Alice @xmath is affected. In the
global command model she chooses two compatible strategies but in the
local command she may only choose one (since she never actually finds
out what they are trying to unveil).

###### Definition 3.2.

Let @xmath be a pair of states that Alice @xmath and Alice @xmath can
enforce at the opening point given that Alice @xmath employs two
compatible strategies and Alice @xmath employs

-    local command: only one strategy (regardless of the value of @xmath
    ).

-    global command: two compatible strategies.

Let @xmath be opening maps of the form

-    local command: @xmath .

-    global command: @xmath .

Define @xmath to be the probability that Alice’s attempt to unveil
@xmath is accepted by Bob

  -- -------- --
     @xmath   
  -- -------- --

A multiagent bit commitment protocol is called @xmath -binding in the
local/global command model if for all states @xmath and for all opening
maps @xmath allowed by the model we have

  -- -------- --
     @xmath   
  -- -------- --

To see that the distinction between the two models is important, note
that the local command model allows for the following trivial bit
commitment protocol.

Protocol 3: Bit commitment in the local command model

1.  (commit) Alice sends @xmath to Alice @xmath and Alice @xmath .

2.  (open) Alice @xmath sends @xmath and Alice @xmath sends @xmath to
    Bob.

3.  (verify) Bob verifies that @xmath .

In the local command model dishonest Alice @xmath receives the challenge
and knows what they are trying to unveil but Alice @xmath does not.
Since the value they are challenged to unveil is chosen uniformly at
random, she cannot guess it too well. In fact, the best she can do is to
always output the same value, which essentially corresponds to an honest
commitment. Here, security is a direct consequence of the fact that
Alice @xmath does not know what she is supposed to be unveiling. It is
clear that in this protocol Alice is committed as soon as communication
between Alice @xmath and Alice @xmath is forbidden. Protocol 3 is secure
in the local command model but it is easy to see that it is completely
insecure in the more stringent global command model. Does there exist a
protocol that remains secure in the global command model?

It turns out that no classical protocol in the @xmath -split model can
meet this requirement and the argument is similar to the standard no-go
for bit commitment. Let us assume that the protocol is correct and
hiding, i.e. it allows Alice @xmath and Alice @xmath to make an honest
commitment, which until the opening point leaks no information to Bob
and the opening is always accepted. Suppose Alice @xmath and Alice
@xmath honestly commit to @xmath . Clearly, unveiling @xmath in the open
phase is easy but since Bob cannot rule out Alice’s commitment to @xmath
, there must also exist a sequence of messages from Alice @xmath and
Alice @xmath which will make him accept @xmath . Since now both of them
know what they are trying to unveil, this strategy can be implemented
and the protocol is completely insecure.

The intuitive argument presented above makes a subtle assumption that
all information that Alice and Bob exchange in the commit phase is
available to both Alice @xmath and Alice @xmath in the open phase. There
are two ways of invalidating this assumption.

1.  Make the information that Bob shares with Alice in the commit phase
    quantum. Then, by the no-cloning theorem [ WŻ82 ] it will not (in
    general) be possible for both Alice @xmath and Alice @xmath to have
    an exact copy.

2.  Strengthen the communication constraint, i.e. require that only
    Alice @xmath takes part in the commit phase while Alice @xmath is
    already isolated.

The first solution was explored under the name of quantum relativistic
bit commitment by Kent [ Ken11 , Ken12b ] and a rigorous security
analysis of the latter protocol (including experimental imperfections
like noise and losses) can be found in Chapter 5 of this thesis.
Moreover, two new protocols based on different features of quantum
theory were recently proposed [ AK15a , AK15b ] . The second solution
corresponds to the original proposal of Ben-Or et al. [ BGKW88 ] ,
further developed in Refs. [ Sim07 , CSST11 ] . Since the protocol is
simple and intuitive we present it here but we defer rigorous security
analysis until Chapter 6 .

The bit commitment scheme proposed in Ref. [ BGKW88 ] is sufficient from
the complexity point of view but it is not the most convenient
formulation for cryptographic purposes. As described in Section 2.4 in
cryptography it is convenient to have a family of protocols with a
parameter @xmath which can be chosen to guarantee the desired level of
security. Such a protocol was presented under the name simplified-BGKW (
sBGKW ) in Refs. [ Sim07 , CSST11 ] . In this case Alice @xmath and
Alice @xmath are not allowed to communicate throughout the entire
protocol. Let @xmath and @xmath be @xmath -bit strings chosen uniformly
at random by Alice and Bob, respectively.

Protocol 4: Simplified-BGKW

1.  (commit) Bob sends @xmath to Alice @xmath and she replies with
    @xmath .

2.  (open) Alice @xmath reveals @xmath to Bob.

3.  (verify) Bob verifies that @xmath .

(The bit-by-string multiplication was defined in Section 2.1.1 .) In a
protocol which requires Alice @xmath and Alice @xmath to be already
isolated in the commit phase, it becomes important whether the value of
the commitment must be known to both or just one of them. In this
particular case Alice @xmath can single-handedly decide on the value of
the commitment. ¹² ¹² 12 It is interesting to note that Alice @xmath
(the only agent of Alice who takes part in the open phase) does not need
to know the value she is unveiling. Correctness of the protocol is easy
to verify while the hiding property is a simple consequence of the fact
that the message that Alice @xmath sends to Bob in the commit phase is
“one-time padded” with a uniformly random string. On the other hand, we
intuitively see that the binding property is a direct consequence of the
communication constraint between Alice @xmath and Alice @xmath (cheating
would be easy if Alice @xmath knew @xmath ). Moreover, note that in this
protocol Alice @xmath can simply refuse to take part in the open phase
and then the commitment made by Alice @xmath (if she indeed followed the
protocol in the commit phase) will remain secret forever. In this
aspect, this protocol differs significantly from Protocol 2 . This
difference will have quite interesting consequences when we consider
relativistic variants of these protocols in Section 4.1 .

## Chapter 4 Relativistic protocols

This chapter is based on

-    Secure bit commitment from relativistic constraints [ arXiv:
    1206.1740 ]
    J. Kaniewski, M. Tomamichel, E. Hänggi and S. Wehner
    IEEE Transactions on Information Theory 59 , 7 (2013).
    (presented at QCrypt ’12 )

In Chapter 3 we saw that communication constraints are useful in a
variety of situations. In particular, they enable us to implement
cryptographic primitives which are not possible otherwise.
Non-communicating models are widely studied in computer science but
unless one can justify such communication constraints, they should be
treated on equal footing with other technological limitations and we
already know that assumptions concerning computational power or storage
capabilities make two-party cryptography possible.

How could Alice possibly ensure that Bob @xmath and Bob @xmath cannot
communicate? Well, in principle she could lock each of them up in
separate rooms. First of all, Bob @xmath and Bob @xmath might not be
happy with such a solution but even if they are, how does she ensure
that the rooms are perfectly shielded from the outside world? Does this
not lead to yet another technological assumption?

One way out of the vicious circle of technological assumptions is
relativity. Imposing an upper bound on the speed at which information
spreads implies that communication between any two distinct locations
incurs some minimal delay (proportional to the distance between them).
This gives rise to temporary communication constraints, which rely
solely on the correctness of the theory of relativity. It is worth
pointing out that this is the only feature of relativity used in
relativistic cryptography.

It is important to stress the difference between non-communicating and
relativistic protocols. In a non-communicating protocol (like the ones
discussed in Chapter 3 ) we first explicitly specify communication
constraints and then the interactions between the agents. On the other
hand, in a relativistic protocol one cannot simply impose such arbitrary
communication constraints. Instead, they must arise from the arrangement
of agents in space and appropriately chosen timing of the protocol.
Therefore, the description of the protocol must specify where and when
each interaction takes place and then the resulting communication
constraints may be used to prove security. Note that not every
combination of communication constraints might be achieved in this
model, e.g. if Alice simultaneously communicates with Bob @xmath and Bob
@xmath , they must be able to communicate too.

To the best of our knowledge, the idea of combining relativity and
quantum mechanics for cryptographic purposes first appeared in writing
in a summary article by Gilles Brassard and Claude Crépeau [ BC96 ,
Cré96 ] , who attributed it to Louis Salvail. The foundations were laid
by Adrian Kent (first relativistic commitment schemes [ Ken99 , Ken05 ]
) and Roger Colbeck (proposals for various flavours of coin-tossing and
impossibility results for secure two-party computation [ Col06 , CK06 ,
Col07 ] ). More recently, significant interest was sparked by
position-verification schemes [ KMS11 , BCF @xmath 11 , TFKW13 , Unr14 ,
RG15 ] . A relativistic quantum key distribution scheme has also been
proposed [ RKKM14 ] .

The defining feature of relativistic cryptography is the requirement
that different phases of the protocol take place at distinct locations.
With the appropriate choice of timing this imposes communication
constraints, which are no longer due to technological limitations but
result directly from the physical theory (security of such schemes is
often advertised to be “guaranteed by the laws of physics”).
Unfortunately, this desirable feature comes at a price. Communication
constraints guaranteed by relativity are temporary , which means that we
must leave the neat and tidy world of non-communicating models, in which
we are free to impose arbitrary communication constraints, and enter the
complex world of relativistic models, in which communication is only
delayed rather than forbidden . ¹ ¹ 1 It is useful to contrast this
aspect of relativistic models with the non-communicating case. In the
non-communicating world we can choose whether or not the agents are
allowed to communicate once the protocol is finished and both options
are equally valid. In the relativistic setting there is only one natural
solution, which lies somewhere in between the two extremes: the agents
can communicate but their communication is not instantaneous. The
analysis of such scenarios becomes significantly more involved if the
agents are required to handle quantum information (or when dishonest
parties use quantum devices to cheat in a classical protocol). In fact,
this has led to interesting and fundamental questions about how to
define the location of a quantum system. Consider the process of
teleportation [ BBC @xmath 93 ] , in which a quantum state @xmath
located initially at one place is reconstructed at another place by
using entanglement (pre-shared between the two locations) and sending
classical data. Interestingly enough, during this procedure there is a
period of time when the state seemingly “ceases to exist”, in the sense
that there is no location at which any information about @xmath can be
immediately extracted. Where is the state then? This counter-intuitive
phenomenon is captured operationally through the task of summoning
recently investigated by Kent [ Ken13 , Ken12a ] , Hayden and May [ HM12
] .

Outline: In this chapter we first show how some of the protocols
discussed in Chapter 3 can be implemented in the relativistic setting
and what limitations such a “translation” brings about. We then present
an explicit procedure for mapping a relativistic protocol onto a
communication-constrained model. We show that in the fully classical
setting communication-constrained models can be further mapped onto
non-communicating models and we discuss why such a simplifying reduction
cannot be done when quantum information is involved. Finally, we discuss
the power and limitations of relativistic cryptography.

### 4.1 Non-communicating schemes in the relativistic setting

We start by considering how some of the non-communicating schemes
discussed in Chapter 3 can be implemented in the relativistic setting.
Since the communication constraints imposed by relativity are temporary,
the resulting commitment schemes cannot guarantee everlasting security.
² ² 2 Unless the parties keep communicating, see Section 4.3 for more
details. Understanding exactly the “mode of failure”, i.e. how different
commitment schemes “expire”, provides valuable insight into the power of
relativistic cryptography.

The only realistic implementation of a relativistic protocol involves
stationary agents exchanging information at the speed of light. The
protocol specifies a set of locations and each party is required to
delegate a (stationary) agent to each location. All communication
between Alice and Bob occurs locally, i.e. between agents occupying the
same location, and for simplicity we assume that all local communication
is instantaneous. ³ ³ 3 Note that this is the only reasonable model. If
an agent of Alice were to send a message to a far-away agent of Bob, she
would either have to “escort” the message until it reaches the agent of
Bob (which is equivalent to placing an extra agent at the receiving end
as in our model) or she would let the message out unguarded, in which
case there is no guarantee that the message will not be intercepted by
some other agent of Bob at some earlier location. Communication between
distinct agents of the same party is unrestricted (and assumed to be
secure) but must respect the speed-of-light constraint (for simplicity
we take @xmath ). ⁴ ⁴ 4 Security of internal communication can be
ensured by using teleportation to transmit quantum states and
information-theoretic encryption (one-time pad) for classical
information. Alternatively, we can assume that distinct agents occupy
different locations within the same laboratory (e.g. the model of two
long laboratories in a single spatial dimension as in Section 1.7.2 and
Fig. 1.6 of Ref. [ Col06 ] ).

All examples considered in this thesis take place in a single spatial
dimension labelled by @xmath and as usual time is labelled by @xmath .
All considerations in this chapter extend in a straightforward fashion
to more spatial dimensions but we are not aware of any examples in which
this gives any advantage. We label the locations by integers and refer
to the agents occupying Location @xmath as Alice @xmath and Bob @xmath .
For convenience we define the following three locations.

  ------------ --------
  Location 0   @xmath
  Location 1   @xmath
  Location 2   @xmath
  ------------ --------

It is important to bear in mind that in relativistic protocols all the
interactions are performed by agents occupying well-defined locations.
We avoid referring to the main party (whose location during the protocol
is not specified) as it might create the impression that there exists
some higher form of life that is able to instantaneously communicate
with all its agents. The existence of such a being is forbidden by
relativity and would indeed render all the relativistic protocols
insecure.

Let us first present a relativistic variant of Protocol 2 . Before the
protocol begins Alice @xmath and Alice @xmath must be provided with a
random bit @xmath (e.g. generated by Alice @xmath at @xmath ).

Protocol 5: Bit commitment from secret sharing (relativistic)

1.  (commit) At @xmath , Alice @xmath sends @xmath to Bob @xmath and
    Alice @xmath sends @xmath to Bob @xmath . Bob @xmath and Bob @xmath
    immediately send @xmath and @xmath to Bob @xmath .

2.  (open and verify) At @xmath , Bob @xmath receives @xmath and @xmath
    and computes the commitment as @xmath .

In a sense this protocol is easier to understand than the original,
non-communicating version (cf. the spacetime diagram in Fig. 4.1 ). It
is clear that Alice becomes committed at @xmath (the commitment point)
and that the commitment becomes known to Bob (Bob @xmath to be more
specific) at @xmath (the opening point), hence, the commitment is valid
for @xmath . On the other hand, in the non-communicating variant it is
not a priori clear when (and why!) communication constraints vanish and
the commitment opens. Just like in Protocol 4 , Alice @xmath can
single-handedly decide on the commitment and the choice can be delayed
until @xmath .

Our second example is a relativistic variant of Protocol 4 . This time
Alice @xmath and Alice @xmath must share a random @xmath -bit string
@xmath .

Protocol 6: Simplified-BGKW (relativistic)

1.  (commit) At @xmath , Bob @xmath sends @xmath to Alice @xmath and she
    replies with @xmath . Bob @xmath immediately sends @xmath to Bob
    @xmath .

2.  (open) At @xmath , Alice @xmath reveals @xmath to Bob @xmath .

3.  (verify) At @xmath , Bob @xmath receives @xmath and verifies that
    @xmath .

Just like in Protocol 4 , Alice @xmath can choose the value of the
commitment single-handedly and this choice can be delayed until @xmath
(Alice @xmath does not need to know it). The requirement that the open
phase happens at @xmath ensures that no signals can be sent between the
commit and open phases (cf. Fig. 4.2 ). It is easy to see that Alice
@xmath could cheat perfectly if she knew @xmath so the timing must be
chosen such that @xmath , which is announced by Bob @xmath at @xmath ,
is not available to Alice @xmath during the open phase. Under this
condition the relativistic protocol and the original, non-communicating
version are equivalent as far as security is concerned.

Note that in this relativistic scheme there is always a non-zero delay
in verifying the commitment but it can be made arbitrarily small. ⁵ ⁵ 5
The possibility of immediate verification of the opening would imply
that the commit phase and the open phase are not space-like separated.
Then, there would have been enough time for @xmath to reach Alice @xmath
, which would render the protocol insecure. Whether this constitutes a
severe limitation or not depends on the particular application but this
feature, which appears often in relativistic protocols, should be always
kept in mind, especially when considering composability (i.e. executing
a relativistic scheme as a subroutine in a longer procedure).

It is instructive to consider what happens if for some reason the open
phase does not happen in the interval @xmath . At @xmath dishonest Alice
@xmath receives @xmath (sent by dishonest Alice @xmath at @xmath ) and
at this point she can provide a valid proof for either value of @xmath ,
which makes the protocol completely insecure. In other words, the
commitment expires at @xmath and no opening should be accepted at (or
after) that point. If Alice @xmath does not perform the opening during
@xmath , Bob will never find out whether Alice @xmath made an honest
commitment, let alone its value.

Having presented two cases in which non-communicating protocols can be
turned in a straightforward manner into relativistic protocols, let us
briefly discuss one case in which such a simple translation is not
possible. Recall Protocol 1 for distributed oblivious transfer presented
in Section 3.2 . Security of this protocol hinges on the assumption that
Bob @xmath and Bob @xmath cannot communicate from the beginning of the
protocol until the end of time. We know that permanent communication
constraints cannot be enforced by relativity so we cannot hope for
everlasting security but temporary security is not immediately ruled
out. To restrict communication between Bob @xmath and Bob @xmath we
would have to place them at distant locations, as usual accompanied by
their communication partners Alice @xmath and Alice @xmath . During the
protocol each Alice receives a single message and the message that they
actually want to obtain is the XOR of the two. Unfortunately, the
earliest point at which the transmitted message might be reconstructed
coincides with the point at which the information gathered by Bob @xmath
and Bob @xmath can be recombined to reveal which message Alice chose to
retrieve (the spacetime diagram is essentially identical to the one
shown in Fig. 4.1 ). We could have hoped for some finite interval during
which Alice already knows the message but Bob still remains ignorant
about her choice but in case of Protocol 1 this is not possible. This
shows that not all non-communicating protocols can be mapped directly
onto the relativistic setting in a meaningful way.

### 4.2 Explicit analysis of relativistic protocols

We have seen how simple non-communicating protocols can be implemented
in the relativistic setting but so far the security analysis was rather
ad hoc. While this is sufficient for simple schemes, for more complex
protocols (involving more agents and/or multiple rounds, which might be
necessary to achieve improved security features, e.g. longer commitment
time) a systematic approach is desirable. In this section we provide a
solution to a subclass of these problems and discuss the complications
arising while dealing with the most general case.

A relativistic protocol is classical if all the messages exchange
between agents of Alice and agents of Bob are classical. A protocol is
quantum if there is at least one quantum message. Since classical
protocols are designed to be executed by classical parties they should
not require the agents of Alice or Bob to perform quantum operations in
the honest scenario . However, this cannot be ruled out in the dishonest
case and it is natural to study the security of classical protocols
against quantum adversaries.

We first consider classical protocols and we show that analysing the
dishonest scenario is equivalent to a certain multiplayer game with
partial communication constraints ⁶ ⁶ 6 Similar models have been
previously studied from the foundational point of view under the name of
time-ordered models [ GWC @xmath 14 ] or correlation scenarios [ Fri12 ,
Fri14 ] . played by the agents of the dishonest party. ⁷ ⁷ 7 Note that
this procedure is not specific to commitment schemes and applies to any
relativistic protocol in which cheating can be cast as a game. In
Section 4.2.1 we show that if the agents are restricted to classical
strategies, the situation is equivalent to a multiplayer game of
non-communicating players. In Section 4.2.2 we mention some
complications that arise when analysing such games against quantum
players. Finally, in Section 4.2.3 we discuss briefly the problems
related to quantum relativistic protocols.

For the sake of concreteness let us consider the case of honest Alice.
Since the agents of Alice follow the protocol, we might think of them as
an omnipresent referee, who interacts with the agents of Bob. The
following simple procedure explains how to turn a relativistic protocol
into a multiplayer game (similar to those described in Section 2.3 )
such that winning the game is equivalent to cheating in the protocol.

1.  Identify all points of spacetime at which the agents of Alice and
    Bob interact, order them by their time coordinate and label by
    (positive) integers. ⁸ ⁸ 8 For interactions occurring at the same
    time the order does not matter. Without loss of generality we assume
    that every interaction consists of a challenge from Alice followed
    by a response from Bob, which for the @xmath interaction are denoted
    by @xmath and @xmath , respectively. ⁹ ⁹ 9 If the protocol requires
    more rounds of communications in a sequence, consider them as
    separate interactions. Let @xmath be the spacetime coordinates of
    the @xmath interaction and let @xmath be the total number of
    interactions in the protocol. Construct the communication graph
    @xmath , in which each vertex corresponds to an interaction and the
    set of (directed) edges is determined by the causality constraints.
    More precisely, @xmath is an edge iff @xmath is in the future light
    cone of @xmath

      -- -------- --
         @xmath   
      -- -------- --

    Note that @xmath is an oriented and acyclic graph.

2.  Without loss of generality the challenge issued by Alice in the
    @xmath interaction is a deterministic function of some pre-shared
    randomness (represented by a random variable @xmath ) and the
    previous responses of Bob. For a particular value of the random
    variable @xmath we have

      -- -------- --
         @xmath   
      -- -------- --

    (Clearly, @xmath might not depend on the responses which do not
    belong to the past light cone of the @xmath interaction but to keep
    the notation simple we do not indicate this restriction explicitly.)
    The collection of functions @xmath together with the probability
    distribution of @xmath fully determines the distribution of
    challenges issued by Alice.

3.  Deciding whether a cheating attempt is successful, i.e. the
    predicate function for the game, might without loss of generality be
    taken to depend only on the initial randomness and the responses
    from Bob, i.e. @xmath .

This procedure provides us with three components: the communication
graph, the distribution of challenges and the predicate function.
Clearly, this triple defines a multiplayer game in which communication,
instead of being completely forbidden, is restricted. More specifically,
we can identify the @xmath interaction with a player @xmath and starting
from @xmath every player takes part in the following procedure.

1.  Player @xmath receives messages sent by previous players.

2.  Player @xmath receives a challenge @xmath and issues a response
    @xmath .

3.  Player @xmath might send a message to any player @xmath such that
    @xmath .

At the end all the answers are collected and the predicate function
@xmath is evaluated to determine whether the game is won or lost.

Since quantum communication can be implemented by teleportation (and we
do not impose any restrictions on the amount of entanglement shared by
the players) we can assume all communication to be classical.

Let us summarise what we have accomplished so far. We have started from
a classical relativistic protocol and we have turned it into an
equivalent classical multiplayer game with communication constraints.
Note that by classical we mean that all the challenges and responses are
classical but this does not prevent the players from using quantum
systems to generate them. As discussed in the next section, the case of
quantum players (i.e. players using quantum systems to generate their
classical responses) is significantly harder to analyse than the case of
classical players.

Note that multiplayer games with communication constraints include many
interesting scenarios as special cases. For example if @xmath (i.e. the
communication graph @xmath has no edges) we recover the standard
scenario of multiplayer non-communicating games. The other extreme case
is when the players satisfy a “total order”, i.e. @xmath , which is
equivalent to a single player responding to a sequence of challenges.
This is exactly the scenario that arises in classical non-relativistic
two-party cryptography. ¹⁰ ¹⁰ 10 These two special cases have also been
studied if the challenges and/or responses are quantum. For some recent
results on two-player quantum games see Refs. [ RV13 , CJPPG15 ] while
for sequential quantum games see papers on quantum non-relativistic
two-party cryptography listed in Section 1.3 .

#### 4.2.1 Classical players

Any strategy available to classical players can be expressed as a convex
combination of deterministic strategies. Since randomness can be shared
among the players in advance and their goal is to achieve the optimal
winning probability (which is determined by a fixed and known function),
we might restrict our attention to deterministic strategies. What is the
most general strategy of @xmath , i.e. what is his response allowed to
depend on? Clearly, it might depend on the challenge that he receives
@xmath but it might also depend on messages received by him from the
‘‘previous’’ players. This seems to complicate the situation, since
these might be arbitrary and depend on anything that was available to
the sender, etc. However, a simple observation allows us to simplify
this seemingly complicated structure. Since the message sent by a
particular player is a function of the data available to him, he could
alternatively send the whole data set to the receiver, who can then
generate the message himself. This leads to the simple conclusion that
it is optimal ¹¹ ¹¹ 11 Optimal in the sense of spreading information to
the largest number of players, certainly not in terms of efficiency. to
broadcast any challenge received from the referee to all eligible
players. Then the response of @xmath becomes a deterministic function of
all the challenges in his past . If we supply every player with these
additional inputs, they no longer need to communicate. This reduction
works because there exists a trivial but optimal communication strategy
for the players, namely “broadcast everything”.

###### Observation 4.1.

Let @xmath be the game in which @xmath receives @xmath and the allowed
communication pattern is specified by @xmath . Let @xmath be the game in
which @xmath receives @xmath where

  -- -------- --
     @xmath   
  -- -------- --

and no communication is allowed @xmath . The sets of strategies
available to the classical players in games @xmath and @xmath are
identical.

This observation plays a crucial role in the analysis of a multiround
classical relativistic bit commitment protocol in Chapter 6 .

#### 4.2.2 Quantum players

We have seen that for classical players games with communication
constraints can be reduced to fully non-communicating games. What
happens if we attempt such a reduction for quantum players?

As one might expect the quantum case is not so simple and it is
instructive to consider the following example. Consider a game of three
players where @xmath contains only one edge, @xmath . Clearly, @xmath
cannot communicate with the other players but his presence is necessary
to hope for a quantum advantage. ¹² ¹² 12 Without @xmath we would have a
game equivalent to asking a sequence of classical questions to a single
player and in such games no quantum advantage is possible. The response
of @xmath is determined by some measurement he performs on his quantum
system (and the measurement setting depends on the challenge @xmath ).
Then he passes whatever is left of the quantum system along with the
classical messages @xmath and @xmath to @xmath who then receives @xmath
and completely measures the quantum system to obtain @xmath .

This scenario is difficult to analyse because the measurement performed
by @xmath affects how much information @xmath (who learns a new piece of
information @xmath ) might extract from the state. This problem goes
under the name of sequential measurements and is currently an active
area of research [ HM15 ] . Note that in the classical setting such
trade-offs do not exist: generating the response for the current round
does not affect the information that might be sent to other players.

To the best of our knowledge, this is the simplest example in which
finding the quantum value of a classical game cannot be reduced to any
of the previously studied models. Interestingly enough, this is
precisely the scenario which arises when analysing security of the
multiround protocol presented in Chapter 6 against quantum adversaries.

#### 4.2.3 Quantum relativistic protocols

While presenting the procedure to map a relativistic protocol onto a
communication-constrained model, we have explicitly restricted ourselves
to classical protocols. This was mainly to avoid the trouble of
specifying the most general way in which the referee may choose the
challenge. While this is conceptually not difficult, formalising these
notions would be quite cumbersome. In particular, we would need to
explicitly define the Hilbert spaces corresponding to the referee’s
memory, the ‘‘message’’ space, define the class of operations the
referee might use to prepare the challenge, argue what the new predicate
is, etc. ¹³ ¹³ 13 Note that as a special case we must recover the
standard model for quantum protocols of Yao [ Yao95 ] , which puts a
lower bound on the complexity of the description.

While mapping a quantum relativistic protocol onto a quantum game is not
difficult, we do not know how to analyse the resulting “quantum” games.
Without aiming for full generality let us just sketch out two quantum
games, which demonstrate difficulties that might arise in these
scenarios.

The first game is a variation on the example presented in the previous
section. Basically, by making the first challenge @xmath quantum we can
eliminate @xmath without trivialising the problem. Consider a game of
two players @xmath such that @xmath . The challenge received by @xmath
is an unknown quantum state and he is required to give a classical
response @xmath . @xmath passes the remaining quantum state together
with his classical response to @xmath , who receives a new (classical)
challenge and must produce another classical response. Clearly, the
information extractable in the second round depends on the measurement
performed in the first one, hence, the two rounds cannot be decoupled
and mapped onto a non-communicating model. Games of this type arise when
considering quantum non-relativistic protocols.

The second game is arguably the simplest manifestation of no-cloning.
Consider a game of three players whose communication graph contains two
edges: @xmath . The challenge issued to @xmath is an unknown quantum
state and no response is required. Players @xmath and @xmath are then
challenged to unveil one out of two incompatible properties of the
original state. Clearly, this would be easy if each of them could hold a
copy of the original state but this is forbidden by the no-cloning
theorem. One solution is for @xmath to measure one of the two properties
and send the classical outcomes to @xmath and @xmath . However, this
only allows them to answer one of the challenges correctly. This is
exactly the quantum feature used in Kent’s quantum relativistic bit
commitment protocol [ Ken12b ] , whose complete analysis can be found in
Chapter 5 .

### 4.3 Limitations of relativistic cryptography

We have made contributions towards understanding of relativistic
commitment schemes but in general the exact power of relativistic
cryptography is not yet completely understood. The goal of this section
is to summarise what is known to be possible and what the known
limitations are. It turns out that between the two there is a sizeable
piece of land yet to be discovered.

Let us start with the simplest task: coin tossing. The trivial classical
protocol (described for example as Protocol 2.3 in Ref. [ Col06 ] ), in
which Alice @xmath sends a random bit to Bob @xmath and simultaneously
Bob @xmath sends a random bit to Alice @xmath and the outcome of the
coin toss is the XOR of the two bits, achieves perfect security and is
easily implemented in the simplest relativistic model with just two
locations. More sophisticated flavours of coin tossing, in which Alice
and Bob can partially influence the bias of the coin, are also possible
[ Col06 ] .

The situation becomes a bit more complicated when it comes to bit
commitment. All the commitment protocols we have discussed so far expire
in some way: in case of Protocol 5 the commitment automatically opens,
in case of Protocol 6 the commitment vanishes. In principle these
commitments can be made arbitrarily long but only at the price of
increasing the spatial separation between the sites. This is clearly not
a desirable solution, since in practice we are restricted to a fixed
region of space (we have easy access to the surface of the Earth but
going beyond that seems somewhat impractical). Can we achieve an
arbitrarily long commitment while performing the protocol in a finite
region of space? Let us first consider protocols in which the commit
phase only requires a finite amount of communication, i.e. at some point
the communication stops and no more messages need to be exchanged until
the open phase. It is clear that at that point both parties could bring
all their systems together and within some period of time (proportional
to the size of the accessible region of space) we would be back in the
standard scenario, in which the usual trade-offs apply. Hence,
arbitrarily long commitment cannot be achieved by a protocol with a
bounded number of messages in the commit phase. What about protocols in
which the agents keep communicating? The multiround scheme presented in
Chapter 6 belongs to this class and implements bit commitment which is
secure against classical adversaries and can be made arbitrarily long.
We conjecture that the protocol remains secure against quantum
adversaries but we currently do not have a proof.

Commitments with a finite period of validity (which at some point
expire) have been previously studied under the name of timed commitments
. For example Boneh and Naor [ BN00 ] study commitments which fail in
the same way as Protocol 5 , i.e. after some fixed time the committed
value is revealed to Bob. ¹⁴ ¹⁴ 14 Their motivation comes from schemes
which only offer computational security. Such schemes can always be
forced open given enough time and computational power. They show that
such commitments can be used for contract signing or honesty-preserving
auctions. Generally speaking, such temporary secrecy is sufficient if
the goal is to force parties to act simultaneously (in the sense that
their respective actions should not depend on each other) even if the
communication model is sequential. Broadbent and Tapp considered the
task of secure voting, for which such commitments would be sufficient [
BT08 ] . Timed commitments that vanish (i.e. the commitment is no longer
valid but the committed value, if there was one, remains secret) can be
used in similar situations if we want to give Alice more power to
protect her privacy. This type of commitment might also be used in
multiparty protocols which are robust against a certain fraction of
dishonest parties (then any party that refuses to open the commitment
would be declared dishonest).

To see the limitations of relativistic commitment schemes it is
instructive to investigate whether they can be used to implement other,
more powerful primitives. For example, a well-known construction shows
how to use bit commitment and quantum communication to implement
oblivious transfer [ BBCS92 , Yao95 ] . Are relativistic schemes
suitable for this canonical construction? Without going into too many
details let us describe one important feature of this construction. At
some point of the procedure Bob is required to make several commitments.
Later, Alice asks Bob to open a random subset of them but the rest he
keeps untouched. Security for Bob hinges on the fact that some
commitments remain closed, which rules out relativistic schemes that
expire by opening (like Protocol 5 ). The commitments that vanish
without revealing any information (like Protocol 6 ) might seem
perfectly suited for the task. However, a simple conceptual problem
referred to as classical certification or retractability arises [ Ken12c
, Col06 ] . Basically, the canonical construction implicitly assumes
that every commitment (including the unopened ones) has a value . While
it might not be immediately clear what it means for an unopened
commitment to have a value, this concept can be made rigorous and it is
possible to show that relativistic protocols do not satisfy this
property. A more detailed discussion on the issue of classical
certification of relativistic commitment schemes and an explicit example
how it renders the canonical construction insecure can be found in
Appendix A . While this is by no means a proof that no relativistic
commitment scheme can be used for the canonical construction, we have at
least ruled out the ones considered so far.

What about implementing relativistic oblivious transfer directly without
going through canonical construction? This possibility seems unlikely
due to the following informal argument. In every (correct) oblivious
transfer protocol at some fixed point Alice must receive the chosen
message. At this point the knowledge of Alice (or Bob) might be
scattered among all their agents but in an attempt to cheat it can be
(within some finite time) gathered at one location and then the usual
impossibility results apply. Investigating whether this intuition can be
turned into a rigorous argument would be an interesting research problem
for two reasons: it would require us to propose a meaningful definition
of relativistic oblivious transfer and the actual impossibility result
(if true) would determine an important boundary point of quantum
relativistic cryptography. Alternatively, one can relax the requirements
and look for a protocol whose security is only guaranteed for a finite
period of time. Such protocols might exist and it would be interesting
to know how useful they are.

## Chapter 5 Bit commitment by transmitting measurement outcomes

This chapter is based on

-    Experimental bit commitment based on quantum communication and
    special relativity [ arXiv: 1306.4801 ]
    T. Lunghi, J. Kaniewski, F. Bussières, R. Houlmann, M.
    Tomamichel, A. Kent, N. Gisin, S. Wehner and H. Zbinden
    Physical Review Letters 111 , 180504 (2013).
    (presented at QCrypt ’13 )

In the previous chapters we have seen why non-communicating models are
useful in cryptography and how such models can be implemented using
relativity. In this chapter we use the tools introduced before and
present a complete analysis of a particular quantum relativistic bit
commitment protocol proposed by Kent [ Ken12b ] . Our initial approach
to this problem, presented in Ref. [ KTHW13 ] , relied on some tools
from non-asymptotic quantum information theory and a recently discovered
uncertainty relation [ TR11 , Tom12 ] . Later, however, we found
another, simpler approach (which does not explicitly use any uncertainty
relation), which we then extended to apply to experimental
implementations [ LKB @xmath 13 ] . In this chapter we only present the
latter, superior method. Note that similar techniques found applications
to other interesting problems in quantum cryptography [ TFKW13 ] .
(During the lifetime of these projects an independent security analysis
of the same protocol was provided by Croke and Kent [ CK12 ] and an
independent experiment was performed by Liu, Cao, Curty, Liao, Wang,
Cui, Li, Lin, Sun, Li, Zhang, Zhao, Chen, Peng, Zhang, Cabello and Pan [
LCC @xmath 14 ] ).

Outline: We start by proving security of the original protocol. Our
methods are robust, as they also apply to the case of imperfect state
preparation and noisy transmission. This would be sufficient to prove
security of an implementation that uses a single-photon source, a
lossless quantum channel and perfect detectors (or devices which are
good approximations thereof). Unfortunately, such devices are not
available at the moment, hence, we modify the protocol so it can be
implemented using currently available devices, in our case a
weak-coherent source and inefficient and noisy detectors. We describe
the new security model, extend the previous security analysis and
determine the minimum requirements on the honest devices that allow for
a secure implementation of the protocol. We also present an explicit
calculation of the security parameter of the protocol. We finish this
chapter by giving a brief overview of an experiment performed between
Geneva and Singapore in collaboration with an experimental group at the
University of Geneva.

### 5.1 The original protocol

We use the following notation for the BB84 states

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

where @xmath . For a sequence of BB84 states described by @xmath we use

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

For a particular basis string @xmath we define @xmath and @xmath to be
the rounds in which Alice encoded her qubits in the computational and
Hadamard basis, respectively,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

The protocol proposed by Kent [ Ken12b ] uses the same locations as
described in Section 4.1 and Fig. 5.1 shows the relevant spacetime
diagram. The parameter @xmath determines the usual cost vs. security
trade-off (see Section 2.4 ), while @xmath specifies the noise tolerance
of the protocol. Recall that @xmath is the fractional Hamming distance
(defined in Section 2.1.1 ).

Protocol 7: Bit commitment by transmitting measurement outcomes

1.  (commit) At @xmath , Bob @xmath chooses @xmath uniformly at random,
    creates @xmath and sends it to Alice @xmath . Alice @xmath measures
    all the incoming qubits in the same basis (computational if @xmath
    and Hadamard if @xmath ) to produce @xmath (the string of
    measurement outcomes), which she then sends to Alice @xmath and
    Alice @xmath .

2.  (open) At @xmath , Alice @xmath and Alice @xmath simultaneously send
    @xmath and @xmath to Bob @xmath and Bob @xmath , respectively.

3.  (verify) Bob @xmath and Bob @xmath pass all the information to Bob
    @xmath , who verifies that:

    -   Alice @xmath and Alice @xmath have attempted to unveil the same
        value

    -   Alice @xmath and Alice @xmath have provided exactly the same
        string @xmath

    -   the string @xmath is consistent with the BB84 states initially
        prepared by Bob @xmath up to the error threshold @xmath

          -- -------- -------- --
             @xmath   @xmath   
             @xmath   @xmath   
          -- -------- -------- --

    If all three conditions are satisfied, Bob @xmath accepts the
    commitment.

Before we proceed with a complete analysis let us mention a couple of
unusual features of the protocol.

First of all, it seems that Alice becomes committed without actually
sending any information to Bob (no communication from Alice to Bob
happens until the open phase). Is that possible? How can Bob be sure
that for @xmath Alice is indeed committed?

To answer this question it is instructive to consider a slight variation
on Protocol 7 , in which the open phase is delayed until @xmath .
Clearly, in this case Alice @xmath could keep the quantum states
untouched until @xmath and only then perform the measurement. For this
modified protocol Alice only becomes committed at @xmath , which does
not occur immediately after the communication in the commit phase is
over (as was the case in all the previous protocols).

This quantum protocol challenges the preconception that the timing of
the commitment point is determined by the interactions in the commit
phase. Strangely enough, in this case the commitment point is determined
by the timing of and locations used in the open phase. In fact, it is
easy to see that the commitment point is determined by the latest point
in the common past of the openings performed by Alice @xmath and Alice
@xmath .

Protocols discussed in Section 4.1 result in commitments which are only
valid for a finite amount of time (in case of Protocol 5 the commitment
at some point automatically opens while in case of Protocol 6 at some
point security for honest Bob is lost). It is interesting to note that
the quantum commitment scheme we consider now does not expire. A
commitment initiated at @xmath may be opened at any @xmath but a
successful opening only demonstrates that Alice was committed for @xmath
. It is important to stress that at @xmath Alice is not yet committed,
so we must take the commitment point to be @xmath , where @xmath is an
arbitrarily small (but non-zero) constant.

Finally, let us point out that verifying whether an opening should be
accepted or not is not immediate. Moreover, in contrast to Protocol 6 ,
the delay cannot be made arbitrarily small. Since the conditions that
Bob needs to verify depend on data unveiled at both opening locations,
the delay is proportional to the distance between them.

#### 5.1.1 Correctness

Correctness in the noiseless setting is clear by inspection while for an
experimental implementation the only relevant quantity turns out to be
the total bit-flip error rate between (honest) Alice and Bob (this rate
includes contributions coming from imperfect state preparation,
transmission noise and measurement errors). For simplicity we assume
that noise acts independently on every qubit. Let @xmath be the bit-flip
error rate, i.e. the probability of obtaining the wrong outcome despite
the qubit having been prepared and measured in the same basis. ¹ ¹ 1 If
the error probabilities are different for the two bases, we take the
larger value to be on the safe side. The protocol is asymptotically
correct (i.e. the probability of honest parties aborting decays
exponentially in @xmath ) if

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

Note that this depends solely on the numerical value of @xmath and not
on the exact effects that contribute to it.

#### 5.1.2 Security for honest Alice

Since Bob receives no information before the open phase, he remains
completely ignorant about Alice’s commitment and so the protocol is
hiding.

#### 5.1.3 Security for honest Bob

To investigate security for honest Bob we first turn the original
prepare-and-measure scheme of Kent into an entanglement-based scheme
(equivalence for security purposes was explained in Section 2.2.3 ). In
the entanglement-based formulation instead of generating BB84 states Bob
@xmath generates EPR pairs, he keeps one half of each (to be measured
later) and sends the other halves to Alice @xmath . The most general
attack performed by Alice @xmath during the commit phase is to perform
an isometry that “splits up” the entire quantum system received from Bob
@xmath into two parts, which she then sends to Alice @xmath and Alice
@xmath . In the open phase, Alice @xmath and Alice @xmath measure their
respective quantum systems and pass the outcomes to Bob @xmath and Bob
@xmath , respectively.

Since we want to prove security with respect to the global command
variant of Definition 3.2 let us spell out how this definition applies
to the protocol. ² ² 2 Security in the local command can be achieved by
the trivial Protocol 3 , cf. Section 3.3 .

First, we need to characterise the set of states that Alice @xmath might
enforce at the commitment point. While at @xmath the state is (without
loss of generality) only shared between Alice @xmath and Bob @xmath , at
the commitment point ( @xmath ) the share of Alice @xmath is already
explicitly split up into two parts (that will reach Alice @xmath and
Alice @xmath in time for the open phase) and this partitioning is
essential to determine the commitment. We denote the relevant subsystems
by @xmath and @xmath (even if at the commitment point these subsystems
are not with the agents Alice @xmath and Alice @xmath yet). It is
straightforward to see that at the commitment point any tripartite state
@xmath can be enforced as long as the marginal state held by Bob @xmath
remains unchanged, i.e.

  -- -------- --
     @xmath   
  -- -------- --

Interestingly enough, our proof does not make use of this property. In
other words, the protocol remains secure even if Alice @xmath were
allowed to provide an arbitrary tripartite state compatible with the
measurements that Bob @xmath will later perform (i.e. the subsystem of
Bob @xmath must consist of @xmath qubits).

In the open phase Alice @xmath and Alice @xmath must provide proofs,
which are just classical strings of length @xmath . Hence, the opening
maps correspond to measurements. Each of Alice @xmath and Alice @xmath
has two different measurements used to unveil the two different values
of the commitment and we denote the measurement operators of Alice
@xmath (Alice @xmath ) attempting to unveil @xmath by @xmath ( @xmath )
. Since we do not impose any constraints on the local dimensions of
@xmath and @xmath we may without loss of generality assume that these
measurements are projective. The fact that Alice @xmath might use
different measurements for @xmath and @xmath indicates that we work in
the global command model.

If @xmath is the basis string (picked by Bob @xmath uniformly at
random), then his measurement is described by operators @xmath as
defined in Eq. ( 5.2 ). The commitment is accepted if the strings
supplied by Alice @xmath and Alice @xmath are consistent with the
classical outcomes obtained by Bob @xmath . This condition can be
written as a projector acting on the original tripartite state and it is
easy to see that the projector @xmath corresponding to Bob @xmath
accepting the unveiling of @xmath for a particular basis string @xmath
equals

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

and the three registers correspond to the subsystems held by Bob @xmath
, Alice @xmath and Alice @xmath , respectively (and the latter two
result from an isometry applied by Alice @xmath to subsystem @xmath ,
which she received in the commit phase). These projectors require that
Alice @xmath and Alice @xmath unveil the same string, which on the
relevant subset ( @xmath for @xmath and @xmath for @xmath ) is @xmath
-close (in terms of fractional Hamming distance) to the string obtained
by Bob. To calculate the probability of successfully unveiling @xmath we
must average over all possible basis choices

  -- -------- --
     @xmath   
  -- -------- --

In fact, our technique allows us to generalise the definition ( 5.1 ) to
any pair of bases on a qubit

  -- -------- --
     @xmath   
  -- -------- --

This requirement comes directly from the fact that the equivalence
between prepare-and-measure and entanglement-based schemes as presented
in Section 2.2.3 only applies if the average state is fully mixed. It
turns out that the final bound depends only on the overlap between the
bases

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

which is a well-known measure of incompatibility used extensively in the
study of uncertainty relations [ Deu83 , MU88 , BCC @xmath 09 , TR11 ] .

###### Proposition 5.1.

Let

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the overlap as defined in Eq. ( 5.4 ). For any strategy
of dishonest Alice, the probabilities of Bob accepting the commitment
satisfy

  -- -------- --
     @xmath   
  -- -------- --

for

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

###### Proof.

Let us write the sum out explicitly

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

Adding up the two projectors (for a particular value of @xmath ) gives

  -- -------- --
     @xmath   
  -- -------- --

The terms in the square bracket can be upper bounded by replacing one of
the measurement operators by the identity matrix. Therefore,

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where the last step follows from the following operator inequality

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

which holds for any @xmath . Therefore,

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

where

  -- -------- --
     @xmath   
  -- -------- --

is a projector for the “cross-game”, in which Alice @xmath has to unveil
a string consistent with @xmath and Alice @xmath has to unveil a string
consistent with @xmath . ³ ³ 3 Our security analysis goes through a
thought experiment in which Alice @xmath and Alice @xmath are challenged
to unveil different bits and in the current method this connection is
made through the operator inequality ( 5.7 ). Interestingly enough, our
previous method relies on the same idea but expressed at the level of
no-signalling probability distributions (see Lemma V.1 of Ref. [ KTHW13
] ). Combining Eqs. ( 5.6 ) and ( 5.8 ) gives

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes averaging over @xmath , i.e. @xmath , and @xmath
denotes the Schatten @xmath -norm (defined in Section 2.2.1 ). Changing
the order of summation in @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

Now, it is clear that only the @xmath -dependent part needs to be
averaged:

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

Since the product @xmath yields orthogonal projectors, we have

  -- -------- -- -------
     @xmath      (5.9)
  -- -------- -- -------

To identify values of @xmath and @xmath which maximise the norm we take
a closer look at the matrices @xmath . For every @xmath define @xmath to
be the string that satisfies @xmath and @xmath . Relabelling @xmath
yields

  -- -------- --
     @xmath   
  -- -------- --

The constraints on the second sum can be relaxed by noting that @xmath
and @xmath imply @xmath . Therefore,

  -- -------- --
     @xmath   
  -- -------- --

which makes the second sum independent of @xmath . Hence, the summation
over @xmath can be performed first and due to the tensor product
structure we have

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Therefore,

  -- -------- --
     @xmath   
  -- -------- --

where

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Note that @xmath so they are diagonal in the same basis.
Therefore, without loss of generality we can write

  -- -------- --
     @xmath   
  -- -------- --

for @xmath , where @xmath . In particular, we have

  -- -------- --
     @xmath   
  -- -------- --

Therefore, we also know the eigenbasis of

  -- -------- --
     @xmath   
  -- -------- --

and the largest eigenvalue equals

  -- -------- --
     @xmath   
  -- -------- --

Recall from Eq. ( 5.9 ) that the expression we want to bound is

  -- -------- --
     @xmath   
  -- -------- --

It is clear that every bit of @xmath and @xmath should be chosen to
satisfy @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Finally, since we know that

  -- -------- --
     @xmath   
  -- -------- --

we obtain the security guarantee of the form

  -- -------- --
     @xmath   
  -- -------- --

For @xmath there is only one term in the sum while for @xmath we use the
Chernoff bound (Lemma 2.2 ) to obtain the final result of the lemma. ∎

The protocol is secure as long as @xmath , which combined with Eq. ( 5.3
) implies that correctness and security is possible as long as

  -- -------- --
     @xmath   
  -- -------- --

This allows us to check whether a particular experimental setup
(characterised by @xmath and @xmath ) allows for a secure implementation
of the protocol. For example, if the source emits perfect BB84 states
(or, in fact, any two mutually unbiased bases on a qubit) we can
tolerate up to @xmath of errors.

### 5.2 Modelling imperfect devices

While we have allowed our states to be imperfect and undergo some noise
process in transit, we have implicitly assumed that every time Bob
@xmath pushes a button a qubit in a well-defined state is sent towards
Alice @xmath , who always detects it to obtain a particular classical
outcome. As of today there is no physical system which matches this
idealised description to a reasonable degree. Therefore, in
collaboration with an experimental group at the University of Geneva, we
have developed a new version of the protocol, which can be implemented
using currently available devices.

First of all, instead of a single-photon source we use a weak-coherent
source with phase randomisation ⁴ ⁴ 4 We have decided to use phase
randomisation because then the number of photons in a pulse can be
modelled as a classical random variable, which turns out to be
convenient for the security analysis. , which emits pulses of light in
which the number of photons is a Poisson-distributed random variable.
Let @xmath be the Fock state of @xmath photons and @xmath be the average
number of photons per pulse (an adjustable parameter of the source).
Then, the ensemble emitted by a weak-coherent source can be written as

  -- -- --
        
  -- -- --

A direct consequence of this model is that some pulses might contain
more than one photon and we refer to those as multiphoton emissions .
Such pulses constitute a deadly threat to our protocol since Alice
@xmath could measure the first photon in the computational basis, the
second photon in the Hadamard basis and, hence, obtain enough
information to open either value with certainty. Clearly, multiphoton
emissions do not contribute to security and so their number must be
rigorously controlled.

Besides the imperfections of the source, there is also a certain
probability that a photon might be lost either in transit or during the
detection process. Let @xmath be the detection efficiency , i.e. the
probability that a photon sent by Bob @xmath is detected by Alice @xmath
. We assume that the loss process affects every photon independently so
the number of photons detected by Alice @xmath is, again, a
Poisson-distributed random variable. The probability of detecting @xmath
photons equals

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

We assume that the detection efficiency depends neither on the
measurement setting nor on the incoming state. Note that while this is a
natural assumption from the theoretical point of view, it does not
always hold for an experimental setup (it is common to have slightly
different detection efficiencies for measurements in different bases)
and this issue needs to be addressed while analysing experimental data
as explained in Section 5.4 . Moreover, it has recently been
demonstrated that strong pulses of light might allow Bob to learn some
information about Alice’s basis setting [ LWW @xmath 10 ] , which is not
included in our analysis.

We follow the standard approach (presented in Section 2.4 ), i.e. we
assume that the devices used by the honest party are trusted (their
characterisation including any imperfections is known) but the dishonest
party is limited only by the laws of physics. The following table lists
the models used for each of the three distinct scenarios.

  Alice       Bob         source                 losses           errors
  ----------- ----------- ---------------------- ---------------- --------
  honest      honest      weak-coherent source   yes              yes
  honest      dishonest   perfect                detectors only   N/A
  dishonest   honest      weak-coherent source   no               no

### 5.3 Protocol with backreporting

If we try to implement the original protocol using the equipment
described above, we run into a very simple problem: in most rounds Alice
@xmath simply does not see a click (either because the photon was never
emitted or it was not detected). What is she supposed to do then? One
solution would be to simply generate a random bit and act as if this was
the outcome of the measurement. This solution works as long as losses
are infrequent and can be “hidden” within the error threshold. However,
in the experimental setup described above losses are extremely common.
In fact, it is the detection events that are rare. Therefore, flipping a
coin for every loss is not a feasible solution.

We solve this problem using a standard technique known as backreporting
, which requires Alice @xmath to inform Bob @xmath at the end of the
quantum exchange which rounds were successful (i.e. a photon was
detected) and only these rounds are used for the protocol (all the
remaining data is discarded). This clearly restores correctness but,
unfortunately, it opens a new security loophole as dishonest Alice
@xmath might also backreport single-photon rounds in order to increase
the contribution of multiphoton emissions, which she can win with
certainty. To avoid this threat Bob @xmath must carefully monitor the
number of rounds backreported by Alice. Let @xmath be the set of rounds
in which Alice @xmath observed a click, which we call the valid set .
Bob @xmath only continues with the protocol if the size of the valid set
exceeds a certain threshold, @xmath , where @xmath is an adjustable
parameter of the protocol called the detection threshold .

Protocol 8: Bit commitment by transmitting measurement outcomes with
backreporting

1.  (commit) At @xmath , Bob @xmath chooses @xmath uniformly at random,
    creates @xmath and sends it to Alice @xmath . Alice @xmath measures
    all the incoming qubits in the same basis (computational if @xmath
    and Hadamard if @xmath ) . The rounds in which a click was observed
    form @xmath and @xmath is the string of outcomes. Alice @xmath
    announces @xmath to Bob @xmath . Bob @xmath continues with the
    protocol only if @xmath .

2.  (open) At @xmath , Alice @xmath and Alice @xmath simultaneously send
    @xmath and @xmath to Bob @xmath and Bob @xmath , respectively.

3.  (verify) Bob @xmath and Bob @xmath pass all the information to Bob
    @xmath , who verifies that:

    -   Alice @xmath and Alice @xmath have attempted to unveil the same
        value

    -   Alice @xmath and Alice @xmath have provided exactly the same
        string @xmath

    -   the string @xmath is consistent with the BB84 states initially
        prepared by Bob @xmath up to the error threshold @xmath

          -- -------- -------- --
             @xmath   @xmath   
             @xmath   @xmath   
          -- -------- -------- --

    If all three conditions are satisfied, Bob @xmath accepts the
    commitment.

#### 5.3.1 Correctness

To guarantee correctness we must first ensure that Alice registers a
sufficient number of clicks. Asymptotically, we simply require that the
probability of seeing a click (i.e. detecting at least one photon) is
larger than the detection threshold

  -- -------- --
     @xmath   
  -- -------- --

Using Eq. ( 5.10 ) to express @xmath in terms of @xmath and @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

Since in our model errors are independent of losses or multiphoton
emissions, the second correctness condition remains the same as before,
i.e. Eq. ( 5.3 ).

#### 5.3.2 Security for honest Alice

Since backreporting introduces communication from Alice @xmath to Bob
@xmath in the commit phase, security for honest Alice is no longer
unconditionally true. To make sure that the valid set @xmath does not
contain any information about the commitment we must ensure that the
detection efficiencies do not depend on the basis choice regardless of
the state that the dishonest Bob @xmath sends in. We assume that the
detection system used by Alice satisfies these properties (see Section
5.2 ).

#### 5.3.3 Security for honest Bob

Security analysis for honest Bob is an extension built on top of the
previous argument. We take advantage of the fact that all the
experimental imperfections (e.g. multiphoton emissions or no-detection
events) can be modelled as classical random variables and that for
particular values of these random variables Proposition 5.1 provides an
explicit security bound.

In every round a certain number of photons (between @xmath and @xmath )
is emitted (recall that in this case we assume that Alice @xmath has
perfect detectors, i.e. @xmath ). Pulses with no photons affect
correctness but do not constitute a security threat. Pulses with one
photon is what the original protocol calls for and what we analysed in
the previous section. Finally, multiphoton pulses are a serious threat
as they allow Alice @xmath to obtain sufficient information to
successfully open both values of the commitment. To simplify our
analysis we replace all the zero-photon emissions by single-photon
emissions (which only gives Alice more power). Eq. ( 5.10 ) with @xmath
implies that the probability of a multiphoton emission in a particular
round equals

  -- -------- --
     @xmath   
  -- -------- --

The number of multiphoton rounds @xmath is a binomially-distributed
random variable

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

The optimal strategy of dishonest Alice @xmath is to discard as many
single-photon rounds as possible. It is clear that if she can discard
all of them, she is left with multiphoton emissions only and no security
can be guaranteed. Therefore, the necessary condition for security is
that the number of multiphoton rounds is lower than the detection
threshold

  -- -------- --
     @xmath   
  -- -------- --

After using up the entire backreporting allowance the number of valid
rounds equals @xmath but there are only @xmath (which is now guaranteed
to be a positive number) single-photon rounds among them. Honest Bob
believes that they are performing a bit commitment protocol of @xmath
rounds but there is a certain number of multiphoton ones, which Alice
can win “for free”. Hence, she can concentrate her error allowance on
the single-photon rounds and the security we achieve is that of playing
a game of @xmath rounds with the absolute (non-fractional) error
allowance of @xmath , which gives the effective (fractional) error
allowance of

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

The proof in Section 5.1.3 is valid only if the effective (fractional)
error allowance, @xmath , satisfies

  -- -------- --
     @xmath   
  -- -------- --

where @xmath measures the incompatibility of the measurements performed
by Bob @xmath . Hence, in our case we require

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

In the asymptotic limit it is sufficient to look at the expectation
value

  -- -------- --
     @xmath   
  -- -------- --

which substituted into Eq. ( 5.13 ) gives

  -- -------- --
     @xmath   
  -- -------- --

#### 5.3.4 Requirements on the honest devices

Having derived explicit criteria for correctness and security we can
check whether a given experimental setup allows for a secure
implementation of the protocol. The correctness and security constraints
are

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

It is clear that @xmath and @xmath (parameters of the protocol) can be
taken arbitrarily close to the values which would turn the first two
conditions into equalities. This leaves us with only one, but rather
complicated, condition

  -- -------- --
     @xmath   
  -- -------- --

This expression allows us to check whether for devices of certain
quality (quantified by @xmath , @xmath and @xmath ) there exists a value
of @xmath that makes the protocol both correct and secure. ⁵ ⁵ 5 Note
that changing the mean photon number @xmath affects the physical aspect
of the protocol so it might influence other physical parameters like the
error rate. On the other hand, parameters like @xmath or @xmath , which
are only relevant for the post-processing, do not have such an effect.

#### 5.3.5 Explicit security calculation

The asymptotic analysis is relevant as @xmath but in any practical
scenario the number of rounds is finite. Therefore, we want to
explicitly calculate security guarantees as a function of @xmath . Since
correctness is verified experimentally and security for honest Alice is
perfect by assumption, we only need to calculate security for honest
Bob.

Let @xmath denote the event that Alice successfully cheats in the bit
commitment protocol. We have shown in Eq. ( 5.12 ) that the probability
of cheating successfully depends on the number of multiphoton emissions.
Therefore, let us write

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

Equation ( 5.5 ) allows us to bound @xmath as long as the number of
multiphoton emissions is below the threshold. For @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

On the other hand, for @xmath there is no security and the trivial
bound, @xmath , is the best we can hope for. The second term is given by
Eq. ( 5.11 ). Performing the summation ( 5.14 ) for any particular
values of the parameters is a straightforward exercise in any package
for numerical calculations (e.g. Octave [ EBH09 ] ).

### 5.4 Experimental implementation

Protocol 8 requires the use of three equidistant locations on a line.
This is clearly quite difficult to do if we want to take maximal
advantage of the size of the Earth. Therefore, we have implemented a
modified protocol, in which only two locations are used. The experiment
is performed between Geneva (Location 1) and Singapore (Location 2) and
achieves secure commitment for 15.6 ms (the maximal duration achievable
on the Earth, corresponding to antipodal locations on the surface,
equals 21.2 ms). As explained in Section 5.1 the maximal commitment time
equals half the time it takes to travel at lightspeed between the two
opening locations (we cannot rule out the possibility that dishonest
Alice deployed an extra agent exactly in between the two locations, who
receives the quantum states at @xmath and only then performs the
measurements, cf. Fig. 5.2 ).

Each location hosts one agent for each player synchronised to universal
time using a global positioning system (GPS) clocks. The protocol
consists of two parts: (i) exchange of quantum information in the commit
phase and (ii) exchange of classical information in the open phase.
Phase (i) was implemented using a commercial quantum key distribution
system Vectis 5100 from ID Quantique located at the University of Geneva
(see Fig. 5.3 ). This system is based on the two-way “Plug&Play”
configuration [ MHH @xmath 97 ] : strong optical pulses travel from
Alice @xmath to Bob @xmath , who uses them to encode the BB84 states.
Moreover, he attenuates the optical power down to single photon level
and sends these weak-coherent pulses back to Alice @xmath . Trojan-horse
attacks on Bob’s side are particularly effective against the “Plug&Play”
configuration so the power of the incoming beam is continuously
monitored by Bob @xmath . To use the quantum key distribution system for
bit commitment some software changes must be made, in particular
communication from Alice @xmath to Bob @xmath is restricted to
backreporting only. As discussed in Section 5.3.2 extra care has to be
taken to ensure that the backreported data does not leak any information
about the choice of measurements performed by Alice @xmath . In our
experimental setup the two bases exhibit slightly different detection
probabilities so the raw data must be artificially ‘‘equalised’’. ⁶ ⁶ 6
More specifically, with probability @xmath we discard an outcome
obtained for the more efficient setting, where @xmath is chosen to make
the expected number of detections backreported for both settings equal.

The duration of the commitment is ultimately limited by the distance
between the locations under the assumption that all local communication
is instantaneous. However, since the exchange of quantum states in the
commit phase takes a considerate amount of time, which would reduce the
achievable commitment time, we have performed a delayed commitment . In
a delayed commitment scheme Alice @xmath first commits to a random bit
@xmath and only later announces @xmath , which initiates the actual
commitment (and determines its value). This allows us to perform all the
quantum information exchange in advance, which maximises the commitment
time.

Classical information needed by Alice @xmath in Singapore to open the
commitment was transmitted in advance through the internet (one-time-pad
encrypted using pre-shared keys generated by a quantum random generator
from ID Quantique). The classical information exchange in the open phase
was performed using stand-alone computers equipped with
field-programmable gate array (FPGA) to make the transmission time
negligible relative to the commitment time (around 3 @xmath s).

## Chapter 6 Multiround relativistic bit commitment protocol

This chapter is based on

-    Practical relativistic bit commitment [ arXiv: 1411.4917 ]
    T. Lunghi, J. Kaniewski, F. Bussières, R. Houlmann, M.
    Tomamichel, S. Wehner and H. Zbinden
    Physical Review Letters 115 , 030502 (2015).
    (presented at QCrypt ’14 )

The quantum protocol discussed in the previous chapter implements secure
bit commitment in the @xmath -split model (one of the minimal splits, in
which, as discussed in Section 3.3 , no classical protocol can give
security). This demonstrates that quantum protocols are strictly more
powerful and in this particular case the extra power results from the
no-cloning theorem. However, a weak point of that scheme is the length
of the commitment, which is limited by the spatial separation of the two
opening sites. In particular, for a protocol taking place on the Earth,
the commitment time is limited to 21 ms. While this might be sufficient
for some purposes, extending the commitment time would be highly
desirable. It is clear that if the spatial arrangement is fixed, the
only manner to extend the commitment time is to introduce additional
rounds of communication. In fact, this idea was proposed by Kent quite
early on [ Ken99 , Ken05 ] , where instead of opening the commitment
Alice commits to the information she would have used in the unveiling.
The original way of “chaining” commitments has the drawback that the
communication required grows exponentially with the number of rounds [
Ken99 ] . This was later rectified by adding a compression scheme on top
of the protocol [ Ken05 ] . Security of such a chained scheme would
follow directly if the individual commitments were composably secure ¹ ¹
1 In fact, this is exactly the idea of composable security: the protocol
is indistinguishable from the ideal primitive in all possible scenarios
. . However, we do not know how to prove composable security of
relativistic commitment schemes and there is evidence that this might
indeed be impossible (e.g. in Appendix A we show that the classical
relativistic sBGKW scheme is not secure according to the usual
composable definition). Therefore, the security proof must explicitly
consider all the intermediate commitments. Security argument against
classical adversaries presented by Kent [ Ken05 ] is of asymptotic
nature and, therefore, not sufficient for implementation purposes.

Outline: With the goal of finding a new classical multiround protocol in
mind we first revisit the two-round protocol proposed in Ref. [ Sim07 ,
CSST11 ] and show that security for honest Bob relies on the difficulty
of a certain non-local game, whose quantum value was recently
investigated by Sikora, Chailloux and Kerenidis [ SCK14 ] . This
completes the security analysis and shows that the two-round protocol is
secure against quantum adversaries. ² ² 2 Security for honest Alice is
obvious against classical Bob. Security against quantum Bob follows from
a simple observation that if only one agent (Bob @xmath ) is involved in
the commit phase of a classical protocol, no advantage can be gained by
using quantum systems (cf. footnote 12 in Section 4.2.2 ). With the
two-round scheme as our starting point we propose a new classical
multiround protocol (with constant communication rate) and analyse its
security against classical adversaries. ³ ³ 3 For more than two rounds
security analysis against quantum adversaries becomes rather involved as
explained in Section 4.2.2 . Correctness can be verified by inspection,
security for honest Alice is intuitively obvious (nevertheless
formalising it requires some work) and security for honest Bob turns out
to be more involved but we eventually derive an explicit and easily
computable security bound. Unfortunately, the bound suffers from rather
undesirable scaling in the number of rounds (which is proportional to
the length of the commitment). While the commitment time is not subject
to any fundamental limitations, an implementation using standard digital
equipment only allows modest commitment times. In collaboration with the
Geneva group we have implemented the protocol to achieve a secure
commitment of 2 ms. ⁴ ⁴ 4 An attentive reader might be puzzled that the
new multiround protocol yields commitment time which is significantly
shorter than the one previously achieved by the quantum protocol. The
solution of this conundrum is that while the previous experiment was
performed between Geneva and Singapore, the new multiround one was (for
practical reasons) executed between two locations within Switzerland.
Performing the multiround protocol between Geneva and Singapore would
give a commitment time of 156 ms (a tenfold improvement over the quantum
protocol).

Note added: After the completion of this work, two groups independently
provided security proofs that give significantly improved security
bounds [ FF15b , CCL15 ] . These results imply that Protocol 9 can be
used to realise long-lasting commitments with very modest resources,
hence, making it truly practical.

### 6.1 Two-round protocol

Since the two-round protocol has already been discussed in Section 4.1
let us go directly to the security analysis. Recall that the protocol
requires two sites labelled Location 1 and Location 2. To simplify
notation in this chapter we assume that these locations are separated by
@xmath units of length for some @xmath . Therefore, one unit of time is
not sufficient to transmit information between them.

Protocol 6: Simplified-BGKW (relativistic)

1.  (commit) At @xmath , Bob @xmath sends @xmath to Alice @xmath and she
    replies with @xmath . Bob @xmath immediately sends @xmath to Bob
    @xmath .

2.  (open) At @xmath , Alice @xmath reveals @xmath to Bob @xmath .

3.  (verify) At @xmath , Bob @xmath receives @xmath and verifies that
    @xmath .

(Note that the verification step could be performed slightly earlier
using an agent positioned somewhere in between Bob @xmath and Bob @xmath
but since @xmath is chosen to be essentially @xmath this makes no
difference.)

Correctness is straightforward to check and security for honest Alice
comes from the fact that the message that Bob @xmath receives in the
commit phase is one-time-padded with a uniformly random string.

Security for honest Bob is quantified using Definition 3.2 . Since only
one agent (Alice @xmath ) is involved in the open phase, the distinction
between local and global command does not arise. As explained in Section
2.5.1 it is often helpful to explicitly state the cheating game that
Alice attempts to win. In the commit phase Alice @xmath receives @xmath
(chosen uniformly at random) and in the open phase Alice @xmath receives
nothing from Bob but she is challenged to open @xmath chosen uniformly
at random. In each phase she is required to output an @xmath -bit
string, which we denote by @xmath and @xmath , respectively. Since there
is no communication between Alice @xmath and Alice @xmath this is
equivalent to a two-player game which (using the formalism presented in
Section 2.3 ) is specified by the uniform input distribution @xmath and
the predicate function

  -- -------- --
     @xmath   
  -- -------- --

Since this game can be seen as a generalisation of the CHSH game (which
corresponds to @xmath ), let us call it @xmath after Ref. [ SCK14 ] .
Calculating the classical value is straightforward but let us do it
explicitly for completeness.

As explained in Section 2.3 we might without loss of generality assume
that Alice @xmath and Alice @xmath employ deterministic strategies,
which we denote by functions @xmath and @xmath . Define @xmath as the
event over @xmath (private randomness of Bob) that the opening of @xmath
is accepted

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

Since both @xmath and @xmath are defined over @xmath it is meaningful to
talk about @xmath and @xmath . ⁵ ⁵ 5 This is exactly where the argument
breaks down when applied to the quantum world, in which @xmath and
@xmath are not in general defined simultaneously . Note that @xmath .
The event @xmath happens when condition ( 6.1 ) is satisfied for both
values of @xmath . Define @xmath to be the event that the XOR of the two
is satisfied

  -- -------- --
     @xmath   
  -- -------- --

Since the left-hand side is a uniformly distributed random variable and
the right-hand side is a constant @xmath . Moreover, as @xmath we have
@xmath . Combining the two statements implies that for any strategy of
classical Alice we have @xmath which leads to

  -- -------- --
     @xmath   
  -- -------- --

It is easy to check that the trivial strategy of always outputting
@xmath saturates this bound. Intuitively this game should be difficult
because unveiling @xmath and @xmath requires Alice @xmath to know @xmath
and @xmath , respectively. She cannot guess both of these too well since
@xmath is chosen uniformly at random by Bob @xmath .

Applying this reasoning to quantum adversaries is not so straightforward
because Alice @xmath might have two distinct measurements that reveal
@xmath and @xmath , respectively, but they might be incompatible so the
implications on her ability to guess @xmath are not so obvious.
Fortunately, the following bound on the quantum value was recently
proven [ SCK14 ]

  -- -------- --
     @xmath   
  -- -------- --

This is sufficient for our purposes as it implies that

  -- -------- --
     @xmath   
  -- -------- --

for all strategies of dishonest quantum Alice. Therefore, the protocol
is @xmath -binding with @xmath decaying exponentially in @xmath (but
note that the decay rate is half of the decay rate against classical
adversaries).

This is a prime example that analysing classical protocols against
quantum adversaries is not always a futile task and sometimes leads to
interesting observations. An immediate question arises regarding
super-quantum adversaries: what if Alice @xmath and Alice @xmath have
access to stronger-than-quantum correlations? It is straightforward to
see that the protocol is completely insecure against Alice @xmath and
Alice @xmath who have access to no-signalling correlations [ Sim07 ,
CSST11 ] . In fact, it was shown recently that in this particular model
it is not possible to have a protocol secure against no-signalling
adversaries [ FF15a ] . This is a consequence of the fact that in this
context the hiding property coincides with the definition of
no-signalling and so if the protocol is hiding then there exists a
perfect cheating strategy consistent with no-signalling. This is yet
another example of how classical and quantum theories are qualitatively
different from the no-signalling world.

### 6.2 Multiround protocol

To extend the commitment time we must introduce additional rounds of
communication, which keep the commitment “alive” (the sustain phase). If
Alice and Bob require the commitment to be valid for @xmath units of
time (for some @xmath ) they need to execute the following protocol of
@xmath rounds. We use @xmath as a label for the round under
consideration and since the rounds alternate between the two locations
we define

  -- -------- --
     @xmath   
  -- -------- --

We use @xmath and @xmath to denote private strings (chosen uniformly at
random) of Alice and Bob, respectively and @xmath and @xmath to denote
messages announced by Alice and Bob, respectively, in the @xmath round
of the protocol. All the @xmath -bit strings are interpreted as elements
of the finite field @xmath and “ @xmath ” denotes the finite field
multiplication.

Protocol 9: Multiround bit commitment

1.  (commit, @xmath ) At @xmath , Bob @xmath sends @xmath to Alice
    @xmath . Alice @xmath returns @xmath .

2.  (sustain, @xmath ) At @xmath , Bob @xmath sends @xmath to Alice
    @xmath . Alice @xmath returns @xmath .

3.  (open, @xmath ) At @xmath , Alice @xmath sends @xmath and @xmath to
    Bob @xmath .

4.  (verify) At @xmath , Bob @xmath receives @xmath and accepts the
    opening if

      -- -------- -------- -------- -------
         @xmath   @xmath            (6.2)
                  @xmath   @xmath   
      -- -------- -------- -------- -------

It is easy to see that the timing is chosen precisely to make every two
consecutive rounds space-like separated. In the formalism presented in
Section 4.2 there are @xmath interactions and the communication graph is

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

Correctness of the protocol is straightforward to check by substituting
the honest responses of Alice @xmath and Alice @xmath into the
acceptance condition ( 6.2 ).

#### 6.2.1 Security for honest Alice

Security for honest Alice is a direct consequence of the fact that every
message she announces is one-time-padded with a fresh secret @xmath -bit
string. Hence, we would intuitively expect the transcripts corresponding
to @xmath and @xmath to be statistically indistinguishable. We prove
this statement by considering an arbitrary adaptive attack (consistent
with relativity) that classical Bob @xmath and Bob @xmath might
implement. While we do not believe that Bob @xmath and Bob @xmath can
gain anything by using quantum systems, we currently do not have a
rigorous argument to justify this belief.

We start with a lemma which formalises the intuition that if we take an
arbitrary random variable taking values in @xmath and add it to a
uniform and uncorrelated random variable (over @xmath ) then there will
be no correlations between the input and the output (or any function
thereof). More specifically, in the following lemma @xmath is a random
variable from which the input is generated using function @xmath ,
@xmath is the fresh (finite field) randomness and @xmath is a function
allowing us to condition on a certain subset of values of @xmath .

###### Lemma 6.1.

Let @xmath and @xmath be arbitrary finite sets. Let @xmath and @xmath be
two random variables taking values in @xmath and @xmath , respectively,
such that @xmath is uniform and independent from @xmath

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

for all @xmath and @xmath . Then for arbitrary functions @xmath , @xmath
and arbitrary fixed @xmath , @xmath it holds that

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Note that

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where the second last equality follows from applying the assumption (
6.4 ) to every term of the sum. ∎

Lemma 6.1 allows us to prove security for honest Alice.

###### Proposition 6.1.

If Alice is honest then the protocol is hiding.

###### Proof.

We want to show that the transcripts for @xmath and @xmath at the
opening point (i.e. after the last sustain round) are indistinguishable,
i.e.

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . In fact, we show a stronger statement, namely

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

for all @xmath and both values of @xmath .

Honest Alice follows the protocol, which means that @xmath are drawn
independently, uniformly at random from @xmath and so Alice’s message in
the @xmath round (represented as a random variable) equals

  -- -- -- -------
           (6.6)
  -- -- -- -------

Bob @xmath and Bob @xmath , on the other hand, are only limited by the
causal constraints, which means that the message in the @xmath round
might depend on some pre-shared randomness denoted by @xmath and all the
responses of Alice @xmath and Alice @xmath which belong to the past of
the @xmath round. Therefore, without loss of generality the message in
the @xmath round is

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

for some arbitrary function @xmath (we include all randomness used by
Bob in @xmath so @xmath is deterministic).

In this scenario the full transcript is a deterministic function of
Alice’s commitment @xmath , her private randomness @xmath and Bob’s
pre-shared randomness @xmath . For every string announced by Alice and
Bob we can explicitly find the subset of random variables it may depend
on as listed in the table below

  --------- -------------------------------------
  message   random variables it might depend on
  @xmath    @xmath
  @xmath    @xmath
  @xmath    @xmath
  ⋮         ⋮
  @xmath    @xmath
  ⋮         ⋮
  @xmath    @xmath
  @xmath    @xmath
  @xmath    @xmath
  @xmath    @xmath
  ⋮         ⋮
  @xmath    @xmath
  ⋮         ⋮
  @xmath    @xmath
  --------- -------------------------------------

First, we verify that condition ( 6.5 ) holds for @xmath

  -- -------- --
     @xmath   
  -- -------- --

where the first two equalities follow from Eqs. ( 6.6 ) and ( 6.7 ),
respectively. The last equality is a direct consequence of Lemma 6.1 (in
a simplified form: no conditioning) applied to @xmath , @xmath , @xmath
. Now, suppose that Eq. ( 6.5 ) holds for @xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where the second last inequality follows from applying Lemma 6.1 to

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.8)
     @xmath   @xmath      
  -- -------- -------- -- -------

Note that it is not immediately obvious and the reader should verify
(using the table presented above) that the quantities on the right-hand
side of Eq. ( 6.8 ) are functions of @xmath alone, and therefore satisfy
the assumptions of the lemma. This shows that Eq. ( 6.5 ) holds for
@xmath and so by induction it must hold for all @xmath . This shows that
even at the opening point the transcript contains no information about
Alice’s commitment, which implies that the protocol is hiding. ∎

#### 6.2.2 Security for honest Bob

Security for honest Bob is where the framework developed in Section 4.2
comes in useful. We immediately identify the case of honest Bob as a
game of @xmath players @xmath whose communication is restricted by
@xmath defined in Eq. ( 6.3 ). Player @xmath (for @xmath ) receives a
uniformly random @xmath -bit string represented by the random variable
@xmath . Moreover, all the players except for @xmath receive @xmath (the
value they are challenged to unveil) chosen uniformly at random. It is
clear that @xmath must not be available to @xmath (this would correspond
to an honest commitment) but it must be available to all the other
players. This is important as it fixes the commitment point to occur
immediately after @xmath , i.e. allows us to claim that Alice becomes
committed immediately after the first round.

Having explicitly determined the inputs received by each player and the
communication constraints we apply Observation 4.1 to turn this scenario
into a non-communicating game. It is easy to verify that the output of
@xmath denoted by @xmath can be written as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath corresponds to any randomness shared by the players. For
@xmath for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Finally, for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

This allows us to prove security for honest Bob.

###### Proposition 6.2.

If Bob is honest then the protocol is @xmath -binding for @xmath defined
in Eq. ( 2.4 ).

###### Proof.

The argument is essentially identical to the one presented in Section
6.1 and we use the same definitions for the events @xmath and @xmath .
Since @xmath is defined as the XOR of Eq. ( 6.2 ) for @xmath and @xmath
we have

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

To bound @xmath note that the right-hand side contains exactly @xmath
terms, but each of them depends on @xmath @xmath ’s; none of the terms
depends on all @xmath ’s simultaneously . The terms corresponding to
@xmath have some internal structure (e.g. the dependence on @xmath is
not arbitrary) but we can relax the problem to the case where the @xmath
term is an arbitrary function of all the @xmath ’s except for @xmath
denoted by @xmath . The winning condition for the relaxed game is

  -- -------- --
     @xmath   
  -- -------- --

In Section 2.3.3 we define the optimal winning probability for this game
to be @xmath , which concludes the proof since

  -- -------- --
     @xmath   
  -- -------- --

The recursive argument presented in Section 2.3.5 allows us to obtain
explicit upper bounds on @xmath . In particular, we have @xmath , where

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

For large @xmath , to a good approximation we have @xmath . The decay is
exponential in @xmath but since the decay rate strongly depends on
@xmath , security deteriorates rapidly as we increase the number of
rounds. The tightness of these bounds is an interesting open problem and
is briefly discussed in Appendix B.5 of Ref. [ LKB @xmath 15 ] . No
explicit cheating strategy is known, whose winning probability would
approach our security bounds.

### 6.3 Experimental implementation

Both the two-round and the multiround protocols have been implemented
between University of Geneva and University of Berne. The straight-line
distance between these two locations is @xmath km, which corresponds to
@xmath s. Each classical agent consists of a standalone computer
equipped with a FPGA and the agents are connected by an optical link
(see Fig. 6.1 ). Synchronisation to universal time is achieved via a GPS
clock. While the task of exchanging classical information is on its own
quite straightforward, the challenge in our case is to take maximal
advantage of the relativistic constraints. To maximise the commitment
time, it is crucial to ensure that the devices are synchronised up to
high accuracy and that classical data manipulation (communication with
an external memory to load and store data, data exchange between the two
agents and local computation) are optimised to produce the highest
feasible rate.

The protocol was implemented with @xmath bits, which for the two-round
protocol gives the security parameter of @xmath (against quantum
adversaries). The multiround protocol was implemented with @xmath rounds
which gives the security parameter of @xmath (against classical
adversaries). The total commitment time was 2 ms but placing exactly the
same setup at the antipodes of the Earth would allow for commitment time
of 212 ms. Of course, the commitment time could be made longer by
employing more sophisticated hardware, which allows us to exchange more
data within the relativistic constraints, but since our main goal was to
demonstrate the feasibility of implementing multiround schemes we
decided not to do it.

## Chapter 7 Conclusions

The central theme of this thesis is the study of how communication
constraints can be used in classical and quantum cryptography, with a
particular focus on commitment schemes. Communication constraints
resulting from fundamental physical principles (like the fact that the
speed of light is finite) are of particular interest. While relativity
does not permit to implement the ideal commitment functionality, some
weaker variants are possible and understanding similarities and
differences between these schemes lies at the heart of this thesis.

It seems fair to claim that we now have a good understanding of
relativistic commitment schemes, in particular the simplest class, in
which no messages are exchanged when the commitment is valid. The main
drawback of such schemes is the limitation on the commitment time, which
is proportional to the distance between the agents. In order to increase
the length of the commitment (without moving the agents further apart)
one needs to resort to multiround schemes and we have presented a
particular classical protocol along with a security proof against
classical adversaries. This shows that in the classical world one can
achieve arbitrary long commitments even if the agents are forced to
occupy a finite region of space.

A natural follow-up question is to ask whether this statement remains
true in the quantum world. Security analysis of the aforementioned
multiround protocol against quantum adversaries is currently out of
reach but we conjecture that the protocol remains secure against quantum
adversaries (although with weaker security guarantees). Moreover,
security analysis of relativistic protocols against quantum adversaries
leads to a new, interesting class of problems: multiplayer games with
communication constraints, which have not been studied before (except
for a few special cases) and might be of independent interest. Note that
multiround commitment schemes against no-signalling adversaries have
recently been shown to be impossible [ FF15a ] .

Having understood the features and limitations of relativistic
commitment schemes, the next step would be to look at more powerful
primitives and oblivious transfer would be a natural choice. While we
know that perfect oblivious transfer is not possible, one might think of
weaker variants which have not been ruled out. We do not see a
straightforward way of translating distributed oblivious transfer
protocols into the relativistic setting (see Section 4.1 for details)
and, to the best of our knowledge, no explicitly relativistic schemes
have been proposed. Investigating the possibility of relativistic
oblivious transfer would constitute an important step towards
characterising the exact power of quantum relativistic cryptography.
