## Chapter 1 Introduction

In this thesis we study the design and analysis of new efficient
randomized iterative methods for solving large scale linear systems,
stochastic quadratic optimization problems, the best approximation
problem and quadratic optimization problems. A large part of the thesis
is also devoted to the development of efficient methods for obtaining
average consensus on large scale networks. As we will explain later in
more detail, some of our proposed algorithms for solving the average
consensus problem are carefully constructed special cases of methods for
solving linear systems. All methods presented in the thesis (except two
algorithms in the last chapter that converge with a sublinear rate)
converge with global linear convergence rates, which means that they
achieve an approximate solution of the problem fast.

In this introductory chapter we present the setting shared throughout
the thesis and explain the relationships between the four problems
mentioned above. We describe some baseline methods for solving these
problems and present their convergence rates. Finally, we give a summary
of the main contributions of each chapter.

###### Organization of thesis.

The thesis is divided into two main parts. In the first part (Chapters 2
and 3 ) we present and analyze novel momentum (Chapter 2 ) and inexact
(Chapter 3 ) variants of several randomized iterative methods for
solving three closely related problems:

1.  stochastic convex quadratic minimization,

2.  best approximation, and

3.  (bounded) concave quadratic maximization.

In the second part (Chapters 4 and 5 ), we focus on the design and
analysis of novel randomized gossip algorithms for solving the average
consensus problem. This is a fundamental problem in distributed
computing with the following goal: each node of a network initially
holds a number or a vector, and the aim is for every node to calculate
the average of these objects in a decentralized fashion (communicating
with neighbors only). The proposed decentralized algorithms are inspired
by recent advances in the area of randomized numerical linear algebra
and optimization. In particular, in Chapter 4 we propose a new framework
for the design and analysis of efficient randomized gossip protocols. We
show how randomized iterative methods for solving linear systems can be
interpreted as gossip algorithms when applied to special systems
encoding the underlying network. Using the already developed framework
of Chapter 4 , we move towards a different direction and in Chapter 5 we
present the first randomized gossip algorithms for solving the average
consensus problem while at the same time protecting the information
about the initial private values stored at the nodes.

Excluding some introductory results presented in this section, each
chapter of the thesis is self-contained, including the objective,
contributions, definitions and notation. However, to the extend that
this was possible and meaningful, a unified notation has been adopted
throughout the thesis.

### 1.1 Thesis’ Philosophy: Place in the Literature

Here we start by providing a bird’s-eye view of the main concepts and a
simple first explanation of the context and of the problems under study.
We present how this thesis is related to different areas of research and
provide important connections that allow readers with different
backgrounds to easily navigate through the main contributions of this
work.

#### 1.1.1 Bridge across several communities

This thesis is related to three different areas of research: linear
algebra, stochastic optimization and machine learning.

Linear Algebra

Linear systems form the backbone of most numerical codes used in
industry and academia. Solving large linear systems is a central problem
in numerical linear algebra and plays an important role in computer
science, mathematical computing, optimization, signal processing,
engineering and many other fields.

In this thesis we are concerned with the problem of solving a consistent
linear system. In particular, given a matrix @xmath and a vector @xmath
, we are interested to solve the problem:

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

Main Assumption: Consistency. Throughout the thesis we assume that the
linear system ( 1.1 ) has a solution @xmath (not necessarily unique)
that satisfies @xmath . That is, the linear system is consistent, i.e.,
@xmath . We make no extra assumption on the form, positive definiteness,
rank or any other property of matrix @xmath . Thus, all methods proposed
in this thesis converge under virtually no additional assumptions on the
system beyond consistency. However, our methods are particularly well
suited for the case of large over-determined linear systems. That is, to
the case when the number of linear equations (rows) of the matrix is
much larger than number of columns (variables) ( @xmath ).

Stochastic Optimization

This thesis is also related to the stochastic optimization literature,
through a recently proposed stochastic optimization reformulation of
linear systems [ 168 ] .

It is well known that the linear system ( 1.1 ) can be expressed as an
optimization problem as follows [ 133 ] :

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath denotes the @xmath row of matrix @xmath . Note that if we
denote with @xmath the solution set of problem ( 1.2 ), then @xmath ,
where @xmath is the solution set of the consistent linear system ( 1.1
).

The above approach of reformulating a linear system to an optimization
problem is without doubt one of the most popular. However as we will
later explain in more detail, it is not the only one. For example, one
may instead consider the more general formulation

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

where @xmath is a symmetric and positive definite matrix. In [ 168 ] ,
Richtárik and Takáč proposed a stochastic optimization reformulation of
linear systems similar to ( 1.3 ). In particular, they consider ( 1.3 )
with @xmath and allow @xmath to be positive semi-definite. The
expectation is over random matrices @xmath ( @xmath is matrix expression
involving random matrix @xmath ) that depend on an arbitrary
user-defined distribution @xmath and the matrix @xmath of the linear
system ( 1.1 ). Under a certain assumption on @xmath , for which the
term exactness was coined in [ 168 ] , the solution set of the
stochastic optimization reformulation is identical to the solution set
of the linear system. In [ 168 ] , the authors provide necessary and
sufficient conditions for exactness. Later in Sections 1.2 and 1.3 we
describe exactness and comment on its importance in more detail.

In this thesis we design and analyze randomized iterative methods
(stochastic optimization algorithms) for solving the stochastic convex
quadratic minimization reformulation proposed in [ 168 ] .

Machine Learning

Stochastic optimization problems are at the heart of many machine
learning and statistical techniques used in data science. Machine
learning practitioners, as part of their data analysis, are often
interested in minimizing function @xmath which in full generality takes
the form:

  -- -- -- -------
           (1.4)
  -- -- -- -------

where @xmath denotes the expectation over an arbitrary distribution
@xmath .

If we further assume that the distribution @xmath is uniform over @xmath
functions @xmath , the stochastic optimization problem is simplified to
the finite-sum structure problem:

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

Problem ( 1.5 ) is referred to as Empirical Risk Minimization (ERM), and
is one of the key optimization problems arising in large variety of
models, ranging from simple linear regressions to deep learning. For
example, note that problem ( 1.2 ) is also a special case of ERM ( 1.5 )
when functions @xmath are chosen to be @xmath .

A trivial benchmark for solving problem ( 1.5 ) in the case of
differentiable function is Gradient Descent (GD). That is,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the stepsize parameter (learning rate). However in
modern machine learning applications the number @xmath of component
functions @xmath can be very large ( @xmath ). As a result, computing
the full gradient in each iteration is prohibitively expensive and GD
becomes impractical for most state-of-the-art applications.

To avoid such issues, machine learning practitioners use Stochastic
Gradient Descent (SGD), a randomized variant of GD, first proposed by
Robbins and Monro [ 169 ] in 1951 and which has enjoyed a lot of success
ever since. For solving ( 1.5 ), SGD first uniformly at random samples
function @xmath (where @xmath ) and then performs the iteration:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the stepsize parameter (learning rate). SGD has become
the workhorse for training supervised machine learning problems which
have the generic form ( 1.5 ) and many papers devoted to the
understanding of its convergence behavior in different applications and
under different assumptions on the functions @xmath [ 137 , 136 , 81 ,
177 , 170 , 141 , 68 , 194 ] .

This thesis is closely related to machine learning literature and the
papers devoted to the analysis of SGD and its variants. In particular,
besides other methods, we focus on analyzing SGD and two of its most
popular variants: SGD with momentum (Chapter 2 ) and Inexact SGD
(Chapter 3 ) for solving the stochastic optimization reformulation of
linear systems proposed in [ 168 ] .

#### 1.1.2 Roadmap

In this subsection, by following the flowchart of Figure 1.2 we present
the hierarchy of the main problems under study, explain the
relationships between them and provide a brief summary of the chapters
of the thesis. More details will be provided in the remaining sections
of the Introduction.

In this thesis, we are studying the problem of solving large-dimensional
consistent linear systems of the form @xmath . In particular, we are
adopting the stochastic optimization reformulation of linear systems
first proposed in [ 168 ] . As we have already briefly mentioned, under
a certain assumption ( exactness ) on the randomness of the stochastic
reformulation, the solution set of the stochastic convex quadratic
minimization problem is equal to the solution set of the original linear
system. Hence, solving the stochastic optimization problem @xmath is
equivalent to solving the original linear system.

For solving the stochastic convex quadratic minimization problem one can
use stochastic gradient descent (SGD), a popular stochastic optimization
algorithm, particularly useful in machine learning applications (large
scale setting). In Section 1.3 we explain how other stochastic
optimization methods, like stochastic Newton (SN) method and stochastic
proximal point (SPP) method, are identical to SGD for solving this
particular problem and provide a simple analysis for their linear
(exponential) convergence.

As it turns out, SGD and its equivalent methods converge to one
particular minimizer of the stochastic optimization problem: the
projection of their starting point @xmath onto the solution set of the
linear system ( 1.1 ). This leads to the best approximation problem ,
which is the problem of projecting a given vector onto the solution
space of the linear system. The best approximation problem is popular in
numerical linear algebra and is normally solved using sketching
techniques. We show how the sketch-and-project method proposed in [ 73 ]
for solving the best approximation problem has also identical updates to
SGD.

The dual of the best approximation problem is a bounded unconstrained
concave quadratic maximization problem . In this thesis, we are also
interested in the development and convergence analysis of efficient,
dual in nature, algorithms for directly solving the dual of the best
approximation problem. The baseline method for solving the dual of the
best approximation problem is stochastic dual subspace accent (SDSA) [
74 ] . As we will explain later, the random iterates of SGD, SN and SPP
arise as affine images of the random iterates produced by SDSA.

In Chapters 2 and 3 we study novel momentum and inexact variants of
several randomized iterative methods for solving the above problems.
Among the methods studied are: stochastic gradient descent, stochastic
Newton, stochastic proximal point and stochastic dual subspace ascent.

As we can also see in Figure 1.2 , a large part of the thesis will be
devoted to the development of efficient methods for solving the average
consensus (AC) problem . In particular, we will explain how the AC
problem can be expressed as a best approximation problem once we choose
special linear systems encoding the underlying network (average
consensus systems). In Chapter 4 we show how classical randomized
iterative methods for solving the best approximation problem can be
interpreted as gossip algorithms and explain in detail their
decentralized nature. In Chapter 5 , we present the first
privacy-preserving randomized gossip algorithms that solve the AC
problem while at the same time protect the private values stored at the
nodes as these may be sensitive.

### 1.2 Stochastic Optimization Reformulation of Linear Systems

The starting point of this thesis is a general framework for studying
consistent linear systems via carefully designed stochastic
reformulations recently proposed by Richtárik and Takáč [ 168 ] . In
particular, given the consistent linear system ( 1.1 ), the authors
provide four reformulations in the form of a stochastic optimization
problem, stochastic linear system, stochastic fixed point problem and a
stochastic feasibility problem. These reformulations are equivalent in
the sense that their solution sets are identical. That is, the set of
minimizers of the stochastic optimization problem is equal to the set of
solutions of the stochastic linear system and so on. Under a certain
assumption on the randomness defining these reformulations, for which
the term exactness was coined in [ 168 ] , the solution sets of these
reformulations are equal to the solution set of the linear system.

For the sake of a simplified narrative, in this thesis we choose to
focus mostly on one of the above reformulations: the stochastic convex
quadratic optimization problem, which can be expressed as follows:

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

Here the expectation is over random matrices @xmath drawn from an
arbitrary, user defined, distribution @xmath and @xmath is a stochastic
convex quadratic function of a least-squares type, defined as

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

Function @xmath depends on the matrix @xmath and vector @xmath of the
linear system ( 1.1 ) and on a random symmetric positive semidefinite
matrix

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

The @xmath positive definite matrix @xmath , in the expression of matrix
@xmath , defines the geometry of the space and throughout the thesis,
gives rise to an inner product

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

and the induced norm @xmath on @xmath . By @xmath we denote the
Moore-Penrose pseudoinverse.

###### On Moore-Pernose Pseudoinverse:

The Moore-Pernose pseudoinverse matrix (or simply pseudoinverse) @xmath
of a matrix @xmath was first intoduced by Moore [ 125 ] and Penrose [
154 , 153 ] in their pioneering work.

A computationally simple and accurate way to compute the matrix @xmath
is by using the singular value decomposition [ 67 , 38 ] . That is, if
@xmath is the singular value decomposition of matrix @xmath , then
@xmath , where the diagonal matrix @xmath is computed by taking the
reciprocal of each non-zero element on the diagonal of matrix @xmath ,
leaving the zeros in place. That is @xmath for all @xmath . Note that by
its definition Moore-Penrose pseudoinverse is uniquely defined for all
matrices (not necessarily square) whose entries are real or complex
numbers.

It is worth to highlight that in this thesis, we applied the
Moore-Pernose pseudoinverse only on symmetric positive semidefinite
matrices. In particular, if @xmath is a symmetric @xmath matrix then its
pseudoinverse will appear as a part of the expression @xmath , where
@xmath . Using properties of pseudoinverse this is equivalent to the
least-norm solution of the least-squares problem @xmath [ 67 , 74 ] .
Hence, if the system @xmath has a solution the following holds:

  -- -- -- --------
           (1.10)
  -- -- -- --------

Let us know present some basic properties of the pseudoinverse:

-   If matrix @xmath is invertible, its pseudoinverse is its inverse.
    That is, @xmath .

-   The pseudoinverse of the pseudoinverse is the original matrix. That
    is , @xmath

-   If @xmath is symmetric positive semidefinite matrix , then @xmath is
    also symmetric positive semidefinite matrix.

-   There are several identities that can be used to cancel certain
    subexpressions or expand expressions involving pseudoinverses:
    @xmath , @xmath , @xmath , @xmath and @xmath . For more useful
    identities see [ 67 ] .

As we have already mentioned, problem ( 1.6 ) is constructed in such a
way that the set of minimizers of @xmath is identical to the set of
solutions of the given (consistent) linear system ( 1.1 ). In this
sense, ( 1.6 ) can be seen as the reformulation of the linear system (
1.1 ) into a stochastic optimization problem. As argued in [ 168 ] ,
such reformulations provide an explicit connection between the fields of
linear algebra and stochastic optimization, and allow the transfer of
knowledge, techniques, and algorithms from one field to another. For
instance, the randomized Kaczmarz method of Strohmer and Vershynin [ 182
] for solving ( 1.1 ) is equivalent to the stochastic gradient descent
method applied to ( 1.6 ), with @xmath corresponding to a discrete
distribution over unit coordinate vectors in @xmath [ 133 ] . However,
the flexibility of being able to choose @xmath arbitrarily allows for
numerous generalizations of the randomized Kaczmarz method [ 168 ] .
Likewise, provably faster variants of the randomized Kaczmarz method
(for instance, by utilizing importance sampling) can be designed using
the connection.

Since their introduction in [ 168 ] , stochastic reformulations of
otherwise deterministic problems have found surprising applications in
various areas, and are hence an important object of study in its own
right. For instance, using a different stochastic reformulation Gower et
al. [ 68 ] performed a tight convergence analysis of stochastic gradient
descent in a more general convex setting, while [ 70 ] utilized
“controlled" stochastic reformulations to develop a new approach to
variance reduction for finite-sum problems appearing in machine
learning. Further, this approach led to the development of the first
accelerated quasi-Newton matrix update rules in the literature [ 72 ]
and to the design of efficient randomized projection methods for convex
feasibility problems [ 130 ] ; all solving open problems in the
literature.

###### Closed form expressions.

We shall often refer to matrix expressions involving the random matrix
@xmath and the matrices @xmath and @xmath . In order to keep these
expressions brief throughout the thesis, it will be useful to define the
@xmath matrix:

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

Using matrix @xmath we can easily express important quantities related
to the problems under study. For example, the stochastic functions
@xmath defined in ( 1.7 ) can be also expressed as

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

where @xmath . In addition, the gradient and the Hessian of @xmath with
respect to the @xmath inner product ( 1.9 ) are equal to

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

where @xmath and @xmath [ 168 ] .

Using the above expressions, the gradient and the Hessian of the
objective function @xmath of problem ( 1.6 ) are given by

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

respectively.

###### Projections.

Let @xmath be a closed convex set. Throughout the thesis, with @xmath we
denote the projection operator onto @xmath , in the @xmath -norm. That
is, @xmath . In particular, we are interested in the projection onto
@xmath . An explicit formula for the projection onto @xmath is given by

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

A formula for the projection onto the sketched system @xmath is obtained
by simply replacing matrix @xmath and vector @xmath in ( 1.14 ) with the
matrix @xmath and vector @xmath , respectively. In this case we write
@xmath .

###### On complexity results.

The complexity of the linearly convergent methods presented in this
thesis is described by the spectrum of the following key matrix:

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

Matrix @xmath has the same spectrum as the Hessian matrix @xmath and at
the same time is symmetric and positive semidefinite (with respect to
the standard inner product). Note that @xmath is a not symmetric matrix
(although it is self-adjoint with respect to the @xmath -inner product).

Let @xmath be the eigenvalue decomposition of @xmath , where @xmath is
an orthonormal matrix composed of eigenvectors, and @xmath is the
diagonal matrix of eigenvalues with @xmath . In this thesis, by @xmath
we will denote the smallest nonzero eigenvalue, and by @xmath the
largest eigenvalue of matrix @xmath . It was shown in [ 168 ] that
@xmath for all @xmath .

###### Main Assumption: Exactness.

Note that in view of ( 1.12 ), @xmath whenever @xmath . However, @xmath
can be zero also for points @xmath outside of @xmath . Clearly, @xmath
is nonnegative, and @xmath for @xmath . However, without further
assumptions, the set of minimizers of @xmath can be larger than @xmath .
The exactness assumption mentioned above ensures that this does not
happen. For necessary and sufficient conditions for exactness, we refer
the reader to [ 168 ] . One of a number of equivalent characterizations
of exactness is the condition:

  -- -- -- --------
           (1.16)
  -- -- -- --------

For this thesis it suffices to remark that a sufficient condition for
exactness is to require @xmath to be positive definite. This is easy to
see by observing that @xmath In other words, if @xmath is the solution
set of the stochastic optimization problem ( 1.6 ) and @xmath the
solution set of the linear system ( 1.1 ), then the notion of exactness
is captured by:

  -- -------- --
     @xmath   
  -- -------- --

### 1.3 Stochastic Gradient Descent (SGD) and Equivalent Iterative
Methods

Problem ( 1.6 ) has several peculiar characteristics which are of key
importance to this thesis. For instance, the Hessian of @xmath is a
(random) projection matrix, which can be used to show that @xmath (see
equation ( 1.38 ) in Lemma 2 ). Moreover, as we have already mentioned
the Hessian of @xmath has all eigenvalues bounded by 1, and so on. These
characteristics can be used to show that several otherwise distinct
stochastic algorithms for solving the stochastic optimization problem (
1.6 ) are identical .

In particular, the following optimization methods for solving ( 1.6 )
are identical

-   Stochastic Gradient Descent (SGD):

      -- -------- -- --------
         @xmath      (1.17)
      -- -------- -- --------

-   Stochastic Newton Method (SN) ¹ ¹ 1 In this method we take the
    @xmath -pseudoinverse of the Hessian of @xmath instead of the
    classical inverse, as the inverse does not exist. When @xmath , the
    @xmath pseudoinverse specializes to the standard Moore-Penrose
    pseudoinverse. :

      -- -------- -- --------
         @xmath      (1.18)
      -- -------- -- --------

-   Stochastic Proximal Point Method (SPP) ² ² 2 In this case, the
    equivalence only works for @xmath . :

      -- -------- -- --------
         @xmath      (1.19)
      -- -------- -- --------

In all methods @xmath , is a fixed stepsize and @xmath is sampled afresh
in each iteration from distribution @xmath .

Note that the equivalence of these methods for solving problem ( 1.6 )
is useful for the purposes of the thesis as it allows us to study their
variants with momentum (Chapter 2 ) and their inexact variants (Chapter
3 ) by studying a single algorithm only.

Using the closed form expression ( 1.13 ) of the gradient of functions
@xmath , the update rules of the equivalent algorithms ( 1.17 ),( 1.18 )
and ( 1.19 ) can be also written as:

  -- -------- -- --------
     @xmath      (1.20)
  -- -------- -- --------

Following [ 168 ] , we name the algorithmic update of equation ( 1.20 ),
basic method and we use this in several parts of this thesis to
simultaneously refer to the above equivalent update rules.

By choosing appropriately the two main parameters of the basic method,
the matrix @xmath and distribution @xmath of the random matrices @xmath
, we can recover a comprehensive array of well known algorithms for
solving linear systems as special cases, such as the randomized Kaczmarz
method, randomized Gauss Seidel (randomized coordinate descent) and
their block variants. In addition, it is worth to notice that the basic
method allows for a much wider selection of these two parameters, which
means that it is possible to obtain a number of new specific and
possibly more exotic algorithms as special cases. Hence, by having a
convergence analysis for the general method ( 1.20 ) we can easily
obtain the convergence rates of all these special cases by choosing
carefully the combinations of the two main parameters.

###### Example 1.

As a special case of the general framework, let us choose @xmath and
@xmath , where @xmath is chosen in each iteration independently, with
probability @xmath . Here with @xmath we denote the @xmath unit
coordinate vector in @xmath . In this setup the update rule ( 1.20 )
simplifies to:

  -- -------- -- --------
     @xmath      (1.21)
  -- -------- -- --------

where @xmath indicates the @xmath row of matrix @xmath . This is a
relaxed variant (stepsize not necessarily @xmath ) of the randomized
Kaczmarz method [ 182 ] .

###### On Exactness.

An important assumption that is required for the convergence analysis of
the randomized iterative methods presented in this thesis is exactness .
The exactness property is of key importance for the setting under study,
and should be seen as an assumption on the distribution @xmath and not
on matrix @xmath .

Clearly, an assumption on the distribution @xmath of the random matrices
@xmath should be required for the convergence of ( 1.20 ). For an
instance, if @xmath in the randomized Kaczmarz method ( 1.21 ), is such
that, @xmath with probability 1, where @xmath be the @xmath unit
coordinate vector in @xmath , then the algorithm will select the same
row of matrix @xmath in each step. For this choice of distribution it is
clear that the algorithm will not converge to a solution of the linear
system. The exactness assumption guarantees that this will not happen.

For necessary and sufficient conditions for exactness, we refer the
reader to [ 168 ] . For this thesis, it suffices to remark that the
exactness condition is very weak, allowing @xmath to be virtually any
reasonable distribution of random matrices. For instance, as we have
already mentioned, a sufficient condition for exactness is for the
matrix @xmath to be positive definite [ 74 ] .

A much stronger condition than exactness is @xmath which has been used
for the convergence analysis of ( 1.20 ) in [ 73 ] . In this case, the
matrix @xmath of the linear system requires to have full column rank and
as a result the consistent linear system has a unique solution.

### 1.4 Best Approximation and its Dual Problem

###### Best approximation problem.

It was shown in [ 168 ] that SGD, SN and SPP converge to a very
particular minimizer of @xmath : the projection in the @xmath -norm, of
the starting point @xmath onto the solution set of the linear system (
1.1 ). That is, @xmath . This naturally leads to the best approximation
problem , which is the problem of projecting a given vector onto the
solution space of the linear system ( 1.1 ):

  -- -------- -- --------
     @xmath      (1.22)
  -- -------- -- --------

Note that, unlike the linear system ( 1.1 ), which is allowed to have
multiple solutions, the best approximation problem has always (from its
construction) a unique solution.

For solving problem ( 1.22 ), the Sketch and Project Method (SPM) :

  -- -- -------- -- -------- -------- --------
        @xmath      @xmath            (1.23)
                             @xmath   
  -- -- -------- -- -------- -------- --------

was analyzed in [ 73 , 74 ] . The name “sketch-and-project" method is
justified by the iteration structure which consists of two steps: (i)
draw a random matrix @xmath from distribution @xmath and formulate the
sketched system @xmath , (ii) project the last iterate @xmath onto
@xmath . Analysis in [ 73 ] was done under the assumption that @xmath
has full column rank. This assumption was lifted in [ 74 ] , and a
duality theory for the method developed.

Using the closed form expression of projection ( 1.14 ), the iterative
process of ( 1.23 ) can be equivalently written as [ 73 ] :

  -- -------- -- --------
     @xmath      (1.24)
  -- -------- -- --------

and for the more general case of @xmath the update takes the form:

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

By combining the definition of projection ( 1.25 ) and the update rule
of equation ( 1.14 ) it can be easily observed that the sketch and
project method is identical to the basic method ( 1.20 ). As a result,
it is also identical to the previously mentioned algorithms, SGD ( 1.17
), SN ( 1.18 ) and SPP ( 1.19 ). Thus, these methods can be also
interpreted as randomized projection algorithms.

###### On Sketching.

In numerical linear algebra, sketching is one of the most popular
techniques used for the evaluation of an approximate solution of large
dimensional linear systems @xmath where @xmath and @xmath [ 197 ] .

Let @xmath be a random matrix with the same number of rows as @xmath but
far fewer columns ( @xmath ). The goal of sketching is to design the
distribution of random matrix @xmath such that the solutions set of the
much smaller (and potential much easier to solve) sketched system @xmath
to be close to the solution set of the original large dimensional
system, with high probability. That is, @xmath with high probability.
Determining the random matrix @xmath that satisfy the above constraint
can be challenging and often depends on the properties and form of
matrix @xmath . For recent advances in the area of sketching we suggest
[ 197 , 66 , 37 , 122 , 44 , 155 ] .

In our setting, as we have already described above, sketching is part of
our iterative process. In each iteration sketching is used in
combination with a projection step in order to evaluate an exact
solution of the sketched system.

###### On Sketch and Project Methods.

Variants of the sketch-and-project method have been recently proposed
for solving several other problems. [ 69 , 75 ] use sketch-and-project
ideas for the development of linearly convergent randomized iterative
methods for computing/estimating the inverse and pseudoinverse of a
large matrix, respectively. A limited memory variant of the stochastic
block BFGS method for solving the empirical risk minimization problem
arising in machine learning was proposed by [ 71 ] . Tu et al. [ 192 ]
utilize the sketch-and-project framework to show that breaking block
locality can accelerate block Gauss-Seidel methods. In addition, they
develop an accelerated variant of the method for a specific distribution
@xmath . An accelerated (in the sense of Nesterov) variant of the sketch
and prokect method proposed in [ 72 ] for the more general Euclidean
setting and applied to matrix inversion and quasi-Newton updates. As we
have already mentioned, in [ 168 ] , through the development of
stochastic reformulations, a stochastic gradient descent interpretation
of the sketch and project method have been proposed. Similar stochastic
reformulations that have the sketch and project method as special case
were also proposed in the more general setting of convex optimization [
68 ] and in the context of variance-reduced methods [ 70 ] .

###### The dual problem.

Duality is an important tool in optimization literature and plays a
major role in the development and understanding of many popular
randomized optimization algorithms. In this thesis, we are also
interested in the development of efficient, dual in nature, algorithms
for directly solving the dual of the best approximation problem.

In particular, the Lagrangian dual of ( 1.22 ) is the (bounded)
unconstrained concave quadratic maximization problem ³ ³ 3 Technically
problem ( 1.26 ) is both the Lagrangian and the Fenchel dual of ( 1.22 )
[ 74 ] .

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

Boundedness follows from consistency. It turns out that by varying
@xmath and @xmath (but keeping consistency of the linear system), the
dual problem in fact captures all bounded unconstrained concave
quadratic maximization problems.

Let us define an affine mapping from @xmath to @xmath as follows:

  -- -------- -- --------
     @xmath      (1.27)
  -- -------- -- --------

It turns out, from Fenchel duality ⁴ ⁴ 4 For more details on Fenchel
duality, see [ 15 ] . , that for any dual optimal @xmath , the vector
@xmath must be primal optimal [ 74 ] . That is:

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

A dual variant of the basic method for solving problem ( 1.26 ) was
first proposed in [ 74 ] . The dual method— Stochastic Dual Subspace
Ascent (SDSA) —updates the dual vectors @xmath as follows:

  -- -------- -- --------
     @xmath      (1.29)
  -- -------- -- --------

where the random matrix @xmath is sampled afresh in each iteration from
distribution @xmath , and @xmath is chosen to maximize the dual
objective @xmath : @xmath . More specifically, SDSA is defined by
picking the maximizer with the smallest (standard Euclidean) norm. This
leads to the formula:

  -- -------- -- --------
     @xmath      (1.30)
  -- -------- -- --------

Note that, SDSA proceeds by moving in random subspaces spanned by the
random columns of @xmath . In the special case when @xmath and @xmath ,
Gower and Richtárik [ 74 ] established the following relationship
(affine mapping @xmath ) between the iterates @xmath produced by the
primal methods ( 1.17 ), ( 1.18 ), ( 1.19 ), ( 1.25 ) (which are
equivalent), and the iterates @xmath produced by the dual method ( 1.29
):

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

In Section 1.5 we show with a simple proof how this equivalence extends
beyond the @xmath case, specifically for @xmath (see Proposition 4 ).
Later, a similar approach will be used in the derivation of the momentum
and inexact variant of SDSA in Chapters 2 and 3 respectively.

An interesting property that holds between the suboptimalities of the
primal methods and SDSA is that the dual suboptimality of @xmath in
terms of the dual function values is equal to the primal suboptimality
of @xmath in terms of distance [ 74 ] . That is,

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

This simple-to-derive result (by combining the expression of the dual
function @xmath ( 1.26 ) and the equation ( 1.27 )) gives for free the
convergence analysis of SDSA, in terms of dual function suboptimality
once the analysis of the primal methods is available (see Proposition 5
in Section 1.5 ).

Note that SDSA update ( 1.29 )+( 1.30 ) depends on the same two
parameters, matrix @xmath and distribution @xmath , of the basic method
(SGD, SN and SPP). Therefore, similar to the previous subsection, by
choosing appropriately the two parameters we can recover many known
algorithms as special cases of SDSA.

###### Example 2.

Let @xmath and @xmath , where @xmath is chosen in each iteration
independently, with probability @xmath . Here with @xmath we denote the
@xmath unit coordinate vector in @xmath . In this setup the update rule
( 1.29 ) simplifies to:

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

where @xmath indicates the @xmath row of matrix @xmath . This is the
randomized coordinate ascent method [ 139 ] applied to the dual problem.
Having said that, the analysis provided in [ 139 ] does not apply
because the objective of the dual problem is not strongly concave
function.

### 1.5 Simple Analysis of Baseline Methods

Having presented the problems that we are interested in this thesis and
explained the relationships between them, let us know present some
interesting properties of our setting and a simple convergence analysis
of the baseline methods for solving them.

In Sections 1.3 and 1.4 we have introduced these baseline methods. As a
reminder, these are the stochastic gradient descent (SGD) ( 1.17 ),
stochastic Newton method (SN) ( 1.18 ), stochastic proximal point method
(SPP) ( 1.19 ), sketch and project method (SPM) ( 1.25 ), and stochastic
dual subspace ascent (SDSA)( 1.29 ).

To simplify the presentation, in the remaining sections of the
introduction we focus on two of these algorithms: SGD and SDSA. Recall
at this point that SGD, SN, SPP and SPM have identical updates for the
problems under study. This means that the analysis presented here for
SGD holds for all of these methods.

We start by presenting some interesting properties of the stochastic
quadratic optimization problem ( 1.6 ) and discussing connections with
existing literature. Then we focus on the convergence analysis results.

#### 1.5.1 Technical preliminaries

Recently, linear convergence of opimization methods has been established
under several conditions that are satisfied in many realistic scenarios.
We refer the interested reader to [ 92 ] and [ 129 ] for more details on
these conditions and how they are related to each other.

In this thesis, we are particularly interested in the Quadratic Growth
condition (QG). We say that a function @xmath satisfies the QG
inequality if the following holds for some @xmath :

  -- -------- -- --------
     @xmath      (1.34)
  -- -------- -- --------

Here @xmath is the projection of vector @xmath onto the solution set
@xmath of the optimization problem @xmath and @xmath denotes the optimal
function value.

Under this condition it can be shown that SGD with constant stepsize
@xmath converges with a linear rate up to a neighborhoud around the
optimal point that is proportional to the value of @xmath [ 92 ] . For
general convex function the convergence of SGD is sublinear [ 169 , 136
] .

In [ 168 ] it was shown the the function of the stochastic quadratic
optimization problem ( 1.6 ) satisfies the QG condition as well. In
particular the following lemma was proved.

###### Lemma 1 (Quadratic bounds, [168]).

For all @xmath and @xmath the objective function of the stochastic
optimization problem ( 1.6 ) satisfies:

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

Moreover, if exactness is satisfied, and we let @xmath , we have

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

Note that inequality ( 1.37 ) is precisely the quadratic growth
condition ( 1.34 ) with @xmath and @xmath .

The following identities were also established in [ 168 ] . For
completeness, we include different (and somewhat simpler) proofs here.

###### Lemma 2.

For all @xmath and any @xmath we have

  -- -------- -- --------
     @xmath      (1.38)
  -- -------- -- --------

Moreover, if @xmath (i.e., if @xmath satisfies @xmath ), then for all
@xmath we have

  -- -------- -- --------
     @xmath      (1.39)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (1.40)
  -- -------- -- --------

###### Proof.

In view of ( 1.13 ), and since @xmath (see [ 168 ] ), we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Moreover,

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
  -- -------- -------- -------- --

By taking expectations in the last identity with respect to the random
matrix @xmath , we get @xmath ∎

###### No need for variance reduction

SGD is arguably one of the most popular algorithms in machine learning.
Unfortunately, SGD suffers from slow convergence, which is due to the
fact that the variance of the stochastic gradient as an estimator of the
gradient does not naturally diminish. For this reason, SGD is typically
used with a decreasing stepsize rule, which ensures that the variance
converges to zero. However, this has an adverse effect on the
convergence rate. For instance, SGD has a sublinear rate even if the
function to be minimized is strongly convex (conergence to the optimum
point, not to a neighborhoud around it). To overcome this problem, a new
class of so-called variance-reduced methods was developed over the last
8 years, including SAG [ 173 ] , SDCA [ 178 , 166 ] , SVRG/S2GD [ 89 ,
97 ] , minibatch SVRG/S2GD [ 96 ] , and SAGA [ 34 , 33 ] .

In our setting, we assume that the linear system ( 1.1 ) is feasible.
Thus, it follows that the stochastic gradient vanishes at the optimal
point (i.e., @xmath for any @xmath ). This suggests that additional
variance reduction techniques are not necessary since the variance of
the stochastic gradient drops to zero as we approach the optimal point
@xmath . In particular, in our context, SGD with fixed stepsize enjoys
linear rate without any variance reduction strategy (see Theorem 3 ).
Hence, in this thesis we can bypass the development of variance
reduction techniques, which allows us to focus on the momentum term in
Chapter 2 on the inexact computations in Chapter 3 and on gossip
protocols that converge to consensus in Chapters 4 and 5 .

#### 1.5.2 Theoretical guarantees

The following convergence rates of SGD and SDSA are easy to establish,
having the bounds and identities of Lemmas 1 and 2 . Nevertheless we
present the statements of the theorems and proofs for completeness and
because we use similar ideas and approaches in the rest of the thesis.
For the benefit of the reader, we also include the derivations of the
two equations ( 1.31 ) and ( 1.32 ) presented in the previous section
which connect the primal and the dual iterates.

###### Theorem 3 ([168]).

Let assume exactness and let @xmath be the iterates produced by SGD with
constant stepsize @xmath . Set @xmath . Then,

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

###### Proof.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.42)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

By taking expectation with respect to @xmath and using quadratic growth
inequality ( 1.37 ):

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.43)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Taking expectation again and by unrolling the recurrence we obtain (
1.41 ). ∎

###### Proposition 4.

Let @xmath be the iterates produced by SGD( 1.17 ) with @xmath . Let
@xmath , and let @xmath be the iterates of SDSA ( 1.29 ). Assume that
the methods use the same stepsize @xmath and the same sequence of random
matrices @xmath . Then @xmath holds for all @xmath . That is, the primal
iterates arise as affine images of the dual iterates.

###### Proof.

First note that

  -- -------- -- --------
     @xmath      (1.44)
  -- -------- -- --------

We now use this to show that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

So, the sequence of vectors @xmath satisfies the same recursion to the
sequence @xmath defined by SGD. It remains to check that the starting
vectors of both recursions coincide. Indeed, since @xmath , we have
@xmath . ∎

###### Proposition 5 ([74]).

Let @xmath be a solution of the dual problem ( 1.26 ). Then,

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (1.45)
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

In the @xmath equality above we use ( 1.28 ) for the optimal primal and
dual values. In particular, @xmath . ∎

The next theorem has been proved in [ 74 ] for the case of @xmath . Here
we extend this convergence to the more general case of @xmath .

###### Theorem 6.

Let us assume exactness. Choose @xmath . Let @xmath be the sequence of
random iterates produced by SDSA with stepsize @xmath . Then,

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

###### Proof.

This follows by applying Theorem 3 together with Proposition 5 . ∎

#### 1.5.3 Iteration Complexity

In several parts of this thesis we compare the performance of linearly
convergent algorithms using their iteration complexity bounds. That is,
we derive a lower bound on the number of iterations that are sufficient
to achieve a prescribed accuracy. The following lemma shows the
derivation of this bound for the sequence @xmath .

###### Lemma 7.

Consider a non-negative sequence @xmath satisfying

  -- -------- -- --------
     @xmath      (1.47)
  -- -------- -- --------

where @xmath . Then, for a given @xmath and for:

  -- -------- -- --------
     @xmath      (1.48)
  -- -------- -- --------

it holds that:

  -- -------- -- --------
     @xmath      (1.49)
  -- -------- -- --------

###### Proof.

Note that since @xmath , we have:

  -- -------- -- --------
     @xmath      (1.50)
  -- -------- -- --------

Therefore,

  -- -------- -- --------
     @xmath      (1.51)
  -- -------- -- --------

Applying exponentials to the above inequality completes the proof. ∎

As an instance, of how the above lemma can be used, recall the
convergence result of Theorem 3 , where we have proved that SGD with
constant stepsize @xmath converges as follows:

  -- -------- --
     @xmath   
  -- -------- --

In this setting, Lemma 7 can be utilized with @xmath and @xmath to
obtain:

  -- -------- --
     @xmath   
  -- -------- --

In this case we say that SGD converges with iteration complexity

  -- -------- --
     @xmath   
  -- -------- --

### 1.6 Structure of the Thesis

In the remainder of this section we give a summary of each chapter of
this thesis. The detailed proofs and careful deductions of any claims
made here are left to the chapters.

#### 1.6.1 Chapter 2: Randomized Iterative Methods with Momentum and
Stochastic Momentum

The baseline first-order method for minimizing a differentiable function
@xmath is the gradient descent (GD) method,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a stepsize [ 21 ] . For convex functions with @xmath
-Lipschitz gradient, GD converges at at the rate of @xmath . When, in
addition, @xmath is @xmath -strongly convex, the rate is linear: @xmath
[ 140 ] . To improve the convergence behavior of the method, Polyak
proposed to modify GD by the introduction of a (heavy ball) momentum
term ⁵ ⁵ 5 A more popular, and certainly theoretically much better
understood alternative to Polyak’s momentum is the momentum introduced
by Nesterov [ 138 , 140 ] , leading to the famous accelerated gradient
descent (AGD) method. This method converges non-asymptotically and
globally; with optimal sublinear rate @xmath [ 137 ] when applied to
minimizing a smooth convex objective function (class @xmath ), and with
the optimal linear rate @xmath when minimizing smooth strongly convex
functions (class @xmath ). Recently, variants of Nesterov’s momentum
have also been introduced for the acceleration of stochastic gradient
descent. We refer the interested reader to [ 65 , 1 , 88 , 87 , 214 ,
215 , 98 ] and the references therein. Both Nesterov’s and Polyak’s
update rules are known in the literature as “momentum” methods. In
Chapter 2 , however, we focus exclusively on Polyak’s heavy ball
momentum. , @xmath [ 156 , 157 ] . This leads to the gradient descent
method with momentum (mGD), popularly known as the heavy ball method:

  -- -------- --
     @xmath   
  -- -------- --

More specifically, Polyak proved that with the correct choice of the
stepsize parameters @xmath and momentum parameter @xmath , a local
accelerated linear convergence rate of @xmath can be achieved in the
case of twice continuously differentiable, @xmath -strongly convex
objective functions with @xmath -Lipschitz gradient [ 156 , 157 ] .

The theoretical behavior of the above deterministic heavy ball method is
now well understood in different settings. In contrast to this, there
has been less progress in understanding the convergence behavior of
stochastic variants of the heavy ball method. The key method in this
category is stochastic gradient descent with momentum (mSGD; stochastic
heavy ball method): @xmath where @xmath is an unbiased estimator of the
true gradient @xmath . In our setting, where our goal is to solve the
stochastic optimization problem ( 1.6 ), mSGD takes the following form:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes a fixed stepsize and matrix @xmath is sampled
afresh in each iteration from distribution @xmath .

In Chapter 2 , we study several classes of stochastic optimization
algorithms enriched with the heavy ball momentum for solving the three
closely related problems already described in the introduction. These
are the stochastic quadratic optimization problem ( 1.6 ), the best
approximation problem ( 1.22 ) and the dual quadratic optimization
problem ( 1.26 ). Among the methods studied are: stochastic gradient
descent ( 1.17 ), stochastic Newton ( 1.18 ), stochastic proximal point
( 1.19 ) and stochastic dual subspace ascent ( 1.29 ). This is the first
time momentum variants of several of these methods are studied. We prove
global non-asymptotic linear convergence rates for all methods and
various measures of success, including primal function values, primal
iterates, and dual function values. We also show that the primal
iterates converge at an accelerated linear rate in a somewhat weaker
sense. This is the first time a linear rate is shown for the stochastic
heavy ball method (i.e., stochastic gradient descent method with
momentum). Under somewhat weaker conditions, we establish a sublinear
convergence rate for Cesàro averages of primal iterates. Moreover, we
propose a novel concept, which we call stochastic momentum , aimed at
decreasing the cost of performing the momentum step. We prove linear
convergence of several stochastic methods with stochastic momentum, and
show that in some sparse data regimes and for sufficiently small
momentum parameters, these methods enjoy better overall complexity than
methods with deterministic momentum. Finally, we perform extensive
numerical testing on artificial and real datasets.

#### 1.6.2 Chapter 3: Inexact Randomized Iterative Methods

A common feature of existing randomized iterative methods is that in
their update rule a particular subproblem needs to be solved exactly .
In the large scale setting, often this step can be computationally very
expensive. The purpose of the work in Chapter 3 is to reduce the cost of
this step by incorporating inexact updates in the stochastic methods
under study.

From a stochastic optimization viewpoint, we analyze the performance of
inexact SGD (iSGD):

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes a fixed stepsize, matrix @xmath is sampled afresh
in each iteration from distribution @xmath and @xmath represents a
(possibly random) error coming from inexact computations.

In Chapter 3 , we propose and analyze inexact variants of the exact
algorithms presented in previous sections for solving the stochastic
optimization problem ( 1.6 ), the best approximation problem ( 1.22 )
and the dual problem ( 1.26 ). Among the methods studied are: stochastic
gradient descent (SGD), stochastic Newton (SN), stochastic proximal
point (SPP), sketch and project method (SPM) and stochastic subspace
ascent (SDSA). In all of these methods, a certain potentially expensive
calculation/operation needs to be performed in each step; it is this
operation that we propose to be performed inexactly . For instance, in
the case of SGD, it is the computation of the stochastic gradient @xmath
, in the case of SPM is the computation of the projection @xmath , and
in the case of SDSA it is the computation of the dual update @xmath .

We perform an iteration complexity analysis under an abstract notion of
inexactness and also under a more structured form of inexactness
appearing in practical scenarios. Typically, an inexact solution of
these subproblems can be obtained much more quickly than the exact
solution. Since in practical applications the savings thus obtained are
larger than the increase in the number of iterations needed for
convergence, our inexact methods can be dramatically faster.

Inexact variants of many popular and some more exotic methods, including
randomized block Kaczmarz, randomized Gaussian Kaczmarz and randomized
block coordinate descent, can be cast as special cases of our analysis.
Finally, we present numerical experiments which demonstrate the benefits
of allowing inexactness.

#### 1.6.3 Chapter 4: Revisiting Randomized Gossip Algorithms

In Chapter 4 we present a new framework for the analysis and design of
randomized gossip algorithms for solving the average consensus (AC)
problem, a fundamental problem in distributed computing and multi-agent
systems.

In the AC problem we are given an undirected connected network @xmath
with node set @xmath and edges @xmath . Each node @xmath “knows” a
private value @xmath . The goal of AC is for every node to compute the
average of these private values, @xmath , in a decentralized fashion.
That is, the exchange of information can only occur between connected
nodes (neighbors).

In an attempt to connect the AC problem to optimization, consider the
simple optimization problem:

  -- -------- -- --------
     @xmath      (1.52)
  -- -------- -- --------

where @xmath is the vector of the initial private values @xmath .
Observe that its optimal solution @xmath must necessarily satisfy @xmath
for all @xmath , where @xmath is the value that each node needs to
compute in the AC problem. Note also that, if we represent the
constraint @xmath of ( 1.52 ) as a linear system then the optimization
problem ( 1.52 ) is an instance of the best approximation problem ( 1.22
) with @xmath (identity matrix). Perhaps, there is a deeper link here?
Indeed, it turns out that properly chosen randomized algorithms for
solving ( 1.52 ) can be interpreted as decentralized protocols for
solving the AC problem.

A simple way to express the constraint of problem ( 1.52 ) as linear
system @xmath is by selecting @xmath to be the incidence matrix of the
network and the right hand side to be the zero vector ( @xmath ). By
using this system the most basic randomized gossip algorithm (“randomly
pick an edge @xmath and then replace the values stored at vertices
@xmath and @xmath by their average") is an instance of the randomized
Kaczmarz (RK) method ( 1.21 ) for solving consistent linear systems,
applied to this system.

Using this observation as a starting point, in Chapter 4 we show how
classical randomized iterative methods for solving linear systems can be
interpreted as gossip algorithms when applied to special systems
encoding the underlying network and explain in detail their
decentralized nature. Our general framework recovers a comprehensive
array of well-known gossip algorithms as special cases, including the
pairwise randomized gossip algorithm and path averaging gossip, and
allows for the development of provably faster variants. The flexibility
of the new approach enables the design of a number of new specific
gossip methods. For instance, we propose and analyze novel block and the
first provably accelerated randomized gossip protocols, and dual
randomized gossip algorithms.

From a numerical analysis viewpoint, our work is the first that explores
in depth the decentralized nature of randomized iterative methods for
linear systems and proposes them as methods for solving the average
consensus problem.

We evaluate the performance of the proposed gossip protocols by
performing extensive experimental testing on typical wireless network
topologies.

#### 1.6.4 Chapter 5: Privacy Preserving Randomized Gossip Algorithms

In Chapter 5 , we present three different approaches to solving the
Average Consensus problem while at the same time protecting the
information about the initial values of the nodes. To the best of our
knowledge, this work is the first which combines the gossip framework
with the privacy concept of protection of the initial values.

The randomized methods we propose are all dual in nature. That is, they
solve directly the dual problem ( 1.26 ). In particular, the three
different techniques that we use for preserving the privacy are “Binary
Oracle”, “ @xmath -Gap Oracle” and “Controlled Noise Insertion”.

Binary Oracle: We propose to reduce the amount of information
transmitted in each iteration to a single bit. More precisely, when an
edge is selected, each corresponding node will only receive information
whether the value on the other node is smaller or larger. Instead of
setting the value on the selected nodes to their average, each node
increases or decreases its value by a pre-specified amount.

@xmath -Gap Oracle: In this case, we have an oracle that returns one of
three options and is parametrized by @xmath . If the difference in
values of sampled nodes is larger than @xmath , an update similar to the
one in Binary Oracle is taken. Otherwise, the values remain unchanged.
An advantage compared to the Binary Oracle is that this approach will
converge to a certain accuracy and stop there, determined by @xmath
(Binary Oracle will oscillate around optimum for a fixed stepsize).
However, in general, it will disclose more information about the initial
values.

Controlled Noise Insertion: This approach protects the initial values by
inserting noise in the process. Broadly speaking, in each iteration,
each of the sampled nodes first adds a noise to its current value, and
an average is computed afterwards. Convergence is guaranteed due to the
correlation in the noise across iterations. Each node remembers the
noise it added last time it was sampled, and in the following iteration,
the previously added noise is first subtracted, and a fresh noise of
smaller magnitude is added. Empirically, the protection of initial
values is provided by first injecting noise into the system, which
propagates across the network, but is gradually withdrawn to ensure
convergence to the true average.

We give iteration complexity bounds for all proposed privacy preserving
randomized gossip algorithms and perform extensive numerical
experiments.

### 1.7 Summary

The content of this thesis is based on the following publications and
preprints:

###### Chapter 2

-   Nicolas Loizou and Peter Richtárik.“Momentum and Stochastic Momentum
    for Stochastic Gradient, Newton, Proximal Point and Subspace Descent
    Methods", arXiv preprint arXiv:1712.09677 (2017). [ 115 ]

-   Nicolas Loizou and Peter Richtárik. “Linearly Convergent Stochastic
    Heavy Ball Method for Minimizing Generalization Error", Workshop on
    Optimization for Machine Learning, NIPS 2017. [ 114 ]

###### Chapter 3

-   Nicolas Loizou and Peter Richtárik. “Convergence Analysis of Inexact
    Randomized Iterative Methods", arXiv preprint arXiv:1903.07971
    (2019). [ 117 ]

###### Chapter 4

-   Nicolas Loizou and Peter Richtárik. “A New Perspective on Randomized
    Gossip Algorithms", IEEE Global Conference on Signal and Information
    Processing (GlobalSIP), pp.440-444, 2016 [ 113 ]

-   Nicolas Loizou and Peter Richtárik. “Accelerated Gossip via
    Stochastic Heavy Ball Method." 56th Annual Allerton Conference on
    Communication, Control, and Computing (Allerton) (pp. 927-934),
    2018. [ 116 ]

-   Nicolas Loizou, Mike Rabbat and Peter Richtárik. “Provably
    Accelerated Randomized Gossip Algorithms" 2019 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), pp.
    7505-7509 [ 112 ]

-   Nicolas Loizou and Peter Richtárik. “Revisiting Randomized Gossip
    Algorithms: General Framework, Convergence Rates and Novel Block and
    Accelerated Protocols", arXiv preprint arXiv:1905.08645, [ 118 ] .

###### Chapter 5

-   Filip Hanzely, Jakub Konečný, Nicolas Loizou, Peter Richtárik and
    Dmitry Grishchenko. “A Privacy Preserving Randomized Gossip
    Algorithm via Controlled Noise Insertion", NeurIPS 2018 - Privacy
    Preserving Machine Learning Workshop, [ 80 ]

-   Filip Hanzely, Jakub Konečný, Nicolas Loizou, Peter Richtárik and
    Dmitry Grishchenko. “Privacy Preserving Randomized Gossip
    Algorithms", arXiv preprint arXiv:1706.07636, 2017 [ 79 ]

During the course of my study, I also co-authored the following works
which were not used in the formation of this thesis:

-   Mahmoud Assran, Nicolas Loizou, Nicolas Ballas and Mike Rabbat.
    “Stochastic Gradient Push for Distributed Deep Learning",
    Proceedings of the 36th International Conference on Machine Learning
    (ICML), 2019 [ 4 ]

-   Robert Mansel Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev,
    Egor Shulgin and Peter Richtárik. “SGD: General Analysis and
    Improved Rates" Proceedings of the 36th International Conference on
    Machine Learning (ICML), 2019 [ 68 ]

-   Nicolas Loizou. “Distributionally Robust Games with Risk-Averse
    Players", In Proceedings of 5th International Conference on
    Operations Research and Enterprise Systems (ICORES), 186-196, 2016 [
    111 ]

In [ 68 ] , we propose a general theory describing the convergence of
Stochastic Gradient Descent (SGD) under the “arbitrary sampling
paradigm". Our theory describes the convergence of an infinite array of
variants of SGD, each of which is associated with a specific probability
law governing the data selection rule used to form minibatches. This is
the first time such an analysis is performed, and most of our variants
of SGD were never explicitly considered in the literature before.

In [ 4 ] , we study Stochastic Gradient Push (SGP), an algorithm which
combines PushSum gossip protocol with stochastic gradient updates for
distributed deep learning. We prove that SGP converges to a stationary
point of smooth, non-convex objectives at the same sub-linear rate as
SGD, that all nodes achieve consensus, and that SGP achieves a linear
speedup with respect to the number of compute nodes. Furthermore, we
empirically validate the performance of SGP on image classification
(ResNet-50, ImageNet) and machine translation (Transformer, WMT’16 En-
De) workloads.

In [ 111 ] we present a new model of incomplete information games
without private information in which the players use a distributionally
robust optimization approach to cope with the payoff uncertainty.

## Chapter 2 Randomized Iterative Methods with Momentum and Stochastic
Momentum

### 2.1 Introduction

Two of the most popular algorithmic ideas for solving optimization
problems involving big volumes of data are stochastic approximation and
momentum . By stochastic approximation we refer to the practice
pioneered by Robins and Monro [ 169 ] of replacement of
costly-to-compute quantities (e.g., gradient of the objective function)
by cheaply-to-compute stochastic approximations thereof (e.g., unbiased
estimate of the gradient). By momentum we refer to the heavy ball
technique originally developed by Polyak [ 156 ] to accelerate the
convergence rate of gradient-type methods.

While much is known about the effects of stochastic approximation and
momentum in isolation, surprisingly little is known about the combined
effect of these two popular algorithmic techniques. For instance, to the
best of our knowledge, there is no context in which a method combining
stochastic approximation with momentum is known to have a linear
convergence rate. One of the contributions of this work is to show that
there are important problem classes for which a linear rate can indeed
be established for a range of stepsize and momentum parameters.

#### 2.1.1 The setting

In this chapter we study the three closely related problems described in
the introduction of this thesis. These are:

1.  stochastic quadratic optimization ( 1.6 ),

2.  best approximation ( 1.22 ), and

3.  (bounded) concave quadratic maximization ( 1.26 ).

In particular we are interested in the complexity analysis and efficient
implementation of momentum variants of the baseline algorithms presented
in the introduction. As a reminder, these methods are the following:
stochastic gradient descent (SGD), stochastic Newton method (SN),
stochastic proximal point methods (SPP), sketch and project method (SPM)
and stochastic dual subspace ascent (SDSA).

We are not aware of any successful attempts to analyze momentum variants
of SN and SPP, SPM and SDSA and to the best of our knowledge there are
no linearly convergent variants of SGD with momentum in any setting.

In addition, we propose and analyze a novel momentum strategy for SGD,
SN, SPP and SPM, which we call stochastic momentum . It is a stochastic
approximation of the popular deterministic heavy ball momentum which in
some situations could be particularly beneficial in terms of overall
complexity. Similar to the classical momentum, we prove linear
convergence rates for this momentum strategy.

#### 2.1.2 Structure of the chapter

This chapter is organized as follows. In Section 2.2 we summarize our
contributions in the context of existing literature. In Section 2.3 we
describe and analyze primal methods with momentum (mSGD, mSN and mSPP),
and in Section 2.4 we describe and analyze the dual method with momentum
(mSDSA). In Section 2.5 we describe and analyze primal methods with
stochastic momentum (smSGD, smSN and smSPP). Numerical experiments are
presented in Section 2.7 . Proofs of all key results can be found in
Section 2.9 .

#### 2.1.3 Notation

The following notational conventions are used in this chapter. Boldface
upper-case letters denote matrices; @xmath is the identity matrix. By
@xmath we denote the solution set of the linear system @xmath . By
@xmath , where @xmath is a random matrix, we denote the solution set of
the sketched linear system @xmath . By @xmath and @xmath we indicate the
@xmath row and the @xmath column of matrix @xmath , respectively. Unless
stated otherwise, throughout the chapter, @xmath is the projection of
@xmath onto @xmath in the @xmath -norm: @xmath . We also write @xmath .
Finally, we say that a function @xmath belongs to the class @xmath if it
is convex, continuously differentiable, and its gradient is Lipschitz
continuous with constant @xmath . If in addition the function @xmath is
@xmath -strongly convex with strong convexity constant @xmath , then we
say that it belongs to the class @xmath . When it is also twice
continuously differentiable, it belongs to the function class @xmath .

### 2.2 Momentum Methods and Main Contributions

In this section we give a brief review of the relevant literature, and
provide a summary of our contributions.

#### 2.2.1 Heavy ball method

As we have already mentioned in Section 1.6 , Polyak’s seminal work [
156 , 157 ] showed that deterministic heavy ball method:

  -- -------- --
     @xmath   
  -- -------- --

converges with a local accelerated linear convergence rate of @xmath in
the case of twice continuously differentiable, @xmath -strongly convex
objective functions with @xmath -Lipschitz gradient (function class
@xmath ).

Recently, Ghadimi et al. [ 62 ] performed a global convergence analysis
for the heavy ball method. In particular, the authors showed that for a
certain combination of the stepsize and momentum parameter, the method
converges sublinearly to the optimum when the objective function is
convex and has Lipschitz gradient ( @xmath ), and linearly when the
function is also strongly convex ( @xmath ). A particular selection of
the parameters @xmath and @xmath that gives the desired accelerated
linear rate was not provided.

To the best of our knowledge, despite considerable amount of work on the
heavy ball method, there is still no global convergence analysis which
would guarantee an accelerated linear rate for @xmath . However, in the
special case of a strongly convex quadratic, an elegant proof was
recently proposed in [ 103 ] . Using the notion of integral quadratic
constraints from robust control theory, the authors proved that by
choosing @xmath and @xmath , the heavy ball method enjoys a global
asymptotic accelerated convergence rate of @xmath . The aforementioned
results are summarized in the first part of Table 2.1 .

Extensions of the heavy ball method have been recently proposed in the
proximal setting [ 145 ] , non-convex setting [ 146 , 210 ] and for
distributed optimization [ 63 ] . For more recent analysis under several
combinations of assumptions we suggest [ 184 , 183 , 100 ] .

#### 2.2.2 Stochastic heavy ball method

In contrast to the recent advances in our theoretical understanding of
the (classical) heavy ball method, there has been less progress in
understanding the convergence behavior of stochastic variants of the
heavy ball method. The key method in this category is stochastic
gradient descent with momentum (mSGD; aka: stochastic heavy ball
method):

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is an unbiased estimator of the true gradient @xmath .
While mSGD is used extensively in practice, especially in deep learning
[ 185 , 186 , 99 , 196 ] , its convergence behavior is not very well
understood.

In fact, we are aware of only two papers, both recent, which set out to
study the complexity of mSGD: the work of Yang et al. [ 206 ] , and the
work of Gadat et al. [ 60 ] . In the former paper, a unified convergence
analysis for stochastic gradient methods with momentum (heavy ball and
Nesterov’s momentum) was proposed; and an analysis for both convex and
non convex functions was performed. For a general Lipschitz continuous
convex objective function with bounded variance, a rate of @xmath was
proved. For this, the authors employed a decreasing stepsize strategy:
@xmath , where @xmath is a positive constant. In [ 60 ] , the authors
first describe several almost sure convergence results in the case of
general non-convex coercive functions, and then provide a complexity
analysis for the case of quadratic strongly convex function. However,
the established rate is slow. More precisely, for strongly convex
quadratic and coercive functions, mSGD with diminishing stepsizes @xmath
was shown to convergence as @xmath when the momentum parameter is @xmath
, and with the rate @xmath when @xmath . The convergence rates
established in both of these papers are sublinear. In particular, no
insight is provided into whether the inclusion of the momentum term
provides what it was aimed to provide: acceleration.

The above results are summarized in the second part of Table 2.1 . From
this perspective, our contribution lies in providing an in-depth
analysis of mSGD (and, additionally, of SGD with stochastic momentum).

Many recent papers have built upon our analysis [ 115 , 114 ] and have
already extended our results in several settings. For more details see [
18 , 121 , 40 , 3 , 41 ] .

###### On definitions of convergence presented in Table 2.1.

In Table 2.1 we present two main notions to characterize the convergence
guarantees presented in the literature for the analysis of deterministic
and stochastic heavy ball methods. These are, (i) Local/ Global
convergence and (ii) Asymptotic/ Non-asymptotic convergence. For
clarity, in this paragraph, we present these definitions of convergence.

Local convergence we have only if the convergence guarantees depend on
the starting point of the method. That is, if we can guarantee
convergence only if @xmath is in a neighborhood of the optimal point
@xmath . If the method convergence for any starting point then we have
global convergence.

We have asymptotic convergence when the provided rate can be shown to
hold only after specific number of iterations. For example, we say that
a deterministic method converges with asymptotic linear rate if there is
@xmath such that for @xmath we have @xmath , where @xmath . We have a
non-asymptotic convergence if the rate satisfy the above definition for
@xmath .

#### 2.2.3 Connection to incremental gradient methods

Assuming @xmath is discrete distribution (i.e., we sample from @xmath
matrices, @xmath , where @xmath is chosen with probability @xmath .
Here, @xmath is fixed.), we can write the stochastic optimization
problem ( 1.6 ) in the finite-sum form

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

Choosing @xmath , mSGD with fixed stepsize @xmath applied to ( 2.1 ) can
be written in the form

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

where @xmath with probability @xmath . Problem ( 2.1 ) can be also
solved using incremental average/aggregate gradient methods, such as the
IAG method of Blatt et al. [ 13 ] . These methods have a similar form to
( 2.2 ); however the past gradients are aggregated somewhat differently.
While ( 2.2 ) uses a geometric weighting of the gradients, the
incremental average gradient methods use a uniform/arithmetic weighting.
The stochastic average gradient (SAG) method of Schmidt et al. [ 173 ]
can be also written in a similar form. Note that mSGD uses a geometric
weighting of previous gradients, while the the incremental and
stochastic average gradient methods use an arithmetic weighting.
Incremental and incremental average gradient methods are widely studied
algorithms for minimizing objective functions which can expressed as a
sum of finite convex functions. For a review of key works on incremental
methods and a detailed presentation of the connections with stochastic
gradient descent, we refer the interested reader to the excellent survey
of Bertsekas [ 11 ] ; see also the work of Tseng [ 188 ] .

In [ 77 ] , an incremental average gradient method with momentum was
proposed for minimizing strongly convex functions. It was proved that
the method converges to the optimum with linear rate. The rate is always
worse than that of the no-momentum variant. However, it was shown
experimentally that in practice the method is faster, especially in
problems with high condition number. In our setting, the objective
function has a very specifc structure ( 1.6 ). It is not a finite sum
problem as the distribution @xmath could be continous; and we also do
not assume strong convexity. Thus, the convergence analysis of [ 77 ]
can not be directly applied to our problem.

#### 2.2.4 Summary of contributions

We now summarize the contributions of this chapter.

New momentum methods. We study several classes of stochastic
optimization algorithms (SGD, SN, SPP and SDSA) with momentum , which we
call mSGD, mSN, mSPP and mSDSA, respectively (see the first and second
columns of Table 2.2 ). We do this in a simplified setting with
quadratic objectives where all of these algorithms are equivalent. These
methods can be seen as solving three related optimization problems: the
stochastic optimization problem ( 1.6 ), the best approximation problem
( 1.22 ) and its dual. To the best of our knowledge, momentum variants
of SN, SPP and SDSA were not analyzed before.

Linear rate. We prove several (global and non-asymptotic) linear
convergence results for our primal momentum methods mSGD/mSN/mSPP.
First, we establish a linear rate for the decay of @xmath to zero, for a
range of stepsizes @xmath and momentum parameters @xmath . We show that
the same rate holds for the decay of the expected function values @xmath
of ( 1.6 ) to zero. Further, the same rate holds for mSDSA, in
particular, this is for the convergence of the dual objective to the
optimum. For a summary of these results, and pointers to the relevant
theorems, refer to lines 1, 2 and 6 of Table 2.3 . Unfortunately, the
theoretical rate for all our momentum methods is optimized for @xmath ,
and gets worse as the momentum parameter increases. However, no prior
linear rate for any of these methods with momentum are known. We give
the first linear convergence rate for SGD with momentum (i.e., for the
stochastic heavy ball method).

Accelerated linear rate. We then study the decay of the larger quantity
@xmath to zero. In this case, we establish an accelerated linear rate,
which depends on the square root of the condition number (of the Hessian
of @xmath ). This is a quadratic speedup when compared to the
no-momentum methods as these depend on the condition number. See lines 4
and 5 of Table 2.3 . To the best of our knowledge, this is the first
time an accelerated rate is obtained for the stochastic heavy ball
method (mSGD). Note that there are no global non-asymptotic accelerated
linear rates proved even in the non-stochastic setting (i.e., for the
heavy ball method). Moreover, we are not aware of any accelerated linear
convergence results for the stochastic proximal point method.

Sublinear rate for Cesàro averages. We show that the Cesàro averages,
@xmath , of all primal momentum methods enjoy a sublinear @xmath rate
(see line 3 of Table 2.3 ). This holds under weaker assumptions than
those which lead to the linear convergence rate.

Primal-dual correspondence. We show that SGD, SN and SPP with momentum
arise as affine images of SDSA with momentum (see Theorem 12 ). This
extends the result of [ 74 ] where this was shown for the no-momentum
methods ( @xmath ) and in the special case of the unit stepsize ( @xmath
).

Stochastic momentum. We propose a new momentum strategy, which we call
stochastic momentum . Stochastic momentum is a stochastic
(coordinate-wise) approximation of the deterministic momentum, and hence
is much less costly, which in some situations leads to computational
savings in each iteration. On the other hand, the additional noise
introduced this way increases the number of iterations needed for
convergence. We analyze the SGD, SN and SPP methods with stochastic
momentum, and prove linear convergence rates. We prove that in some
settings the overall complexity of SGD with stochastic momentum is
better than the overall complexity of SGD with momentum. For instance,
this is the case if we consider the randomized Kaczmarz (RK) method as a
special case of SGD, and if @xmath is sparse.

Space for generalizations. We hope that the present work can serve as a
starting point for the development of SN, SPP and SDSA methods with
momentum for more general classes (beyond special quadratics) of convex
and perhaps also nonconvex optimization problems. In such more general
settings, however, the symmetry which implies equivalence of these
algorithms will break, and hence a different analysis will be needed for
each method.

### 2.3 Primal Methods with Momentum

Applied to problem ( 1.6 ), i.e., @xmath the gradient descent method
with momentum (also known as the heavy ball method) of Polyak [ 156 ,
157 ] takes the form

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

where @xmath is a stepsize and @xmath is a momentum parameter. Instead
of marrying the momentum term with gradient descent, we can marry it
with SGD. This leads to SGD with momentum (mSGD), also known as the
stochastic heavy ball method :

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

Since SGD is equivalent to SN and SPP, this way we obtain momentum
variants of the stochastic Newton (mSN) and stochastic proximal point
(mSPP) methods. The method is formally described below:

1: Distribution @xmath from which method samples matrices; positive
definite matrix @xmath ; stepsize/relaxation parameter @xmath ; the
heavy ball/momentum parameter @xmath .

2: Choose initial points @xmath

3: for @xmath do

4: Generate a fresh sample @xmath

5: Set @xmath

6: end for

7: Output: The last iterate @xmath

Algorithm 1 mSGD / mSN / mSPP

To the best of our knowledge, momentum variants of SN and SPP were not
considered in the literature before. Moreover, as far as we know, there
are no momentum variants of even deterministic variants of ( 1.18 ), (
1.19 ) and ( 1.25 ), such as incremental or batch Newton method,
incremental or batch proximal point method and incremental or batch
projection method; not even for a problem formulated differently.

In the rest of this section we state our convergence results for
mSGD/mSN/mSPP.

#### 2.3.1 Convergence of iterates and function values: linear rate

In this section we study the convergence rate of the quantity @xmath to
zero for mSGD/mSN/mSPP . We show that for a range of stepsize parameters
@xmath and momentum terms @xmath , the method enjoys global linear
convergence rate; see ( 2.5 ). To the best of our knowledge, these
results are the first of their kind for the stochastic heavy ball
method. As a corollary of this result, we obtain convergence of the
expected function values; see ( 2.6 ).

###### Theorem 8.

Choose @xmath . Assume exactness. Let @xmath be the sequence of random
iterates produced by mSGD/mSN/mSPP. Assume @xmath and @xmath and that
the expressions

  -- -------- --
     @xmath   
  -- -------- --

satisfy @xmath . Let @xmath . Then

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

where @xmath and @xmath . Moreover, @xmath .

###### Proof.

See Section 2.9.2 . ∎

In the above theorem we obtain a global linear rate. To the best of our
knowledge, this is the first time that linear rate is established for a
stochastic variant of the heavy ball method (mSGD) in any setting. All
existing results are sublinear. These seem to be the first momentum
variants of SN and SPP methods.

If we choose @xmath , then the condition @xmath is satisfied for all

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

If @xmath , mSGD reduces to SGD analyzed in [ 168 ] . In this special
case, @xmath , which is the rate established in [ 168 ] . Hence, our
result is more general.

Let @xmath be the rate as a function of @xmath . Note that since @xmath
, we have

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (2.8)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Clearly, the lower bound on @xmath is an increasing function of @xmath .
Also, for any @xmath the rate is always inferior to that of SGD ( @xmath
). It is an open problem whether one can prove a strictly better rate
for mSGD than for SGD.

Our next proposition states that @xmath (recall that @xmath ) for all
iterations @xmath of mSGD. This invariance property plays an important
role in our convergence analysis, and “explains” why the algorithm to
converges to @xmath .

###### Proposition 9.

Let @xmath be the starting points of the mSGD method and let @xmath be
the random iterates generated by mSGD. Then @xmath for all @xmath .

###### Proof.

Note that in view of ( 1.7 ), @xmath . Since

  -- -------- --
     @xmath   
  -- -------- --

and since @xmath , it can shown by induction that @xmath for all @xmath
. However, @xmath is the orthogonal complement to @xmath in the @xmath
-inner product. Since @xmath is parallel to @xmath , vectors @xmath must
have the same @xmath -projection onto @xmath for all @xmath : @xmath . ∎

This property also intuitively explains why mSGD converges to the
projection of the starting point onto @xmath . Indeed, one may ask: why
is the starting point special? After all, each iterate depends on the
previous two iterates only, and all older iterates, including the
starting point @xmath , seem to be eventually “forgotten”. Still, the
iterative process has the property that all iterates live in the affine
space passing through @xmath and orthogonal to @xmath , which means that
the projection of all iterates onto @xmath is identical.

#### 2.3.2 Cesàro average: sublinear rate without exactness assumption

In this section we present the convergence analysis of the function
values computed on the Cesàro average. Again our results are global in
nature. To the best of our knowledge these are the first results that
show @xmath convergence of the stochastic heavy ball method. Existing
results apply in more general settings at the expense of slower rates.
In particular, [ 206 ] and [ 60 ] get @xmath and @xmath convergence when
@xmath , respectively. When @xmath , [ 60 ] gets @xmath rate.

###### Theorem 10.

Choose @xmath and let @xmath be the random iterates produced by
mSGD/mSN/ mSPP, where the momentum parameter @xmath and relaxation
parameter (stepsize) @xmath satisfy @xmath . Let @xmath be any vector
satisfying @xmath . If we let @xmath , then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Section 2.9.3 . ∎

In the special case of @xmath , the above theorem gives the rate

  -- -------- --
     @xmath   
  -- -------- --

This is the convergence rate for Cesàro averages of the “basic method”
(i.e., SGD) established in [ 168 ] .

Our proof strategy is similar to [ 62 ] in which the first global
convergence analysis of the (deterministic) heavy ball method was
presented. There it was shown that when the objective function has a
Lipschitz continuous gradient, the Cesàro averages of the iterates
converge to the optimum at a rate of @xmath . To the best of our
knowledge, there are no results in the literature that prove the same
rate of convergence in the stochastic case for any class of objective
functions.

In [ 206 ] the authors analyzed mSGD for general Lipshitz continuous
convex objective functions (with bounded variance) and proved the
sublinear rate @xmath . In [ 60 ] , a complexity analysis is provided
for the case of quadratic strongly convex smooth coercive functions. A
sublinear convergence rate of @xmath , where @xmath , was proved. In
contrast to our results, where we assume fixed stepsize @xmath , both
papers analyze mSGD with diminishing stepsizes.

#### 2.3.3 Accelerated linear rate for expected iterates

In this section we show that by a proper combination of the relaxation
(stepsize) parameter @xmath and the momentum parameter @xmath ,
mSGD/mSN/mSPP enjoy an accelerated linear convergence rate in mean. That
is, while SGD needs @xmath iterations to find @xmath such that @xmath [
168 ] , mSGD only needs @xmath iterations (see Theorem 11 (ii)), where
@xmath . The word acceleration typically refers to improvement from a
leading factor of @xmath to @xmath , which is significant in the
ill-conditioned case, i.e., when @xmath is very large. In other words,
the linear rate @xmath of mSGD is much better than linear rate @xmath of
SGD, which in view of ( 2.8 ) is better than the linear rate of mSGD
established in ( 2.5 ) (for a different quantity converging to zero) .

###### Theorem 11.

Assume exactness. Let @xmath be the sequence of random iterates produced
by mSGD / mSN / mSPP, started with @xmath satisfying the relation @xmath
, with relaxation parameter (stepsize) @xmath and momentum parameter
@xmath . Let @xmath . Then there exists constant @xmath such that for
all @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

-    If we choose @xmath and @xmath then @xmath and the iteration
    complexity becomes @xmath .

-    If we choose @xmath and @xmath then @xmath and the iteration
    complexity becomes @xmath .

###### Proof.

See Section 2.9.4 . ∎

Note that the convergence factor is precisely equal to the value of the
momentum parameter @xmath . Let @xmath be any random vector in @xmath
with finite mean @xmath , and @xmath is any reference vector (for
instance, any solution of @xmath ). Then we have the identity (see, for
instance [ 73 ] )

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

This means that the quantity @xmath appearing in the convergence result
of Theorem 8 is larger than @xmath appearing in the the convergence
result of Theorem 11 , and hence harder to push to zero. As a corollary,
the convergence rate of @xmath to zero established in Theorem 8 )
implies the same rate for the convergence of @xmath to zero. However,
note that in Theorem 11 we have established an accelerated rate for
@xmath . A similar theorem, also obtaining an accelerated rate for
@xmath , was established in [ 168 ] for an accelerated variant of SGD in
the sense of Nesterov.

### 2.4 Dual Methods with Momentum

In the previous sections we focused on methods for solving the
stochastic optimization problem ( 1.6 ) and the best approximation
problem ( 1.22 ). In this section we focus on the dual of the best
approximation problem, and propose a momentum variant of SDSA, which we
call mSDSA.

1: Distribution @xmath from which method samples matrices; positive
definite matrix @xmath ; stepsize/relaxation parameter @xmath the heavy
ball/momentum parameter @xmath .

2: Choose initial points @xmath

3: for @xmath do

4: Draw a fresh @xmath

5: Set @xmath

6: Set @xmath

7: end for

8: Output: last iterate @xmath

Algorithm 2 Stochastic Dual Subspace Ascent with Momentum (mSDSA)

#### 2.4.1 Correspondence between primal and dual methods

In our first result we show that the random iterates of the
mSGD/mSN/mSPP methods arise as an affine image of mSDSA under the
mapping @xmath defined in ( 1.27 ).

###### Theorem 12 (Correspondence Between Primal and Dual Methods).

Let @xmath and let @xmath be the iterates of mSGD/mSN/mSPP. Let @xmath ,
and let @xmath be the iterates of mSDSA. Assume that the methods use the
same stepsize @xmath , momentum parameter @xmath , and the same sequence
of random matrices @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . That is, the primal iterates arise as affine images of
the dual iterates.

###### Proof.

First note that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

We now use this to show that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

So, the sequence of vectors @xmath mSDSA satisfies the same recursion of
degree as the sequence @xmath defined by mSGD. It remains to check that
the first two elements of both recursions coincide. Indeed, since @xmath
and @xmath , we have @xmath , and @xmath . ∎

#### 2.4.2 Convergence

We are now ready to state a linear convergence convergence result
describing the behavior of mSDSA in terms of the dual function values
@xmath .

###### Theorem 13 (Convergence of dual objective).

Choose @xmath . Assume exactness. Let @xmath be the sequence of random
iterates produced by mSDSA. Assume @xmath and @xmath and that the
expressions

  -- -------- --
     @xmath   
  -- -------- --

satisfy @xmath . Let @xmath and let @xmath be any dual optimal solution.
Then

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

where @xmath and @xmath . Moreover, @xmath .

###### Proof.

This follows by applying Theorem 8 together with Theorem 12 and the
identity @xmath . ∎

Note that for @xmath , mSDSA simplifies to SDSA. Also recall that for
unit stepsize ( @xmath ), SDSA was analyzed in [ 73 ] . In the @xmath
and @xmath case, our result specializes to that established in [ 73 ] .
Following similar arguments to those in [ 73 ] , the same rate of
convergence can be proved for the duality gap @xmath .

### 2.5 Methods with Stochastic Momentum

To motivate stochastic momentum , for simplicity fix @xmath , and assume
that @xmath is chosen as the @xmath th random unit coordinate vector of
@xmath with probability @xmath . In this case, SGD ( 1.17 ) reduces to
the randomized Kaczmarz method for solving the linear system @xmath ,
first analyzed for @xmath by Strohmer and Vershynin [ 182 ] .

In this case, mSGD becomes the randomized Kaczmarz method with momentum
(mRK), and the iteration ( 2.4 ) takes the explicit form

  -- -------- --
     @xmath   
  -- -------- --

Note that the cost of one iteration of this method is @xmath , where the
cardinality term @xmath comes from the stochastic gradient part, and
@xmath comes from the momentum part. When @xmath is sparse, the second
term will dominate. Similar considerations apply for many other (but
clearly not all) distributions @xmath .

In such circumstances, we propose to replace the expensive-to-compute
momentum term by a cheap-to-compute stochastic approximation term . In
particular, we let @xmath be chosen from @xmath uniformly at random, and
replace @xmath with @xmath , where @xmath is the @xmath -th unit basis
vector in @xmath , and @xmath with @xmath . Note that @xmath can be
computed in @xmath time. Moreover,

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

Hence, we replace the momentum term by an unbiased estimator, which
allows us to cut the cost to @xmath .

#### 2.5.1 Primal methods with stochastic momentum

We now propose a variant of the SGD/SN/SPP methods employing stochastic
momentum (smSGD/smSN/smSPP). Since SGD, SN and SPP are equivalent, we
will describe the development from the perspective of SGD. In
particular, we propose the following method:

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

The method is formalized below:

1: Distribution @xmath from which the method samples matrices;
stepsize/relaxation parameter @xmath the heavy ball/momentum parameter
@xmath .

2: Choose initial points @xmath ; set @xmath

3: for @xmath do

4: Generate a fresh sample @xmath .

5: Pick @xmath uniformly at random

6: Set @xmath

7: end for

8: Output: The last iterate @xmath

Algorithm 3 smSGD/smSN/smSPP

#### 2.5.2 Convergence

In the next result we establish linear convergence of smSGD/smSN/smSPP.
For this we will require the matrix @xmath to be equal to the identity
matrix.

###### Theorem 14.

Choose @xmath . Assume exactness. Let @xmath . Let @xmath be the
sequence of random iterates produced by smSGD/smSN/smSPP. Assume @xmath
and @xmath and that the expressions

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

satisfy @xmath . Let @xmath . Then

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

and @xmath where @xmath and @xmath . Moreover, @xmath .

###### Proof.

See Section 2.9.5 . ∎

It is straightforward to see that if we choose @xmath , then the
condition @xmath is satisfied for all @xmath belonging to the interval

  -- -------- --
     @xmath   
  -- -------- --

The upper bound is similar to that for mSGD/mSN/mSPP; the only
difference is an extra factor of @xmath next to the constant 16.

#### 2.5.3 Momentum versus stochastic momentum

As indicated above, if we wish to compare mSGD with momentum parameter
@xmath to smSGD with momentum parameter @xmath , it makes sense to set
@xmath . Indeed, this is because in view of ( 2.11 ), the momentum term
in smSGD will then be an unbiased estimator of the deterministic
momentum term used in mSGD.

Let @xmath be the convergence constant for mSGD with stepsize @xmath and
an admissible momentum parameter @xmath . Further, let @xmath be the
convergence constants for smSGD with stepsize @xmath and momentum
parameter @xmath . We have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Hence, the lower bound on the rate for smSGD is worse than the lower
bound for mSGD.

The same conclusion holds for the convergence rates themselves. Indeed,
note that since @xmath and @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

and hence the rate of mSGD is always better than that of smSGD.

However, the expected cost of a single iteration of mSGD may be
significantly larger than that of smSGD. Indeed, let @xmath be the
expected cost of evaluating a stochastic gradient. Then we need to
compare @xmath (mSGD) against @xmath (smSGD). If @xmath , then one
iteration of smSGD is significantly cheaper than one iteration of mSGD.
Let us now compare the total complexity to investigate the trade-off
between the rate and cost of stochastic gradient evaluation. Ignoring
constants, the total cost of the two methods (cost of a single iteration
multiplied by the number of iterations) is:

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

Since

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

and since @xmath and @xmath are continuous functions of @xmath , then
because @xmath , for small enough @xmath we will have @xmath In
particular, the speedup of smSGD compared to mSGD for @xmath will be
close to

  -- -------- --
     @xmath   
  -- -------- --

Thus, we have shown the following statement.

###### Theorem 15.

For small momentum parameters satisfying @xmath , the total complexity
of smSGD is approximately @xmath times smaller than the total complexity
of mSGD, where @xmath is the number of columns of @xmath , and @xmath is
the expected cost of evaluating a stochastic gradient @xmath .

### 2.6 Special Cases: Randomized Kaczmarz with Momentum and Randomized
Coordinate Descent with Momentum

In Table 2.4 we specify several special instances of mSGD by choosing
distinct combinations of the parameters @xmath and @xmath . We use
@xmath to denote the @xmath th unit coordinate vector in @xmath , and
@xmath for the column submatrix of the @xmath identity matrix indexed by
(a random) set @xmath .

The updates for smSGD can be derived by substituting the momentum term
@xmath with its stochastic variant @xmath . We do not aim to be
comprehensive. For more details on the possible combinations of the
parameters @xmath and @xmath we refer the interested reader to Section 3
of [ 73 ] .

In the rest of this section we present in detail two special cases: the
randomized Kaczmarz method with momentum (mRK) and the randomized
coordinate descent method with momentum (mRCD). Further, we compare the
convergence rates obtained in Theorem 11 (i.e., bounds on @xmath ) with
rates that can be inferred from known results for their no-momentum
variants.

#### 2.6.1 mRK: randomized Kaczmarz with momentum

We now provide a discussion on mRK (the method in the first row of Table
2.4 ). Let @xmath and let pick in each iteration the random matrix
@xmath with probability @xmath . In this setup the update rule of the
mSGD simplifies to

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.18)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

The objective function takes the following form:

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

For @xmath , this method reduces to the randomized Kaczmarz method with
relaxation, first analyzed in [ 168 ] . If we also have @xmath , this is
equivalent with the randomized Kaczmarz method of Strohmer and Vershynin
[ 182 ] . RK without momentum ( @xmath ) and without relaxation ( @xmath
) converges with iteration complexity [ 182 , 73 , 74 ] of

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

In contrast, based on Theorem 11 we have

-   For @xmath and @xmath , the iteration complexity of the mRK is:

      -- -------- --
         @xmath   
      -- -------- --

-   For @xmath and @xmath the iteration complexity becomes:

      -- -------- --
         @xmath   
      -- -------- --

This is quadratic improvement on the previous best result ( 2.20 ).

###### Related Work.

The Kaczmarz method for solving consistent linear systems was originally
introduced by Kaczmarz in 1937 [ 91 ] . This classical method selects
the rows to project onto in a cyclic manner. In practice, many different
selection rules can be adopted. For non-random selection rules (cyclic,
greedy, etc) we refer the interested reader to [ 158 , 17 , 144 , 159 ,
27 ] . In this work we are interested in randomized variants of the
Kaczmarz method, first analyzed by Strohmer and Vershynin [ 182 ] . In [
182 ] it was shown that RK converges with a linear convergence rate to
the unique solution of a full-rank consistent linear system. This result
sparked renewed interest in design of randomized methods for solving
linear systems [ 132 , 134 , 49 , 120 , 216 , 135 , 175 , 114 ] . All
existing results on accelerated variants of RK use the Nesterov’s
approach of acceleration [ 102 , 107 , 192 , 168 ] . To the best of our
knowledge, no convergence analysis of mRK exists in the literature
(Polyak’s momentum). Our work fills this gap.

#### 2.6.2 mRCD: randomized coordinate descent with momentum

We now provide a discussion on the mRCD method (the method in the second
row of Table 2.4 ). If the matrix @xmath is positive definite, then we
can choose @xmath and @xmath with probability @xmath . It is easy to see
that @xmath . In this case, @xmath is positive definite and as a result,
@xmath . Moreover, we have

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

For @xmath and @xmath the method is equivalent with randomized
coordinate descent of Leventhal and Lewis [ 104 ] , which was shown to
converge with iteration complexity

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

In contrast, following Theorem 11 , we can obtain the following
iteration complexity results for mRCD:

-   For @xmath and @xmath , the iteration complexity is

      -- -------- --
         @xmath   
      -- -------- --

-   For @xmath and @xmath the iteration complexity becomes

      -- -------- --
         @xmath   
      -- -------- --

This is quadratic improvement on the previous best result ( 2.22 ).

###### Related Work.

It is known that if @xmath is positive definite, the popular randomized
Gauss-Seidel method can be interpreted as randomized coordinate descent
(RCD). RCD methods were first analyzed by Lewis and Leventhal in the
context of linear systems and least-squares problems [ 104 ] , and later
extended by several authors to more general settings, including smooth
convex optimization [ 139 ] , composite convex optimization [ 166 ] ,
and parallel/subspace descent variants [ 167 ] . These results were
later further extended to handle arbitrary sampling distributions [ 160
, 161 , 163 , 22 ] . Accelerated variants of RCD were studied in [ 102 ,
51 , 2 ] . For other non-randomized coordinate descent variants and
their convergence analysis, we refer the reader to [ 199 , 143 , 27 ] .
To the best of our knowledge, mRCD and smRCD have never been analyzed
before in any setting.

#### 2.6.3 Visualizing the acceleration mechanism

We devote this section to the graphical illustration of the acceleration
mechanism behind momentum. Our goal is to shed more light on how the
proposed algorithm works in practice. For simplicity, we illustrate this
by comparing RK and mRK.

In Figure 2.1 we present in a simple @xmath illustration of the
difference between the workings of RK and mRK. Our goal is to show
graphically how the addition of momentum leads to acceleration. Given
iterate @xmath , one can think of the update rule of the mRK ( 2.4 ) in
two steps:

1.  The Projection: The projection step corresponds to the first part
    @xmath of the mRK update ( 2.4 ) and it means that the current
    iterate @xmath is projected onto a randomly chosen hyperplane @xmath
    ¹ ¹ 1 In the plots of Figure 2.1 , the hyperplane of each update is
    chosen in an alternating fashion for illustration purposes . The
    value of the stepsize @xmath defines whether the projection is exact
    or not. When @xmath (no relaxation) the projection is exact, that is
    the point @xmath belongs in the hyperplane @xmath . In Figure 2.1
    all projections are exact.

2.  Addition of the momentum term : The momentum term (right part of the
    update rule) @xmath forces the next iterate @xmath to be closer to
    the solution @xmath than the corresponding point @xmath . Note also
    that the vector @xmath is always parallel to @xmath for all @xmath .

###### Remark 1.

In the example of Figure 2.1 , the performance of mRK is similar to the
performance of RK until iterate @xmath . After this point, the momentum
parameter becomes more effective and the mRK method accelerates. This
behavior appears also in our experiments in the next section where we
work with matrices with many rows. There we can notice that the momentum
parameter seems to become more effective after the first @xmath
iterations.

### 2.7 Numerical Experiments

In this section we study the computational behavior of the two proposed
algorithms, mSGD and smSGD. In particular, we focus mostly on the
evaluation of the performance of mSGD. To highlight the usefulness of
smSGD, an empirical verification of Theorem 15 is presented in
subsection 2.7.2 . As we have already mentioned, both mSGD and smSGD can
be interpreted as sketch-and-project methods (with relaxation), and as a
result a comprehensive array of well-known algorithms can be recovered
as special cases by varying the main parameters of the methods (check
Section 2.6 ). In our experiments we focus on the popular special cases
of randomized Kaczmarz method (RK) and the randomized coordinate descent
method (RCD) without relaxation ( @xmath ), and show the practical
benefits of adding the momentum term ² ² 2 The experiments were repeated
with various values of the main parameters and initializations, and
similar results were obtained in all cases. . The choice of the stepsize
@xmath is not arbitrary. Recently, in [ 168 ] both relaxed RK and
relaxed RCD were analyzed, and it was proved that the quantity @xmath
converges linearly to zero for @xmath , and that the best convergence
rate is obtained precisely for @xmath . Thus the comparison is with the
best-in-theory no-momentum variants.

Note that, convergence analysis of the error @xmath and of the expected
function values @xmath in Theorem 8 shows that mSGD enjoys global
non-asymptotic linear convergence rate but not faster than the
no-momentum method. The accelerated linear convergence rate has been
obtained only in the weak sense (Theorem 11 ). Nevertheless, in practice
as indicated from our experiments, mSGD is faster than its no momentum
variant. Note also that in all of the presented experiments the momentum
parameters @xmath of the methods are chosen to be positive constants
that do not depend on parameters that are not known to the users such as
@xmath and @xmath .

In comparing the methods with their momentum variants we use both the
relative error measure @xmath and the function values @xmath ³ ³ 3
Remember that in our setting we have @xmath for the optimal solution
@xmath of the best approximation problem; thus @xmath . The function
values @xmath refer to function ( 2.19 ) in the case of RK and to
function ( 2.21 ) for the RCD. For block variants the objective function
of problem ( 1.6 ) has also closed form expression but it can be very
difficult to compute. In these cases one can instead evaluate the
quantity @xmath . . In all implementations, except for the experiments
on average consensus (Section 2.7.3 ), the starting point is chosen to
be @xmath . In the case of average consensus the starting point must be
the vector with the initial private values of the nodes of the network.
All the code for the experiments is written in the Julia programming
language. For the horizontal axis we use either the number of iterations
or the wall-clock time measured using the tic-toc Julia function.

This section is divided in three main experiments. In the first one we
evaluate the performance of the mSGD method in the special cases of mRK
and mRCD for solving both synthetic consistent Gaussian systems and
consistent linear systems with real matrices. In the second experiment
we computationally verify Theorem 15 (comparison between the mSGD and
smSGD methods). In the last experiment building upon the recent results
of [ 113 ] we show how the addition of the momentum accelerates the
pairwise randomized gossip (PRG) algorithm for solving the average
consensus problem.

#### 2.7.1 Evaluation of mSGD

In this subsection we study the computational behavior of mRK and mRCD
when they compared with their no momentum variants for both synthetic
and real data.

##### Synthetic Data

The synthetic data for this comparison is generated as follows ⁴ ⁴ 4
Note that in the first experiment we use Gaussian matrices which by
construction are full rank matrices with probability 1 and as a result
the consistent linear systems have unique solution. Thus, for any
starting point @xmath , the vector @xmath that is used to create the
linear system is the solution mSGD converges to. This is not true for
general consistent linear systems, with no full-rank matrix. In this
case, the solution @xmath that mSGD converges to is not necessarily
equal to @xmath . For this reason, in the evaluation of the relative
error measure @xmath , one should be careful and use the value @xmath .
.

For mRK: All elements of matrix @xmath and vector @xmath are chosen to
be i.i.d @xmath . Then the right hand side of the linear system is set
to @xmath . With this way the consistency of the linear system with
matrix @xmath and right hand side @xmath is ensured.

For mRCD: A Gaussian matrix @xmath is generated and then matrix @xmath
is used in the linear system. The vector @xmath is chosen to be i.i.d
@xmath and again to ensure consistency of the linear system, the right
hand side is set to @xmath .

In particular for the evaluation of mRK we generate Gaussian matrices
with @xmath rows and several columns while for the case of mRCD the
matrix @xmath is chosen to be Gaussian with @xmath rows and several
columns ⁵ ⁵ 5 RCD converge to the optimal solution only in the case of
positive definite matrices. For this reason @xmath is used which with
probability @xmath is a full rank matrix . Linear systems of these forms
were extensively studied [ 182 , 61 ] and it was shown that the quantity
@xmath (condition number) can be easily controlled.

For each linear system we run mRK (Figures 2.2 and 2.3 ) and mRCD
(Figures 2.4 and 2.5 ) for several values of momentum parameters @xmath
and fixed stepsize @xmath and we plot the performance of the methods
(average after 10 trials) for both the relative error measure and the
function values. Note that for @xmath the methods are equivalent with
their no-momentum variants RK and RCD respectively.

From Figures 2.2 , 2.3 , 2.4 and 2.5 it is clear that the addition of
momentum term leads to an improvement in the performance of both, RK and
RCD. More specifically, from the four figures we observe the following:

-   For the well conditioned linear systems ( @xmath small) it is known
    that even the no-momentum variant converges rapidly to the optimal
    solution. In these cases the benefits of the addition of momentum
    are not obvious. The momentum term is beneficial for the case where
    the no-momentum variant ( @xmath ) converges slowly, that is when
    @xmath is large (ill-conditioned linear systems).

-   For the case of fixed stepsize @xmath , the problems with small
    condition number require smaller momentum parameter @xmath to have
    faster convergence. Note the first two rows of Figures 2.2 and 2.4 ,
    where @xmath or @xmath , are good options.

-   For large values of @xmath , it seems that the choice of @xmath is
    the best. As an example for matrix @xmath in Figure 2.2 , (where
    @xmath ), note that to reach relative error @xmath , RK needs around
    2 million iterations, while mRK with momentum parameter @xmath
    requires only half that many iterations. The acceleration is obvious
    also in terms of time where in 12 seconds the mRK with momentum
    parameter @xmath achieves relative error of the order @xmath and RK
    requires more than 25 seconds to obtain the same accuracy.

-   We observe that both mRK and mRCD, with appropriately chosen
    momentum parameters @xmath , always converge faster than their
    no-momentum variants, RK and RCD, respectively. This is a smaller
    momentum parameter than @xmath which is being used extensively with
    mSGD for training deep neural networks [ 211 , 196 , 185 ] .

-   In [ 203 ] a stochastic power iteration with momentum is proposed
    for principal component analysis (PCA). There it was demonstrated
    empirically that a naive application of momentum to the stochastic
    power iteration does not result in a faster method. To achieve
    faster convergence, the authors proposed mini-batch and
    variance-reduction techniques on top of the addition of momentum. In
    our setting, mere addition of the momentum term to SGD (same is true
    for special cases such as RK and RCD) leads to empirically faster
    methods.

##### Real Data

In the following experiments we test the performance of mRK using real
matrices (datasets) from the library of support vector machine problems
LIBSVM [ 23 ] . Each dataset consists of a matrix @xmath ( @xmath
features and @xmath characteristics) and a vector of labels @xmath . In
our experiments we choose to use only the matrices of the datasets and
ignore the label vector. As before, to ensure consistency of the linear
system, we choose a Gaussian vector @xmath and the right hand side of
the linear system is set to @xmath . Similarly as in the case of
synthetic data, mRK is tested for several values of momentum parameters
@xmath and fixed stepsize @xmath .

In Figure 2.6 the performance of all methods for both relative error
measure @xmath and function values @xmath is presented. Note again that
@xmath represents the baseline RK method. The addition of momentum
parameter is again often beneficial and leads to faster convergence. As
an example, inspect the plots for the mushrooms dataset in Figure 2.6 ,
where mRK with @xmath is much faster than the simple RK method in all
presented plots, both in terms of iterations and time. In particular,
the addition of a momentum parameter leads to visible speedup for the
datasets mushrooms , splice , a9a and ionosphere . For these datasets
the acceleration is obvious in all plots both in terms of relative error
and function values. For the datasets australian , gisette and madelon
the speedup is less obvious in the plots of the relative error, while
for the plots of function values it is not present at all.

#### 2.7.2 Comparison of momentum & stochastic momentum

In Theorem 15 , the total complexities (number of operations needed to
achieve a given accuracy) of mSGD and smSGD have been compared and it
has been shown that for small momentum parameter @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath represent the total costs of the two methods.
The goal of this experiment is to show that this relationship holds also
in practice.

For this experiment we assume that the non-zeros of matrix @xmath are
not concentrated in certain rows but instead that each row has the same
number of non-zero coordinates. We denote by @xmath the number the
non-zero elements per row. Having this assumption it can be shown that
for the RK method the cost of one projection is equal to @xmath
operations while the cost per iteration of the mRK and of the smRK are
@xmath and @xmath respectively. For more details about the cost per
iteration of the general mSGD and smSGD check Table 2.6 .

As a first step a Gaussian matrix @xmath is generated. Then using this
matrix several consistent linear systems are obtained as follows.
Several values for @xmath are chosen and for each one of these a matrix
@xmath with the same elements as @xmath but with @xmath zero coordinates
per row is produced. For every matrix @xmath , a Gaussian vector @xmath
is drawn and to ensure consistency of the linear system, the right hand
side is set to @xmath .

We run both mSGD and smSGD with small momentum parameter @xmath for
solving the linear systems @xmath for all selected values of @xmath .
The starting point for each run is taken to be @xmath . The methods run
until @xmath , where @xmath ⁶ ⁶ 6 To pre-compute the solution @xmath for
each linear system @xmath we use the closed form expression of the
projection ( 1.14 ). and @xmath is the solution set of the linear system
@xmath . In each run the number of operations needed to achieve the
accuracy @xmath have been counted. For each linear system the average
after @xmath trials of the value @xmath is computed.

In Figure 2.7 the actual ratio @xmath and the theoretical approximation
@xmath are plot and it is shown that they have similar behavior. Thus
the theoretical prediction of Theorem 15 is numerically confirmed. In
particular in the implementations we use the Gaussian matrices @xmath
and @xmath .

#### 2.7.3 Faster method for average consensus

##### Background

Average consensus (AC) is a fundamental problem in distributed computing
and multi-agent systems [ 42 , 16 ] . Consider a connected undirected
network @xmath with node set @xmath and edges @xmath , ( @xmath ), where
each node @xmath owns a private value @xmath . The goal of the AC
problem is for each node of the network to compute the average of these
private values, @xmath , via a protocol which allows communication
between neighbours only. The problem comes up in many real world
applications such as coordination of autonomous agents, estimation,
rumour spreading in social networks, PageRank and distributed data
fusion on ad-hoc networks and decentralized optimization.

It was shown recently that several randomized methods for solving linear
systems can be interpreted as randomized gossip algorithms for solving
the AC problem when applied to a special system encoding the underlying
network [ 74 , 113 ] . As we have already explained both basic method [
168 ] and basic method with momentum (this chapter) find the solution of
the linear system that is closer to the starting point of the
algorithms. That is, both methods converge linearly to @xmath ; the
projection of the initial iterate onto the solution set of the linear
system. As a result (check the Introduction) , they can be interpreted
as methods for solving the best approximation problem ( 1.22 ). In the
special case that

1.  the linear system in the constraints of ( 1.22 ) is the homogeneous
    linear system ( @xmath ) with matrix @xmath being the incidence
    matrix of the undirected graph @xmath , and

2.  the starting point of the method are the initial values of the nodes
    @xmath ,

it is straightforward to see that the solution of the best approximation
problem is a vector with all components equal to the consensus value
@xmath . Under this setting, the famous randomized pairwise gossip
algorithm (randomly pick an edge @xmath and replace the private values
of its two nodes to their average) that was first proposed and analyzed
in [ 16 ] , is equivalent to the RK method without relaxation ( @xmath )
[ 74 , 113 ] .

###### Remark 2.

In the gossip framework, the condition number of the linear system when
RK is used has a simple structure and it depends on the characteristics
of the network under study. More specifically, it depends on the number
of the edges @xmath and on the Laplacian matrix of the network ⁷ ⁷ 7
Matrix @xmath of the linear system is the incidence matrix of the graph
and it is known that the Laplacian matrix is equal to @xmath , where
@xmath . :

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

where @xmath is the Laplacian matrix of the network and the quantity
@xmath is the very well studied algebraic connectivity of the graph [ 31
] .

###### Remark 3.

The convergence analysis in this chapter holds for any consistent linear
system @xmath without any assumption on the rank of the matrix @xmath .
The lack of any assumption on the form of matrix @xmath allows us to
solve the homogeneous linear system @xmath where @xmath is the incidence
matrix of the network which by construction is rank deficient. More
specifically, it can be shown that @xmath [ 113 ] . Note that many
existing methods for solving linear systems make the assumption that the
matrix @xmath of the linear systems is full rank [ 182 , 132 , 134 ] and
as a result can not be used to solve the AC problem.

##### Numerical Setup

Our goal in this experiment is to show that the addition of the momentum
term to the randomized pairwise gossip algorithm (RK in the gossip
setting) can lead to faster gossip algorithms and as a result the nodes
of the network will converge to the average consensus faster both in
number of iterations and in time. We do not intend to analyze the
distributed behavior of the method (this is an ongoing research work).
In our implementations we use three of the most popular graph topologies
in the literature of wireless sensor networks. These are the line graph,
cycle graph and the random geometric graph @xmath . In practice, @xmath
consider ideal for modeling wireless sensor networks, because of their
particular formulation. In the experiments the @xmath -dimensional
@xmath is used which is formed by placing @xmath nodes uniformly at
random in a unit square with edges only between nodes that have
euclidean distance less than the given radius @xmath . To preserve the
connectivity of @xmath a radius @xmath is used [ 152 ] . The AC problem
is solved for the three aforementioned networks for both @xmath and
@xmath number of nodes. We run mRK with several momentum parameters
@xmath for 10 trials and we plot their average. Our results are
available in Figures 2.8 and 2.9 .

Note that the vector of the initial values of the nodes can be chosen
arbitrarily, and the proposed algorithms will find the average of these
values. In Figures 2.8 and 2.9 the initial value of each node is chosen
independently at random from the uniform distribution in the interval
@xmath .

##### Experimental Results

By observing Figures 2.8 and 2.9 , it is clear that the addition of the
momentum term improves the performance of the popular pairwise
randomized gossip (PRG) method [ 16 ] . The choice @xmath as the
momentum parameter improves the performance of the vanilla PRG for all
networks under study and @xmath is a good choice for the cases of the
cycle and line graph. Note that for networks such as the cycle and line
graphs there are known closed form expressions for the algebraic
connectivity [ 31 ] . Thus, using equation ( 2.23 ), we can compute the
exact values of the condition number @xmath for these networks.
Interestingly, as we can see in Table 2.7 for @xmath and @xmath (number
of nodes), the condition number @xmath appearing in the iteration
complexity of our methods is not very large. This is in contrast with
experimental observations from Section 2.7.1 where it was shown that the
choice @xmath is good for very ill conditioned problems only ( @xmath
very large).

### 2.8 Conclusion

In this chapter, we studied the convergence analysis of several
stochastic optimization algorithms enriched with heavy ball momentum for
solving stochastic optimization problems of special structure. We proved
global, non-asymptotic linear convergence rates of all of these methods
as well as accelerated linear rate for the case of the norm of expected
iterates. We also introduced a new momentum strategy called stochastic
momentum which is beneficial for the case of sparse data and proved
linear convergence in this setting. We corroborated our theoretical
results with extensive experimental testing.

Our work is amenable to further extensions. A natural extension of our
results is the analysis of heavy ball momentum variants of our proposed
methods (SGD,SN, SPP, etc) in the case of general convex or strongly
convex functions. While we have shown that the expected iterates
converge in an accelerated manner, it is an open problem whether an
accelerated rate can be established for the expected distance, i.e., for
@xmath . In our analysis we also focus on the case of fixed constant
step-size and momentum parameters. A study of the effect of decreasing
or adaptive choice of the parameters might provide novel insights.

The obtained results hold under the exactness condition which as we
explain is very weak, allowing for virtually arbitrary distributions
@xmath from which the random matrices are drawn. One may wish to design
optimized distributions in terms of the convergence rates or overall
complexity.

Finally, we show how the addition of momentum on top of gossip
algorithms can lead to faster convergence. An interesting question is to
interpret the distributed nature of these algorithms and try to
understand how we can improve the analysis using the properties of the
underlying network. This is precisely what we are doing later in Chapter
4 .

### 2.9 Proofs of Main Results

#### 2.9.1 Technical lemmas

###### Lemma 16.

Fix @xmath and let @xmath be a sequence of nonnegative real numbers
satisfying the relation

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

where @xmath , @xmath and at least one of the coefficients @xmath is
positive. Then the sequence satisfies the relation @xmath for all @xmath
where @xmath and @xmath . Moreover,

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

with equality if and only if @xmath (in which case @xmath and @xmath ).

###### Proof.

Choose @xmath . We claim @xmath and @xmath . Indeed, non-negativity of
@xmath follows from @xmath , while the second relation follows from the
fact that @xmath satisfies

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

In view of these two relations, adding @xmath to both sides of ( 2.24 ),
we get

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

Let us now argue that @xmath . Non-negativity of @xmath follows from
non-negativity of @xmath . Clearly, as long as @xmath , @xmath is
positive. If @xmath , then @xmath by assumption, which implies that
@xmath is positive. The inequality @xmath follows directly from the
assumption @xmath . By unrolling the recurrence ( 2.27 ), we obtain
@xmath

Finally, let us establish ( 2.27 ). Noting that @xmath , and since in
view of ( 2.26 ) we have @xmath , we conclude that @xmath , where the
inequality follows from @xmath . ∎

Finally, let us present a simple lemma of an identity that we use in our
main proofs. This preliminary result is known to hold for the case of
Euclidean norms ( @xmath ). We provide the proof for the more general
@xmath norm for completeness.

###### Lemma 17.

Let @xmath be arbitrary vectors in @xmath and let @xmath be a positive
definite matrix. Then the following identity holds: @xmath

###### Proof.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

LHS (left-hand side)=RHS (right-hand side) and this completes the proof.
∎

#### 2.9.2 Proof of Theorem 8

First, we decompose

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.28)
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

We will now analyze the three expressions [] , [] , [] separately. The
first expression can be written as

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (2.29)
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

We will now bound the second expression. First, we have

  -- -- -------- -------- --------
        @xmath            (2.30)
                 @xmath   
                 @xmath   
  -- -- -------- -------- --------

Using the identity from Lemma 17 for the vectors @xmath and @xmath we
obtain:

  -- -------- --
     @xmath   
  -- -------- --

Substituting this into ( 2.30 ) gives

  -- -- -------- -- --------
        @xmath      (2.31)
  -- -- -------- -- --------

The third expression can be bounded as

  -- -------- -- --------
     @xmath      (2.32)
  -- -------- -- --------

By substituting the bounds ( 2.29 ), ( 2.31 ), ( 2.32 ) into ( 2.28 ) we
obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Now by first taking expectation with respect to @xmath , we obtain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where in the second step we used the inequality @xmath and the fact that
@xmath , which follows from the assumptions. We now apply inequalities (
1.36 ) and ( 1.37 ), obtaining

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

By taking expectation again, and letting @xmath , we get the relation

  -- -------- -- --------
     @xmath      (2.33)
  -- -------- -- --------

It suffices to apply Lemma 16 to the relation ( 2.33 ). The conditions
of the lemma are satisfied. Indeed, @xmath , and if @xmath , then @xmath
and hence @xmath . The condition @xmath holds by assumption.

The convergence result in function values, @xmath , follows as a
corollary by applying inequality ( 1.36 ) to ( 2.5 ).

#### 2.9.3 Proof of Theorem 10

Let @xmath and @xmath . In view of ( 2.4 ), we can write

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.34)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

and therefore

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Taking expectation with respect to the random matrix @xmath we obtain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where the inequality follows from convexity of @xmath . After
rearranging the terms we get

  -- -------- --
     @xmath   
  -- -------- --

where @xmath . Taking expectations again and using the tower property,
we get

  -- -------- -- --------
     @xmath      (2.35)
  -- -------- -- --------

where @xmath . By summing up ( 2.35 ) for @xmath we get

  -- -------- -- --------
     @xmath      (2.36)
  -- -------- -- --------

Finally, using Jensen’s inequality, we get

  -- -------- --
     @xmath   
  -- -------- --

It remains to note that @xmath

#### 2.9.4 Proof of Theorem 11

In the proof of Theorem 11 the following two lemmas are used.

###### Lemma 18 ([168]).

Assume exactness. Let @xmath and @xmath . If @xmath , then @xmath .

###### Lemma 19 ([48, 53]).

Consider the second degree linear homogeneous recurrence relation:

  -- -------- -- --------
     @xmath      (2.37)
  -- -------- -- --------

with initial conditions @xmath . Assume that the constant coefficients
@xmath and @xmath satisfy the inequality @xmath (the roots of the
characteristic equation @xmath are imaginary). Then there are complex
constants @xmath and @xmath (depending on the initial conditions @xmath
and @xmath ) such that:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath is such that @xmath and @xmath .

We can now turn to the proof of Theorem 11 . Plugging in the expression
for the stochastic gradient, mSGD can be written in the form

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.38)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Subtracting @xmath from both sides of ( 2.38 ), we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Multiplying the last identity from the left by @xmath , we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Taking expectations, conditioned on @xmath (that is, the expectation is
with respect to @xmath ):

  -- -------- -- --------
     @xmath      (2.39)
  -- -------- -- --------

Taking expectations again, and using the tower property, we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Plugging the eigenvalue decomposition @xmath of the matrix @xmath into
the above, and multiplying both sides from the left by @xmath , we
obtain

  -- -------- -- --------
     @xmath      (2.40)
  -- -------- -- --------

Let us define @xmath . Then relation ( 2.40 ) takes the form of the
recursion

  -- -------- --
     @xmath   
  -- -------- --

which can be written in a coordinate-by-coordinate form as follows:

  -- -------- -- --------
     @xmath      (2.41)
  -- -------- -- --------

where @xmath indicates the @xmath th coordinate of @xmath .

We will now fix @xmath and analyze recursion ( 2.41 ) using Lemma 19 .
Note that ( 2.41 ) is a second degree linear homogeneous recurrence
relation of the form ( 2.37 ) with @xmath and @xmath . Recall that
@xmath for all @xmath . Since we assume that @xmath , we know that
@xmath for all @xmath . We now consider two cases:

1.  @xmath .

    In this case, ( 2.41 ) takes the form:

      -- -------- -- --------
         @xmath      (2.42)
      -- -------- -- --------

    Applying Proposition 9 , we know that @xmath . Using Lemma 18 twice,
    once for @xmath and then for @xmath , we observe that @xmath and
    @xmath . Finally, in view of ( 2.42 ) we conclude that

      -- -------- -- --------
         @xmath      (2.43)
      -- -------- -- --------

2.  @xmath .

    Since @xmath and @xmath , we have @xmath and hence

      -- -------- --
         @xmath   
      -- -------- --

    where the last inequality can be shown to hold ⁸ ⁸ 8 The lower bound
    on @xmath is tight. However, the upper bound is not. However, we do
    not care much about the regime of large @xmath as @xmath is the
    convergence rate, and hence is only interesting if smaller than 1.
    for @xmath . Applying Lemma 19 the following bound can be deduced

      -- -------- -------- -------- -- --------
         @xmath   @xmath   @xmath      (2.44)
      -- -------- -------- -------- -- --------

    where @xmath is a constant depending on the initial conditions (we
    can simply choose @xmath ).

Now putting the two cases together, for all @xmath we have

  -- -------- -------- -------- --
     @xmath   @xmath            
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where @xmath .

#### 2.9.5 Proof of Theorem 14

The proof follows a similar pattern to that of Theorem 8 . However,
stochasticity in the momentum term introduces an additional layer of
complexity, which we shall tackle by utilizing a more involved version
of the tower property.

For simplicity, let @xmath and @xmath . First, we decompose

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.45)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

We shall use the tower property in the form

  -- -------- -- --------
     @xmath      (2.46)
  -- -------- -- --------

where @xmath is some random variable. We shall perform the three
expectations in order, from the innermost to the outermost. Applying the
inner expectation to the identity ( 2.45 ), we get

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.47)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

We will now analyze the three expressions [] , [] , [] separately. The
first expression is constant under the expectation, and hence we can
write

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (2.48)
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

We will now bound the second expression. Using the identity

  -- -------- -- --------
     @xmath      (2.49)
  -- -------- -- --------

we can write

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (2.50)
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

Using the fact that for arbitrary vectors @xmath we have the identity
@xmath we obtain

  -- -------- --
     @xmath   
  -- -------- --

Substituting this into ( 2.50 ) gives

  -- -- -------- -- --------
        @xmath      (2.51)
  -- -- -------- -- --------

The third expression can be bound as

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (2.52)
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

By substituting the bounds ( 2.48 ), ( 2.51 ), ( 2.52 ) into ( 2.47 ) we
obtain

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.54)
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

We now take the middle expectation (see ( 2.46 )) and apply it to
inequality ( 2.54 ):

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

where in the second step we used the inequality @xmath and the fact that
@xmath , which follows from the assumptions. We now apply inequalities (
1.36 ) and ( 1.37 ), obtaining

  -- -------- -------- -------- --
     @xmath   @xmath            
                       @xmath   
  -- -------- -------- -------- --

By taking expectation again (outermost expectation in the tower rule (
2.46 )), and letting @xmath , we get the relation

  -- -------- -- --------
     @xmath      (2.55)
  -- -------- -- --------

It suffices to apply Lemma 16 to the relation ( 2.33 ). The conditions
of the lemma are satisfied. Indeed, @xmath , and if @xmath , then @xmath
and hence @xmath . The condition @xmath holds by assumption.

The convergence result in function values follows as a corollary by
applying inequality ( 1.36 ) to ( 2.14 ).

## Chapter 3 Inexact Randomized Iterative Methods

### 3.1 Introduction

In the era of big data where data sets become continuously larger,
randomized iterative methods become very popular and are increasingly
playing a major role in areas such as numerical linear algebra,
scientific computing and optimization. They are preferred mainly because
of their cheap per-iteration cost which leads to improvements in terms
of complexity upon classical results by orders of magnitude. In addition
they can easily scale to extreme dimensions. However, a common feature
of these methods is that in their update rule a particular subproblem
needs to be solved exactly . In a large scale setting, often this step
is computationally very expensive. The purpose of this work is to reduce
the cost of this step by allowing for inexact updates in the stochastic
methods under study.

#### 3.1.1 The setting

In this chapter we are interested to solve the three closely related
problems described in the previous chapters. As a reminder, these are:

1.  stochastic quadratic optimization ( 1.6 ),

2.  best approximation ( 1.22 ), and

3.  (bounded) concave quadratic maximization ( 1.26 ).

In particular we propose and analyze inexact variants of the exact
algorithms presented in the introduction of this thesis for solving the
above problems. Among the methods studied are: stochastic gradient
descent (SGD), stochastic Newton (SN), stochastic proximal point (SPP),
sketch and project method (SPM) and stochastic subspace ascent (SDSA).
In all of these methods, a certain potentially expensive
calculation/operation needs to be performed in each step; it is this
operation that we propose to be performed inexactly . For instance, in
the case of SGD, it is the computation of the stochastic gradient @xmath
, in the case of SPM is the computation of the projection @xmath , and
in the case of SDSA it is the computation of the dual update @xmath .

We perform an iteration complexity analysis under an abstract notion of
inexactness and also under a more structured form of inexactness
appearing in practical scenarios. An inexact solution of these
subproblems can be obtained much more quickly than the exact solution.
Since in practical applications the savings thus obtained are larger
than the increase in the number of iterations needed for convergence,
our inexact methods can be dramatically faster.

#### 3.1.2 Structure of the chapter and main contributions

Let us now outline the main contribution and the structure of this
chapter.

In Section 3.2 we describe the subproblems and introduce two notions of
inexactness (abstract and structured) that will be used in the rest of
this chapter. The Inexact Basic Method (iBasic) is also presented.
iBasic is a method that simultaneously captures inexact variants of the
algorithms ( 1.17 ), ( 1.18 ), ( 1.19 ) for solving the stochastic
optimization problem ( 1.6 ) and algorithm ( 1.25 ) for solving the best
approximation problem ( 1.22 ). It is an inexact variant of the Basic
Method , first presented in [ 168 ] , where the inexactness is
introduced by the addition of an inexactness error @xmath in the
original update rule. We illustrate the generality of iBasic by
presenting popular algorithms that can be cast as special cases.

In Section 3.3 we establish convergence results of iBasic under general
assumptions on the inexactness error @xmath of its update rule (see
Algorithm 4 ). In this part we do not focus on any specific mechanisms
which lead to inexactness; we treat the problem abstractly. However,
such errors appear often in practical scenarios and can be associated
with inaccurate numerical solvers, quantization, sparsification and
compression mechanisms. In particular, we introduce several abstract
assumptions on the inexactness level and describe our generic
convergence results. For all assumptions we establish linear rate of
decay of the quantity @xmath (i.e. L2 convergence) ¹ ¹ 1 As we explain
later, a convergence of the expected function values of problem 1.6 can
be easily obtained as a corollary of L2 convergence. .

Subsequently, in Section 3.4 we apply our general convergence results to
a more structured notion of inexactness error and propose a concrete
mechanisms leading to such errors. We provide theoretical guarantees for
this method in situations when a linearly convergent iterative method
(e.g., Conjugate Gradient) is used to solve the subproblem inexactly. We
also highlight the importance of the dual viewpoint through a
sketch-and-project interpretation.

In Section 3.5 we study an inexact variant of SDSA, which we called
iSDSA, for directly solving the dual problem ( 1.26 ). We provide a
correspondence between iBasic and iSDSA and we show that the random
iterates of iBasic arise as affine images of iSDSA. We consider both
abstract and structured inexactness errors and provide linearly
convergent rates in terms of the dual function suboptimality @xmath .

Finally, in Section 3.6 we evaluate the performance of the proposed
inexact methods through numerical experiments and show the benefits of
our approach on both synthetic and real datasets. Concluding remarks are
given in Section 3.7 .

A summary of the convergence results of iBasic under several assumptions
on the inexactness error with pointers to the relevant theorems is
available in Table 3.1 . We highlight that similar convergence results
can be also obtained for iSDSA in terms of the dual function
suboptimality @xmath (check Section 3.5 for more details on iSDSA).

#### 3.1.3 Notation

Following the rest of this thesis, with boldface upper-case letters we
denote matrices and @xmath is the identity matrix. By @xmath we denote
the solution set of the linear system @xmath . By @xmath , where @xmath
is a random matrix, we denote the solution set of the sketched linear
system @xmath . In general, we use @xmath to express the exact solution
of a sub-problem and @xmath to indicate its inexact variant. Unless
stated otherwise, throughout the chapter, @xmath is the projection of
@xmath onto @xmath in the @xmath -norm: @xmath .

### 3.2 Inexact Update Rules

In this section we start by explaining the key sub-problems that need to
be solved exactly in the update rules of the previously described
methods. We present iBasic, a method that solves problems ( 1.6 ) and (
1.22 ) and we show how by varying the main parameters of the method we
recover inexact variants of popular algorithms as special cases. Finally
closely related work on inexact algorithms for solving different
problems is also presented.

#### 3.2.1 Expensive sub-problems in update rules

Let us devote this subsection on explaining how the inexactness can be
introduced in the current exact update rules of SGD ² ² 2 Note that SGD
has identical updates to the Stochastic Newton and Stochastic proximal
point method. Thus the inexactness can be added to these updates in
similar way. ( 1.17 ), Sketch and Project ( 1.25 ) and SDSA ( 1.29 ) for
solving the stochastic optimization, best approximation and the dual
problem respectively. As we have shown these methods solve closely
related problems and the key subproblems in their update rule are
similar. However the introduction of inexactness in the update rule of
each one of them can have different interpretation.

For example for the case of SGD for solving the stochastic optimization
problem ( 1.6 ) (see also Section 3.4.1 and 3.4.2 for more details), if
we define @xmath then the stochastic gradient of function @xmath becomes
@xmath and the update rule of SGD takes the form: @xmath . Clearly in
this update the expensive part is the computation of the quantity @xmath
that can be equivalently computed to be the least norm solution of the
smaller (in comparison to @xmath ) linear system @xmath . In our work we
are suggesting to use an approximation @xmath of the exact solution and
with this way avoid executing the possibly expensive step of the update
rule. Thus the inexact update is taking the following form:

  -- -------- --
     @xmath   
  -- -------- --

Here @xmath denotes a more abstract notion of inexactness and it is not
necessary to be always equivalent to the quantity @xmath . It can be
interpreted as an expression that acts as an perturbation of the exact
update. In the case that @xmath has the above form we say that the
notion of inexactness is structured. In our work we are interested in
both the abstract and more structured notions of inexactness. We first
present general convergence results where we require the error @xmath to
satisfy general assumptions (without caring how this error is generated)
and later we analyze the concept of structured inexactness by presenting
algorithms where @xmath .

In similar way, the expensive operation of SPM ( 1.25 ) is the exact
computation of the projection @xmath . Thus we are suggesting to replace
this step with an inexact variant and compute an approximation of this
projection. The inexactness here can be also interpreted using both, the
abstract @xmath error and its more structured version @xmath . At this
point, observe that, by using the expression ( 1.14 ) the structure of
the @xmath in SPM and SGD has the same form.

In the SDSA the expensive subproblem in the update rule is the
computation of the @xmath that satisfy @xmath . Using the definition of
the dual function ( 1.26 ) this value can be also computed by evaluating
the least norm solution of the linear system @xmath . Later in Section
3.5 we analyze both notions of inexactness (abstract and more
structured) for inexact variants of SDSA.

Table 3.2 presents the key sub-problem that needs to be solved in each
algorithm as well as the part where the inexact error is appeared in the
update rule.

#### 3.2.2 The inexact basic method

In each iteration of the all aforementioned exact methods a sketch
matrix @xmath is drawn from a given distribution and then a certain
subproblem is solved exactly to obtain the next iterate. The sketch
matrix @xmath requires to have @xmath rows but no assumption on the
number of columns is made which means that the number of columns @xmath
allows to vary through the iterations and it can be very large. The
setting that we are interested in is precisely that of having such large
random matrices @xmath . In these cases we expect that having
approximate solutions of the subproblems will be beneficial.

Recently randomized iterative algorithms that requires to solve large
subproblems in each iteration have been extensively studied and it was
shown that are really beneficial when they compared to their single
coordinates variants ( @xmath ) [ 134 , 135 , 166 , 113 ] . However, in
theses cases the evaluation of an exact solution for the suproblem in
the update rule can be computationally very expensive. In this work we
propose and analyze inexact variants by allowing to solve the subproblem
that appear in the update rules of the stochastic methods, inexactly. In
particular, following the convention established in [ 168 ] of naming
the main algorithm of the paper Basic method we propose the inexact
Basic method (iBasic) (Algorithm 4 ).

1: Distribution @xmath from which we draw random matrices @xmath ,
positive definite matrix @xmath , stepsize @xmath .

2: @xmath

3: for @xmath do

4: Generate a fresh sample @xmath

5: Set @xmath

6: end for

Algorithm 4 Inexact Basic Method (iBasic)

The @xmath in the update rule of the method represents the abstract
inexactness error described in Subsection 3.2.1 . Note that, iBasic can
have several equivalent interpretations. This allow as to study the
methods ( 1.17 ),( 1.18 ),( 1.19 ) for solving the stochastic
optimization problem and the sketch and project method ( 1.25 ) for the
best approximation problem in a single algorithm only. In particular
iBasic can be seen as inexact stochastic gradient descent (iSGD) with
fixed stepsize applied to ( 1.6 ). From ( 1.13 ), @xmath and as a result
the update rule of iBasic can be equivalently written as: @xmath In the
case of the best approximation problem ( 1.22 ), iBasic can be
interpreted as inexact Sketch and Project method (iSPM) as follows:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.1)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

For the dual problem ( 1.26 ) we devote Section 3.5 for presenting an
inexact variant of the SDSA (iSDSA) and analyze its convergence using
the rates obtained for the iBasic in Sections 3.3 and 3.4 .

#### 3.2.3 General framework and further special cases

The proposed inexact methods, iBasic (Algorithm 4 ) and iSDSA (Section
3.5 ), belong in the general sketch and project framework, first
proposed from Gower and Richtarik in [ 73 ] for solving consistent
linear systems and where a unified analysis of several randomized
methods was studied. This interpretation of the algorithms allow us to
recover a comprehensive array of well-known methods as special cases by
choosing carefully the combination of the main parameters of the
algorithms.

In particular, the iBasic has two main parameters (besides the stepsize
@xmath of the update rule). These are the distribution @xmath from which
we draw random matrices @xmath and the positive definite matrix @xmath .
By choosing carefully combinations of the parameters @xmath and @xmath
we can recover several existing popular algorithms as special cases of
the general method. For example, special cases of the exact Basic method
are the Randomized Kaczmarz, Randomized Gaussian Kaczmarz ³ ³ 3 Special
case of the iBasic, when the random matrix @xmath is chosen to be a
Gaussian vector with mean @xmath and a positive definite covariance
matrix @xmath . That is @xmath [ 73 ] . , Randomized Coordinate Descent
and their block variants. For more details about the generality of the
sketch and project framework and further algorithms that can be cast as
special cases of the analysis we refer the interested reader to Section
3 of [ 73 ] . Here we present only the inexact update rules of two
special cases that we will later use in the numerical evaluation.

Special Cases: Let us define with @xmath the column concatenation of the
@xmath identity matrix indexed by a random subset @xmath of @xmath .

-   Inexact Randomized Block Kaczmarz (iRBK) : Let @xmath and let pick
    in each iteration the random matrix @xmath . In this setup the
    update rule of the iBasic simplifies to

      -- -------- -- -------
         @xmath      (3.2)
      -- -------- -- -------

-   Inexact Randomized Block Coordinate Descent (iRBCD) ⁴ ⁴ 4 In the
    setting of solving linear systems Randomized Coordinate Descent is
    known also as Gauss-Seidel method. Its block variant can be also
    interpret as randomized coordinate Newton method (see [ 162 ] ). :
    If the matrix @xmath of the linear system is positive definite then
    we can choose @xmath . Let also pick in each iteration the random
    matrix @xmath . In this setup the update rule of the iBasic
    simplifies to

      -- -------- -- -------
         @xmath      (3.3)
      -- -------- -- -------

For more papers related to Kaczmarz method (randomized, greedy, cyclic
update rules) we refer the interested reader to [ 91 , 114 , 158 , 17 ,
144 , 159 , 27 , 132 , 134 , 49 , 120 , 216 , 135 , 175 ] . For the
coordinate descent method (a.k.a Gauss-Seidel for linear systems) and
its block variant, Randomized Block Coordinate Descent we suggest [ 104
, 139 , 166 , 167 , 160 , 161 , 163 , 22 , 102 , 51 , 2 , 192 ] .

#### 3.2.4 Other related work on inexact methods

One of the current trends in the large scale optimization problems is
the introduction of inexactness in the update rules of popular
deterministic and stochastic methods. The rational behind this is that
an approximate/inexact step can often computed very efficiently and can
have significant computational gains compare to its exact variants.

In the area of deterministic algorithms, the inexact variant of the full
gradient descent method, @xmath , has received a lot of attention [ 174
, 39 , 180 , 59 , 128 ] . It has been analyzed for the cases of convex
and strongly convex functions under several meaningful assumptions on
the inexactness error @xmath and its practical benefit compared to the
exact gradient descent is apparent. For further deterministic inexact
methods check [ 36 ] for Inexact Newton methods, [ 181 , 171 ] for
Inexact Proximal Point methods and [ 12 ] for Inexact Fixed point
methods.

In the recent years, with the explosion that happens in areas like
machine learning and data science inexactness enters also the updating
rules of several stochastic optimization algorithms and many new methods
have been proposed and analyzed.

In the large scale setting, stochastic optimization methods are
preferred mainly because of their cheap per iteration cost (compared to
their deterministic variants), their property to scale to extreme
dimensions and their improved theoretical complexity bounds. In areas
like machine learning and data science, where the datasets become larger
rapidly, the development of faster and efficient stochastic algorithms
is crucial. For this reason, inexactness has recently introduced to the
update rules of several stochastic optimization algorithms and new
methods have been proposed and analyzed. One of the most interesting
work on inexact stochastic algorithms appears in the area of second
order methods. In particular on inexact variants of the Sketch-Newton
method and subsampled Newton Method for minimize convex and non-convex
functions [ 172 , 9 , 14 , 204 , 205 , 207 ] . Note that our results are
related also with this literature since our algorithm can be seen as
inexact stochastic Newton method (see equation ( 1.18 )). To the best or
our knowledge our work is the first that provide convergence analysis of
inexact stochastic proximal point methods (equation ( 1.19 )) in any
setting. From numerical linear algebra viewpoint inexact sketch and
project methods for solving the best approximation problem and its dual
problem where also never analyzed before.

As we already mentioned our framework is quite general and many
algorithms, like iRBK ( 3.2 ) and iRBCD ( 3.3 ) can be cast as special
cases. As a result, our general convergence analysis includes the
analysis of inexact variants of all of these more specific algorithms as
special cases. In [ 134 ] an analysis of the exact randomized block
Kacmzarz method has been proposed and in the experiments an inexact
variant was used to speedup the method. However, no iteration complexity
results were presented for the inexact variant and both the analysis and
numerical evaluation have been made for linear systems with full rank
matrices that come with natural partition of the rows (this is a much
more restricted case than the one analyzed in our setting). For inexact
variants of the randomized block coordinate descent algorithm in
different settings than ours we suggest [ 187 , 54 , 20 , 46 ] .

Finally an analysis of approximate stochastic gradient descent for
solving the empirical risk minimization problem using quadratic
constraints and sequential semi-definite programs has been presented in
[ 85 ] .

### 3.3 Convergence Results Under General Assumptions

In this section we consider scenarios in which the inexactness error
@xmath can be controlled, by specifying a per iteration bound @xmath on
the norm of the error. In particular, by making different assumptions on
the bound @xmath we derive general convergence rate results. Our focus
is on the abstract notion of inexactness described in Section 3.2.1 and
we make no assumptions on how this error is generated.

An important assumption that needs to be hold in all of our results is
exactness . A formal presentation of exactness was presented in the
introduction of this thesis. We highlight that is a requirement for all
of the convergence results of this chapter (It is also required in the
analysis of the exact algorithms; see Theorems 3 and 6 in the
introduction).

#### 3.3.1 Assumptions on inexactness error

In the convergence analysis of iBasic the following assumptions on the
inexactness error are used. We note that Assumptions 3.3.1 , 3.3.1 and
3.3.1 are special cases of Assumption 3.3.1 . Moreover Assumption 3.3.1
is algorithmic dependent and can hold in addition of any of the other
four assumptions. In our analysis, depending on the result we aim at, we
will require either one of the first four Assumptions to hold by itself,
or to hold together with Assumption 3.3.1 . We will always assume
exactness.

In all assumptions the expectation on the norm of error ( @xmath ) is
conditioned on the value of the current iterate @xmath and the random
matrix @xmath . Moreover it is worth to mention that for the convergence
analysis we never assume that the inexactness error has zero mean, that
is @xmath .

###### Assumption 1.

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

where the upper bound @xmath is a sequence of random variables (that can
possibly depends on both the value of the current iterate @xmath and the
choice of the random @xmath at the @xmath iteration).

The following three assumptions on the sequence of upper bounds are more
restricted however as we will later see allow us to obtain stronger and
more controlled results.

###### Assumption 1@xmath.

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

where the upper bound @xmath is a sequence of real numbers.

###### Assumption 1@xmath.

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

where the upper bound is a special sequence that depends on a
non-negative inexactness parameter @xmath and the distance to the
optimal value @xmath .

###### Assumption 1@xmath.

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

where the upper bound is a special sequence that depends on a
non-negative inexactness parameter @xmath and the value of the
stochastic function @xmath computed at the iterate @xmath . Recall, that
in our setting @xmath ( 1.38 ). Hence, the upper bound can be
equivalently expressed as @xmath .

Finally the next assumption is more algorithmic oriented. It holds in
cases where the inexactness error @xmath in the update rule is chosen to
be orthogonal with respect to the @xmath -inner product to the vector
@xmath . This statement may seem odd at this point but its usefulness
will become more apparent in the next section where inexact algorithms
with structured inexactness error will be analyzed. As it turns out, in
the case of structured inexactness error (Algorithm 5 ) this assumption
is satisfied.

###### Assumption 2.

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

#### 3.3.2 Convergence results

In this section we present the analysis of the convergence rates of
iBasic by assuming several combination of the previous presented
assumptions.

All convergence results are described only in terms of convergence of
the iterates @xmath , that is @xmath , and not the objective function
values @xmath . This is sufficient, because by @xmath (see Lemma 1 ) we
can directly deduce a convergence rate for the function values.

The exact Basic method (Algorithm 4 with @xmath ), has been analyzed in
[ 168 ] and it was shown to converge with @xmath where @xmath . Our
analysis of iBasic is more general and includes the convergence of the
exact Basic method as special case when we assume that the upper bound
is @xmath . For brevity, in he convergence analysis results of this
chapter we also use

  -- -------- --
     @xmath   
  -- -------- --

Let us start by presenting the convergence of iBasic when only
Assumption 3.3.1 holds for the inexactness error.

###### Theorem 20.

Let assume exactness and let @xmath be the iterates produced by iBasic
with @xmath . Set @xmath and consider the error @xmath be such that it
satisfies Assumption 3.3.1 . Then,

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

###### Proof.

See Section 3.8.1 . ∎

###### Corollary 21.

In the special case that the upper bound @xmath in Assumption 3.3.1 is
fixed, that is @xmath for all @xmath then inequality ( 3.9 ) of Theorem
20 takes the following form:

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

This means that we obtain a linear convergence rate up to a solution
level that is proportional to the upper bound @xmath ⁵ ⁵ 5 Several
similar more specific assumptions can be made for the upper bound @xmath
. For example if the upper bound satisfies @xmath with @xmath for all
@xmath then it can be shown that @xmath exist such that inequality ( 3.9
) of Theorem 20 takes the form: @xmath (see [ 180 , 59 ] for similar
results). .

###### Proof.

See Section 3.8.2 . ∎

Inspired from [ 59 ] , let us now analyze iBasic using the sequence of
upper bounds that described in Assumption 3.3.1 . This construction of
the upper bounds allows us to obtain stronger and more controlled
results. In particular using the upper bound of Assumption 3.3.1 the
sequence of expected errors converge linearly to the exact @xmath (not
in a potential neighborhood like the previous result). In addition
Assumption 3.3.1 guarantees that the distance to the optimal solution
reduces with the increasing of the number of iterations. However for
this stronger convergence a bound for @xmath is required, a quantity
that in many problems is unknown to the user or intractable to compute.
Nevertheless, there are cases that this value has a closed form
expression and can be computed before hand without any further cost. See
for example [ 113 , 116 , 112 , 80 ] where methods for solving the
average consensus were presented and the value of @xmath corresponds to
the algebraic connectivity of the network under study.

###### Theorem 22.

Assume exactness. Let @xmath be the iterates produced by iBasic with
@xmath . Set @xmath and consider the inexactness error @xmath be such
that it satisfies Assumption 3.3.1 , with @xmath . Then

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

###### Proof.

See Section 3.8.3 . ∎

At Theorem 22 , to guarantee linear convergence the inexact parameter
@xmath should live in the interval @xmath . In particular, @xmath is the
parameter that controls the level of inexactness of Algorithm 4 . Not
surprisingly the fastest convergence rate is obtained when @xmath ; in
such case the method becomes equivalent with its exact variant and the
convergence rate simplifies to @xmath . Note also that similar to the
exact case the optimal convergence rate is obtained for @xmath [ 168 ] .

Moreover, the upper bound @xmath of Assumption 3.3.1 depends on two
important quantities, the @xmath (through the upper bound of the
inexactness parameter @xmath ) and the distance to the optimal solution
@xmath . Thus, it can have natural interpretation. In particular the
inexactness error is allowed to be large either when the current iterate
is far from the optimal solution ( @xmath large) or when the problem is
well conditioned and @xmath is large. In the opposite scenario, when we
have ill conditioned problem or we are already close enough to the
optimum @xmath we should be more careful and allow less errors to the
updates of the method.

In the next theorem we provide the complexity results of iBasic in the
case that the Assumption 3.3.1 is satisfied combined with one of the
previous assumptions.

###### Theorem 23.

Let assume exactness and let @xmath be the iterates produced by iBasic
with @xmath . Set @xmath . Let also assume that the inexactness error
@xmath be such that it satisfies Assumption 3.3.1 . Then:

1.   If Assumption 3.3.1 holds:

      -- -------- -- --------
         @xmath      (3.12)
      -- -------- -- --------

    where @xmath

2.   If Assumption 3.3.1 holds with @xmath :

      -- -------- -------- -------- -- --------
         @xmath   @xmath   @xmath      (3.13)
      -- -------- -------- -------- -- --------

3.   If Assumption 3.3.1 holds with @xmath :

      -- -------- -- --------
         @xmath      (3.14)
      -- -------- -- --------

###### Proof.

See Section 3.8.4 . ∎

###### Remark 4.

In the case that Assumptions 3.3.1 and 3.3.1 hold simultaneously, the
convergence of iBasic is similar to ( 3.12 ) but in this case @xmath
(due to Assumption 3.3.1 , @xmath is a sequence of real numbers). In
addition, note that for @xmath having Assumption 3.3.1 on top of
Assumption 3.3.1 leads to improvement of the convergence rate. In
particular, from Theorem 22 , iBasic converges with rate @xmath while
having both assumptions this is simplified to the faster @xmath ( 3.13
).

### 3.4 iBasic with Structured Inexactness Error

Up to this point, the analysis of iBasic was focused in more general
abstract cases where the inexactness error @xmath of the update rule
satisfies several general assumptions. In this section we are focusing
on a more structured form of inexactness error and we provide
convergence analysis in the case that a linearly convergent algorithm is
used for the computation of the expensive key subproblem of the method.

#### 3.4.1 Linear system in the update rule

As we already mentioned in Section 3.2.1 the update rule of the exact
Basic method (Algorithm 4 with @xmath ) can be expressed as @xmath ,
where @xmath .

Using this expression the exact Basic method can be equivalently
interpreted as the following two step procedure:

1.  Find the least norm solution ⁶ ⁶ 6 We are precisely looking for the
    least norm solution of the linear system @xmath because this
    solution can be written down in a compact way using the
    Moore-Penrose pseudoinverse. This is equivalent with the expression
    that appears in our update: @xmath . However it can be easily shown
    that the method will still converge with the same rate of
    convergence even if we choose any other solution of the linear
    system @xmath . of @xmath . That is find @xmath where @xmath .

2.  Compute the next iterate: @xmath

In the case that the random matrix @xmath is large (this is the case
that we are interested in), solving exactly the linear system @xmath in
each step can be prohibitively expensive. To reduce this cost we allow
the inner linear system @xmath to be solved inexactly using an iterative
method. In particular we propose and analyze the following inexact
algorithm:

1: Distribution @xmath from which we draw random matrices @xmath ,
positive definite matrix @xmath , stepsize @xmath .

2: @xmath

3: for @xmath do

4: Generate a fresh sample @xmath

5: Using an iterative method compute an approximation @xmath of the
least norm solution of the linear system:

  -- -------- -- --------
     @xmath      (3.15)
  -- -------- -- --------

6: Set @xmath .

7: end for

Algorithm 5 iBasic with structured inexactness error

For the computation of the inexact solution of the linear system ( 3.15
) any known iterative method for solving general linear systems can be
used. In our analysis we focus on linearly convergent methods. For
example based on the properties of the linear system ( 3.15 ), conjugate
gradient (CG) or sketch and project method (SPM) can be used for the
execution of step 3. In these cases, we name Algorithm 5 , InexactCG and
InexactSP respectively.

It is known that the classical CG can solve linear systems with positive
definite matrices. In our approach matrix @xmath is positive definite
only when the original linear system @xmath has full rank matrix @xmath
. On the other side SPM can solve any consistent linear system and as a
result can solve the inner linear system @xmath without any further
assumption on the original linear system. In this case, one should be
careful because the system has no unique solution. We are interested to
find the least norm solution of @xmath which means that the starting
point of the sketch and project at the @xmath iteration should be always
@xmath . Recall that any special case of the sketch and project method
(Section 3.2.3 ) solves the best approximation problem.

Let us now define @xmath to be the approximate solution @xmath of the
@xmath linear system ( 3.15 ) obtained after @xmath steps of the
linearly convergent iterative method. Using this, the update rule of
Algorithm 5 , takes the form:

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

###### Remark 5.

The update rule ( 3.16 ) of Algorithm 5 is equivalent to the update rule
of iBasic (Algorithm 4 ) when the error @xmath is chosen to be,

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

This is precisely the connection between the abstract and more
concrete/structured notion of inexactness that first presented in Table
3.2 .

Let us now define a Lemma that is useful for the analysis of this
section and it verifies that Algorithm 5 with unit stepsize satisfies
the general Assumption 3.3.1 presented in Section 3.3.1 .

###### Lemma 24.

Let us denote @xmath the projection of @xmath onto @xmath in the @xmath
-norm and @xmath . Let also assume that @xmath (unit stepsize). Then for
the updates of Algorithm 5 it holds that:

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

###### Proof.

Note that @xmath . Moreover @xmath . From the knowledge that the null
space of an arbitrary matrix is the orthogonal complement of the range
space of its transpose we have that @xmath is orthogonal with respect to
the @xmath -inner product to @xmath . This completes the proof (see
Figure 3.1 for the graphical interpretation). ∎

#### 3.4.2 Sketch and project interpretation

Let us now give a different interpretation of the inexact update rule of
Algorithm 5 using the sketch and project approach. That will make us
appreciate more the importance of the dual viewpoint and make clear the
connection between the primal and dual methods.

In general, execute a projection step is one of the most common task in
numerical linear algebra/optimization literature. However in the large
scale setting even this task can be prohibitively expensive and it can
be difficult to execute inexactly. For this reason we suggest to move to
the dual space where the inexactness can be easily controlled.

Observe that the update rule of the exact sketch and project method (
1.23 ) has the same structure as the best approximation problem ( 1.22 )
where the linear system under study is the sketched system @xmath and
the starting point is the current iterate @xmath . Hence we can easily
compute its dual:

  -- -- -- --------
           (3.19)
  -- -- -- --------

where @xmath is the dual variable. The @xmath (possibly more than one)
that solves the dual problem in each iteration @xmath , is the one that
satisfies @xmath . By computing the derivative this is equivalent with
finding the @xmath that satisfies the linear system @xmath . This is the
same linear system we desire to solve inexactly in Algorithm 5 . Thus,
computing an inexact solution @xmath of the linear system is equivalent
with computing an inexact solution of the dual problem ( 3.19 ). Then by
using the affine mapping ( 1.27 ) that connects the primal and the dual
spaces we can also evaluate an inexact solution of the original primal
problem ( 1.23 ).

The following result relates the inexact levels of these quantities. In
particular it shows that dual suboptimality of @xmath in terms of dual
function values is equal to the distance of the dual values @xmath in
the @xmath -norm.

###### Lemma 25.

Let us define @xmath be the exact solution of the linear system @xmath
or equivalently of dual problem ( 3.19 ). Let us also denote with @xmath
the inexact solution. Then:

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where in the second equality we use equation ( 1.28 ) to connect the
optimal solutions of ( 1.23 ) and ( 3.19 ) and obtain @xmath ∎

#### 3.4.3 Complexity results

In this part we analyze the performance of Algorithm 5 when a linearly
convergent iterative method is used for solving inexactly the linear
system ( 3.15 ) in step 3 of Algorithm 5 . We denote with @xmath the
approximate solution of the linear system after we run the iterative
method for @xmath steps.

Before state the main convergence result let us present a lemma that
summarize some observations that are true in our setting.

###### Lemma 26.

Let @xmath be the exact solution and @xmath be approximate solution of
the linear system ( 3.15 ). Then, @xmath and @xmath .

###### Proof.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.20)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Moreover,

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.21)
  -- -------- -------- -------- -- --------

∎

###### Theorem 27.

Let us assume that for the computation of the inexact solution of the
linear system ( 3.15 ) in step 3 of Algorithm 5 , a linearly convergent
iterative method is chosen such that ⁷ ⁷ 7 In the case that
deterministic iterative method is used, like CG, we have that @xmath
which is also true in expectation. :

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

where @xmath for any @xmath and @xmath for every choice of @xmath . Let
exactness hold and let @xmath be the iterates produced by Algorithm 5
with unit stepsize ( @xmath ). Set @xmath . Suppose further that there
exists a scalar @xmath such that with probability 1, @xmath . Then,
Algorithm 5 converges linearly with:

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Theorem 27 can be interpreted as corollary of the general Theorem 23
(iii). Thus, it is sufficient to show that Algorithm 5 satisfies the two
Assumptions 3.3.1 and 3.3.1 . Firstly, note that from Lemma 24 ,
Assumption 3.3.1 is true. Moreover,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

which means that Assumption 3.3.1 also holds with @xmath . This
completes the proof. ∎

Having present the main result of this section let us now state some
remarks that will help understand the convergence rate of the last
Theorem.

###### Remark 6.

From its definition @xmath and as a result @xmath . This means that the
method converges linearly but always with worst rate than its exact
variant.

###### Remark 7.

Let as assume that @xmath is fixed. Then as the number of iterations in
step 3 of the algorithm ( @xmath ) increasing @xmath and as a result the
method behaves similar to the exact case.

###### Remark 8.

The @xmath depends only on the random matrices @xmath and to the
positive definite matrix @xmath and is independent to the iterative
process used in step 3. The iterative process of step 3 controls only
the parameter @xmath of the convergence rate.

###### Remark 9.

Let us assume that we run Algorithm 5 two separate times for two
different choices of the linearly convergence iterative method of step
3. Let also assume that the distribution @xmath of the random matrices
and the positive definite matrix @xmath are the same for both instances
and that for step 3 the iterative method run for @xmath steps for both
algorithms. Let assume that @xmath then we have that @xmath . This means
in the case that @xmath is easily computable, we should always prefer
the inexact method with smaller @xmath .

The convergence of Theorem 27 is quite general and it holds for any
linearly convergent methods that can inexactly solve ( 3.15 ). However,
in case that the iterative method is known we can have more concrete
results. See below the more specified results for the cases of Conjugate
gradient (CG) and Sketch and project method (SPM).

###### Convergence of InexactCG:

CG is deterministic iterative method for solving linear systems @xmath
with symmetric and positive definite matrix @xmath in finite number of
iterations. In particular, it can be shown that converges to the unique
solution in at most @xmath steps. The worst case behavior of CG is given
by [ 198 , 67 ] ⁸ ⁸ 8 A sharper convergence rate of CG [ 198 ] for
solving @xmath can be also used

@xmath

where matrix @xmath has @xmath eigenvalues. :

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

where @xmath is the @xmath iteration of the method and @xmath the
condition number of matrix @xmath .

Having present the convergence of CG for general linear systems, let us
now return back to our setting. We denote @xmath to be the approximate
solution of the inner linear system ( 3.15 ) after @xmath conjugate
gradient steps. Thus using ( 3.23 ) we know that @xmath where @xmath .
Now by making the same assumption as the general Theorem 27 the
InexactCG converges with @xmath where @xmath such that @xmath with
probability 1.

###### Convergence of InexactSP:

In this setting we suggest to run the sketch and project method (SPM)
for solving inexactly the linear system ( 3.15 ). This allow us to have
no assumptions on the structure of the original system @xmath and as a
result we are able to solve more general problems compared to what
problems InexactCG can solve ⁹ ⁹ 9 Recall that InexactCG requires the
matrix @xmath to be positive definite (this is true when matrix @xmath
is a full rank matrix) . Like before, by making the same assumptions as
in Theorem 27 the more specific convergence @xmath for the InexactSP can
be obtained. Now the quantity @xmath denotes the convergence rate of the
exact Basic method ¹⁰ ¹⁰ 10 Recall that iBasic and its exact variant (
@xmath ) can be expressed as sketch and project methods ( 3.1 ). when
this applied to solve linear system ( 3.15 ) and @xmath is a scalar such
that @xmath with probability 1.

### 3.5 Inexact Dual Method

In the previous sections we focused on the analysis of inexact
stochastic methods for solving the stochastic optimization problem ( 1.6
) and the best approximation ( 1.22 ). In this section we turn into the
dual of the best approximation ( 1.26 ) and we propose and analyze an
inexact variant of the SDSA ( 1.29 ). We call the new method iSDSA and
is formalized as Algorithm 6 . In the update rule @xmath indicates the
dual inexactness error that appears in the @xmath iteration of iSDSA.

1: Distribution @xmath from which we draw random matrices @xmath ,
positive definite matrix @xmath , stepsize @xmath .

2: @xmath , @xmath

3: for @xmath do

4: Draw a fresh sample @xmath

5: Set @xmath

6: end for

Algorithm 6 Inexact Stochastic Dual Subspace Ascent (iSDSA)

#### 3.5.1 Correspondence between the primal and dual methods

With the sequence of the dual iterates @xmath produced by the iSDSA we
can associate a sequence of primal iterates @xmath using the affine
mapping ( 1.31 ). In our first result we show that the random iterates
produced by iBasic arise as an affine image of iSDSA under this affine
mapping.

###### Theorem 28.

(Correspondence between the primal and dual methods) Let @xmath be the
iterates produced by iBasic (Algorithm 4 ). Let @xmath , and @xmath the
iterates of the iSDSA. Assume that the two methods use the same stepsize
@xmath and the same sequence of random matrices @xmath . Assume also
that @xmath where @xmath and @xmath are the inexactness errors appear in
the update rules of iBasic and iSDSA respectively. Then

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath . That is, the primal iterates arise as affine images of
the dual iterates.

###### Proof.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus by choosing the inexactness error of the primal method to be @xmath
the sequence of vectors @xmath satisfies the same recursion as the
sequence @xmath defined by iBasic. It remains to check that the first
element of both recursions coincide. Indeed, since @xmath , we have
@xmath . ∎

#### 3.5.2 iSDSA with structured inexactness error

In this subsection we present Algorithm 7 . It can be seen as a special
case of iSDSA but with a more structured inexactness error.

1: Distribution @xmath from which we draw random matrices @xmath ,
positive definite matrix @xmath , stepsize @xmath .

2: @xmath , @xmath

3: for @xmath do

4: Generate a fresh sample @xmath

5: Using an Iterative method compute an approximation @xmath of the
least norm solution of the linear system:

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

6: Set @xmath

7: end for

Algorithm 7 iSDSA with structured inexactness error

Similar to their primal variants, it can be easily checked that
Algorithm 7 is a special case of the iSDSA ( Algorithm 6 ) when the dual
inexactness error is chosen to be @xmath . Note that, using the
observation of Remark 5 that @xmath and the above expression of @xmath
we can easily verify that the expression @xmath holds. This is precisely
the connection between the primal and dual inexactness errors that have
already been used in the proof of Theorem 28 .

#### 3.5.3 Convergence of dual function values

We are now ready to state a linear convergence result describing the
behavior of the inexact dual method in terms of the function values
@xmath . The following result is focused on the convergence of iSDSA by
making similar assumption to Assumption 3.3.1 . Similar convergence
results can be obtained using any other assumption of Section 3.3.1 .
The convergence of Algorithm 7 , can be also easily derived using
similar arguments with the one presented in Section 3.4 and the
convergence guarantees of Theorem 27 .

###### Theorem 29.

(Convergence of dual objective). Assume exactness. Let @xmath and let
@xmath to be the dual iterates of iSDSA (Algorithm 6 ) with @xmath . Set
@xmath and let @xmath be any dual optimal solution. Consider the
inexactness error @xmath be such that it satisfies @xmath where @xmath .
Then

  -- -------- -- --------
     @xmath      (3.25)
  -- -------- -- --------

###### Proof.

The proof follows by applying Theorem 22 together with Theorem 28 and
the identity @xmath ( 1.32 ). ∎

Note that in the case that @xmath , iSDSA simplifies to its exact
variant SDSA and the convergence rate coincide with the one presented in
Theorem 6 . Following similar arguments to those in [ 74 ] , the same
rate can be proved for the duality gap @xmath .

### 3.6 Numerical Evaluation

In this section we perform preliminary numerical tests for studying the
computational behavior of iBasic with structured inexactness error when
is used to solve the best approximation problem ( 1.22 ) or equivalently
the stochastic optimization problem ( 1.6 ) ¹¹ ¹¹ 11 Note that from
Section 3.5 and the correspondence between the primal and dual methods,
iSDSA will have similar behavior when is applied to the dual problem (
1.26 ). . As we have already mentioned, iBasic can be interpreted as
sketch-and-project method, and as a result a comprehensive array of
well-known algorithms can be recovered as special cases by varying the
main parameters of the methods (Section 3.2.3 ). In particular, in our
experiments we focus on the evaluation of two popular special cases, the
inexact Randomized Block Kaczmarz (iRBK) (equation ( 3.2 )) and inexact
randomized block coordinate descent method (iRBCD) (equation ( 3.3 ))We
implement Algorithm 5 presented in Section 3.4 using CG ¹² ¹² 12 Recall
that in order to use CG, the matrix @xmath that appears in linear system
( 3.15 ) should be positive definite. This is true in the case that the
matrix @xmath of the original system has full column rank matrix. Note
however that the analysis of Section 3.4 holds for any consistent linear
system @xmath and without making any further assumption on its structure
or the linearly convergence methods. to inexactly solve the linear
system of the update rule (equation ( 3.15 )). Recall that in this case
we named the method InexactCG.

The convergence analysis of previous sections is quite general and holds
for several combinations of the two main parameters of the method, the
positive definite matrix @xmath and the distribution @xmath of the
random matrices @xmath . For obtaining iRBK as special case we have to
choose @xmath (Identity matrix) and for the iRBCD the given matrix
@xmath should be positive definite and choose @xmath . For both methods
the distribution @xmath should be over random matrices @xmath where
@xmath is the column concatenation of the @xmath identity matrix indexed
by a random subset @xmath of @xmath . In our experiments we choose to
have one specific distribution over these matrices. In particular, we
assume that the random matrix in each iteration is chosen uniformly at
random to be @xmath with the subset @xmath of @xmath to have fixed
pre-specified cardinality.

The code for all experiments is written in the Julia 0.6.3 programming
language and run on a Mac laptop computer (OS X El Capitan), 2.7 GHz
Intel Core i5 with 8 GB of RAM.

To coincide with the theoretical convergence results of Algorithm 5 the
relaxation parameter (stepsize) of the methods study in our experiments
is chosen to be @xmath (no relaxation). In all implementations, we use
@xmath as an initial point and in comparing the methods with their
inexact variants we use the relative error measure @xmath . We run each
method (exact and inexact) until the relative error is below @xmath .
For the horizontal axis we use either the number of iterations or the
wall-clock time measured using the tic-toc Julia function. In the exact
variants, the linear system ( 3.15 ) in Algorithm 5 needs to be solved
exactly. In our experiments we follow the implementation of [ 73 ] for
both exact RBCD and exact RBK where the built-in direct solver
(sometimes referred to as "backslash") is used.

###### Experimental setup:

For the construction of consistent linear systems @xmath we use the
setup described in Section 2.7.1 . In particular, the linear systems
used for the numerical evaluation of iRBK and iRBCD have been generated
as described in Section 2.7.1 for algorithms mRK and mRCD, respectively.

#### 3.6.1 Importance of large block size

Many recent works have shown that using larger block sizes can be very
beneficial for the performance of randomized iterative algorithms [ 73 ,
166 , 134 , 113 ] . In Figure 3.2 we numerically verify this statement.
We show that both RBK and RBCD (no inexact updates) outperform in number
of iterations and wall clock time their serial variants where only one
coordinate is chosen (block of size @xmath ) per iteration. This justify
the necessity of choosing methods with large block sizes. Recall that
this is precisely the class of algorithms that could have an expensive
subproblem in their update rule which is required to be solved exactly
and as a result can benefit the most from the introduction of
inexactness.

#### 3.6.2 Inexactness and block size (iRBCD)

In this experiment, we first construct a positive definite linear system
following the previously described procedure for iRBCD. We first
generate a Gaussian matrix @xmath and then the positive definite matrix
@xmath is used to define a consistent liner system. We run iRBCD in this
specific linear system and compare its performance with its exact
variance for several block sizes @xmath (numbers of column of matrix
@xmath ). For evaluating the inexact solution of the linear system in
the update rule we run CG for either 2, 5 or 10 iterations. In Figure
3.3 , we plot the evolution of the relative error in terms of both the
number of iterations and the wall-clock time.

We observe that for any block size the inexact methods are always faster
in terms of wall clock time than their exact variants even if they
require (as is expected) equal or larger number of iterations. Moreover
it is obvious that the performance of the inexact method becomes much
better than the exact variant as the size @xmath increases and as a
results the sub-problem that needs to be solved in each step becomes
more expensive. It is worth to highlight that for the chosen systems,
the exact RBCD behaves better in terms of wall clock time as the size of
block increases (this coincides with the findings of the previous
experiment).

#### 3.6.3 Evaluation of iRBK

In the last experiment we evaluate the performance of iRBK in both
synthetic and real datasets. For computing the inexact solution of the
linear system in the update rule we run CG for pre-specified number of
iterations that can vary depending the datasets. In particular, we
compare iRBK and RBK on synthetic linear systems generated with the
Julia Gaussian matrix functions “randn(m,n)" and “sprandn(m,n,r)" (input
@xmath of sprandn function indicates the density of the matrix). For the
real datasets, we test the performance of iRBK and RBK using real
matrices from the library of support vector machine problems LIBSVM [ 23
] . Each dataset of the LIBSVM consists of a matrix @xmath ( @xmath
features and @xmath characteristics) and a vector of labels @xmath . In
our experiments we choose to use only the matrices of the datasets and
ignore the label vectors ¹³ ¹³ 13 Note that the real matrices of the
Splice and Madelon datasets are full rank matrices. . As before, to
ensure consistency of the linear system, we choose a Gaussian vector
@xmath and the right hand side of the linear system is set to @xmath
(for both the synthetic and the real matrices). By observing Figure 3.4
it is clear that for all problems under study the performance of iRBK in
terms of wall clock time is much better than its exact variant RBK.

### 3.7 Conclusion

In this chapter we propose and analyze inexact variants of several
stochastic algorithms for solving quadratic optimization problems and
linear systems. We provide linear convergence rate under several
assumptions on the inexactness error. The proposed methods require more
iterations than their exact variants to achieve the same accuracy.
However, as we show through our numerical evaluations, the inexact
algorithms require significantly less time to converge.

With the continuously increasing size of datasets, inexactness should
definitely be a tool that practitioners should use in their
implementations even in the case of stochastic methods that have much
cheaper-to-compute iteration complexity than their deterministic
variants. Recently, accelerated and parallel stochastic optimization
methods [ 115 , 168 , 192 ] have been proposed for solving linear
systems. We speculate that the addition of inexactness to these update
rules will lead to methods faster in practice. We also believe that our
approach and complexity results can be extended to the more general case
of minimization of convex and non-convex functions in the stochastic
setting.

### 3.8 Proofs of Main Results

In our convergence analysis we use several popular inequalities. Look
Table 3.3 for the abbreviations and the relevant formulas.

A key step in the proofs of the theorems is to use the tower property of
the expectation. We use it in the form

  -- -------- -- --------
     @xmath      (3.26)
  -- -------- -- --------

where @xmath is some random variable. In all proofs we perform the three
expectations in order, from the innermost to the outermost. Similar to
the main part of this chapter we use @xmath .

The following remark on random variables is also used in our proofs.

###### Remark 10.

Let @xmath and @xmath be random vectors and let @xmath positive
constant. If we assume @xmath then by using the variance inequality
(check Table 3.3 ) we obtain @xmath . In our setting if we assume @xmath
where @xmath is the inexactness error and @xmath is the current iterate
then by the variance inequality it holds that @xmath .

#### 3.8.1 Proof of Theorem 20

###### Proof.

First we decompose:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.27)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Applying the innermost expectation of ( 3.26 ) to ( 3.27 ), we get:

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (3.28)
                          @xmath   
  -- -- -------- -------- -------- --------

We now analyze the three expression T1,T2,T3 separately.

Note that an upper bound for the expression T2 can be directly obtained
from the assumption

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

The first expression can be written as:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.30)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

For expression T3:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.31)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where in the inequality @xmath we use Remark 10 and ( 3.5 ).

By substituting the bounds ( 3.29 ), ( 3.30 ), and ( 3.31 ) into ( 3.28
) we obtain:

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (3.32)
                          @xmath   
  -- -- -------- -------- -------- --------

We now take the middle expectation (see ( 3.26 )) and apply it to
inequality ( 3.32 ):

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.33)
                                @xmath   
  -- -------- -------- -------- -------- --------

Now let us find a bound on the quantity @xmath . Note that from ( 1.43 )
and ( 1.42 ) we have that @xmath . By using Remark 10 in the last
inequality we obtain:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.34)
  -- -------- -------- -------- -- --------

By substituting ( 3.34 ) in ( 3.33 ):

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.35)
                                @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

We take the final expectation (outermost expectation in the tower rule (
3.26 )) on the above expression to find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.36)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Using @xmath equation ( 3.36 ) takes the form:

  -- -------- -------- -- --
     @xmath   @xmath      
  -- -------- -------- -- --

If we further substitute @xmath and @xmath the recurrence simplifies to:

  -- -------- -------- -- --
     @xmath   @xmath      
  -- -------- -------- -- --

By unrolling the final inequality:

  -- -------- --
     @xmath   
  -- -------- --

Hence,

  -- -------- --
     @xmath   
  -- -------- --

The result is obtained by using V.I in the last expression. ∎

#### 3.8.2 Proof of Corollary 21

By denoting @xmath in ( 3.9 ) we obtain:

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath the result is obtained.

#### 3.8.3 Proof of Theorem 22

In order to prove Theorem 22 we need to follow similar steps to the
proof of Theorem 20 . The main differences of the two proofs appear at
the points that we need to upper bound the norm of the inexactness error
( @xmath ). In particular instead of using the general sequence @xmath
we utilize the bound @xmath from Assumption 3.3.1 . Thus, it is
sufficient to focus at the parts of the proof that these bound is used.

Similar to the proof of Theorem 20 we first decompose to obtain the
equation ( 3.28 ). There, the expression T1 can be upper bounded from (
3.30 ) but now using the Assumption 3.3.1 the expression T2 and T3 can
be upper bounded as follows:

  -- -------- -- --------
     @xmath      (3.37)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.38)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

As a result by substituting the bounds ( 3.30 ), ( 3.37 ), and ( 3.38 )
into ( 3.28 ) we obtain:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.39)
                                @xmath   
  -- -------- -------- -------- -------- --------

By following the same steps to the proof of Theorem 20 the equation (
3.35 ) takes the form:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.40)
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

We take the final expectation (outermost expectation in the tower rule (
3.26 )) on the above expression to find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.41)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

The final result follows by unrolling the recurrence.

#### 3.8.4 Proof of Theorem 23

###### Proof.

Similar to the previous two proofs by decomposing the update rule and
using the innermost expectation of ( 3.26 ) we obtain equation ( 3.28 ).
An upper bound of expression T1 is again given by inequality ( 3.30 ).
For the expression T2 depending the assumption that we have on the norm
of the inexactness error different upper bounds can be used. In
particular,

1.  If Assumption 3.3.1 holds then: @xmath

2.  If Assumption 3.3.1 holds then: @xmath

3.  If Assumption 3.3.1 holds then: @xmath

The main difference from the previous proofs, is that due to the
Assumption 3.3.1 and tower property ( 3.26 ) the expression T3 will
eventually be equal to zero. More specifically, we have that:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.42)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Thus, in this case equation ( 3.32 ) takes the form:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (3.43)
  -- -------- -------- -------- -- --------

Using the above expression depending the assumption that we have we
obtain the following results:

1.  By taking the middle expectation (see ( 3.26 )) and apply it to the
    above inequality:

      -- -------- -------- -------- -------- --------
         @xmath   @xmath   @xmath            (3.44)
                           @xmath   @xmath   
      -- -------- -------- -------- -------- --------

    We take the final expectation (outermost expectation in the tower
    rule ( 3.26 )) on the above expression to find:

      -- -------- -------- -------- -------- --------
         @xmath   @xmath   @xmath            (3.45)
                           @xmath   @xmath   
                           @xmath   @xmath   
                           @xmath   @xmath   
      -- -------- -------- -------- -------- --------

    Using @xmath the last inequality takes the form @xmath . By
    unrolling the last expression: @xmath Hence,

      -- -------- --
         @xmath   
      -- -------- --

2.  For the case (ii) inequality ( 3.43 ) takes the form:

      -- -------- --
         @xmath   
      -- -------- --

    and by taking the middle expectation (see ( 3.26 )) we obtain:

      -- -------- -------- -------- -------- --------
         @xmath   @xmath   @xmath            (3.46)
                           @xmath   @xmath   
                           @xmath   @xmath   
      -- -------- -------- -------- -------- --------

    By taking the final expectation of the tower rule ( 3.26 ) and apply
    it to the above inequality:

      -- -------- -------- -------- -- --------
         @xmath   @xmath   @xmath      (3.47)
      -- -------- -------- -------- -- --------

    and the result is obtain by unrolling the last expression.

3.  For the case (iii) inequality ( 3.43 ) takes the form:

      -- -------- -------- -- -- --------
         @xmath   @xmath         (3.48)
      -- -------- -------- -- -- --------

    and by taking the middle expectation (see ( 3.26 )) we obtain:

      -- -------- -------- -------- -------- --------
         @xmath   @xmath   @xmath            (3.49)
                           @xmath   @xmath   
                           @xmath   @xmath   
      -- -------- -------- -------- -------- --------

    By taking the final expectation of the tower rule ( 3.26 ) to the
    above inequality:

      -- -------- -------- -------- -- --------
         @xmath   @xmath   @xmath      (3.50)
      -- -------- -------- -------- -- --------

    and the result is obtain by unrolling the last expression.

∎

## Chapter 4 Revisiting Randomized Gossip Algorithms

### 4.1 Introduction

Average consensus is a fundamental problem in distributed computing and
multi-agent systems. It comes up in many real world applications such as
coordination of autonomous agents, estimation, rumour spreading in
social networks, PageRank and distributed data fusion on ad-hoc networks
and decentralized optimization. Due to its great importance there is
much classical [ 190 , 35 ] and recent [ 202 , 201 , 16 ] work on the
design of efficient algorithms/protocols for solving it.

In the average consensus (AC) problem we are given an undirected
connected network @xmath with node set @xmath and edges @xmath . Each
node @xmath “knows” a private value @xmath . The goal of AC is for every
node to compute the average of these private values, @xmath , in a
decentralized fashion. That is, the exchange of information can only
occur between connected nodes (neighbors).

Among the most attractive protocols for solving the average consensus
problem are gossip algorithms. The development and design of gossip
algorithms was studied extensively in the last decade. The seminal 2006
paper of Boyd et al. [ 16 ] motivated a fury of subsequent research and
gossip algorithms now appear in many applications, including distributed
data fusion in sensor networks [ 202 ] , load balancing [ 29 ] and clock
synchronization [ 56 ] . For a survey of selected relevant work prior to
2010, we refer the reader to the work of Dimakis et al. [ 42 ] . For
more recent results on randomized gossip algorithms we suggest [ 217 ,
106 , 148 , 109 , 131 , 6 ] . See also [ 43 , 7 , 149 ] .

#### 4.1.1 Main contributions

In this chapter, we connect two areas of research which until now have
remained remarkably disjoint in the literature: randomized iterative
(projection) methods for solving linear systems and randomized gossip
protocols for solving the average consensus. This connection enables us
to make contributions by borrowing from each body of literature to the
other and using it we propose a new framework for the design and
analysis of novel efficient randomized gossip protocols.

The main contributions of our work include:

-    RandNLA. We show how classical randomized iterative methods for
    solving linear systems can be interpreted as gossip algorithms when
    applied to special systems encoding the underlying network and
    explain in detail their decentralized nature. Through our general
    framework we recover a comprehensive array of well-known gossip
    protocols as special cases. In addition our approach allows for the
    development of novel block and dual variants of all of these
    methods. From a numerical analysis viewpoint our work is the first
    that explores in depth, the decentralized nature of randomized
    iterative methods for solving linear systems and proposes them as
    efficient methods for solving the average consensus problem (and its
    weighted variant).

-    Weighted AC. The methods presented in this chapter solve the more
    general weighted average consensus (Weighted AC) problem (Section
    4.3.1 ) popular in the area of distributed cooperative spectrum
    sensing networks. The proposed protocols are the first randomized
    gossip algorithms that directly solve this problem with finite-time
    convergence rate analysis. In particular, we prove linear
    convergence of the proposed protocols and explain how we can obtain
    further acceleration using momentum. To the best of our knowledge,
    the existing decentralized protocols that solve the weighted average
    consensus problem show convergence but without convergence analysis.

-    Acceleration. We present novel and provably accelerated randomized
    gossip protocols. In each step, of the proposed algorithms, all
    nodes of the network update their values using their own information
    but only a subset of them exchange messages. The protocols are
    inspired by the recently proposed accelerated variants of randomized
    Kaczmarz-type methods and use momentum terms on top of the sketch
    and project update rule (gossip communication) to obtain better
    theoretical and practical performance. To the best of our knowledge,
    our accelerated protocols are the first randomized gossip algorithms
    that converge to a consensus with a provably accelerated linear rate
    without making any further assumptions on the structure of the
    network. Achieving an accelerated linear rate in this setting using
    randomized gossip protocols was an open problem.

-    Duality. We reveal a hidden duality of randomized gossip
    algorithms, with the dual iterative process maintaining variables
    attached to the edges of the network. We show how the randomized
    coordinate descent and randomized Newton methods work as edge-based
    dual randomized gossip algorithms.

-    Experiments. We corroborate our theoretical results with extensive
    experimental testing on typical wireless network topologies. We
    numerically verify the linear convergence of the our protocols for
    solving the weighted AC problem. We explain the benefit of using
    block variants in the gossip protocols where more than two nodes
    update their values in each iteration. We explore the performance of
    the proposed provably accelerated gossip protocols and show that
    they significantly outperform the standard pairwise gossip algorithm
    and existing fast pairwise gossip protocols with momentum. An
    experiment showing the importance of over-relaxation in the gossip
    setting is also presented.

We believe that this work could potentially open up new avenues of
research in the area of decentralized gossip protocols.

#### 4.1.2 Structure of the chapter

This chapter is organized as follows. Section 4.2 introduces the
necessary background on basic randomized iterative methods for linear
systems that will be used for the development of randomized gossip
protocols. Related work on the literature of linear system solvers,
randomized gossip algorithms for averaging and gossip algorithms for
consensus optimization is presented. In Section 4.3 the more general
weighted average consensus problem is described and the connections
between the two areas of research (randomized projection methods for
linear systems and gossip algorithms) is established. In particular we
explain how methods for solving linear systems can be interpreted as
gossip algorithms when applied to special systems encoding the
underlying network and elaborate in detail their distributed nature.
Novel block gossip variants are also presented. In Section 4.4 we
describe and analyze fast and provably accelerated randomized gossip
algorithms. In each step of these protocols all nodes of the network
update their values but only a subset of them exchange their private
values. Section 4.5 describes dual randomized gossip algorithms that
operate with values that are associated to the edges of the network and
Section 4.6 highlights further connections between methods for solving
linear systems and gossip algorithms. Numerical evaluation of the new
gossip protocols is presented in Section 4.7 . Finally, concluding
remarks are given in Section 4.8 .

#### 4.1.3 Notation

For convenience, a table of the most frequently used notation of this
chapter is included in Section A.2 . In particular, with boldface
upper-case letters denote matrices; @xmath is the identity matrix. By
@xmath and @xmath we denote the Euclidean norm and the Frobenius norm,
respectively. For a positive integer number @xmath , we write @xmath .
By @xmath we denote the solution set of the linear system @xmath , where
@xmath and @xmath .

Vector @xmath represents the vector with the private values of the
@xmath nodes of the network at the @xmath iteration while with @xmath we
denote the value of node @xmath at the @xmath iteration. @xmath denotes
the set of nodes that are neighbors of node @xmath . By @xmath we denote
the algebraic connectivity of graph @xmath . Throughout the chapter,
@xmath is the projection of @xmath onto @xmath in the @xmath -norm. We
write @xmath .

The complexity of all gossip protocols presented in this chapter is
described by the spectrum of matrix

  -- -- -- -------
           (4.1)
  -- -- -- -------

where the expectation is taken over @xmath . With @xmath and @xmath we
indicate the smallest nonzero and the largest eigenvalue of matrix
@xmath , respectively. Recall that this is exactly the same matrix used
in the previous chapters of this thesis.

Finally, with @xmath we define the incidence matrix and with @xmath the
Laplacian matrix of the network. Note that it holds that @xmath .
Further, with @xmath we denote the degree matrix of the graph. That is,
@xmath where @xmath is the degree of node @xmath .

### 4.2 Background - Technical Preliminaries

As we have already mentioned in this thesis, solving linear systems is a
central problem in numerical linear algebra and plays an important role
in computer science, control theory, scientific computing, optimization,
computer vision, machine learning, and many other fields. With the
advent of the age of big data, practitioners are looking for ways to
solve linear systems of unprecedented sizes. In this large scale
setting, randomized iterative methods are preferred mainly because of
their cheap per iteration cost and because they can easily scale to
extreme dimensions.

#### 4.2.1 Randomized iterative methods for linear systems

Recall that in the introduction of this thesis we presented the sketch
and project method ( 1.25 ) and we explained how this algorithm is
identical to SGD ( 1.17 ), SN ( 1.18 ) and SPP ( 1.19 ) for solving the
stochastic quadratic optimization problem ( 1.6 ). For the benefit of
the reader and for the easier comparison to the gossip algorithms, a
formal presentation of the Sketch and Project method for solving a
consistent linear system @xmath is presented in Algorithm 8 .

1: Parameters: Distribution @xmath from which method samples matrices;
stepsize/relaxation parameter @xmath ; momentum parameter @xmath .

2: Initialize: @xmath

3: for @xmath do

4: Draw a fresh @xmath

5: Set @xmath

6: end for

7: Output: The last iterate @xmath

Algorithm 8 Sketch and Project Method [ 168 ]

In this chapter, we are mostly interested in two special cases of the
sketch and project framework— the randomized Kaczmarz (RK) method and
its block variant, the randomized block Kaczmarz (RBK) method. In
addition, in the following sections we present novel scaled and
accelerated variants of these two selected cases and interpret their
gossip nature. In particular, we focus on explaining how these methods
can solve the average consensus problem and its more general version,
the weighted average consensus (subsection 4.3.1 ).

Let @xmath be the @xmath unit coordinate vector in @xmath and let @xmath
be column submatrix of the @xmath identity matrix with columns indexed
by @xmath . Then RK and RBK methods can be obtained as special cases of
Algorithm 8 as follows:

-   RK: Let @xmath and @xmath , where @xmath is chosen independently at
    each iteration, with probability @xmath . In this setup the update
    rule of Algorithm 8 simplifies to

      -- -------- -- -------
         @xmath      (4.2)
      -- -------- -- -------

-   RBK: Let @xmath and @xmath , where set @xmath is chosen
    independently at each iteration, with probability @xmath . In this
    setup the update rule of Algorithm 8 simplifies to

      -- -------- -- -------
         @xmath      (4.3)
      -- -------- -- -------

As we explained in Chapter 1 , the sketch and project method, converges
linearly to one particular solution of the linear system: the projection
(on @xmath -norm) of the initial iterate @xmath onto the solution set of
the linear system, @xmath . Therefore, the method solve the best
approximation problem ( 1.22 ).

The convergence performance of the Sketch and Project method (Algorithm
8 ) for solving the best approximation problem is described by the
following theorem ¹ ¹ 1 For the proof of Theorem 30 check Theorem 3 in
Section 1.5 and recall that SGD and the sketch and project method are
identical in this setting. .

###### Theorem 30.

Let assume exactness and let @xmath be the iterates produced by the
sketch and project method (Algorithm 8 ) with step-size @xmath . Set,
@xmath . Then,

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

In other words, using standard arguments, from Theorem 30 we observe
that for a given @xmath we have that:

  -- -------- --
     @xmath   
  -- -------- --

#### 4.2.2 Other related work

###### Gossip algorithms for average consensus

The problem of average consensus has been extensively studied in the
automatic control and signal processing literature for the past two
decades [ 42 ] , and was first introduced for decentralized processing
in the seminal work [ 190 ] . A clear connection between the rate of
convergence and spectral characteristics of the underlying network
topology over which message passing occurs was first established in [ 16
] for pairwise randomized gossip algorithms.

Motivated by network topologies with salient properties of wireless
networks (e.g., nodes can communicate directly only with other nearby
nodes), several methods were proposed to accelerate the convergence of
gossip algorithms. For instance, [ 8 ] proposed averaging among a set of
nodes forming a path in the network (this protocol can be seen as
special case of our block variants in Section 4.3.4 ). Broadcast gossip
algorithms have also been analyzed [ 7 ] where the nodes communicate
with more than one of their neighbors by broadcasting their values.

While the gossip algorithms studied in [ 16 , 8 , 7 ] are all
first-order (the update of @xmath only depends on @xmath ), a faster
randomized pairwise gossip protocol was proposed in [ 19 ] which
suggested to incorporate additional memory to accelerate convergence.
The first analysis of this protocol was later proposed in [ 106 ] under
strong condition. It is worth to mention that in the setting of
deterministic gossip algorithms theoretical guarantees for accelerated
convergence were obtained in [ 150 , 94 ] . In Section 4.4 we propose
fast and provably accelerated randomized gossip algorithms with memory
and compare them in more detail with the fast randomized algorithm
proposed in [ 19 , 106 ] .

###### Gossip algorithms for multiagent consensus optimization.

In the past decade there has been substantial interest in
consensus-based mulitiagent optimization methods that use gossip updates
in their update rule [ 131 , 209 , 179 ] . In multiagent consensus
optimization setting , @xmath agents or nodes, cooperate to solve an
optimization problem. In particular, a local objective function @xmath
is associated with each node @xmath and the goal is for all nodes to
solve the optimization problem

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

by communicate only with their neighbors. In this setting gossip
algorithms works in two steps by first executing some local computation
followed by communication over the network [ 131 ] . Note that the
average consensus problem with @xmath as node @xmath initial value can
be case as a special case of the optimization problem ( 4.6 ) when the
function values are @xmath .

Recently there has been an increasing interest in applying mulitagent
optimization methods to solve convex and non-convex optimization
problems arising in machine learning [ 189 , 105 , 4 , 5 , 25 , 95 , 83
] . In this setting most consensus-based optimization methods make use
of standard, first-order gossip, such as those described in [ 16 ] , and
incorporating momentum into their updates to improve their practical
performance.

### 4.3 Sketch and Project Methods as Gossip Algorithms

In this section we show how by carefully choosing the linear system in
the constraints of the best approximation problem ( 1.22 ) and the
combination of the parameters of the Sketch and Project method
(Algorithm 8 ) we can design efficient randomized gossip algorithms. We
show that the proposed protocols can actually solve the weighted average
consensus problem, a more general version of the average consensus
problem described in Section 4.1 . In particular we focus, on a scaled
variant of the RK method ( 4.2 ) and on the RBK ( 4.3 ) and understand
the convergence rates of these methods in the consensus setting, their
distributed nature and how they are connected with existing gossip
protocols.

#### 4.3.1 Weighted average consensus

In the weighted average consensus (Weighted AC) problem we are given an
undirected connected network @xmath with node set @xmath and edges
@xmath . Each node @xmath holds a private value @xmath and its weight
@xmath . The goal of this problem is for every node to compute the
weighted average of the private values,

  -- -------- --
     @xmath   
  -- -------- --

in a distributed fashion. That is, the exchange of information can only
occur between connected nodes (neighbors).

Note that in the special case when the weights of all nodes are the same
( @xmath for all @xmath ) the weighted average consensus is reduced to
the standard average consensus problem. However, there are more special
cases that could be interesting. For instance the weights can represent
the degree of the nodes ( @xmath ) or they can denote a probability
vector and satisfy @xmath with @xmath .

It can be easily shown that the weighted average consensus problem can
be expressed as optimization problem as follows:

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

where matrix @xmath is a diagonal positive definite matrix (that is
@xmath for all @xmath ) and @xmath the vector with the initial values
@xmath of all nodes @xmath . The optimal solution of this problem is
@xmath for all @xmath which is exactly the solution of the weighted
average consensus.

As we have explained, the standard average consensus problem can be cast
as a special case of weighted average consensus. However, in the
situation when the nodes have access to global information related to
the network, such as the size of the network (number of nodes @xmath )
and the sum of the weights @xmath , then any algorithm that solves the
standard average consensus can be used to solve the weighted average
consensus problem with the initial private values of the nodes changed
from @xmath to @xmath .

The weighted AC problem is popular in the area of distributed
cooperative spectrum sensing networks [ 84 , 151 , 212 , 213 ] . In this
setting, one of the goals is to develop decentralized protocols for
solving the cooperative sensing problem in cognitive radio systems. The
weights in this case represent a ratio related to the channel conditions
of each node/agent [ 84 ] . The development of methods for solving the
weighted AC problem is an active area of research (check [ 84 ] for a
recent comparison of existing algorithms). However, to the best of our
knowledge, existing analysis for the proposed algorithms focuses on
showing convergence and not on providing convergence rates. Our
framework allows us to obtain novel randomized gossip algorithms for
solving the weighted AC problem. In addition, we provide a tight
analysis of their convergence rates. In particular, we show convergence
with a linear rate. See Section 4.7.1 for an experiment confirming
linear convergence of one of our proposed protocols on typical wireless
network topologies.

#### 4.3.2 Gossip algorithms through sketch and project framework

We propose that randomized gossip algorithms should be viewed as special
case of the Sketch and Project update to a particular problem of the
form ( 1.22 ). In particular, we let @xmath be the initial values stored
at the nodes of @xmath , and choose @xmath and @xmath so that the
constraint @xmath is equivalent to the requirement that @xmath (the
value stored at node @xmath is equal to the value stored at node @xmath
) for all @xmath .

###### Definition 31.

We say that @xmath is an “average consensus (AC) system” when @xmath iff
@xmath for all @xmath .

It is easy to see that @xmath is an AC system precisely when @xmath and
the nullspace of @xmath is @xmath , where @xmath is the vector of all
ones in @xmath . Hence, @xmath has rank @xmath . Moreover in the case
that @xmath , it is easy to see that for any AC system, the solution of
( 1.22 ) necessarily is @xmath — this is why we singled out AC systems.
In this sense, any algorithm for solving ( 1.22 ) will “find” the
(weighted) average @xmath . However, in order to obtain a distributed
algorithm we need to make sure that only “local” (with respect to @xmath
) exchange of information is allowed.

###### Choices of AC systems.

It can be shown that many linear systems satisfy the above definition.

For example, we can choose:

1.  @xmath and @xmath to be the incidence matrix of @xmath . That is,
    @xmath such that @xmath directly encodes the constraints @xmath for
    @xmath . That is, row @xmath of matrix @xmath contains value @xmath
    in column @xmath , value @xmath in column @xmath (we use an
    arbitrary but fixed order of nodes defining each edge in order to
    fix @xmath ) and zeros elsewhere.

2.  A different choice is to pick @xmath and @xmath , where @xmath is
    the Laplacian matrix of network @xmath .

Depending on what AC system is used, the sketch and project methods can
have different interpretations as gossip protocols.

In this work we mainly focus on the above two AC systems but we
highlight that other choices are possible ² ² 2 Novel gossip algorithms
can be proposed by using different AC systems to formulate the average
consensus problem. For example one possibility is using the random walk
normalized Laplacian @xmath . For the case of degree-regular networks
the symmetric normalized Laplacian matrix @xmath can also being used. .
In Section 4.4.2 for the provably accelerated gossip protocols we also
use a normalized variant ( @xmath ) of the Incidence matrix.

##### Standard form and mass preservation

Assume that @xmath is an AC system. Note that since @xmath , the update
rule of Algorithm 8 simplifies to:

  -- -- -- -------
           (4.8)
  -- -- -- -------

This is the standard form in which randomized gossip algorithms are
written. What is new here is that the iteration matrix @xmath has a
specific structure which guarantees convergence to @xmath under very
weak assumptions (see Theorem 30 ). Note that if @xmath , i.e., the
starting primal iterate is the vector of private values (as should be
expected from any gossip algorithm), then the iterates of ( 4.8 ) enjoy
a mass preservation property (the proof follows the fact that @xmath ):

###### Theorem 32 (Mass preservation).

If @xmath is an AC system, then the iterates produced by ( 4.8 )
satisfy: @xmath , for all @xmath .

###### Proof.

Let fix @xmath then,

  -- -- --
        
  -- -- --

∎

##### @xmath-Averaging time

Let @xmath . The typical measure of convergence speed employed in the
randomized gossip literature, called @xmath -averaging time and here
denoted by @xmath , represents the smallest time @xmath for which @xmath
gets within @xmath from @xmath , with probability greater than @xmath ,
uniformly over all starting values @xmath . More formally, we define

  -- -------- --
     @xmath   
  -- -------- --

This definition differs slightly from the standard one in that we use
@xmath instead of @xmath .

Inequality ( 4.4 ), together with Markov inequality, can be used to give
a bound on @xmath , formalized next:

###### Theorem 33.

Assume @xmath is an AC system. Let @xmath and @xmath be positive
definite diagonal matrix. Assume exactness. Then for any @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is defined in ( 4.5 ).

###### Proof.

See Section 4.9.1 . ∎

Note that under the assumptions of the above theorem, @xmath only has a
single zero eigenvalue, and hence @xmath is the second smallest
eigenvalue of @xmath . Thus, @xmath is the second largest eigenvalue of
@xmath . The bound on @xmath appearing in Thm 33 is often written with
@xmath replaced by @xmath [ 16 ] .

In the rest of this section we show how two special cases of the sketch
and project framework, the randomized Kaczmarz (RK) and its block
variant, randomized block Kaczmatz (RBK) work as gossip algorithms for
the two AC systems described above.

#### 4.3.3 Randomized Kaczmarz method as gossip algorithm

As we described before the sketch and project update rule of Algorithm 8
has several parameters that should be chosen in advance by the user.
These are the stepsize @xmath (relaxation parameter), the positive
definite matrix @xmath and the distribution @xmath of the random
matrices @xmath .

In this section we focus on one particular special case of the sketch
and project framework, a scaled/weighted variant of the randomized
Kaczmarz method (RK) presented in ( 4.2 ), and we show how this method
works as gossip algorithm when applied to special systems encoding the
underlying network. In particular, the linear systems that we solve are
the two AC systems described in the previous section where the matrix is
either the incidence matrix @xmath or the Laplacian matrix @xmath of the
network.

As we described in ( 4.2 ) the standard RK method can be cast as special
case of Algorithm 8 by choosing @xmath and @xmath . In this section, we
focus on a small modification of this algorithm and we choose the
positive definite matrix @xmath to be @xmath , the diagonal matrix of
the weights presented in the weighted average consensus problem.

###### Scaled RK:

Let us have a general consistent linear system @xmath with @xmath . Let
us also choose @xmath and @xmath , where @xmath is chosen in each
iteration independently, with probability @xmath . In this setup the
update rule of Algorithm 8 simplifies to

  -- -- -- -------
           (4.9)
  -- -- -- -------

This small modification of RK allow us to solve the more general
weighted average consensus presented in Section 4.3.1 (and at the same
time the standard average consensus problem if @xmath where @xmath ). To
the best of our knowledge, even if this variant is special case of the
general Sketch and project update, was never precisely presented before
in any setting.

##### AC system with incidence matrix @xmath

Let us represent the constraints of problem ( 4.7 ) as linear system
with matrix @xmath be the Incidence matrix of the graph and right had
side @xmath . Lets also assume that the random matrices @xmath are unit
coordinate vectors in @xmath .

Let @xmath then from the definition of matrix @xmath we have that @xmath
where @xmath are unit coordinate vectors in @xmath . In addition, from
the definition the diagonal positive definite matrix @xmath we have that

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

Thus in this case the update rule ( 4.9 ) simplifies:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.11)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

From ( 4.11 ) it can be easily seen that only the values of coordinates
@xmath and @xmath update their values. These coordinates correspond to
the private values @xmath and @xmath of the nodes of the selected edge
@xmath . In particular the values of @xmath and @xmath are updated as
follows:

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

###### Remark 11.

In the special case that @xmath where @xmath (we solve the standard
average consensus problem) the update of the two nodes is simplified to

  -- -------- --
     @xmath   
  -- -------- --

If we further select @xmath then this becomes:

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

which is the update of the standard pairwise randomized gossip algorithm
first presented and analyzed in [ 16 ] .

##### AC system with Laplacian matrix @xmath

The AC system takes the form @xmath , where matrix @xmath is the
Laplacian matrix of the network. In this case, each row of the matrix
corresponds to a node. Using the definition of the Laplacian, we have
that @xmath , where @xmath are unit coordinate vectors in @xmath and
@xmath is the degree of node @xmath .

Thus, by letting @xmath to be the diagonal matrix of the weights we
obtain:

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

In this case, the update rule ( 4.9 ) simplifies to:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.15)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

From ( 4.15 ), it is clear that only coordinates @xmath update their
values. All the other coordinates remain unchanged. In particular, the
value of the selected node @xmath (coordinate @xmath ) is updated as
follows:

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

while the values of its neighbors @xmath are updated as:

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

###### Remark 12.

Let @xmath and @xmath where @xmath then the selected nodes update their
values as follows:

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

That is, the selected node @xmath updates its value to the average of
its neighbors and itself, while all the nodes @xmath update their values
using the current value of node @xmath and all nodes in @xmath .

In a wireless network, to implement such an update, node @xmath would
first broadcast its current value to all of its neighbors. Then it would
need to receive values from each neighbor to compute the sums over
@xmath , after which node @xmath would broadcast the sum to all
neighbors (since there may be two neighbors @xmath for which @xmath ).
In a wired network, using standard concepts from the MPI library, such
an update rule could be implemented efficiently by defining a process
group consisting of @xmath , and performing one Broadcast in this group
from @xmath (containing @xmath ) followed by an AllReduce to sum @xmath
over @xmath . Note that the terms involving diagonal entries of @xmath
and the degrees @xmath could be sent once, cached, and reused throughout
the algorithm execution to reduce communication overhead.

##### Details on complexity results

Recall that the convergence rate of the sketch and project method
(Algorithm 8 ) is equivalent to:

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath (from Theorem 30 ). In this subsection we
explain how the convergence rate of the scaled RK method ( 4.9 ) is
modified for different choices of the main parameters of the method.

Let us choose @xmath (no over-relaxation). In this case, the rate is
simplified to @xmath .

Note that the different ways of modeling the problem (AC system) and the
selection of the main parameters (weight matrix @xmath and distribution
@xmath ) determine the convergence rate of the method through the
spectrum of matrix @xmath .

Recall that in the @xmath iterate of the scaled RK method ( 4.9 ) a
random vector @xmath is chosen with probability @xmath . For
convenience, let us choose ³ ³ 3 Similar probabilities have been chosen
in [ 73 ] for the convergence of the standard RK method ( @xmath ). The
distribution @xmath of the matrices @xmath used in equation ( 4.19 ) is
common in the area of randomized iterative methods for linear systems
and is used to simplify the analysis and the expressions of the
convergence rates. For more choices of distributions we refer the
interested reader to [ 73 ] . It is worth to mention that the
probability distribution that optimizes the convergence rate of the RK
and other projection methods can be expressed as the solution to a
convex semidefinite program [ 73 , 30 ] . :

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

Then we have that:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.20)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

and

  -- -------- -- --------
     @xmath      (4.21)
  -- -------- -- --------

###### Incidence Matrix:

Let us choose the AC system to be the one with the incidence matrix
@xmath . Then @xmath and we obtain

  -- -- --
        
  -- -- --

If we further have @xmath , then @xmath and the convergence rate
simplifies to:

  -- -------- --
     @xmath   
  -- -------- --

If @xmath where @xmath (solve the standard average consensus problem),
then @xmath and the convergence rate simplifies to

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

which is exactly the same convergence rate of the pairwise gossip
algorithm presented in [ 16 ] . This was expected, since the gossip
protocol in this case works exactly the same as the one proposed in [ 16
] , see equation ( 4.13 ).

###### Laplacian Matrix:

If we choose to formulate the AC system using the Laplacian matrix
@xmath , that is @xmath , then @xmath and we have:

  -- -- --
        
  -- -- --

If @xmath , then the convergence rate simplifies to:

  -- -------- --
     @xmath   
  -- -------- --

If @xmath , where @xmath , then @xmath and the convergence rate
simplifies to

  -- -------- --
     @xmath   
  -- -------- --

#### 4.3.4 Block gossip algorithms

Up to this point we focused on the basic connections between the
convergence analysis of the sketch and project methods and the
literature of randomized gossip algorithms. We show how specific
variants of the randomized Kaczmarz method (RK) can be interpreted as
gossip algorithms for solving the weighted and standard average
consensus problems.

In this part we extend the previously described methods to their block
variants related to randomized block Kaczmarz (RBK) method ( 4.3 ). In
particular, in each step of Algorithm 8 , the random matrix @xmath is
selected to be a random column submatrix of the @xmath identity matrix
corresponding to columns indexed by a random subset @xmath . That is,
@xmath , where a set @xmath is chosen in each iteration independently,
with probability @xmath (see equation ( 4.3 )). Note that in the special
case that set @xmath is a singleton with probability 1 the algorithm is
simply the randomized Kaczmarz method of the previous section.

To keep things simple, we assume that @xmath (standard average
consensus, without weights) and choose the stepsize @xmath . In the next
section, we will describe gossip algorithms with heavy ball momentum and
explain in detail how the gossip interpretation of RBK change in the
more general case of @xmath .

Similar to the previous subsections, we formulate the consensus problem
using either @xmath or @xmath as the matrix in the AC system. In this
setup, the iterative process of Algorithm 8 has the form:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (4.23)
  -- -------- -------- -------- -- --------

which, as explained in the introduction, can be equivalently written as:

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Essentially in each step of this method the next iterate is evaluated to
be the projection of the current iterate @xmath onto the solution set of
a row subsystem of @xmath .

###### AC system with Incidence Matrix:

In the case that @xmath the selected rows correspond to a random subset
@xmath of selected edges. While ( 4.23 ) may seem to be a complicated
algebraic (resp. variational) characterization of the method, due to our
choice of @xmath we have the following result which gives a natural
interpretation of RBK as a gossip algorithm (see also Figure 4.1 ).

###### Theorem 34 (RBK as Gossip algorithm: RBKG).

Consider the AC system with the constraints being expressed using the
Incidence matrix @xmath . Then each iteration of RBK (Algorithm ( 4.23
)) works as gossip algorithm as follows:

1.   Select a random set of edges @xmath ,

2.   Form subgraph @xmath of @xmath from the selected edges

3.   For each connected component of @xmath , replace node values with
    their average.

###### Proof.

See Section 4.9.2 . ∎

Using the convergence result of general Theorem 30 and the form of
matrix @xmath (recall that in this case we assume @xmath , @xmath and
@xmath ), we obtain the following complexity for the algorithm:

  -- -------- -- --------
     @xmath      (4.25)
  -- -------- -- --------

For more details on the above convergence rate of randomized block
Kaczmarz method with meaningfully bounds on the rate in a more general
setting we suggest the papers [ 134 , 135 ] .

There is a very closed relationship between the gossip interpretation of
RBK explained in Theorem 34 and several existing randomized gossip
algorithms that in each step update the values of more than two nodes.
For example the path averaging algorithm porposed in [ 8 ] is a special
case of RBK, when set @xmath is restricted to correspond to a path of
vertices. That is, in path averaging, in each iteration a path of nodes
is selected and the nodes that belong to it update their values to their
exact average. A different example is the recently proposed clique
gossiping [ 110 ] where the network is already divided into cliques and
through a random procedure a clique is activated and the nodes of it
update their values to their exact average. In [ 16 ] a synchronous
variant of gossip algorithm is presented where in each step multiple
node pairs communicate exactly at the same time with the restriction
that these simultaneously active node pairs are disjoint.

It is easy to see that all of the above algorithms can be cast as
special cases of RBK if the distribution @xmath of the random matrices
is chosen carefully to be over random matrices @xmath (column
sub-matrices of Identity) that update specific set of edges in each
iteration. As a result our general convergence analysis can recover the
complexity results proposed in the above works.

Finally, as we mentioned, in the special case in which set @xmath is
always a singleton, Algorithm ( 4.23 ) reduces to the standard
randomized Kaczmarz method. This means that only a random edge is
selected in each iteration and the nodes incident with this edge replace
their local values with their average. This is the pairwise gossip
algorithm of Boyd er al. [ 16 ] presented in equation ( 4.13 ). Theorem
34 extends this interpretation to the case of the RBK method.

###### AC system with Laplacian Matrix:

For this choice of AC system the update is more complicated. To simplify
the way that the block variant work as gossip we make an extra
assumption. We assume that the selected rows of the constraint @xmath in
update ( 4.24 ) have no-zero elements at different coordinates. This
allows to have a direct extension of the serial variant presented in
Remark 12 . Thus, in this setup, the RBK update rule ( 4.23 ) works as
gossip algorithm as follows:

1.  @xmath nodes are activated (with restriction that the nodes are not
    neighbors and they do not share common neighbors)

2.  For each node @xmath we have the following update:

      -- -------- -- --------
         @xmath      (4.26)
      -- -------- -- --------

The above update rule can be seen as a parallel variant of update ( 4.18
). Similar to the convergence in the case of Incidence matrix, the RBK
for solving the AC system with a Laplacian matrix converges to @xmath
with the following rate (using result of Theorem 30 ):

  -- -------- --
     @xmath   
  -- -------- --

### 4.4 Faster and Provably Accelerated Randomized Gossip Algorithms

The main goal in the design of gossip protocols is for the computation
and communication to be done as quickly and efficiently as possible. In
this section, our focus is precisely this. We design randomized gossip
protocols which converge to consensus fast with provable accelerated
linear rates. To the best of our knowledge, the proposed protocols are
the first randomized gossip algorithms that converge to consensus with
an accelerated linear rate.

In particular, we present novel protocols for solving the average
consensus problem where in each step all nodes of the network update
their values but only a subset of them exchange their private values.
The protocols are inspired from the recently developed accelerated
variants of randomized Kaczmarz-type methods for solving consistent
linear systems where the addition of momentum terms on top of the sketch
and project update rule provides better theoretical and practical
performance.

In the area of optimization algorithms, there are two popular ways to
accelerate an algorithm using momentum. The first one is using the
Polyak’s heavy ball momentum [ 156 ] and the second one is using the
theoretically much better understood momentum introduced by Nesterov [
138 , 140 ] . Both momentum approaches have been recently proposed and
analyzed to improve the performance of randomized iterative methods for
solving linear systems.

To simplify the presentation, the accelerated algorithms and their
convergence rates are presented for solving the standard average
consensus problem ( @xmath ). Using a similar approach as in the
previous section, the update rules and the convergence rates can be
easily modified to solve the more general weighted average consensus
problem. For the protocols in this section we use the incidence matrix
@xmath or its normalized variant to formulate the AC system.

#### 4.4.1 Gossip algorithms with heavy ball momentum

In Chapter 2 of this thesis we have analyzed heavy ball momentum
variants of several algorithms for solving the stochastic optimization
problem ( 1.6 ) and as we explained the best approximation problem (
1.22 ). In this section we revisit Algorithm 1 of Chapter 2 and we focus
on its sketch and project viewpoint. In particular, we explain how it
works as gossip algorithm when is applied to the AC system with the
incidence matrix.

##### Sketch and project with heavy ball momentum

The sketch and project method with heavy ball momentum is formally
presented in the following algorithm.

1: Parameters: Distribution @xmath from which method samples matrices;
stepsize/relaxation parameter @xmath ; momentum parameter @xmath .

2: Initialize: @xmath

3: for @xmath do

4: Draw a fresh @xmath

5: Set

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

6: end for

7: Output: The last iterate @xmath

Algorithm 9 Sketch and Project with Heavy Ball Momentum

Using, @xmath and the same choice of distribution @xmath as in equations
( 4.2 ) and ( 4.3 ) we can now obtain momentum variants of the RK and
RBK as special case of the above algorithm as follows:

-   RK with momentum (mRK):

      -- -------- -- --------
         @xmath      (4.28)
      -- -------- -- --------

-   RBK with momentum (mRBK):

      -- -------- -- --------
         @xmath      (4.29)
      -- -------- -- --------

For more details on the convergence analysis of Algorithm 9 see Section
2.3 and recall that in our setting the sketch and project update rule is
identical to the SGD (Chapter 1 ). As a result Algorithm 9 is identical
to Algorithm 1 (mSGD/mSN/mSPP).

Having presented Algorithm 9 , let us now describe its behavior as a
randomized gossip protocol when applied to the AC system @xmath with
@xmath (incidence matrix of the network).

Note that since @xmath (from the AC system definition), the update rule
( 4.27 ) of Algorithm 9 is simplified to (and by having @xmath ):

  -- -------- -- --------
     @xmath      (4.30)
  -- -------- -- --------

In the rest of this section we focus on two special cases of ( 4.30 ):
RK with heavy ball momentum (equation ( 4.28 ) with @xmath ) and RBK
with heavy ball momentum (equation ( 4.29 ) with @xmath ).

##### Randomized Kaczmarz gossip with heavy ball momentum

As we have seen in previous section when the standard RK is applied to
solve the AC system @xmath , one can recover the famous pairwise gossip
algorithm [ 16 ] . Algorithm 10 describes how a relaxed variant of
randomized Kaczmarz with heavy ball momentum ( @xmath and @xmath )
behaves as a gossip algorithm. See also Figure ( 4.2 ) for a graphical
illustration of the method.

1: Parameters: Distribution @xmath from which method samples matrices;
stepsize/relaxation parameter @xmath ; heavy ball/momentum parameter
@xmath .

2: Initialize: @xmath

3: for @xmath do

4: Pick an edge @xmath following the distribution @xmath

5: The values of the nodes are updated as follows:

-    Node @xmath : @xmath

-    Node @xmath : @xmath

-    Any other node @xmath : @xmath

6: end for

7: Output: The last iterate @xmath

Algorithm 10 mRK: Randomized Kaczmarz with momentum as a gossip
algorithm

###### Remark 13.

In the special case that @xmath (zero momentum) only the two nodes of
edge @xmath update their values. In this case the two selected nodes do
not update their values to their exact average but to a convex
combination that depends on the stepsize @xmath . To obtain the pairwise
gossip algorithm of [ 16 ] , one should further choose @xmath .

Distributed Nature of the Algorithm: Here we highlight a few ways to
implement mRK in a distributed fashion.

-   Pairwise broadcast gossip: In this protocol each node @xmath of the
    network @xmath has a clock that ticks at the times of a rate 1
    Poisson process. The inter-tick times are exponentially distributed,
    independent across nodes, and independent across time. This is
    equivalent to a global clock ticking at a rate @xmath Poisson
    process which wakes up an edge of the network at random. In
    particular, in this implementation mRK works as follows: In the
    @xmath iteration (time slot) the clock of node @xmath ticks and node
    @xmath randomly contact one of its neighbors and simultaneously
    broadcast a signal to inform the nodes of the whole network that is
    updating (this signal does not contain any private information of
    node @xmath ). The two nodes @xmath share their information and
    update their private values following the update rule of Algorithm
    10 while all the other nodes update their values using their own
    information. In each iteration only one pair of nodes exchange their
    private values.

-   Synchronous pairwise gossip: In this protocol a single global clock
    is available to all nodes. The time is assumed to be slotted
    commonly across nodes and in each time slot only a pair of nodes of
    the network is randomly activated and exchange their information
    following the update rule of Algorithm 10 . The remaining not
    activated nodes update their values using their own last two private
    values. Note that this implementation of mRK comes with the
    disadvantage that it requires a central entity which in each step
    requires to choose the activated pair of nodes ⁴ ⁴ 4 We speculate
    that a completely distributed synchronous gossip algorithm that
    finds pair of nodes in a distributed manner without any additional
    computational burden can be design following the same procedure
    proposed in Section III.C of [ 16 ] . .

-   Asynchronous pairwise gossip with common counter: Note that the
    update rule of the selected pair of nodes @xmath in Algorithm 10 can
    be rewritten as follows:

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

    In particular observe that the first part of the above expressions
    @xmath (for the case of node @xmath ) is exactly the same with the
    update rule of the non activate nodes at @xmath iterate (check step
    5 of Algorithm 10 ) . Thus, if we assume that all nodes share a
    common counter that keeps track of the current iteration count and
    that each node @xmath remembers the iteration counter @xmath of when
    it was last activated, then step 5 of Algorithm 10 takes the form:

    -   @xmath

    -   @xmath

    -   @xmath

    -   Any other node @xmath : @xmath

    where @xmath ( @xmath ) denotes the number of iterations between the
    current iterate and the last time that the @xmath ( @xmath ) node is
    activated. In this implementation only a pair of nodes communicate
    and update their values in each iteration (thus the justification of
    asynchronous), however it requires the nodes to share a common
    counter that keeps track the current iteration count in order to be
    able to compute the value of @xmath .

##### Connections with existing fast randomized gossip algorithms

In the randomized gossip literature there is one particular method
closely related to our approach. It was first proposed in [ 19 ] and its
analysis under strong conditions was presented in [ 106 ] . In this work
local memory is exploited by installing shift registers at each agent.
In particular we are interested in the case of two registers where the
first stores the agent’s current value and the second the agent’s value
before the latest update. The algorithm can be described as follows.
Suppose that edge @xmath is chosen at time @xmath . Then,

-   Node @xmath : @xmath

-   Node @xmath : @xmath

-   Any other node @xmath : @xmath

where @xmath . The method was analyzed in [ 106 ] under a strong
assumption on the probabilities of choosing the pair of nodes, that as
the authors mentioned, is unrealistic in practical scenarios, and for
networks like the random geometric graphs. At this point we should
highlight that the results presented in Chapter 2 hold for essentially
any distribution @xmath ⁵ ⁵ 5 The only restriction is the exactness
condition to be satisfied. See Theorem 8 . and as a result in the
proposed gossip variants with heavy ball momentum such problem cannot
occur.

Note that, in the special case that we choose @xmath in the update rule
of Algorithm 10 is simplified to:

-   Node @xmath : @xmath

-   Node @xmath : @xmath

-   Any other node @xmath : @xmath

Recall that in order to apply Theorem 8 , we need to assume that @xmath
and @xmath which also means that @xmath . Thus for @xmath and momentum
parameter @xmath it is easy to see that our approach is very similar to
the shift-register algorithm. Both methods update the selected pair of
nodes in the same way. However, in Algorithm 10 the not selected nodes
of the network do not remain idle but instead update their values using
their own previous information.

By defining the momentum matrix @xmath , the above closely related
algorithms can be expressed, in vector form, as:

  -- -------- -- --------
     @xmath      (4.31)
  -- -------- -- --------

In particular, in mRK every diagonal element of matrix @xmath is equal
to @xmath , while in the algorithm of [ 19 , 106 ] all the diagonal
elements are zeros except the two values that correspond to nodes @xmath
and @xmath that are equal to @xmath .

###### Remark 14.

The shift register algorithm of [ 106 ] and Algorithm 10 of this work
can be seen as the two limit cases of the update rule ( 4.31 ). As we
mentioned, the shift register method [ 106 ] uses only two non-zero
diagonal elements in @xmath , while our method has a full diagonal. We
believe that further methods can be developed in the future by exploring
the cases where more than two but not all elements of the diagonal
matrix @xmath are non-zero. It might be possible to obtain better
convergence if one carefully chooses these values based on the network
topology. We leave this as an open problem for future research.

##### Randomized block Kaczmarz gossip with heavy ball momentum

Recall that Theorem 34 explains how RBK (with no momentum and no
relaxation) can be interpreted as a gossip algorithm. In this subsection
by using this result we explain how relaxed RBK with momentum works.
Note that the update rule of RBK with momentum can be rewritten as
follows:

  -- -------- -- --------
     @xmath      (4.32)
  -- -------- -- --------

and recall that @xmath is the update rule of the standard RBK ( 4.23 ).

Thus, in analogy to the standard RBK, in the @xmath step, a random set
of edges is selected and @xmath connected components are formed as a
result. This includes the connected components that belong to both
sub-graph @xmath and also the singleton connected components (nodes
outside the @xmath ). Let us define the set of the nodes that belong in
the @xmath connected component at the @xmath step @xmath , such that
@xmath and @xmath for any @xmath .

Using the update rule ( 4.32 ), Algorithm 11 shows how mRBK is updating
the private values of the nodes of the network (see also Figure 4.3 for
the graphical interpretation).

1: Parameters: Distribution @xmath from which method samples matrices;
stepsize/relaxation parameter @xmath ; heavy ball/momentum parameter
@xmath .

2: Initialize: @xmath

3: for @xmath do

4: Select a random set of edges @xmath

5: Form subgraph @xmath of @xmath from the selected edges

6: Node values are updated as follows:

-    For each connected component @xmath of @xmath , replace the values
    of its nodes with:

      -- -------- -- --------
         @xmath      (4.33)
      -- -------- -- --------

-    Any other node @xmath : @xmath

7: end for

8: Output: The last iterate @xmath

Algorithm 11 mRBK: Randomized Block Kaczmarz Gossip with momentum

Note that in the update rule of mRBK the nodes that are not attached to
a selected edge (do not belong in the sub-graph @xmath ) update their
values via @xmath . By considering these nodes as singleton connected
components their update rule is exactly the same with the nodes of
sub-graph @xmath . This is easy to see as follows:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.34)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

###### Remark 15.

In the special case that only one edge is selected in each iteration (
@xmath ) the update rule of mRBK is simplified to the update rule of
mRK. In this case the sub-graph @xmath is the pair of the two selected
edges.

###### Remark 16.

In previous section we explained how several existing gossip protocols
for solving the average consensus problem are special cases of the RBK
(Theorem 34 ). For example two gossip algorithms that can be cast as
special cases of the standard RBK are the path averaging proposed in [ 8
] and the clique gossiping [ 110 ] . In path averaging, in each
iteration a path of nodes is selected and its nodes update their values
to their exact average ( @xmath ). In clique gossiping, the network is
already divided into cliques and through a random procedure a clique is
activated and the nodes of it update their values to their exact average
( @xmath ). Since mRBK contains the standard RBK as a special case (when
@xmath ), we expect that these special protocols can also be accelerated
with the addition of momentum parameter @xmath .

##### Mass preservation

One of the key properties of some of the most efficient randomized
gossip algorithms is mass preservation. That is, the sum (and as a
result the average) of the private values of the nodes remains fixed
during the iterative procedure ( @xmath ). The original pairwise gossip
algorithm proposed in [ 16 ] satisfied the mass preservation property,
while exisiting fast gossip algorithms [ 19 , 106 ] preserving a scaled
sum. In this subsection we show that mRK and mRBK gossip protocols
presented above satisfy the mass preservation property. In particular,
we prove mass preservation for the case of the block randomized gossip
protocol (Algorithm 11 ) with momentum. This is sufficient since the
randomized Kaczmarz gossip with momentum (mRK), Algorithm 10 can be cast
as special case.

###### Theorem 35.

Assume that @xmath . That is, the two registers of each node have the
same initial value. Then for the Algorithms 10 and 11 we have @xmath for
any @xmath and as a result, @xmath .

###### Proof.

We prove the result for the more general Algorithm 11 . Assume that in
the @xmath step of the method @xmath connected components are formed.
Let the set of the nodes of each connected component be @xmath so that
@xmath and @xmath for any @xmath . Thus:

  -- -------- -- --------
     @xmath      (4.35)
  -- -------- -- --------

Let us first focus, without loss of generality, on connected component
@xmath and simplify the expression for the sum of its nodes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.36)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

By substituting this for all @xmath into the right hand side of ( 4.35 )
and from the fact that @xmath , we obtain:

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath , we have @xmath , and as a result @xmath for all @xmath .
∎

#### 4.4.2 Provably accelerated randomized gossip algorithms

In this subsection we focus on one specific case of the Sketch and
Project framework, the RK method ( 4.2 ). We present two accelerated
variants of RK where the Nesterov’s momentum is used, for solving
consistent linear systems and we describe their theoretical convergence
results. Based on these methods we propose two provably accelerated
gossip protocols, along with some remarks on their implementation.

##### Accelerated Kaczmarz methods using Nesterov’s momentum

There are two different but very similar ways to provably accelerate the
randomized Kaczmarz method using Nesterov’s acceleration. The first
paper that proves asymptotic convergence with an accelerated linear rate
is [ 107 ] . The proof technique is similar to the framework developed
by Nesterov in [ 139 ] for the acceleration of coordinate descent
methods. In [ 192 , 72 ] a modified version for the selection of the
parameters was proposed and a non-asymptotic accelerated linear rate was
established. In Algorithm 12 , pseudocode of the Accelerated Kaczmarz
method (AccRK) is presented where both variants can be cast as special
cases, by choosing the parameters with the correct way.

1: Data: Matrix @xmath ; vector @xmath

2: Choose @xmath and set @xmath

3: Parameters: Evaluate the sequences of the scalars @xmath following
one of two possible options.

4: for @xmath do

5: @xmath

6: Draw a fresh sample @xmath with equal probability

7: @xmath

8: @xmath

9: end for

Algorithm 12 Accelerated Randomized Kaczmarz Method (AccRK)

There are two options for selecting the parameters of the AccRK for
solving consistent linear systems with normalized matrices, which we
describe next.

1.  From [ 107 ] : Choose @xmath and set @xmath . Generate the sequence
    @xmath by choosing @xmath to be the largest root of

      -- -------- --
         @xmath   
      -- -------- --

    and generate the sequences @xmath and @xmath by setting

      -- -------- --
         @xmath   
      -- -------- --

2.  From [ 72 ] : Let

      -- -------- -- --------
         @xmath      (4.37)
      -- -------- -- --------

    Choose the three sequences to be fixed constants as follows: @xmath
    , @xmath , @xmath where @xmath .

##### Theoretical guarantees of AccRK

The two variants (Option 1 and Option 2) of AccRK are closely related,
however their convergence analyses are different. Below we present the
theoretical guarantees of the two options as presented in [ 107 ] and [
72 ] .

###### Theorem 36 ([107]).

Let @xmath be the sequence of random iterates produced by Algorithm 12
with the Option 1 for the parameters. Let @xmath be normalized matrix
and let @xmath . Set @xmath and @xmath . Then for any @xmath we have
that:

  -- -------- --
     @xmath   
  -- -------- --

###### Corollary 37 ([107]).

Note that as @xmath , we have that @xmath . This means that the decrease
of the right hand side is governed mainly by the behavior of the term
@xmath in the denominator and as a result the method converge
asymptotically with a decrease factor per iteration: @xmath That is, as
@xmath :

  -- -------- --
     @xmath   
  -- -------- --

Thus, by choosing @xmath and for the case that @xmath is small,
Algorithm 12 will have significantly faster convergence rate than RK.
Note that the above convergence results hold only for normalized
matrices @xmath , that is matrices that have @xmath for any @xmath .

Using Corollary 37 , Algorithm 12 with the first choice of the
parameters converges linearly with rate @xmath . That is, it requires
@xmath iterations to obtain accuracy @xmath .

###### Theorem 38 ([72]).

Let @xmath and let assume exactness ⁶ ⁶ 6 Note that in this setting
@xmath , which means that @xmath , and the exactness assumption takes
the form @xmath . . Let @xmath be the iterates of Algorithm 12 with the
Option 2 for the parameters. Then

  -- -------- --
     @xmath   
  -- -------- --

where @xmath .

The above result implies that Algorithm 12 converges linearly with rate
@xmath , which translates to a total of @xmath iterations to bring the
quantity @xmath below @xmath . It can be shown that @xmath , (Lemma 2 in
[ 72 ] ) where @xmath is as defined in ( 4.37 ). Thus, @xmath which
means that the rate of AccRK (Option 2) is always better than that of
the RK with unit stepsize which is equal to @xmath (see Theorem 30 ).

In [ 72 ] , Theorem 38 has been proposed for solving more general
consistent linear systems (the matrix @xmath of the system is not
assumed to be normalized). In this case @xmath and the parameter @xmath
is slightly more complicated than the one of equation ( 4.37 ). We refer
the interested reader to [ 72 ] for more details.

###### Comparison of the convergence rates:

Before describe the distributed nature of the AccRK and explain how it
can be interpreted as a gossip algorithm, let us compare the convergence
rates of the two options of the parameters for the case of general
normalized consistent linear systems ( @xmath for any @xmath ).

Using Theorems 36 and 38 , it is clear that the iteration complexity of
AccRK is

  -- -------- -- --------
     @xmath      (4.38)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (4.39)
  -- -------- -- --------

for the Option 1 and Option 2 for the parameters, respectively.

In the following derivation we compare the iteration complexity of the
two methods.

###### Lemma 39.

Let matrices @xmath and @xmath where @xmath be positive semidefinite,
and satisfying @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

From the definition of the matrices it holds that @xmath for any @xmath
. Using the properties of Moore-Penrose pseudoinverse, this implies that

  -- -------- -- --------
     @xmath      (4.40)
  -- -------- -- --------

Therefore

  -- -------- -- --------
     @xmath      (4.41)
  -- -------- -- --------

From the definition of the matrices by taking the sum over all @xmath we
obtain:

  -- -------- --
     @xmath   
  -- -------- --

which completes the proof. ∎

Let us now choose @xmath and @xmath . Note that from their definition
the matrices are positive semidefinite and satisfy @xmath . Using Lemma
39 it is clear that:

  -- -------- --
     @xmath   
  -- -------- --

or in other words, for any vector @xmath we set the inequality

  -- -------- --
     @xmath   
  -- -------- --

Multiplying both sides by @xmath , we set:

  -- -------- --
     @xmath   
  -- -------- --

Using the above derivation, it is clear from the definition of the
parameter @xmath ( 4.37 ), that @xmath By combining our finding with the
bounds already obtained in [ 72 ] for the parameter @xmath , we have
that:

  -- -------- -- --------
     @xmath      (4.42)
  -- -------- -- --------

Thus, by comparing the two iteration complexities of equations ( 4.38 )
and ( 4.39 ) it is clear that Option 2 for the parameters [ 72 ] is
always faster in theory than Option 1 [ 107 ] . To the best of our
knowledge, such comparison of the two choices of the parameters for the
AccRK was never presented before.

##### Accelerated randomized gossip algorithms

Having presented the complexity analysis guarantees of AccRK for solving
consistent linear systems with normalized matrices, let us now explain
how the two options of AccRK behave as gossip algorithms when they are
used to solve the linear system @xmath where @xmath is the normalized
incidence matrix of the network. That is, each row @xmath of @xmath can
be represented as @xmath where @xmath (resp. @xmath ) is the @xmath
(resp. @xmath ) unit coordinate vector in @xmath .

By using this particular linear system, the expression @xmath that
appears in steps 7 and 8 of AccRK takes the following form when the row
@xmath is sampled:

  -- -------- --
     @xmath   
  -- -------- --

Recall that with @xmath we denote the Laplacian matrix of the network.
For solving the above AC system (see Definition 31 ), the standard RK
requires @xmath iterations to achieve expected accuracy @xmath . To
understand the acceleration in the gossip framework this should be
compared to the

  -- -------- --
     @xmath   
  -- -------- --

of AccRK (Option 1) and the

  -- -------- --
     @xmath   
  -- -------- --

of AccRK (Option 2).

Algorithm 13 describes in a single framework how the two variants of
AccRK of Section 4.4.2 behave as gossip algorithms when are used to
solve the above linear system. Note that each node @xmath of the network
has two local registers to save the quantities @xmath and @xmath . In
each step using these two values every node @xmath of the network
(activated or not) computes the quantity @xmath . Then in the @xmath
iteration the activated nodes @xmath and @xmath of the randomly selected
edge @xmath exchange their values @xmath and @xmath and update the
values of @xmath , @xmath and @xmath , @xmath as shown in Algorithm 13 .
The rest of the nodes use only their own @xmath to update the values of
@xmath and @xmath without communicate with any other node.

The parameter @xmath can be estimated by all nodes in a decentralized
manner using the method described in [ 24 ] . In order to implement this
algorithm, we assume that all nodes have synchronized clocks and that
they know the rate at which gossip updates are performed, so that
inactive nodes also update their local values. This may not be feasible
in all applications, but when it is possible (e.g., if nodes are
equipped with inexpensive GPS receivers, or have reliable clocks) then
they can benefit from the significant speedup achieved.

1: Data: Matrix @xmath (normalized incidence matrix); vector @xmath

2: Choose @xmath and set @xmath

3: Parameters: Evaluate the sequences of the scalars @xmath following
one of two possible options.

4: for @xmath do

5: Each node @xmath evaluate @xmath .

6: Pick an edge @xmath uniformly at random.

7: Then the nodes update their values as follows:

-   The selected node @xmath and node @xmath :

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

      -- -------- --
         @xmath   
      -- -------- --

-   Any other node @xmath :

      -- -------- --
         @xmath   
      -- -------- --

8: end for

Algorithm 13 Accelerated Randomized Gossip Algorithm (AccGossip)

### 4.5 Dual Randomized Gossip Algorithms

An important tool in optimization literature is duality. In our setting,
instead of solving the original minimization problem (primal problem)
one may try to develop dual in nature methods that have as a goal to
directly solve the dual maximization problem. Then the primal solution
can be recovered through the use of optimality conditions and the
development of an affine mapping between the two spaces (primal and
dual).

In this section, using existing dual methods and the connection already
established between the two areas of research (methods for linear
systems and gossip algorithms), we present a different viewpoint that
allows the development of novel dual randomized gossip algorithms.

Without loss of generality we focus on the case of @xmath (no weighted
average consensus). For simplicity, we formulate the AC system as the
one with the incidence matrix of the network ( @xmath ) and focus on
presenting the distributed nature of dual randomized gossip algorithms
with no momentum. While we focus only on no-momentum protocols, we note
that accelerated variants of the dual methods could be easily obtained
using tools from Section 4.4 .

#### 4.5.1 Dual problem and SDSA

As we have already presented in Section 1.4 , the Lagrangian dual of the
best approximation problem ( 1.22 ) is the (bounded) unconstrained
concave quadratic maximization problem:

  -- -------- -- --------
     @xmath      (4.43)
  -- -------- -- --------

A direct method for solving the dual problem is Stochastic Dual Subspace
Accent (SDSA), a randomized iterative algorithm first proposed in [ 74 ]
, which updates the dual vectors @xmath as follows:

  -- -- -- --------
           (4.44)
  -- -- -- --------

In Section 1.4 we showed that the iterates @xmath of the sketch and
project method (Algorithm 8 ) can be arised as affine images of the
iterates @xmath of the dual method ( 4.44 ) through the mapping:

  -- -------- -- --------
     @xmath      (4.45)
  -- -------- -- --------

and we provided a proof for the linear convergence of SDSA (see Theorem
6 ). Recall that SDSA and the sketch and project method (Algorithm 8 )
converge to a solution of the dual problem and primal problem,
respectively, with exactly the same convergence rate.

Let us choose @xmath . In the special case that the random matrix @xmath
is chosen randomly from the set of unit coordinate/basis vectors in
@xmath , the dual method ( 4.44 ) is the randomized coordinate descent [
104 , 166 ] , and the corresponding primal method is RK ( 4.2 ). More
generally, if @xmath is a random column submatrix of the @xmath identity
matrix, the dual method is the randomized Newton method [ 162 ] , and
the corresponding primal method is RBK ( 4.3 ). Next we shall describe
the more general block case in more detail.

#### 4.5.2 Randomized Newton method as a dual gossip algorithm

In this subsection we bring a new insight into the randomized gossip
framework by presenting how the dual iterative process that is
associated to RBK method solves the AC problem with @xmath (incidence
matrix). Recall that the right hand side of the linear system is @xmath
. For simplicity, we focus on the case of @xmath and @xmath .

Under this setting ( @xmath , @xmath and @xmath ) the dual iterative
process ( 4.44 ) takes the form:

  -- -------- -- --------
     @xmath      (4.46)
  -- -------- -- --------

and from Theorem 6 converges to a solution of the dual problem as
follows:

  -- -------- --
     @xmath   
  -- -------- --

Note that the convergence rate is exactly the same with the rate of the
RBK under the same assumptions (see ( 4.25 )).

This algorithm is a randomized variant of the Newton method applied to
the problem of maximizing the quadratic function @xmath defined in (
4.43 ). Indeed, in each iteration we perform the update @xmath , where
@xmath is chosen greedily so that @xmath is maximized. In doing so, we
invert a random principal submatrix of the Hessian of @xmath , whence
the name.

Randomized Newton Method (RNM) was first proposed by Qu et al. [ 162 ] .
RNM was first analyzed as an algorithm for minimizing smooth strongly
convex functions . In [ 74 ] it was also extended to the case of a
smooth but weakly convex quadratics . This method was not previously
associated with any gossip algorithm.

The most important distinction of RNM compared to existing gossip
algorithms is that it operates with values that are associated to the
edges of the network. To the best of our knowledge, it is the first
randomized dual gossip method . In particular, instead of iterating over
values stored at the nodes, RNM uses these values to update “dual
weights” @xmath that correspond to the edges @xmath of the network.
However, deterministic dual distributed averaging algorithms were
proposed before [ 164 , 64 ] . Edge-based methods have also been
proposed before; in particular in [ 195 ] an asynchronous distributed
ADMM algorithm presented for solving the more general consensus
optimization problem with convex functions.

Natural Interpretation. In iteration @xmath , RNM (Algorithm ( 4.46 ))
executes the following steps: 1) Select a random set of edges @xmath ,
2) Form a subgraph @xmath of @xmath from the selected edges, 3) The
values of the edges in each connected component of @xmath are updated:
their new values are a linear combination of the private values of the
nodes belonging to the connected component and of the adjacent edges of
their connected components. (see also example of Figure 4.4 ).

Dual Variables as Advice. The weights @xmath of the edges have a natural
interpretation as advice that each selected node receives from the
network in order to update its value (to one that will eventually
converge to the desired average).

Consider RNM performing the @xmath iteration and let @xmath denote the
set of nodes of the selected connected component that node @xmath
belongs to. Then, from Theorem 34 we know that @xmath . Hence, by using
( 4.45 ), we obtain the following identity:

  -- -------- -- --------
     @xmath      (4.47)
  -- -------- -- --------

Thus in each step @xmath represents the term (advice) that must be added
to the initial value @xmath of node @xmath in order to update its value
to the average of the values of the nodes of the connected component
@xmath belongs to.

Importance of the dual perspective: It was shown in [ 162 ] that when
RNM (and as a result, RBK, through the affine mapping ( 4.45 )) is
viewed as a family of methods indexed by the size @xmath (we choose
@xmath of fixed size in the experiments), then @xmath , where @xmath is
defined in ( 4.5 ), decreases superlinearly fast in @xmath . That is, as
@xmath increases by some factor, the iteration complexity drops by a
factor that is at least as large. Through preliminary numerical
experiments in Section 4.7.2 we experimentally show that this is true
for the case of AC systems as well.

### 4.6 Further Connections Between Methods for Solving Linear Systems
and Gossip Algorithms

In this section we highlight some further interesting connections
between linear systems solvers and gossip protocols for average
consensus:

-    Eavesdrop gossip as special case of Kaczmarz-Motzkin method. In [
    193 ] greedy gossip with eavesdropping (GGE), a novel randomized
    gossip algorithm for distributed computation of the average
    consensus problem was proposed and analyzed. In particular it was
    shown that that greedy updates of GGE lead to rapid convergence. In
    this protocol, the greedy updates are made possible by exploiting
    the broadcast nature of wireless communications. During the
    operation of GGE, when a node decides to gossip, instead of choosing
    one of its neighbors at random, it makes a greedy selection,
    choosing the node which has the value most different from its own.
    In particular the method behaves as follows:

    At the @xmath iteration of GGE, a node @xmath is chosen uniformly at
    random from @xmath . Then, @xmath identifies a neighboring node
    @xmath satisfying:

      -- -------- --
         @xmath   
      -- -------- --

    which means that the selected node @xmath identifies a neighbor that
    currently has the most different value from its own. This choice is
    possible because each node @xmath maintains not only its own local
    variable @xmath , but also a copy of the current values at its
    neighbors @xmath for @xmath . In the case that node @xmath has
    multiple neighbors whose values are all equally (and maximally)
    different from its current value, it chooses one of these neighbors
    at random. Then node @xmath and @xmath update their values to:

      -- -------- --
         @xmath   
      -- -------- --

    In the area of randomized methods for solving large linear system
    there is one particular method, the Kaczmarz-Motzkin algorithm [ 32
    , 78 ] that can work as gossip algorithm with the same update as the
    GGE when is use to solve the homogeneous linear system with matrix
    the Incidence matrix of the network.

    Update rule of Kaczmarz-Motzkin algorithm (KMA) [ 32 , 78 ] :

    1.  Choose sample of @xmath constraints, @xmath , uniformly at
        random from among the rows of matrix @xmath .

    2.  From among these @xmath constraints, choose @xmath

    3.  Update the value: @xmath

    It is easy to verify that when the Kaczmarz-Motzkin algorithm is
    used for solving the AC system with @xmath (incidence matrix) and in
    each step of the method the chosen constraints @xmath of the linear
    system correspond to edges attached to one node it behaves exactly
    like the GGE. From numerical analysis viewpoint an easy way to
    choose the constraints @xmath that are compatible to the desired
    edges is in each iteration to find the indexes of the non-zeros of a
    uniformly at random selected column (node) and then select the rows
    corresponding to these indexes.

    Therefore, since GGE [ 193 ] is a special case of the KMA (when the
    later applied to special AC system with Incidence matrix) it means
    that we can obtain the convergence rate of GGE by simply use the
    tight conergence analysis presented in [ 32 , 78 ] ⁷ ⁷ 7 Note that
    the convergence theorems of [ 32 , 78 ] use @xmath . However, with a
    small modification in the original proof the theorem can capture the
    case of different @xmath . . In [ 193 ] it was mentioned that
    analyzing the convergence behavior of GGE is non-trivial and not an
    easy task. By establishing the above connection the convergence
    rates of GGE can be easily obtained as special case of the theorems
    presented in [ 32 ] .

    In Section 4.4 we presented provably accelerated variants of the
    pairwise gossip algorithm and of its block variant. Following the
    same approach one can easily develop accelerated variants of the GGE
    using the recently proposed analysis for the accelerated
    Kaczmarz-Motzkin algorithm presented in [ 126 ] .

-    Inexact Sketch and Project Methods:

    In Chapter 3 , several inexact variants of the sketch and project
    method ( 8 ) have been proposed. As we have already mentioned the
    sketch and project method is a two step procedure algorithm where
    first the sketched system is formulated and then the last iterate
    @xmath is exactly projected into the solution set of the sketched
    system. In Chapter 3 , we replace the exact projection with an
    inexact variant and we suggest to run a different algorithm (this
    can be the sketch and project method itself) in the sketched system
    to obtain an approximate solution. It was shown that in terms of
    time the inexact updates can be faster than their exact variants.

    In the setting of randomized gossip algorithms for the AC system
    with Incidence matrix ( @xmath ) , @xmath and @xmath a variant of
    the inexact sketch and project method will work as follows (similar
    to the update proved in Theorem 34 ):

    1.  Select a random set of edges @xmath .

    2.  Form subgraph @xmath of @xmath from the selected edges.

    3.  Run the pairwise gossip algorithm of [ 16 ] (or any variant of
        the sketch and project method) on the subgraph @xmath until an
        accuracy @xmath is achieved (reach a neighborhood of the exact
        average).

-    Non-randomized gossip algorithms as special cases of Kaczmarz
    methods:

    In the gossip algorithms literature there are efficient protocols
    that are not randomized [ 127 , 82 , 108 , 208 ] . Typically, in
    these algorithms the pairwise exchanges between nodes it happens in
    a deterministic, such as predefined cyclic, order. For example,
    @xmath -periodic gossiping is a protocol which stipulates that each
    node must interact with each of its neighbours exactly once every
    @xmath time units. It was shown that under suitable connectivity
    assumptions of the network @xmath , the @xmath -periodic gossip
    sequence will converge at a rate determined by the magnitude of the
    second largest eigenvalue of the stochastic matrix determined by the
    sequence of pairwise exchanges which occurs over a period. It has
    been shown that if the underlying graph is a tree, the mentioned
    eigenvalue is constant for all possible @xmath -periodic gossip
    protocols.

    In this work we focus only on randomized gossip protocols. However
    we speculate that the above non-randomized gossip algorithms would
    be able to express as special cases of popular non-randomized
    projection methods for solving linear systems [ 159 , 144 , 45 ] .
    Establishing connections like that is an interesting future
    direction of research and can possibly lead to the development of
    novel block and accelerated variants of many non-randomized gossip
    algorithms, similar to the protocols we present in Sections 4.3 and
    4.4 .

### 4.7 Numerical Evaluation

In this section, we empirically validate our theoretical results and
evaluate the performance of the proposed randomized gossip algorithms.
The section is divided into four main parts, in each of which we
highlight a different aspect of our contributions.

In the first experiment, we numerically verify the linear convergence of
the Scaled RK algorithm (see equation ( 4.9 )) for solving the weighted
average consensus problem presented in Section 4.3.1 . In the second
part, we explain the benefit of using block variants in the gossip
protocols where more than two nodes update their values in each
iteration (protocols presented in Section 4.3.4 ). In the third part, we
explore the performance of the faster and provably accelerated gossip
algorithms proposed in Section 4.4 . In the last experiment, we
numerically show that relaxed variants of the pairwise randomized gossip
algorithm converge faster than the standard randomized pairwise gossip
with unit stepsize (no relaxation). This gives a specific setting where
the phenomenon of over-relaxation of iterative methods for solving
linear systems is beneficial.

In the comparison of all gossip algorithms we use the relative error
measure @xmath where @xmath is the starting vector of the values of the
nodes and matrix @xmath is the positive definite diagonal matrix with
weights in its diagonal (recall that in the case of standard average
consensus this can be simply @xmath ). Depending on the experiment, we
choose the values of the starting vector @xmath to follow either a
Gaussian distribution or uniform distribution or to be integer values
such that @xmath . In the plots, the horizontal axis represents the
number of iterations except in the figures of subsection 4.7.2 , where
the horizontal axis represents the block size.

In our implementations we use three popular graph topologies from the
area of wireless sensor networks. These are the cycle (ring graph), the
2-dimension grid and the random geometric graph (RGG) with radius @xmath
. In all experiments we formulate the average consensus problem (or its
weighted variant) using the incidence matrix. That is, @xmath is used as
the AC system. Code was written in Julia 0.6.3.

#### 4.7.1 Convergence on weighted average consensus

As we explained in Section 4.3 , the sketch and project method
(Algorithm 8 ) can solve the more general weighted AC problem. In this
first experiment we numerically verify the linear convergence of the
Scaled RK algorithm ( 4.9 ) for solving this problem in the case of
@xmath . That is, the matrix @xmath of the weights is the degree matrix
@xmath of the graph ( @xmath , @xmath ). In this setting the exact
update rule of the method is given in equation ( 4.12 ), where in order
to have convergence to the weighted average the chosen nodes are
required to share not only their private values but also their weight
@xmath (in our experiment this is equal to the degree of the node @xmath
). In this experiment the starting vector of values @xmath is a Gaussian
vector. The linear convergence of the algorithm is clear in Figure 4.5 .

#### 4.7.2 Benefit of block variants

We devote this experiment to evaluate the performance of the randomized
block gossip algorithms presented in Sections 4.3.4 and 4.5 . In
particular, we would like to highlight the benefit of using larger block
size in the update rule of randomized Kaczmarz method and as a result
through our established connection of the randomized pairwise gossip
algorithm [ 16 ] (see equation ( 4.13 )).

Recall that in Section 4.5 we show that both RBK and RNM converge to the
solution of the primal and dual problems respectively with the same rate
and that their iterates are related via a simple affine transform ( 4.45
). In addition note that an interesting feature of the RNM [ 162 ] , is
that when the method viewed as algorithm indexed by the size @xmath , it
enjoys superlinear speedup in @xmath . That is, as @xmath (block size)
increases by some factor, the iteration complexity drops by a factor
that is at least as large (see Section 4.5.2 ). Since RBK and RNM share
the same rates this property naturally holds for RBK as well.

We show that for a connected network @xmath , the complexity improves
superlinearly in @xmath , where @xmath is chosen as a subset of @xmath
of size @xmath , uniformly at random (recall the in the update rule of
RBK the random matrix is @xmath ). Similar to the rest of this section
in comparing the number of iterations for different values of @xmath ,
we use the relative error @xmath . We let @xmath for each node @xmath
(vector of integers). We run RBK until the relative error becomes
smaller than @xmath . The blue solid line in the figures denotes the
actual number of iterations (after running the code) needed in order to
achieve @xmath for different values of @xmath . The green dotted line
represents the function @xmath , where @xmath is the number of
iterations of RBK with @xmath (i.e., the pairwise gossip algorithm). The
green line depicts linear speedup; the fact that the blue line (obtained
through experiments) is below the green line points to superlinear
speedup. In this experiment we use the Cycle graph with @xmath and
@xmath nodes (Figure 4.6 ) and the @xmath two dimension grid graph
(Figure 4.7 ). Note that, when @xmath the convergence rate of the method
becomes @xmath and as a result it converges in one step.

#### 4.7.3 Accelerated gossip algorithms

We devote this subsection to experimentally evaluate the performance of
the proposed accelerated gossip algorithms: mRK (Algorithm 10 ), mRBK
(Algorithm 11 ) and AccGossip with the two options of the parameters
(Algorithm 13 ). In particular we perform four experiments. In the first
two we focus on the performance of the mRK and how the choice of
stepsize (relaxation parameter) @xmath and heavy ball momentum parameter
@xmath affect the performance of the method. In the next experiment we
show that the addition of heavy ball momentum can be also beneficial for
the performance of the block variant mRBK. In the last experiment we
compare the standard pairwise gossip algorithm (baseline method) from [
16 ] , the mRK and the AccGossip and show that the probably accelerated
gossip algorithm, AccGossip outperforms the other algorithms and
converge as predicted from the theory with an accelerated linear rate.

##### Impact of momentum parameter on mRK

As we have already presented in the standard pairwise gossip algorithm
(equation ( 4.13 )) the two selected nodes that exchange information
update their values to their exact average while all the other nodes
remain idle. In our framework this update can be cast as special case of
mRK when @xmath and @xmath .

In this experiment we keep the stepsize fixed and equal to @xmath which
means that the pair of the chosen nodes update their values to their
exact average and we show that by choosing a suitable momentum parameter
@xmath we can obtain faster convergence to the consensus for all
networks under study. The momentum parameter @xmath is chosen following
the suggestions made in Chapter 2 for solving general consistent linear
systems. See Figure 4.8 for more details. It is worth to point out that
for all networks under study the addition of a heavy ball momentum term
is beneficial in the performance of the method.

##### Comparison of mRK and shift-Register algorithm [106]

In this experiment we compare mRK with the shift register gossip
algorithm (pairwise momentum method, abbreviation: Pmom) analyzed in [
106 ] . We choose the parameters @xmath and @xmath of mRK in such a way
in order to satisfy the connection established in Section 4.4.1 . That
is, we choose @xmath for any choice of @xmath . Observe that in all
plots of Figure 4.9 mRK outperforms the corresponding shift-register
algorithm.

##### Impact of momentum parameter on mRBK

In this experiment our goal is to show that the addition of heavy ball
momentum accelerates the RBK gossip algorithm presented in Section 4.3.4
. Without loss of generality we choose the block size to be equal to
@xmath . That is, the random matrix @xmath in the update rule of mRBK is
a @xmath column submatrix of the indetity @xmath matrix. Thus, in each
iteration @xmath edges of the network are chosen to form the subgraph
@xmath and the values of the nodes are updated according to Algorithm 11
. Note that similar plots can be obtained for any choice of block size.
We run all algorithms with fixed stepsize @xmath . From Figure 4.10 , it
is obvious that for all networks under study, choosing a suitable
momentum parameter @xmath gives faster convergence than having no
momentum, @xmath .

##### Performance of AccGossip

In the last experiment on faster gossip algorithms we evaluate the
performance of the proposed provably accelerated gossip protocols of
Section 4.4.2 . In particular we compare the standard RK (pairwise
gossip algorithm of [ 16 ] ) the mRK (Algorithm 10 ) and the AccGossip
(Algorithm 13 ) with the two options for the selection of the parameters
presented in Section 4.4.2 .

The starting vector of values @xmath is taken to be a Gaussian vector.
For the implementation of mRK we use the same parameters with the ones
suggested in the stochastic heavy ball (SGB) setting in Chapter 2 . For
the AccRK (Option 1) we use @xmath and for AccRK (Option 2) we select
@xmath ⁸ ⁸ 8 For the networks under study we have @xmath . Thus, by
choosing @xmath we select the pessimistic upper bound of the parameter (
4.42 ) and not its exact value ( 4.37 ). As we can see from the
experiments, the performance is still accelerated and almost identical
to the performance of AccRK (Option 1) for this choice of @xmath . .
From Figure 4.11 it is clear that for all networks under study the two
randomized gossip protocols with Nesterov momentum are faster than both
the pairwise gossip algorithm of [ 16 ] and the mRK/SHB (Algorithm 10 ).
To the best of our knowledge Algorithm 13 (Option 1 and Option 2) is the
first randomized gossip protocol that converges with provably
accelerated linear rate and as we can see from our experiment its faster
convergence is also obvious in practice.

#### 4.7.4 Relaxed randomized gossip without momentum

In the area of randomized iterative methods for linear systems it is
know that over-relaxation (using of larger step-sizes) can be
particularly helpful in practical scenarios. However, to the best of our
knowledge there is not theoretical justification of why this is
happening.

In our last experiment we explore the performance of relaxed randomized
gossip algorithms ( @xmath ) without momentum and show that in this
setting having larger stepsize can be particularly beneficial.

As we mentioned before (see Theorem 30 ) the sketch and project method
(Algorithm 8 ) converges with linear rate when the step-size (relaxation
parameter) of the method is @xmath and the best theoretical rate is
achieved when @xmath . In this experiment we explore the performance of
the standard pairwise gossip algorithm when the step-size of the update
rule is chosen in @xmath . Since there is no theoretical proof of why
over-relaxation can be helpful we perform the experiments using
different starting values of the nodes. In particular we choose the
values of vector @xmath to follow (i) Gaussian distribution, (ii)
Uniform Distribution and (iii) to be integers values such that @xmath .
Our findings are presented in Figure 4.12 . Note that for all networks
under study and for all choices of starting values having larger
stepsize, @xmath can lead to better performance. Interesting observation
from Figure 4.12 is that the stepsizes @xmath and @xmath give the best
performance (among the selected choices of stepsizes) for all networks
and for all choices of starting vector @xmath .

### 4.8 Conclusion

In this chapter, we present a general framework for the analysis and
design of randomized gossip algorithms. Using tools from numerical
linear algebra and the area of randomized projection methods for solving
linear systems we propose novel serial, block and accelerated gossip
protocols for solving the average consensus and weighted average
consensus problems.

We believe that this work could open up several future avenues for
research. Using similar approach with the one presented in this
manuscript, many popular projection methods can be interpreted as gossip
algorithms when used to solve linear systems encoding the underlying
network. This can lead to the development of novel distributed protocols
for average consensus.

In addition, we speculate that the gossip protocols presented in this
work can be extended to the more general setting of multi-agent
consensus optimization where the goal is to minimize the average of
convex or non-convex functions @xmath in a decentralized way [ 131 ] .

### 4.9 Missing Proofs

#### 4.9.1 Proof of Theorem 33

###### Proof.

Let @xmath , @xmath is the starting point and @xmath is as defined in (
4.5 ). From Theorem 30 we know that sketch and project method converges
with

  -- -------- -- --------
     @xmath      (4.48)
  -- -------- -- --------

where @xmath is the solution of ( 1.22 ). Inequality ( 4.48 ), together
with Markov inequality can be used to give the following bound

  -- -------- -- --------
     @xmath      (4.49)
  -- -------- -- --------

Therefore, as long as @xmath is large enough so that @xmath , we have
@xmath . That is, if

  -- -------- --
     @xmath   
  -- -------- --

then:

  -- -------- --
     @xmath   
  -- -------- --

Hence, an upper bound for value @xmath can be obtained as follows,

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.50)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

where in last inequality we use @xmath which is true because @xmath . ∎

#### 4.9.2 Proof of Theorem 34

###### Proof.

The following notation conventions are used in this proof. With @xmath
we indicate the number of connected components of subgraph @xmath ,
while with @xmath we denote the set of nodes of each connected component
@xmath @xmath . Finally, @xmath shows the cardinality of set @xmath .
Notice that, if @xmath is the set of all nodes of the graph then @xmath
and @xmath .

Note that from equation ( 4.24 ), the update of RBK for @xmath
(Incidence matrix) can be expressed as follows:

  -- -- -------- -- -------- -------- --------
        @xmath      @xmath            (4.51)
                             @xmath   
  -- -- -------- -- -------- -------- --------

Notice that @xmath is a row submatrix of matrix @xmath with rows those
that correspond to the random set @xmath of the edges. From the
expression of matrix @xmath we have that

  -- -------- --
     @xmath   
  -- -------- --

Now, using this, it can be seen that the constraint @xmath of problem (
1.22 ) is equivalent to @xmath equations (number of connected
components) where each one of them forces the values @xmath of the nodes
@xmath to be equal. That is, if we use @xmath to represent the value of
all nodes that belong in the connected component @xmath then:

  -- -------- -- --------
     @xmath      (4.52)
  -- -------- -- --------

and the constrained optimization problem ( 1.22 ) can expressed as
unconstrained as follows:

  -- -------- -- --------
     @xmath      (4.53)
  -- -------- -- --------

where @xmath is the vector of all values @xmath when @xmath . Since our
problem is unconstrained the minimum of equation ( 4.53 ) is obtained
when @xmath .

By evaluating partial derivatives of ( 4.53 ) we obtain:

  -- -------- --
     @xmath   
  -- -------- --

As a result,

  -- -------- --
     @xmath   
  -- -------- --

Thus from ( 4.52 ), the value of each node @xmath will be updated to

  -- -------- --
     @xmath   
  -- -------- --

. ∎

## Chapter 5 Privacy Preserving Randomized Gossip Algorithms

### 5.1 Introduction

In this chapter, similar to Chapter 4 , we consider the average
consensus (AC) problem. In particular, we focus on randomized gossip
algorithms for solving the AC problem and propose techniques for
protecting the information of the initial values @xmath , as these may
be sensitive. We develop and analyze three privacy preserving variants
of the randomized pairwise gossip algorithm (“randomly pick an edge
@xmath and then replace the values stored at vertices @xmath and @xmath
by their average”) first proposed in [ 16 ] for solving the average
consensus problem. While we shall not formalize the notion of privacy
preservation in this work, it will be intuitively clear that our methods
indeed make it harder for nodes to infer information about the private
values of other nodes, which might be useful in practice.

#### 5.1.1 Background

The literature on decentralized protocols for solving the average
consensus problem is vast and has long history [ 191 , 190 , 10 , 93 ] .
In particular, the algorithms for solving this problem can be divided
into two broad categories: the average consensus algorithms [ 201 ]
which work in a synchronous setting and the gossip algorithms [ 16 , 176
] which they consider ideal protocols for the asynchronous time model [
16 ] . In the average consensus algorithms, all nodes of the network
update their values simultaneously by communicating with a set of their
neighbours and in each iteration of the algorithmic procedure the same
update occurs. On the other hand, in gossip protocols only one edge of
the whole network is selected at each iteration and only the nodes, that
this edge connects, exchange their private information and update their
values to their average.

In this chapter, we focus on modifying the basic algorithm of [ 16 ] ,
which we refer to as “Standard Gossip” algorithm. In the following, we
review some of the most important gossip protocols for solving the
average consensus proposed in the last decade. While we do not address
any privacy considerations for these protocols, they can serve as
inspiration for further work. For a survey of relevant work, we refer
the interested reader to [ 42 , 147 , 165 , 131 ] .

The Geographic Gossip algorithm was proposed in [ 43 ] , in which the
authors combine the gossip approach with a geographic routing towards a
randomly chosen location with the main goal to improve the convergence
rate of Standard Gossip algorithm. In each step, a node is activated,
assuming that it is aware of its geographic location and some additional
assumptions on the network topology, it chooses another node from the
rest of the network (not necessarily one of its neighbours) and performs
a pairwise averaging with this node. Later, using the same assumptions,
this algorithm was extended into Geographic Gossip Algorithm with Path
Averaging [ 8 ] , in which connected sequences of nodes were chosen in
each step and they averaged their values. More recently, in [ 57 ] and [
58 ] authors propose a geographic and path averaging methods which
converge to the average consensus without the assumption that nodes are
aware of their geographic location. Recall that, in Section 4.3.4 we
show how the path averaging gossip algorithm can be seen as special case
of the Randomized Block Kaczmarz method for solving consistent linear
systems.

Another important randomized gossip algorithm is the Broadcast Gossip
algorithm , first proposed in [ 7 ] and then extended in [ 55 , 200 , 90
] . The idea of this algorithm is simple: In each step, a node in the
network is activated uniformly at random, following the asynchronous
time model, and broadcasts its value to its neighbours. The neighbours
receive this value and update their own values. It was experimentally
shown that this method converges faster than the pairwise and geographic
randomized gossip algorithms.

Alternative gossip protocols are the so-called non-randomized Gossip
algorithms [ 127 , 82 , 108 , 208 ] . Typically, this class of
algorithms executes the pairwise exchanges between nodes in a
deterministic, such as predefined cyclic, order. @xmath -periodic
gossiping is a protocol which stipulates that each node must interact
with each of its neighbours exactly once every @xmath time units. Under
suitable connectivity assumptions of the network @xmath , the @xmath
-periodic gossip sequence will converge at a rate determined by the
magnitude of the second largest eigenvalue of the stochastic matrix
determined by the sequence of pairwise exchanges which occurs over a
period. It has been shown that if the underlying graph is a tree, the
mentioned eigenvalue is constant for all possible @xmath -periodic
gossip protocols.

Accelerated Gossip algorithms have also been proposed for solving the
average consensus problem. In this setting, the nodes of the network
incorporate additional memory to accelerate convergence. In particular,
the nodes update their value using an update rule that involves not only
the current values of the sampled nodes but also their previous values.
This idea is closely related to the shift register methods studied in
numerical linear algebra for improving the convergence rate of linear
system solvers. The works [ 19 , 106 ] have shown theoretically and
numerically, that under specific assumptions this idea can improve the
performance of the Standard Gossip algorithm. For more details on these
gossip protocols check also Section 4.4.1 of this thesis.

Randomized Kaczmarz-type Gossip algorithms. In Chapter 4 of this thesis
we presented how popular randomized Kaczmarz-type methods for solving
large linear systems can also solve the AC problem. We explained how
these methods can be interpreted as randomized gossip algorithms when
applied to special systems encoding the underlying network structure and
present in detail their decentralized nature.

###### Asynchronous Time Model:

In this chapter, we are interested in the asynchronous time model [ 16 ,
10 ] . More precisely, we assume that each node of our network has a
clock which ticks at a rate of @xmath Poisson process. This is
equivalent of having available a global clock which ticks according to a
rate @xmath Poisson process and selects an edge of the network uniformly
at random. In general, the synchronous setting (all nodes update the
values of their nodes simultaneously using information from a set of
their neighbours) is convenient for theoretical considerations but is
not representative of some practical scenarios, such as the distributed
nature of sensor networks. For more details on clock modeling we refer
the reader to [ 16 ] , as the contribution of this chapter is orthogonal
to these considerations.

###### Privacy and Average Consensus:

Finally, the introduction of notions of privacy within the AC problem is
relatively recent in the literature, and the existing works consider two
different ideas.

1.  In [ 86 ] , the concept of differential privacy [ 47 ] is used to
    protect the output value @xmath computed by all nodes. In this work,
    an exponentially decaying Laplacian noise is added to the consensus
    computation. This notion of privacy refers to protection of the
    final average , and formal guarantees are provided.

2.  A different approach with a more stricter goal is the design of
    privacy-preserving average consensus protocols that guarantee
    protection of the initial values @xmath of the nodes [ 142 , 123 ,
    124 ] . In this setting each node should be unable to infer a lot
    about the initial values @xmath of any other node. In the existing
    works, this is mainly achieved with the clever addition of noise
    through the iterative procedure that guarantees preservation of
    privacy and at the same time converges to the exact average. We
    shall however mention, that none of these works address any specific
    notion of privacy (no clear measure of privacy is presented) and it
    is still not clear how the formal concept of differential privacy [
    47 ] can be applied in this setting.

It is worth to highlight that all of the above-mentioned privacy
preserving average consensus papers propose protocols which work on the
synchronous setting (all nodes update their values simultaneously). To
the best of our knowledge our proposed protocols are the first that
solve the AC problem and at the same time protect the initial values of
the nodes using the asynchronous time model (by having gossip updates).

#### 5.1.2 Main contributions

In this chapter, we present three different approaches for solving the
Average Consensus problem while at the same time protecting the
information about the initial values. To the best of our knowledge, this
work is the first which combines the gossip framework with the privacy
concept of protection of the initial values. It is important to stress
that, we provide tools for protection of the initial values, but we do
not address any specific notion of privacy or a threat model, nor how
these quantitatively translate to any explicit measure. These would be
highly application dependent, and we only provide theoretical
convergence rates for the techniques we propose.

The methods we propose are all dual in nature. The dual setting of this
chapter will be explained in detail in Section 5.2 . Recall that in
Chapters 1 , 2 and 3 of this thesis, we have shown how duality and dual
algorithms can be used for solving consistent linear systems. In
addition, in Chapter 4 , the dual viewpoint was extended to the concept
of the average consensus problem and the first dual gossip algorithms
were presented. As we have seen, the dual updates correspond to updates
of the primal variables, via an affine mapping. Using this relationship
of the primal and the dual spaces the convergence analysis of the dual
methods can be easily obtained once the analysis of the primal methods
is available (see for example the proof of Theorem 6 in the introduction
of this thesis). In this chapter, one of our contributions is a novel
dual analysis of randomized pairwise gossip (without the use of rates
that obtain first through a primal analysis) which exactly recovers
existing convergence rates for the primal iterates.

We now outline the three different techniques we propose in this
chapter, which we refer to as “Binary Oracle”, “ @xmath -Gap Oracle” and
“Controlled Noise Insertion”. The first two are, to best of our
knowledge, the first proposals of weakening the oracle used in the
gossip framework. Privacy preservation is attained implicitly, as the
nodes do not exchange the full information about their values. The last
technique is inspired by the addition of noise proposed in [ 101 , 142 ,
123 , 124 ] for the synchronous setting. We extend this technique by
providing explicit finite time convergence guarantees.

Binary Oracle. We propose to reduce the amount of information
transmitted in each iteration to a single bit ¹ ¹ 1 We do not refer to
the size of the object being transmitted over the network, but the
binary information that can be inferred from the exchange. In practice,
this might be achieved using secure multiparty protocols [ 26 ] ,
causing the overall network bandwidth to slightly increase compared to
the usual implementation of standard gossip algorithm. . More precisely,
when an edge is selected, each corresponding node will only receive
information whether the value on the other node is smaller or larger.
Instead of setting the value on the selected nodes to their average,
each node increases or decreases its value by a pre-specified step.

@xmath -Gap Oracle. In this case, we have an oracle that returns one of
three options and is parametrized by @xmath . If the difference in
values of sampled nodes is larger than @xmath , an update similar to the
one in Binary Oracle is taken. Otherwise, the values remain unchanged.
An advantage compared to the Binary Oracle is that this approach will
converge to a certain accuracy and stop there, determined by @xmath
(Binary Oracle will oscillate around optimum for a fixed stepsize).
However, in general, it will disclose more information about the initial
values.

Controlled Noise Insertion. This approach is inspired by the works of [
123 , 124 ] , and protects the initial values by inserting noise in the
process. Broadly speaking, in each iteration, each of the sampled nodes
first adds a noise to its current value, and an average is computed
afterward. Convergence is guaranteed due to the correlation in the noise
across iterations. Each node remembers the noise it added last time it
was sampled, and in the following iteration, the previously added noise
is first subtracted, and a fresh noise of smaller magnitude is added.
Empirically, the protection of initial values is provided by first
injecting noise into the system, which propagates across the network,
but is gradually withdrawn to ensure convergence to the true average.

###### Convergence Rates of our Methods:

In Table 5.1 , we present the summary of convergence guarantees for the
above three techniques. By @xmath we denote the standard Euclidean norm.

The two approaches which restrict the amount of information disclosed,
Binary Oracle and @xmath -Gap Oracle, converge slower than the standard
Gossip. In particular, these algorithms have sublinear convergence rate.
At first sight, this should not be surprising, since we indeed use much
less information. However, in Theorem 45 , we show that if we had in a
certain sense perfect global information, we could use it to construct a
sequence of adaptive stepsizes, which would push the capability of the
binary oracle to a linear convergence rate. However, this rate is still
@xmath -times slower than the standard rate of the binary gossip
algorithm. We note, however, that having the global information at hand
is an impractical assumption. Nevertheless, this result highlights that
there is a potentially large scope for improvement, which we leave for
future work.

The approach of Controlled Noise Insertion yields a linear convergence
rate which is driven by the minimum of two factors. Without going into
details, which of these is bigger depends on the speed by which the
magnitude of the inserted noise decays. If the noise decays fast enough,
we recover the convergence rate of the standard the gossip algorithm. In
the case of slow decay, the convergence is driven by this decay. By
@xmath we denote the algebraic connectivity of graph @xmath [ 52 ] . The
parameter @xmath controls the decay speed of the inserted noise, see
Corollary 50 .

Measures of Success: Note that the convergence of each randomized gossip
algorithm in Table 5.1 naturally depends on a different measure of
suboptimality. All of them converge to @xmath as we approach the optimal
solution. The details of these measures will be described later in the
main body of this chapter. In particular a lemma that formally describes
the key connections between these measures is presented in Section 5.3.1
. For now lets us give a brief description of these results. The
standard Gossip and Controlled Noise Insertion essentially depend on the
same quantity, but we present the latter in terms of dual values as this
is what our proofs are based on. Lemma 43 formally specifies this
equivalence. The binary oracle depends on the average difference among
directly connected nodes. The measure for the @xmath -Gap Oracle depends
on quantities @xmath , which is the number of edges that the values of
their connecting nodes differ by more than @xmath .

#### 5.1.3 Structure of the chapter

The remainder of this chapter is organized as follows: Section 5.2
introduces the basic setup that is used through the chapter. A detailed
explanation of the duality behind the randomized pairwise gossip
algorithm is given. We also include a novel and insightful dual analysis
of this method as it will make it easier for the reader to parse later
development. In Section 5.3 we present our three private gossip
algorithms as well as the associated iteration complexity results.
Section 5.4 is devoted to the numerical evaluation of our methods.
Finally, conclusions are drawn in Section 5.5 .

### 5.2 Dual Analysis of Randomized Pairwise Gossip

As we outlined in the introduction of this chapter, our approach for
extending the (standard) randomized pairwise gossip algorithm to privacy
preserving variants utilizes duality. The purpose of this section is to
formalize this duality. In addition, we provide a novel and
self-contained dual analysis of randomized pairwise gossip. While this
is of an independent interest, we include the proofs as their
understanding aids in the understanding of the more involved proofs of
our private gossip algorithms developed in the remainder of the chapter.

The main problems under study are the best approximation problem ( 1.22
) and its dual ( 1.26 ) that we have seen multiple times throughout the
thesis. However, similar to Chapter 4 we focus on the more specific
setting of the average consensus. To keep the chapter self-contained and
for the benefit of the reader we present the definitions of these
problems and we explain again how they are related to the average
consensus problem.

#### 5.2.1 Primal and dual problems

Consider solving the (primal) problem of projecting a given vector
@xmath onto the solution space of a linear system:

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

where @xmath , @xmath , @xmath . Note that this the best approximation
problem ( 1.22 ) with @xmath (Identity matrix). We assume the problem is
feasible, i.e., that the system @xmath is consistent. With the above
optimization problem we associate the dual problem

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

As we have explained in the previous chapters, the dual is an
unconstrained concave (but not necessarily strongly concave) quadratic
maximization problem. It can be seen that as soon as the system @xmath
is feasible, the dual problem is bounded. Moreover, all bounded concave
quadratics in @xmath can be written in the as @xmath for some matrix
@xmath and vectors @xmath and @xmath (up to an additive constant).

With any dual vector @xmath we associate the primal vector via an affine
transformation: @xmath It can be shown that if @xmath is dual optimal,
then @xmath is primal optimal [ 74 ] . Hence, any dual algorithm
producing a sequence of dual variables @xmath gives rise to a
corresponding primal algorithm producing the sequence @xmath . We shall
now consider one such dual algorithm.

#### 5.2.2 Stochastic dual subspace ascent

Stochastic dual subspace ascent (SDSA) is a stochastic method for
solving the dual problem ( 5.2 ). In Section 1.4 we have already
described how by choosing appropriately the main parameters of SDSA we
can recover many known algorithms as special cases. In this chapter we
focus only on one special case of the general algorithm. For the more
general update rule of SDSA check equations ( 1.29 ) and ( 1.30 ). In
particular, following the notation of the rest of the thesis, we select
@xmath (stepsize of the method) and @xmath (positive definite matrix
that defines the geometry of the space). If we further use the fact that
AC linear systems (see Definition 31 ) have zero right hand side (
@xmath ), then the update rule of SDSA takes the form:

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

where @xmath is a random matrix drawn independently at each iteration
@xmath from an arbitrary but fixed distribution @xmath , and @xmath
denotes the Moore-Penrose pseudoinverse.

The corresponding primal iterates are defined via:

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

The relevance of this all to average consensus follows through the
observation that for a specific choice of matrix @xmath and distribution
@xmath , the primal method produced by combining ( 5.4 ) and ( 5.3 ) is
equivalent to the (standard) randomized pairwise gossip method (see
discussion in Chapter 4 ). In that case, SDSA is a dual variant of
randomized pairwise gossip. In particular, in this chapter, we define
@xmath as follows: @xmath is a unit basis vector in @xmath , chosen
uniformly at random from the collection of all such unit basis vectors,
denoted @xmath . In this case, SDSA is the randomized coordinate ascent
method applied to the dual problem.

#### 5.2.3 Randomized gossip setup: choosing @xmath

We wish @xmath to be an average consensus (AC) system (see Definition 31
). As we explained in Chapter 4 if @xmath is an AC system, then the
solution of the primal problem ( 5.1 ) is necessarily @xmath , where
@xmath is the value that each node needs to compute in the standard
average consensus problem ( @xmath for all @xmath ).

In the rest of this chapter we focus on a specific AC system; the one in
which the matrix @xmath is the incidence matrix of the graph @xmath . In
particular, we let @xmath be the matrix defined as follows. Row @xmath
of @xmath is given by @xmath , @xmath and @xmath if @xmath . Notice that
the system @xmath encodes the constraints @xmath for all @xmath , as
desired.

#### 5.2.4 Randomized pairwise gossip

We provide both primal and dual form of the (standard) randomized
pairwise gossip algorithm.

The primal form is standard and needs no lengthy commentary. At the
beginning of the process, node @xmath contains private information
@xmath . In each iteration we sample a pair of connected nodes @xmath
uniformly at random, and update @xmath and @xmath to their average. We
let the values at the remaining nodes intact.

1: Vector of private values @xmath .

2: Set @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Update the primal variable:

  -- -------- --
     @xmath   
  -- -------- --

6: end for

7: Return @xmath

Algorithm 14 (Primal form)

The dual form of the standard randomized pairwise gossip method is a
specific instance of SDSA, as described in ( 5.3 ), with @xmath and
@xmath being a randomly chosen standard unit basis vector @xmath in
@xmath ( @xmath is a randomly selected edge). It can be seen [ 74 ] that
in that case, ( 5.3 ) takes the following form:

1: Vector of private values @xmath .

2: Set @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Update the dual variable:

  -- -------- --
     @xmath   
  -- -------- --

6: end for

7: Return @xmath

Algorithm 14 (Dual form)

The following lemma is useful for the analysis of all our methods. It
describes the increase in the dual function value after an arbitrary
change to a single dual variable @xmath .

###### Lemma 40.

Define @xmath , where @xmath and @xmath . Then

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

###### Proof.

The claim follows by direct calculation:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

∎

The maximizer in @xmath of the expression in ( 5.5 ) leads to the exact
line search formula @xmath used in the dual form of the method.

#### 5.2.5 Complexity results

With graph @xmath we now associate a certain quantity, which we shall
denote @xmath . It is the smallest nonnegative number @xmath such that
the following inequality ² ² 2 We write @xmath to indicate sum over all
unordered pairs of vertices. That is, we do not count @xmath and @xmath
separately, only once. By @xmath we denote a sum over all edges of
@xmath . On the other hand, by writing @xmath , we are summing over all
(unordered) pairs of vertices twice. holds for all @xmath :

  -- -------- -- -------
     @xmath      (5.6)
  -- -------- -- -------

The Laplacian matrix of graph @xmath is given by @xmath . Let @xmath be
the eigenvalues of @xmath . The algebraic connectivity of @xmath is the
second smallest eigenvalue of @xmath :

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

We have @xmath . Since we assume @xmath to be connected, we have @xmath
. Thus, @xmath is the smallest nonzero eigenvalue of the Laplacian:
@xmath As the next result states, the quantities @xmath and @xmath are
inversely proportional.

###### Lemma 41.

@xmath

###### Proof.

See Section 5.6.1 . ∎

The following theorem gives a complexity result for (standard)
randomized gossip. Our analysis is dual in nature.

###### Theorem 42.

Consider the randomized gossip algorithm (Algorithm 14) with uniform
edge-selection probabilities: @xmath . Then:

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Section 5.6.2 ∎

Theorem 42 yields the complexity estimate @xmath , which exactly matches
the complexity result obtained from the primal analysis (see ( 4.22 ) in
Chapter 4 ). Hence, the primal and dual analyses give the same rate.

Randomized coordinate descent methods were first analyzed in [ 104 , 139
, 166 , 167 ] . For a recent treatment, see [ 160 , 161 ] . Duality in
randomized coordinate descent methods was studied in [ 178 , 163 ] .
Acceleration was studied in [ 102 , 51 , 2 ] . These methods extend to
nonsmooth problems of various flavours [ 50 , 22 ] .

With all of this preparation, we are now ready to formulate and analyze
our private gossip algorithms; we do so in Section 5.3 .

### 5.3 Private Gossip Algorithms

In this section, we introduce three novel private gossip algorithms,
complete with iteration complexity guarantees. In Section 5.3.1 the key
relationships between the measures of success (see Table 5.1 ) of all
proposed algorithms are presented. In Section 5.3.2 the privacy is
protected via a binary communication protocol. In Section 5.3.3 we
communicate more: besides binary information, we allow for the
communication of a bound on the gap, introducing the @xmath -gap oracle.
In Section 5.3.4 we introduce a privacy-protection mechanism based on a
procedure we call controlled noise insertion .

#### 5.3.1 Measures of success

We devote this subsection to present Lemma 43 that formally specifies
the connections between the different measures of suboptimality of the
privacy preserving algorithms, firstly presented in Table 5.1 .

###### Lemma 43.

(Relationship between convergence measures) Suppose that @xmath is
primal variable corresponding to the dual variable @xmath as defined in
( 5.4 ). Dual suboptimality can be expressed as the following [ 74 ] :

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

Moreover, for any @xmath we have :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (5.9)
     @xmath   @xmath   @xmath      (5.10)
     @xmath   @xmath   @xmath      (5.11)
     @xmath   @xmath   @xmath      (5.12)
  -- -------- -------- -------- -- --------

###### Proof.

See Section 5.6.3 . ∎

#### 5.3.2 Private gossip via binary oracle

We now present the gossip algorithm with Binary Oracle in detail and
provide theoretical convergence guarantee. The information exchanged
between sampled nodes is constrained to a single bit, describing which
of the nodes has the higher value. As mentioned earlier, we only present
the conceptual idea, not how exactly would the oracle be implemented
within a secure multiparty protocol between participating nodes [ 26 ] .

We will first introduce the dual version of the algorithm.

1: Vector of private values @xmath , sequence of positive stepsizes
@xmath

2: Set @xmath , @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Update the dual variable:

  -- -------- --
     @xmath   
  -- -------- --

6: Set

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

7: end for

8: Return @xmath

Algorithm 15 (Dual form)

The update of primal variables above is equivalent to set @xmath as
primal point corresponding to dual iterate: @xmath . In other words, the
primal iterates @xmath associated with the dual iterates @xmath can be
written in the form:

  -- -------- --
     @xmath   
  -- -------- --

It is easy to verify that due to the structure of @xmath , this is
equivalent to the updates above.

Since the evolution of dual variables @xmath serves only the purpose of
the analysis, the method can be written in the primal-only form as
follows:

1: Vector of private values @xmath , sequence of positive stepsizes
@xmath

2: Set @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Set

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

6: end for

7: Return @xmath

Algorithm 15 (Primal form)

Given a sequence of stepsizes @xmath , it will be convenient to define
@xmath and @xmath . In the following theorem, we study the convergence
of the quantity

  -- -------- -- --------
     @xmath      (5.13)
  -- -------- -- --------

###### Theorem 44.

For all @xmath we have

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

Moreover:

1.   If we set @xmath for all @xmath , then @xmath .

2.   Let @xmath be any constant such that @xmath . If we fix @xmath ,
    then the choice of stepsizes @xmath which minimizes @xmath
    correspond to the constant stepsize rule @xmath for all @xmath , and
    @xmath .

3.   If we set @xmath for all @xmath , then

      -- -------- --
         @xmath   
      -- -------- --

###### Proof.

See Section 5.6.4 ∎

The part (ii) of Theorem 44 is useful in the case that we know exactly
the number of iterations before running the algorithm, providing in a
sense optimal stepsizes and rate @xmath . However, this might not be the
case in practice. Therefore part (iii) is also relevant, which yields
the rate @xmath . These bounds are significantly weaker than the
standard bound in Theorem 42 . This should not be surprising though, as
we use significantly less information than the Standard Gossip
algorithm.

Nevertheless, there is a potential gap in terms of what rate can be
practically achievable. The following theorem can be seen as a form of a
bound on what convergence rate is possible to be attained by the Binary
Oracle. However, this rate can be attained with access to very strong
information. It requires a specific sequence of stepsizes @xmath which
is likely unrealistic in practical scenarios. This result points to a
gap in the analysis which we leave open. We do not know whether the
sublinear convergence rate in Theorem 44 is necessary or improvable
without additional information about the system.

###### Theorem 45.

For Algorithm 15 with stepsizes chosen in iteration @xmath adaptively to
the current values of @xmath as @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Section 5.6.5 ∎

Comparing Theorem 45 with the result for standard Gossip in Theorem 42 ,
the convergence rate is worse by factor of @xmath , which is the price
we pay for the weaker oracle.

An alternative to choosing adaptive stepsizes is the use of adaptive
probabilities [ 28 ] . We leave such a study for future work.

#### 5.3.3 Private gossip via @xmath-gap oracle

Here we present the gossip algorithm with @xmath -Gap Oracle in detail
and provide theoretical convergence guarantees. The information
exchanged between the sampled nodes is restricted to be one of three
cases, based on the difference of their values. As mentioned earlier, we
only present the conceptual idea, not how exactly would the oracle be
implemented within a secure multiparty protocol between participating
nodes [ 26 ] .

We will first introduce the dual version of the algorithm.

1: Vector of private values @xmath ; error tolerance @xmath

2: Set @xmath ; @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Update the dual variable:

  -- -------- --
     @xmath   
  -- -------- --

6: If @xmath then @xmath and @xmath

7: If @xmath then @xmath and @xmath

8: end for

9: Return @xmath

Algorithm 16 (Dual form)

Note that the primal iterates @xmath associated with the dual iterates
@xmath can be written in the form:

  -- -------- --
     @xmath   
  -- -------- --

The above is equivalent to setting @xmath .

Since the evolution of dual variables @xmath serves only the purpose of
the analysis, the method can be written in the primal-only form as
follows:

1: Vector of private values @xmath ; error tolerance @xmath

2: Set @xmath .

3: for @xmath do

4: Set @xmath

5: Choose edge @xmath uniformly at random.

6: If @xmath then @xmath and @xmath

7: If @xmath then @xmath and @xmath

8: end for

9: Return @xmath

Algorithm 16 (Primal form)

Before stating the convergence result, let us define a quantity the
convergence will naturally depend on. For each edge @xmath and iteration
@xmath define the random variable

  -- -------- --
     @xmath   
  -- -------- --

Moreover, let

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

The following Lemma bounds the expected increase in dual function value
in each iteration.

###### Lemma 46.

For all @xmath we have @xmath

###### Proof.

See Section 5.6.6 ∎

Our complexity result will be expressed in terms of the quantity:

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

###### Theorem 47.

For all @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Section 5.6.7 ∎

Note that if @xmath , it does not mean the primal iterate @xmath is
optimal. This only implies that the values of all pairs of directly
connected nodes differ by less than @xmath .

#### 5.3.4 Private gossip via controlled noise insertion

In this section, we present the gossip algorithm with Controlled Noise
Insertion. As mentioned in the introduction of this chapter, the
approach is similar to the technique proposed in [ 123 , 124 ] . Those
works, however, address only algorithms in the synchronous setting,
while our work is the first to use this idea in the asynchronous
setting. Unlike the above, we provide finite time convergence guarantees
and allow each node to add the noise differently, which yields a
stronger result.

In our approach, each node adds noise to the computation independently
of all other nodes. However, the noise added is correlated between
iterations for each node. We assume that every node owns two parameters
— the initial magnitude of the generated noise @xmath and rate of decay
of the noise @xmath . The node inserts noise @xmath to the system every
time that an edge corresponding to the node was chosen, where variable
@xmath carries an information how many times the noise was added to the
system in the past by node @xmath . Therefore, if we denote by @xmath
the current number of iterations, we have @xmath .

In order to ensure convergence to the optimal solution, we need to
choose a specific structure of the noise in order to guarantee the mean
of the values @xmath converges to the initial mean. In particular, in
each iteration a node @xmath is selected, we subtract the noise that was
added last time, and add a fresh noise with smaller magnitude:

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

where @xmath and @xmath for all iteration counters @xmath is independent
to all other randomness in the algorithm. This ensures that all noise
added initially is gradually withdrawn from the whole network.

After the addition of noise, a standard Gossip update is made, which
sets the values of sampled nodes to their average. Hence, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as desired.

It is not the purpose of this work to define any quantifiable notion of
protection of the initial values formally. However, we note that it is
likely the case that the protection of private value @xmath will be
stronger for bigger @xmath and for @xmath closer to @xmath .

For simplicity, we provide only the primal algorithm below.

1: Vector of private values @xmath ; initial variances @xmath and
variance decrease rate @xmath such that @xmath for all nodes @xmath .

2: Set @xmath ; @xmath , @xmath .

3: for @xmath do

4: Choose edge @xmath uniformly at random.

5: Generate @xmath and @xmath

6: Set

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

7: Update the primal variable:

  -- -------- --
     @xmath   
  -- -------- --

8: Set @xmath , @xmath

9: end for

10: Return @xmath

Algorithm 17 (Primal form)

We now provide results of dual analysis of Algorithm 17. The following
lemma provides us the expected decrease in dual suboptimality for each
iteration.

###### Lemma 48.

Let @xmath denote the number of neighbours of node @xmath . Then,

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

###### Proof.

See Section 5.6.8 ∎

We use the lemma to prove our main result, in which we show linear
convergence for the algorithm. For notational simplicity, we decided to
have @xmath , i.e. superscript of @xmath denotes its power, not an
iteration counter.

###### Theorem 49.

Let us define the following quantities:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Then for all @xmath we have the following bound

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

See Section 5.6.9 ∎

Note that @xmath is a weighted sum of @xmath -th powers of real numbers
smaller than one. For large enough @xmath , this quantity will depend on
the largest of these numbers. This brings us to define @xmath as the set
of indices @xmath for which the quantity @xmath is maximized:

  -- -------- --
     @xmath   
  -- -------- --

Then for any @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

which means that increasing @xmath for @xmath will not substantially
influence convergence rate.

Note that as soon as we have

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

for all @xmath , the rate from theorem 49 will be driven by @xmath (as
@xmath ) and we will have

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

One can think of the above as a threshold: if there is @xmath such that
@xmath is large enough so that the inequality ( 5.19 ) does not hold,
the convergence rate is driven by @xmath . Otherwise, the rate is not
influenced by the insertion of noise. Thus, in theory, we do not pay
anything in terms of performance as long as we do not hit the threshold.
One might be interested in choosing @xmath so that the threshold is
attained for all @xmath , and thus @xmath . This motivates the following
result:

###### Corollary 50.

Let us choose

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

for all @xmath , where @xmath . Then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

As a consequence, @xmath is the largest decrease rate of noise for node
@xmath such that the guaranteed convergence rate of the algorithm is not
violated.

###### Proof.

See Section 5.6.10 ∎

While the above result clearly states the important threshold, it is not
always practical as @xmath might not be known. However, note that if we
choose @xmath , we have @xmath since @xmath where @xmath denotes graph
edge connectivity : the minimal number of edges to be removed so that
the graph becomes disconnected. Inequality @xmath is a well known result
in spectral graph theory [ 52 ] . As a consequence, if for all @xmath we
have

  -- -------- --
     @xmath   
  -- -------- --

then the convergence rate is not driven by the noise.

### 5.4 Numerical Evaluation

We devote this section to experimentally evaluate the performance of the
Algorithms 15, 16 and 17 we proposed in the previous sections, applied
to the Average Consensus problem. In the experiments, we used two
popular graph topologies the cycle graph (ring network) and the random
geometric graph (see Figure 5.1 for an illustration of the two graphs).

-    Cycle graph with @xmath nodes: @xmath . In our experiments we
    choose @xmath . This small simple graph with regular topology is
    chosen for illustration purposes.

-    Random geometric graph with @xmath nodes and radius @xmath : @xmath
    . Random geometric graphs [ 152 ] are very important in practice
    because of their particular formulation which is ideal for modeling
    wireless sensor networks [ 76 , 16 ] . In our experiments we focus
    on a @xmath -dimensional random geometric graph @xmath which is
    formed by placing @xmath nodes uniformly at random in a unit square
    with edges between nodes which are having euclidean distance less
    than the given radius @xmath . We set this to be to be @xmath — it
    is well know that the connectivity is preserved in this case [ 76 ]
    . We set @xmath .

Setup: In all experiments we generate a vector with of initial values
@xmath from a uniform distribution over @xmath . We run several
experiments and present two kinds of figures that help us to understand
how the algorithms evolve and verify the theoretical results of the
previous sections. These figures are:

1.  The evolution of the initial values of the nodes. In these figures,
    we plot how the trajectory of the values @xmath of each node @xmath
    evolves throughout iterations. The black dotted horizontal line
    represents the exact average consensus value which all nodes should
    approach, and thus all other lines should approach this level.

2.  The evolution of the relative error measure @xmath where @xmath is
    the starting vector of the values of the nodes. In these figures we
    choose to have the relative error, both in normal and logarithmic
    scale on the vertical axis and the number of iterations on the
    horizontal axis.

For our evaluation we run each privacy preserving algorithm for several
parameters and for a pre-specified number of iterations not necessarily
the same for each experiment.

To illustrate the first concept (trajectories of the values @xmath ) ,
we provide a simple example of the evolution of the initial values
@xmath for the case of the Standard Gossip algorithm [ 16 ] in Figure
5.2 . The horizontal black dotted line represents the average consensus
value. It is the exact average of the initial values @xmath of the nodes
in the network.

In the rest of this section we evaluate the performance of the three
privacy preserving randomized gossip algorithms of Section 5.3 , and
contrast with the above Standard Gossip algorithm, which we refer to as
“Baseline” in the following figures labels.

#### 5.4.1 Private gossip via binary oracle

In this section, we evaluate the performance of Algorithm 15 presented
in Section 5.3.2 . In the algorithm, the input parameters are the
positive stepsizes @xmath . The goal of the experiments is to compare
the performance of the proposed algorithm using different choices of
@xmath .

In particular, we use decreasing sequences of stepsizes @xmath and
@xmath , and three different fixed values for the stepsizes @xmath . We
also include the adaptive choice @xmath which we have proven to converge
with linear rate in Theorem 45 . We compare these choices in Figures 5.4
and 5.6 , along with the Standard Gossip algorithm for clear comparison.

In general, we clearly see what is expected with the constant stepsizes
— that they converge to a certain neighbourhood and oscillate around
optimum. With smaller stepsize, this neighbourhood is more accurate, but
it takes longer to reach. With decreasing stepsizes, Theorem 44 suggests
that @xmath of order @xmath should be optimal. Figure 5.6 demonstrates
this, as the choice of @xmath decreases the stepsizes too quickly.
However, this is not the case in Figure 5.4 in which we observe the
opposite effect. This is due to the cycle graph being small and simple,
and hence the diminishing stepsize becomes a problem only after a
relatively large number of iterations. With the adaptive choice of
stepsizes, we recover the linear convergence rate as predicted by
Theorem 45 .

The results in Figure 5.6 show one surprising comparison. The adaptive
choice of stepsizes does not seem to perform better than @xmath .
However, we verified that when running for more iterations, the linear
rate of adaptive stepsize is present and converges significantly faster
to higher accuracies. We chose to present the results for @xmath
iterations since we found it overall cleaner.

#### 5.4.2 Private gossip via @xmath-gap oracle

In this section, we evaluate the performance of the
Algorithm 16 presented in Section 5.3.3 . In the algorithm, the input
parameter is the positive error tolerance variable @xmath . For
experimental evaluation. we choose three different values for the input,
@xmath , and again use the same cycle and random geometric graphs. The
trajectories of the values @xmath are presented in Figures 5.7 and 5.9 ,
respectively. The performance of the algorithm in terms of the relative
error is presented in Figures 5.8 and 5.10 .

The performance is exactly matching the expectation — with larger @xmath
, the method converges very fast to a wide neighbourhood of the optimum.
For a small value, it converges much closer to the optimum, but it
requires more iterations.

#### 5.4.3 Private gossip via controlled noise insertion

In this section, we evaluate the performance of Algorithm 17 presented
in Section 5.3.4 . This algorithm has two different parameters for each
node @xmath . These are the initial variance @xmath and the rate of
decay, @xmath , of the noise.

To evaluate the impact of these parameters, we perform several
experiments. As earlier, we use the same graph structures for
evaluation: cycle graph and random geometric graph. The algorithm
converges with a linear rate depending on the minimum of two factors —
see Theorem 49 and Corollary 50 . We will verify that this is indeed the
case, and for values of @xmath above a certain threshold, the
convergence is driven by the rate at which the noise decays. This is
true for both identical values of @xmath for all @xmath , and for
varying values as per ( 5.21 ). We further demonstrate the latter is
superior in the sense that it enables insertion of more noise, without
sacrificing the convergence speed. Finally, we study the effect of
various magnitudes of the noise inserted initially.

##### Fixed variance, identical decay rates

In this part, we run Algorithm 17 with @xmath for all @xmath , and set
@xmath for all @xmath and some @xmath . We study the effect of varying
the value of @xmath on the convergence of the algorithm.

In both Figures 5.12 b and 5.14 b, we see that for small values of
@xmath , we eventually recover the same rate of linear convergence as
the Standard Gossip algorithm. If the value of @xmath is sufficiently
close to @xmath however, the rate is driven by the noise and not by the
convergence of the Standard Gossip algorithm. This value is @xmath for
cycle graph, and @xmath for the random geometric graph in the plots we
present.

Looking at the individual runs for small values of @xmath in Figure 5.14
b, we see some variance in terms of when the asymptotic rate is
realized. We would like to point out that this does not provide
additional insight into whether specific small values of @xmath are in
general better for the following reason. The Standard Gossip algorithm
is itself a randomized algorithm, with an inherent uncertainty in the
convergence of any particular run. If we ran the algorithms multiple
times, we observe variance in the evolution of the suboptimality of
similar magnitude, just as what we see in the figure. Hence, the
variance is expected, and not significantly influenced by the noise.

##### Variance 1 and different decay rates

In this section, we perform a similar experiment as above, but the
values @xmath are not all the same. We rather control them by the choice
of @xmath as in ( 5.21 ). Note that by decreasing @xmath , we increase
@xmath , and thus smaller @xmath means the noise decays at a slower
rate. Here, due to the regular structure of the cycle graph, we present
only results for the random geometric graph.

It is not straightforward to compare this setting with the setting of
identical @xmath , and we return to it in the next section. Here we only
remark that we again see the existence of a threshold predicted by
theory, beyond which the convergence is dominated by the inserted noise.
Otherwise, we recover the rate of the Standard Gossip algorithm.

##### Impact of varying @xmath

In this experiment, we demonstrate the practical utility of letting the
rate of decay @xmath to be different on each node @xmath . In order to
do so, we run the experiment on the random geometric graph and compare
the settings investigated in the previous two sections — the noise decay
rate driven by @xmath , or by @xmath .

In first place, we choose the values of @xmath such that that the two
factors in Corollary 50 are equal. For the particular graph we used,
this corresponds to @xmath with @xmath . Second, we make the factors
equal, but with constraint of having @xmath to be equal for all @xmath .
This corresponds to @xmath for all @xmath .

The performance for a large number of iterations is displayed in the
left side of Figure 5.17 . We see that the above two choices indeed
yield very similar practical performance, which also eventually matches
the rate predicted by theory. For a complete comparison, we also include
the performance of the Standard Gossip algorithm.

The important message is conveyed in the histogram in the right side of
Figure 5.17 . The histogram shows the distribution of the values of
@xmath for different nodes @xmath . The minimum of these values is what
we needed in the case of identical @xmath for all @xmath . However, most
of the values are significantly higher. This means, that if we allow the
noise decay rates to depend on the number of neighbours, we are able to
increase the amount of noise inserted, without sacrificing practical
performance. This is beneficial, as more noise will likely be beneficial
for any formal notion of protection of the initial values.

### 5.5 Conclusion

In this chapter, we addressed the Average Consensus problem via novel
asynchronous privacy preserving randomized gossip algorithms. In
particular, we propose three different algorithmic tools for the
protection of the initial private values of the nodes.

The first two proposed algorithms “Private Gossip via Binary Oracle" and
“Private Gossip via @xmath -Gap Oracle" are based on the same idea of
weakening the oracle used in the gossip update rule. In these two
protocols the chosen pair of nodes of each gossip step instead of share
their exact values they provide only categorical (or even binary)
information to each other.

In the third protocol “Private Gossip via Controlled Noise Insertion",
we systematically inject and withdraw noise throughout the iterations,
so as to ensure convergence to the average consensus value and at the
same time protect the private information of the nodes.

In all cases, we provide explicit convergence rates and evaluate
practical convergence on common simulated network topologies.

Future work inludes the design of privacy preserving variants of several
popular and fast gossip protocols [ 7 , 127 , 82 , 19 , 106 ] . One can
also investigate more challenging types of consensus problems like the
finite step consensus or consensus on networks with time-varying
topology, and design gossip protocols that preserve the privacy of the
participating agents. Designing the optimal network structure for
information preservation is also an interesting research direction.

As we have already mentioned the gossip algorithms of this chapter do
not address any specific notion of privacy (no clear measure of privacy
is presented) and it is still not clear how the formal concept of
differential privacy [ 47 ] can be applied in protocols for solving the
average consensus problem. Propose efficient differential privacy
guarantees for gossip protocols in general graphs is an interesting open
problem.

### 5.6 Proofs of Main Results

#### 5.6.1 Proof of Lemma 41

Let us first present a lemma that we use in the proof of Lemma 41 .

###### Lemma 51.

The eigenvalues of @xmath are @xmath

###### Proof.

Clearly, @xmath . Consider some vector @xmath such that @xmath . Then,
@xmath thus @xmath is an eigenvector corresponding to eigenvalue @xmath
. Thus, we can pick @xmath linearly independent eigenvectors of @xmath
corresponding to eigenvalue @xmath , which concludes the proof. ∎

Having established the above lemma let us present the proof Lemma 41 .

The Laplacian matrix of @xmath is the matrix @xmath . We have @xmath
(degree of vertex @xmath ), @xmath if @xmath and @xmath otherwise. A
simple computation reveals that for any @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath be the @xmath matrix corresponding to the complete graph
@xmath on @xmath . Let @xmath be its Laplacian. We have @xmath for all
@xmath and @xmath for @xmath . So, @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

Inequality ( 5.6 ) can therefore be recast as follows:

  -- -------- --
     @xmath   
  -- -------- --

Let @xmath . Note that both @xmath and @xmath are Hermitian thus have
real eigenvalues and there exist an orthonormal basis of their
eigenvectors. Suppose that @xmath are eigenvectors of @xmath
corresponding to eigenvalues @xmath . Without loss of generality assume
that these eigenvectors form an orthonormal basis and @xmath .

Clearly, @xmath , @xmath , and @xmath . Lemma 51 states that eigenvalues
of @xmath are @xmath .

One can easily see that eigenvector corresponding to zero eigenvalue of
@xmath is @xmath . Note that eigenvectors @xmath generate an eigenspace
corresponding to eigenvalue @xmath of @xmath .

Consider some @xmath , @xmath for all @xmath . Then we have

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof.

#### 5.6.2 Proof of Theorem 42

We first establish two lemmas which will be needed to prove Theorem 42 .

###### Lemma 52.

Assume that edge @xmath is selected in iteration @xmath of Algorithm 14.
Then

  -- -------- -- --------
     @xmath      (5.22)
  -- -------- -- --------

###### Proof.

We have @xmath where @xmath is chosen so that @xmath is maximized.
Applying Lemma 40 , we have

  -- -------- --
     @xmath   
  -- -------- --

∎

###### Lemma 53.

Let @xmath such that @xmath . Then

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

###### Proof.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

∎

Having established Lemmas 52 and 53 , we can now proceed with the proof
of Theorem 42 :

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Taking expectation again, we get the recursion

  -- -------- --
     @xmath   
  -- -------- --

#### 5.6.3 Proof of Lemma 43

Let us first present a Lemma that we use in the proof of Lemma 43 .

###### Lemma 54.

  -- -------- -- --------
     @xmath      (5.24)
  -- -------- -- --------

###### Proof.

Using simple algebra we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Manipulating right hand side of ( 5.24 ) we obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Clearly, LHS and RHS of ( 5.24 ) are equal. ∎

In order to show ( 5.9 ) it is enough to notice that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Note that we have

  -- -------- --
     @xmath   
  -- -------- --

which proves ( 5.10 ). On the other hand, we have

  -- -------- --
     @xmath   
  -- -------- --

which concludes ( 5.11 ). Inequality ( 5.12 ) holds trivially.

#### 5.6.4 Proof of Theorem 44

The following lemma is used in the proof of Theorem 44 .

###### Lemma 55.

Fix @xmath and let @xmath . Then

  -- -------- --
     @xmath   
  -- -------- --

and the optimal solution is given by @xmath for all @xmath .

###### Proof.

Define @xmath . If we write @xmath , where @xmath and @xmath is of unit
norm, then @xmath . Clearly, for any fixed @xmath , the @xmath
minimizing @xmath is @xmath , where @xmath is the vector of ones in
@xmath . It now only remains to minimize the function @xmath . This
function is convex and differentiable. Setting the derivative to zero
leads to @xmath . Combining the above, we get the optimal solution
@xmath . ∎

Let @xmath be the edge selected at iteration @xmath . Applying Lemma 40
, we see that @xmath Taking expectation with respect to edge selection,
we get

  -- -------- --
     @xmath   
  -- -------- --

and taking expectation again and using the tower property, we get the
identity

  -- -------- --
     @xmath   
  -- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

It remains to reshuffle the resulting inequality to obtain ( 5.14 ).

We can see that part (i) follows directly. Optimality of stepsizes in
(ii) is due to Lemma 55 . To show (iii) we should state that

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

The inequality above holds due to the fact that for @xmath we have
@xmath since @xmath is convex function.

#### 5.6.5 Proof of Theorem 45

Using Lemma 40 with we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Taking the expectation again we obtain

  -- -------- -- --------
     @xmath      (5.25)
  -- -------- -- --------

On the other hand, we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Taking the expectation of the above and combining with ( 5.25 ) we
obtain the desired recursion

  -- -------- --
     @xmath   
  -- -------- --

#### 5.6.6 Proof of Lemma 46

Let @xmath be the edge selected at iteration @xmath . Applying Lemma 40
, we see that

  -- -------- --
     @xmath   
  -- -------- --

This implies that

  -- -------- --
     @xmath   
  -- -------- --

Taking expectation in the selection of @xmath , we get

  -- -------- --
     @xmath   
  -- -------- --

It remains to take expectation again.

#### 5.6.7 Proof of Theorem 47

Since for all @xmath we have @xmath , it follows that

  -- -------- --
     @xmath   
  -- -------- --

It remains to apply Lemma 46 .

#### 5.6.8 Proof of Lemma 48

Let us first present three lemmas that we use in the proof of Lemma 48 .

###### Lemma 56.

Suppose that we run Algorithm 17 for @xmath iterations and @xmath
denotes the number of times that some edge corresponding to node @xmath
was selected during the algorithm.

1.  @xmath and @xmath are independent for all (i.e., not necessarily
    distinct) @xmath .

2.  @xmath and @xmath are independent for all (i.e., not necessarily
    distinct) @xmath .

3.  @xmath and @xmath have zero correlation for all @xmath .

4.  @xmath and @xmath have zero correlation for all (i.e., not
    necessarily distinct) @xmath .

###### Proof.

1.  Follows from the definition of @xmath .

2.  Follows from the definition of @xmath .

3.  Note that we have @xmath and @xmath . Clearly, @xmath and @xmath
    have zero correlation. Similarly @xmath and @xmath have zero
    correlation. Thus, @xmath and @xmath have zero correlation.

4.  Clearly, @xmath is a function initial state and all instances of
    random variables up to the iteration @xmath . Thus, @xmath is
    independent to @xmath from the definition. Thus, @xmath and @xmath
    have zero correlation.

∎

###### Lemma 57.

  -- -------- -- --------
     @xmath      (5.26)
  -- -------- -- --------

###### Proof.

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
              
     @xmath   
     @xmath   
  -- -------- --

where in the first equality we add and subtracting @xmath . In step
@xmath we denote by @xmath a node such that that the noise @xmath was
added to the system when the edge @xmath was chosen (we do not consider
@xmath since in this case the Lemma 57 trivially holds). ∎

###### Lemma 58.

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

###### Proof.

Since we have @xmath , and also for any random variable @xmath : @xmath
, we only need to compute the variance:

  -- -------- --
     @xmath   
  -- -------- --

∎

Having presented the above lemmas we can now proceed with the proof of
Lemma 48 .

Firstly, let us compute the increase of the dual function value at
iteration @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.28)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Our goal is to estimate an upper bound of the quantity @xmath . There
are three terms in ( 5.28 ). Since the expectation is linear, we will
evaluate the expectations of these three terms separately and merge them
at the end.

Taking the expectation over the choice of edge and inserted noise in
iteration @xmath we obtain

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

Thus we have

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Taking the full expectation of the above and using tower property, we
get

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

Now we are going to take the expectation of the second term of ( 5.28 ).
We will use the “tower rule" of expectations in the form

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

where @xmath are random variables. In particular, we get

  -- -------- -- --------
     @xmath      
     @xmath      (5.32)
  -- -------- -- --------

In equation ( 5.6.8 ), @xmath denotes the edge selected at iteration
@xmath .

Let us first calculate the inner most expectation of the right hand side
of ( 5.6.8 ):

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
              
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Now we take the expectation of the last expression above with respect to
the choice of an edge at @xmath -th iteration. We obtain

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

where in the last step we change the summation order.

Taking the expectation with respect to the algorithm we obtain

  -- -------- -- --------
     @xmath      
                 
     @xmath      
     @xmath      
     @xmath      (5.33)
  -- -------- -- --------

Taking an expectation of the third term of ( 5.28 ) with respect to
lastly added noise, the expression @xmath is equal to

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Taking the expectation over @xmath we obtain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where in the last step we change the summation order.

Finally, taking the expectation with respect to the algorithm we get

  -- -------- -- --------
     @xmath      
                 
                 
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
                 (5.34)
  -- -------- -- --------

where in step (*) we change the summation order.

Combining ( 5.28 ) with ( 5.30 ), ( 5.33 ) and ( 5.34 ) we obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

which concludes the proof.

#### 5.6.9 Proof of Theorem 49

Let us present two lemmas that we use in the proof of Theorem 49 .

###### Lemma 59.

After @xmath iterations of algorithm 17 we have

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

###### Proof.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

∎

###### Lemma 60.

Random variables @xmath and @xmath are nonegatively correlated, i.e.

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

###### Proof.

Denote @xmath to be a random variable equal to 1 if the noise @xmath was
added to the system when edge @xmath was chosen and equal to 0
otherwise. We can rewrite the expectation in the following way:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

The inequality @xmath holds due to the fact that @xmath was added to
@xmath with the positive sign. ∎

Combining ( 5.18 ) with the results of Lemmas 5.35 and 5.36 we obtain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

The recursion above gives us inductively the following

  -- -------- --
     @xmath   
  -- -------- --

which concludes the proof of the theorem.

#### 5.6.10 Proof of Corollary 50

Note that we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

In view of Theorem 49 , this gives us the following:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

## Chapter 6 Conclusion and Future Work

### 6.1 Conclusions

In this thesis we studied the design and analysis of novel efficient
randomized iterative methods for solving large scale linear systems,
stochastic quadratic optimization problems, the best approximation
problem and quadratic optimization problems. Using these methods we also
proposed and analyzed efficient gossip protocols for solving the average
consensus problem on large scale networks.

In Chapter 2 , we studied the convergence of several stochastic
optimization algorithms enriched with heavy ball momentum for solving
stochastic optimization problems of special structure. We proved global,
non-asymptotic linear convergence rates of all of these methods as well
as accelerated linear rate for the case of the norm of expected
iterates. We also introduced a new momentum strategy called stochastic
momentum which is beneficial in the case of sparse data, and proved
linear convergence in this setting. We corroborated our theoretical
results with extensive experimental testing.

In Chapter 3 , we proposed and analyzed inexact variants of several
stochastic algorithms for solving quadratic optimization problems and
linear systems. We provided linear convergence rate under several
assumptions on the inexactness error. The proposed methods require more
iterations than their exact variants to achieve the same accuracy.
However, as we show through our numerical evaluations, the inexact
algorithms require significantly less time to converge.

In Chapter 4 , we presented a general framework for the analysis and
design of randomized gossip algorithms for solving the average consensus
problem. Using tools from numerical linear algebra and the area of
randomized projection methods for solving linear systems, we proposed
novel serial, block and accelerated gossip protocols for solving the
average consensus and weighted average consensus problems.

In Chapter 5 , we addressed the average consensus problem via novel
asynchronous privacy preserving randomized gossip algorithms. In
particular, we proposed three different algorithmic tools for the
protection of the initial private values of the nodes. The first two
proposed algorithms “Private Gossip via Binary Oracle" and “Private
Gossip via @xmath -Gap Oracle" are based on the same idea of weakening
the oracle used in the gossip update rule. Instead of sharing their
exact values, in these two protocols the chosen pair of nodes of each
gossip step provide only categorical (or even binary) information to
each other. In the third protocol, “Private Gossip via Controlled Noise
Insertion", we systematically inject and withdraw noise throughout the
iterations, so as to ensure convergence to the average consensus value,
and at the same time protect the private information of the nodes. For
all proposed protocols, we provide explicit convergence rates and
evaluate practical convergence on common simulated network topologies.

### 6.2 Future Work

Perhaps the most exciting direction for future work is to extend the
analysis of the proposed randomized iterative methods to more general
settings. In particular, the more natural extension of our results is
the analysis of heavy ball momentum variants and inexact variants of the
proposed methods (SGD, SN, SPP, SPM and SDSA) in the case of general
convex or strongly convex functions.

From numerical linear algebra viewpoint, we believe that the proposed
randomized iterative methods of Chapters 2 and 3 could have great
potential to make a practical difference to iterative solvers for
large-scale linear systems. In this aspect, a future effort needs to be
devoted to the practical development and implementations of the
algorithms. For example, one promising direction is to use new
sophisticated sketching matrices @xmath , such as the Walsh-Hadamard
matrix [ 155 , 119 ] in the update rules of the proposed methods.

In this thesis we focused on algorithms with a fixed constant step-size.
An interesting extension will be to study the effect of decreasing or
adaptive choice for the relaxation parameter. This might provide novel
insights, even in the case of quadratic functions and (not necessarily
consistent) linear systems. As we have mentioned in several parts of the
thesis, the obtained results hold under the exactness condition, which
as we explained, is very weak, allowing for virtually arbitrary
distributions @xmath from which the random matrices are drawn. A
different future direction will be the design of optimized distributions
in order to improve further the convergence rates and the overall
complexity of the proposed algorithms.

In addition, we believe that the gossip protocols proposed in Chapters 4
and 5 would be particularly useful in the development of efficient
decentralized protocols.

Using the novel framework presented in this thesis, many popular
projection methods can be interpreted as gossip algorithms when used to
solve linear systems encoding the underlying network. This can lead to
the development of novel distributed protocols for average consensus.

Our work on gossip algorithms is amenable to further extensions. For
instance, the proposed novel gossip protocols (block, accelerated,
privacy-preserving) can be extended to the more general setting of
multi-agent consensus optimization, where the goal is to minimize the
average of convex or non-convex functions @xmath in a decentralized way.
Such protocols will be particularly useful in settings where the data
describing a given optimization problem is so big that it becomes
impossible to store it on a single machine. These situations often arise
in modern machine learning and deep learning applications.
