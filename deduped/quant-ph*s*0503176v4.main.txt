##### Contents

-    1 Introduction
-    2 Elements of game theory
    -    2.1 Introduction
    -    2.2 Representations of games
        -    2.2.1 Normal form
        -    2.2.2 Extensive form
    -    2.3 Information structure in games
        -    2.3.1 Cooperative games
        -    2.3.2 Non-cooperative games
    -    2.4 Matrix games
        -    2.4.1 Constant-sum games
        -    2.4.2 Zero-sum game
        -    2.4.3 Bi-matrix games
    -    2.5 Examples of matrix games
        -    2.5.1 Prisoners’ Dilemma
        -    2.5.2 Battle of Sexes
        -    2.5.3 Matching Pennies
        -    2.5.4 Rock-Scissors-Paper
    -    2.6 Solution concepts
        -    2.6.1 Rational “solution” of Prisoners’ Dilemma
        -    2.6.2 Nash equilibrium
        -    2.6.3 Nash equilibrium in the Prisoners’ Dilemma
        -    2.6.4 Nash equilibrium in the Battle of Sexes
    -    2.7 Evolutionary game theory
        -    2.7.1 Evolutionarily stable strategies
        -    2.7.2 ESS as a refinement of Nash equilibrium
-    3 Review of quantum mechanics
    -    3.1 Introduction
    -    3.2 Fundamental concepts
    -    3.3 Postulates of quantum mechanics
    -    3.4 Qubits
    -    3.5 Quantum measurement
        -    3.5.1 Positive Operator-Valued Measure
    -    3.6 Pure and mixed states
    -    3.7 Density matrix
    -    3.8 Quantum Entanglement
-    4 Quantum games
    -    4.1 Introduction
    -    4.2 Why games in the quantum world?
    -    4.3 Examples of quantum games
        -    4.3.1 Vaidman’s game
        -    4.3.2 Meyer’s PQ Penny-Flip
        -    4.3.3 Eisert, Wilkens and Lewenstein’s quantum Prisoners’
            Dilemma
        -    4.3.4 Quantum Battle of Sexes
        -    4.3.5 Quantum version of the Monty Hall problem
        -    4.3.6 Quantum market games
        -    4.3.7 Quantum Parrondo’s Games
-    5 Comments on proposed set-ups to play quantum games
    -    5.1 Enk’s comment on Meyer’s quantum Penny-Flip
        -    5.1.1 Meyer’s reply
    -    5.2 Benjamin and Hayden’s comment on quantization of Prisoners’
        Dilemma
    -    5.3 Benjamin’s comment on Marinatto and Weber’s quantum Battle
        of Sexes
        -    5.3.1 Marinatto and Weber’s reply
        -    5.3.2 ‘Quantum form’ of a matrix game and initial quantum
            states
    -    5.4 Enk and Pike’s comment on quantum Prisoners’ Dilemma
-    6 Evolutionary stability in quantum games
    -    6.1 Introduction
    -    6.2 Quantization as a refinement notion of Nash equilibrium?
    -    6.3 Quantization changing evolutionary stability?
    -    6.4 ESSs in Eisert, Wilkens and Lewenstein’s scheme
        -    6.4.1 Case ( 1 )
        -    6.4.2 Case ( 2 )
        -    6.4.3 Case ( 3 )
    -    6.5 ESSs in Marinatto and Weber’s scheme
        -    6.5.1 Example of quantum Prisoners’ Dilemma
        -    6.5.2 ESSs in two-player two-strategy asymmetric games
        -    6.5.3 ESSs in two-player two-strategy symmetric games
        -    6.5.4 ESSs in three-player two-strategy symmetric games
    -    6.6 Quantum Rock-Scissors-Paper game
        -    6.6.1 Rock-Scissors-Paper in a slightly modified version
        -    6.6.2 Nash equilibrium and ESS in Rock-Scissors-Paper game
        -    6.6.3 Quantization of Rock-Scissors-Paper game
        -    6.6.4 Consideration of evolutionary stability
    -    6.7 Stability of a mixed Nash equilibrium
        -    6.7.1 Discussion
    -    6.8 Equilibria of replicator dynamics in quantum games
        -    6.8.1 Introduction
        -    6.8.2 Equilibria and attractors of replicator dynamics
-    7 Relevance of evolutionary stability in quantum games
    -    7.1 Quantum mechanics deciding an evolutionary outcome
    -    7.2 Development of complexity and self-organization
    -    7.3 Genetic code evolution
    -    7.4 Quantum evolutionary algorithms
    -    7.5 Evolutionary quantum optimization and computation
-    8 Cooperation in quantum games
    -    8.1 Introduction
    -    8.2 A three-player symmetric cooperative game
        -    8.2.1 Classical form
        -    8.2.2 Quantum form
    -    8.3 Discussion
-    9 Backwards-induction outcome in quantum games
    -    9.1 Introduction
    -    9.2 Backwards-induction outcome
    -    9.3 Stackelberg duopoly
        -    9.3.1 Classical form
        -    9.3.2 Quantum form
    -    9.4 Discussion
-    10 Quantum repeated games
    -    10.1 Introduction
    -    10.2 Two-stage games of complete but imperfect information
    -    10.3 Two-stage Prisoners’ Dilemma
        -    10.3.1 Classical form
        -    10.3.2 Quantum form
    -    10.4 Discussion
-    11 New proposals to play quantum games
    -    11.1 Introduction
    -    11.2 Quantum games with a diffraction set-up
        -    11.2.1 Playing Prisoners’ Dilemma
    -    11.3 Performing EPR type experiments to play a bi-matrix game
        -    11.3.1 Quantum correlation games
        -    11.3.2 A new approach towards defining a correlation game
        -    11.3.3 Defining correlation payoffs
        -    11.3.4 Nash equilibria of quantum correlation games
        -    11.3.5 Quantum game as another classical game?
        -    11.3.6 Discussion
-    12 Conclusions

###### List of Figures

-    4.1 Eisert et al.’s scheme to play a quantum game.
-    4.2 Marinatto and Weber’s scheme to play a quantum game.
-    8.1 A three-player quantum game played with Marinatto and Weber’s
    scheme. Players @xmath and @xmath form a coalition. @xmath is the
    identity and @xmath is the inversion operator.
-    9.1 Playing a quantum form of Stackelberg duopoly.
-    10.1 Playing a two-stage quantum game of Prisoners’ Dilemma.
-    11.1 A multi-slit diffraction set-up to play a quantum form of
    Prisoners’ Dilemma. A window with four slits faces an electron
    source. Each player has access to two slits. A player plays a pure
    strategy by opening a slit and closing the other. Referee finds the
    players’ payoffs by measuring the peak-to-peak distance on the
    diffraction pattern formed on the screen.

Dedication

This thesis is dedicated to my wife Ayesha and son Emmad. Both suffered
and were kept waiting for long hours during the years of research. I
greatly appreciate Ayesha’s warm and continuous support and Emmad’s
patience, without which the task was plainly impossible. The thesis is
also dedicated to the loving memory of my late parents.

    

This thesis is based on the following publications:

-   A. Iqbal and A. H. Toor, Evolutionarily stable strategies in quantum
    games . Physics Letters, A 280 /5-6, pp 249-256 (2001).

-   A. Iqbal and A. H. Toor, Entanglement and dynamic stability of Nash
    equilibria in a symmetric quantum game . Physics Letters, A 286 /4,
    pp 245-250 (2001).

-   A. Iqbal and A. H. Toor, Quantum mechanics gives stability to a Nash
    equilibrium . Physical Review, A 65 , 022306 (2002). This article is
    also selected to be reproduced in the February 1, 2002 issue of the
    Virtual Journal of Biological Physics Research:
    http://www.vjbio.org.

-   A. Iqbal and A. H. Toor, Quantum cooperative games . Physics
    Letters, A 293 /3-4 pp 103-108 (2002).

-   A. Iqbal and A. H. Toor, Darwinism in quantum systems? Physics
    Letters, A 294 /5-6 pp 261-270 (2002).

-   A. Iqbal and A. H. Toor, Backwards-induction outcome in a quantum
    game . Physical Review, A 65 , 052328 (2002). This article is also
    selected to be reproduced in the May 2002 issue of the Virtual
    Journal of Quantum Information: http://www.vjquantuminfo.org.

-   A. Iqbal and A. H. Toor, Quantum repeated games . Physics Letters, A
    300 /6, pp 537-542 (2002).

-   A. Iqbal and A. H. Toor, Stability of mixed Nash equilibria in
    symmetric quantum games . Communications in Theoretical Physics,
    Vol. 42 , No. 3, pp 335-338 (2004).

-   A. Iqbal, Quantum games with a multi-slit electron diffraction
    set-up. Nuovo Cimento B, Vol. 118 , Issue 5, pp 463-468 (2003).

-   A. Iqbal, Quantum correlations and Nash equilibria of a bi-matrix
    game . Journal of Physics A: Mathematical and General 37 , L353-L359
    (2004).

## Chapter 1 Introduction

Game theory [ 1 ] is a branch of mathematics that presents formal
analysis of the interaction among a group of rational players. The
players have choices available to them, so as to select particular
course of action. They are supposed to behave strategically and are
motivated to increase their utilities that depend on the collective
course of action.

Modern game theory started with the work of John von Neumann and Oskar
Morgenstern [ 2 ] in 1930s. During the same years von Neumann [ 3 ] also
made important contributions in quantum mechanics, a branch of physics
developed in 1920s to understand the microworld of atoms and molecules.
However, game theory and quantum mechanics were developed as separate
fields with apparently different domains of applications.

The early years of development in both of these fields could not find
some common ground, or physical situation, that could motivate an
interplay between the two fields. More than fifty years afterwards,
quantum computation [ 4 , 5 , 6 , 7 , 8 , 9 ] was developed in 1980s as
a new field of research that combined elements from quantum mechanics
and the theory of computation [ 10 ] . Computer science extensively uses
the theory of information and communication [ 11 ] . Quantum computation
motivated the development of quantum information [ 12 ] ; thus providing
an environment where the two distinct interests of von Neumann, i.e.
quantum mechanics and game theory, could be shown to have some sort of
interplay. Certain quantum communication protocols, and algorithms, were
reformulated in the language of game theory [ 13 , 14 , 15 , 16 , 17 ,
18 ] . It was not long before the first systematic procedures [ 19 , 20
] were proposed to quantize well-known classical games [ 1 ] .

Classical bits are the entities that are used to physically implement
classical information. Quantum information [ 21 ] , on the other hand,
uses quantum bits (qubits) for its physical implementation. It is known
that the problems of classical game theory can be translated into
physical set-ups that use classical bits. It immediately motivates the
question of how games can be transformed when implemented with qubits.
Like it is the case with quantum information, it helps to quantize
classical games when qubits, instead of classical bits, are used in
physical set-ups to play games.

This thesis follows a particular approach in the theory of quantum
games. The thesis builds up on proposed convincing procedures telling
how to quantize well-known games from the classical game theory. A large
part of this thesis concerns studying the concept of an Evolutionarily
Stable Strategy (ESS) [ 22 ] from mathematical population biology within
the context of quantum games. The thesis argues that importing a
population setting towards quantum games is not unusual though it may
give such an impression. It is observed that even John Nash [ 23 , 24 ]
had a population setting in his mind when he introduced his solution
concept of the Nash equilibrium for non-cooperative games. The study of
evolutionary stability in quantum games is presented with the view that
importing the concept of an ESS, and its associated population setting,
to quantum games is natural to an equal extent as it is to study Nash
equilibrium in quantum games.

Game theory [ 1 ] also offers solution concepts that are relevant to
certain types of games. The notions of value of coalition,
backwards-induction outcome and subgame-perfect outcome present a few
examples. The types of games for which these concepts are appropriate
are known to be the cooperative, the sequential (with moves made in
order) and repeated (with moves made simultaneously in one stage) games,
respectively. To show how quantization affects solutions of these games,
the relevant solution concepts are investigated in relation to
quantization of these games. This study shows that quantum versions of
these games may have outcomes that are often extraordinary and sometimes
may even be counter-intuitive, from the point of view of classical game
theory.

Motivated by our preferred approach towards quantum games, i.e. to rely
on proposed convincing procedures to quantize known games from the
classical game theory, two new suggestions are put forward about quantum
versions of two-player two-strategy games. The first suggestion presents
a set-up that uses the association of De Broglie waves with travelling
material objects to play a quantum version of a two-player two-strategy
game. The second suggestion uses an EPR type setting in which spatially
separated players make measurements along chosen directions to play a
game.

The concluding chapter collects together main results obtained in the
thesis.

## Chapter 2 Elements of game theory

### 2.1 Introduction

Many decision making problems in sociology, politics and economics deal
with situations in which the results depend not only on the action of
one individual but also on the actions of others. Game theory is a
branch of mathematics which is used in modelling situations in which
many individuals with conflicting interests interact, such that the
results depend on the actions of all the participants. It is considered
a formal way to analyze interaction among a group of individuals who
behave rationally and strategically. The participants in a game strive
to maximize their (expected) utilities by choosing particular courses of
action. Because the actions of the others matter, a player’s final
utility depends on the profile of courses of action chosen by all the
individuals. A game deals with the following concepts:

-   Players . These are the individuals who compete in the game. A
    player can be an individual or a set of individuals.

-   A move will be a player’s action.

-   A player’s (pure) strategy will be a rule (or function) that
    associates a player’s move with the information available to her at
    the time when she decides which move to choose.

-   A player’s mixed strategy is a probability measure on the player’s
    space of pure strategies.

-   Payoffs are real numbers representing the players’ utilities.

Although first attempts to analyze such problems are apparently rather
old [ 25 ] , modern game theory started with the work of John von
Neumann and Oskar Morgenstern who wrote the book Theory of Games and
Economic Behaviour [ 2 ] . Game theory is now widely used in research in
diverse areas ranging from economics, social science, to evolutionary
biology and population dynamics.

### 2.2 Representations of games

There are different ways to represent a strategic interaction between
players. In game theory [ 1 ] two representations are well known:

#### 2.2.1 Normal form

A normal (strategic) form of a game consists of:

1.  A finite set of @xmath agents or players

2.  Strategy sets @xmath for the @xmath players

3.  Payoff functions @xmath , @xmath , are mappings from the set @xmath
    to the set of real numbers @xmath .

The set @xmath is called the strategy space @xmath . A member @xmath is
known as a strategy profile with @xmath and @xmath .

#### 2.2.2 Extensive form

The extensive form of a game is a complete description of:

1.  the set of players

2.  who moves when and what their choices are

3.  the players’ payoffs as a function of the choices that are made

4.  what players know when they move

The extensive form of a game, as opposed to the normal (or strategic)
form, provides a more appropriate framework for the analysis of
strategic interactions that involve sequential moves. It gives a richer
specification of a strategic interaction by specifying who moves when,
doing what and with what information. The easiest way to represent an
extensive form game is to use a game tree , which is multi-person
generalization of a decision tree [ 1 ] .

### 2.3 Information structure in games

The information at the disposal of a player, when she has to select a
move, is described by the information structure in the game . Based on
this structure games can usually be put in either one of the following
two broad classes, which also form the two main branches of game theory.

#### 2.3.1 Cooperative games

In cooperative games the players are allowed to form binding agreements.
These are restrictions on the possible actions decided by two or more
players. To be binding an agreements usually requires an outside
authority that can monitor the agreement at no cost and impose on
violators sanctions so severe that cheating is prevented. For players in
a binding agreement there is a strong incentive to work together to
receive the largest total payoff. The agreements may include, for
example, commitments and threats .

#### 2.3.2 Non-cooperative games

In non-cooperative games the players may not form binding agreements.
Neither do the players cooperate nor do they enter into negotiation for
achieving a common course of action. However the players know how the
actions, their own and the actions of the other players, will determine
the payoffs of every player.

### 2.4 Matrix games

One way to describe a game is to list the players participating in the
game, and to list the alternative choices or moves available to each
player. In the case of a two-player game, the moves of the first player
form the rows, and the moves of the second player the columns of a
matrix . The entries in the matrix are two numbers representing the
payoff to the first and second player, respectively. Such a description
of a game makes possible to completely represent the players’ payoffs by
a matrix. In game theory these games are recognized as matrix games. The
example below is a matrix game between two players:

  -- -- -- -------
           (2.1)
  -- -- -- -------

#### 2.4.1 Constant-sum games

In a constant-sum game , the sum of all players’ payoffs is the same for
any outcome. Hence, a gain for one participant is always at the expense
of another, such as in most sporting events.

#### 2.4.2 Zero-sum game

A zero-sum game is a special case of a constant sum game in which all
outcomes involve a sum of all player’s payoffs of @xmath . Since payoffs
can always be normalized, a constant sum game may be represented as (and
is equivalent to) a zero-sum game.

#### 2.4.3 Bi-matrix games

A class of games that have attracted much attention because of the
relative simplicity of their mathematical analysis involve two players
Alice and Bob. Each player has his own payoff matrix written as @xmath
and @xmath , respectively. Games of this kind are called bi-matrix
games.

### 2.5 Examples of matrix games

The following examples describe some well-known matrix games.

#### 2.5.1 Prisoners’ Dilemma

The most popular bi-matrix game is the so-called the Prisoners’ Dilemma
(PD) describing the following situation:

-   Two criminals are arrested after having committed a crime together
    and wait for their trial.

-   Each suspect is placed in a separate cell and offered the
    opportunity to confess to the crime.

-   Each suspect may choose between two strategies namely confessing (
    @xmath ) and not confessing ( @xmath ), where @xmath and @xmath
    stand for cooperation and defection.

-   If neither suspect confesses, i.e. @xmath they go free, and split
    the proceeds of their crime which we represent by @xmath units of
    payoff for each suspect.

-   However, if one prisoner confesses ( @xmath ) and the other does not
    ( @xmath ), the prisoner who confesses testifies against the other
    in exchange for going free and gets the entire @xmath units of
    payoff, while the prisoner who did not confess goes to prison and
    gets nothing.

-   If both prisoners confess, i.e. ( @xmath ), then both are given a
    reduced term, but both are convicted, which we represent by giving
    each @xmath unit of payoff: better than having the other prisoner
    confess, but not so good as going free.

The game can be represented by the following matrix of payoffs:

  -- -- -- -------
           (2.2)
  -- -- -- -------

where the first and the second entry correspond to Alice’s and Bob’s
payoff, respectively.

For either choice of the opponent it is hence advantageous to defect (
@xmath ). On the other hand, if both defect ( @xmath ) the payoff
remains less than in the case when both cooperate ( @xmath ). This is
the origin of dilemma.

A generalized matrix for the PD is given as:

  -- -- -- -------
           (2.3)
  -- -- -- -------

where @xmath .

#### 2.5.2 Battle of Sexes

Battle of Sexes (BoS) is a bi-matrix game that can be described as
follows:

-   Alice and Bob agree to meet in the evening, but cannot recall if
    they will be attending the opera or a boxing match.

-   Alice prefers the opera and Bob prefers the boxing match.

-   Both prefer being together to being apart.

Thus, while both parties prefer to find themselves at the same place,
Alice and Bob cannot agree which event to attend. The game has the
following matrix representation:

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

where @xmath .

#### 2.5.3 Matching Pennies

Matching Pennies is a zero-sum game with two players Alice and Bob. Each
shows either heads or tails from a coin. If both are heads or both are
tails then Alice wins, otherwise Bob wins. The payoff matrix is given as

  -- -- -- -------
           (2.5)
  -- -- -- -------

with a winner getting a reward of @xmath against the loser getting
@xmath .

#### 2.5.4 Rock-Scissors-Paper

Two children, Alice and Bob, simultaneously make one of three symbols
with their fists - a rock, paper, or scissors (RSP). Simple rules of
“rock breaks scissors, scissors cut paper, and paper covers rock”
dictate which symbol beats the other. If both symbols are the same, the
game is a tie:

  -- -- -- -------
           (2.6)
  -- -- -- -------

### 2.6 Solution concepts

Solving a game means finding a set of moves for the players which
represent their rational choices. Unlike in other fields, the notion of
a “solution” is more tenuous in game theory. In game theory a solution
is generally thought of as a systematic description of the outcomes that
may emerge during the play of a game.

#### 2.6.1 Rational “solution” of Prisoners’ Dilemma

For the bi-matrix PD it is self-evident how an intelligent individual
should behave. No matter what a suspect believes his partner is going to
do, it is always best to confess ( @xmath ):

-   If the partner in the other cell is not confessing ( @xmath ), it is
    possible to get @xmath instead of @xmath .

-   If the partner in the other cell is confessing ( @xmath ), it is
    possible to get @xmath instead of @xmath .

Yet the pursuit of individually sensible behavior results in each player
getting only @xmath unit of payoff, much less than the @xmath units each
that they would get if neither confessed ( @xmath ). This conflict
between the pursuit of individual goals and the common good is at the
heart of many game theoretic problems. For PD the rational choice for
both players is to defect.

#### 2.6.2 Nash equilibrium

A Nash equilibrium ( NE), named after John Nash, is a set of strategies,
one for each player, such that no player has an incentive to
unilaterally change her action. Players are in equilibrium if a change
in strategies by any one of them would lead that player to earn less
than if she remained with her current strategy.

The implicit assumption behind the concept of a NE is that players make
their choices simultaneously and independently. This idea also assumes
that each player participating in a game behaves rational and searches
to maximize his/her own payoff. A strategy profile @xmath is a NE if
none of them is left with a motivation to deviate unilaterally. Suppose
@xmath is the @xmath th-player’s payoff then the following condition
defines the NE:

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

When the @xmath players are playing the strategy profile @xmath the
@xmath th player’s decision to play @xmath instead of @xmath cannot
increase his/her payoff. A NE thus defines a set of strategies that
represents a best choice for each single player if all the other players
take their best decisions too.

The well-known Nash Theorem [ 23 ] in game theory guarantees the
existence of a set of mixed strategies for finite non-cooperative games
of two or more players in which no player can improve his payoff by
unilaterally changing his/her strategy.

#### 2.6.3 Nash equilibrium in the Prisoners’ Dilemma

Let Alice play @xmath with probability @xmath and play @xmath with
probability @xmath . Similarly, let Bob play @xmath with probability
@xmath and play @xmath with probability @xmath . The players’ payoffs
for the PD matrix ( 2.2 ) are

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (2.8)
     @xmath   @xmath      
              @xmath      (2.9)
  -- -------- -------- -- -------

The inequalities defining the NE in PD can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.10)
  -- -------- -------- -- --------

which produces a unique NE in the PD: @xmath . The NE corresponds to
both players playing the pure strategy @xmath .

#### 2.6.4 Nash equilibrium in the Battle of Sexes

Similar to the case of PD we assume that the numbers @xmath are the
probabilities with which Alice and Bob play the strategy @xmath ,
respectively. They then play @xmath with the probabilities @xmath and
@xmath , respectively. Players’ payoffs for the BoS matrix ( 2.4 ) are [
52 ] :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.11)
  -- -------- -------- -- --------

The NE @xmath is then found from the inequalities:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.12)
  -- -------- -------- -- --------

Three NE arise:

##### 1. @xmath

Both players play the pure strategy @xmath . The Nash inequalities are

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.13)
  -- -------- -------- -- --------

and the payoffs they obtain are

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

##### 2. @xmath

Both players now play the pure strategy @xmath and the Nash inequalities
are

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.15)
  -- -------- -------- -- --------

The players get

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

##### 3. @xmath @xmath

Players play a mixed strategy because @xmath . The players’ payoffs are

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

Compared to the equilibria @xmath and @xmath the players now get
strictly smaller payoffs because

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

### 2.7 Evolutionary game theory

Game theory suggests static ‘solutions’ obtained by analyzing the
behavior of ‘rational agents’. Such models are obviously unrealistic
because real life behavior is shaped by trial and error. Real life
‘players’ are subjected to the pressures of adaptation and are forced to
learn individually. In situations where players do not have the capacity
to learn individually, natural selection favors better players through
step-wise adaptation. John von Neumann and Oskar Morgenstern, in their
pioneering work on game theory [ 2 ] , also realized the need for such a
dynamic approach towards game theory. After all, the word game itself
suggests ‘motion’ in one way or the other.

In 1970’s Maynard Smith developed game-theoretic models of evolution in
a population which is subjected to Darwinian selection. In his book
Evolution and the Theory of Games [ 22 ] he diverted attention away from
the prevalent view – treating players as rational beings – and presented
an evolutionary approach in game theory. This approach can be seen as a
large population model of adjustment to a NE i.e. an adjustment of
population segments by evolution as opposed to learning. Maynard Smith’s
model consisted of strategic interaction among the members of a
population continuing over time in which higher payoff strategies
gradually displace strategies with lower payoffs. To distinguish
evolutionary from revolutionary changes some inertia is involved,
guaranteeing that aggregate behavior does not change too abruptly.

Most important feature of evolutionary game theory is that the
assumption of rational players – borrowed from game theory – does not
remain crucial. It is achieved when players’ payoffs are equated to
success in terms of their survival. Players in an evolutionary model are
programmed to play only one strategy. Step-wise selection assures
survival of better players at the expense of others. In other words, an
initial collection of strategies play a tournament and the average
scores are recorded. Successful strategies increase their share of the
population. Changing the population mix changes the expected payoff.
Again successful strategies increase in the population, and the expected
payoff is calculated. A population equilibrium occurs when the
population shares are such that the expected payoffs for all strategies
are equal.

Many successful applications of evolutionary game theory appeared in
mathematical biology [ 26 ] to predict the behavior of bacteria and
insects, that can hardly be said to think at all.

Economists too did not like game theory that mostly concerned itself
with hyper-rational players who are always trying to maximize their
payoffs. Hence the population setting of game theory, invented by
mathematical biologists, was welcomed by the economists too. Even John
Nash himself, as it was found later [ 27 ] , had a population setting in
his mind when he introduced his equilibrium notion. In his unpublished
thesis he wrote ‘ it is unnecessary to assume that the participants
have…… the ability to go through any complex reasoning process. But the
participants are supposed to accumulate empirical information on the
various pure strategies at their disposal…….We assume that there is a
population …….of participants……and that there is a stable average
frequency with which a pure strategy is employed by the “average member”
of the appropriate population ’ [ 24 , 28 ] .

#### 2.7.1 Evolutionarily stable strategies

Maynard Smith introduced the idea of an Evolutionarily Stable Strategy
(ESS) in a seminal paper ‘The logic of animal conflict’ [ 29 ] . In
rough terms [ 30 ] an ESS is a strategy which, if played by almost all
the members of a population, cannot be displaced by a small invading
group that plays any alternative strategy. So that, a population playing
an ESS can withstand invasion by a small group. The concept was
developed by combining ingredients from game theory and some work on the
evolution of the sex ratio [ 31 ] .

Maynard Smith considers a large population in which members are matched
repeatedly and randomly in pairs to play a bi-matrix game. The players
are anonymous, that is, any pair of players plays the same symmetric
bi-matrix game. Also the players are identical with respect to their set
of strategies and their payoff functions. The symmetry of a bi-matrix
game means that for a strategy set @xmath Alice’s payoff when she plays
@xmath and Bob plays @xmath is the same as Bob’s payoff when he plays
@xmath and Alice plays @xmath . In game theory [ 1 ] a symmetric
bi-matrix game is represented by an expression @xmath where @xmath is
the first player’s payoff matrix and @xmath , its transpose, is the
second players’ payoff matrix. In a symmetric pair-wise contest @xmath
gives the payoff to a @xmath -player against a @xmath -player. In such
contest exchange of strategies by the two players also exchanges their
respective payoffs. Hence, a player’s payoff is defined by his/her
strategy and not by his/her identity.

Mathematically speaking, [ 32 ] @xmath is an ESS when for each strategy
@xmath the inequality:

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

should hold for all sufficiently small @xmath . The left side of ( 2.19
) is the payoff to the strategy @xmath when played against the strategy
@xmath where @xmath . For @xmath becoming greater than @xmath the
inequality ( 2.19 ) does not hold and @xmath does not remain an ESS. The
situation when @xmath is also known as the invasion by the mutant
strategy. The quantity @xmath is called the invasion barrier .

To be precise [ 27 ] a strategy @xmath is an ESS:

-   If for each mutant strategy @xmath there exists a positive invasion
    barrier .

-   The invasion barrier exists such that if the population share of
    individuals playing the mutant strategy @xmath falls below this
    barrier, then @xmath earns a higher expected payoff than @xmath .

This condition for an ESS can be shown [ 22 ] equivalent to the
following two requirements:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.20)
  -- -------- -------- -- --------

An ESS, therefore, is a symmetric NE which also possesses a property of
stability against small mutations. Condition @xmath in the definition (
2.20 ) shows @xmath is a NE for the bi-matrix game @xmath if @xmath is
an ESS. Nevertheless, the converse is not true. That is, if @xmath is a
NE then @xmath is an ESS only if @xmath satisfies condition @xmath in
the definition.

In evolutionary game theory the concept of fitness [ 33 ] of a strategy
is considered crucial. Suppose @xmath and @xmath are pure strategies
played in a population setting. Their fitnesses are defined as:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (2.21)
  -- -------- -------- -- --------

where @xmath and @xmath are frequencies (the relative proportions) of
the pure strategies @xmath and @xmath respectively.

The concept of evolutionary stability provided much of the motivation
for the development of evolutionary game theory. Presently, the ESS
concept is considered as the central model of evolutionary dynamics of a
populations of interacting individuals. It asks, and finds answer to it,
a basic question: Which states of a population – during the course of a
selection process that favors better performing strategies – are stable
against perturbations induced by mutations? The theory is inspired by
Darwinian natural selection which is formulated as an algorithm called
replicator dynamics . Iterations of selections from randomly mutating
replicators is the important feature of the dynamics. The dynamics is a
mathematical statement saying that in a population the proportion of
players which play better strategies increase with time. With replicator
dynamics being the underlying selection mechanism in a population, ESSs
come out [ 34 ] as stable strategies against small perturbations. In
other words ESSs are rest points of the replicator dynamics.

#### 2.7.2 ESS as a refinement of Nash equilibrium

In the history of game theory elaborate definitions of rationality, on
the behalf of the players, led to many refinements [ 35 ] of the NE
concept. In situations where multiple NE appear as potential solutions
to a game, a refinement is required to prefer some over the others.
Refinements of NE are popular as well as numerous in classical game
theory. Speaking historically, the set of refinements became so large
that eventually almost any NE could be justified in terms of someone or
other’s refinement. The concept of an ESS is a refinement on the set of
symmetric Nash equilibria [ 32 ] . Apart from being a symmetric NE it
has robustness against small mutations [ 36 ] . For symmetric bi-matrix
games this relationship is described as [ 37 ] :

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

where @xmath and @xmath , @xmath , @xmath are the sets of symmetric Nash
equilibria, symmetric proper equilibrium, and ESSs respectively.

## Chapter 3 Review of quantum mechanics

Quantum mechanics: Real Black Magic Calculus

– Albert Einstein

### 3.1 Introduction

Quantum theory is the theoretical basis of modern physics that explains
the nature and behavior of matter and energy on the atomic and subatomic
level. The physical systems at these levels are known as quantum systems
. Thus quantum mechanics is a mathematical model of the physical world
that describes the behavior of quantum systems. A physical model is
characterized by how it represents physical states , observables ,
measurements , and dynamics of the system under consideration. A quantum
description of a physical model is based on the following concepts:

### 3.2 Fundamental concepts

A state is a complete description of a physical system. Quantum
mechanics associates a ray in Hilbert space to the physical state of a
system. What is Hilbert space?

-   Hilbert space is a complex linear vector space. In Dirac’s ket-bra
    notation states are denoted by ket vectors @xmath in Hilbert space.
    Any two state vectors differing only by an overall phase factor
    @xmath ( @xmath real) represent the same state.

-   Corresponding to a ket vector @xmath there is another kind of state
    vector called bra vector , which is denoted by @xmath . The inner
    product of a bra @xmath and ket @xmath is defined as follows:

      -- -------- -------- -- -------
         @xmath   @xmath      
         @xmath   @xmath      (3.1)
      -- -------- -------- -- -------

    for any @xmath , the set of complex numbers. There is a one-to-one
    correspondence between the bras and the kets. Furthermore

      -- -------- -------- -- -------
         @xmath   @xmath      
         @xmath   @xmath      (3.2)
      -- -------- -------- -- -------

-   The state vectors in Hilbert space are normalized which means that
    the inner product of a state vector with itself gives unity, i.e.,

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

-   Operations can be performed on a ket @xmath and transform it to
    another ket @xmath . There are operations on kets which are called
    linear operators , which have the following properties. For a linear
    operator @xmath we have

  -- -------- -------- -- -------
              @xmath      
     @xmath   @xmath      (3.4)
  -- -------- -------- -- -------

for any @xmath .

-   The sum and product of two linear operators @xmath and @xmath are
    defined as:

      -- -------- -------- -- -------
         @xmath   @xmath      
         @xmath   @xmath      (3.5)
      -- -------- -------- -- -------

    Generally speaking @xmath is not necessarily equal to @xmath , i.e.
    @xmath

-   The adjoint @xmath of an operator @xmath is defined by the
    requirement:

      -- -------- -- -------
         @xmath      (3.6)
      -- -------- -- -------

    for all kets @xmath , @xmath in the Hilbert space.

-   An operator @xmath is said to be self-adjoint or Hermitian if:

      -- -------- -- -------
         @xmath      (3.7)
      -- -------- -- -------

Hermitian operators are the counterparts of real numbers in operators.
In quantum mechanics, the dynamical variables of physical systems are
represented by Hermitian operators. More specifically, every
experimental arrangement in quantum mechanics is associated with a set
of operators describing the dynamical variables that can be observed.
These operators are usually called observables .

### 3.3 Postulates of quantum mechanics

For an isolated quantum system, quantum theory is based on the following
postulates:

-   A ket vector @xmath in Hilbert space gives a complete description of
    the state of the physical system.

-   Dynamics are specified by Hermitian operators and time evolution is
    given by Schrödinger’s equation:

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

where @xmath is the Hamiltonian operator . Schrödinger’s equation is a
deterministic equation of motion that allows one to determine the state
vector at any time once the initial conditions are provided.

Classical games can be played when players share coins. Coins are
physical systems that represent classical bits which takes one of the
two possible values @xmath , or simply head and tail. A bit is also the
indivisible unit of classical information. For example in
non-cooperative games coins are distributed among the players and they
do their actions on them. At the end of the game the coins are collected
by a referee who rewards the players, after observing the collected
coins. The earliest suggestions for playing quantum games can be thought
of letting players act on qubits , which are a quantum generalization of
classical two level systems like a coin.

### 3.4 Qubits

In two-dimensional Hilbert space an orthonormal basis can be written as
@xmath . A general qubit state is then

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

where @xmath satisfying @xmath . In other words, @xmath is a unit vector
in two-dimensional complex vector space for which a particular basis has
been fixed. One of the simplest physical examples of a qubit is the spin
@xmath of an electron. The spin-up and spin-down states of an electron
can be taken as the states @xmath , @xmath of a qubit.

A non-cooperative classical game can be played by coin distribution and
players’ rewards are decided after observing the coins. Likewise, a
non-cooperative quantum game can be played by distributing qubits among
the players. After the players’ moves the qubits are brought together
for an observation which is known as quantum measurement .

### 3.5 Quantum measurement

Unlike observation of coins by a referee who organizes a classical game,
the concept of measurement of a quantum state of many qubits is subtle
and lies at the heart of quantum theory. The measurement postulate of
quantum mechanics states [ 39 ] :

-   Mutually exclusive measurement outcomes correspond to orthogonal
    projection operators @xmath and the probability of a particular
    outcome @xmath is @xmath . If the outcome @xmath is attained the
    (normalized) quantum state after the measurement becomes

  -- -------- -- --------
     @xmath      (3.10)
  -- -------- -- --------

Consider a measurement made on a qubit whose state vector resides in
two-dimensional Hilbert space. A measuring device has associated an
orthonormal basis with respect to which the quantum measurement takes
place. Measurement transforms the state of the qubit into one of
measuring device’s associated basis vectors . Assume the measurement is
performed on the qubit that has the state ( 3.9 ). The measurement
projects the state ( 3.9 ) to the basis @xmath . Now in this case the
measurement postulate says that the outcome @xmath will happen with
probability @xmath and the outcome @xmath with probability @xmath .

Furthermore, measurement of a quantum state changes the state according
to the result of the measurement. That is, if the measurement of @xmath
results in @xmath , then the state @xmath changes to @xmath and a second
measurement, with respect to the same basis, will return @xmath with
probability @xmath . Thus, unless the original state happened to be one
of the basis vectors, measurement will change that state, and it is not
possible to determine what the original state was.

Although a qubit can be put in infinitely many superposition states,
only a single classical bit’s worth of information can be extracted from
it. It is because the measurement changes the state of the qubit to one
of the basis states.

Measurement made with orthogonal projection operators @xmath is also
called projective measurement .

#### 3.5.1 Positive Operator-Valued Measure

Apart from projective measurement the quantum theory also uses another
important concept of measurement, whose implementation can be useful. It
is the concept of positive operator-valued measure (POVM). A POVM
consists of a set of non-negative quantum mechanical Hermitian operators
that add up to the identity. The probability that a quantum system is in
a particular state is given by the expectation value of the POVM
operator corresponding to that state. POVMs are sometimes also referred
to as the “generalized measurements”.

Nielsen and Chuang [ 21 ] have discussed a simple example showing the
utility of POVM formalism. Suppose Alice gives Bob a qubit prepared in
one of two states, @xmath or @xmath . It can be shown that there is no
quantum measurement capable of distinguishing the two states with
perfect reliability. However, using a POVM Bob can perform a measurement
that distinguishes the two states some of the time, but never makes an
error of misidentification.

In this connection Neumark’s theorem [ 38 ] needs to be mentioned here
that states that, at least in principle, any POVM can be implemented by
the adjunction of an ancilla ¹ ¹ 1 Ancilla bits are extra scratch qubits
that quantum operations often use. in a known state, followed by a
standard measurement in the enlarged Hilbert space.

### 3.6 Pure and mixed states

In quantum mechanics a pure state is defined as a quantum state that can
be described by a ket vector:

  -- -------- -- --------
     @xmath      (3.11)
  -- -------- -- --------

Such a state evolves in time according to the time-dependent Schrödinger
equation ( 3.8 ). A mixed quantum state is a statistical mixture of pure
states. In such a state the exact quantum-mechanical state of the system
is not known and only the probability of the system being in a certain
state can be given, which is accomplished by the density matrix .

### 3.7 Density matrix

A quantum game involves two or more players having access to parts of a
quantum system. These parts are usually the subsystems of a bigger
quantum system. To use the system for playing a game one must know it
detailed statistical state. Quantum mechanics uses the concept of a
density matrix to describe the statistical state of a quantum system. It
is the quantum-mechanical analogue to a phase-space density (probability
distribution of position and momentum) in classical statistical
mechanics. Suppose the quantum state of a system is expressed in terms
of a denumerable orthonormal basis @xmath . The state @xmath of the
system at time @xmath in the basis is given as

  -- -------- -- --------
     @xmath      (3.12)
  -- -------- -- --------

Let @xmath be normalized

  -- -------- -- --------
     @xmath      (3.13)
  -- -------- -- --------

The matrix elements of a self-adjoint operator @xmath in the basis are

  -- -------- -- --------
     @xmath      (3.14)
  -- -------- -- --------

The average (expectation) value of @xmath at time @xmath for the system
in state @xmath is

  -- -- -- --------
           (3.15)
  -- -- -- --------

Consider the operator @xmath . It has matrix elements

  -- -------- -- --------
     @xmath      (3.16)
  -- -------- -- --------

The calculation of @xmath involves these matrix elements. Hence define

  -- -------- -- --------
     @xmath      (3.17)
  -- -------- -- --------

which is known as the density matrix of the pure state @xmath . It is a
Hermitian operator, acting on the Hilbert space of the system in
question, with matrix elements

  -- -------- -- --------
     @xmath      (3.18)
  -- -------- -- --------

Eq. ( 3.17 ) shows that for a pure state the density matrix is given by
the projection operator of this state.

Since @xmath is normalized, we also have

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

The expectation value of the observable @xmath can now be re-expressed
using the density operator:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (3.20)
  -- -------- -------- -- --------

For a mixed state, where a quantum system is in the state @xmath with
probability @xmath , the density matrix is the sum of the projectors
weighted with the appropriate probabilities:

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

Density matrix is a powerful tool in quantum games because a game
usually involves a multi-partite quantum system. Compared to the
description of a quantum game based on state vectors, density matrix
provides much compact notation.

### 3.8 Quantum Entanglement

Some of the most interesting investigations in quantum games concern the
relationship between game-theoretic solution concepts and entanglement
present within the quantum system that players are using to play the
game. The phenomenon of entanglement can be traced back to Einstein,
Podolsky and Rosen (EPR)’s famous paper [ 40 ] of 1935. EPR argued that
quantum mechanical description of physical reality can not be considered
complete because of its rather strange predictions about two particles
that once have interacted but now are separate from one another and do
not interact. Quantum mechanics predicts that the particles can be
entangled even after separation. Entangled particles have correlated
properties and these correlations are at the heart of the EPR paradox.

Consider a system that can be divided into two subsystems. Assume @xmath
and @xmath to be the Hilbert spaces corresponding to the subsystems. Let
@xmath @xmath where @xmath be a complete orthonormal basis for @xmath ,
and @xmath @xmath where @xmath be a complete orthonormal basis for
@xmath . In quantum mechanics the Hilbert space @xmath (tensor product)
is associated to the two subsystems taken together. The tensor product
Hilbert space @xmath is spanned by the states @xmath . By dropping the
tensor product sign @xmath is also written as @xmath . Any state of the
system @xmath is a linear combination of the basis states @xmath i.e.

  -- -------- -- --------
     @xmath      (3.22)
  -- -------- -- --------

where @xmath are complex coefficients. State @xmath is usually taken to
be normalized

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

A state @xmath is a direct product state when it factors into a
normalized state @xmath in @xmath and a normalized state @xmath in
@xmath i.e.

  -- -------- -- --------
     @xmath      (3.24)
  -- -------- -- --------

Now, interestingly, there exist some states in @xmath that can not be
written as product states. The state @xmath is one example. When @xmath
is not a product state it is called entangled [ 41 , 21 ] .

Quantum games have extensively used entangled states to see the
resulting affects on solutions of a game. However, it is considered a
usual requirement in quantum games that players’ access to product
states leads to the classical game.

## Chapter 4 Quantum games

### 4.1 Introduction

It is difficult to trace back the earliest work on quantum games. Many
situations in quantum theory can be reformulated in terms of game
theory. Several works in the literature of quantum physics can be
identified having game-like underlying structure. For example:

-   Wiesner’s work on quantum money [ 13 ] .

-   Mermin’s account [ 42 ] of Greeberger, Horne, and Zeilinger (GHZ)’s
    [ 43 ] version of the Bell’s theorem [ 44 , 38 ] without
    inequalities.

-   Elitzur-Vaidman bomb detector [ 45 ] , suggesting an interferometer
    which splits a photon in two and then puts it back together again
    (interaction-free measurement).

-   Vaidman’s illustration [ 15 ] of GHZ’s version of the Bell’s
    theorem.

-   Meyer’s demonstration [ 19 ] of a quantum version of a penny-flip
    game.

-   Eisert, Wilkens, and Lewenstein’s [ 20 ] quantization of the famous
    game of Prisoners’ Dilemma (PD).

In general, a quantum game can be thought of as strategic manoeuvreing
of a quantum system by parties who have necessary means for such
actions. Some of its essential parts can be recognized as follows:

-   A definition of the physical system which can be analyzed using the
    tools of quantum mechanics.

-   Existence of one or more parties, usually referred to as players,
    who are able to manipulate the quantum system.

-   Players’ knowledge about the quantum system on which they will make
    their moves or actions.

-   A definition of what constitutes a strategy for a player.

-   A definition of strategy space for the players, which is the set of
    all possible actions that players can take on the quantum system.

-   A definition of the pay-off functions or utilities associated with
    the players’ strategies.

A two-player quantum game, for example, is a set [ 46 ] :

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

consisting of an underlying Hilbert space @xmath of the physical system,
the initial state @xmath , the sets @xmath and @xmath of allowed quantum
operations for two players, and the pay-off functions or utilities
@xmath and @xmath . In most of the existing set-ups to play quantum
games the initial state @xmath is the state of one or more qubits. More
complex quantum systems like qutrits (three-dimensional quantum systems)
or even qudits (d-dimensional quantum system) can also be used to play
quantum games.

### 4.2 Why games in the quantum world?

The question why game theory can be interesting in the quantum world has
been addressed in the earliest suggestions for quantum games. Some of
the stated reasons [ 19 , 20 ] are:

-   Classical game theory is based on probability to a large extent.
    Generalizing it to quantum probability is fundamentally interesting.

-   Quantum algorithms may be thought of as games between classical and
    quantum agents. Only a few quantum algorithms are known to date. It
    appears reasonable that an analysis of quantum games may help
    finding new quantum algorithms.

-   There is an intimate connection between the theory of games and
    theory of quantum communication. Eavesdropping [ 16 , 17 ] and
    optimal cloning [ 18 ] can readily be conceived as games between
    players.

-   Quantum mechanics may assure fairness in remote gambling [ 14 ] .

-   If the ‘Selfish Gene’ [ 47 ] is a reality then the games of survival
    are already being played at molecular level, where quantum mechanics
    dictates the rules.

### 4.3 Examples of quantum games

As the subject of quantum games has developed during recent years, many
examples have been put forward illustrating how such game can be
different from their classical analogues. Here are some of the well
known quantum games:

#### 4.3.1 Vaidman’s game

Vaidman [ 15 ] presented an example of a game for a team of three
players that can only be won if played in the quantum world. Three
players are sent to remote locations @xmath @xmath and @xmath . At a
certain time @xmath each player is asked one of the two possible
questions:

1.  What @xmath ?

2.  What @xmath ?

Both of these questions have @xmath or @xmath as possible answers. Rules
of the game are such that:

-   Either all players are asked the @xmath question or

-   Only one player is asked the @xmath question and the other two are
    asked the @xmath question.

The team wins if

-   The product of their three answers is @xmath in the case of three
    @xmath questions or

-   The product of three answers is @xmath in the case of one @xmath and
    two @xmath questions.

What should the team do? Let @xmath be the answer of player @xmath to
the @xmath question. Similarly, one can define @xmath etc. The winning
condition can now be written as

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (4.2)
  -- -------- -------- -- -------

The product of all left hand sides of Eqs. ( 4.2 ) is @xmath , because
each of the @xmath or @xmath take the values @xmath only. The product of
right sides is @xmath , which leads to a contradiction. Therefore, the
game cannot be won, with a success probability of @xmath , by a team of
classical players. Eqs. ( 4.2 ) show that the probability of winning the
game by classical players can not exceed @xmath . However, Vaidman
showed that a quantum solution exists for the team. Three particles are
prepared in a correlated state (GHZ):

  -- -- -- -------
           (4.3)
  -- -- -- -------

If a member  of the team is asked the @xmath question, she measures
@xmath . If she is asked the @xmath question, she measures @xmath
instead. Quantum mechanics implies that for the GHZ state one gets [ 15
]

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (4.4)
  -- -------- -------- -- -------

The Vaidman’s game can, therefore, be won by a group of quantum players
with @xmath success probability.

There remains a subtle point in Vaidman’s argument. The contradiction
obtained by comparing the four equations in ( 4.2 ) assume that all four
equations hold simultaneously. In fact, the four equations represent
four incompatible situations.

#### 4.3.2 Meyer’s PQ Penny-Flip

Two players can play a simple game if they share a coin having two
possible states, head or tail. The first strong argument for quantum
games was presented by Meyer [ 19 ] as a coin flip game played by two
characters, Captain Picard and Q, from the popular American science
fiction series Star Trek. In a quantum version of the game the flipping
action is performed on a “quantum coin”, which can be thought of as an
electron that, on measurement, is found to exist either in spin-up (
@xmath ) or in spin-down ( @xmath ) state.

In Meyer’s interesting description of a quantum game, the story starts
when starship Enterprise faces some imminent catastrophe. Q appears on
the bridge and offers Picard to rescue the ship if he can beat him in a
penny-flip game. Q asks Picard to place the penny in a box, head up.
Then Q, Picard, and finally Q play their moves. Q wins if the penny is
head up when the box is opened. For classical version of this game the
payoff matrix can be constructed as

  -- -- -- -------
           (4.5)
  -- -- -- -------

where rows and columns are Picard’s and Q’s pure strategies
respectively. Let @xmath be the basis of a @xmath -dimensional vector
space. The players’ moves can be represented by a sequence of @xmath
matrices. In the matrix ( 4.5 ) the moves ‘to flip’ and ‘not to flip’
are represented by @xmath and @xmath , respectively:

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

defined to act, on left multiplication, on a vector representing the
state of the coin. A general mixed strategy is described by the matrix:

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

where @xmath is the probability with which the player flips the coin. A
sequence of mixed actions puts the state of the coin into a convex
linear combination @xmath where @xmath . The coin is then in @xmath
state with probability @xmath . Q plays his move first, after Picard
puts the coin in the @xmath state.

Now Meyer presents a look at a quantum version of this game. Q has
studied quantum theory and implements his strategy as a sequence of
unitary rather than stochastic matrices. Such action requires a
description of the state of the coin in two-dimensional Hilbert space.
Let its basis be the kets @xmath and @xmath , in Dirac notation. A pure
state of the coin is @xmath where @xmath and @xmath .

Given the coin is initially in the state @xmath , the following unitary
action @xmath by @xmath puts the coin into the state @xmath :

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

Using the density matrix notation, the initial state of the coin can be
written as

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

Q’s unitary action @xmath changes the state @xmath to

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

because unitary transformations act on density matrices by conjugation.
Picard is restricted to use only a classical mixed strategy ( 4.7 ) by
flipping the coin with probability @xmath . After his action the coin is
in the pure state @xmath with probability @xmath and in the pure state
@xmath with probability @xmath . Picard’s action acts on the density
matrix @xmath , not as a stochastic matrix on a probabilistic state, but
as a convex linear combination of unitary (deterministic)
transformations:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.11)
  -- -------- -------- -- --------

Interestingly, Q has at his disposal a move:

  -- -- -- --------
           (4.12)
  -- -- -- --------

that can put the coin into a simultaneous eigenstate with eigenvalue
@xmath of both @xmath and @xmath which then becomes an invariant under
any mixed strategy @xmath of Picard. In his second action Q acts again
with @xmath and gets back the state @xmath and wins. The game can also
be understood with the following chart.

  -- -- -- --------
           (4.13)
  -- -- -- --------

where @xmath is a Hadamard transformation and @xmath is the flipping
operator. @xmath is the head state of the coin and @xmath is the
identity operator. Q plays a quantum strategy by putting the coin into a
symmetric superposition of head and tail. Now, whether Picard flips the
coin or not, it remains in the symmetric superposition which Q can
rotate back to head applying @xmath again since @xmath @xmath .

#### 4.3.3 Eisert, Wilkens and Lewenstein’s quantum Prisoners’ Dilemma

Eisert, Wilkens, and Lewenstein [ 20 ] gave a physical model of the PD
and suggested that the players can escape the dilemma if they both
resort to quantum strategies. Their physical model consists of

-   A source making available two bits, one for each player.

-   Physical instruments enabling the players to manipulate, in a
    strategic manner, their own bits.

-   A measurement device that determines the players’ payoffs from the
    final state of the two bits.

In a quantum formulation the classical strategies @xmath and @xmath are
assigned two basis vectors @xmath and @xmath in Hilbert space of a
qubit. A vector in the tensor product space, which is spanned by the
classical game basis @xmath and @xmath describes the state of the game.

The game’s initial state is @xmath where @xmath is a unitary operator
known to both players. Alice and Bob’s strategic moves are associated
with unitary operators @xmath and @xmath respectively, chosen from a
strategic space @xmath . The players’ actions are local i.e. each
operates on his/her qubit. After players’ moves the state of the game
changes to @xmath . Measurements are now performed to determine the
players’ payoffs. Measurement consists of applying a reverse unitary
operator @xmath followed by a pair of Stern-Gerlach type detectors.
Before detection the final state of the game is given by

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

Eisert et al. [ 20 ] define Alice’s expected payoff as

  -- -- -- --------
           (4.15)
  -- -- -- --------

where the quantities @xmath and @xmath are from the PD matrix ( 2.3 ).
Bob’s payoff @xmath is obtained by interchanging @xmath in Eq. ( 4.15 ).
Eisert and Wilkens [ 46 ] use following matrix representations of
unitary operators of their one- and two-parameter strategies,
respectively:

  -- -------- -------- -- --------
     @xmath   @xmath      (4.16)
     @xmath               (4.17)
  -- -------- -------- -- --------

where @xmath and @xmath . To ensure that the ordinary PD is faithfully
represented in its quantum version, Eisert et al. imposed additional
conditions on @xmath :

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

where @xmath and @xmath are the operators corresponding to the
strategies of cooperation and defection respectively. A unitary operator
satisfying the condition ( 4.18 ) is

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

where @xmath . @xmath can be called a measure of the game’s
entanglement. At @xmath the game reduces to its classical form. For a
maximally entangled game @xmath the classical NE @xmath is replaced by a
different unique equilibrium @xmath with @xmath The new equilibrium is
also found to be Pareto optimal , that is, a player cannot increase
his/her payoff by deviating from this pair of strategies without
reducing the other player’s payoff. Classically ( @xmath ) is Pareto
optimal, but is not an equilibrium. Eisert et al. claimed that in its
quantum version the dilemma in PD disappears from the game and quantum
strategies give a superior performance if entanglement is present.

In density matrix notation, the players’ actions change the initial
state @xmath to

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

The arbiter applies the following operators on @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (4.21)
  -- -------- -------- -- --------

The expected payoffs are

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (4.22)
  -- -------- -------- -- --------

Where, for example, @xmath is the Alice’s classical payoff when she
plays @xmath and Bob plays @xmath . For one-parameter strategies the
classical pure strategies @xmath and @xmath are realized as @xmath and
@xmath , respectively; while for two-parameter strategies the classical
pure strategies @xmath and @xmath are realized as @xmath and @xmath ,
respectively. Fig. ( 4.1 ) shows Eisert et al.’s scheme to play a
quantum game.

Many recent investigations [ 48 , 49 , 50 , 51 ] in quantum games have
been motivated by the Eisert et. al.’s scheme.

#### 4.3.4 Quantum Battle of Sexes

Motivated by the Eisert et al.’s proposal, Marinatto and Weber [ 52 ]
introduced a new scheme for quantizing bi-matrix games by presenting a
quantized version of the BoS. In this scheme a state in a @xmath
dimensional Hilbert space is referred to as a strategy . At the start of
the game the players are supplied with this strategy. The players
manipulate the strategy, in the next phase, by playing their tactics .
The state is finally measured and the payoffs are rewarded depending on
the results of the measurement. A player can do actions within a
two-dimensional subspace. Tactics are therefore local actions on a
player’s qubit. The final measurement, made independently on each qubit,
takes into consideration the local nature of players’ manipulations. It
is achieved by selecting a measurement basis that respects the division
of Hilbert space into two equal parts.

Essentially, the scheme differs from the earlier proposed scheme of
Eisert et al. [ 20 ] by the absence of reverse gate @xmath . The gate
makes sure that the classical game remains a subset of its quantum
version. In Marinatto and Weber’s scheme the state is measured without
passing it through the reverse gate. They showed that the classical game
still remains a subset of the quantum game if the players’ tactics are
limited to a probabilistic choice between applying the identity @xmath
and the Pauli spin-flip operator @xmath . Also the classical game
results when the players are forwarded an initial strategy @xmath .

Suppose @xmath is the initial strategy, which the players Alice and Bob
receive at the start of the game. Let Alice acts with identity @xmath on
@xmath with probability @xmath and with @xmath with probability @xmath .
Similarly, let Bob acts with identity @xmath with probability @xmath and
with @xmath with probability @xmath . After the players’ actions the
state changes to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (4.23)
  -- -------- -------- -- --------

For the bi-matrix:

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

Marinatto and Weber defined the following payoff operators

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (4.25)
  -- -------- -------- -- --------

where the states @xmath and @xmath are used for the measurement basis,
corresponding to the pure strategies @xmath and @xmath , respectively.
The payoff functions are then obtained as mean values of these
operators:

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

Fig. ( 4.2 ) sketches the idea of playing a quantum game in Marinatto
and Weber’s scheme. The scheme was developed for the BoS given by the
matrix ( 2.4 ). On receiving an initial strategy:

  -- -------- -- --------
     @xmath      (4.27)
  -- -------- -- --------

the players’ tactics cannot change it, and the final strategy remains
identical to the initial one. The players’ expected payoffs are
maximized for the tactics @xmath or @xmath , that is, both players
either apply @xmath with certainty or @xmath with certainty. In either
case the expected payoff is @xmath to each player. Marinatto and Weber
suggested that a unique solution thus exists in the game.

#### 4.3.5 Quantum version of the Monty Hall problem

Monty Hall is a game in which Alice secretly selects one door out of
three to place a prize there. It is now Bob’s turn who picks a door.
Alice then opens a different door showing that the prize is not behind
it. Bob now has the option of changing to the untouched door or sticking
with his current selection. In classical version of the game Bob’s
optimum strategy is to alter his choice of door and it doubles his
chances of winning.

Li et al. [ 53 ] , Flitney and Abbot [ 54 ] and D’Ariano et al. [ 55 ]
have proposed various quantum versions of the Monty Hall problem.

#### 4.3.6 Quantum market games

During recent years Piotrowski and Sladkowski [ 56 , 57 , 58 ] have
proposed quantum-like description of markets and economics. This
development can be shown having roots in quantum game theory and is
considered part of new field of econophysics. In econophysics [ 60 ]
mathematical techniques developed by physicists are used to analyze the
complex financial and economic systems. Developments in econophysics
have motivated some authors [ 61 ] to ask about the possibility of a
meaning of Heisenberg uncertainty principle in economics. Others have
even claimed that quantum mechanics and mathematical economics are
isomorphic [ 62 ] .

#### 4.3.7 Quantum Parrondo’s Games

A Parrondo’s game is an interesting problem in game theory. Two games
that are losing when played individually can be combined to produce a
winning game. The game can be put into the form of a gambling utilizing
a set of biased coins.

Flitney and Abbott [ 63 , 64 ] studied a quantum version of the
Parrondo’s game where the rotation operators representing the toss of a
classical biased coin are replaced by general SU(2) operators to
transform the game into the quantum domain. They found that
superposition of qubits can couple the two games and produce
interference leading to different payoffs than in the classical case.

## Chapter 5 Comments on proposed set-ups to play quantum games

Meyer [ 19 ] demonstrated with the example of a penny-flip game how
quantum mechanics can affect game theory. He introduced a game where a
suitable quantum strategy can beat any classical strategy. Comments and
criticism followed soon after this demonstration of the power of quantum
strategies, which are reviewed in the following.

### 5.1 Enk’s comment on Meyer’s quantum Penny-Flip

Though agreeing that Meyer reached a correct conclusion, Enk [ 65 ]
commented that Meyer’s particular example is flawed for the following
reasons:

-   Q’s quantum strategy can also be implemented classically.

-   Meyer’s game only shows the superiority of an extended set of
    strategies over a restricted one, which is not surprising.

-   A single qubit is not truly a quantum system because its dynamics
    and its response to measurements can also be described by a
    classical hidden-variable model. Bell’s inequalities, or the
    Kochen-Specker theorem, do not exist for a two-dimensional system,
    thus making it possible to explicitly construct classical models for
    such systems.

#### 5.1.1 Meyer’s reply

Meyer replied [ 66 ] and disagreed with Enk’s claim that the existence
of classical models for Q’s strategy necessarily prevents it from being
called quantum mechanical. He argued as the following:

-   Enk’s claim implies that P’s strategy is also not classical because
    quantum models exist for flipping a two-state system.

-   Though classical models do indeed exist for qubit systems but they
    scale exponentially as the number of qubits increase.

Entangled qubits do not possess classical models but entanglement itself
has been shown unnecessary to outperform a quantum algorithm from a
classical one. For example, Grover’s algorithm [ 8 ] , although
discovered in the context of quantum computation, can be implemented
using a system allowing superposition of states, like classical coupled
simple harmonic oscillators [ 67 ] . It does not seem fair to claim that
such an implementation prohibits calling it a quantum algorithm.

Related to the third point in Enk’s comment, it seems related to mention
that recently Khrennikov [ 68 ] proved an analogue of Bell’s inequality
for conditional probabilities. Interestingly the inequality can be
applied not only to pairs of correlated particles, but also to a single
particle. The inequality is violated for spin projections of the single
particle. Khrennikov concludes that a realistic pre-quantum model does
not exist even for the two-dimensional Hilbert space.

### 5.2 Benjamin and Hayden’s comment on quantization of Prisoners’
Dilemma

Eisert et al. obtained @xmath as the new quantum equilibrium in PD, when
both players have access to a two-parameter set ( 4.17 ) of unitary
@xmath matrices. Benjamin and Hayden [ 69 ] observed that when their
two-parameter set is extended to all local unitary operations (i.e. all
of @xmath ) the strategy @xmath does not remain an equilibrium. They
showed that in the full space of deterministic quantum strategies there
exists no equilibrium for Eisert et al.’s quantum PD. They also observed
that Eisert’s set of two-parameter quantum strategies is not closed
under composition, which is reasonable requirement for a set of quantum
strategies.

### 5.3 Benjamin’s comment on Marinatto and Weber’s quantum Battle of
Sexes

In his comment Benjamin [ 70 ] made two observations about Marinatto and
Weber’s quantum battle of sexes:

-   The overall quantization scheme is fundamentally very similar to the
    Eisert et al.’s previously proposed scheme [ 20 ] .

-   The quantum BoS does not have a unique solution. Though the dilemma
    may be easier to resolve in its quantum version, the players still
    face it as they do in the traditional game.

In the quantum BoS the players’s expected payoffs are maximized when
their tactics consist of either both applying @xmath with certainty (
@xmath ) or both applying @xmath with certainty ( @xmath ). Marinatto
and Weber concluded that an entangled initial strategy @xmath ,
therefore, gives a unique solution in the game. Given that the players’
tactics are independent, the players are faced with a dilemma once again
in opting for ( @xmath ) or ( @xmath ). Mismatched tactics, i.e. (
@xmath ) or ( @xmath ), both lead to a worst-case situation.

Benjamin [ 70 ] also pointed out a difference in terminology. In
Marinatto and Weber’s set-up an initial strategy, in the form of a
quantum state, is forwarded to the players who then apply their tactics
to modify the state. In the Eisert et al.’s scheme, on the other hand,
players’ ‘moves’ are their manipulations, and their overall act of
choosing what move to play is their strategy.

Recently Nawaz and Toor [ 71 ] showed that by using a more general
initial quantum state the dilemma in the classical BoS can be resolved,
and a unique solution can be found.

#### 5.3.1 Marinatto and Weber’s reply

In a reply Marinatto and Weber [ 72 ] defended their choice of calling
strategies the quantum states instead of operators used to manipulate
them. They claimed that their choice is very natural and consistent with
the spirit of classical game theory, where at the start of a game each
player has at her disposal an ensemble of strategies.

Regarding Benjamin’s claim that the dilemma persists in quantum BoS
since players cannot decide between the two options, i.e. ( @xmath ) and
( @xmath ), Marinatto and Weber replied that the second option of doing
nothing ( @xmath ) amounts to the most rational behavior of the two
players. According to them no incentive exists for a player for doing
something (i.e. @xmath or @xmath ) because:

-   It cannot lead to a better payoff and each player knows that.

-   It only generates the extra risk of incurring a loss.

-   It is more expensive than doing nothing, in terms of resources
    needed to operate on the strategies.

#### 5.3.2 ‘Quantum form’ of a matrix game and initial quantum states

In Eisert et al.’s set-up when the parameter @xmath of the initial
quantum state is different from zero, the players’ payoffs are generally
non-classical, except for special moves available to them that can
result in the classical payoffs. Eisert et al. allow a range of values
to the parameter @xmath and found how it affects the equilibria of the
game.

Marinatto and Weber [ 52 ] forward an initial strategy to the two
players who then apply their ‘tactics’ on it. In their scheme the
classical game corresponds to the initial state @xmath .

Suppose the players receive pure two-qubit states, different from @xmath
, but the measurement uses the same payoff operators. The payoff
operators used in measurement in Marinatto and Weber’s scheme contains
all the information about what matrix game is being played. Given the
measurement apparatus remains the same, a ‘quantum form’ of the matrix
game can be obtained by only choosing among different initial states.
Hence, this approach translates the problem of finding a quantum form of
a matrix game to the problem of finding a pure initial state.

The approach should be seen from the view that the only restriction on a
‘quantum form’ of a game is that the corresponding classical game must
be reproducible as a special case. Because a product initial state
results in a classical game, therefore, the above approach is within the
mentioned restriction.

The Eisert et al.’s set-up suggests studying the behavior of equilibria
in relation to the parameter @xmath . The above approach, on the other
hand, suggests studying the behavior of equilibria in relation to
different pure initial states.

### 5.4 Enk and Pike’s comment on quantum Prisoners’ Dilemma

More recently Enk and Pike [ 73 ] have argued that the quantum solutions
of PD, found by Eisert et al. [ 20 ] , are neither quantum mechanical
nor do they solve the classical game. Their argument is based on the
observation that it is possible to capture the essence of quantized PD
by simply extending the payoff matrix of the classical game, by only
including an additional purely classical move corresponding to @xmath ,
which Eisert et al. obtained as a new quantum-mechanical ‘solution-move’
that could remove the dilemma inherent in the game. Enk and Pike
maintained that when Eisert’s quantum solution to PD can be
reconstructed in a classical way, the only defense that remains for its
quantum solution is its efficiency, which does not play a role in PD.

Enk and Pike also suggested that a quantum game that exploits
non-classical correlations in entangled states, similar to those that
violate the Bell’s inequality, should be worthy of investigation. Such
correlations are without a role in Eisert et al.’s set-up, and other
quantization procedures derived from it, even though entangled states
may be present. It is because various qubits, after their local unitary
manipulations, are brought together during the final stage of the game
to make the payoffs-generating measurement.

## Chapter 6 Evolutionary stability in quantum games

### 6.1 Introduction

As discussed in Section ( 2.7 ), the concept of an ESS was introduced in
classical game theory for two reasons:

1.  Two player games can have multiple Nash equilibria and ESS offers
    its refinement notion.

2.  Population biology problems can be modelled with the help of the ESS
    concept.

The reasons for claim that ( 1 ) holds for quantum as well as classical
games are not far from obvious. In our opinion the reason ( 2 ) also has
a meaning in a quantum context. Like NE, the ESS is a game-theoretic
concept. The concept assumes a population setting which is relevant to
problems in evolutionary biology. As a game-theoretic concept, the ESS
is equally worthy of investigation as the concept of NE is in relation
to quantization of games. The view that a population setting of
evolutionary biology can not be relevant in quantum games is based on
the assumption that the participants in a quantum game must always be
rational agents. We believe that when the rewards for players, forming a
population, not only depend on their individual moves but also on
whether the game they play is classical or quantum in nature, then the
concepts fundamentally developed for a population setting also become
relevant in a quantum context. As mentioned in the Section ( 2.7 ), John
Nash himself had a population setting in his mind when he introduced his
equilibrium notion. His equilibrium notion is well-known from the early
known studies in quantum games. The fact that a population setting was
behind the notion of a NE provides an almost natural relevance of this
setting for the quantum games as well. The idea of a population of
‘quantum players’ itself is not very much beyond imagination. Such a
population may, for example, consist of a large number of interacting
molecules where ‘decisions’ are taken in individual quantum
interactions. These interactions can easily be imagined pair-wise and
also random, which are the fundamental assumptions behind the concept of
an ESS.

In quantum setting the players’ payoffs become sensitive to quantum
affects. Which direction evolution drives the population of quantum
players now? The direction should, of course, be decided by the nature
of quantum affects.

### 6.2 Quantization as a refinement notion of Nash equilibrium?

Research in quantum games [ 20 , 52 ] has shown appearance of entirely
new equilibria on quantization of a game. The next logical question is
to ask whether quantization can provide another refinement to the NE
concept? Such a question is relevant in a situation where an equilibrium
is retained, whether the game is played classically or quantum
mechanically, but some property of the equilibrium changes during such a
switch-over. ESS, being a refinement notion of the NE concept, is a
symmetric NE with an extra property of stability against small
perturbations. We believe the question whether quantization can affect
stability of a symmetric NE is equally interesting as the question how
quantization leads to different equilibria.

### 6.3 Quantization changing evolutionary stability?

Our motivation is how game-theoretic models, of evolutionary dynamics in
a population, shape themselves in the new setting recently provided to
game theory by quantum mechanics? This motivation is, in a sense, a
portion of a bigger question: Can quantum mechanics have a role in
directing, or even dictating, the dynamics of evolution? To study
evolution in a quantum setting we have chosen the ESS concept firstly
for its beauty and simplicity. Secondly, because ESS is a
game-theoretical concept, the new developments in quantum games
themselves provide a motivation to look at the resulting effects on such
concepts. Following questions arise immediately:

-   How ESSs are affected when a classical game, played by a population,
    changes itself to one of its quantum forms?

-   How pure and mixed ESSs are distinguished from one another when such
    a change in the form of a game takes place?

And most importantly

-   How and if evolutionary dynamics can be related to quantum
    entanglement?

Imagine a population of players in which a classical strategy has
established itself as an ESS. We ask:

-   What happens when ‘mutants’ of ESS theory come up with quantum
    strategies and try to invade the classical ESS?

-   What happens if such an invasion is successful and a new ESS is
    established – an ESS that is quantum in nature?

-   Suppose afterwards another small group of mutants appears which is
    equipped with some other quantum strategy. Would it be successful
    now to invade the quantum ESS?

In the following we present an analysis based on these questions
considering a population in which symmetric pair-wise contests are
taking place.

In trying to extend an idea, originally proposed for problems in
population biology, to quantum domain we give an analysis using Eisert
et al.’s quantization of the symmetric bi-matrix game of PD.

### 6.4 ESSs in Eisert, Wilkens and Lewenstein’s scheme

For PD Cooperation ( @xmath ) and Defection ( @xmath ) are the pure
classical strategies. Which strategies are likely to be stable and
persistent when the game is played by a population engaged in pair-wise
contests? In each such contest PD is played. Straightforward analysis [
33 ] shows that @xmath will be the pure classical strategy prevalent in
the population and hence the classical ESS.

Eisert et al. used the matrix ( 2.2 ) in their quantum version of PD.
Assume a population setting where in each pair-wise encounter the
players play PD with the same matrix. Consider the following three
situations:

1.  A small group of mutants appear equipped with one-parameter quantum
    strategy @xmath when @xmath exists as a classical ESS.

2.  The mutants are equipped with two-parameter quantum strategy @xmath
    against the classical ESS.

3.  The mutants have successfully invaded and a two-parameter quantum
    strategy @xmath has established itself as a new quantum ESS. Again
    another small group of mutants appear, using some other
    two-parameter quantum strategy, and try to invade the quantum ESS,
    that is @xmath .

#### 6.4.1 Case (1)

In quantum PD with the matrix ( 2.2 ):

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

the players are anonymous and one can denote, for example, @xmath to
represent the payoff to @xmath -player against the @xmath -player. Here
@xmath is the Eisert et al.’s one-parameter quantum strategy set ( 4.16
). Players’ payoffs can be found as

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.2)
  -- -------- -------- -- -------

Now @xmath for all @xmath . Hence the first condition for an ESS holds
and @xmath is an ESS. The case @xmath corresponds to one-parameter
mutant strategy coinciding with the ESS, which is ruled out. If @xmath
is played by almost all the members of the population – which
corresponds to high frequency @xmath for @xmath – we then have @xmath
for all @xmath . The fitness of a one-parameter quantum strategy ¹ ¹ 1
In Eisert et al.’s set-up one-parameter quantum strategies correspond to
mixed (randomized) classical strategies. , therefore, cannot be greater
than that of a classical ESS. And a one-parameter quantum strategy
cannot invade a classical ESS.

#### 6.4.2 Case (2)

Let @xmath be a two-parameter strategy from the set ( 4.17 ). The
expected payoffs are

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
              @xmath      (6.3)
  -- -------- -------- -- -------

Here @xmath if @xmath and if @xmath then @xmath . Therefore @xmath is an
ESS if @xmath otherwise the strategy @xmath will be in position to
invade @xmath . Alternatively if most of the members of the population
play @xmath – meaning high frequency @xmath for @xmath – then the
fitness @xmath will remain greater than the fitness @xmath if @xmath .
For @xmath the strategy @xmath can invade the strategy @xmath , which is
the classical ESS.

In this analysis the possession of a richer strategy by the mutants
leads to invasion of @xmath when @xmath . Such an invasion may seem not
so unusual given the mutants exploiting richer strategies. But it leads
to the third case when ‘quantum mutants’ have successfully invaded and a
two-parameter strategy @xmath has established itself. Can now some new
mutants coming up with @xmath and invade the ‘quantum ESS’?

#### 6.4.3 Case (3)

Eisert et al. [ 20 , 46 ] showed that in their quantum PD the quantum
strategy @xmath , played by both the players, is the unique NE. How
mutants playing @xmath come up against @xmath which already exists as an
ESS? To find it following payoffs are obtained.

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.4)
  -- -------- -------- -- -------

Now the inequality @xmath holds for all @xmath and @xmath except when
@xmath and @xmath , which is the case when the mutant strategy @xmath is
the same as @xmath . This case is obviously ruled out. The first
condition for @xmath to be an ESS, therefore, holds. The condition
@xmath implies @xmath and @xmath . Again we have the situation of mutant
strategy same as @xmath and the case is neglected. If @xmath is played
by most of the players, meaning high frequency @xmath for @xmath , then
@xmath for all @xmath and @xmath . A two parameter quantum strategy
@xmath , therefore, cannot invade the quantum ESS (i.e. the strategy
@xmath ). Mutants’ access to richer strategies, as it happens in the
case (B), does not continue to be an advantage and most of the
population also have access to it. Hence @xmath comes out as the unique
NE and ESS of the game.

### 6.5 ESSs in Marinatto and Weber’s scheme

What happens to PD, from the point of view of evolutionary stability,
when it is played via Marinatto and Weber’s scheme [ 52 ] ? In our view
this scheme is more suitable for consideration of evolutionary stability
in quantum regime for the following reasons:

-   In a symmetric bi-matrix game, played in a population setting,
    players have access to two pure strategies. Players can also play a
    mixed strategy by combining the pure strategies with certain
    probabilities. In a similar way players in Marinatto and Weber’s
    scheme can be said to play a mixed strategy when they apply the two
    unitary operators, on the initial state, with a probabilistic
    combination.

-   Definition ( 2.21 ) of fitness of a pure strategy in evolutionary
    games [ 33 ] can be given a straightforward extension in Marinatto
    and Weber’s scheme. It corresponds to a situation when, in the
    quantum game, a player uses only one unitary operator out of the
    two.

-   Theory of ESSs, in the classical domain, deals with anonymous
    players possessing a discrete number of pure strategies. Eisert’s
    scheme involves players possessing a continuum of pure quantum
    strategies. The concept of an ESS as a stable equilibrium is
    confronted with problems [ 74 ] when players possess a continuum of
    pure strategies.

#### 6.5.1 Example of quantum Prisoners’ Dilemma

Assume the PD, defined by the matrix ( 6.1 ), is played with Marinatto
and Weber’s scheme. The initial state made available to the players is

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

where @xmath and @xmath . Payoffs to Alice and Bob can be found as

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      (6.6)
  -- -------- -------- -- -------

where @xmath and @xmath are the probabilities for Alice and Bob,
respectively, to act with the operator @xmath . We look for symmetric
Nash equilibria from the Nash inequalities while using only the
parameter @xmath of the initial state @xmath . For the state ( 6.5 ) the
game is reduced to the classical game when @xmath , i.e. when it is a
product state. Nash inequalities are then

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (6.7)
  -- -------- -------- -- -------

Here the parameter @xmath decides what should be the Nash equilibria of
the game. Three symmetric equilibria arise:

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.8)
  -- -------- -------- -- -------

The first two equilibria are independent of the parameter @xmath while
the third depends on it. We ask which of these equilibria are
evolutionary stable assuming that an equilibrium exists for initial
states of the form ( 6.5 ). Because the players play a symmetric game,
the payoff to a player using @xmath with probability @xmath , when
opponent uses it with the probability @xmath , can be written as

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (6.9)
  -- -------- -------- -- -------

which can also be identified as the payoff to the @xmath -player against
the @xmath -player. For the strategy pair @xmath one gets @xmath when
@xmath and @xmath imply @xmath . Also @xmath and @xmath . Now @xmath
when @xmath Therefore the pair @xmath is an ESS when @xmath .

For the pair @xmath we have @xmath which means @xmath if @xmath . And
@xmath means for @xmath we have @xmath . In such case @xmath and @xmath
. Now @xmath because @xmath for @xmath . Therefore @xmath is an ESS when
@xmath .

For the third pair, @xmath , we get @xmath . Also we find @xmath .
Hence, the condition @xmath holds and the pair @xmath is an ESS for
@xmath .

All three symmetric equilibria, definable for different ranges of @xmath
, are also ESSs. Each of the three sets of initial states @xmath give a
unique equilibrium which is an ESS too. Switching from one to the other
set of initial states also changes the equilibrium and ESS accordingly.

A question arises here: Is it possible that a particular equilibrium
switches-over between ‘ESS’ and ‘not ESS’ when the initial state changes
between some of its possible choices? The question is relevant given the
fact that transition between classical and quantum game is also achieved
by a change in the initial state: classical payoffs are obtained when
the initial state is a product state. It implies that it may be possible
for a symmetric NE to switch-over between being ‘ESS’ and being ‘not
ESS’ when a game changes between its ‘classical’ and ‘quantum’ forms.
This possibility makes the ESS concept interesting also from the point
of view of quantum games. Because the quantum PD, in the form considered
above, does not allow such a possibility, therefore, asymmetric
bi-matrix games are investigated now.

#### 6.5.2 ESSs in two-player two-strategy asymmetric games

ESS for an asymmetric bi-matrix game, i.e. @xmath when @xmath , is
defined as a strict NE [ 32 ] . A strategy pair @xmath is an ESS of the
game @xmath if it is a strict NE:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.10)
  -- -------- -------- -- --------

For example, consider BoS with the matrix:

  -- -------- -- --------
     @xmath      (6.11)
  -- -------- -- --------

where @xmath . It is a asymmetric game with three classical NE [ 52 ] :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.12)
  -- -------- -------- -- --------

The equilibria ( @xmath ) and ( @xmath ) are also ESS’s but ( @xmath )
is not because it is not a strict NE. The asymmetric game ( 6.11 )
played with an initial state @xmath , where @xmath and @xmath are
players’ pure classical strategies, has the following three Nash
equilibria [ 52 ] :

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Similar to the classical case, the equilibria ( @xmath ) and ( @xmath )
are ESSs while ( @xmath ) is not. First two ESSs do not depend on the
parameters @xmath and @xmath of the initial state while the third NE
does. Interestingly, playing BoS game with a different initial state:

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

changes the scene. The payoffs to Alice and Bob are:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      (6.15)
  -- -------- -------- -- --------

and there is only one NE i.e.

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

which is not an ESS. So that no ESS exists when BoS is played with the
state ( 6.14 ).

An essential requirement on a quantum version of a game is that the
corresponding classical game must be its subset. Suppose for a quantum
game, corresponding to an asymmetric bi-matrix classical game, a
particular strategy pair @xmath is an ESS for all initial states @xmath
given in some particular form. That is, it remains an ESS for all @xmath
and @xmath when @xmath is given in terms of @xmath and @xmath . Because
classical game is a subset of the quantum game, the strategy pair @xmath
must then also be an ESS in the classical game. On the other hand a
strategy pair @xmath which is an ESS in a classical game may not remain
so in its quantum version.

Quantization of an asymmetric classical game can thus make disappear the
classical ESSs but it cannot make appear new ESSs, provided an ESS in
quantum version remains so for every possible choice of the parameters
@xmath and @xmath . However when an ESS is defined as a strict NE
existing only for a set of initial states for which that NE exists, the
statement that quantization can only make disappear classically
available ESSs may not remain valid. In such a case quantization may
make appear new ESSs definable for certain ranges of the parameters
@xmath and @xmath .

To find games with the property that a particular NE switches over
between ‘ESS’ and ‘not ESS’ when the initial state changes between its
possible choices, we now look at the following asymmetric quantum game:

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

For the initial state @xmath the players’ payoffs are:

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      (6.19)
  -- -------- -------- -- --------

The NE conditions are

  -- -------- -- --------
     @xmath      
     @xmath      (6.20)
     @xmath      
     @xmath      (6.21)
  -- -------- -- --------

Let now @xmath be a NE:

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

When the strategy pair @xmath is an ESS in the classical game @xmath
i.e. @xmath we should have

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.23)
  -- -------- -------- -- --------

It implies @xmath and @xmath .

For the pair @xmath to be not an ESS for some @xmath , let take @xmath
and @xmath . We have

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.24)
  -- -------- -------- -- --------

and the pair @xmath doesn’t remain an ESS at @xmath . A game with these
properties is given by the matrix:

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

For this game the pair @xmath is an ESS when @xmath (classical game) but
it is not when for example @xmath , though it remains a NE in both the
cases. The example shows a NE can be switched between ESS and ‘not ESS’
by adjusting the parameters @xmath and @xmath of the initial state.
Opposite to the previous case, the initial states - different from the
one corresponding to the classical game - can also make a strategy pair
an ESS. An example of a game for which it happens is

  -- -------- -- --------
     @xmath      (6.26)
  -- -------- -- --------

Playing this game again via @xmath gives the following payoff
differences for the strategy pair @xmath :

  -- -------- -- --------
     @xmath      (6.27)
  -- -------- -- --------

for Alice and Bob respectively. Therefore ( 6.26 ) is an example of a
game for which the pair @xmath is not an ESS when the initial state
corresponds to the classical game. But the pair is an ESS for other
initial states for which @xmath .

#### 6.5.3 ESSs in two-player two-strategy symmetric games

To explore a possible relation between evolutionary stability and
quantization consider the following symmetric bi-matrix game:

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

which is played by an initial state:

  -- -------- -- --------
     @xmath      (6.29)
  -- -------- -- --------

Let Alice’s strategy consists of applying the identity operator @xmath
with probability @xmath and the operator @xmath with probability @xmath
, on the initial state written @xmath in density matrix notation.
Similarly Bob applies the operators @xmath and @xmath with the
probabilities @xmath and @xmath respectively. The final state is

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

where unitary and Hermitian operator @xmath is either @xmath or @xmath .
@xmath , @xmath are the probabilities, for Alice and Bob respectively,
to apply the operator on the initial state. The matrix @xmath is
obtained from @xmath by a convex combination of players’ possible
quantum operations. Payoff operators for Alice and Bob are [ 52 ]

  -- -- -- --------
           (6.31)
  -- -- -- --------

The payoffs are then obtained as mean values of these operators i.e.
@xmath Tr @xmath . Because the quantum game is symmetric with the
initial state ( 6.29 ) and the payoff matrix ( 6.28 ), there is no need
for subscripts. We can , then, write the payoff to a @xmath -player
against a @xmath -player as @xmath , where the first number is the focal
player’s move. When @xmath is a NE we find the following payoff
difference:

  -- -------- -- --------
     @xmath      
     @xmath      (6.32)
  -- -------- -- --------

Now the ESS conditions for the pure strategy @xmath are given as

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      (6.33)
  -- -------- -- --------

where @xmath is the NE condition. Similarly the ESS conditions for the
pure strategy @xmath are

  -- -------- -- --------
     @xmath      
     @xmath      
                 (6.34)
  -- -------- -- --------

Because these conditions, for both the pure strategies @xmath and @xmath
, depend on @xmath , therefore, there can be examples of two-player
symmetric games for which the evolutionary stability of pure strategies
can be changed while playing the game using initial state in the form
@xmath . However, for the mixed NE, given as @xmath , the corresponding
payoff difference ( 6.32 ) becomes identically zero. From the second
condition of an ESS we find for the mixed NE @xmath the difference

  -- -------- -- --------
     @xmath      
     @xmath      (6.35)
  -- -------- -- --------

Therefore, the mixed strategy @xmath is an ESS when @xmath . This
condition, making the mixed NE @xmath an ESS, is independent ² ² 2 An
alternative possibility is to adjust @xmath = @xmath which makes the
difference @xmath identically zero. The mixed strategy @xmath then does
not remain an ESS. However such ‘mutant dependent’ adjustment of @xmath
is not reasonable because the mutant strategy @xmath can be anything in
the range @xmath . of @xmath . So that, in this symmetric two-player
quantum game, evolutionary stability of the mixed NE @xmath can not be
changed when the game is played using initial quantum states of the form
( 6.29 ).

However, evolutionary stability of pure strategies can be affected, with
this form of the initial states, for two-player symmetric games.
Examples of the games with this property are easy to find. The class of
games for which @xmath and @xmath the strategies @xmath and @xmath
remain NE for all @xmath ; but the strategy @xmath is not an ESS when
@xmath and the strategy @xmath is not an ESS when @xmath .

##### An example

Consider the symmetric bi-matrix game ( 6.28 ) with the constants @xmath
satisfying the conditions:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.36)
  -- -------- -------- -- --------

The condition making @xmath a NE is given by ( 6.32 ). For this game
three Nash equilibria arise i.e. two pure strategies @xmath , @xmath ,
and one mixed strategy @xmath . These three cases are considered below.

###### Case @xmath

For the strategy @xmath to be a NE one requires

  -- -------- -- --------
     @xmath      (6.37)
  -- -------- -- --------

and the difference @xmath when @xmath . In this range of @xmath the
equilibrium @xmath is a pure ESS. However, when @xmath we have the
difference @xmath identically zero. The strategy @xmath can be an ESS if

  -- -------- -- --------
     @xmath      
     @xmath      (6.38)
  -- -------- -- --------

that can be written as

  -- -------- -- --------
     @xmath      (6.39)
  -- -------- -- --------

where @xmath when @xmath The strategy @xmath can be an ESS only when
@xmath which is not possible because @xmath is fixed at @xmath Therefore
the strategy @xmath is an ESS for @xmath and for @xmath this NE becomes
unstable. The classical game is obtained by taking @xmath for which
@xmath is an ESS or a stable NE. However this NE does not remain stable
for @xmath which corresponds to an entangled initial state; though the
NE remains intact in both forms of the game.

###### Case @xmath

Similar to the last case the NE condition for the strategy @xmath can be
written as

  -- -- -- --------
           (6.40)
  -- -- -- --------

Now @xmath is a pure ESS for @xmath . For @xmath the difference @xmath
becomes identically zero. The strategy @xmath is an ESS when

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

It is possible only if @xmath Therefore the strategy @xmath is a stable
NE (ESS) for @xmath It is not stable classically (i.e. for @xmath ) but
becomes stable for an entangled initial state.

###### Case @xmath

In case of the mixed strategy:

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

the NE condition ( 6.32 ) turns into

  -- -------- -- --------
     @xmath      (6.43)
  -- -------- -- --------

The mixed strategy ( 6.42 ) can be an ESS if

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

for all @xmath . Write now the strategy @xmath as @xmath . For the mixed
strategy ( 6.42 ) the payoff difference of the Eq. (
LABEL:Difference3Symmetric ) is reduced to

  -- -------- -- --------
     @xmath      (6.45)
  -- -------- -- --------

Hence, for the game defined in the conditions ( 6.36 ), the mixed
strategy @xmath cannot be an ESS, though it can be a NE of the symmetric
game.

It is to be pointed out that above considerations apply when the game is
played with the initial state ( 6.29 ).

To find examples of symmetric quantum games, where evolutionary
stability of the mixed strategies may also be affected by controlling
the initial states, the number of players are now increased from two to
three.

#### 6.5.4 ESSs in three-player two-strategy symmetric games

In extending the two-player scheme to a three-player case, we assume
that three players @xmath and @xmath play their strategies by applying
the identity operator @xmath with the probabilities @xmath and @xmath
respectively on the initial state @xmath . Therefore, they apply the
operator @xmath with the probabilities @xmath and @xmath respectively.
The final state becomes

  -- -------- -- --------
     @xmath      (6.46)
  -- -------- -- --------

where the @xmath basis vectors are @xmath , for @xmath . Again we use
initial quantum state in the form @xmath , where @xmath . It is a
quantum state in @xmath dimensional Hilbert space that can be prepared
from a system of three two-state quantum systems or qubits. Similar to
the two-player case, the payoff operators for the players @xmath @xmath
and @xmath can be defined as

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (6.47)
  -- -------- -- --------

where @xmath for @xmath are @xmath constants of the matrix of this
three-player game. Payoffs to the players @xmath and @xmath are then
obtained as mean values of these operators

  -- -------- -- --------
     @xmath      (6.48)
  -- -------- -- --------

Here, similar to the two-player case, the classical payoffs can be
obtained by making the initial quantum state unentangled and fixing
@xmath . To get a symmetric game we define @xmath as the payoff to
player @xmath when players @xmath , @xmath , and @xmath play the
strategies @xmath , @xmath , and @xmath respectively. With following
relations the players’ payoffs become identity-independent.

  -- -------- -- --------
     @xmath      
     @xmath      (6.49)
  -- -------- -- --------

The players in the game then become anonymous and their payoffs depend
only on their strategies. The relations ( 6.49 ) hold with the following
replacements for @xmath and @xmath :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.50)
  -- -------- -------- -- --------

Also, it is now necessary that we should have

  -- -------- -- --------
     @xmath      (6.51)
  -- -------- -- --------

A symmetric game between three players, therefore, can be defined by
only six constants of the payoff matrix. These constants can be taken as
@xmath and @xmath . Payoff to a @xmath -player, when other two players
play @xmath and @xmath , can now be written as @xmath . A symmetric NE
@xmath is now found from the Nash condition @xmath i.e.

  -- -------- -- --------
     @xmath      
     @xmath      (6.52)
  -- -------- -- --------

where

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.53)
  -- -------- -------- -- --------

Three possible NE are found as

  -- -------- -- --------
     @xmath      (6.54)
  -- -------- -- --------

It is observed that the mixed NE @xmath makes the difference @xmath
identically zero and two values for @xmath can be found for a given
@xmath . Apart from @xmath the other two NE (i.e. @xmath and @xmath )
are pure strategies. Also now @xmath comes out a NE without imposing
further restrictions on the matrix of the symmetric three-player game.
However, the pure strategies @xmath and @xmath can be NE when further
restriction are imposed on the matrix of the game. For example, @xmath
can be a NE provided @xmath for all @xmath . Similarly @xmath can be NE
when @xmath .

Now we address the question: How evolutionary stability of these three
NE can be affected while playing the game via initial quantum states
given in the following form?

  -- -------- -- --------
     @xmath      (6.55)
  -- -------- -- --------

For the two-player asymmetric game of BoS we showed that out of three NE
only two can be evolutionary stable. In classical evolutionary game
theory the concept of an ESS is well-known [ 75 , 76 ] to be extendable
to multi-player case. When mutants are allowed to play only one strategy
the definition of an ESS for the three-player case is written as [ 75 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.56)
  -- -------- -------- -- --------

Here @xmath is a NE if it satisfies the condition @xmath against all
@xmath . For our case the ESS conditions for the pure strategies @xmath
and @xmath can be written as follows. For example @xmath is an ESS when

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.57)
  -- -------- -------- -- --------

where @xmath is NE condition for the strategy @xmath . Similarly @xmath
is an ESS when

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath               (6.58)
  -- -------- -------- -- --------

and both the pure strategies @xmath and @xmath are ESSs when @xmath .
The conditions ( 6.58 ) can also be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.59)
  -- -------- -------- -- --------

For the strategy @xmath the ESS conditions ( 6.57 ) reduce to

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.60)
  -- -------- -------- -- --------

Examples of three-player symmetric games are easy to find for which a
pure strategy is a NE for the whole range @xmath , but it is not an ESS
for some particular value of @xmath . An example of a class of such
games is for which @xmath , @xmath , and @xmath . In this class the
strategy @xmath is a NE for all @xmath but not an ESS when @xmath .

Apart from the pure strategies, the mixed strategy equilibrium @xmath
forms the most interesting case. It makes the payoff difference @xmath
identically zero for every strategy @xmath . The strategy @xmath is an
ESS when @xmath but

  -- -------- -- --------
     @xmath      
     @xmath      (6.61)
  -- -------- -- --------

Therefore, out of the two possible roots @xmath and @xmath of the
quadratic equation ³ ³ 3 These roots make the difference @xmath greater
than and less than zero, respectively. :

  -- -------- -- --------
     @xmath      
     @xmath      (6.62)
  -- -------- -- --------

only @xmath can exist as an ESS. When the square root term in the
equation ( 6.61 ) becomes zero we have only one mixed NE, which is not
an ESS. Hence, out of four possible NE in this three-player game only
three can be ESSs.

An interesting class of three-player games is the one for which @xmath .
For these games the mixed NE are

  -- -------- -- --------
     @xmath      (6.63)
  -- -------- -- --------

and, when played classically, we can get only one mixed NE that is not
an ESS. However for all @xmath , different from zero, we generally
obtain two NE out of which one can be an ESS.

Similar to the two-player case, the equilibria in a three-player
symmetric game where quantization affects evolutionary stability, are
the ones that survive for two initial states, one of which is
unentangled and corresponds to the classical game. Suppose @xmath
remains a NE for @xmath and some other non-zero @xmath . It is possible
when

  -- -------- -- --------
     @xmath      (6.64)
  -- -------- -- --------

Alternatively the strategy @xmath remains a NE for all @xmath . It
reduces the defining quadratic equation ( 6.62 ) for @xmath to

  -- -------- -- --------
     @xmath      (6.65)
  -- -------- -- --------

and makes the difference @xmath independent of @xmath . Therefore the
strategy @xmath , even when it is retained as an equilibrium for all
@xmath , cannot be an ESS in only one version of the symmetric
three-player game. For the second possibility @xmath the defining
equation for @xmath is reduced to

  -- -------- -- --------
     @xmath      (6.66)
  -- -------- -- --------

for which

  -- -------- -- --------
     @xmath      (6.67)
  -- -------- -- --------

Here the difference @xmath still depends on @xmath and becomes zero for
@xmath .

Hence, for the class of games for which @xmath and @xmath , one of the
mixed strategies @xmath remains a NE for all @xmath but not an ESS when
@xmath . In this class of three-player quantum games the evolutionary
stability of a mixed strategy can, therefore, be changed while the game
is played using initial quantum states in the form ( 6.55 ).

### 6.6 Quantum Rock-Scissors-Paper game

Long played as a children’s pastime, or as an odd-man-out selection
process, the Rock-Scissors-Paper (RSP) is a game for two players
typically played using the players’ hands. The players opposite each
others, tap their fist in their open palm three times (saying Rock,
Scissors, Paper) and then show one of three possible gestures. The Rock
wins against the scissors (crushes it) but looses against the paper (is
wrapped into it). The Scissors wins against the paper (cuts it) but
looses against the rock (is crushed by it). The Paper wins against the
rock (wraps it) but looses against the scissors (is cut by it). The game
is also played in nature like many other games. Lizards in the Coast
Range of California play this game [ 77 ] using three alternative male
strategies locked in an ecological never ending process from which there
seems little escape.

#### 6.6.1 Rock-Scissors-Paper in a slightly modified version

In a slightly modified version of the RSP game both players get a small
premium @xmath for a draw. This game can be represented by the payoff
matrix:

  -- -- -- --------
           (6.68)
  -- -- -- --------

where @xmath . The matrix of the usual game is obtained when @xmath is
zero.

#### 6.6.2 Nash equilibrium and ESS in Rock-Scissors-Paper game

One cannot win if one’s opponent knew which strategy was going to be
picked. For example, picking Rock consistently all the opponent needs to
do is pick Paper and s/he would win. Players find soon that in case
predicting opponent’s strategy is not possible the best strategy is to
pick Rock, Scissors, or Paper at random. In other words, the player
selects Rock, Scissors, or Paper with a probability of @xmath . In case
opponent’s strategy is predictable picking a strategy at random with a
probability of @xmath is not the best thing to do unless the opponent is
doing the same [ 33 ] .

Analysis [ 32 ] of the modified RSP game of matrix ( 6.68 ) shows that
its NE consists of playing each of the three different pure strategies
with a fixed equilibrial probability @xmath . However it is not an ESS
because @xmath is negative.

Here we want to study the effects of quantization on evolutionary
stability for the modified RSP game. The game is different, from others
considered earlier, because classically each player now possesses three
pure strategies instead of two. A classical mixed NE exists which is not
an ESS. Our motivation is to explore the possibility that the classical
mixed NE becomes an ESS for some quantum form of the game.

#### 6.6.3 Quantization of Rock-Scissors-Paper game

Using simpler notation: @xmath @xmath @xmath we quantize this game via
Marinatto and Weber’s scheme [ 52 ] . We assume the two players are in
possession of three unitary and Hermitian operators @xmath and @xmath
defined as follows.

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.69)
  -- -------- -------- -- --------

where @xmath and @xmath and @xmath is the identity operator.

Consider a general two-player payoff matrix when each player has three
strategies:

  -- -- -- --------
           (6.70)
  -- -- -- --------

where @xmath and @xmath are the payoffs to Alice and Bob, respectively,
when Alice plays @xmath and Bob plays @xmath and @xmath . Suppose Alice
and Bob apply the operators @xmath , @xmath , and @xmath with the
probabilities @xmath , @xmath , @xmath and @xmath , @xmath , @xmath
respectively. The initial state of the game is @xmath . Alice’s move
changes the state changes to

  -- -------- -- --------
     @xmath      (6.71)
  -- -------- -- --------

The final state, after Bob too has played his move, is

  -- -------- -- --------
     @xmath      (6.72)
  -- -------- -- --------

This state can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (6.73)
  -- -------- -------- -- --------

The nine basis vectors of initial quantum state with three pure
classical strategies are @xmath for @xmath . We consider the initial
state to be a pure quantum state of two qutrits i.e.

  -- -- -- --------
           (6.74)
  -- -- -- --------

The payoff operators for Alice and Bob are [ 52 ]

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

The players’ payoffs are then

  -- -------- -- --------
     @xmath      (6.76)
  -- -------- -- --------

Payoff to Alice, for example, can be written as

  -- -------- -- --------
     @xmath      (6.77)
  -- -------- -- --------

where @xmath is for transpose, and the matrices @xmath @xmath and @xmath
are

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
     @xmath            
     @xmath            
  -- -------- -------- --

The payoff ( 6.77 ) corresponds to the matrix ( 6.70 ). Payoffs in
classical mixed strategy game can be obtained from Eq. ( 6.76 ) for the
initial state @xmath . The game is symmetric when @xmath in the matrix (
6.70 ). The quantum game played using the quantum state ( 6.74 ) is
symmetric when @xmath for all constants @xmath in the state ( 6.74 ).
These two conditions together guarantee a symmetric quantum game. The
players’ payoffs @xmath , @xmath then do not need a subscript and we can
simply use @xmath to denote the payoff to the @xmath -player against the
@xmath -player.

The question of evolutionary stability in quantized RSP game is
addressed below.

#### 6.6.4 Consideration of evolutionary stability

Assume a strategy is defined by a pair of numbers @xmath for players
playing the quantized RSP game. These numbers are the probabilities with
which the player applies the operators @xmath and @xmath . The identity
operator @xmath is, then, applied with probability @xmath . Similar to
the conditions @xmath and @xmath in Eq. ( 2.20 ), the conditions making
a strategy @xmath an ESS can be written as [ 29 , 32 ]

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.79)
  -- -------- -------- -- --------

Suppose @xmath is a mixed NE then

  -- -------- -- --------
     @xmath      (6.80)
  -- -------- -- --------

Using substitutions

  -- -------- -- --------
     @xmath      (6.81)
  -- -------- -- --------

we get

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (6.82)
  -- -------- -------- -- --------

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (6.83)
  -- -------- -------- -- --------

For the matrix ( 6.68 ) the equations ( 6.82 , 6.83 ) can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (6.84)
     @xmath   @xmath      
              @xmath      (6.85)
  -- -------- -------- -- --------

The payoff difference in the second condition of an ESS given in the Eq.
( 6.79 ) reduces to

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (6.86)
  -- -------- -- --------

With the substitutions @xmath and @xmath the above payoff difference is

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      (6.87)
  -- -------- -- --------

provided

  -- -------- -- --------
     @xmath      (6.88)
  -- -------- -- --------

The conditions in Eq. ( 6.88 ) together define the mixed NE @xmath .
Consider now the modified RSP game in classical form obtained by setting
@xmath . The Eqs. ( 6.88 ) become

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (6.89)
  -- -------- -------- -- --------

and @xmath is obtained as a mixed NE for all the range @xmath . From Eq.
( 6.87 ) we get

  -- -------- -- --------
     @xmath      
     @xmath      (6.90)
  -- -------- -- --------

In the classical RSP game, therefore, the mixed NE @xmath is a NE but
not an ESS, because the second condition of an ESS given in the Eq. (
6.79 ) does not hold.

Now define a new initial state as

  -- -------- -- --------
     @xmath      (6.91)
  -- -------- -- --------

and use it to play the game, instead of the classical game obtained from
@xmath . The strategy @xmath still forms a mixed NE because the
conditions ( 6.88 ) hold true for it. However the payoff difference of
Eq. ( 6.87 ) is now given below, when @xmath and @xmath :

  -- -------- -- --------
     @xmath      
     @xmath      (6.92)
  -- -------- -- --------

Therefore the mixed NE @xmath , not existing as an ESS in the classical
form of the RSP game, becomes an ESS when the game is quantized and
played using an initial (entangled) quantum state given by the Eq. (
6.91 ).

Note that from Eq. ( 6.76 ) the sum of the payoffs to Alice and Bob
@xmath can be obtained for both the classical mixed strategy game (i.e.
when @xmath ) and the quantum game played using the quantum state of Eq.
( 6.91 ). For the matrix ( 6.68 ) we write these sums as @xmath and
@xmath for classical mixed strategy and quantum games respectively. We
obtain

  -- -------- -- --------
     @xmath      (6.93)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (6.94)
  -- -------- -- --------

In case @xmath both the classical and quantum games are clearly zero
sum. For the slightly modified version of the RSP game we have @xmath
and both versions of the game become non zero-sum.

### 6.7 Stability of a mixed Nash equilibrium

In a classical symmetric bi-matrix game, played in an evolutionary set
up involving a population, all the members of the population are
indistinguishable and each individual is equally likely to face the
other. In such a set-up individuals interact only in pair-wise
encounters.

Assume a finite set of pure strategies @xmath is available to each
player. In one pair-wise encounter let a player @xmath receives a reward
@xmath by playing strategy @xmath against another player @xmath playing
strategy @xmath . In symmetric situation the player @xmath , then, gets
@xmath as a reward. The value @xmath is an element in the @xmath payoff
matrix @xmath . We assume that the players also have an option to play a
mixed strategy. It means he/she plays the strategy @xmath with
probability @xmath for all @xmath A strategy vector @xmath with
components @xmath represents the mixed strategy played by the player. In
standard notation an average, or expected, payoff for player @xmath
playing strategy @xmath against player @xmath playing @xmath is written
as @xmath [ 78 ] :

  -- -------- -- --------
     @xmath      (6.95)
  -- -------- -- --------

where @xmath is for transpose.

In evolutionary game theory mixed strategies play a significant role.
The well-known Bishop-Cannings theorem (BCT) [ 79 ] describes an
interesting property of mixed ESSs in symmetric bi-matrix games.
Introducing the concept of support of an ESS is helpful to understand
the BCT [ 78 , 80 ] . Suppose a strategy vector @xmath is an ESS. Its
support @xmath is the set @xmath . Hence the support of @xmath is the
set of pure strategies that can be played by a @xmath -player. BCT
states that if @xmath is an ESS with support I and @xmath @xmath is an
ESS with support @xmath , then @xmath @xmath @xmath . For bi-matrix
games the BCT shows that no pure strategy can be evolutionary stable
when a mixed ESS exists [ 78 ] . Naturally one, then, asks about the
classical pure ESSs when a switch-over to a quantum form of a classical
symmetric bi-matrix game also gives evolutionary stability to a mixed
symmetric NE.

Following the approach developed for quantum RSP game, we now consider a
general form of a two-qubit initial quantum state. Our results show that
for this form of the initial quantum state, the corresponding quantum
version of a bi-matrix game can give evolutionary stability to a mixed
symmetric NE when classically it is not stable. It is interesting to
observe that by ensuring evolutionary stability to a mixed NE in a
quantum form of the game, the BCT forces out the pure ESSs present in
classical form of the game.

The payoff to a player in the quantized version of the RSP game can also
be written in similar form to ( 6.95 ), provided the matrix @xmath is
replaced with a matrix corresponding to quantum version of this game.

For example, Alice’s payoff, who plays the strategy @xmath (where @xmath
@xmath @xmath ) against Bob who plays the strategy @xmath (where @xmath
@xmath @xmath ), can be written as

  -- -------- -- --------
     @xmath      (6.96)
  -- -------- -- --------

where the matrix @xmath is given by

  -- -------- -- --------
     @xmath      (6.97)
  -- -------- -- --------

and the elements of @xmath are given by the following matrix equation

  -- -------- --
     @xmath   
     @xmath   
              
  -- -------- --

The matrix ( 6.97 ) reduces to its classical form ( 6.70 ) by fixing
@xmath .

In a symmetric game the exchange of strategies by Alice and Bob also
exchanges their respective payoffs. The quantum game corresponding to
the matrix ( 6.70 ), when played using the initial quantum state of Eq.
( 6.74 ), becomes symmetric when

  -- -------- -- --------
     @xmath      (6.99)
  -- -------- -- --------

The two-player quantum game, with three pure strategies, gets a form
similar to a classical matrix game. The payoff matrix of the classical
game, however, is replaced with its quantum version ( 6.97 ). Also the
matrix ( 6.97 ) now involves the coefficients @xmath of the initial
quantum state ( 6.74 ).

To reduce the above mathematical formalism to two-player, two-strategy
quantum game lets fix @xmath , that is, both players do not use the
operator @xmath at all, and apply only the operators @xmath and @xmath
on the initial quantum state. Payoff to the player who plays the
strategy vector @xmath (where @xmath @xmath ) against the player who
plays the strategy vector @xmath (where @xmath @xmath ) can again be
written as @xmath . Nevertheless, @xmath is reduced to its simpler form:

  -- -------- -- ---------
     @xmath      (6.100)
  -- -------- -- ---------

where elements of the matrix are

  -- -------- -- ---------
     @xmath      (6.101)
  -- -------- -- ---------

It becomes a bi-matrix game played with the initial quantum state ( 6.74
). The available pure strategies are @xmath and @xmath only and the
terms with subscripts containing @xmath disappear. Take @xmath and
@xmath so that @xmath and @xmath are probabilities with which players
apply identity operator on the initial state @xmath . The strategy
vectors @xmath and @xmath can now be represented only by the numbers
@xmath and @xmath , respectively. Payoff to a @xmath -player against a
@xmath -player is then obtained as

  -- -------- -- ---------
     @xmath      (6.102)
  -- -------- -- ---------

Suppose @xmath is a NE, i.e.

  -- -------- -- ---------
     @xmath      
     @xmath      (6.103)
  -- -------- -- ---------

for all @xmath . The mixed strategy @xmath makes the payoff difference
@xmath identically zero. The subscript @xmath is for ‘quantum’. Let
@xmath then

  -- -------- -- ---------
     @xmath      (6.104)
  -- -------- -- ---------

Now @xmath is an ESS if @xmath for all @xmath , which leads to the
requirement @xmath

The classical game corresponds when @xmath and it gives @xmath , @xmath
@xmath , and @xmath , in accordance with the Eq. ( LABEL:QMatrix1Mixed )
@xmath In case @xmath , the mixed NE of a classical game, i.e. @xmath ,
is not an ESS. Here the subscript @xmath is for ‘classical’. Since we
look for a situation where evolutionary stability of a symmetric NE
changes — while the corresponding NE remains intact — in a switch-over
of the game from its classical to quantum form, lets take

  -- -------- -- ---------
     @xmath      (6.105)
  -- -------- -- ---------

saying that the classical NE @xmath is also a NE in quantum form of the
game. Now from the matrix in the Eq. ( 6.101 )

  -- -------- -- ---------
     @xmath      
                 (6.106)
  -- -------- -- ---------

and

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (6.107)
  -- -------- -------- -- ---------

A substitution from Eqs. ( 6.106 , 6.107 ) into the Eq. ( 6.105 ) gives
@xmath , and this leads to @xmath . Therefore the mixed strategy @xmath
remains a NE in both the classical and quantum form of the game.
Consider this mixed NE for a classical game with @xmath , a condition
that assures that it is not an ESS. The Eq. ( 6.106 ) shows an
interesting possibility that one can have @xmath if

  -- -------- -- ---------
     @xmath      (6.108)
  -- -------- -- ---------

In other words, the evolutionary stability of a mixed strategy, which is
a NE in both classical and quantum versions of the game, changes when
the game switches-over between its two forms. To have a symmetric game
also in its quantum form we need @xmath , which reduces the inequality (
6.108 ) to @xmath .

Hence, a quantum version of a symmetric bi-matrix classical game with
the matrix:

  -- -------- -- ---------
     @xmath      (6.109)
  -- -------- -- ---------

can be played if both the players have access to two unitary and
Hermitian operators and the game starts with a two-qubit quantum state
of the form:

  -- -------- -- ---------
     @xmath      (6.110)
  -- -------- -- ---------

where @xmath . In case @xmath the mixed strategy @xmath is not an ESS in
the classical game if @xmath . Nevertheless, the strategy @xmath becomes
an ESS when @xmath . In case @xmath the strategy @xmath is an ESS
classically but does not remain so if again @xmath . Now suppose @xmath
, the Eq. ( 6.106 ) reduces to

  -- -------- -- ---------
     @xmath      (6.111)
  -- -------- -- ---------

It is observed from the equation ( 6.111 ) that if a quantum game is
played by the following simple form of the initial quantum state:

  -- -------- -- ---------
     @xmath      (6.112)
  -- -------- -- ---------

then it is not possible to influence the evolutionary stability of a
mixed NE.

#### 6.7.1 Discussion

Mixed ESSs appear in many games of interest that are played in the
natural world. The examples of the RSP and Hawks and Doves games are
well known from evolutionary game theory. The Bishop-Cannings theorem of
evolutionary game theory does not permit pure ESSs when a mixed ESS
exists in a population engaged in a bi-matrix game. The possibility of
changing evolutionary stability of a pure symmetric NE has been
considered earlier with normalized states of the form @xmath . Using
such initial states, however, cannot change evolutionary stability of a
mixed strategy. In this section, following an approach developed for the
quantum RSP game, we play a bi-matrix game with a general two-qubit pure
initial quantum state. Such state allows changing evolutionary stability
of a mixed NE. For a bi-matrix game a symmetric mixed NE is found that
remains intact in both the classical and quantum versions of the game.
For this mixed NE conditions are then found allowing the change of
evolutionary stability with a switch-over of the game, between its two
forms, one classical and the other quantum.

### 6.8 Equilibria of replicator dynamics in quantum games

#### 6.8.1 Introduction

Maynard Smith and Price [ 29 ] introduced the idea of an ESS essentially
as a static concept. Nothing in the definition of an ESS guarantees that
the dynamics of evolution in small mutational steps will necessarily
converge the process of evolution to an ESS. In fact directional
evolution may also become responsible for the establishment of
strategies that are not evolutionary stable [ 36 ] .

What are the advantages involved in a dynamic approach towards theory of
ESSs? A stated reason [ 82 ] is that dynamic approach introduces
structural stability into game theory. Historically Liapunov provided a
classic definition of stability of equilibria for general dynamical
systems. This definition can also be adapted for the stability of a NE.
A pair of strategies @xmath is Liapunov stable when for every trajectory
starting somewhere in a small neighborhood of radius @xmath around a
point representing the pair @xmath another small neighborhood of radius
@xmath can be defined such that the trajectory stays in it. When every
trajectory starting in a small neighborhood of radius @xmath around the
point @xmath converges to @xmath the strategy pair @xmath becomes an
attractor . Trajectories are defined by the dynamics underlying the
game.

Taylor and Jonker [ 34 ] introduced a dynamics into evolutionary games
with the hypothesis that the growth rate of those playing each strategy
is proportional to the advantage of that strategy. This hypothesis is
now understood as one of many different forms of replicator dynamics [
36 , 83 ] . In simple words assume that @xmath is the frequency (i.e.
relative proportion) of the individuals using strategy @xmath and @xmath
, where @xmath and @xmath is the transpose, is a vector whose components
are the frequencies with @xmath . Let @xmath be the average payoff for
using @xmath when the population is in the state @xmath . Let @xmath be
the average success in the population. The replicator equation is, then,
written as [ 84 ]

  -- -------- -- ---------
     @xmath      (6.113)
  -- -------- -- ---------

where the dot is derivative with respect to time. Let the payoff matrix
be @xmath with @xmath being the average payoff for strategy @xmath when
the other player uses @xmath . The average payoff for the strategy
@xmath in the population (with the assumption of random encounters of
the individuals) is @xmath and the Eq. ( 6.113 ) becomes

  -- -------- -- ---------
     @xmath      (6.114)
  -- -------- -- ---------

The population state is then given as a point in @xmath simplex @xmath [
85 ] . The hypothesis of Taylor and Jonker [ 34 ] gives a flow on @xmath
whose flow lines represent the evolution of the population. In
evolutionary game theory it is agreed [ 32 ] that every ESS is an
attractor of the flow defined on @xmath by the replicator equation (
6.113 ), however, the converse does not hold: an attractor is not
necessarily an ESS.

Our motivation is to find how equilibria of replicator dynamics are
affected when a matrix game played by a population is quantized. It
should, of course, be sensitive to quantization procedure selected for
the matrix game. We find the effects when the matrix game is quantized
via Marinatto and Weber’s scheme.

#### 6.8.2 Equilibria and attractors of replicator dynamics

Early studies about the attractors of replicator dynamic by Schuster,
Sigmund and Wolff [ 86 , 87 ] reported the dynamics of enzymatic actions
of chemicals in a mixture when their relative proportions could be
changed. For example, in the case of a mixture of three chemicals added
in a correct order, such that corresponding initial conditions are in
the basin of an interior attractor, it becomes a stable cooperative
mixture of all three chemicals. But if they are added in a wrong order
the initial conditions then lie in another basin and only one of the
chemicals survives with others two excluded. Eigen and Schuster [ 86 ,
87 , 27 ] also studied resulting dynamics in the evolution of
macromolecules before the advent of life.

Schuster and Sigmund [ 88 ] applied the dynamic to animal behavior in
BoS and described the evolution of strategies by treating it as a
dynamical system. They wrote replicator Eqs. ( 6.114 ) for the payoff
matrix:

  -- -------- -- ---------
     @xmath      (6.115)
  -- -------- -- ---------

where a male can play pure strategies @xmath , @xmath and a female can
play pure strategies @xmath , @xmath respectively. Let in a population
engaged in this game the frequencies of @xmath and @xmath are @xmath and
@xmath respectively. Similarly the frequencies of @xmath and @xmath are
@xmath and @xmath respectively. Obviously

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (6.116)
  -- -------- -------- -- ---------

the replicator equations ( 6.114 ) for the matrix ( 6.115 ) with
conditions ( 6.116 ) are, then, written as

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (6.117)
  -- -------- -------- -- ---------

where @xmath and @xmath . These are Lotka-Volterra type equations
describing the evolution of two populations identified as predator and
prey [ 89 ] . Schuster and Sigmund [ 88 ] simplified the problem by
taking

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.118)
  -- -------- -------- -- ---------

which does not restrict generality of the problem and the replicator
Eqs. ( 6.117 ) remain similar. Payoffs to the male @xmath and to the
female @xmath , when the male plays @xmath with probability @xmath (he
then plays @xmath with the probability @xmath ) and the female plays
@xmath with the probability @xmath (she then plays @xmath with the
probability @xmath ) are written as [ 30 ]

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (6.119)
  -- -------- -------- -- ---------

where

  -- -- -- ---------
           (6.120)
  -- -- -- ---------

also

  -- -------- -- ---------
     @xmath      (6.121)
  -- -------- -- ---------

and @xmath is for transpose.

Now a quantum form of the matrix game ( 6.115 ) can be played using
Marinatto and Weber’s scheme [ 52 ] . The players have at their disposal
an initial quantum state:

  -- -------- -- ---------
     @xmath      (6.122)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (6.123)
  -- -------- -- ---------

In quantum version the male and female players apply the identity @xmath
on @xmath with probabilities @xmath and @xmath respectively. Also they
apply @xmath with probabilities @xmath and @xmath , respectively.
Payoffs to the players are written in a similar form, as in the Eq. (
6.119 ):

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (6.124)
  -- -------- -------- -- ---------

@xmath and @xmath are quantum forms of the payoff matrices @xmath and
@xmath respectively i.e.

  -- -------- -- ---------
     @xmath      (6.125)
  -- -------- -- ---------

where

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.126)
  -- -------- -------- -- ---------

similarly

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.127)
  -- -------- -------- -- ---------

For the initial state @xmath the matrices @xmath and @xmath are same as
@xmath and @xmath respectively. The classical game is, therefore,
embedded in the quantum game. Simplified matrices @xmath and @xmath can
be obtained by the assumption of Eq. ( 6.118 ), that is

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.128)
  -- -------- -------- -- ---------

The replicator Eqs. ( 6.117 ) can now be written in the following
‘quantum’ form:

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (6.129)
  -- -------- -------- -- ---------

where @xmath and @xmath . These equations reduce to Eqs. ( 6.117 ) for
@xmath i.e. @xmath . Similar to the classical version [ 88 ] the
dynamics ( 6.129 ) has five rest or equilibrium points @xmath @xmath ;
@xmath @xmath ; @xmath @xmath ; @xmath @xmath ; and an interior
equilibrium point:

  -- -------- -- ---------
     @xmath      (6.130)
  -- -------- -- ---------

This equilibrium point is the same as in the classical game [ 88 ] for
@xmath i.e.

  -- -------- -- ---------
     @xmath      (6.131)
  -- -------- -- ---------

We use the method of linear approximation [ 89 ] at equilibrium points
to find the general character of phase diagram of the system ( 6.129 ).
Write the system ( 6.129 ) as

  -- -------- -- ---------
     @xmath      (6.132)
  -- -------- -- ---------

The matrix for linearization [ 89 ] is

  -- -------- -- ---------
     @xmath      (6.133)
  -- -------- -- ---------

where, for example, @xmath denotes @xmath . The matrix ( 6.133 ) is
evaluated at each equilibrium point in turn. Write now these terms as

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.134)
  -- -------- -------- -- ---------

and the characteristic equation [ 89 ] at an equilibrium point is
obtained from

  -- -------- -- ---------
     @xmath      (6.135)
  -- -------- -- ---------

The patterns of phase paths around equilibrium points classify the
points into a few principal cases. Suppose @xmath are roots of the
characteristic Eq. ( 6.135 ). A few cases are as follows:

1.  @xmath are real, different, non-zero, and of same sign. If @xmath
    then the equilibrium point is an unstable node or a repeller. If
    @xmath the node is stable or an attractor .

2.  @xmath are real, different, non-zero, and of opposite sign. The
    equilibrium point is a saddle point .

3.  @xmath , and @xmath . The equilibrium is a stable spiral (attractor)
    if @xmath , an unstable spiral (repeller) if @xmath , a center if
    @xmath .

Consider an equilibrium or rest point @xmath @xmath , written simply as
@xmath . At this point the characteristic Eq. ( 6.135 ) has the roots:

  -- -------- -- ---------
     @xmath      (6.136)
  -- -------- -- ---------

For the classical game, i.e. @xmath , these roots are @xmath , @xmath .
Therefore in case @xmath the equilibrium point @xmath is an attractor in
the classical game.

Consider the interior equilibrium point @xmath of Eq. ( 6.130 ). The
terms of the matrix of linearization of Eq. ( 6.134 ) are:

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (6.137)
  -- -------- -------- -- ---------

the roots of the characteristic Eq. ( 6.135 ) are numbers @xmath where

  -- -------- -- ---------
     @xmath      (6.138)
  -- -------- -- ---------

the term in square root can be a positive or negative real number.
Therefore:

-   A saddle (center) in classical game can be a center (saddle) in
    certain quantum form of the game.

-   A saddle or a center in a classical (quantum) game can not be an
    attractor or a repeller in quantum (classical) form of the game.

## Chapter 7 Relevance of evolutionary stability in quantum games

Evolutionary game theory considers attractors of a dynamics and ESSs
with reference to population models. Extending these ideas to a quantum
setting requires an assumption of population of individuals, or
entities, with access to quantum states and quantum mechanical
operators. What is the possible relevance of such an assumption in the
real world? To answer it we observe that the concept of evolutionary
stability is based on the following assumptions, that also define its
population setting:

-   There are random and pair-wise interactions between the
    participating players forming a population. These interactions can
    be re-expressed in game-theoretic language by constructing symmetric
    bi-matrices.

-   A step-wise selection mechanism that ensures that a successful
    strategy has better chance to spread itself in the population at the
    expense of other strategies.

While bringing the ESS concept to quantum games, we retain the
population setting of evolutionary game theory as well as the step-wise
selection mechanism. However, the games played among the players, during
pair-wise interactions, are replaced with their quantum counterparts.
Questions now naturally arise how such a switch-over to a quantum game
changes the evolutionary outcome.

Following are the some suggestions where a relevance of quantization of
games may affect, and even decide, an evolutionary outcome.

### 7.1 Quantum mechanics deciding an evolutionary outcome

Evolutionary game theory was developed to provide game-theoretic models
of animal conflicts that occur in our macro-world. However, recent work
in biology [ 90 ] suggests that nature also plays classical games at
micro-level. Bacterial infections by viruses are classical game-like
situations where nature prefers dominant strategies. The
game-theoretical explanation of stable states in a population of
interacting individuals can be considered a model of rationality which
is physically grounded in natural selection.

A motivation to study evolutionary stability in quantum games exists
because the population setting of evolutionary game theory can also be
introduced to quantum games. It can be done on the same ground as it is
done in the classical games. The notion of a Nash equilibrium, that
became the topic of pioneering work on quantum games, was itself
motivated by a population setting.

Consideration of evolutionary stability in quantum games shows how
quantization of games, played in a population, can lead to new stable
states of the population. It shows that the presence of quantum
interactions, in a population undergoing evolution, can alter its stable
states resulting from the evolutionary dynamics. When quantum effects
decide the evolutionary outcomes, the role for quantum mechanics clearly
increases, from just keeping atoms together, to deciding the outcome of
an evolutionary dynamics.

### 7.2 Development of complexity and self-organization

This new role for quantum mechanics can be to define and maintain
complexity emerging from quantum interactions among a collection of
molecules. Eigen, Schuster, Sigmund and Wolf [ 86 , 87 ] consider an
example of a mixture in which an equilibrium is achieved from competing
chemical reactions. Such an equilibrium can also be an outcome of
quantum interactions occurring at molecular level. When quantum nature
of molecular interactions can decide an equilibrium state, there is a
clear possibility for the quantum mechanical role in the models of
self-organization in matter. These considerations seem quite relevant to
the evolution of macromolecules before the advent of life. The
possibility that stability of solutions (or equilibria) can be affected
by quantum interactions provides a new approach towards understanding of
rise of complexity in groups of quantum-interacting entities.

Physicists have expressed opinions [ 91 ] about the possibility of
quantum mechanics ‘fast tracking’ a chemical soup to states that are
biological and complex, and the debate continues. We suggest that
quantum game theory also have contributions to make towards the attempts
to understand quantum mechanical role in life, especially evolution and
development of self organization and complexity in molecular systems,
and possibly the origin of consciousness.

Considering development of quantum mechanical models of life, in a
recent paper Flitney and Abbott [ 92 ] studied a version of John
Conway’s game of Life [ 93 ] where the normal binary values of the cells
are replaced by oscillators which can represent a superposition of
states. They showed that the original game of Life is reproduced in the
classical limit, but in general additional properties not seen in the
original game are present that display some of the effects of a quantum
mechanical Life.

### 7.3 Genetic code evolution

Genetic code is the relationship between sequence of bases in DNA and
the sequence of amino acids in proteins. Suggestions have been made
earlier about quantum mechanical role in the genetic code. For example,
supersymmetry in particle physics, giving a unified description of
fermions and bosons, have been suggested [ 94 ] to provide an
explanation of coding assignments in genetic code. Recent work [ 95 ]
about evolvability of the genetic code suggests that the code, like all
other features of organisms, was shaped by natural selection. The
question about the process and evolutionary mechanism by which the
genetic code was optimized is still unanswered. Two suggested
possibilities are:

-   A large number of codes existed out of which the adaptive one was
    selected.

-   Adaptive and error-minimizing constraints gave rise to an adaptive
    code via code expansion and simplification.

The second possibility of code expansion from earlier simpler forms is
now thought to be supported by much empirical and genetic evidence [ 96
] and results suggest that the present genetic code was strongly
influenced by natural selection for error minimization.

Patel [ 97 ] suggested quantum dynamics played a role in the DNA
replication and in the optimization criteria involved in genetic
information processing. He considers the criteria as a task similar to
an unsorted assembly operation, with possible connection to the Grover’s
database search algorithm [ 8 ] , given different optimal solutions
result from the classical and quantum dynamics.

The assumption in this approach is that an adaptive code was selected
out of a large numbers that existed earlier. The suggestion of natural
selection being the process, for error minimization in the mechanism of
adaptive code evolution, puts forward an evolutionary approach for this
optimization problem. We believe that, in the evolution and expansion of
the code from its earlier simpler forms, quantum dynamics has played a
role. The mechanism leading to this optimization will be, however,
different. Our result that stable outcomes, of an evolutionary process
based on natural selection, may also depend on the quantum nature of
interactions clearly implies the possibility that such interactions may
decide the optimal outcome of evolution.

We believe that the code optimization is a problem having close
similarities to the problem of evolutionary stability. And this
optimization was probably achieved by interactions that were quantum
mechanical in nature.

### 7.4 Quantum evolutionary algorithms

A polynomial time algorithm that can solve an NP problem is not known
yet. A viable alternative approach, shown to find acceptable solutions
within a reasonable time period, is the evolutionary search [ 98 ] .
Iteration of selection based on competition, random variation or
mutation, and exploration of the fitness landscape of possible
solutions, are the basic ingredients of many distinct paradigms of
evolutionary computing [ 99 ] . On the other hand superposition of all
possible solution states, unitary operators exploiting interference to
enhance the amplitude of the desired states, and final measurement
extracting the solution are the components of quantum computing. These
two approaches in computing are believed to represent different
philosophies [ 100 ] .

Finding ESSs can also be formulated as an evolutionary algorithm. The
view that quantum mechanics has a role in the theory of ESSs suggests
that the two philosophies – considered different so far – may have
common grounds uniting them. It also hints the possibility of
evolutionary algorithms that utilize, or even exploit, quantum effects.
In such an evolutionary algorithm, we may have, for example, fitness
functions depending on the amount of entanglement present. The natural
question to ask is then how the population will evolve towards an
equilibrium state in relation to the amount of entanglement.

### 7.5 Evolutionary quantum optimization and computation

The perspective that matrix game theory provides, on what should be an
outcome of evolution, has been studied in this thesis. Another
perspective is provided by optimization models [ 101 ] . In evolutionary
matrix games a frequency-dependent selection takes place and all
alternative strategies become equally fit when an ESS establishes
itself. On the other hand, in optimization models the selection is
frequency-independent and evolution is imagined as a hill-climbing
process. Optimal solution is obtained when fitness is maximized.
Evolutionary optimization is the basis of evolutionary and genetic
algorithms and is generally considered to be a different approach from
ESSs in matrix games. These are not, however, in direct contradiction
and give different outlooks on evolutionary process. We suggest that
evolutionary optimization is another area where a role for quantum
mechanics exists and quantum game theory provides hints to find it.

It seems appropriate to mention here the evolutionary quantum
computation (EQC) described in the Ref [ 102 ] . In EQC an ensemble of
quantum subsystems is considered changing continually such a way as to
optimize some measure of emergent patterns between the system and its
environment. It seems reasonable that this optimization is related to an
equilibrium or some of its properties. When quantum interactions decide
the equilibria and their stability properties, it implies that the
optimization itself depends on it. Brain also has been proposed [ 102 ]
as an evolutionary quantum computer.

## Chapter 8 Cooperation in quantum games

### 8.1 Introduction

In contrast to non-cooperative games the players in cooperative games
are not able to form binding agreements even if they may communicate.
The distinctive feature of cooperative games is a strong incentive to
work together to receive the largest total payoff. These games allow
players to form coalitions, binding agreements, pay compensations, make
side payments etc. Von Neumann and Morgenstern [ 2 ] in their pioneering
work on the theory of games offered models of coalition formation where
the strategy of each player consists of choosing the coalition s/he
wishes to join. In coalition games, that are part of cooperative game
theory, the possibilities for the players are described by the available
resources of different groups (coalitions) of players. Joining a group
or remaining outside is part of strategy of a player affecting his/her
payoff.

Recent work in quantum games arises a natural and interesting question:
what is the possible quantum mechanical role in cooperative games that
are considered an integral part of the classical game theory? In our
view it may be quite interesting, and fruitful as well, to investigate
coalitions in quantum versions of cooperative games. Our present
motivation is to investigate what might happen to the advantage of
forming a coalition in a quantum game compared to its classical
analogue. We rely on the concepts and ideas of von Neumann’s cooperative
game theory [ 2 ] and consider a three-player coalition game in a
quantum form. We then compare it to the classical version of the game
and see how the advantage of forming a coalition can be affected.

In classical analysis of coalition games the notion of a strategy
disappears; the main features are those of a coalition and the value or
worth of the coalition. The underlying assumption is that each coalition
can guarantee its members a certain amount called the ‘ value of a
coalition ’ . “The value of coalition measures the worth the coalition
possesses and is characterized as the payoff which the coalition can
assure for itself by selecting an appropriate strategy, whereas the ‘odd
man’ can prevent the coalition from getting more than this amount” [ 104
] . Using this definition we study cooperative games in quantum settings
to see how advantages of making coalitions can be influenced in the new
setting.

Within the framework of playing a quantum game given by Marinatto and
Weber, we find a quantum form of a symmetric cooperative game played by
three players. In classical form of this game any two players, out of
three, get an advantage when they successfully form a coalition and play
the same strategy. We investigate how the advantage for forming a
coalition are affected when the game switches its form from classical to
quantum.

### 8.2 A three-player symmetric cooperative game

#### 8.2.1 Classical form

A classical three-person normal form game [ 104 ] is given by:

-   Three non-empty sets @xmath , @xmath , and @xmath . These are the
    strategy sets of the players @xmath , @xmath , and @xmath .

-   Three real valued functions @xmath , @xmath , and @xmath defined on
    @xmath .

The product space @xmath is the set of all tuples @xmath with @xmath ,
@xmath and @xmath . A strategy is understood as such a tuple @xmath and
@xmath , @xmath , @xmath are payoff functions of the three players. The
game is denoted as @xmath . Let @xmath be the set of players and @xmath
be an arbitrary subset of @xmath . The players in @xmath may form a
coalition so that, for all practical purposes, the coalition @xmath
appears as a single player. It is expected that players in @xmath will
form an opposing coalition and the game has two opposing “coalition
players” i.e. @xmath and @xmath .

We study quantum version of an example of a classical three player
cooperative game discussed in Ref. [ 104 ] . Each of the three players
@xmath , @xmath , and @xmath chooses one of the two strategies @xmath ,
@xmath . If the three players choose the same strategy there is no
payoff; otherwise, the two players who have chosen the same strategy
receive one unit of money each from the ‘odd man.’ Payoff functions
@xmath , @xmath and @xmath for players @xmath , @xmath and @xmath ,
respectively, are given as [ 104 ] :

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (8.1)
  -- -------- -------- -- -------

with similar expressions for @xmath and @xmath . Suppose @xmath , hence
@xmath . The coalition game represented by @xmath is given by the payoff
matrix [ 104 ] :

  -- -------- -- -------
     @xmath      (8.2)
  -- -------- -- -------

Here the strategies @xmath and @xmath are dominated by @xmath and @xmath
. After eliminating these dominated strategies the payoff matrix becomes

  -- -------- -- -------
     @xmath      (8.3)
  -- -------- -- -------

It is seen that the mixed strategies:

  -- -------- -- -------
     @xmath      (8.4)
     @xmath      (8.5)
  -- -------- -- -------

are optimal for @xmath and @xmath respectively. With these strategies a
payoff @xmath for players @xmath is assured for all strategies of the
opponent; hence, the value of the coalition @xmath is @xmath i.e. @xmath
. Since @xmath is a zero-sum game @xmath can also be used to find @xmath
as @xmath . The game is symmetric and one can write

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (8.6)
  -- -------- -------- -- -------

#### 8.2.2 Quantum form

In quantum form of this three-player game the players – identified as
@xmath , @xmath and @xmath – play their strategies by applying the
identity operator @xmath with probabilities @xmath , @xmath , and @xmath
, respectively, on a three-qubit initial quantum state. The players
apply the operator @xmath with probabilities @xmath , @xmath , and
@xmath respectively. If @xmath is the initial state, the final state,
after players have played their strategies, becomes

  -- -------- -- -------
     @xmath      (8.7)
  -- -------- -- -------

where the unitary and Hermitian operator @xmath can be either @xmath or
@xmath . @xmath , @xmath and @xmath are the probabilities with which
players @xmath , @xmath , and @xmath apply the operator @xmath on the
initial state respectively. @xmath corresponds to a convex combination
of players’ quantum operations. Let the arbiter prepares a three-qubit
pure initial quantum state:

  -- -- -- -------
           (8.8)
  -- -- -- -------

where the basis vectors of the quantum state are @xmath for @xmath . The
state ( 8.8 ) is in @xmath dimensional Hilbert space and corresponds to
three qubits.

Assume the matrix of the three-player game is given by @xmath constants
@xmath with @xmath . Write the payoff operators for players @xmath ,
@xmath and @xmath as

  -- -------- -------- -- -------
     @xmath               
              @xmath      
              @xmath      
              @xmath      (8.9)
  -- -------- -------- -- -------

Payoffs to the players @xmath , @xmath and @xmath are then obtained as
mean values of these operators:

  -- -------- -- --------
     @xmath      (8.10)
  -- -------- -- --------

Where the players’ moves are identified by the numbers @xmath , @xmath
and @xmath , respectively. Fig. ( 8.1 ) shows the three-player quantum
game. The cooperative game of Eq. ( 8.1 ) with the classical payoff
functions @xmath , @xmath and @xmath for players @xmath , @xmath and
@xmath respectively, together with the definition of payoff operators
for these players in Eq. ( 8.9 ), imply that

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

With these constants, in quantum version of the game, the payoff to
player @xmath , for example, can be found as

  -- -------- -- --------
     @xmath      (8.12)
  -- -------- -- --------

Similarly, payoffs to players @xmath and @xmath can be obtained.
Classical mixed strategy payoffs can be recovered from the Eq. ( 8.12 )
by taking @xmath . The classical game is therefore imbedded in its
quantum form.

The classical form of this game is symmetric in the sense that payoff to
a player depends on his/her strategy and not on his/her identity. These
requirements that result in a three-player symmetric game are written as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (8.13)
  -- -------- -------- -- --------

Now in this quantum form of the game, @xmath becomes same as @xmath when
[ 105 ] :

  -- -------- -- --------
     @xmath      (8.14)
  -- -------- -- --------

Similarly @xmath and @xmath when the following conditions hold [ 105 ] :

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (8.15)
  -- -------- -------- -- --------

Combining Eq. ( 8.14 ) and Eq. ( 8.15 ) give

  -- -------- -- --------
     @xmath      (8.16)
  -- -------- -- --------

and then payoff to a @xmath -player remains same when other two players
interchange their strategies. The symmetry conditions ( 8.13 ) hold if,
together with Eqs. ( 8.14 ), the following relations are also true

  -- -------- -- --------
     @xmath      (8.17)
  -- -------- -- --------

These form the extra restrictions on the constants of payoff matrix and,
together with the conditions ( 8.14 ), give a three player symmetric
game in a quantum form. No subscript in a payoff expression is then
needed and @xmath represents the payoff to a @xmath -player against two
other players playing @xmath and @xmath . The payoff @xmath is found as

  -- -------- -- --------
     @xmath      (8.18)
  -- -------- -- --------

Assume now that the pure strategies @xmath and @xmath correspond to
@xmath and @xmath , respectively. The mixed strategy @xmath , where
@xmath , means that the strategy @xmath is played with probability
@xmath and @xmath with probability @xmath . Also suppose that coalition
@xmath plays the mixed strategy ¹ ¹ 1 In a Comment on “Quantum
cooperative games” that appeared in Physics Letters A, Volume 328,
Issues 4-5, Pages 414-415, 2 August 2004, Liang Dai and Qing Chen have
pointed out that because the mixed strategies @xmath and @xmath are not
always dominated by @xmath and @xmath in quantum form, there is no
ground for assuming that the coalition @xmath always plays the mixed
strategy @xmath . :

  -- -------- -- --------
     @xmath      (8.19)
  -- -------- -- --------

where the strategy @xmath means that both players in the coalition
@xmath apply the identity operator @xmath with zero probability.
Similarly the strategy @xmath can be defined. The strategy in the Eq. (
8.19 ) is such that the coalition @xmath plays @xmath with probability
@xmath and @xmath with probability @xmath . Similarly assume that the
player in @xmath plays the mixed strategy:

  -- -------- -- --------
     @xmath      (8.20)
  -- -------- -- --------

The payoff to the coalition @xmath is then obtained as

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (8.21)
  -- -------- -------- -- --------

where @xmath is the payoff to @xmath when all three players play @xmath
i.e. the strategy @xmath . Similarly @xmath is the coalition payoff when
the coalition players play @xmath and the player in @xmath plays @xmath
. Now from Eq. ( 8.18 ) we get

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (8.22)
  -- -------- -------- -- --------

Also from Eq. ( 8.21 ):

  -- -------- -- --------
     @xmath      (8.23)
  -- -------- -- --------

To find the value of coalition @xmath in the quantum game we find @xmath
and equate it to zero i.e. @xmath is such a payoff to @xmath that the
player in @xmath cannot change it by changing his/her strategy given in
Eq. ( 8.20 ). It gives, interestingly, @xmath and the classical optimal
strategy of the coalition @xmath becomes optimal in the quantum game as
well. In the quantum game the coalition then secures following payoff,
which is also termed as the value of the coalition:

  -- -------- -- --------
     @xmath      (8.24)
  -- -------- -- --------

Similarly we get the value of coalition for @xmath :

  -- -------- -- --------
     @xmath      (8.25)
  -- -------- -- --------

Note that these values reduce to their classical counterparts of Eq. (
8.6 ) when the initial quantum state becomes unentangled and is given by
@xmath . Classical form of the coalition game is, therefore, a subset of
its quantum version.

Suppose the arbiter now has at his disposal a quantum state:

  -- -------- -- --------
     @xmath      
     @xmath      (8.26)
  -- -------- -- --------

If we assume that, with this initial state, the coalition @xmath still
plays the mixed strategy ² ² 2 Liang Dai and Qing Chan have also
indicated that when @xmath the strategies @xmath and @xmath are optimal.
@xmath of the classical case, then @xmath becomes a negative quantity
and @xmath because of the normalization given in Eq. ( 8.8 ). Another
possible case is when the arbiter has the state:

  -- -------- -- --------
     @xmath      (8.27)
  -- -------- -- --------

at his disposal. Because now both @xmath and @xmath are @xmath and the
players are left with no motivation to form the same coalition as they
do in the classical game.

Liang Dai and Qing Chen [ 105 ] have observed ³ ³ 3 Liang Dai and Qing
Chen [ 105 ] pointed out a flaw in the calculations in the Ref. [ 103 ]
by Iqbal and Toor. We argue that even after the detection of the
indicated flaw by Liang Dai and Qing Chen [ 105 ] the main conclusion of
the Ref. [ 103 ] remains intact. It can be seen as follows. In their
comment Liang Dai and Qing Chen [ 105 ] wrote “In quantum form, the
authors (Iqbal and Toor [ 103 ] ) concluded that the game was not
zero-sum, and, in some cases, the players had no motivation to make a
coalition because the advantage was lost. In this comment we argue that
the conclusions in Ref. [ 103 ] are incorrect and led to invalid
conclusions.” Now we refer to the main conclusion of the Ref. [ 103 ] ,
written in its abstract, saying “In its classical form (of a
three-player game) making a coalition gives advantage to players and
they are motivated to do so. However, in its quantum form the advantage
is lost and players are left with no motivation to make a coalition.” We
argue that this conclusion remains intact because: Consider the quote
from the page @xmath of the Ref. [ 103 ] “The underlying assumption in
this approach is that because the arbiter, responsible for providing
three-qubit pure quantum initial states to be later unitarily
manipulated by the players, can forward a quantum state that corresponds
to the classical game, therefore, other games corresponding to different
initial pure quantum states are quantum forms of the classical game.This
assumption makes possible to translate the problem of finding a quantum
version of the classical coalition game, having the property that the
advantage of making a coalition is lost, to finding some pure initial
quantum states. We showed that such quantum states can be found and,
therefore, there are quantum versions of the three-player coalition game
where the motivation for coalition formation is lost.” In view of this
quote along with Liang Dai and Qing Chen’s finding that when @xmath
their remains no motivation to form a coalition, it can be observed
that, even after the indicated flaw in the calculation, the main
conclusion of the Ref. [ 103 ] remain intact. It is because the
assumption made in the Ref. [ 103 ] , which is quoted above in detail,
allows to consider the corresponding game when @xmath as a quantum form
of the classical game. So that, Liang Dai and Qing Chen [ 105 ] main
conclusion is same as in the Ref. [ 103 ] , apart from their
identification of the correct mathematical conditions that are required
to find the particular quantum form of the game in which the advantages
of forming a coalition are lost. that in case @xmath , the motivation to
form a coalition remains in the quantum form. In case @xmath , every
player’s payoff becomes zero whatever strategies they adapt, and hence
the motivation to form a coalition is lost.

### 8.3 Discussion

There may appear several guises in which the players can cooperate in a
game. One possibility is that they are able to communicate and, hence,
able to correlate their strategies. In certain situations players can
make binding commitments before or during the play of a game. Even in
the post-play behavior the commitments can make players to redistribute
their final payoffs.

Two-player games are different from multi-player games in an important
aspect. In two-player games the question before the players is whether
to cooperate or not. In multi-player case the players are faced with a
more difficult task. Each player has to decide which coalition to join.
There is also certain uncertainty that the player faces about the extent
to which players outside his coalition may coordinate their actions.

Recent developments in quantum games provide a motivation to see how
forming a coalition, and its associated advantages, can be influenced in
quantum versions of these classical cooperative games. To study this we
selected an interesting, but simple, cooperative game and a recently
proposed scheme telling how to play a quantum game. We allowed the
players in the quantum version of the game to form a coalition similar
to the classical game.

The underlying assumption in this approach is that because the arbiter,
responsible for providing three-qubit pure initial quantum states, to be
later manipulated by the players, can forward a quantum state that
corresponds to the classical game, therefore, other games that result
from different initial pure quantum states are quantum forms of the
classical game. This assumption reduces the problem of finding a quantum
version of the classical coalition game to finding some pure initial
quantum states. It is shown that a quantum version of the three-player
coalition game can be found where the motivation for coalition formation
is lost.

## Chapter 9 Backwards-induction outcome in quantum games

### 9.1 Introduction

The notion of NE, the central solution-concept in non-cooperative game
theory, was developed by John Nash in early 1950s. In fact Cournot
(1838) [ 25 ] anticipated Nash’s definition of equilibrium by over a
century but only in the context of a particular model of a market which
is dominated by only two producers. In economics an oligopoly is a form
of market in which a number @xmath of producers, say, @xmath , and no
others , provide the market with a certain commodity. In the special
case where @xmath it is called a duopoly. Cournot’s work [ 25 ] is one
of the classics of game theory and also a cornerstone of the theory of
industrial organization [ 106 ] .

In Cournot model of duopoly two-firms simultaneously put certain
quantities of a homogeneous product in the market. Cournot obtained an
equilibrium value for the quantities both firms will decide to put in
the market. This equilibrium value was based on a rule of behavior which
says that if all the players except one abide by it, the remaining
player cannot do better than to abide by it too. Nash gave a general
concept of an equilibrium point in a noncooperative game but existence
of an equilibrium in duopoly game was known much earlier. The “Cournot
equilibrium” refers to NE in non-cooperative form of duopoly that
Cournot considered.

In an interesting later development, Stackelberg (1934) [ 107 , 108 ]
proposed a dynamic model of duopoly in which – contrary to Cournot’s
assumption of simultaneous moves – a leader (or dominant) firm moves
first and a follower (or subordinate) firm moves second. A well known
example is the General Motors playing this leadership role in the early
history of US automobile industry when more than one firms like Ford and
Chrysler acted as followers. In this sequential game a “Stackelberg
equilibrium” is obtained using the backwards-induction outcome of the
game. Stackelberg equilibrium refers to sequential nature of the game
and it is a stronger solution-concept than the NE because sequential
move games sometimes have multiple NE , only one of which is associated
with the backwards-induction outcome of the game [ 108 ] .

In this chapter we present a quantum perspective on the interesting game
of Stackelberg duopoly. We start with the same assumption that a game is
decided only by players’ unitary manipulations, payoff operators, and
the measuring apparatus deciding payoffs. When these are same a
different input quantum initial state gives a different form of the same
game. With this assumption we studied evolutionary stability of a mixed
NE in the RSP game. Hence, a game obtained by using a general two-qubit
pure state is a quantum form of the classical game provided the rest of
the procedures in playing the quantum game remain same .

We now present an analysis of the Stackelberg duopoly by raising a
question: Is it possible to find a two-qubit pure quantum state that
generates the classical Cournot equilibrium as a backwards-induction
outcome of the quantum form of Stackelberg duopoly? Why can this
question be of interest? It is interesting because in case the answer is
yes, then, quantization can potentially be a useful element for the
follower in the leader-follower model of the Stackelberg duopoly [ 108 ]
. It is due to a known result that, in classical setting, when static
duopoly changes to a dynamic form, the follower becomes worse-off
compared to the leader who becomes better-off. We find that, under
certain restrictions, it is possible to find the needed two-qubit
quantum states. Hence a quantum form of a dynamic game of complete
information has an equilibrium that corresponds to classical static form
of the same game. The leader, thus, does not become better-off in the
quantum form of the dynamic duopoly.

### 9.2 Backwards-induction outcome

Consider a simple three step game:

1.  Player @xmath chooses an action @xmath from the feasible set @xmath
    .

2.  Player @xmath observes @xmath and then chooses an action @xmath from
    the feasible set @xmath .

3.  Payoffs are @xmath and @xmath .

This game is an example of the dynamic games of complete and perfect
information. Key features of such games are:

1.  The moves occur in sequence.

2.  All previous moves are known before next move is chosen, and

3.  The players’ payoffs are common knowledge.

Given the action @xmath is previously chosen, at the second stage of the
game, when player @xmath gets the move s/he faces the problem:

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

Assume that for each @xmath in @xmath , player @xmath ’s optimization
problem has a unique solution @xmath , which is also known as the best
response of player @xmath . Now player @xmath can also solve player
@xmath ’s optimization problem by anticipating player @xmath ’s response
to each action @xmath that player @xmath might take. So that player
@xmath faces the problem:

  -- -------- -- -------
     @xmath      (9.2)
  -- -------- -- -------

Suppose this optimization problem also has a unique solution for player
@xmath and is denoted by @xmath . The solution @xmath is the
backwards-induction outcome of this game.

In a simple version of the Cournot’s model two firms simultaneously
decide the quantities @xmath and @xmath respectively of a homogeneous
product they want to put into market. Suppose @xmath is the aggregate
quantity i.e. @xmath and @xmath be the market-clearing price , which is
the price at which all products or services available in a market will
find buyers. Assume the total cost to a firm producing quantity @xmath
is @xmath i.e. there are no fixed costs and the marginal cost is a
constant @xmath with @xmath . In a two-player game theoretical model of
this situation a firm’s payoff or profit can be written as [ 108 ]

  -- -- -- -------
           (9.3)
  -- -- -- -------

Solving for the NE easily gives the Cournot equilibrium:

  -- -------- -- -------
     @xmath      (9.4)
  -- -------- -- -------

At this equilibrium the payoffs to both the firms from Eq. ( 9.3 ) are

  -- -------- -- -------
     @xmath      (9.5)
  -- -------- -- -------

Consider now the classical form of duopoly game when it becomes dynamic.
In dynamic form of the game the payoffs to players are given by Eq. (
9.3 ) as they are for the Cournot’s game. We find backwards-induction
outcome in classical and a quantum form of the Stackelberg’s duopoly.
Taking advantage from a bigger picture given to this dynamic game, by
the Hilbert structure of its strategy space, we then find two-qubit pure
quantum states that give classical Cournot’s equilibrium as the
backwards-induction outcome of the quantum game of Stackelberg’s
duopoly.

### 9.3 Stackelberg duopoly

#### 9.3.1 Classical form

A leader (or dominant) firm moves first and a follower (or subordinate)
firm moves second in Stackelberg model of duopoly [ 108 ] . The sequence
of events is

1.  Firm @xmath chooses a quantity @xmath .

2.  Firm @xmath observes @xmath and then chooses a quantity @xmath .

3.  The payoffs to firms @xmath and @xmath are given by their respective
    profit functions as

  -- -------- -------- -- -------
     @xmath   @xmath      
     @xmath   @xmath      (9.6)
  -- -------- -------- -- -------

The backwards-induction outcome is found by first finding firm @xmath ’s
reaction to an arbitrary quantity by firm @xmath Denoting this quantity
as @xmath we find

  -- -------- -- -------
     @xmath      (9.7)
  -- -------- -- -------

with @xmath . Firm @xmath can now solve also the firm @xmath ’s problem.
Firm @xmath can anticipate that a choice of the quantity @xmath will
meet a reaction @xmath . In the first stage of the game firm @xmath can
then compute a solution to his/her optimization problem as

  -- -------- -- -------
     @xmath      (9.8)
  -- -------- -- -------

It gives

  -- -------- -- -------
     @xmath      (9.9)
  -- -------- -- -------

It is the classical backwards-induction outcome of dynamic form of the
duopoly game. At this equilibrium payoffs to the players @xmath and
@xmath are given by Eqs. ( 9.6 ) and ( 9.9 )

  -- -------- -- --------
     @xmath      (9.10)
  -- -------- -- --------

From Eq. ( 9.10 ) find the ratio:

  -- -------- -- --------
     @xmath      (9.11)
  -- -------- -- --------

showing that in comparison with the Cournot game, the leader firm
becomes better-off and the follower firm becomes worse-off in the
Stackelberg game. This aspect also hints an important difference between
single and multi-person decision problems. In single-person decision
theory having more information can never make the decision maker
worse-off. In game theory, however, having more information (or, more
precisely, having it made public that one has more information) can make
a player worse-off [ 108 ] .

Now we look at the backwards-induction outcome in a quantum perspective.
Our motivation is an interesting aspect that quantum form can bring into
the backwards-induction outcome. It is the possibility of firm @xmath
not becoming worse-off because of having extra information.

#### 9.3.2 Quantum form

Stackelberg duopoly is a two-player sequential game. Meyer [ 19 ]
considered a quantum form of the sequential game of PQ penny flip by
unitary operations on single qubit. Important difference between Meyer’s
game and Stackelberg duopoly is that at the second stage player in PQ
penny flip doesn’t know the previous move but in Stackelberg duopoly he
knows that.

We prefer Marinatto and Weber’s scheme to play the sequential game of
Stackelberg duopoly for two reasons:

1.  The classical game is obtained for a product initial state.

2.  When players’ actions and payoff-generating measurement are exactly
    the same, we assume other games, corresponding to every pure
    two-qubit initial state, are quantum forms of the classical game.

As discussed earlier, the second assumption originates from the fact
that the classical game corresponds to a pure two-qubit initial product
state. The assumption reduces the problem of finding a quantum form of
Stackelberg duopoly, with the property that its equilibrium is the same
as in Cournot’s duopoly, to the problem of finding conditions on the
parameters of two-qubit pure initial quantum state. If the conditions
are realistic then the corresponding quantum game gives Cournot’s
equilibrium as the backwards-induction outcome.

Stackelberg duopoly is a dynamic game of complete information. Its
quantum form in Marinatto and Weber’s scheme starts by preparing a pure
two-qubit initial quantum state. Suppose Alice plays first and she
announces her move immediately, so that Bob knows Alice’s move before
playing his move. Bob plays his move and both players forward their
qubits for measurement.

Information about the previous moves is crucial for the game considered
here. A comparison of the sequential game of Stackelberg duopoly with
the simultaneous-move game of BoS makes evident different information
structure in these games. For example let BoS be played sequentially.
But Alice does not announce her first move to Bob before he makes his.
It makes the game sequential but the information structure is still the
same as in its static form. Hence, a sequential BoS in the above form
has the same NE as in its static form. An unobserved-action form of a
game has the same NE as its simultaneous-move form. This observation led
us to play a quantum form of Stackelberg duopoly while keeping intact
the original structure of a scheme designed for simultaneous moves. A
consideration of playing a sequential game in a quantum way brings to
mind the Meyer’s PQ penny-flip [ 19 ] where only one qubit is used.
Contrary to this, in present section we use the two-qubit system of a
simultaneous-move game, to play a sequential game.

Why to use two qubits when a quantum form of this sequential game can
also be played by only one qubit, in similar way as Meyer’s PQ
penny-flip. We prefer two qubits because in this case a comparison
between classical and a quantum form of the game translates itself to
comparing two games resulting from using a product and an entangled
initial quantum state. We do not rule out the possibility that a
consideration of the dynamic game using only single qubit gives equally,
or even more, interesting results. We let classical payoffs in
Stackelberg duopoly, given by Eq. ( 9.6 ), reproduced when the initial
state @xmath is used to play the game. The upper state of a qubit is
then represented by @xmath . The state @xmath in density matrix notation
is

  -- -------- -- --------
     @xmath      (9.12)
  -- -------- -- --------

Assume the player Alice and Bob apply @xmath with probabilities @xmath
and @xmath respectively. The state ( 9.12 ) changes to

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath are identified as the players’ moves. The moves by Alice
and Bob in classical duopoly game are given by quantities @xmath and
@xmath where @xmath . We assume that Alice and Bob agree on a function
that can uniquely define a real positive number in the range @xmath for
every quantity @xmath in @xmath . A simple such function is @xmath . So
that, Alice and Bob find @xmath and @xmath , respectively, as

  -- -------- -- --------
     @xmath      (9.14)
  -- -------- -- --------

and use these real positive numbers as the probabilities with which they
apply the identity operator @xmath on the quantum state at their
disposal. With a substitution from Eqs. ( 9.12 , 9.14 ) the final state
( LABEL:FinDenMat ) becomes

  -- -------- -- --------
     @xmath      (9.15)
  -- -------- -- --------

We now assume that in the measurement and payoffs-finding phase the
quantities @xmath and @xmath are also known to the referee. The referee
applies the following payoff operators on the final quantum state:

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (9.16)
  -- -------- -------- -- --------

Note that the classical payoffs of Eq. ( 9.6 ) are reproduced with the
initial state @xmath as

  -- -------- -- --------
     @xmath      (9.17)
  -- -------- -- --------

A more general form of quantum duopoly can now be played by keeping the
payoff operators of Eq. ( 9.16 ) in the referee’s possession and
preparing an initial two-qubit pure state:

  -- -- -- --------
           (9.18)
  -- -- -- --------

Payoffs to Alice and Bob can now be obtained, in this quantum game, from
Eqs. ( 9.17 ) that use the payoff operators of Eqs. ( 9.16 ). The
payoffs to Alice and Bob are written as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (9.19)
  -- -------- -------- -- --------

where the subscript @xmath is for ‘quantum’ and

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

The classical payoffs of duopoly game given in Eqs. ( 9.6 ) are
recovered from the Eqs. ( 9.19 ) when the initial quantum state is
@xmath . Classical duopoly is, therefore, a subset of its quantum
version.

We now find the backwards-induction outcome in this quantum form of
Stackelberg duopoly. Fig. ( 9.1 ) shows the overall idea to play the
game. We proceed in exactly the same way as it is done in the classical
game except that players’ payoffs are now given by Eqs. ( 9.19 ) and not
by Eqs. ( 9.6 ). The first step in the backwards-induction in quantum
game is to find Bob’s reaction to an arbitrary quantity @xmath chosen by
Alice. Denoting this quantity as @xmath we find

  -- -------- -- --------
     @xmath      (9.21)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      
     @xmath      (9.22)
  -- -------- -- --------

This reaction reduces to its classical value of Eq. ( 9.7 ) when @xmath
. Similar to the classical game Alice can now solve Bob’s problem as
well. Alice can anticipate that a choice of quantity @xmath will meet a
reaction @xmath . In the first stage of the game, like its classical
version, Alice can compute a solution to her optimization problem as

  -- -------- -- --------
     @xmath      (9.23)
  -- -------- -- --------

To find it Alice calculates the quantity:

  -- -------- -------- --
     @xmath   @xmath   
                       
              @xmath   
  -- -------- -------- --

and replaces @xmath in Eq. ( LABEL:derivative ) with @xmath given by Eq.
( 9.21 ) and then equates Eq. ( LABEL:derivative ) to zero to find a
@xmath that maximizes her payoff @xmath . For a maxima she would ensure
that the second derivative of @xmath with respect to @xmath at @xmath is
a negative quantity. The quantity @xmath together with @xmath will form
the backwards-induction outcome of the quantum game.

An interesting situation is when the backwards-induction outcome in
quantum version of Stackelberg duopoly becomes same as the classical
Cournot equilibrium of duopoly. The classical situation of leader
becoming better-off, while the follower becomes worse-off, is then
avoided in the quantum form of Stackelberg duopoly. To look for this
possibility we need such an initial state @xmath that at @xmath we have
the following relations to be true, along with the normalization
condition given in Eq. ( 9.18 ):

  -- -------- -- --------
     @xmath      (9.25)
     @xmath      (9.26)
     @xmath      (9.27)
  -- -------- -- --------

The conditions ( 9.25 , 9.26 ) simply say that the backwards-induction
outcome of the quantum game is the same as Cournot equilibrium in
classical game. The condition ( 9.27 ) says that Bob’s reaction to
Alice’s choice of @xmath is @xmath . To show that such quantum states
can exist for which the conditions ( 9.25 , 9.26 , 9.27 ), with the
normalization ( 9.18 ), to be true, we give an example where @xmath and
@xmath are written as functions of @xmath , with our assumption that
@xmath . Though this assumption puts its own restriction, on the
possible range of @xmath for which the above conditions hold for these
functions, but still it shows clearly the possibility of finding the
required initial quantum states. The functions are found as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      (9.28)
  -- -------- -------- -- --------

also

  -- -------- -------- -- --------
     @xmath   @xmath      (9.29)
     @xmath   @xmath      (9.30)
  -- -------- -------- -- --------

Now, interestingly, given that allowed range of @xmath is @xmath , all
of the conditions ( 9.18 , 9.25 , 9.26 , 9.27 ) hold at @xmath . So that
in this range of @xmath a quantum form of Stackelberg duopoly exists
that gives the classical Cournot equilibrium as the backwards-induction
outcome. The restriction on allowed range of @xmath is the result of our
assumption that @xmath , which is introduced to simplify the
calculations. Nevertheless it does not forbid obtaining a quantum form
of Stackelberg duopoly, without the mentioned restriction of the range
of @xmath , when the quantum game still possesses the same properties.

### 9.4 Discussion

What can be a possible relevance of considering a quantum form of a game
that models a competition between two firms in macroscopic world of
economics? Quantum mechanics was developed to understand phenomena in
the regime of atomic and subatomic interactions and it is still mostly
used in that domain. What is of interest in extending a game-theoretical
model of interaction between firms towards quantum domain? These
questions naturally arise not only with reference to Stackelberg duopoly
considered in this paper but also other related works in quantum games.

We believe that like other notions of game theory, finding some
relevance in quantum information, a consideration of backwards-induction
can be of interest for exactly the same reasons. It does not seem hard
to imagine situations in quantum information where moves occur in
sequence, all previous moves are observed before the next move is
chosen, and players’ payoffs from each feasible combination of moves are
common knowledge. Interesting questions then arise about how a quantum
version of dynamic game of complete information can influence the
outcome.

The duopoly game models economic competition between firms and applied
economics is the area where it is studied in detail. The fact that
quantum game theory can give entirely new views on games, which are
important in economics, is apparent in recent interesting papers by
Piotrowski and Sladkowski [ 56 , 57 ] proposing a quantum-like
description of markets and economies where players’ strategies belong to
Hilbert space. It shows that quantum games certainly have features of
interest to applied economists. Reciprocating with it we showed that
games played by firms in economic competition can give counter-intuitive
solutions when played in the quantum world.

## Chapter 10 Quantum repeated games

### 10.1 Introduction

The PD attracted early attention [ 20 ] in recent studies in quantum
game theory. In classical game theory [ 108 ] a two-stage repeated
version of this game consists of two players playing the game twice,
observing the outcome of the first play before the second play begins.
The payoffs for the entire game are simply taken as the sum of the
payoffs from the two stages. Generally a two-stage repeated game has
more complex strategic structure than its one-stage counterpart and
players’ strategic choices in the second stage are affected by the
outcome of their moves in the first stage. For the classical one-stage
PD the strategy of ‘defection’ by both the players is a unique NE. In
its two-stage version the same NE appears again at the second stage
because the first stage payoffs are added as constants to the second
stage. In fact in all of finitely repeated versions of the PD
‘defection’ by both the players appears as unique NE at every stage [
108 ] .

Eisert et al.’s study [ 20 ] of the one-stage quantum PD raises a
question: what can possibly be a role for quantum mechanics when the
game is played twice? It seems that this role should be relevant to the
new feature showing itself in the game i.e. the two-stages. A role for
quantum mechanics exists if it inter-links the two stages of the game in
some way of interest. Classically both the players ‘defect’ at each
stage and strategic choices remain the same because of uniqueness of the
NE at each stage. In our search for a quantum role we find useful the
idea of subgame-perfect outcome (SGPO) [ 108 ] in a two-stage repeated
bi-matrix game in its quantum form.

For a two-stage repeated game the idea of a SGPO is natural analog of
the backwards-induction outcome (BIO) [ 108 ] from the games of complete
and perfect information. In the last chapter we considered the BIO idea
in a quantum form of duopoly game and showed how a quantum version of
this game can give an outcome corresponding to the static form of the
duopoly, even when the game is played dynamically. In present chapter we
study the natural analogue of BIO for a two-stage repeated PD quantum
game, i.e., the idea of SGPO in a situation that can be said to lie in
quantum domain. We solve the two-stage PD quantum game in the spirit of
backwards-induction from the last section; but now the first step in
working backwards from the end of the game involves solving a real game
rather than solving a single-person optimization problem.

In game theory the idea of SGPO comes out as a stronger solution concept
especially when multiple NE appear in a stage. Our motivation is the
observation that a quantization scheme for the PD is known in which the
NE in a stage is not unique – thus making relevant a consideration of
the concept of SGPO in the two-stage game played in a quantum setting.
For the purpose of completeness, we will first describe how SGPO works
for the classical two-stage PD. Afterwards, we quantize the game using a
known scheme, and then, show how a SGPO can exist that is
counter-intuitive compared to the classical SGPO for the two-stage
repeated PD.

### 10.2 Two-stage games of complete but imperfect information

Like dynamic game of complete and perfect information – for example the
Stackelberg duopoly – the play in a two-stage game of complete but
imperfect information proceeds in a sequence, with the moves in the
first stage observed before the next stage begins. The new feature is
that within each stage now there are simultaneous moves. The
simultaneity of moves within each stage means that information is
imperfect in the game. A two-stage game of complete but imperfect
information consists of the steps [ 108 ] :

1.  Players @xmath and @xmath simultaneously choose actions @xmath and
    @xmath from feasible sets @xmath and @xmath , respectively.

2.  Players @xmath and @xmath observe outcome of the first stage, @xmath
    , and then simultaneously choose actions @xmath and @xmath from
    feasible sets @xmath and @xmath , respectively.

3.  Payoffs are @xmath for @xmath @xmath .

A usual approach to solve a game from this class uses the method of
backwards-induction. In the last section the first step in working
backwards involves solving a single-person optimization problem. Now the
first step involves solving a simultaneous-move game between players
@xmath and @xmath in the second stage, given the outcome from stage one.
If the players @xmath and @xmath anticipate that their second-stage
behavior will be given by @xmath , then the first-stage interaction
between them amounts to the simultaneous-move game:

1.  Players @xmath and @xmath simultaneously choose actions @xmath and
    @xmath from feasible sets @xmath and @xmath , respectively.

2.  Payoffs are @xmath for @xmath .

When @xmath is the unique NE of this simultaneous-move game, the set of
four numbers @xmath is known as the SGPO [ 108 ] of this two-stage game.
This outcome is the natural analog of BIO in games of complete and
perfect information.

### 10.3 Two-stage Prisoners’ Dilemma

#### 10.3.1 Classical form

We use a normal form of the PD given by the matrix:

  -- -- -- --------
           (10.1)
  -- -- -- --------

The players play this simultaneous-move game twice. The outcome of the
first play is observed before the second stage begins. Payoff for the
entire game is simply the sum of the payoffs from the two stages. It is
a two-stage game of complete but imperfect information [ 108 ] .

Assume players @xmath and @xmath play the pure strategy @xmath with
probabilities @xmath and @xmath , respectively, in the stage @xmath .
Also assume the players @xmath and @xmath play the strategy @xmath with
probabilities @xmath and @xmath , respectively, in the stage @xmath .
Call @xmath and @xmath the payoffs to players @xmath and @xmath ,
respectively, in the stage @xmath , where the symbol @xmath is for
‘classical’. These payoffs can be found from the matrix ( 10.1 ) as

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

The NE conditions for this stage are

  -- -------- -- --------
     @xmath      (10.3)
  -- -------- -- --------

giving @xmath (i.e. defection for both the players) as the unique NE in
this stage. Likewise, in the second stage the payoffs to players @xmath
and @xmath are written as @xmath and @xmath respectively, where

  -- -------- -- --------
     @xmath      (10.4)
  -- -------- -- --------

and once again the strategy of defection, i.e. @xmath , comes out as the
unique NE in the second stage. To compute SGPO of this two-stage game,
we analyze its first stage given that the second-stage outcome is also
the NE of that stage —namely @xmath . For this NE the players’ payoffs
in the second stage are

  -- -------- -- --------
     @xmath      (10.5)
  -- -------- -- --------

The players’ first-stage interaction, therefore, in the two-stage PD
amounts to a one-shot game, in which the payoff pair @xmath from the
second stage is added to their first-stage payoff pair. Write the
players’ payoffs in the one-shot game as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (10.6)
  -- -------- -------- -- --------

It has again @xmath as the unique NE. Therefore, the unique SGPO of the
two-stage PD is @xmath in the first stage, followed by @xmath in the
second stage. The strategy of defection in both the stages comes out as
SGPO for the two stage classical PD.

It is now shown how it becomes possible, in a quantum form of this
two-stage PD, to achieve a SGPO in which the players decide to cooperate
in the first stage while knowing that they both will defect in the
second. The quantum form of the two-stage PD is played using a system of
four qubits. Players manipulate these qubits in Marinatto and Weber’s
scheme to play a quantum form of a matrix game.

#### 10.3.2 Quantum form

Marinatto and Weber’s scheme can be extended to play a two-stage version
of a bi-matrix game. For example, a quantum version of the two-stage PD
starts by making available a four-qubit pure quantum state to the
players. This state can be written as

  -- -------- -- --------
     @xmath      (10.7)
  -- -------- -- --------

where @xmath and @xmath are identifying symbols for four qubits. The
upper and lower states of a qubit are @xmath and @xmath respectively;
and @xmath are complex numbers. It is a quantum state in @xmath
-dimensional Hilbert space. We suppose the qubits @xmath and @xmath are
manipulated by the players in the first stage of the game and,
similarly, the qubits @xmath and @xmath are manipulated in the second
stage. Let @xmath denote the initial state ( 10.7 ) in the density
matrix formalism. Assume during their moves in the first stage of the
game, the players @xmath and @xmath apply the identity operator @xmath
on the initial state with probabilities @xmath and @xmath ,
respectively. Also they apply the operator @xmath with probabilities
@xmath and @xmath , respectively. The players’ actions in the first
stage changes @xmath to

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

The players’ actions in this stage are simultaneous and they remember
their moves (i.e. the numbers @xmath and @xmath ) also in the next
stage. In the second stage, players @xmath and @xmath apply the identity
operator with probabilities @xmath and @xmath , respectively, on @xmath
. The operator @xmath is, then, applied with probabilities @xmath and
@xmath on @xmath , respectively. Fig. ( 10.1 ) shows the overall idea of
playing the two-stage game. Players’ moves in the two stages of the game
are done on two different pairs of qubits.

After the moves performed in the second stage the quantum state changes
to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (10.9)
  -- -------- -------- -- --------

which is ready for measurement, giving payoffs for the two stages of the
game. If classically the bi-matrix game ( 10.1 ) is played at each
stage, the possession of the following four payoff operators by the
referee corresponds to a ‘quantum version’ of the two-stage game:

  -- -------- -- --
     @xmath      
     @xmath      
     @xmath      
     @xmath      
  -- -------- -- --

The corresponding payoffs are, then, obtained as mean values of these
operators. For example, Alice’s payoff in stage @xmath is

  -- -- -- ---------
           (10.11)
  -- -- -- ---------

We consider a two-stage quantum PD played with pure four-qubit initial
state in the form:

  -- -------- -- ---------
     @xmath      (10.12)
  -- -------- -- ---------

with @xmath . For this state the payoffs to the players @xmath and
@xmath in the two stages are found as

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      (10.13)
  -- -------- -------- -- ---------

The players’ payoffs in the classical two-stage PD given by Eqs. ( 10.2
, 10.4 ) can now be recovered from the Eq. ( 10.13 ) by taking @xmath .
The classical game is, therefore, a subset of its quantum version.

One now proceeds, in the spirit of backwards-induction, to find a NE in
the second stage of the quantum game. Suppose @xmath is a NE in the
second stage, then

  -- -------- -- ---------
     @xmath      (10.14)
  -- -------- -- ---------

With the players’ payoffs of the two stages given by Eq. ( 10.13 ), the
Nash inequalities ( 10.14 ) can be written as

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (10.15)
  -- -------- -------- -- ---------

and the strategy of defection by both the players, i.e. @xmath becomes a
NE in the second stage of the quantum game, if

  -- -------- -- ---------
     @xmath      (10.16)
  -- -------- -- ---------

Similar to the classical analysis, players’ payoffs can be found when
both decide to defect in the second stage:

  -- -------- -- ---------
     @xmath      (10.17)
  -- -------- -- ---------

The classical payoffs, when both players defect, of the Eq. ( 10.5 ) can
be recovered from Eq. ( 10.17 ) when @xmath , i.e. for an unentangled
initial state.

Similar to the classical case the players’ first-stage interaction, in
the two-stage quantum PD, amounts to a one-shot game. In this one-shot
game the payoff @xmath , from the second stage, is added to their
first-stage payoffs:

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      
     @xmath   @xmath      
              @xmath      
              @xmath      (10.18)
  -- -------- -------- -- ---------

The strategy of cooperation (that is @xmath ) can now be a NE for the
first-stage interaction in this two-stage quantum game, if

  -- -------- -- ---------
     @xmath      (10.19)
  -- -------- -- ---------

The inequalities ( 10.16 ) and ( 10.19 ) are the conditions on the
initial state when the players cooperate in their first-stage
interaction while both defect in the next stage. These conditions can be
rewritten as

  -- -------- -- ---------
     @xmath      (10.20)
  -- -------- -- ---------

For example, at @xmath and @xmath these conditions hold. Because for the
classical game the inequalities ( 10.20 ) together cannot hold, showing
why classically it is not possible that players cooperate in the first
stage knowing that they both will defect in the second.

### 10.4 Discussion

Essentially, the repeated games differ from one-shot games in that
players’ current actions can depend on their past behavior. In a
repeated bi-matrix game the same matrix game is played repeatedly, over
a number of stages that represent the passing of time. The payoffs are
accumulated over time. Accumulation of information about the “history”
of the game changes the structure of the game with time. With each new
stage the information at the disposal of the players changes and, since
strategies transform this information into actions, the players’
strategic choices are affected. If a game is repeated twice, the
players’ moves at the second stage depend on the outcome of the first
stage. This situation becomes more and more complex as the number of
stages increases, since the players can base their decisions on
histories represented by sequences of actions and outcomes observed over
increasing number of stages.

Recent findings in quantum game theory motivate a study of repeated
games in the new quantum setting. It is because useful and extensive
analysis of repeated games is already found in literature of classical
game theory. In present chapter – to look for a quantum role in repeated
games – we consider a quantum form of a well-known bi-matrix game of PD.

Classical analysis of the PD has been developed in many different
formats, including its finitely and infinitely repeated versions. In the
history of quantum games the PD became a focus of early and important
study [ 20 ] telling how to play a quantum form of a bi-matrix game. To
play a quantum form of repeated PD we select Marinatto and Weber’s
scheme. In this scheme a repeated game is played when the players select
positive numbers in the range @xmath , giving the probabilities with
which they apply the identity operator @xmath on a four-qubit pure
initial quantum state. The players’ actions in each stage are performed
on two different pairs of qubits. The classical two-stage PD corresponds
to an unentangled initial state, and the classical SGPO consists of
players defecting in both the stages. It is shown that a SGPO where the
players go for cooperation in a stage is a non-classical feature that
can be made to appear in quantum setting.

The argument presented here is based on the assumption that other games,
resulting from a play starting with a four-qubit quantum state of the
form of the Eq. ( 10.7 ), are ‘quantum forms’ of the classical two-stage
game. This assumption originates from the fact that the classical game
corresponds to a particular four-qubit pure quantum state which is
unentangled. The assumption makes possible to translate the desired
appearance of cooperation in a stage to certain conditions on the
parameters of the initial state, thus giving a SGPO where players decide
to cooperate in their first-stage interaction while they both defect in
the next stage.

One may ask about the compelling reason to choose a @xmath dimensional
Hilbert space instead of a @xmath dimensional one. A @xmath dimensional
treatment of this problem, in the same quantization scheme, involves
denominator terms in the expressions for payoff operators, when these
are obtained under the condition that classical game corresponds to an
unentangled initial state. It then leads to many ‘if-then’ conditions
before one gets finally the payoffs. On the contrary, a treatment in
@xmath dimensions is much smoother. Also a study of the concept of SGPO
in a two-stage repeated quantum game, then, becomes a logical extension
of the backwards-induction procedure proposed in the last chapter.

## Chapter 11 New proposals to play quantum games

### 11.1 Introduction

Meyer [ 19 ] and Du et al. [ 109 ] have shown that entanglement may not
be essential for a quantum game. Eisert et al.’s quantum PD was the
first proposal where entanglement was used as a resource. There has been
noticeably greater attention paid in exploiting entanglement for quantum
games. It is not unusual and can be traced back to exciting and
counter-intuitive properties of this phenomenon, as well as to its
recent enthusiastic investigation in quantum information theory [ 21 ] .

Local unitary manipulations of entangled qubits to play matrix games is
indeed an interesting concept that gives new dimensions to classical
game theory. But it does not forbid the use of other quantum mechanical
effects to play other ‘quantum forms’ of matrix games – games for which
extensive analysis in the classical domain already exists in literature
[ 104 , 108 ] . A look at the Eisert et al.’s set-up [ 20 , 46 ] makes
apparent some of its similarities to well-known Young’s double-slit
apparatus [ 110 ] . Simultaneous and local unitary manipulation of a
maximally entangled two-qubit quantum state, and its later measurement,
is the essential feature of Eisert et al.’s set-up. In Young’s
double-slit set-up, however, coherent light passes through two slits to
form a diffraction pattern on a screen facing the slits. Similarity
between these setups becomes noticeable if a comparison is made between:

-   The properties of entanglement and coherence.

-   Players’ moves in manipulations of qubits and the process of opening
    or closing the slits.

-   Wavefunction-collapsing measurement and the appearance of the
    diffraction pattern.

Such a comparison, in its turn, asks for a quantum feature that can be
exploited to give new dimension to a matrix game, when it is played
using a Young’s double-slit like apparatus. In Eisert et al.’s set-up
this quantum feature is obviously the quantum phenomenon of
entanglement. In Young’s apparatus this feature is the association of
wave-like properties to material objects like electrons, producing a
diffraction pattern on a screen. Section ( 11.2 ) exploits such
association of waves as a resource to play quantum versions of classical
games.

Playing of a game requires resources for its physical implementation.
For example, to play a bi-matrix game the resources may consist of pairs
of two-valued ‘objects’, like coins, distributed between the players.
The players perform their moves on the objects and later a referee
decides payoffs after observing the objects. Game theory usually links
players’ actions directly to their payoffs, without a reference to the
nature of the objects on which the players have made their moves.
However, playing quantum games [ 20 ] show that radically different
‘solutions’ can emerge when the same game is physically implemented on
distributed objects which are quantum mechanically correlated.

In Section ( 5.4 ) Enk and Pike’s argument [ 73 ] is briefly discussed.
Essentially it says that the emergence of new equilibrium in quantum
Prisoners’ Dilemma can also be understood as an equilibrium in a
modified form of the game. They constructed another matrix game, in
which players have access to three pure classical strategies instead of
the usual two, commenting that it ‘captures’ everything quantum
Prisoners’ Dilemma has to offer. Constructing an extended matrix with an
extra pure classical move, in their view, is justified because also in
quantum Prisoners’ Dilemma players can play moves which are
superpositions of the two classical moves.

Truly quantum pairs of objects possess non-local correlations. Though it
is impossible to have a local model of a quantum game set-up, producing
exactly the same data, but how such unusual correlations may explicitly
affect solutions of a game when implemented with quantum objects. To how
far extent solutions of a quantum game themselves can be called ‘truly
quantum’ in nature. Section ( @xmath ) tries to address these questions.

### 11.2 Quantum games with a diffraction set-up

Historically speaking, the De Broglie’s original idea [ 110 , 111 ] –
that travelling material particles have waves associated with them – was
undoubtedly the key concept behind the development of quantum physics in
early part of the twentieth century. Soon afterwards, Davisson and
Germer [ 110 ] verified the idea in their experimental demonstration of
the diffraction of electrons by crystals. De Broglie’s proposed that a
travelling electron with momentum @xmath has an associated wave of
wavelength @xmath , where @xmath is the Plank’s constant. To make @xmath
a measurable quantity, under normal laboratory conditions, the momentum
@xmath should have similar order of magnitude as @xmath . @xmath being a
very small quantity shows why it is very hard to detect waves associated
with macroscopic objects. Our motivation is to take this quantum feature
– associating wave-like properties to micro objects – as a resource that
can be used to play a quantum game. Such a quantum game can be realized
using an apparatus consisting of travelling electrons, multiple slits
intercepting them, and a resulting diffraction pattern. In this set-up a
player’s choice of a ‘pure strategy’ consists of opening or closing
slits at his/her disposal. Suppose the apparatus is adjusted such that
when @xmath approaches zero the classical game is reproduced. It can
then be argued that because an observation of a value of @xmath quite
away from zero is entirely a quantum feature, therefore, the resulting
different payoffs for the players correspond to a quantum form of the
classical game. In this setup the players’ payoffs are to be found from
the diffraction pattern formed on the screen. We show the possibility of
finding a value for @xmath that makes appear a non-classical equilibrium
in the PD when the players play only the pure strategies. The classical
game remains a subset of its quantum version because with @xmath
approaching zero the classical game is reproduced.

The motivation to play a quantum form of PD, without using the
phenomenon of entanglement, also derives from Feynman’s excellent
exposition [ 112 ] of quantum behavior of atomic objects. He describes
and compares the diffraction patterns in two similar set-ups that are
imaginary but experimentally realizable. The two set-ups consist of
bullets and electrons passing through a wall with two slits. Feynman
then describes the well-known quantum property – associating waves to
all material particles – to distinguish the diffraction patterns of
bullets and electrons. The disappearance of a pattern for the bullets,
he explains, is due to tiny wavelengths of the associated waves. For
such waves the pattern becomes very fine and, with a detector of finite
size, one cannot distinguish the separate maxima and minima. We ask why
not to play a game, in the Feynman’s imaginary experimental set-up, such
that the classical game corresponds when, in Feynman’s words, bullets
are fired; and a quantum game corresponds when electrons replace the
bullets.

#### 11.2.1 Playing Prisoners’ Dilemma

We select the PD to be played in a diffraction set-up. The classical PD,
in its general form, is represented by the following matrix:

  -- -- -- --------
           (11.1)
  -- -- -- --------

where @xmath . To make the classical game imbedded in its quantum
version the positive coefficients @xmath and @xmath , appearing in the
matrix ( 11.1 ), are translated into distances between the slits. Each
player is in control of two slits such that his/her strategy consists of
opening one of the slits and closing the other. For example, if Alice
decides to cooperate then she opens the slit @xmath and closes the slit
@xmath . Because Bob has a similar choice, therefore, all possible moves
by the players leads to the opening of two slits and closure of the
other two, with the separation between the two open slits depending on
the moves of the players. It happens when only the so-called
‘pure-strategies’ can be played by the players, which in the present
setup means to open a slit and close the other. Now, at the final stage
of the game, the action of the arbiter – responsible for finding the
payoffs when the players have made their moves – consists of measuring
the distance between two peaks of the diffraction pattern. This
peak-to-peak distance is known [ 110 ] to be @xmath , where @xmath is
the separation between the open sits and @xmath is the wavelength
associated with the bombarded material objects, like electrons. Payoffs
to the players are functions of @xmath and it, then, explains why it is
useful to translate the coefficients of the matrix of the classical game
into the separations @xmath between the slits. When bullets are fired,
which means the particles become heavier and corresponding @xmath is
very nearly zero, the payoffs become classical and depend only on @xmath
i.e. the separation between the slits. A payoff representation in terms
of @xmath contains both the classical and quantum aspects of the matrix
game played in this set-up. The experimental set-up shown in the Fig. (
11.1 ) sketches the diffraction set-up to play a quantum game.

For PD the payoffs are symmetric for the players and a single equation
can describe the payoffs to both the players when their strategies are
known. A usual way to express it is to write @xmath for the payoff to
the @xmath -player against the @xmath -player. Such a single equation
representation is usually used in evolutionary games [ 32 ] consisting
of symmetric bi-matrix conflicts. The @xmath -player is referred to as
the ‘focal’ player and the @xmath -player as just the ‘other’ player.
The PD is one such example for which a single payoff equation can
capture the essence of the idea of a symmetric NE. A strategy @xmath is
a symmetric NE if

  -- -------- -- --------
     @xmath      (11.2)
  -- -------- -- --------

saying that the focal player cannot be better off by diverging away from
@xmath . Because the set-up of the Fig. ( 11.1 ) involves coefficients
in the classical payoff matrix corresponding to the first player,
therefore, finding a symmetric NE with Eq. ( 11.2 ) becomes immediately
possible when the first player is taken as focal. It also shows why
writing payoff as @xmath is relevant to the set-up of the Fig. ( 11.1 ).
For example, classically the strategy of defection @xmath is a symmetric
NE because @xmath , where the players’ moves consist of only the pure
strategies.

In the set-up of Fig. ( 11.1 ) for every pure strategy move the players
have option to play, a unique separation @xmath between the slits is
obtained that can have four possible values i.e. @xmath or @xmath .
Classically @xmath , @xmath , @xmath and @xmath . It is observed in the
Fig. ( 11.1 ) that the classical payoff to the focal player, against the
other, can be equated to the separation between the two open slits
@xmath .

Now assume that instead of simply @xmath the arbiter uses the payoff
equation:

  -- -------- -- --------
     @xmath      (11.3)
  -- -------- -- --------

where @xmath is a positive constant that can be called a scaling factor
. @xmath , obviously, reduces to its classical counterpart when @xmath
is very nearly zero. Suppose the strategy of cooperation @xmath is a
symmetric NE:

  -- -------- -- --------
     @xmath      (11.4)
  -- -------- -- --------

It requires @xmath . For electrons of mass @xmath travelling with
velocity @xmath it gives @xmath Supposing @xmath and @xmath are both
non-zero, the arbiter’s problem consists of finding an appropriate value
for the scaling factor @xmath that brings @xmath into a reasonable range
from experimental point of view. When the electrons have associated
wavelength @xmath the strategy of cooperation becomes a symmetric NE,
and each player gets a payoff @xmath . Similarly when the pure strategy
of defection is a symmetric NE in the quantum game, we have

  -- -------- -- --------
     @xmath      (11.5)
  -- -------- -- --------

It requires @xmath . After the scaling factor @xmath is decided the
wavelength @xmath determines which pure strategy should be a symmetric
NE. Two ranges for @xmath can be indicated as @xmath and @xmath .
Defection and cooperation are symmetric NE for these ranges,
respectively. Because the constants @xmath and @xmath are all positive
the classical game is in the first range of @xmath . Non-classical
equilibrium of cooperation shows itself in the second range of @xmath .

Du et al.’s recent analysis [ 113 ] of the quantum PD, with players’
access to Eisert’s two-parameter set of unitary operators, has shown an
intriguing structure in the game as a function of the amount of
entanglement. The game becomes classical when the entanglement vanishes.

In the set-up of Fig. ( 11.1 ) the quantity @xmath behaves in a way
similar to the amount of entanglement in Du et al.’s analysis [ 113 ,
114 ] . But this set-up is devoid of the notion of entanglement and
relies instead on a different quantum aspect. An aspect which is as much
‘quantum’ in nature as the phenomenon of entanglement for qubit systems.

There is however a difference, to be noticed, between the set-ups of
Eisert et al. and that of the Fig. ( 11.1 ). Players’ actions in Eisert
et al.’s set-up are quantum mechanical in nature in that they make moves
with quantum operators. In the present set-up, on the contrary, the
players’ actions are entirely classical consisting of opening or closing
slits. In a sense it is similar to the players’ actions in Marinatto and
Weber’s scheme. In their scheme players possess quantum operators but
they apply them on an initial quantum state with classical
probabilities; so that the players’ moves can be considered classical as
well. It can be said that, apart from the work of Eisert et al., the set
up of Fig. ( 11.1 ) is also motivated, to an almost equal extent, by the
Marinatto and Weber’s idea of playing a quantum version of a matrix
game.

### 11.3 Performing EPR type experiments to play a bi-matrix game

To address the question raised in the Section ( 11.1 ), i.e. to how much
extent a quantum game can be called ‘truly quantum’, following two
constraints are suggested [ 115 ] which a quantization scheme should
follow:

(C1). In both classical and quantum version of the game the same set of
moves should be made available to the players.

(C2). The players agree together on explicit expressions for their
payoffs which must not be modified when introducing the quantized
version of the game.

With these constraints one can hope that only the nature of
correlations, existing between the objects the players receive, will
decide whether the resulting game is classical or quantum.

Consider a symmetric bi-matrix game between two players Alice and Bob
with the matrix representation:

  -- -- -- --------
           (11.6)
  -- -- -- --------

For which the mixed strategy payoffs for the players can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (11.7)
  -- -------- -------- -- --------

where the constants @xmath and @xmath can be found in terms of @xmath
and @xmath , the coefficients of the bi-matrix ( 11.6 ). The NE defining
conditions are

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (11.8)
  -- -------- -------- -- --------

For example, for PD we may have @xmath and @xmath that reduce the
inequalities ( 11.8 ) to

  -- -------- -------- -- --------
     @xmath   @xmath      
     @xmath   @xmath      (11.9)
  -- -------- -------- -- --------

It produces @xmath or @xmath as the unique equilibrium.

#### 11.3.1 Quantum correlation games

The idea of a ‘correlation game’ in the Ref. [ 115 ] was introduced to
put forward a scheme to play a quantum version of a bi-matrix game that
respects the constraints C1 and C2 of the Section ( 11.3 ). Its
motivation comes from EPR type experiments performed on singlet states
involving correlations of the measurement outcomes. In such experiments
the Bell’s inequalities [ 38 ] are well-known to be the constraints –
derived under the principle of local causes – on correlations of
measurement outcomes of two-valued (dichotomic) variables. Truly quantum
correlations are non-local in character and violate the inequalities.

The two parties involved in the usual  EPR type setting are recognized
as the players. Repeated measurements are performed on correlated pairs
of objects by the two players, each receiving one half.

Players Alice and Bob share a Cartesian coordinate system between them
and each player’s move consists of deciding a direction in a given
plane. For Alice and Bob these are the @xmath - @xmath and @xmath -
@xmath planes respectively. Call @xmath and @xmath the unit vectors
representing the players’ moves. Both players have a choice between two
different orientations i.e. @xmath and @xmath for Alice and @xmath and
@xmath for Bob. Each player measures the angular momentum or spin of
his/her respective half in one of two directions. Let the vectors @xmath
and @xmath make angles @xmath and @xmath , respectively, with the @xmath
-axis.

To link the players’ moves, represented now by angles @xmath and @xmath
, to the usual probabilities @xmath and @xmath appearing in a bi-matrix
game, an invertible function @xmath is made public at the start of a
game. The @xmath -function maps @xmath to @xmath and allows to translate
the players’ moves to the probabilities @xmath and @xmath .

The results of measurements performed on dichotomic variables may take
only the values @xmath . These are represented by @xmath and @xmath for
the directions @xmath and the @xmath -axis respectively. Correlations
@xmath and @xmath can then be found from the measurement outcomes, where
the two entries in a bracket represent the players’ chosen directions.

In a correlation experiment in which the @xmath -axis is the common
direction for the players, the Bell’s inequality ¹ ¹ 1 For perfectly
anticorrelated pairs the right hand side of the inequality is @xmath .
is written [ 38 ] as

  -- -------- -- ---------
     @xmath      (11.10)
  -- -------- -- ---------

The classical correlations corresponding to the above situation, when
written in terms of @xmath and @xmath , are known [ 38 ] to be
invertible. This invertibility allows to express @xmath and @xmath in
terms of the correlations @xmath and @xmath . The @xmath -function
allows now to translate @xmath and @xmath to @xmath and @xmath ,
respectively. In effect the classical bi-matrix payoffs are re-expressed
in terms of the classical correlations @xmath and @xmath .

One can now claim that the classical game is given by definition in
terms of the correlations. The point for such a re-expression of the
classical game is that it opens the way to ‘quantum’ version of the
game. It, of course, happens when the correlations become quantum
mechanical.

In the setting of a correlation game the players’ payoffs involve only
the correlations @xmath and @xmath , instead of the three correlations
@xmath and @xmath present in the inequality ( 11.10 ), when @xmath -axis
is the common direction between the players. This aspect results in [
115 ] obtaining ‘quantum’ payoffs even when the correlations are local
and satisfy the inequality ( 11.10 ).

The motivation for introducing EPR type setting to bi-matrix games is to
exploit quantum correlations to generate quantum payoffs. So that, when
the correlations are local, the classical game must be produced. We show
below the possibility of such a connection by a different setting in
which the classical payoffs are always obtained whenever the
correlations @xmath and @xmath satisfy the Bell’s inequality ( 11.10 ).

#### 11.3.2 A new approach towards defining a correlation game

Consider an EPR type set-up to play a game between two players.
Following rules apply:

1.  A player’s move consists of defining a direction in space by
    orientating a unit vector. However, this direction is not confined
    to only the @xmath - @xmath or @xmath - @xmath planes. A player’s
    choice of a direction can be anywhere in three-dimensional space.
    Therefore, Alice’s move is to define a unit vector @xmath and,
    similarly, Bob’s move is to define a unit vector @xmath .

2.  The @xmath -axis is shared between the players as the common
    direction.

3.  On receiving a half of a correlated pair, a player measures its spin
    in one of the two directions. For Alice these directions are @xmath
    and @xmath and for Bob these directions are @xmath and @xmath .

4.  Each player measures spin with equal probability in his/her two
    directions.

5.  Players agree together on explicit expressions giving their payoffs
    @xmath and @xmath in terms of all three correlations i.e.

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (11.11)
  -- -------- -------- -- ---------

A game defined by these rules eliminates the need for introducing the
@xmath -functions. The rules are also consistent with the constraints C1
and C2 and the idea of a correlation game essentially retains its
spirit.

#### 11.3.3 Defining correlation payoffs

A possible way is shown now to define the correlation payoffs ( 11.11 )
which reduce to the classical payoffs ( 11.7 ) whenever the correlations
@xmath and @xmath satisfy the inequality ( 11.10 ).

Consider two quantities @xmath and @xmath defined as:

  -- -------- -- ---------
     @xmath      (11.12)
  -- -------- -- ---------

The quantities @xmath and @xmath can adapt only real values because the
correlations @xmath and @xmath are always in the interval @xmath .
Consider now the quantities @xmath and @xmath . By definition @xmath and
@xmath are non-negative, therefore, the quantity @xmath always remains
non-negative. It is observed that if @xmath @xmath then the correlations
@xmath and @xmath always satisfy the inequality ( 11.10 ). It is because
if @xmath then @xmath . But @xmath so that @xmath which results in the
inequality ( 11.10 ). All the steps in the proof can be reversed and it
follows that whenever the correlations @xmath and @xmath satisfy the
Bell’s inequality, the quantity @xmath remains non-negative

For a singlet state satisfying the inequality ( 11.10 ) both the
quantities @xmath and @xmath are non-negative and must have maxima.
Hence, it is possible to find two non-negative numbers @xmath and @xmath
in the range @xmath , whenever the inequality ( 11.10 ) holds. Because
@xmath we have @xmath and @xmath . The numbers @xmath and @xmath are in
the range @xmath when the inequality holds. These numbers are also
independent from each other.

The above argument paves the way to associate a pair @xmath of
independent numbers to the players’ moves @xmath , that is

  -- -------- -- ---------
     @xmath      (11.13)
  -- -------- -- ---------

where the numbers @xmath are in the interval @xmath when the input
states do not violate the inequality ( 11.10 ) for all direction pairs (
@xmath ). The pair @xmath is related to the two directions as

  -- -------- -- ---------
     @xmath      (11.14)
  -- -------- -- ---------

It can be noticed that more than one pair @xmath of directions may,
however, correspond to a given pair of numbers. The converse, although,
is not true for known input states. That is, for known input states,
only one pair @xmath can be obtained from a given pair @xmath of
directions.

Players’ payoffs can now be re-expressed by making the replacements:

  -- -------- -- ---------
     @xmath      (11.15)
  -- -------- -- ---------

which lead to re-writing the classical payoffs ( 11.7 ) as

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (11.16)
  -- -------- -------- -- ---------

or more explicitly:

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (11.17)
  -- -------- -------- -- ---------

This expression shows that a player’s payoff now depends on the
direction s/he has chosen. The payoffs ( 11.17 ) are obtained under the
constraints C1 and C2 and are functions of all the three correlations.

The relations ( 11.13 ) can also imagined as follows. When Alice decides
a direction @xmath in space, it corresponds to a curve in the @xmath -
@xmath plane. Similarly, Bob’s decision of the direction @xmath defines
another curve in the @xmath - @xmath plane. The relations ( 11.15 )
assure that only one pair @xmath can then be obtained as the
intersection between the two curves.

The set-up assures that for input product states all of the players’
moves @xmath result in the correlation payoffs ( 11.17 ) generating
identical to the classical payoffs ( 11.7 ). For such input states the
relations ( 11.15 ) give the numbers @xmath in the interval @xmath ,
which can then be interpreted as probabilities. However, for input
states for which the inequality ( 11.10 ) is violated in some
directions, a pair @xmath @xmath cannot be associated to those
directions. It is because for entangled states there exist pairs of
directions for which the corresponding quantity @xmath becomes negative.
For those directions the correlation payoffs ( 11.17 ) would generate
results that can only be understood, within the structure of classical
payoffs ( 11.7 ), by invoking negative probabilities.

#### 11.3.4 Nash equilibria of quantum correlation games

Because the players’ moves consist of defining directions in space, the
Nash inequalities are

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (11.18)
  -- -------- -------- -- ---------

where the pair @xmath corresponds to the pair @xmath via the relations (
11.15 ). The inequalities ( 11.18 ) are same as the inequalities ( 11.8
), except their re-expression in terms of the directions.

When the correlations in the input state correspond to an entangled
state, the payoff relations ( 11.17 ) would lead to disappearance of the
classical equilibria. It can be seen, for example, by considering the
Nash inequalities for the Prisoners’ Dilemma ( 11.9 ). Let the
directional pair @xmath correspond to the equilibrium @xmath , that is,
the inequalities ( 11.18 ) are

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      (11.19)
  -- -------- -------- -- ---------

Assume the players receive input states that are entangled. There will
now exist pairs of players’ moves @xmath and @xmath that would make the
quantity @xmath . The pair @xmath will not correspond to a point in the
@xmath - @xmath plane where @xmath .

It can also be noticed that for entangled input states the directional
pair @xmath does not remain a NE. It is because the pair @xmath is a NE
only if players’ choices of any directional pair @xmath corresponds to a
point in the @xmath - @xmath plane where @xmath .

Because for entangled input states there exist pairs of players’ moves
@xmath that do not correspond to points in the @xmath - @xmath plane
with @xmath . Hence, the directional pair @xmath does not remain a NE in
the quantum game. Interestingly, the disappearance of the classical
equilibrium now becomes directly linked with the violation of the
inequality ( 11.10 ) by the correlations in the input states.

#### 11.3.5 Quantum game as another classical game?

Coming back to the questions raised in the Section ( 11.1 ), we now try
to construct a classical bi-matrix game corresponding to a quantum game
resulting from the payoff relations ( 11.17 ). The classical game is
assumed to have the same general structure of players’ payoffs as given
in Eqs. ( 11.7 ). This assumption derives from the hope that the quantum
game, corresponding to correlations in the input states that violate the
inequality ( 11.10 ), is also equivalent to another symmetric bi-matrix
game. It is shown below that such a construction cannot be permitted.

Suppose the correlations in the input states violate the inequality (
11.10 ). A pair of directions ( @xmath ) can now be found for which the
Bell’s inequality is violated. For Alice’s move to select the direction
@xmath her payoff, given by the Eqs. ( 11.17 ), is

  -- -------- -- ---------
     @xmath      (11.20)
  -- -------- -- ---------

where @xmath and @xmath and @xmath . Assuming that the constants @xmath
and @xmath define a ‘new’ symmetric bi-matrix game the Bob’s payoff is

  -- -------- -- ---------
     @xmath      (11.21)
  -- -------- -- ---------

But in fact ( 11.21 ) is not obtained as the Bob’s payoff in our quantum
game when he goes for the direction @xmath . Bob’s payoff is, in fact,
given as

  -- -------- -- ---------
     @xmath      (11.22)
  -- -------- -- ---------

which may not necessarily coincide with the payoff given in the Eq. (
11.21 ). Hence, the game resulting from the presence of quantum
correlations in the input states cannot be simply explained as another
classical symmetric bi-matrix game: a game obtained by defining new
coefficients of the matrix involved. Players’ payoffs in the quantum
game are found to reside outside the structure of payoffs in a classical
symmetric bi-matrix game. The payoffs can be explained within this
structure only by invoking negative probabilities.

An asymmetric bi-matrix game can, of course, be constructed having
identical solutions to the quantum game. In fact for any quantum game a
classical model can always be constructed that summarizes the complete
situation and has identical to the quantum solutions, as far as the
players’ payoffs are concerned. It would be a model that relates
players’ moves to their payoffs in accordance with the usual approach in
game theory. But constructing such a model is not an answer to our
original question: How solutions of a game are affected by the presence
of quantum correlations between the physical objects used to implement
the game? It is because the question can then simply be rephrased as:
What if the modified classical game is played with physical objects
having quantum correlations?

#### 11.3.6 Discussion

The idea of a correlation game is about re-expression of payoffs of a
classical bi-matrix game in terms of correlations of measurement
outcomes made on pairs of disintegrating particles. The measurement
outcomes are dichotomic variables and their correlations are obtained by
averaging over a large number of pairs. Bell’s inequalities represent
constraints on these correlations obtained under the principle of local
causes. A re-expression of the classical payoffs of a bi-matrix game in
terms of correlations opens the way to explicitly see the effects of
quantum correlations on the solutions of the game.

We have proposed a new setting where two players play a bi-matrix game
by repeatedly performing measurements on correlated pairs of objects.
The setting is motivated by EPR type experiments performed on singlet
states. On receiving a half of a pair, a player makes a measurement of
its spin in one of the two directions available to him/her. The
measurements are performed with equal probability in the two directions.
Both players share a common direction and defining the other direction
is a player’s move .

We show how within this set-up a correlation version of a symmetric
bi-matrix game can be defined. The correlation game shows some
interesting properties. For example the correlation game reduces to the
corresponding classical game when the correlations in the input states
are local and do not violate the Bell’s inequality ( 11.10 ). However,
when the inequality is violated, the stronger correlations generate
results that can be understood, within the structure of classical
payoffs in a symmetric bi-matrix game, only by invoking negative
probabilities. It is shown that a classical NE is affected when the game
is played with input states having quantum correlations. The proposed
set-up also provides a new perspective on the possibility of
reformulating the Bell’s inequalities in terms of a bi-matrix game
played between two spatially-separated players.

## Chapter 12 Conclusions

To conclude a summary of the results developed in this thesis is
presented below. The results 1 – 8 refer to Eisert et al.’s and
Marinatto and Weber’s schemes of quantization of matrix games.

1.  In a population engaged in symmetric bi-matrix classical game of
    Prisoners’ Dilemma an invasion of classical ESS is possible by the
    mutants exploiting Eisert’s two-parameter set of quantum strategies.
    We presented an example of an asymmetric quantum game between two
    players in which a strategy pair can be an ESS for either classical
    or quantum version of the game, even when it remains a NE in both
    the versions. It shows quantization can change evolutionary
    stability of Nash equilibria in certain asymmetric bi-matrix games.

2.  ESS concept was originally defined for symmetric bi-matrix contests.
    We showed that quantization can also change evolutionary stability
    of a NE in certain types of symmetric bi-matrix games. It
    immediately makes study of quantum games also relevant to
    evolutionary game theory and conversely. Hence, quantization not
    only leads to new equilibria but it also presents itself also as
    another refinement notion of the NE concept.

3.  Like pure strategies the evolutionary stability of mixed strategies
    can also change as a symmetric bi-matrix game is switched from its
    classical to quantum form. However, for mixed strategies we require
    more general initial quantum states.

4.  Rock-Scissors-Paper (RSP) is a two-player three-strategy game. We
    consider a slightly modified form of RSP played in its classical
    version. A mixed NE exists that is not an ESS. We find a quantum
    form of the same game in which the classical NE becomes an ESS. The
    quantum form is obtained when the game is played with an initial
    entangled state.

5.  Quantization can change properties of equilibria of replicator
    dynamics. We consider a game played in a population setting with the
    underlying process of replicator dynamics. We found a ‘quantum form’
    of the replicator equations, which retain their form as that of
    Lotka-Volterra type. The effects of quantization of the game on a
    saddle or a center of the dynamics are then studied. It is found
    that a saddle (center) in the classical game can be a center
    (saddle) in certain quantum form of the game. A saddle or center in
    a classical (quantum) game can not be, however, an attractor or a
    repeller in quantum (classical) form of the game.

6.  A symmetric cooperative game played by three players is analyzed in
    its classical and quantum forms. In classical form of this game
    forming a coalition gives advantage to players and players are
    motivated to do so. In quantum form of the game, however, an initial
    quantum state can be prepared by the arbiter such that forming the
    same coalition is of no advantage.

7.  A comparison between the NE in Cournot game with the
    backwards-induction outcome in classical Stackelberg duopoly shows
    that having Alice (who acts first) know that Bob (who acts second)
    knows Alice’s move hurts Bob. In fact in classical version of the
    Stackelberg game Bob should not believe that Alice has chosen its
    Stackelberg quantity. We have shown that there can be a quantum
    version of Stackelberg duopoly where Bob is not hurt even if he
    knows the quantity chosen by Alice. The backwards-induction outcome
    of this quantum game is same as the NE in classical Cournot game,
    where decisions are made simultaneously and there is no such
    information that hurts a player.

8.  In infinitely repeated versions of the classical game of Prisoners’
    Dilemma it is established [ 108 ] that cooperation can occur in
    every stage of a subgame-perfect outcome (SGPO), even though the
    only NE in the stage game is defection. We find how cooperation in
    two-stage Prisoners’ Dilemma can be achieved by quantum means. In
    two-stage Prisoners’ Dilemma getting a SGPO where players cooperate
    in the first stage is a result with no classical analogue. We have
    also introduced a possible way to study the concept of SGPO in
    repeated quantum games.

9.  In the standard set-ups to play a quantum game a measure of
    entanglement for a qubit system is introduced. Quantum version of
    the game reduces to classical when the measure becomes zero. We
    suggested a set-up that exploits another resource from quantum
    physics, i.e. the association of waves with travelling material
    objects like electrons. We show how in this set-up such association
    of waves can lead to a non-classical equilibrium in the Prisoners’
    Dilemma. With associating wavelength approaching zero the quantum
    aspect disappears and the classical game is reproduced.

10. Playing a symmetric bi-matrix game is usually physical implemented
    by sharing pairs of ‘objects’ between two players. We proposed a new
    setting that explicitly shows the effects of quantum correlations
    between the pairs on the structure of payoff relations and
    ‘solutions’ of the game. The setting is based on a re-expression of
    the game such that the players play the classical game only if their
    moves are performed on pairs of objects having correlations that
    satisfy the Bell’s inequalities. On players receiving pairs with
    quantum correlations the resulting game cannot be considered another
    classical symmetric bi-matrix game. Also the Nash equilibria of the
    game are found to be decided by the nature of the correlations.

###### Acknowledgement 1

I am grateful to Dr. A. H. Toor for supervising this thesis. I remain
particularly thankful to him for the freedom he granted me in the choice
of topics for the thesis. I am obliged to Prof. Razi Naqvi (NTNU,
Trondheim, Norway) for encouragement, as well as help, that he provided
during the early stages of research. I am thankful to Dr. Mark Broom
(University of Sussex, UK) for giving many remarks while he replied to
my emails. He made available excellent reports on his website that, in
fact, aroused my interest in evolutionarily stable strategies (ESSs). I
am thankful to Dr. Jens Eisert (University of Potsdam, Germany) for
replying to all of my emails and queries. I happened to see his
pioneering paper on quantum games – which indeed provided much of the
later motivation for interest and developments in quantum games – during
the same time when I read about ESSs. Thanks to Dr. Luca Marinatto
(Abdus Salam ICTP, Trieste, Italy) for replying to my emails. I am
thankful to Prof. Dr. S. Azhar Abbas Rizvi (Quaid-i-Azam University) for
offering a course on probability, which helped me later to follow game
theory; to Dr. Qaiser Naqvi (Quaid-i-Azam University) for motivating
discussions on a broad range of topics; to Mr. Ahmad Nawaz (Quaid-i-Azam
University) for many exciting arguments on quantum games. During most of
the research, presented in this thesis, I was supported by the Pakistan
Institute of Lasers and Optics (PILO), Rawalpindi, Pakistan. I remain
thankful to my ex-colleagues Dr. M. M. Gualini and Dr. Mian Ashraf for
encouragement as well as guidance that they provided on many occasions.