## Introduction

A classical theorem in symplectic geometry due to Duistermaat and
Heckman [ DH82 ] states, that the volume of a symplectic reduction
@xmath , where @xmath is a compact symplectic manifold and @xmath a
compact Lie group, is determined by local data around the fixed points
of the @xmath -action on @xmath . This thesis grew out of the question
whether a similar localization theorem could hold in an algebraic
context, were manifolds are replaced by algebraic varieties and the
symplectic volume by a motivic or @xmath -adic volume.

By the motivic volume of a variety we mean here simply its class in the
Grothendieck ring of varieties, and the @xmath -adic volume of a variety
over some local field @xmath comes from the natural Haar measure on
@xmath . As these two volumes have very little in common with the real
symplectic volume, coming from integrating the Liouville form, there is
no way to apply Duistermaat’s and Heckman’s ideas directly. Instead we
will use their theorem as a guiding principle, which we apply in each of
the chapters 2 , 3 and 4 to different situations.

This approach turns out to be quite fruitful and we obtain in each case
explicit formulas for the respective volumes. The (sometimes
conjectural) interpretations of these volumes connect our computations
with the geometry of various moduli spaces, non-abelian Hodge theory,
representations of quivers and even singularity theory.

The thesis is divided in 4 chapters. Chapter 1 contains background
material for the later chapters and no original work apart from
Definition 1.5 and Proposition 1.6 . In Section 1.1 we explain in more
detail the motivation coming from symplectic geometry and the
Duistermaat-Heckman theorem. In Section 1.2 we recall the definition of
the Grothendieck ring of varieties @xmath and introduce the Grothendieck
ring with exponential @xmath [ CL10 , HK09 ] . The latter enables us to
talk about motivic character sums, which leads to the notion of motivic
Fourier transform. This Fourier transform is the key to exploit
localization phenomena for our computations in the Chapters 2 and 3 .
Section 1.3 then explains how to extract geometrical and topological
information about a variety from its motivic volume. Finally, in Section
1.4 we discuss some basic combinatorics of hyperplane arrangements.

We now summarize the original results of this thesis, which are
contained in the Chapters 2 , 3 and 4 . More details on the individual
sections are given at the beginning of each chapter.

#### Motivic Classes of Symplectic Reductions of Vector Spaces

In this chapter we study symplectic reductions of vector spaces and in
particular the two prominent examples of hypertoric varieties and
Nakajima quiver varieties. In Section 2.1 we construct these symplectic
reductions algebraically using geometric invariant theory and explain
how to compute in principle their motivic class (or volume) as an
element in @xmath , or more precisely in the localization @xmath , where
@xmath denotes the class of @xmath in @xmath . The main ingredient here
is Proposition 2.3 , a Fourier transform argument inspired by the finite
field computations in [ Hau06 ] , which exhibits some sort of
localization phenomenon as explained in Remark 2.4 .

Section 2.2 is about hypertoric varieties. In the generic case they are
smooth algebraic varieties @xmath constructed out of a hyperplane
arrangement @xmath and their geometry is closely related to the
combinatorics of @xmath [ BD00 , HS02 ] . Using our motivic localization
formalism we prove a formula for the motivic class of @xmath in terms of
the intersection lattice of flats @xmath and the Möbius function @xmath
(see Section 1.4 for details).

###### Theorem 0.1.

The motivic class of the generic hypertoric variety @xmath in @xmath is
given by the formula

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the rank of @xmath and @xmath the number of
hyperplanes in @xmath .

In Section 2.3 we repeat the same kind of computations for Nakajima
quiver varieties. Here the input data is a quiver @xmath , that is a
finite vertex set @xmath , a set of arrows @xmath and maps @xmath
sending an arrow to its source and target. In [ Nak94 ] [ Nak98 ]
Nakajima associates to @xmath and two dimension vectors @xmath a smooth
algebraic variety @xmath called Nakajima quiver variety. Our main result
here is again a formula for the class of @xmath in @xmath . Explicitly
let @xmath be the set of partitions. For @xmath we write @xmath for its
size and @xmath for the multiplicity of @xmath in @xmath . Given any two
partitions @xmath we define their inner product as @xmath Then we prove

###### Theorem 0.2.

For a fixed dimension vector @xmath the motivic classes of the Nakajima
quiver varieties @xmath in @xmath are given by the generating function

  -- -- --
        
  -- -- --

where @xmath denotes half the dimension of @xmath .

We should mention that both Theorem 0.1 and 0.2 generalize known
formulas for the number of points of the respective varieties over a
finite field @xmath , when we replace everywhere @xmath by @xmath [
Hau06 , Hau10 , PW07 ] . The real insight comes from the idea of using
Grothendieck rings with exponentials in order to perform the Fourier
transform computations motivically.

#### Open de Rham Spaces

Chapter 3 studies the motivic classes of open de Rham spaces and is part
of a joint project with Tamás Hausel and Michael Wong [ HWW ] . In order
to define an open de Rham space, we fix an effective divisor @xmath on
@xmath and at each point in the support of @xmath some local data called
a formal type. Then the open de Rham space @xmath is defined as the
moduli space of connections on the trivial rank @xmath bundle on @xmath
with poles along @xmath with prescribed formal types at the punctures.
If the formal types are chosen generically, @xmath is a smooth affine
variety and can be described as a symplectic fusion of coadjoint orbits
for the groups @xmath for @xmath [ Boa01 ] .

The same motivic Fourier transform formalism already used in Chapter 2
allows us to compute the class of @xmath in @xmath , at least when all
the poles are prescribed to be of order at least @xmath . We write
@xmath for the set of partitions of size @xmath . For a partition @xmath
we define the numbers @xmath and @xmath and furthermore we put

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 0.3.

If the formal types are chosen generically and all poles are prescribed
to be of order at least @xmath , the motivic class of @xmath in @xmath
is given by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

where @xmath denotes the degree of @xmath and @xmath the number of
points in @xmath .

The proof uses motivic Fourier transform and convolution to reduce the
computation to a simpler one at each individual pole. The condition that
a pole has order at least @xmath ensures then, that the computation
localizes from the whole Lie algebra @xmath to the subspace of
semisimple elements.

By passing to finite fields and using results from [ HLRV11 ] the same
formula holds under the weaker condition that only one pole has to be of
order at least @xmath .

As we will show in [ HWW ] , these formulas are in agreement with the
predictions of Hausel, Mereb and Wong [ HMW16 ] on the mixed Hodge
polynomial of wild character varieties, which was the original
motivation for studying the motivic class of @xmath .

#### Push-forward Measures of Moment Maps over Local Fields

In Chapter 4 we consider the same situation as in Chapter 2 , but
instead of the motivic measure we consider the Haar measure coming from
fixing our base field to be a local field @xmath with ring of integers
@xmath . More precisely we consider as in Section 2.2 a hyperplane
arrangement @xmath of rank @xmath consisting of @xmath hyperplanes and
the corresponding hypertoric moment map

  -- -------- --
     @xmath   
  -- -------- --

Then @xmath is by definition given by a homogeneous polynomial of degree
@xmath and as it turns out, a similar localization philosophy as we used
in the previous chapters leads in this situation to a formula for the
Igusa zeta function @xmath of @xmath . Here @xmath can be thought of as
a complex variable, and in fact the general theory for those zeta
functions will imply, that @xmath is a rational function in @xmath ,
where @xmath denotes the cardinality of the the residue field of @xmath
[ Igu00 ] . This rational function can be written in terms of the
combinatorics of @xmath as follows (we refer to Section 1.4 for details
on the notation).

###### Theorem 0.4.

For an essential hyperplane arrangement @xmath the Igusa zeta function
@xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where the sum is over all proper chains of flats in @xmath of length
@xmath and for every flat @xmath we put @xmath .

As an immediate consequence of the theorem we see that the real parts of
the poles of @xmath are amongst the negative integers @xmath for @xmath
. In Section 4.5 we derive a sufficient criterion for when @xmath is an
actual pole of @xmath . The interest in such an analysis comes from
Igusas’s long standing monodromy conjecture [ Igu88 ] , which describes
the poles of @xmath for any polynomial @xmath in terms of the
singularities of @xmath .

In an other direction consider the finite rings @xmath , where @xmath
denotes the unique maximal ideal and @xmath . Then assuming that @xmath
is coloop-free, Theorem 0.4 implies that the asymptotic number of
solutions to @xmath in @xmath , that is

  -- -------- --
     @xmath   
  -- -------- --

converges to a rational function in @xmath . After multiplying @xmath by
an explicit factor we obtain a polynomial @xmath . Using the functional
equation for Igusa zeta functions of homogeneous polynomials [ DM91 ] ,
we show that @xmath is palindromic and based on numerical evidence we
conjecture furthermore, that @xmath has positive coefficients,
Conjecture 4.32 .

Finally, when @xmath is a induced from a quiver @xmath it is natural to
ask for a relation between the number of solutions of the moment map
equation @xmath and the number of indecomposable representations of
@xmath by a theorem of Crawley-Boevey and Van den Bergh [ CBVdB04 ] .
And indeed, the polynomial @xmath seems to agree with the asymptotic
number of indecomposable representations of @xmath over @xmath up to a
factor, see Conjecture 4.37 .

## 1 Generalities

### 1.1 Symplectic geometry

A real manifold @xmath is symplectic if it admits a non-degenerate,
closed @xmath -form @xmath . For such a form to exist it is certainly
necessary, that @xmath is even. Then @xmath will induce a natural
measure @xmath on @xmath , called the Liouville measure , given by
integrating the volume form @xmath .

Next consider a compact Lie group @xmath acting on @xmath by
symplectomorphisms, that is @xmath for every @xmath . Such an action is
Hamiltonian if there exists a map

  -- -------- --
     @xmath   
  -- -------- --

satisfying the following two properties:

-   For every @xmath there is an equality of @xmath -forms @xmath ,
    where @xmath denotes the vector field on @xmath generated by @xmath
    .

-   @xmath is @xmath -equivariant for the coadjoint action of @xmath on
    @xmath .

In this case @xmath is called a moment map for the @xmath -action on
@xmath . From the first condition we deduce in particular, that @xmath
is a regular value of @xmath if and only if @xmath acts locally freely
on @xmath . Hence if @xmath and @xmath acts freely on @xmath we can
consider the quotient manifold

  -- -------- --
     @xmath   
  -- -------- --

By a theorem of Marsden and Weinstein [ MW74 ] the manifold @xmath is
again symplectic and hence admits in particular its own Liouville
measure @xmath . The dependence of @xmath on @xmath is described by a
theorem if Duistermaat and Heckman [ DH82 ] , which we explain now.

As this section serves mostly as a motivation we restrict ourselves to
the case where @xmath is a torus, @xmath is compact and the fixed point
locus @xmath is discrete. Then for any @xmath we get a torus action on
the tangent space @xmath . Equipping @xmath with a compatible complex
structure, we write @xmath for the weights of this action.

###### Theorem 1.1.

[ DH82 , Theorem 4.1] For any @xmath with @xmath for all @xmath the
Fourier transform of the push-forward measure @xmath is given by

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

The slogan we take away from ( 1 ) is, that the density of @xmath varies
evenly on @xmath away from @xmath and hence the only contributions in
the Fourier transform come from @xmath . Their theorem was later
reinterpreted by Atiyah and Bott as a localization theorem in
equivariant cohomology [ AB84 ] , which explains the term ’localization’
in the title of this thesis.

In what follows we will however be interested in a more algebraic
setting, where @xmath is a (smooth) algebraic variety over some field
@xmath . It still makes sense to talk about symplectic forms on @xmath
and moment maps of an action of an algebraic group on @xmath . In this
generality the Liouville measure doesn’t makes sense of course, instead
one can consider the tautological motivic measure, which we introduce in
Section 1.2 below. Also if @xmath is a local field one can in some sense
refine this motivic measure using the Haar measure on @xmath .

It turns out that in both situations there is a notion of Fourier
transform with respect to these measures. Therefore it makes sense to
ask whether there is some sort of localization theorem in this algebraic
setting. The results in this thesis can be seen as a series of examples,
which indicate that such a theorem might exist, even though there are
still too many problems in order to make a precise conjecture.

### 1.2 Grothendieck rings, exponentials and Fourier transform

In this section we start by introducing various Grothendieck rings with
exponentials following closely [ CLL13 ] . This allows us to define a
naive Fourier transform and prove a Fourier inversion formula for
motivic functions. We should mention that nothing in this section is
new, but rather a special case of the theory developed in [ CL10 ] .

Throughout this section let @xmath be any field. By a variety we will
always mean a separated reduced scheme of finite type over @xmath . The
Grothendieck ring of varieties , denoted by @xmath , is the quotient of
the free abelian group generated by isomorphism classes of varieties
modulo the relation

  -- -------- --
     @xmath   
  -- -------- --

for @xmath a variety, @xmath a closed subvariety and @xmath . The
multiplication is given by @xmath , where we write @xmath for the class
of a variety @xmath in @xmath .
The Grothendieck ring with exponentials @xmath is defined similarly.
Instead of varieties we consider pairs @xmath , where @xmath is a
variety and @xmath is a morphism. A morphism of pairs @xmath is a
morphism @xmath such that @xmath . Then @xmath is defined as the free
abelian group generated by isomorphism classes of pairs modulo the
following relations.

1.  For a variety @xmath , a morphism @xmath , a closed subvariety
    @xmath and @xmath the relation

      -- -------- --
         @xmath   
      -- -------- --

2.  For a variety @xmath and @xmath the projection onto @xmath the
    relation

      -- -------- --
         @xmath   
      -- -------- --

The class of @xmath in @xmath will be denoted by @xmath . We define the
product of two generators @xmath and @xmath as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the morphism sending @xmath to @xmath . This gives
@xmath the structure of a commutative ring.

Denote by @xmath the class of @xmath resp. @xmath in @xmath resp. @xmath
. The localizations of @xmath and @xmath with respect to the the
multiplicative subset generated by @xmath and @xmath , where @xmath are
denoted by @xmath and @xmath .

For a variety @xmath there is a straight forward generalization of the
above construction to obtain the relative Grothendieck rings @xmath and
@xmath . For example generators of @xmath are pairs @xmath where @xmath
is a @xmath -variety (i.e. a variety with a morphism @xmath ) and @xmath
a morphism. The class of @xmath in @xmath will be denoted by @xmath or
simply @xmath if the base variety @xmath is clear from the context.

There is a natural map

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

and similarly @xmath , which are both injective ring homomorphisms by [
CLL13 , Lemma 1.1.3] . Hence we do not need to distinguish between
@xmath and @xmath for a @xmath -variety @xmath .

For a morphism of varieties @xmath we have induced maps

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

In general @xmath is a morphism of rings and @xmath a morphism of
additive groups. However it is straightforward to check that for any
@xmath and any @xmath we have

  -- -------- -- -----
     @xmath      (2)
  -- -------- -- -----

where @xmath denotes the class of @xmath and @xmath in @xmath and @xmath
respectively.

Elements of @xmath can be thought of as motivic functions on @xmath .
The evaluation of @xmath at a point @xmath is simply

  -- -------- --
     @xmath   
  -- -------- --

Computations with these motivic functions can sometimes replace finite
field computations. More precisely let @xmath be a finite field and fix
a non-trivial additive character @xmath . Assume that @xmath , @xmath
and @xmath are also defined over @xmath . Then the class of @xmath
corresponds to the function

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

Furthermore for a morphism @xmath the operations @xmath and @xmath
correspond to summation over the fibres of @xmath and composition with
@xmath respectively.

There is a slight technical disadvantage to working over finite fields.
Namely given a fibration @xmath where each fiber is isomorphic to some
fixed variety @xmath , we cannot deduce in general

  -- -------- -- -----
     @xmath      (4)
  -- -------- -- -----

in @xmath or @xmath , whereas a similar relation clearly holds over a
finite field. However ( 4 ) holds if the fibration is Zariski-locally
trivial i.e. @xmath admits an open covering @xmath such that @xmath .
Indeed, in this case we have

  -- -------- --
     @xmath   
  -- -------- --

Next we discuss an analogue of the crucial identity for computing
character sums over finite fields

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is a @xmath vector space and @xmath a linear form.

To establish a similar identity in the motivic setting we let @xmath be
a finite dimensional vector space over @xmath and @xmath a variety. We
replace the linear form above with a family of affine linear forms i.e.
a morphism @xmath , where @xmath is an @xmath -variety. Then we define
@xmath to be the morphism

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Finally, we put @xmath .

###### Lemma 1.2.

With the notation above we have the relation

  -- -------- --
     @xmath   
  -- -------- --

in @xmath . In particular, if @xmath and @xmath , we have @xmath unless
@xmath .

###### Proof.

By using ( 2 ) we may assume @xmath . Now because of [ CLL13 , Lemma
1.1.8] it is enough to check for each point @xmath the identity

  -- -------- --
     @xmath   
  -- -------- --

and this is exactly Lemma @xmath of loc. cit. ∎

Now we are ready to define a naive motivic Fourier transform for
functions on a finite dimensional @xmath -vectorspace @xmath and prove
an inversion formula. All of this is a special case of [ CL10 , Section
7.1] .

###### Definition 1.3.

Let @xmath and @xmath be the obvious projections. The naive Fourier
transformation @xmath is defined as

  -- -------- -------- --
     @xmath   @xmath   
     @xmath            
  -- -------- -------- --

Here @xmath denotes the natural pairing. We will often write @xmath
instead of @xmath when there’s no ambiguity.

Of course the definition is again inspired by the finite field version,
where one defines for any function @xmath the Fourier transform at
@xmath by

  -- -- --
        
  -- -- --

Notice that @xmath is a homomorphism of groups and thus it is worth
spelling out the definition in the case when @xmath is the class of a
generator in @xmath . Letting @xmath be the structure morphism we simply
have

  -- -------- -- -----
     @xmath      (5)
  -- -------- -- -----

Now we are ready to prove an inversion formula for the naive Fourier
transform.

###### Proposition 1.4.

For every @xmath we have the identity

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is multiplication by @xmath .

###### Proof.

Since @xmath is a group homomorphism it is enough to prove the lemma for
@xmath with @xmath . Iterating ( 5 ) we get

  -- -- --
        
  -- -- --

Now we can apply Lemma 1.2 with @xmath to obtain

  -- -------- --
     @xmath   
  -- -------- --

Notice that @xmath is a @xmath -variety via projection onto the second
factor and hence the projection onto the first factor induces a @xmath
-isomorphism @xmath , which gives the desired result. ∎

Finally, we introduce a motivic version of convolution.

###### Definition 1.5.

Let @xmath be the natural morphism sending two varieties over @xmath to
their product, and @xmath the sum operation. The convolution product is
the associative and commutative operation

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

As expected the Fourier transform interchanges product and convolution
product.

###### Proposition 1.6.

For @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

As both @xmath and @xmath are bilinear it is enough to consider
generators @xmath with structure morphisms @xmath respectively. Using (
5 ) we can then directly compute

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

We will use the convolution product to study equations in a product of
varieties i.e. consider @xmath -varieties @xmath say for @xmath . Then
it follows from the definition of @xmath , that for any @xmath the class
of @xmath is given by @xmath . Through Proposition 1.6 we can compute
the latter by understanding the Fourier transforms @xmath separately.

### 1.3 Realization morphisms

As we will see later, the rings @xmath and @xmath and their
localizations @xmath are quite convenient to compute in. However it is a
priori unclear how much geometric information we can extract out of
these computations. Typically this is done via morphisms to other rings,
which are better understood. We will not give all the details of the
constructions we mention here and refer to [ Pop ] and also [ HRV08 ,
Appendix] .

As a first example, when @xmath is a finite field, ( 3 ) defines such a
morphism @xmath . Notice that @xmath and @xmath get mapped to @xmath and
@xmath under @xmath , hence @xmath even lifts to @xmath .

Since our focus is more on the topology of complex varieties, we will be
interested in realization morphism over a fields of characteristic
@xmath . Assuming the transcendence degree of @xmath is at most the one
of @xmath we can embed @xmath into @xmath and consider any variety over
@xmath as a variety over @xmath . This way the @xmath points of any
variety inherit a topology from @xmath and taking the Euler
characteristic of that space gives a ring homomorphism

  -- -------- --
     @xmath   
  -- -------- --

Notice that in this case we do not have an extension to @xmath , as for
example @xmath .

The most interesting realization morphism for us relies on two natural
filtrations, called the weight and the Hodge filtration, on the
compactly supported cohomology @xmath of any complex algebraic variety
@xmath , which were constructed by Deligne [ Del71 , Del74 ] . Taking
the dimensions of the graded pieces we obtain the (compactly supported)
mixed Hodge numbers of @xmath

  -- -------- --
     @xmath   
  -- -------- --

Out of these numbers we form the @xmath -polynomial , a refined Euler
characteristic defined by

  -- -------- -- -----
     @xmath      (6)
  -- -------- -- -----

As it turns out we obtain this way a morphism

  -- -------- -------- -- -----
     @xmath   @xmath      (7)
     @xmath   @xmath      
  -- -------- -------- -- -----

###### Example 1.7.

If @xmath is the affine line, then @xmath and the generator is of type
@xmath , hence @xmath . Since @xmath descends to a morphism on @xmath we
can use the cut and paste relations to compute further

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

From the example we see in particular that @xmath will extend to a
morphism

  -- -------- --
     @xmath   
  -- -------- --

However we do not know how to extend @xmath or @xmath to @xmath , which
is an interesting question in its own right.

We finish with a lemma explaining how to extract some simple topological
information out of the @xmath -polynomial.

###### Lemma 1.8.

[ HLRV13 , Lemma 5.1.2] Let @xmath be smooth and equidimensional of
dimension @xmath . Then @xmath is a polynomial of degree @xmath and the
coefficient of @xmath is the number of connected components of @xmath .

### 1.4 Hyperplane arrangements

A general reference for the theory of hyperplane arrangements is [ Sta04
] and we’ll also use conventions from [ PW07 ] .

Let @xmath be a field. Generally speaking a hyperplane arrangement in a
finite dimensional @xmath -vector space @xmath is a union of finitely
many affine hyperplanes in @xmath . For us it will be important to
consider hyperplanes together with a fixed normal vector, which will
always be integral.

More precisely we fix a basis of @xmath and consider it’s dual @xmath
with the dual basis. If we write @xmath for the dimension of @xmath , we
have a natural morphism @xmath , which is injective if @xmath . Now
consider non-zero vectors @xmath and denote their images in @xmath by
the same letters (if @xmath we’ll always assume that the images of the
@xmath ’s are non-zero). We further fix elements @xmath and denote by
@xmath the hyperplane arrangement in @xmath consisting of the
hyperplanes

  -- -------- --
     @xmath   
  -- -------- --

Most of the time we will just write @xmath for an arrangement and assume
implicitly a choice @xmath .

###### Definition 1.9.

A hyperplane arrangment @xmath is called

-    central , if all hyperplanes are linear subspaces i.e. @xmath for
    all @xmath ,

-    essential , if @xmath ,

-    unimodular , if every collection of @xmath linearly independent
    vectors @xmath spans @xmath over the integers,

The rank of @xmath is defined as @xmath . Most of the time we consider
essential arrangements, in which case @xmath .

For a subset @xmath put @xmath . The subset @xmath is called a flat if
@xmath and @xmath . The set of all flats @xmath is a partially ordered
set with the relation @xmath if @xmath . The unique minimal element in
@xmath is the empty flat @xmath with @xmath and a unique maximal element
exists if and only if @xmath is central, in which case we denote it by
@xmath . The rank @xmath of a flat @xmath is defined as the dimension of
@xmath and the corank as @xmath .

The Möbius function of the poset @xmath

  -- -------- -- -----
     @xmath      (8)
  -- -------- -- -----

is defined inductively by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We also abbreviate @xmath for every @xmath .

We give now a description of @xmath in terms of chains. A chain of flats
in @xmath is a sequence @xmath of flats where all the inclusions are
strict. The integer @xmath is called the length of the chain. For two
flats @xmath write @xmath for the number chains @xmath of length @xmath
with @xmath and @xmath .

###### Lemma 1.10.

For any two flats @xmath in @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We simply define @xmath and show that it satisfies the same recursion as
@xmath . First there’s only one chain of length @xmath from @xmath to
@xmath for any @xmath and hence @xmath . More generally for any @xmath
we have

  -- -------- --
     @xmath   
  -- -------- --

and hence

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

∎

An other important invariant of @xmath is the characteristic polynomial
@xmath given by

  -- -------- -- -----
     @xmath      (9)
  -- -------- -- -----

By definition it is monic of degree @xmath . A priory @xmath depends on
the field @xmath , but it turns out that the dependence is rather mild.
We define the @xmath -variety @xmath .

###### Theorem 1.11.

[ Sta04 , Theorem 5.15] For any ground field @xmath we have in @xmath
the equality

  -- -------- --
     @xmath   
  -- -------- --

In particular, for @xmath a finite field we have

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, away from finitely many positive characteristics @xmath and
@xmath are independent of the field @xmath .

###### Proof.

In [ Sta04 , Theorem 5.15] the finite field case is proven, but the same
proof works also motivically. The last statement is Proposition 5.13 in
loc. cit. ∎

###### Corollary 1.12.

The characteristic polynomial of any central hyperplane arrangement is
divisible by @xmath .

###### Proof.

The complement @xmath of a central arrangement @xmath admits a @xmath
-action by scaling. Hence if @xmath is a finite field, this implies that
@xmath is divisible by @xmath and then statement now follows from
Theorem 1.11 . ∎

Assume now that @xmath is central. For a flat @xmath the localization
@xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

which is an arrangement in @xmath and we have @xmath . The intersection
lattice @xmath can be identified with the sub-lattice of @xmath
consisting of flats contained in @xmath .

Dually, the restriction @xmath is defined as

  -- -------- --
     @xmath   
  -- -------- --

which is an arrangement in the vector space @xmath . If @xmath is
essential we also have @xmath . Similarly @xmath can be identified with
the sub-lattices of @xmath consisting of flats containing @xmath . For
two flats @xmath we write @xmath .

###### Proposition 1.13.

Let @xmath be a central hyperplane arrangement and @xmath two flats in
@xmath . Then we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

The statement depends only on @xmath , hence we may assume, that @xmath
is essential i.e. @xmath . Furthermore by replacing @xmath with @xmath
we can assume @xmath . Then by definition we have @xmath .

For any @xmath we denote by @xmath the flat corresponding to the single
hyperplane @xmath and by @xmath the arrangement we obtain by removing
@xmath from @xmath . Then @xmath satisfies the deletion-restriction
relation

  -- -------- --
     @xmath   
  -- -------- --

This is proven in [ Sta04 , Lemma 2.2] or can also be seen from Theorem
1.11 . The statement now follows by induction on @xmath . If @xmath
there is nothing to prove. For higher rank the deletion-restriction
equation for any @xmath implies

  -- -------- --
     @xmath   
  -- -------- --

as @xmath is again essential. Now if @xmath is not essential we have
@xmath and we are done by the induction hypothesis, as @xmath .
Otherwise we repeat the deletion restriction argument for @xmath until
we reach a non-essential arrangement. ∎

## 2 Motivic Classes of Symplectic Reductions of Vector Spaces

In this chapter we give formulas for the classes of certain hypertoric
and Nakajima quiver varieties in the localized Grothendieck ring @xmath
introduced in 1.2 . These classes are given by a polynomial expression
in @xmath and are the motivic analogue of the point count of these
varieties obtained by Hausel in [ Hau06 , Hau10 ] .

Both hypertoric and Nakajima quiver varieties arise as symplectic
GIT-reduction of an algebraic symplectic vector space and many of the
arguments work in this general setting, which is the content of the
first section. In particular, we prove in Proposition 2.3 a motivic
analogue of [ Hau06 , Proposition 1] , which was the main reason to
introduce the naive Fourier transform in 1.2 . We also explain, how one
can interpret this as an example of ’motivic localization’ in the spirit
of Theorem 1.1 .

In the subsequent Sections 2.2 and 2.3 we start by defining hypertoric
and Nakajima quiver varieties respectively and then compute their
motivic classes explicitly. Having established Proposition 2.3 this
simply amounts to redo carefully Hausel’s finite field computations in
the Grothendieck ring of varieties.

Throughout the whole chapter @xmath will denote an algebraically closed
field of characteristic @xmath

### 2.1 Symplectic reductions of vector spaces

The following constructions are well known and appear for example in [
Pro07 ] . For a detailed account on GIT quotients and the relation with
symplectic reduction we refer to [ MFK94 ] and for our purposes also [
Kin94 ] .

Let @xmath be a reductive algebraic group over @xmath with Lie algebra
@xmath and @xmath a representation, where @xmath is some finite
dimensional @xmath -vector space. We will always assume that @xmath is
injective and hence the action of @xmath on @xmath effective. The
derivative of @xmath is the Lie algebra representation @xmath . The
action of @xmath on @xmath induces a Hamiltonian action on @xmath which
has a moment map @xmath given by

  -- -------- -- ------
     @xmath      (10)
  -- -------- -- ------

for @xmath and @xmath .

Now for any character @xmath and any @xmath we’ll be interested in the
GIT quotient

  -- -------- --
     @xmath   
  -- -------- --

Here the right hand side is defined as

  -- -------- --
     @xmath   
  -- -------- --

with

  -- -------- --
     @xmath   
  -- -------- --

In particular, for @xmath the trivial character @xmath is the affine
variety defined by

  -- -------- --
     @xmath   
  -- -------- --

For general @xmath there is always an affinization map

  -- -------- -- ------
     @xmath      (11)
  -- -------- -- ------

which is proper.

There is a more geometric way to describe @xmath in terms of @xmath
-(semi)stable points. Instead of giving the definition of (semi)stable
points we will directly state ’Mumford’s numerical criterion’
characterizing them. For the purpose of this thesis Proposition 2.1
below may thus be taken as a definition.

A one-parameter subgroup of @xmath is an inclusion @xmath . For any
character @xmath we define the paring @xmath by @xmath .

###### Definition/Proposition 2.1.

[ Kin94 , Proposition 2.5] A point @xmath is called @xmath -semistable
and @xmath -stable respectively if every one-parameter subgroup @xmath
of @xmath , for which @xmath exists, satisfies @xmath and @xmath
respectively.

For any subvariety @xmath we will write @xmath for the open subvariety
of semi-stable points. We also define an equivalence relation on @xmath
by

  -- -------- --
     @xmath   
  -- -------- --

With this notation we can describe (the points of) @xmath as

  -- -------- -- ------
     @xmath      (12)
  -- -------- -- ------

The varieties of interest for us will be of the form @xmath . However
for computing motivic classes the affine varieties @xmath are much more
tractable. The following proposition connects the two under certain
assumptions essentially by an argument of Nakajima [ CBVdB04 , Appendix]
.

###### Proposition 2.2.

Let @xmath be non-zero and @xmath the linear subspace spanned by @xmath
. If @xmath acts freely on @xmath we have in the localized Grothendieck
ring @xmath the equality

  -- -------- -- ------
     @xmath      (13)
  -- -------- -- ------

If furthermore @xmath acts freely on @xmath we have

  -- -------- -- ------
     @xmath      (14)
  -- -------- -- ------

###### Proof.

Since @xmath acts in particular freely on @xmath , we see as in Section
1.1 that @xmath is smooth. Also all @xmath -orbits have the same
dimension and are thus closed. Hence by ( 12 ) @xmath is the quotient
space of a smooth manifold by a free action and is thus smooth itself. A
similar argument also shows that the total space of the family @xmath is
smooth.

Using the bilinearity of @xmath we obtain identifications @xmath and
@xmath , hence in @xmath

  -- -------- --
     @xmath   
  -- -------- --

Now there is a natural contracting @xmath -action on @xmath which
descends to the quotient @xmath and covers the weight @xmath action on
@xmath via @xmath . It follows from considering the affinization map 11
, that every @xmath -orbit under this action has a unique limit point in
@xmath . As we clearly have

  -- -------- --
     @xmath   
  -- -------- --

we deduce from the Bialynicki-Birula Theorem [ BB73 , Theorem 4.1]

  -- -------- --
     @xmath   
  -- -------- --

where we also used [ Sum74 , Corollary 2] to guarantee the existence of
a @xmath -invariant quasi-affine open covering.

By comparing the two expressions for @xmath we obtain ( 13 ) after
inverting @xmath .

Finally, 14 follows simply because the affinization @xmath is an
isomorphism if @xmath acts freely on @xmath . ∎

In our cases of interest we can compute @xmath from the class of the
fiber of the moment map @xmath (see Propositions 2.8 and 2.14 ), so we
finish this section by explaining how to use the naive Fourier transform
1.3 to compute the latter.

We define

  -- -------- --
     @xmath   
  -- -------- --

which is a @xmath -variety via he projection onto the second factor
@xmath . Analogous to [ Hau06 , Proposition 1] we have

###### Proposition 2.3.

Consider @xmath as a @xmath -variety via @xmath . Then we have in @xmath
the equality

  -- -------- -- ------
     @xmath      (15)
  -- -------- -- ------

In particular, for any @xmath the identity

  -- -- -- ------
           (16)
  -- -- -- ------

holds in @xmath .

###### Proof.

By ( 5 ) the naive Fourier transform of @xmath is

  -- -------- --
     @xmath   
  -- -------- --

Now by the definition ( 10 ) of @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

Thus Lemma 1.2 with @xmath and @xmath gives ( 15 ). Next we apply @xmath
again and use the inversion Lemma 1.4 to get

  -- -------- --
     @xmath   
  -- -------- --

Finally, passing to @xmath to invert @xmath and using @xmath gives

  -- -------- --
     @xmath   
  -- -------- --

Then ( 16 ) follows from pulling back both sides along @xmath . ∎

###### Remark 2.4.

We like to think of Proposition 2.3 as an instance of a motivic
localization formula in the spirit of Theorem 1.1 . Namely if a motivic
version of ( 1 ) were to exist, it should ideally express the Fourier
transform @xmath as a sum over the fixed points @xmath . As @xmath acts
linearly on @xmath we further can assume @xmath . Then ( 15 ) indeed
reflects such a localization phenomenon by the fact, that @xmath is an
honest class in @xmath and not @xmath .

### 2.2 Hypertoric varieties

An algebraic construction of hypertoric varieties was first given in [
HS02 , Section 6] , however much of our exposition is taken from [ PW07
] .

Consider an inclusion of tori @xmath which is given in coordinates by an
@xmath -matrix @xmath with integer entries and denote the rows of @xmath
by @xmath . Then the diagonal action of @xmath on @xmath gives rise to
the representation

  -- -------- -------- -- ------
     @xmath   @xmath      
     @xmath   @xmath      (17)
  -- -------- -------- -- ------

where we use the notation @xmath for any @xmath and @xmath . The
derivative @xmath is for any @xmath given by

  -- -------- -- ------
     @xmath      (18)
  -- -------- -- ------

From this we can now construct a variety as in 2.1 . More precisely
@xmath will act on @xmath in a Hamiltonian way with moment map @xmath
given by the explicit formula

  -- -------- -- ------
     @xmath      (19)
  -- -------- -- ------

where @xmath and @xmath via the natural pairing. For a character @xmath
we define the hypertoric variety @xmath by

  -- -------- --
     @xmath   
  -- -------- --

There is a natural central arrangement @xmath given by the normal
vectors @xmath , whose combinatorics are closely related to the geometry
of @xmath .

###### Proposition 2.5.

[ HS02 , Proposition 6.2] For a suitable character @xmath the hypertoric
variety @xmath is smooth if and only if @xmath is unimodular. In this
case @xmath acts freely on @xmath .

###### Proof.

For the only if part we refer to [ HS02 , Proposition 6.2] . As in the
proof of Proposition 2.2 , the if part follows from the second
statement, which we prove now.

To define @xmath consider the set @xmath that is the set of the maximal
flats in @xmath . For every @xmath the intersection of all its
hyperplanes @xmath is a line in @xmath which is spanned by a (up to a
sign) unique primitive @xmath . By changing the sign of @xmath if
necessary we can then choose @xmath such that @xmath for all @xmath .

Let now @xmath . For every @xmath the vector @xmath defines a
one-parameter subgroup of @xmath by @xmath . By Proposition 2.1 we
therefore see, that @xmath doesn’t exist in @xmath for all @xmath .
Writing out the definitions we have

  -- -------- --
     @xmath   
  -- -------- --

From this we deduce that for every @xmath there must be an @xmath such
that, depending on the sign of @xmath , either @xmath or @xmath . In
particular, we can construct from this inductively a set @xmath such
that @xmath are linearly independent, hence a @xmath -basis of @xmath as
@xmath is unimodular, and for every @xmath we have either @xmath or
@xmath .

Now let @xmath be in the stabilizer of @xmath i.e. @xmath . Then we see,
that whenever @xmath or @xmath we must have @xmath . Hence in particular
@xmath for all @xmath . Since @xmath form a @xmath -basis of @xmath we
deduce that @xmath which proves that the stabilizer of @xmath is
trivial. ∎

###### Example 2.6.

Consider the diagonal embedding @xmath . Then @xmath is the @xmath
-matrix @xmath and the moment map is @xmath . Then @xmath will be smooth
for any non-trivial character @xmath . If we take for example @xmath we
get

  -- -------- --
     @xmath   
  -- -------- --

Thus the projection onto the @xmath -coordinate gives a rank @xmath
vector bundle @xmath and one can check that in fact @xmath .

#### 2.2.1 Motivic classes of smooth hypertoric varieties

Throughout this section we assume that @xmath is unimodular and @xmath
is chosen as in Proposition 2.5 , so that @xmath is smooth. Under these
assumptions we prove the following theorem.

###### Theorem 2.7.

The motivic class of a smooth hypertoric variety @xmath in @xmath is
given by the formula

  -- -------- -- ------
     @xmath      (20)
  -- -------- -- ------

where @xmath denotes the Möbius function of the central arrangement
@xmath .

Notice that, the geometry of @xmath will in general depend on the choice
of @xmath [ HS02 , Section 9] , however by Theorem 2.7 not its motivic
class. This can already be seen from the following proposition.

###### Proposition 2.8.

Assume that @xmath does not vanish on @xmath for any @xmath . Then we
have in @xmath

  -- -------- -- ------
     @xmath      (21)
  -- -------- -- ------

###### Proof.

First we claim that @xmath acts freely on @xmath . Indeed, let @xmath be
fixed by some @xmath and put @xmath . From the moment map equation ( 19
)

  -- -------- --
     @xmath   
  -- -------- --

together with the choice of @xmath we deduce that @xmath , and by
unimodularity @xmath contains a @xmath -basis of @xmath . But now @xmath
implies @xmath for all @xmath , which finally implies @xmath i.e @xmath
acts freely on @xmath . Combining this with Propositions 2.2 and 2.5 we
obtain

  -- -------- --
     @xmath   
  -- -------- --

Now as in [ Rei03 , Lemma 6.5] one can show that @xmath acts
scheme-theoretically freely on @xmath , which implies by [ MFK94 ,
Proposition 0.9, Amplification 1.3] , that @xmath is a @xmath -principal
bundle. As every @xmath -principal bundle is Zariski-locally trivial [
Ser58 , Section 4.4] the proposition follows from ( 4 ). ∎

We are thus left with computing @xmath which by ( 16 ) reduces to
understanding @xmath , where @xmath denotes the projection. This is done
by a familiar cut and paste argument. First we have a stratification

  -- -------- -- ------
     @xmath      (22)
  -- -------- -- ------

By ( 18 ) we see that @xmath is a vector bundle of rank @xmath and hence
we have

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the paring with @xmath . Theorem 2.7 now follows
from the following

###### Lemma 2.9.

The class @xmath lies in @xmath and equals @xmath .

###### Proof.

We can check this directly using the recursive definition of @xmath ( 8
). For @xmath we clearly have

  -- -------- --
     @xmath   
  -- -------- --

and for any @xmath

  -- -------- --
     @xmath   
  -- -------- --

by Lemma 1.2 , since by assumption @xmath does not vanish on @xmath . ∎

###### Example 2.10.

We continue Example 2.6 . The corresponding arrangement @xmath is given
by @xmath times the origin, in particular @xmath . Formula ( 20 ) then
reads

  -- -------- --
     @xmath   
  -- -------- --

which of course agrees with the class of @xmath .

###### Remark 2.11.

The proof of Theorem 2.7 relies crucially on Proposition 2.3 , which in
turn can be interpreted as a motivic instance of the Duistermaat-Heckman
Theorem 1.1 , see Remark 2.4 . We will briefly explain here, how the
varieties @xmath themselves give rise to such localization phenomena,
but with more than one fixed point.

First we describe a second arrangement @xmath , which is commonly
associated with @xmath . Writing @xmath and identifying @xmath with
@xmath we obtain a linear map @xmath , where @xmath is a @xmath -matrix
with integer coefficients. We write @xmath for the columns of @xmath and
@xmath for any lift of @xmath . Then @xmath is the arrangement
consisting of the @xmath affine hyperplanes

  -- -------- -- ------
     @xmath      (23)
  -- -------- -- ------

The hypertoric variety @xmath admits a residual torus action of @xmath ,
which is again Hamiltonian. The moment map is given explicitly by (see [
PW07 ] )

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

As opposed to the @xmath -action on @xmath , the @xmath -action on
@xmath will in general have non-trivial isolated fix points. For a
generic point @xmath we thus would expect by our localization philosophy
in @xmath a formula of the form

  -- -------- --
     @xmath   
  -- -------- --

for some @xmath .

This is indeed the case, as we can combine a inclusion-exclusion
argument similar to Lemma 2.9 with the following two facts:

-   The moment map @xmath induces a bijection between @xmath -fixed
    points on @xmath and maximal flats (i.e points) in @xmath .

-   For any flat @xmath and @xmath defined as in ( 22 ) we have

      -- -------- --
         @xmath   
      -- -------- --

Here (i) can can be found in [ BD00 , Corollary 3.5] and (ii) follows
from covering @xmath with affine hypertoric varieties as in [ AP16 ,
Proposition 4.6] .

### 2.3 Nakajima quiver varieties

We start by recalling the definition of Nakajima quiver varieties.
Almost everything can be found in more detail in [ Hau10 ] or in the
original sources [ Nak94 ] [ Nak98 ] .
Let @xmath be a quiver with @xmath the set of vertices and @xmath the
set of arrows. We denote by @xmath and @xmath the source and target
vertex of an arrow @xmath . For each @xmath we fix finite dimensional
@xmath -vector spaces @xmath and write @xmath for their dimension
vectors.

From this data we construct the vector space

  -- -------- --
     @xmath   
  -- -------- --

the algebraic group

  -- -------- --
     @xmath   
  -- -------- --

and its Lie algebra

  -- -------- --
     @xmath   
  -- -------- --

We have a natural representation

  -- -------- --
     @xmath   
  -- -------- --

and its derivative

  -- -------- --
     @xmath   
  -- -------- --

For @xmath and @xmath they are given by the formulas

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

We are again in the situation of section 2.1 i.e. @xmath acts on the
vector space @xmath in a Hamiltonian way with moment map

  -- -------- --
     @xmath   
  -- -------- --

given by ( 10 ).

Following [ Nak98 ] we fix once and for all @xmath to be the character
of @xmath given by @xmath . For @xmath the Nakajima quiver variety
@xmath is then defined as

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 2.12.

For @xmath the action of @xmath will not be faithful, in which case one
should choose a different character (see [ Nak98 , Remark 3.13] ), but
we do not study this case here.

###### Example 2.13.

[ Nak99 , Proposition 2.8] Consider the Jordan quiver @xmath consisting
of a single vertex and a single loop on that vertex with the dimension
vectors given by positive integers @xmath and @xmath . In this case we
can identify @xmath with the set of elements @xmath satisfying

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the commutator and @xmath the transpose of @xmath .

Now @xmath -stability will imply @xmath and that

  -- -------- --
     @xmath   
  -- -------- --

defines an ideal in @xmath of length @xmath . This identifies @xmath
with @xmath , the Hilbert scheme of @xmath points on @xmath .

The motivic class of @xmath can again be determined through Proposition
2.2 . Take @xmath to be the linear functional defined by @xmath for
@xmath .

###### Proposition 2.14.

The equality

  -- -------- --
     @xmath   
  -- -------- --

holds in @xmath .

###### Proof.

First by [ Nak98 , Lemma 3.10] @xmath acts freely on @xmath and also on
@xmath by [ Hau10 , Corollary 5] . Hence by Proposition 2.2 we get

  -- -------- --
     @xmath   
  -- -------- --

Now again as in Proposition 2.8 , the quotient @xmath is a @xmath
-principal bundle, hence Zariski-locally trivial [ Ser58 , Lemma 5 and
6] , this implies the proposition by formula ( 4 ). ∎

#### 2.3.1 Motivic classes of Nakajima quiver varieties

In this section we deduce a formula for the motivic class of @xmath in
terms of the combinatorial data of the quiver @xmath . It will be
convenient to consider the generating series

  -- -- -- ------
           (24)
  -- -- -- ------

where we define

  -- -------- --
     @xmath   
  -- -------- --

Combining Propositions 2.14 and 2.3 we have

  -- -------- -- ------
     @xmath      (25)
  -- -------- -- ------

with the notations

  -- -- --
        
  -- -- --

and @xmath the natural projection.

Next we use some basic linear algebra to split up the above generating
series into a regular and a nilpotent part. Given a finite dimensional
vector space @xmath of dimension @xmath and an endomorphism @xmath of
@xmath , we can write @xmath , where @xmath and @xmath . With respect to
this decomposition we have @xmath with @xmath nilpotent and @xmath
regular.
Now let @xmath with @xmath (i.e the inequality holds for every entry).
We define the three varieties

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### Lemma 2.15.

For every @xmath we have the following relation in @xmath

  -- -- -- ------
           (26)
  -- -- -- ------

###### Proof.

Fix for all @xmath a decomposition @xmath with @xmath . This induces
inclusions

  -- -- --
        
  -- -- --

We will prove that the morphism

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

is a Zariski-locally trivial @xmath -fibration. Since for every @xmath
we have

  -- -- --
        
  -- -- --

this will imply the lemma using ( 4 ).
First notice that @xmath is well defined because

  -- -------- --
     @xmath   
  -- -------- --

The @xmath -action on the domain of @xmath is given as follows. For
@xmath and @xmath we set

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is understood via the inclusion @xmath . One checks
directly that @xmath is invariant under this action and hence each fiber
of @xmath carries a free @xmath -action.

On the other hand, assume @xmath . This implies

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath is nilpotent and @xmath regular for @xmath , the
decomposition @xmath is preserved by @xmath i.e. @xmath , which shows
that each fiber of @xmath is isomorphic to @xmath .

Finally, to trivialize @xmath locally we notice, that there is an open
covering @xmath and algebraic morphisms @xmath such that for @xmath and
@xmath the columns of the matrix @xmath form a basis of @xmath and
@xmath . ∎

Now we use the stratification @xmath together with Lemma 2.15 to get

  -- -------- -------- -- ------
     @xmath   @xmath      
                          
              @xmath      
              @xmath      (27)
  -- -------- -------- -- ------

where we used the notations

  -- -------- --
     @xmath   
  -- -------- --

and

  -- -------- --
     @xmath   
  -- -------- --

Notice that equation ( 25 ) also makes sense for @xmath , in which case
[ Hau10 , Lemma 3] implies @xmath . Therefore

  -- -------- -- ------
     @xmath      (28)
  -- -------- -- ------

which leaves us with computing @xmath .

We denote by @xmath the set of all partitions @xmath , where @xmath .
The size of @xmath is @xmath and @xmath denotes the set of partitions of
size @xmath . For @xmath we write @xmath for the nilpotent conjugacy
class, whose Jordan normal form is given by @xmath . For @xmath with
@xmath we set

  -- -------- --
     @xmath   
  -- -------- --

which gives the stratification

  -- -------- -- ------
     @xmath      (29)
  -- -------- -- ------

To compute @xmath we look at the projection

  -- -------- -- ------
     @xmath      (30)
  -- -------- -- ------

The fiber of @xmath over @xmath is simply @xmath . Because of @xmath the
dimensions of those kernels are constant and hence @xmath is a vector
bundle of rank, say, @xmath .

###### Lemma 2.16.

Denote by @xmath the centralizer of (some element in) @xmath . We have
the following relation in @xmath .

  -- -------- -- ------
     @xmath      (31)
  -- -------- -- ------

###### Proof.

The formula ( 33 ) below shows in particular that @xmath is invertible
in @xmath . Since the projection ( 30 ) is a vector bundle, we are left
with proving @xmath . Since @xmath is isomorphic to @xmath , see for
example [ Bor12 , Chapter 3.9.1] , it is enough to prove that the @xmath
-principal bundle @xmath is Zariski locally trivial by ( 4 ). In fact,
this is true for every @xmath -principal bundle, which follows from
combining Propositions 3.13 and 3.16 of [ Mer13 ] . ∎

To compute @xmath and @xmath , denote by @xmath the multiplicity of
@xmath in a partition @xmath . Then given any two partitions @xmath we
define their inner product to be

  -- -------- --
     @xmath   
  -- -------- --

Lemma 3.3 in [ Hua00 ] implies now

  -- -- -- ------
           (32)
  -- -- -- ------

where @xmath denotes the partition @xmath .

For @xmath we can use the formula (1.6) from [ Mac98 , Chapter 2.1] .
There the formula is worked out over a finite field but Lemma 1.7 of
loc. cit. holds over any field. In our notation this gives (see [ Hua00
, Chapter 3] for details)

  -- -------- -- ------
     @xmath      (33)
  -- -------- -- ------

Finally, combining ( 28 ), ( 29 ), ( 31 ), ( 32 ) and ( 33 ) we obtain

###### Theorem 2.17.

For a fixed non-zero dimension vector @xmath the motivic classes of the
Nakajima quiver varieties @xmath in @xmath are given by the generating
function

  -- -- -- ------
           (34)
  -- -- -- ------

###### Example 2.18.

Consider again the Jordan quiver as in 2.13 , where we saw @xmath . Then
formula ( 34 ) gives a generating series for the classes @xmath :

  -- -- --
        
  -- -- --

On the other hand there is a well known formula for @xmath due to
Göttsche [ G0̈1 ] , which gives

  -- -------- --
     @xmath   
  -- -------- --

Thus we see that ( 34 ) gives already in this case a quite non-trivial
combinatorial statement. Similar identities appear for example in [
Hua00 ] .

## 3 Open de Rham spaces

In this chapter we study meromorphic connections on the trivial rank
@xmath bundle on @xmath . By fixing some local data @xmath at the poles
of the connection one obtains a finite dimensional moduli space @xmath ,
called the open de Rham space . Originally they were introduced by
Boalch [ Boa01 ] to study isomonodromic deformations, however for us
they arise in a slightly different context.

Our starting point is the conjecture of Hausel, Mereb and Wong [ HMW16 ]
on the mixed Hodge polynomial of wild character varieties @xmath . These
character varieties are the target space for the wild Riemann-Hilbert
correspondence, which associates to a meromorphic connection its Stokes
data [ Boa11 ] . Even though this correspondence is not algebraic, the
purity conjecture [ HRV08 ] predicts, that @xmath equals the pure part
of @xmath .

In our forthcoming paper [ HWW ] we find numerical evidence for both
conjectures by computing the @xmath -polynomial of @xmath and proving an
agreement with the conjectural pure part of the mixed Hodge polynomial
of the corresponding @xmath . In this thesis we only explain how to
compute @xmath , or more precisely @xmath , as this fits into the same
motivic Fourier transform setting we already used in Chapter 2 .

In the first two sections we introduce the relevant notation and prove
some computational lemmas on coadjoint orbits. It might therefore be
more interesting to first read Section 3.3 , where we define @xmath and
give a description in terms of coadjoint orbits following . More
precisely a pole of order @xmath can be modeled locally by a coadjoint
orbit @xmath , and @xmath is obtained by a symplectic fusion of the
individual poles, see Proposition 3.6 .

Using the motivic convolution construction 1.5 , the computation of
@xmath reduces to understand the Fourier transform of the composition

  -- -------- --
     @xmath   
  -- -------- --

This key computation is carried out in Section 3.4 under the assumption
@xmath , which will ensure that the ’motivic function’ @xmath is
supported on semi-simple conjugacy classes, which fails for @xmath .
Eventually we would like to explain this phenomenon in a similar way as
in Remarks 2.4 , 2.11 i.e. as an instance of a general motivic
localization formula, but we are not able to do so at the moment.

In Section 3.5 we put everything together and give in Theorem 3.9 an
explicit formula for @xmath as a polynomial in @xmath , assuming that
the order of each pole is @xmath . In the last section we combine our
results with the work of [ HLRV11 ] on order one poles and sketch how to
extend our computations, at least over finite fields, to give a formula
for @xmath under the milder assumption, that at least one pole has to be
of order @xmath .

### 3.1 Jets and duals

Let @xmath be an integer. We abbreviate @xmath and @xmath . Furthermore
@xmath will denote the standard maximal torus consisting of diagonal
matrices, @xmath its Lie algebra and @xmath the subset of elements with
distinct eigenvalues. We also have the jet versions

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

and similarly we define @xmath and @xmath .

Finally, we have the unipotent subgroup @xmath and its Lie algebra
@xmath defined by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Note that we have @xmath , where @xmath acts on @xmath by conjugation,
and thus a decomposition @xmath .

It will be convenient to identify the dual @xmath with

  -- -------- --
     @xmath   
  -- -------- --

via the trace residue pairing i.e. for @xmath and @xmath we set

  -- -------- -- ------
     @xmath      (35)
  -- -------- -- ------

Under this identification @xmath corresponds to @xmath and @xmath to
those elements in @xmath having zero residue term. We write

  -- -------- -- ------
     @xmath      (36)
  -- -------- -- ------

for the natural projections. The adjoint and coadjoint actions of @xmath
on @xmath and @xmath will both be denoted by and are defined by the same
formula @xmath . Notice that with this convention we have @xmath .

### 3.2 Coadjoint orbit computations

We write @xmath for matrices with zeros on the diagonal and for @xmath
we write @xmath for the commutator.

###### Lemma 3.1.

1.   For @xmath and @xmath we have @xmath .

2.   Let @xmath with @xmath and @xmath such that @xmath . Then @xmath
    and @xmath .

3.   Let @xmath and @xmath such that @xmath . Then @xmath .

###### Proof.

The first statement is clear. For part 2 write @xmath . Then by
rewriting we obtain

  -- -------- -- ------
     @xmath      (37)
  -- -------- -- ------

The @xmath term of ( 37 ) reads @xmath , hence @xmath . We now proceed
by induction, assuming @xmath and @xmath for some @xmath . The @xmath
terms of ( 37 ) equal

  -- -------- --
     @xmath   
  -- -------- --

By the induction hypothesis this simplifies to @xmath . Now by the first
part @xmath and hence @xmath . But then @xmath and @xmath commute, which
implies @xmath since @xmath .

For part 3 write @xmath and consider @xmath term by term. An argument
analogous to the one for part 2 gives the desired statement. ∎

Next we study regular semisimple @xmath -coadjoint orbits i.e. let
@xmath with @xmath and write @xmath for the coadjoint orbit through
@xmath .

###### Lemma 3.2.

There is an isomorphism

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where we put @xmath . Here the action of @xmath on @xmath is given by
@xmath . In particular, @xmath is a Zariski locally trivial @xmath
-principal bundle.

###### Proof.

It follows from Lemma 3.1 . 2 that @xmath , hence we have an isomorphism
@xmath which sends @xmath to @xmath . Since @xmath and @xmath we can
further write

  -- -------- --
     @xmath   
  -- -------- --

Finally, given @xmath a direct computation shows that there are unique
@xmath and @xmath such that @xmath . This gives @xmath . It is then
straightforward to check that the @xmath -action on @xmath is as
indicated, and the final statement follows since @xmath is a Zariski
locally trivial @xmath -principal bundle. ∎

### 3.3 Meromorphic connections

In this section we introduce irregular connections on @xmath following [
Boa01 , Section 2] . Fix an effective @xmath -divisor @xmath , where
@xmath are points in @xmath and @xmath . Write @xmath for the canonical
divisor on @xmath . A meromorphic connection with poles along @xmath on
a rank @xmath vector bundle @xmath is a @xmath -linear morphism

  -- -------- --
     @xmath   
  -- -------- --

satisfying the Leibniz rule @xmath , where @xmath is a local holomorphic
function and @xmath a local section of @xmath .

If @xmath is a local coordinate around @xmath we can write, after fixing
a trivialization of @xmath , @xmath , where @xmath is a meromorphic
matrix of @xmath -forms. More precisely we can write

  -- -------- --
     @xmath   
  -- -------- --

with @xmath . The non-holomorphic part @xmath is called the principal
part of @xmath at @xmath . Then @xmath is called regular if for every
@xmath the leading coefficient @xmath is diagonalisable with distinct
eigenvalues, if @xmath , or with distinct eigenvalues modulo @xmath , if
@xmath .

###### Remark 3.3.

1.  If @xmath is the transition function for an other trivialization of
    @xmath on a neighborhood @xmath of @xmath , then the transformation
    @xmath of @xmath is given by (see for example [ Wel07 , Lemma
    III.1.6] )

      -- -------- --
         @xmath   
      -- -------- --

    hence being regular is independent of the choice of trivialization.

2.  In [ Boa01 , Definition 2.2] the term ’generic’ is used instead of
    ’regular’, however ’generic’ will have a different meaning for us,
    see Definition 3.5 .

In order to obtain finite dimensional moduli spaces we need to fix a
formal type of order @xmath at each pole @xmath , that is a matrix of
meromorphic one forms

  -- -------- -- ------
     @xmath      (38)
  -- -------- -- ------

where @xmath and @xmath for @xmath . One can think of @xmath as a
meromorphic connection on the trivial rank @xmath bundle over the formal
disc @xmath around @xmath .

A meromorphic connection @xmath with poles along @xmath has formal type
@xmath at @xmath if there exists a local trivialization of @xmath around
@xmath and a formal bundle automorphism @xmath such that we have @xmath
and @xmath is a diagonal matrix of holomorphic @xmath -forms.

From now on the choice of an effective divisor @xmath and formal types
@xmath for @xmath will be abbreviated by @xmath and the degree of @xmath
by @xmath .

###### Definition 3.4.

The open de Rham space @xmath is the set of isomorphism classes of
meromorphic connections @xmath on @xmath , where @xmath is a trivial
bundle of rank @xmath and @xmath has poles along @xmath with prescribed
formal types @xmath at @xmath .

Notice that @xmath should correspond inside the whole de Rham space (no
assumption on the vector bundle) to the locus, where the underlying
bundle is semi-stable, as on @xmath a semi-stable bundle of degree
@xmath is trivial. Hence the name open de Rham space.

We will see in Proposition 3.6 below, that @xmath admits the structure
of an algebraic variety. In order for this variety to be smooth we need
to impose a genericity condition on @xmath , more precisely on the
residue terms @xmath of the @xmath , which will naturally reappear
during the computations later, see Lemma 3.12 . We will thus be very
explicit about it. Define for @xmath the matrix @xmath by

  -- -------- -- ------
     @xmath      (39)
  -- -------- -- ------

###### Definition 3.5.

We call @xmath generic if @xmath and for every integer @xmath and
subsets @xmath of size @xmath we have

  -- -------- -- ------
     @xmath      (40)
  -- -------- -- ------

In other words there are no invariant subspaces @xmath of the same
dimension such that @xmath , if @xmath is generic. It is clear that we
can always find such a generic @xmath and we will see by direct
computations, that the invariants we compute do not depend on the choice
of @xmath .

We now give an explicit description of @xmath in terms of @xmath
-coadjoint orbits. First notice that a formal type @xmath as in ( 38 )
naturally defines an element in @xmath by taking the principal part and
forgetting @xmath . We denote the @xmath coadjoint orbit through @xmath
by @xmath . The action of @xmath on @xmath is Hamiltonian with respect
to the standard symplectic structure on @xmath and the inclusion @xmath
is a moment map. In particular, a moment map for the induced action of
@xmath is given by @xmath , see ( 36 ). Consequently, for formal types
@xmath the action of @xmath on @xmath by simultaneous conjugation admits
a moment map

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

###### Proposition 3.6.

1.   For any choice of @xmath there is a bijection

      -- -------- --
         @xmath   
      -- -------- --

2.   If @xmath is generic, we can identify @xmath with the points of the
    smooth affine GIT quotient @xmath . If non-empty, @xmath is
    equidimensional of dimension @xmath .

###### Proof.

The first part is contained in [ Boa01 , Proposition 2.1] , but we will
reprove the statement for the convenience of the reader. Fix a
coordinate @xmath on @xmath and assume that none of the @xmath ’s are at
infinity. Given an element @xmath we can write @xmath (after fixing a
trivialization of @xmath ) with

  -- -------- --
     @xmath   
  -- -------- --

where all @xmath . Thus by looking at the principal parts of @xmath and
forgetting @xmath we obtain for each @xmath an element @xmath . By our
assumptions @xmath is regular at each @xmath and hence has formal type
@xmath if and only if @xmath , see for example [ BJL79 , Proposition 1]
. Furthermore the condition @xmath is equivalent to @xmath not having a
pole at infinity. Finally, an isomorphism of trivial bundles over @xmath
is given by an element in @xmath , which corresponds to simultaneous
conjugation on @xmath .

Assume now @xmath is generic. We show first, that @xmath acts freely on
@xmath . Let @xmath and @xmath such that @xmath for @xmath . We show
now, that @xmath is scalar, by looking at some non-zero eigenspace
@xmath of @xmath . Then clearly @xmath will preserve @xmath for all
@xmath and by the moment map condition we deduce @xmath . The point is
now, that for each @xmath there is a subspace @xmath of the same
dimension as @xmath such that

  -- -------- -- ------
     @xmath      (41)
  -- -------- -- ------

By the genericity of @xmath , 3.5 this implies then @xmath and hence
@xmath is scalar.

To prove ( 41 ) we fix an @xmath and write @xmath for some @xmath . By
conjugating @xmath and @xmath with the constant term @xmath of @xmath we
can assume without loss of generality @xmath i.e. @xmath . Then @xmath
and thus @xmath . Next consider @xmath , which satisfies @xmath . By
Lemma 3.1 . 2 we have @xmath and then by 3.1 . 3 @xmath . This implies
that @xmath preserves @xmath for every @xmath and hence we have @xmath .
This proves ( 41 ) and hence @xmath acts freely on @xmath .

In particular, all the @xmath -orbits in @xmath are closed and hence
set-theoretic quotient agrees with the points of the GIT quotient @xmath
[ Dol03 , Theorem 6.1] . Furthermore as in Section 1.1 , freeness of the
@xmath action implies that @xmath is a regular value of @xmath , which
in turn implies smoothness of @xmath and hence of @xmath . By looking at
tangent spaces we see that the dimension of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

∎

### 3.4 Fourier transform of a pole

In this section we compute the Fourier transform @xmath of a coadjoint
orbit @xmath of a formal type @xmath , where we use the language of
Section 1.2 . Assuming @xmath we can give an explicit formula for @xmath
, but before we need to introduce some more notation.

As in Section 2.3.1 we denote by @xmath the set of partitions of @xmath
. A semi-simple element @xmath has type @xmath if @xmath has @xmath
different eigenvalues @xmath and the multiplicity of @xmath is @xmath
for @xmath . We write @xmath and @xmath . Finally, we put @xmath .

###### Theorem 3.7.

For any partition @xmath we have in @xmath the formula

  -- -------- -- ------
     @xmath      (42)
  -- -------- -- ------

where @xmath and @xmath . Furthermore the pullback of @xmath to the
complement @xmath equals @xmath .

###### Proof.

By the formula ( 5 ) we have

  -- -- --
        
  -- -- --

where for the second equality sign we used the definition of @xmath ( 35
).

By Lemma 3.2 we can rewrite this in @xmath as

  -- -------- --
     @xmath   
  -- -------- --

Now notice that for all @xmath we have

  -- -- --
        
  -- -- --

Thus we finally obtain

  -- -------- -- ------
     @xmath      (43)
  -- -------- -- ------

We will simplify this by applying Lemma 1.2 . First write @xmath and
@xmath for the subspaces of strictly lower and upper triangular matrices
in @xmath respectively, such that @xmath . Next consider the
decomposition @xmath with

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

It follows from Lemma 3.8 below that there are functions

  -- -------- --
     @xmath   
  -- -------- --

such that @xmath for all @xmath and @xmath . More explicitly @xmath and
@xmath are given by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Applying now Lemma 1.2 to this decomposition, formula ( 43 ) becomes

  -- -------- --
     @xmath   
  -- -------- --

Again by Lemma 3.8 we have

  -- -------- --
     @xmath   
  -- -------- --

The condition @xmath already implies, that @xmath is supported on @xmath
. Notice further that for @xmath as @xmath , we have

  -- -------- --
     @xmath   
  -- -------- --

in particular @xmath is independent of @xmath . Furthermore for any
@xmath the pullback @xmath is a vector bundle of rank @xmath and thus

  -- -------- --
     @xmath   
  -- -------- --

Together with @xmath the theorem follows. ∎

We are left with proving Lemma 3.8 , for which we need the following
explicit formula for the inverse of an element @xmath . If we write
@xmath , then @xmath is given for any @xmath by

  -- -------- -- ------
     @xmath      (44)
  -- -------- -- ------

Notice that for @xmath , @xmath can appear at most once in each summand
on the right hand side of ( 44 ). This is the crucial observation in the
proof of Lemma 3.8 .

###### Lemma 3.8.

For @xmath the function

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

is affine linear in @xmath . It is independent of those variables if and
only if @xmath and @xmath commute with @xmath .

In this case, if @xmath is odd and we decompose @xmath , where @xmath
and @xmath are strictly lower and upper triangular respectively, then
@xmath is affine linear in @xmath and independent in of @xmath if and
only if @xmath commutes with @xmath .

###### Proof.

It follows directly from ( 44 ), that @xmath depends linearly on @xmath
for @xmath .

For @xmath , using the notation ( 44 ) we have

  -- -------- -- ------
     @xmath      (45)
  -- -------- -- ------

where we use the convention @xmath . We start by looking at the
dependence of @xmath when varying @xmath . The terms in ( 45 )
containing @xmath are given by

  -- -------- --
     @xmath   
  -- -------- --

As @xmath , the commutator @xmath can take any value @xmath , thus
@xmath is independent of @xmath if and only if @xmath .

Assume from now on @xmath . We show now inductively that @xmath is
independent of @xmath if and only if @xmath all commute with @xmath .

To do so, fix @xmath and assume that @xmath commute with @xmath .
Consider the element

  -- -------- --
     @xmath   
  -- -------- --

The point is now, that the @xmath -parts of the explicit formulas for
@xmath and @xmath are very similar. Indeed, from ( 45 ) we see, that all
the terms containing @xmath in @xmath are contained in

  -- -------- -- ------
     @xmath      (46)
  -- -------- -- ------

To write a formula for @xmath we write @xmath . Then we can use a
similar expression as ( 45 ) to conclude that all the terms containing
@xmath in @xmath are contained in

  -- -------- -- ------
     @xmath      (47)
  -- -------- -- ------

Next we want to study the dependence of the difference ( 46 ) - ( 47 )
on @xmath . Notice first, that since @xmath for @xmath also @xmath for
@xmath and furthermore @xmath . From ( 44 ) we also see @xmath for all
@xmath . Finally, we remark that @xmath is independent of @xmath for
@xmath and the terms containing @xmath in @xmath are given by @xmath .
Combining all this we see that the terms containing @xmath in ( 46 ) - (
47 ) are just

  -- -------- --
     @xmath   
  -- -------- --

Since @xmath , the commutator @xmath can take any value in @xmath as we
vary @xmath . Hence in order for @xmath to be constant, we need @xmath .
Since @xmath this is only possible if @xmath , which finishes the
induction step.

Finally, we consider the special case @xmath , when @xmath is odd. Then
by the same argument as before we obtain, that all the terms in @xmath
which depend on @xmath are @xmath . Now using the decomposition @xmath
we have

  -- -------- --
     @xmath   
  -- -------- --

Since the orthogonal complement of strictly upper triangular matrices
are the upper triangular matrices we see that @xmath is independent of
@xmath if and only if @xmath . ∎

### 3.5 Motivic classes of open de Rham spaces

Let @xmath be an effective divisor on @xmath and @xmath formal types
such that @xmath is generic. We compute now @xmath , under the
assumption that all poles are at least of order two, i.e. @xmath for
@xmath . For a partition @xmath we define the numbers @xmath , @xmath
and @xmath the multiplicity of @xmath in @xmath . Furthermore we put

  -- -------- --
     @xmath   
  -- -------- --

###### Theorem 3.9.

The motivic class of @xmath in @xmath for a generic @xmath , where all
poles are of order at least @xmath , is given by

  -- -------- -------- -- ------
     @xmath   @xmath      (48)
     @xmath   @xmath      
  -- -------- -------- -- ------

We start by simplifying @xmath in the following standard way.

###### Lemma 3.10.

In @xmath we have

  -- -------- -- ------
     @xmath      (49)
  -- -------- -- ------

###### Proof.

Similar to Lemma 3.2 we consider the @xmath -principal bundle @xmath .
Notice that @xmath is @xmath -equivariant with respect the free @xmath
-action on @xmath given by left-multiplication. By restriction we obtain
a @xmath -equivariant @xmath -principal bundle @xmath . Taking the
(affine GIT-)quotient by @xmath , we obtain a @xmath -principal bundle
@xmath . Also @xmath is a @xmath -principal bundle, as it is the
restriction of @xmath . As the groups @xmath and @xmath are special [
Ser58 , Section 4.3] , all the principal bundles here are Zariski
locally trivial and we get

  -- -------- --
     @xmath   
  -- -------- --

∎

By ( 49 ) it is enough to determine @xmath , where we consider @xmath as
a morphism. Using motivic convolution and in particular Proposition 1.6
we have an equality of motivic Fourier transforms

  -- -------- -- ------
     @xmath      (50)
  -- -------- -- ------

Notice that the last product is relative to @xmath , hence we have by
Theorem 3.7 for every @xmath

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

with the notations @xmath , @xmath for the @xmath -fold product @xmath
and @xmath for the function taking @xmath to @xmath . By Fourier
inversion 1.4 we thus get

  -- -------- -------- -- ------
     @xmath   @xmath      
              @xmath      (51)
  -- -------- -------- -- ------

This leaves us with understanding @xmath as an element of @xmath .

We start by taking a closer look at @xmath . If we put @xmath we have an
isomorphism

  -- -------- -------- -- ------
     @xmath   @xmath      (52)
     @xmath   @xmath      
  -- -------- -------- -- ------

Next we need to fix some notation to describe @xmath combinatorially. To
parametrize the eigenvalues of elements in @xmath define for any @xmath
the open subvariety @xmath as the complement of @xmath .

Furthermore we need some discrete data. A set partition of @xmath is a
partition @xmath of @xmath i.e @xmath for @xmath and @xmath . For @xmath
we write @xmath for the set of set partitions @xmath of @xmath such that
@xmath . We stress that the @xmath ’s are not ordered and hence @xmath ,
where @xmath denotes the multiplicity of @xmath in @xmath .

With this notations we get a parametrization

  -- -------- -------- -- ------
     @xmath   @xmath      (53)
     @xmath   @xmath      
  -- -------- -------- -- ------

where for any subset @xmath @xmath is defined as in ( 39 ) and we
require @xmath . Notice that @xmath is not uniquely defined this way as
we might switch @xmath and @xmath in a given @xmath , if @xmath . As
this doesn’t matter for us, we will just fix a @xmath once and for all.

For any @xmath we also define @xmath as the image of the restriction
@xmath .

###### Lemma 3.11.

The following relation holds in @xmath

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Combining ( 52 ) and ( 53 ) we have @xmath . One can then check that
@xmath has @xmath connected components, each of which is isomorphic to
@xmath . Applying this reasoning @xmath times and keeping track of the
isomorphisms gives the desired equality. ∎

###### Proof of Theorem 3.9.

Combining ( 49 ), ( 51 ) and Lemma 3.11 we are left with computing the
character sum @xmath for a fixed @xmath -tuple @xmath of set partitions
of @xmath . For @xmath we can write

  -- -------- --
     @xmath   
  -- -------- --

Now for a fixed @xmath we have by definition @xmath . Thus by our
genericity assumption ( 40 ) the numbers @xmath satisfy the assumptions
of Lemma 3.12 below, and we deduce

  -- -------- -- ------
     @xmath      (54)
  -- -------- -- ------

which proves Theorem 3.9 .∎

###### Lemma 3.12.

Let @xmath be complex numbers such that @xmath and for @xmath be a
proper subset @xmath . Then for the function @xmath , @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We use induction on @xmath . For @xmath we have @xmath and @xmath ,
hence the statement is clear. For the induction step consider @xmath as
a subvariety of @xmath . As @xmath we have @xmath , hence

  -- -- --
        
  -- -- --

Now notice that the complement @xmath has @xmath connected components,
each of which is isomorphic @xmath , which implies the formula. ∎

### 3.6 Remarks on finite fields and purity

The description of @xmath in Proposition 3.6 allows us to consider open
de Rham spaces over any field, in particular over a finite field @xmath
. By taking a spreading out of @xmath over some finitely generated
@xmath -algebra we see that if the characteristic of @xmath is large
enough, Theorem 3.9 also hold when we replace every motivic class with
the number of rational points over @xmath [ HRV08 , Appendix] .

We can even say more. Namely the proof of Theorem 3.7 implies that the
Fourier transform of the count function @xmath , @xmath associated to
the coadjoint orbit @xmath is supported on semi-simple elements in
@xmath , whose eigenvalues are in the field @xmath . Given such an
@xmath of type @xmath , the @xmath -version of formula ( 42 ) reads

  -- -- -- ------
           (55)
  -- -- -- ------

where @xmath denotes the orbit of @xmath under the adjoint action and
@xmath and @xmath are defined as in Section 1.2 .

Now even though our argument in Section 3.4 does not work for @xmath ,
formula ( 55 ) continues to hold for @xmath semi-simple with eigenvalues
in @xmath . Indeed in this case @xmath is the characteristic function of
the coadjoint orbit @xmath and the formula (2.5.5) in [ HLRV11 ] for its
Fourier transform agrees with ( 55 ), when we put @xmath .

Hence for a generic @xmath with at least one pole of order @xmath , we
can compute @xmath as in Section 3.5 , since we have to evaluate the
product in ( 50 ) only on semi-simple elements whose eigenvalues are in
@xmath (if all poles are of order @xmath , one also has to consider non
semi-simple elements).

###### Corollary 3.13.

For a generic @xmath with at least one pole of order @xmath , the number
of @xmath -rational points of @xmath is given by formula ( 48 ) when we
replace @xmath by @xmath .

In particular, in this case @xmath is non-empty and connected.

###### Proof.

The explanation why ( 48 ) continues to hold is given in the previous
paragraph. By Katz’s theorem [ HRV08 , Theorem 6.1.2] (or in the motivic
case by applying ( 7 )) we see that the same formula ( 48 ) also gives
the @xmath -polynomial @xmath , when @xmath is replaced everywhere with
@xmath . By a direct inspection we then see that @xmath is a monic
polynomial of degree @xmath , which implies that @xmath is non-empty and
by Lemma 1.8 also connected. ∎

It is somewhat unfortunate that we have to use finite fields to be able
to include order @xmath poles in our computations. We plan to come back
to this problem in the future and hopefully prove formula ( 55 ) in the
motivic setting also for @xmath .

We finish by looking at some special cases of ( 48 ). For @xmath the
formula reads

  -- -------- --
     @xmath   
  -- -------- --

For small values of @xmath @xmath is then given by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath            
  -- -------- -------- --

It turns out that in all examples we can compute, the coefficients of
@xmath as a polynomial in @xmath will always be positive, in particular
the coefficients of @xmath seem to be positive. By ( 6 ) a sufficient
condition for this is that the compactly supported cohomology of @xmath
is pure i.e. @xmath unless @xmath . If all poles in @xmath are of order
1 this is proven in [ HLRV11 , Theorem 2.2.6] using the description of
@xmath as a quiver variety. In [ HWW ] we obtain a quiver like
description of @xmath for poles of any order, giving more evidence and a
possible strategy for the following natural conjecture.

###### Conjecture 3.14.

For any generic @xmath the (compactly supported) mixed Hodge structure
of @xmath is pure.

## 4 Push-forward Measures of Moment Maps over Local Fields

In this final Chapter we consider the same situation as in Section 2.1 ,
but with base field a local field @xmath and instead of the motivic
measure we consider the natural Haar measure @xmath on @xmath . These
two measures are not unrelated. Namely @xmath will induce a canonical
measure @xmath on any variety @xmath which is smooth over the ring of
integers @xmath . By a theorem of Weil [ Wei12 ] the volume of @xmath is
up to a factor equal to @xmath , where @xmath is the residue field of
@xmath , which is always assumed to be finite. As counting over finite
fields is essentially a realization of the motivic measure, we see that
@xmath is in some sense a refinement of the motivic measure.

As a natural question we will thus study the analogue of Proposition 2.3
, i.e. the push forward of the Haar measure along the moment map

  -- -------- -- ------
     @xmath      (56)
  -- -------- -- ------

By Weil’s theorem we do not expect to see anything new at the @xmath
-smooth fibers of @xmath , which is why we focus our attention to @xmath
. More precisely we are interested in the ’relative volume’ @xmath of
@xmath i.e. the value of the density @xmath at @xmath and the geometric
information it contains. We are not able to give a precise answer to
this question here, but we hope that the computations and conjectures we
present will be a starting point for interesting future research
directions.

We now explain the structure of this chapter in more detail. The first
section contains the necessary background on local fields, we introduce
in particular the Fourier transform operator and the corresponding
inversion formula.

In the second section we define the local Igusa zeta function @xmath of
a polynomial map @xmath between affine spaces, our main example being
@xmath a moment map as in ( 56 ). Not only is @xmath a strictly finer
invariant than @xmath , but while @xmath can be infinite, @xmath is
always a rational function in @xmath and if @xmath is finite we can
recover it as a residue of @xmath at a simple pole. Another reason to
consider @xmath is the functional equation it satisfies, which will
explain certain symmetries of @xmath .

In Section 4.3 we use our localization philosophy, or more precisely a
@xmath -adic analogue of Proposition 2.3 , to give a formula for
computing @xmath . In general it seems quite hard to evaluate this
formula, but if we restrict ourselves to the moment maps that appear in
the construction of hypertoric varieties ( 19 ) we can be very explicit.
In this case we can express @xmath in terms of the combinatorics of the
associated hyperplane arrangement @xmath , which is the content of
Section 4.4 .

A direct consequence of this explicit formula is that the (real parts of
the) poles of @xmath are contained in a finite set of negative integers
@xmath . In Section 4.5 we give a criterion, for when an integer in
@xmath is an actual pole of @xmath and deduce that the two largest and
the smallest number in @xmath will always be poles of @xmath . The
interest in the poles of @xmath , or more generally @xmath , comes from
Igusa’s long standing monodromy conjecture [ Igu88 ] . One version of
the conjecture states that the poles of @xmath should agree with the
roots of the so-called Bernstein-Sato polynomial @xmath of @xmath . The
conjecture has been checked in many cases when @xmath is a single
polynomial, but in general only a few examples are known [ HMY07 ] . It
would thus be interesting to see, if one can use analogous localization
ideas to compute the roots of @xmath , which is a question we will try
to answer in the future.

In the last two sections we come back to the relative volume @xmath . In
4.6 we use the description of @xmath as a residue of @xmath to prove
that the ’numerator’ @xmath of @xmath is palindromic as a polynomial in
@xmath . Based on numerical evidence we furthermore conjecture that
@xmath has positive coefficients.

Finally, in Section 4.7 we consider hyperplane arrangements which come
from a quiver @xmath . Here our motivation comes from a result of
Crawley-Boevey and Van den Bergh [ CBVdB04 ] , which says that the
number of indecomposable representations of @xmath over @xmath for an
indivisible dimension vector is up to a factor equal to the number of
stable points on @xmath . In our case, we consider idecomposable @xmath
-dimensional representations of @xmath over the finite quotient rings
@xmath , where @xmath denotes the maximal ideal. Using a formula of
Mellit [ Mel16 ] we show that the asymptotic number of such
representations as @xmath is given by a rational function @xmath . We
finish by giving some numerical evidence for the conjecture that the
numerator @xmath of @xmath equals @xmath .

### 4.1 Local fields and some harmonic analysis

In this section we recall some basic facts about local fields.
Everything we say here can be found in various places, for example [
Ser13 , Tai75 ] .

By a local field @xmath we will always mean a locally compact,
non-discrete, totally disconnected field, where locally compact means
that both abelian groups @xmath and @xmath are locally compact. With
this definition there are two kinds of local fields:

1.  @xmath @xmath is a finite extension of a @xmath -adic field @xmath
    for some prime number @xmath .

2.  @xmath @xmath is the field of rational functions over a finite field
    @xmath i.e. @xmath .

We fix now a local field @xmath once and for all. Write @xmath for the
valuation and @xmath for the norm. The latter is multiplicative and
satisfies the non-archimedean triangle inequality

  -- -------- -- ------
     @xmath      (57)
  -- -------- -- ------

Moreover, we have an equality in ( 57 ) whenever @xmath .

Hence the unit ball @xmath is a sub-ring of @xmath called the ring of
integers . It is a regular local ring of dimension @xmath with maximal
ideal @xmath . In particular, @xmath is principal and we fix for
convenience a generator @xmath i.e. @xmath . The quotient @xmath is
called the residue field and is isomorphic to a finite field @xmath .
The characteristic of @xmath is called the residue characteristic of
@xmath . More generally we have for any @xmath a finite ring @xmath .

The units @xmath of @xmath are the complement of @xmath i.e @xmath .
Then every @xmath can be written uniquely as @xmath for some @xmath and
@xmath . As @xmath we see that the image of the norm map @xmath is
@xmath .

We will need three more pieces of data naturally associated with @xmath
. The first is a natural section of the projection @xmath called the
Teichmüller lift @xmath , which is characterized by @xmath and @xmath
being multiplicative. Every @xmath then has a unique presentation as
convergent power series

  -- -------- --
     @xmath   
  -- -------- --

Hence we can speak of the coefficient of @xmath at @xmath as an element
in @xmath . In particular, we have decompositions

  -- -------- -- ------
     @xmath      (58)
  -- -------- -- ------

Next, since @xmath is locally compact, we can consider the Haar measure
@xmath on @xmath and more generally @xmath on @xmath for any @xmath ,
normalized by @xmath . For any measurable subset @xmath and @xmath we
have

  -- -------- -- ------
     @xmath      (59)
  -- -------- -- ------

All integrals we consider will be with respect to this Haar measure, and
we will in general only indicate the variable, over which we integrate.
The following lemma is an easy consequence of ( 59 ) and we will use it
many times without explicitly mentioning.

###### Lemma 4.1.

For any @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Both equations follow from ( 59 ), for the second one we also use @xmath
. ∎

Finally, we fix a non-trivial additive character @xmath normalized by
the condition @xmath . As in the finite field case, the integrals we
compute will not depend on the actual choice of @xmath .

We finish this section by introducing the Fourier transform on @xmath .
Write @xmath for the @xmath -vector space of locally constant, complex
valued functions with compact support on @xmath . The Fourier transform
@xmath of a function @xmath is a function on @xmath defined by

  -- -------- --
     @xmath   
  -- -------- --

where @xmath denotes the standard inner product.

###### Lemma 4.2.

[ Igu00 , Lemma 8.1.3] The Fourier transform defines a linear
isomorphism @xmath and satisfies

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and @xmath .

For any subset @xmath we write @xmath for the characteristic function of
@xmath . In practice all the Fourier transforms we need can be computed
from the following lemma using the linearity of @xmath .

###### Lemma 4.3.

For every @xmath and @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Since @xmath is a character we can write

  -- -------- --
     @xmath   
  -- -------- --

If for some @xmath we have @xmath with @xmath , then @xmath will descend
to a non-trivial character on the finite abelian group @xmath and hence
@xmath . This implies the lemma. ∎

### 4.2 Local Igusa zeta funcions

In this section we fix a polynomial map @xmath given by @xmath . As
mentioned already, we are interested in the push-forward measure @xmath
and how it compares to @xmath . As it turns out this is described by
some interesting arithmetics of @xmath . For @xmath denote by @xmath the
number of solutions to @xmath modulo @xmath i.e.

  -- -------- --
     @xmath   
  -- -------- --

Looking at the projection @xmath for every @xmath , we see

  -- -------- -- ------
     @xmath      (60)
  -- -------- -- ------

In particular, the ”quotient” @xmath at the origin is given by

  -- -------- --
     @xmath   
  -- -------- --

We think of @xmath as the relative volume of @xmath , which is in
general a singular variety. If @xmath is smooth then it follows from a
theorem of Weil [ Wei12 , Theorem 2.2.5] , that @xmath . In the singular
case @xmath seems to have some interesting properties, as we try to
illustrate with the following example.

###### Example 4.4.

Take @xmath to be given for all @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Then it is not hard to see, that we have

  -- -------- -- ------
     @xmath      (61)
  -- -------- -- ------

A direct computation then shows

  -- -------- -- ------
     @xmath      (62)
  -- -------- -- ------

As it turns out the formula for @xmath will not be particularly nice,
however the limit @xmath seems to be much better behaved. First the
@xmath term in ( 61 ) goes to zero and we get

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

where @xmath denotes the @xmath -th Eulerian polynomial [ Pet15 ] .
These polynomials appear in many places, notably as the Poincaré
polynomials of toric varieties associated with the permutahedra. In
particular, they are palindromic and have positive coefficients. The
first few are given by

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

From the definition of @xmath it is not at all clear, that @xmath and
indeed in general it will not be. In fact this already fails in the
following simple example.

###### Example 4.5.

Consider the multiplication map @xmath given by @xmath . From ( 62 ) we
see that the number @xmath of solution to @xmath in @xmath is given by
@xmath and hence

  -- -------- --
     @xmath   
  -- -------- --

A both interesting and convenient way to deal with this problems is to
introduce an extra complex variable. The resulting object is called the
local Igusa zeta function associated with @xmath and is defined as

  -- -------- --
     @xmath   
  -- -------- --

where @xmath and @xmath with real part greater than @xmath . Because of
the non-Archimedian norm @xmath depends only on the ideal @xmath hence
one can think of @xmath as being associated to the variety @xmath .

The relation with the push-forward measure comes from the almost
tautological formula [ Bog07 , Section 3.6]

  -- -------- -- ------
     @xmath      (63)
  -- -------- -- ------

Maybe not so surprisingly @xmath is also closely related to the @xmath
’s. Namely we define the Poincaré series of @xmath by

  -- -------- --
     @xmath   
  -- -------- --

Then using again ( 60 ) we see

  -- -------- -------- -- ------
     @xmath   @xmath      
              @xmath      
              @xmath      (64)
              @xmath      (65)
  -- -------- -------- -- ------

The real advantage in introducing @xmath comes from its definition as an
integral, which makes it possible to use analytic and geometric methods
to study it. We quickly explain some basic structure results on @xmath ,
assuming for the rest of this section that @xmath .

The key Idea of Igusa [ Igu74 ] was to use an embedded resolution of
@xmath to prove the following theorem, originally in the case @xmath
(for the multivariate case see [ Loe89 ] ).

###### Theorem 4.6.

The Igusa zeta function @xmath is a rational function in @xmath . The
real parts of its poles in @xmath , as a function of @xmath , are
negative rational numbers.

The numerical data of a resolution of @xmath will give a set of possible
poles for @xmath which is in general larger that the actual set of
poles. The description of the actual poles is an intriguing open problem
and the content of various monodromy conjectures (see [ Den90 ] for a
survey). This is the reason we will spend some time on the description
of the poles of @xmath in the cases we can compute, see Section 4.5 .

The same numerical data also describe the asymptotic behavior of @xmath
as @xmath [ VZG08 ] . For us however the following much simpler
criterion will do.

###### Lemma 4.7.

Assume that the largest poles of @xmath is at @xmath . Then @xmath is
finite if and only if @xmath is a simple pole, in which case we have

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

Consider the generating series

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

If @xmath is a simple pole, then it follows from our assumptions and (
65 ), that @xmath converges for @xmath . We can then compute the value
at @xmath as follows:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

If @xmath is a higher order pole, a similar argument shows that @xmath
diverges. ∎

###### Example 4.8.

Continuing Example 4.5 we can use the formula @xmath to compute @xmath
via ( 64 ):

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

In particular, @xmath has a poles of order @xmath at @xmath which by
Lemma 4.7 explains the divergence of @xmath .

Finally, we discuss an analogue of the functional equation satisfied by
the Weil zeta function. For this consider a homogeneous polynomial
@xmath . We denote for every @xmath by @xmath the unique unramified
extension of @xmath of degree @xmath and by @xmath the Igusa zeta
function of @xmath computed over @xmath . We call @xmath universal over
@xmath if there exists @xmath such that for every @xmath we have @xmath
. Under these assumptions the following is a simplified version of a
theorem of Denef and Meuser.

###### Theorem 4.9.

[ DM91 ] For almost all residue characteristics, if @xmath is universal
over @xmath it satisfies the functional equation

  -- -------- --
     @xmath   
  -- -------- --

###### Remark 4.10.

The proof uses an embedded resolution of the projective hypersurface
@xmath and the functional equation of the Weil zeta function of the
exceptional divisors, which are now projective as well. The same
argument should hence also prove a version of Theorem 4.9 when @xmath is
a collection of homogeneous polynomials of the same degree.

### 4.3 Push forward measures of moment maps

In this section we derive an analogue of Proposition 2.3 over local
fields in the following general set up. Let @xmath be an @xmath -linear
map, where @xmath denotes the @xmath -module of @xmath -matrices with
entries in @xmath . Define a ’moment map’ @xmath by the equation

  -- -------- --
     @xmath   
  -- -------- --

for all @xmath and @xmath . Notice that the standard paring @xmath
induces an isomorphism @xmath and hence @xmath is uniquely defined this
way.

Finally, we define a function @xmath by

  -- -- -- ------
           (66)
  -- -- -- ------

for @xmath . Here we also use the notation @xmath for the characteristic
function of @xmath .

###### Proposition 4.11.

The Fourier transform of the push-forward measure @xmath is given by
@xmath . More precisely we have for every compact measurable @xmath

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By definition of the push-forward measure we can write

  -- -- -- ------
           (67)
  -- -- -- ------

For fixed @xmath we have by the Fourier inversion Lemma 4.2

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

By integrating along @xmath we thus have by lemma 4.3

  -- -------- -------- --
     @xmath            
              @xmath   
  -- -------- -------- --

Plugging this into ( 67 ) we obtain the proposition:

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

∎

###### Remark 4.12.

Ideally we would like to phrase Proposition 4.11 differently by writing

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Then we could say, that the density of @xmath with respect to @xmath is
given by the Fourier transform of @xmath , which would be the exact
analogue of Proposition 2.3 . However @xmath will in general not be
integrable (Example 4.5 gives such a case), and hence we cannot
interchange the integration over @xmath and @xmath in general.

###### Example 4.13.

An interesting special case of Proposition 4.11 comes from taking @xmath
where @xmath . Then by definition of the push-forward measure and
similar as in ( 60 ) we have (the @xmath will always denote the
reduction to the residue field @xmath ).

  -- -------- --
     @xmath   
  -- -------- --

On the other hand we have essentially by Lemma 4.3

  -- -------- --
     @xmath   
  -- -------- --

and thus Proposition 4.11 reads

  -- -------- --
     @xmath   
  -- -------- --

Notice now, that the integrand is invariant on cosets of @xmath and by (
60 ) we have the formula @xmath . Hence we recover [ Hau06 , Proposition
1] :

  -- -------- --
     @xmath   
  -- -------- --

As we already mentioned in ( 63 ), the Igusa zeta function @xmath is
closely related to the push-forward measure @xmath and hence Proposition
4.11 implies the following general formula.

###### Corollary 4.14.

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

By the tautological equation ( 63 ) we have

  -- -------- --
     @xmath   
  -- -------- --

With Proposition 4.11 and Lemma 4.3 this becomes

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
  -- -------- -------- --

Now the domain of each integral in each summand contains @xmath . Using
@xmath we can evaluate the integrals over @xmath first and get

  -- -------- --
     @xmath   
  -- -------- --

and then

  -- -- --
        
  -- -- --

Finally, we can reorder the domains of integration according to the norm
of @xmath and obtain

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

∎

###### Example 4.15.

Consider the case @xmath and @xmath given by @xmath . Then the moment
map @xmath is given by @xmath for all @xmath and @xmath is now
straightforward to compute:

First we have for any @xmath and @xmath the equivalence @xmath and hence
@xmath . Then

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Plugging this into Corollary 4.14 we obtain the formula

  -- -------- --
     @xmath   
  -- -------- --

This example appears already in [ Igu00 ] and was part of the initial
motivation for looking at zeta functions of moment maps.

### 4.4 Hypertoric zeta functions

In this section we determine the Igusa zeta function for the moment maps
that appear in the construction of hypertoric varieties 2.2 . Let @xmath
be a central hyperplane arrangement of rank @xmath , where the
hyperplanes @xmath are given by normal vectors @xmath . From now on we
will work under the following assumption:

###### Assumption 4.16.

If @xmath denotes matrix whose rows are the @xmath , we will always
assume that the residue characteristic of @xmath is larger than any of
the minors of @xmath .

As a first consequence of this assumption we notice that the
intersection lattice @xmath does not depend on whether we consider
@xmath over @xmath or over @xmath .

Associated to @xmath we have a moment map @xmath defined by ( 19 ) i.e.

  -- -------- --
     @xmath   
  -- -------- --

The Igusa zeta function associated with @xmath is then defined as

  -- -------- --
     @xmath   
  -- -------- --

This is really an invariant of @xmath and does not depend on the choice
of normal vectors as long as 4.16 is satisfied. Also the assumption that
@xmath is essential is not necessary here, as @xmath depends only on the
span of the @xmath .

In this case @xmath defined in ( 66 ) takes a rather simple form. Namely
using ( 18 ) we have for @xmath

  -- -------- --
     @xmath   
  -- -------- --

The determination of @xmath thus reduces by Corollary 4.14 to computing

  -- -------- -- ------
     @xmath      (68)
  -- -------- -- ------

The point is now, that the integrand of @xmath clearly takes only
countably many different values and we can partition @xmath accordingly.
Let @xmath and define

  -- -------- -- ------
     @xmath      (69)
  -- -------- -- ------

With this we can write @xmath . Now in general for a matrix @xmath ,
which has full rank when reduced over @xmath , we always have

  -- -------- -- ------
     @xmath      (70)
  -- -------- -- ------

by the non-archimedean triangle inequality ( 57 ). In particular, when
we apply this to the matrix @xmath from 4.16 we get

  -- -------- -- ------
     @xmath      (71)
  -- -------- -- ------

Then ( 68 ) becomes

  -- -------- -- ------
     @xmath      (72)
  -- -------- -- ------

where we use the notation @xmath . We will determine @xmath using a
recursion for which it will be more convenient to consider

  -- -------- --
     @xmath   
  -- -------- --

Now in general there are linear relations between the @xmath and hence
@xmath will be empty for many choices of @xmath . Again because of ( 57
) we need for example

  -- -------- --
     @xmath   
  -- -------- --

to be a flat in @xmath for @xmath to be non-empty. Assuming @xmath we
put @xmath and @xmath .

###### Lemma 4.17.

The volume of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where we set @xmath if @xmath or @xmath .

###### Proof.

As we already remarked in ( 71 ) we have @xmath for every @xmath , hence
in particular @xmath . Furthermore for @xmath and @xmath we have by
definition @xmath . In other words, if we write

  -- -------- --
     @xmath   
  -- -------- --

then every non-empty fiber of @xmath is a translation of @xmath and thus

  -- -- -- ------
           (73)
  -- -- -- ------

where we abbreviate @xmath . Now assume first @xmath i.e. @xmath . Then
the image of @xmath under the projection

  -- -------- --
     @xmath   
  -- -------- --

are exactly the points which do not lie in any hyperplane of @xmath .
Thus by Theorem 1.11 we obtain @xmath and @xmath .

Next assume @xmath but @xmath . Then every @xmath satisfies

  -- -------- -- ------
     @xmath      (74)
  -- -------- -- ------

Furthermore by 4.16 we can write the set of all @xmath satisfying ( 74 )
as @xmath in a suitable basis. Now the same argument as for @xmath shows

  -- -- --
        
  -- -- --

The general case works the same way by considering the image of @xmath
under the projection @xmath .

∎

###### Proposition 4.18.

@xmath satisfies the recursion

  -- -------- --
     @xmath   
  -- -------- --

where we put @xmath and @xmath .

###### Proof.

Using Lemma 4.17 this is now a straightforward computation. Fix a flat
@xmath with @xmath and set @xmath . Then we have

  -- -------- -------- --
     @xmath            
              @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

where we used in the last line our convention @xmath for @xmath . Now
the proposition follows by summing over all flats @xmath . ∎

Of course a recursion for @xmath implies one for @xmath , which turns
out to be a bit cumbersome however. Instead we give an explicit formula
by iterating the recursion from Proposition 4.18 . Recall that for any
flat @xmath we can identify @xmath with the sublattice of @xmath
consisting of flats contained in @xmath .

###### Theorem 4.19.

The Igusa zeta function of an essential hyperplane arrangement @xmath of
rank @xmath is given by

  -- -------- -- ------
     @xmath      (75)
  -- -------- -- ------

where the sum is over all proper chains of flats in @xmath of length
@xmath .

###### Example 4.20.

When @xmath is the central arrangement in @xmath consisting of @xmath
times the origin i.e. @xmath we recover Example 4.15 . In this case
@xmath , and the sum in ( 75 ) has only one term corresponding to the
chain @xmath .

From this example we also see that @xmath is really an invariant of
@xmath and not just of @xmath .

###### Example 4.21.

Next we consider the arrangement in @xmath defined by the three normal
vectors @xmath . The moment map is then given by

  -- -------- --
     @xmath   
  -- -------- --

We have @xmath , and hence there are @xmath chains of length @xmath and
@xmath of length @xmath . The contribution of each of them to the sum in
( 75 ) is given by

  -- -------- -------- --
     @xmath   @xmath   
     @xmath   @xmath   
     @xmath   @xmath   
  -- -------- -------- --

Putting this together we get

  -- -------- --
     @xmath   
  -- -------- --

We give a final example to illustrate that in particular the numerators
of @xmath get complicated very quickly and do not seem to have any
interesting structure apart from the symmetry predicted by Theorem 4.9 .

###### Example 4.22.

Consider the arrangement in @xmath given by the six normal vectors

  -- -------- --
     @xmath   
  -- -------- --

With the help of Sage we find that the denominator of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

The numerator is the following:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

### 4.5 Poles

Formula ( 75 ) shows that @xmath is a rational function in @xmath . We
start by studying the poles of @xmath (as a function in @xmath ), more
precisely the real parts of those poles.

Then if follows from our formula that the poles of @xmath are amongst
the negative integers @xmath , as opposed to just negative rational
numbers as in Theorem 4.6 .

Of course for a given @xmath the different summands in ( 75 ) with a
@xmath -term might cancel. We explain now a criterion which will show in
many cases, that there is no such cancellation. Consider the subset

  -- -------- --
     @xmath   
  -- -------- --

with the induced ordering i.e. @xmath iff @xmath . The following
observation gives some control over @xmath .

###### Lemma 4.23.

1.   For any two flats @xmath in @xmath we have @xmath with equality if
    and only if @xmath are linearly independent in @xmath .

    In particular, if @xmath , any @xmath with @xmath is in @xmath

2.   There are unique flats @xmath such that every @xmath contains
    exactly one of the @xmath ’s

###### Proof.

For @xmath we can write

  -- -------- --
     @xmath   
  -- -------- --

Now the normal vectors defining @xmath are exactly the images of @xmath
in @xmath and @xmath follows.

Statement @xmath follows from the observation that given @xmath such
that @xmath for @xmath , we have @xmath . Indeed, first we can reduce
this to the case where @xmath by restricting to @xmath . Then using (i)
we can write @xmath , where @xmath are linearly independent in @xmath .
As @xmath we conclude that @xmath and hence @xmath are linearly
independent in @xmath and @xmath , which finishes the proof. ∎

Next we write @xmath for the length of a maximal chain in @xmath . Each
maximal chain is of the form @xmath for some @xmath , where @xmath is as
in Lemma 4.23 . For a fixed @xmath we write @xmath for the different
@xmath ’s that appear in a maximal chain with smallest flat @xmath .
Notice that again by Lemma 4.23 @xmath are @xmath linearly independent
vectors, hence any maximal chain from @xmath to @xmath is constructed by
adding the @xmath ’s one by one. In particular, there are @xmath
different maximal chains from @xmath to @xmath .

###### Proposition 4.24.

A negative integer @xmath is a pole of @xmath of order @xmath if @xmath
.

###### Proof.

We see directly from ( 75 ), that the order of the pole @xmath is less
than or equal to @xmath as @xmath can appear at most @xmath times in one
summand. For @xmath to be exactly of order @xmath is equivalent to

  -- -------- --
     @xmath   
  -- -------- --

We now study the contribution of a single summand corresponding to the
chain @xmath (notation as in ( 75 )). Clearly @xmath has to contain a
maximal chain from @xmath in order to have a non-zero contribution to
@xmath , so we assume this from now on. Then we can look at the
contribution of @xmath to the limit @xmath , where we include the factor
@xmath to cancel the factor in front of the sum in ( 75 ) . The
polynomial @xmath is of degree @xmath , which can be seen directly from
the definition ( 9 ). Furthermore if @xmath the summand will contain a
factor @xmath , which will tend to zero as @xmath . Combining these two
facts and the description of maximal chains in @xmath above leads to

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

Here we also used Lemma 1.10 for the last equality. By our assumption we
then have @xmath , and hence also @xmath . ∎

###### Remark 4.25.

The proof of Proposition 4.24 considers a limit for @xmath and it is
natural to look also at a similar limit when @xmath . It turns out
however, that this will produce exactly the same criterion.

In the next theorem we summarize all the information we have about the
poles of @xmath .

###### Theorem 4.26.

Let @xmath be a central arrangement of rank @xmath consisting of @xmath
hyperplanes and @xmath one of the three numbers @xmath . Then @xmath is
a pole of @xmath of order @xmath .

###### Proof.

Assume first @xmath . In this case we can directly look at

  -- -------- --
     @xmath   
  -- -------- --

where we consider the limit from above i.e. @xmath . As the
characteristic polynomial of any hyperplane arrangement is monic we see
that every summand in ( 75 ) tends either to @xmath or @xmath
individually (assuming @xmath is large enough), hence @xmath is a pole
of order @xmath .

For @xmath we use the criterion from Proposition 4.24 . Together with
Proposition 1.13 the statement will then follow from the fact that all
@xmath in @xmath have the same rank.

For @xmath we can see this since @xmath consists exactly of those flats
@xmath for which @xmath are linearly independent. Hence the rank of each
@xmath is simply @xmath .

For @xmath we first notice that there is a unique minimal flat @xmath .
Indeed, @xmath is defined by the property @xmath for all @xmath . We can
then see that @xmath and since there cannot be any flat between @xmath
and any @xmath we have @xmath . ∎

### 4.6 The residue at the largest pole

By Theorem 4.26 we know that @xmath has its largest pole at @xmath .
Furthermore we know that @xmath is a simple pole if and only if @xmath .
In this case @xmath is called coloop-free (see for example [ PW07 ,
Remark 2.3] ) meaning there is no @xmath such that @xmath .

Recall that under these assumptions the residue @xmath has an
interesting interpretation. Namely if @xmath denotes the moment map
associated with @xmath and @xmath the limit

  -- -------- --
     @xmath   
  -- -------- --

then Lemma 4.7 implies @xmath . Combining this with Theorem 4.19 gives

###### Corollary 4.27.

@xmath is finite if and only if @xmath is essential and coloop-free. In
this case we have

  -- -------- -- ------
     @xmath      (76)
  -- -------- -- ------

where the sum is over all proper chains of flats in @xmath of length
@xmath .

The formula shows in particular that @xmath is a rational function in
@xmath for @xmath large enough, see 4.16 . It is not hard to see that
@xmath has degree @xmath , where the degree of a rational function is
defined as the degree of the numerator minus the degree of the
denominator. Indeed the contribution of @xmath in ( 76 ) equals @xmath
and all other summands have negative degree since @xmath for any flat
@xmath , as @xmath is coloop-free.

###### Example 4.28.

As in Example 4.20 we start with the arrangement consisting of @xmath
-times the origin in @xmath . Then ( 76 ) has two terms, one for @xmath
and one for @xmath and we get

  -- -------- --
     @xmath   
  -- -------- --

###### Example 4.29.

The case of @xmath hyperplanes in @xmath in general position appeared
already in Example 4.4 and for @xmath in 4.21 . It is also interesting
to consider these arrangements with some hyperplanes doubled e.g. take
@xmath as in 4.21 and add the normal vector @xmath . In this case we
obtain

  -- -------- --
     @xmath   
  -- -------- --

###### Example 4.30.

Finally, we consider again Example 4.22 , in which case @xmath looks
considerably nicer than @xmath :

  -- -------- --
     @xmath   
  -- -------- --

These examples suggest that the ”numerator” of @xmath satisfies some
remarkable properties. In order to make this more precise define the
numerator @xmath by multiplying @xmath with what we expect to be its
denominator i.e.

  -- -------- --
     @xmath   
  -- -------- --

Notice that @xmath is indeed a polynomial since the characteristic
polynomial of any central arrangement is divisible by @xmath , see
Corollary 1.12 .

One thing we would expect from the examples, is that the numerator
@xmath is palindromic, which is indeed the case. This is a consequence
of the functional equation for the Igusa zeta function of a homogeneous
polynomial 4.9 . Since @xmath is in general not given by a single
polynomial, we also rely on Remark 4.10 .

###### Proposition 4.31.

@xmath is a polynomial of degree @xmath which is palindromic i.e.

  -- -------- --
     @xmath   
  -- -------- --

###### Proof.

We saw already, that @xmath has degree @xmath , hence the formula for
@xmath follows directly from the definition of @xmath . From the
equation

  -- -------- --
     @xmath   
  -- -------- --

and the functional equation 4.9 we deduce @xmath , which now implies
palindromicity of @xmath . ∎

The examples above and some further computer evidence also suggest that
the coefficients of @xmath are positive integers. Unfortunately we are
unable to prove this at the moment and can only record it as a
conjecture.

###### Conjecture 4.32.

@xmath is a polynomial with positive coefficients.

### 4.7 Indecomposable quiver representations in higher depth

In this section let @xmath be a quiver as in 2.3 . Most of what we say
in this section will be independent of the orientation of @xmath , hence
we use the words quiver and graph interchangeably. By a subquiver @xmath
of @xmath we will always mean a quiver with @xmath and @xmath .

For a dimension vector @xmath and @xmath we write @xmath for the free
@xmath -module of representations of @xmath over @xmath with dimension
@xmath i.e.

  -- -------- --
     @xmath   
  -- -------- --

We are only considering @xmath -dimensional representations here, that
is @xmath , in which case we abbreviate @xmath .

A representation @xmath is indecomposable if it is not isomorphic to the
sum of two representations with strictly smaller dimension vectors. We
denote the subset of indecomposable representations by @xmath . Since we
are considering only @xmath -dimensional representations, @xmath will be
indecomposable if and only if the subquiver @xmath , where @xmath , is
connected.

As in 2.3 the group

  -- -------- --
     @xmath   
  -- -------- --

will act on @xmath and two representations are isomorphic if and only if
they lie in the same orbit under this action. The number @xmath of
indecomposable representations up to isomorphism is then given by

  -- -------- --
     @xmath   
  -- -------- --

We now explain a formula for @xmath which we learned from unpublished
notes of Anton Mellit [ Mel16 ] . First we have by Burnside’s Lemma

  -- -------- -- ------
     @xmath      (77)
  -- -------- -- ------

To evaluate this sum we define for every @xmath a sequence

  -- -------- --
     @xmath   
  -- -------- --

of subquivers of @xmath by putting @xmath and

  -- -------- --
     @xmath   
  -- -------- --

for @xmath . Here the norm of an element in @xmath is defined as the
norm of any lift to @xmath .

###### Lemma 4.33.

The number of automorphism of @xmath is given by

  -- -------- --
     @xmath   
  -- -------- --

where we write @xmath for the number of connected components of a graph
@xmath .

###### Proof.

An element @xmath is an automorphism of @xmath if and only if for every
@xmath we have

  -- -------- -- ------
     @xmath      (78)
  -- -------- -- ------

In particular, we have @xmath whenever @xmath . This proves the lemma in
the case @xmath . For @xmath denote by @xmath the graph obtained from
@xmath by contracting all the edges in @xmath . Then @xmath and @xmath
descend to a representation @xmath and an automorphism @xmath .
Furthermore we have by construction @xmath for some @xmath . This shows
that the coefficient of @xmath in @xmath does not actually appear in (
78 ). As @xmath is a graph on @xmath vertices we thus obtain the
recursion

  -- -------- --
     @xmath   
  -- -------- --

and the lemma follows by induction on @xmath . ∎

###### Proposition 4.34.

[ Mel16 ] The number of indecomposable representations of @xmath up to
isomorphism over @xmath is given by

  -- -------- -- ------
     @xmath      (79)
  -- -------- -- ------

where we write @xmath for the first Betti number of a graph @xmath .

###### Proof.

For a given sequence @xmath the number of @xmath with @xmath for all
@xmath is given by

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
              @xmath   
  -- -------- -------- --

as the norm @xmath is prescribed for each @xmath by the sequence of
graphs. Since @xmath and @xmath for all @xmath by definition, the
formula follows from Burnside’s Lemma ( 77 ). ∎

As in Section 4.6 we consider now the limit of @xmath as @xmath
appropriately normalized. In order to do this we have to make sure, that
the coefficient of the highest @xmath -power in @xmath doesn’t grow as
we vary @xmath , which will exactly be the case when @xmath is @xmath
-(edge)connected i.e. when @xmath stays connected after removing any of
its edges.

###### Corollary 4.35.

@xmath is a polynomial in @xmath of degree @xmath . The limit @xmath
converges if and only if @xmath is @xmath -connected, in which case it
is given by

  -- -------- -- ------
     @xmath      (80)
  -- -------- -- ------

where the sum is over all strict chains of subgraphs of length @xmath .

###### Proof.

To get the degree of @xmath we notice in general, that given two graphs
@xmath on the same set of vertices we have @xmath since adding an edge
to a graph can at most connect two components. The leading coefficient
of @xmath then comes from summing up over all sequences with @xmath . If
there is any subgraph @xmath with @xmath , then the number of such
sequences will go to infinity as @xmath . Hence @xmath converges if and
only if @xmath for any subgraph of @xmath , which in turn is equivalent
to @xmath being @xmath -connected.

To compute @xmath when @xmath is @xmath -connected it will be convenient
to rewrite ( 79 ) as a sum over strict chains @xmath . Explicitly given
any chain @xmath there exists an integer @xmath and integers @xmath such
that @xmath for @xmath . If we then put @xmath for @xmath we can rewrite
( 79 ) as

  -- -------- -------- --
     @xmath   @xmath   
              @xmath   
  -- -------- -------- --

From this we see that the only sequences @xmath giving a non-zero
contribution to the limit @xmath are the ones where @xmath i.e. @xmath .
The corollary then follows from the iterated geometric series summation

  -- -------- --
     @xmath   
  -- -------- --

∎

In order to compare @xmath with @xmath from the last section, we define
a hyperplane arrangement @xmath out of @xmath . For every edge @xmath
define the hyperplane @xmath in @xmath by the equation @xmath . This
way, if @xmath is connected, we obtain an arrangement of rank @xmath ,
since the @xmath -dimensional subspace spanned by @xmath will be
contained in all hyperplanes. Furthermore @xmath will be coloop-free if
and only if @xmath is @xmath -connected.

Since formula ( 80 ) is essentially a sum over all possible chains of
subgraphs of @xmath it is quite cumbersome to evaluate it even for small
graphs. That is why we used Sage to compute the following examples.

###### Example 4.36.

For @xmath the affine @xmath i.e. @xmath and @xmath we get

  -- -------- --
     @xmath   
  -- -------- --

Similarly for @xmath we have

  -- -------- --
     @xmath   
  -- -------- --

The values @xmath for the corresponding arrangements were studied in
Example 4.4 .

One can also consider non simply-laced quivers, for example @xmath with
one edge doubled, which corresponds to Example 4.29 . In this case we we
have

  -- -------- --
     @xmath   
  -- -------- --

The pattern in all the examples is of course that @xmath and @xmath seem
to have very similar numerators, but slightly different denominators. We
record this observation in the following conjecture.

###### Conjecture 4.37.

For any @xmath -connected graph @xmath with associated arrangement
@xmath we have

  -- -------- --
     @xmath   
  -- -------- --
