# Chapter 1 Introduction

For the last couple of decades a theory that goes by the unassuming name
of ‘The Standard Model’, has been the generally accepted theory of
fundamental physics. This Standard Model has been very successful in
describing experiments in particle physics. All particles that were
theoretically predicted by it have been detected, except for one: the
Higgs particle. By now this Higgs particle, often called ‘the holy grail
of high-energy physics’, has become so important that billions of euros
are spent to build large particle colliders, hoping to produce these
Higgs particles. In Europe the LHC is being built, mainly for this
purpose, and this 27 km long accelerator is expected to become
operational in 2008.

Knowing this it is clear that the Higgs sector of the Standard Model is
very important and interesting. The Higgs mechanism was proposed in the
60’s by Brout and Englert [ 1 ] , Higgs [ 2 , 3 ] and Guralnik, Hagen
and Kibble [ 4 ] to give masses to the gauge bosons and the fermions,
while keeping the theory renormalizable. The main feature of this Higgs
mechanism is the mechanism of spontaneous symmetry breaking (SSB), which
was introduced into quantum field theory by Nambu [ 5 , 6 ] , in analogy
to the BCS theory of superconductivity. This mechanism of SSB will be
the main topic of this thesis.

A nice introduction to SSB and the Higgs mechanism can be found in a
review article by Bernstein [ 7 ] .

### 1.1 Spontaneous Symmetry Breaking

How does SSB work in quantum field theory, and what is it? The canonical
approach to SSB, which one finds in most textbooks (e.g. [ 8 , 9 , 10 ]
), is as follows. One starts with a (bare) Lagrangian, obeying some
symmetry in the fields (e.g. reflection or rotational symmetry), of
which the bare (classical) potential has more than one minimum. The most
common, and most important, example is the ‘Mexican hat’ potential. This
means that the set of minima must also obey the symmetry, which means
again that in any given minimum the fields cannot all be zero. Writing
all fields into the single vector @xmath we have at the minima: @xmath .
Therefore the classical lowest energy states, or vacua, are degenerate
and have a non-zero field value, @xmath . In a quantum field theory the
lowest energy state, or vacuum @xmath , should be calculated from the
Schrödinger equation:

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

Clearly, because of the very complicated form of the Hamiltonian @xmath
in a quantum field theory, this equation can not be solved. Inspired by
the classical minimum-energy states, one therefore postulates that also
the quantum vacuum is degenerate, and that:

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

So there are multiple vacuum states. But we can only live in one of
these, and nature has chosen one of these vacuum states. Which one has
been chosen, cannot be determined, and is therefore unimportant, because
all theories built on one of these states have exactly the same physics.

This is called spontaneous symmetry breaking, i.e. the vacuum state of
the theory does not have the same symmetry as the Lagrangian. So the
dynamics of the theory obey a certain symmetry, which is not respected
by the vacuum state.

Having postulated ( 1.2 ) one can then derive, via the equations of
motion, the Schwinger-Dyson equations and the Feynman rules, that this
gives a mass-like term for all particles coupling to the (Higgs) field
@xmath . The fluctuation in this (Higgs) field around the constant value
it has in the chosen vacuum is the Higgs particle.

After this one can calculate all Green’s functions of the theory. Also
one can construct the 1PI Green’s functions and sum them, in the
appropriate way, to obtain the effective potential. As we shall see this
effective potential comes out to be complex and can be non-convex in
certain domains. This is the well known convexity problem , i.e. the
canonical perturbative calculation gives a non-convex effective
potential, whereas general arguments show that this effective potential
is convex . The precise meaning of convex will be discussed in chapter 2
. Also its convexity will be proven there.

### 1.2 The Path Integral

Now this mechanism of SSB can also be studied from the viewpoint of the
path integral. We know that the path-integral approach, by Feynman, is
just another way of formulating quantum mechanics, or quantum field
theory. Like the Feynman rules in the canonical approach, the path
integral is also a solution to the Schwinger-Dyson equations of the
theory.

In this path-integral approach the path integral gives the Green’s
functions of the theory:

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

Here @xmath is some expression built from the @xmath -fields, like
@xmath , or @xmath .

So from the path-integral viewpoint one should also be able to see
whether we have SSB:

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

as is postulated in the canonical approach.

It is exactly the path-integral approach to SSB that we shall study in
this thesis. The two simplest models to study SSB are of course the
@xmath and @xmath Euclidean linear sigma models, and these models we
will consider.

It will appear that, although the canonical results and the path
integral are solutions to the same Schwinger-Dyson equations, the two
approaches do not give the same results in the case of a classical
potential with more than one minimum, i.e. a non-convex classical
potential.

Also it will appear that this path-integral approach cures the
complexity and non-convexity that were obtained in the canonical
approach.

### 1.3 Literature

What has been discussed in the literature about the convexity problem?
In [ 11 , 12 ] Symanzik and Iliopoulos et al. were the first to realize
that the effective potential is convex. A nice proof of this convexity
property is given by Haymaker et al [ 13 ] . Note that this proof is
based on the path-integral formalism. The fact that there is a convexity
problem (i.e. the perturbatively calculated effective potential, in case
of a non-convex classical potential, is not convex, despite general
proofs that it should be) was first realized by O’Raifeartaigh et al. [
14 ] . After this there were several attempts to modify the computation
of the effective potential to find a proper, convex effective potential.
These attempts can be found in [ 15 , 16 , 17 , 18 , 19 , 20 ] . Indeed
these attempt were successful, in all of these articles a convex,
well-defined effective potential is found for several models. All these
attempts come down to the same idea, to get a convex and well-defined
effective potential one should take the path integral seriously and
calculate from there. This means one should include all minima of the
classical potential in the calculation, i.e. do perturbation theory
around each of the minima and add the generating functionals around each
of the minima to obtain the complete generating functional. If one then
computes the effective potential from this complete generating
functional one finds the result to be convex and well-defined for all
field values.

However, in this new (path-integral) approach, SSB is lost in the strict
sense, i.e. all of the convex effective potentials that are calculated
in the articles above have their minimum at zero for finite space-time
volume. For infinite volume the bottom of the effective potentials
becomes flat (Maxwell construction) and one is left with an infinite set
of minima, living between the classical minima. What, then, is the true
vacuum? Can one still determine what the vacuum is from these effective
potentials? In [ 15 ] one can find a short remark about this. There the
authors state that in the case of a non-convex classical potential,
maybe the effective potential is not the proper thing to look at to find
the true vacuum. Or alternatively one might define SSB not as a non-zero
vacuum expectation value, but as the sensitivity of the effective
potential to small external sources. In this sense the new, convex
effective potential is just as sensitive to a non-zero source as the
old, non-convex effective potential.

However, besides these few vague remarks, no clear explanation is given
as to what the new path-integral approach means for the physics of the
theory.

O’Raifeartaigh et al. [ 21 ] , inspired by [ 22 ] , introduce a
constraint effective potential. This constraint effective potential is
calculated from a path integral, in which a constraint that keeps the
space-time averaged field to a non-zero value is included. Simply
because of the constraint, there is SSB in the strict sense now. However
in the infinite volume limit the constraint effective potential
converges to the convex effective potential again, leaving one again
with a flat bottom of minima. Again it is unclear what this means for
the physics. Also Ringwald et al. [ 23 ] define a constraint effective
potential, however now the constraint keeps the average of the field
over a certain limited domain of space-time to a non-zero value. Again
the constraint effective potential converges to the convex effective
potential in the infinite volume limit. Nothing is said about the
physics behind this theory.

Branchina et al. [ 24 ] do go into more details about the physics. Here
they also include all minima of the path integral (no constraint) and
find a flat bottom. Their approach is essentially based on the canonical
formalism and they find explicitly the ground states in a Gaussian
approximation. They find two pure Gaussian states, which means that all
linear superpositions of these states are also ground states. These
correspond to the flat bottom of the effective potential. They calculate
the probability to be in one of these states. This probability is only
non-zero for the pure Gaussian states. This is their interpretation of
SSB. However, for the rest nothing is said about the physics that
follows from this approach.

Weinberg et al. [ 25 ] further analyze the complex, non-convex effective
potential one finds when only including one minimum (i.e. canonical
approach). They define the vacuum states of the theory to be states
that, of course, minimize the Hamiltonian, but are also localized around
some field value. It appears that the imaginary part of the complex
effective potential is related to the decay rate of the (unstable)
vacuum states which are localized around a point between the classical
minima.

Dannenberg [ 26 ] further analyzes and resolves the convexity problem.
The point is that the convex effective potential, as calculated from the
path integral, and the complex effective potential, as calculated in the
canonical way (the sum of all 1PI diagrams), are simply not the same
thing. In the path-integral approach one includes all minima, in the
canonical approach one includes only one minimum. Although both ways are
solutions to the same Schwinger-Dyson equations, they are not equal. In
this way it is completely understandable that the canonical approach
gives a non-convex effective potential, even though one can prove from
the path integral that the effective potential is convex. Both
approaches are simply different and therefore give different results and
physics.

Wiedemann [ 27 ] further analyzes what the non-convex complex effective
potential and the convex effective potential tell one about the physics
of the theory. It is shown that the flat section of the convex effective
potential corresponds to the ground states of the theory. The complex
effective potential gives one the boundaries of the flat section.

Having considered all of this literature one can conclude the following.
The convexity problem is not really a problem, it originates only
because one compares two different things, at first thought to be the
same. The canonical approach and the path-integral approach, although
solutions to the same Schwinger-Dyson equation, seem to be different in
the case of a non-convex classical potential. So both approaches also
give different results. This difference between the canonical and
path-integral approach will be the main topic of this thesis. It is also
this difference that might create some confusion in for example Peskin
and Schroeder [ 8 ] . In their chapter 11 they first calculate the
effective potential in the canonical approach and find it to be
non-convex. Later they argue that the effective potential is always
convex. They do not clearly explain how this convexity property relates
to the non-convex result.

Taking the viewpoint of the canonical approach, one postulates a
non-zero vacuum expectation value. This is completely self-consistent
and one finds a spontaneously broken theory. One can define the
effective potential as the sum of all 1PI graphs (with the appropriate
factors) and one finds it to be non-convex and complex in certain
regions. This does not matter however, since the proof that the
effective potential is convex originates only in the path-integral
approach, which is not the same.

Taking the viewpoint of the path-integral approach one finds a convex
effective potential, as can be proven on general grounds (within this
approach). However, what the physics of this approach is, is unclear up
to now. Also interesting is whether one can reproduce the physics as it
is found in the canonical approach (with SSB and all) in this
path-integral approach. Can one get the same Green’s functions in this
path-integral approach?

### 1.4 Outline of this Thesis

In the articles mentioned above several links between results from the
canonical approach and results from the path-integral approach are
proven to exist, although both approaches do not give the same results
in general. So a number of big questions remain: Can one somehow
reproduce the canonical results from the path-integral approach? Or are
both approaches fundamentally different? Can one find SSB, with all the
known physics that goes with it, from the path integral? These questions
will be the main topics of this thesis.

In chapter 2 a short introduction to the effective action will be given.
The effective action and effective potential will be defined, their
meaning will be discussed and their convexity will be proven, via the
path integral.

In chapter 3 the canonical approach to the @xmath linear sigma model
will be discussed. We follow here the same lines as in the quantum field
theory textbooks (e.g. [ 8 ] ). The renormalized Green’s functions will
be computed and the counter terms will be found, so we can use them in
later chapters for different approaches. Also the effective potential
will be computed for several dimensions and shown to be complex where
the classical potential is non-convex. Also it will be shown that it can
become non-convex.

In chapter 4 the path-integral approach to the @xmath linear sigma model
will be discussed. This is done in the same way as Fujimoto et al. [ 15
] and Cooper et al. [ 18 ] do. We find the renormalized effective
potential for several dimensions, which is indeed convex and
well-defined everywhere. Also we find the renormalized Green’s functions
and conclude what the physics of this approach is. This physics is
different than in the canonical approach. What the Green’s functions
become when other particles interacting with the (Higgs) fields @xmath
are present will also be discussed.

In chapter 5 we will outline another path-integral approach to the
@xmath linear sigma model. This time, hoping to reproduce the physics of
the canonical approach, we will fix the paths at some time @xmath at a
specific field value over all of space. First we will show that this
model is renormalizable up to 1-loop order. Then we will calculate the
effective potential and the renormalized Green’s functions.

In chapter 6 we will present the canonical approach to the @xmath linear
sigma model. The calculations there are similar to the standard
calculations done in all textbooks, like [ 8 ] . The renormalized
Green’s functions will be computed and the counter terms will be fixed,
such that we can use them later throughout the thesis. The effective
potential will also be calculated and shown to be complex where the
classical potential is non-convex. Also it can become non-convex.

In chapter 7 the path-integral approach to the @xmath linear sigma model
will be presented. We will compute the renormalized Green’s functions by
naively integrating over all minima of the action. Also an approximation
to the effective potential will be found in this naive way. Again, as in
the @xmath linear sigma model, we will see that the physics of this
path-integral approach is different from the physics of the canonical
approach. However, it is questionable whether the naive way of
calculating here is correct.

To do the calculation from chapter 7 in a better way we need the path
integral in terms of polar field variables. These variables are the
natural variables to describe an @xmath -invariant model. This
complicated transformation to polar field variables will be the subject
of chapter 8 . We will show what the path integral looks like in terms
of polar fields, and how it should be calculated.

In chapter 9 we consider again the path-integral approach to the @xmath
linear sigma model. Now we do the calculations via the path integral in
terms of polar variables, discussed in chapter 8 . We will calculate the
renormalized Green’s functions and the effective potential. We will
compare the results obtained here with the results from chapter 7 , and
finally discuss the physics of the path-integral approach to the @xmath
linear sigma model.

## Chapter 2 The Effective Action

### 2.1 Definition

Consider a Euclidean scalar quantum field theory with any number of
fields and any number of space-time points (e.g. infinite number). We
put all field values in one single vector @xmath . For each field value
we also have a source, all these sources are put in the vector @xmath .
The (bare) action of this theory we denote by @xmath . Then the
effective action of this theory, which is a function of a vector @xmath
, is defined by

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

where @xmath is defined as the inverse function of

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

That this inverse functional @xmath always exists can be seen as
follows. If it exists we have:

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

This means that one requirement for @xmath to exist is that the matrix
@xmath has an inverse. This is true if all eigenvalues of this matrix
are non-zero. That this is indeed the case follows from:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (2.4)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

with

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

This means:

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

for all @xmath and arbitrary vector @xmath . This could not immediately
be seen from @xmath because we are dealing with a connected average
here. Writing @xmath in terms of the eigenvectors @xmath (with
eigenvalues @xmath ) of the matrix @xmath :

  -- -------- -- -------
     @xmath      (2.7)
  -- -------- -- -------

we see that also

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

Because the @xmath ’s and thus also the @xmath ’s are arbitrary, all the
eigenvalues @xmath have to be positive. So we see all eigenvalues are
not just non-zero, they are also strictly positive.

There is a small loop-hole here, that we have to discuss. In some
special situations it can happen, for some specially chosen @xmath ,
that the left-hand-side of ( 2.6 ) becomes exactly zero. We shall see in
chapter 5 how this can happen when we introduce constraints in the path
integral. In that case there is no unique inverse. This will be
discussed thoroughly in chapter 5 . In the rest of this chapter we shall
assume that we are not in such a special situation and thus ( 2.6 )
holds.

So now we know that the matrix @xmath exists. To find @xmath itself this
system of partial differential equations has to be integrated. This is
only possible if

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

That this is also the case can be seen by taking another derivative in (
2.3 ):

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

Because the first term is symmetric in @xmath and @xmath the second term
is too. So indeed it is possible to find the inverse @xmath from ( 2.3
).

### 2.2 The Meaning of the Effective Action

The generating functional @xmath of our scalar field theory is

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

This functional generates the connected Green’s functions:

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

Now the physical meaning of the effective action can be seen by taking
derivatives and putting the source @xmath to zero in the definition (
2.1 ).

First, just setting @xmath without taking a derivative we get:

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

where @xmath just means @xmath . This means the effective action has its
minimum at the vacuum expectation value of the field(s).

Taking one derivative with respect to @xmath in ( 2.1 ) gives:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (2.14)
  -- -------- -------- -------- -- --------

Now if we put @xmath on both sides in ( 2.14 ) the righthand side
becomes the inverse of the ordinary connected 2-point Green’s function:

  -- -------- -- --------
     @xmath      (2.15)
  -- -------- -- --------

This means that the second functional derivative of the effective action
at its minimum is equal to @xmath times the inverse connected 2-point
Green’s function.

Taking two derivatives with respect to @xmath and putting @xmath in (
2.1 ) gives:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath                        (2.16)
  -- -------- -------- -------- -- --------

This means the third functional derivative of the effective action at
its minimum is equal to @xmath times the 1PI 3-point Green’s function.

By taking more derivatives with respect to @xmath and putting @xmath it
can be shown that

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

These relations show that when we expand the effective action around its
minimum, read off the propagator and the coupling constants like we
would read them off from the bare action, the Feynman rules thus
obtained would give the complete physical Green’s functions at tree
level. This is the meaning of the effective action, from it one can
immediately see the physical amplitudes.

### 2.3 The Argument for Convexity

What is ‘convex’? Although ‘convex’ and ‘concave’ are often mixed up in
the world-wide literature, we shall stick to the definition that is most
widely used in physics. A convex function @xmath is a function that, for
any @xmath and @xmath ( @xmath and @xmath can be vectors), and any
@xmath in @xmath ( @xmath ), satisfies:

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

In words this means that a linear interpolation of @xmath is always
larger than or equal to @xmath itself. Strictly convex means that the
linear interpolation is always larger than @xmath itself:

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

for all @xmath , @xmath and @xmath .

Now we show that the effective action of a Euclidean quantum field
theory is always convex, in any dimension.

An effective action @xmath is convex if and only if

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

for all @xmath and arbitrary vector @xmath . It is easy to see that this
condition is equivalent to ( 2.18 ).

This condition is equivalent to

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

In ( 2.8 ) we showed that the eigenvalues of the matrix @xmath are all
strictly positive. This means that also the eigenvalues of the inverse
matrix @xmath are strictly positive and that

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

for arbitrary @xmath and all @xmath . Using ( 2.14 ) we then see that (
2.20 ) is indeed true, so the effective action is convex .

The effective action appears to be even strictly convex. However, this
is not necessarily true. Although it is true that the eigenvalues of
@xmath are all strictly positive, it can happen, in the infinite-volume
limit, that one of these eigenvalues goes to infinity. Then, of course,
one of the eigenvalues of @xmath goes to zero in this limit. In this way
the effective action can have flat directions, and it is not strictly
convex, but just convex.

This completes our proof that the effective action, and with it the
effective potential, always have to be convex for a Euclidean quantum
field theory. Our argument does not depend on the dimension of
space-time, nor the number of different fields in our quantum field
theory.

### 2.4 The Effective Potential

The effective potential is defined as the effective action where we take
all fields constant over space-time divided by the volume of space-time.
Up to now we have employed a general formalism in which we did not
explicitly specify what the index of the field @xmath meant. To obtain
the effective potential we have to specify this. Let’s say we have
@xmath fields @xmath , all depending on space-time coordinates @xmath .
Here @xmath is a @xmath -vector containing all space-time coordinates.

To obtain an expression for the effective potential we first expand the
effective action around its minimum. We denote the deviation of the
@xmath -fields from their value @xmath by @xmath , @xmath . Then the
effective action can always be expanded as:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (2.23)
  -- -------- -- --------

Now we use ( 2.15 ), ( 2.16 ) and ( 2.17 ) to obtain the following
expression for the effective action:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.24)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now we can take all @xmath -fields constant to obtain the effective
potential @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.25)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now if the fields @xmath correspond to physical particles, then the
2-point connected Green’s functions are only non-zero when the in- and
outgoing lines are of the same type. Then this propagator becomes
diagonal in momentum space and finding the inverse propagator is very
simple, it just means literally inverting it. So, writing the Green’s
functions in terms of the momentum-space Green’s functions, the
expression for the effective potential becomes particularly simple:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.26)
                                @xmath   
  -- -------- -------- -------- -------- --------

Here @xmath denotes a @xmath -vector with only zeroes. Now we also know
that:

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

and with this the effective potential can be written as:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (2.28)
                                @xmath   
  -- -------- -------- -------- -------- --------

Another convenient way to write this is:

  -- -------- -- --------
     @xmath      (2.29)
  -- -------- -- --------

This is the well known vacuum-graph formula.

## Chapter 3 The @xmath LSM: The Canonical Approach

In this chapter we shall present the canonical approach to the @xmath
linear sigma model. Our calculations mostly follow the well known text
books on quantum field theory (e.g. [ 8 , 10 ] ). The renormalized
Green’s functions and the counter terms will be computed, the latter
will be used in later chapters. Also the effective potential will be
calculated and shown to be complex and non-convex in general.

The Euclidean linear sigma model with @xmath field is defined by the
bare action

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

Here @xmath denotes a @xmath -vector containing all space-time
coordinates

  -- -- -- -------
           (3.2)
  -- -- -- -------

and @xmath is the @xmath -vector

  -- -- -- -------
           (3.3)
  -- -- -- -------

These notations shall be used throughout this thesis. @xmath Is
understood to be positive, @xmath , so we have a non-convex classical
potential and thus SSB in the canonical approach.

### 3.1 Green’s Functions

To compute the renormalized Green’s functions we introduce the following
renormalized quantities:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (3.4)
  -- -------- -------- -------- -- -------

From here on we shall suppress the R-superscripts, understanding that we
always work with renormalized quantities from now on. Written in terms
of these renormalized quantities the action is

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.5)
                                @xmath   
  -- -------- -------- -------- -------- -------

Now the classical action (i.e. the first line of ( 3.5 )) has its minima
at:

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

In the canonical approach it is postulated that also the quantum field
has its vacuum expectation value at one of these classical minima. Which
minimum does not matter for the physics, so we choose @xmath . Therefore
we express the action in terms of the field @xmath , which indicates the
deviation from this minimum:

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

The action then becomes

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (3.8)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

Now all except the first two terms are treated as perturbations. For
convenience define @xmath . The Feynman rules of this theory are then
given by:

  -- -- -------- -------- -- -------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (3.9)
  -- -- -------- -------- -- -------

Now we compute the connected momentum-space Green’s functions up to one
loop. In the case of the 3- and 4-point function we will calculate the
1PI-part of the connected Green’s function, since it is this part that
occurs in our renormalization conditions. We shall write all results in
terms of the standard @xmath -dimensional one-loop integral @xmath :

  -- -------- -- --------
     @xmath      
                 (3.10)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (3.11)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (3.12)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (3.13)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (3.14)
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now our theory contains three free parameters, @xmath , @xmath and
@xmath . To fix these we need three renormalization conditions. We shall
use the following conditions:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (3.15)
  -- -- -------- -------- -- --------

The last condition states that the physical 4-point coupling at @xmath
is @xmath , i.e. we have chosen the renormalized @xmath to be equal to
the physical 4-point coupling constant at @xmath . The first condition
states that @xmath at all orders in perturbation theory. This means we
have also chosen the renormalized @xmath to be equal to the physical
vacuum expectation value of the @xmath -field. This condition fixes (the
renormalized) @xmath . This in turn fixes the physical mass @xmath ,
which can be calculated from the 2-point Green’s function. Note that
@xmath is not equal to the classical value @xmath . The second condition
fixes the wave function renormalization @xmath . This second condition
is equivalent to:

  -- -- -------- -------- -------- --------
        @xmath   @xmath            (3.16)
                 @xmath   @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

where

  -- -- -- --------
           (3.17)
  -- -- -- --------

With these conditions it is now easy to determine the counter terms:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (3.18)
  -- -------- -------- -------- -- --------

@xmath Can be calculated up to order @xmath from the 2-point function (
3.12 ). Substituting the counter terms obtained in ( 3.18 ) and Dyson
summing the result ( 3.12 ) gives

  -- -------- -- --------
     @xmath      (3.19)
  -- -------- -- --------

with

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.20)
                                @xmath   
  -- -------- -------- -------- -------- --------

Now the solution @xmath of

  -- -------- -- --------
     @xmath      (3.21)
  -- -------- -- --------

is @xmath . It is easy to obtain this solution, of course up to order
@xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.22)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

It is easy to see that for @xmath this @xmath is indeed finite. However
for @xmath it is not! This shows that our @xmath linear sigma model,
like all @xmath -theories, is non-renormalizable for @xmath .

Now it can also be shown that the 3- and 4-point 1PI Green’s function (
3.13 , 3.14 ), and in fact all @xmath -point Green’s functions are
finite at one-loop order, for @xmath .

Now we have fixed all of our parameters in terms of the physical
parameters. Our renormalized @xmath is just equal to the physical
4-point coupling @xmath , an so is our renormalized @xmath . This then
fixes our renormalized @xmath (and with it @xmath ): @xmath . Then all
counter terms as given in ( 3.18 ) and the physical mass as given in (
3.22 ) can be expressed in terms of the two physical parameters @xmath
and @xmath .

### 3.2 The Effective Potential

Now we want to find also the one-loop effective potential of our @xmath
linear sigma model. We know that the effective potential @xmath is given
by the vacuum-graph formula, which, in the @xmath case, simplifies to:

  -- -------- -- --------
     @xmath      (3.23)
  -- -------- -- --------

This means to obtain the one-loop effective potential we just have to
take the sum of all 1-loop 1PI diagrams with the appropriate factors and
with zero momentum in the external legs.

Let @xmath and @xmath denote the number of 3- and 4-vertices in a
diagram. Then @xmath is the number of external legs. Every 3-vertex in a
diagram gets a @xmath , every 4-vertex a @xmath . For a diagram with
@xmath (identical) 3-vertices we get a @xmath , likewise we get a @xmath
. To see how many ways there are to connect the legs of the vertices and
the external legs we first decide which legs are going to be part of the
loop. For each 3-vertex there are @xmath ways to choose this, for each
4-vertex there are @xmath ways to choose this. The legs that have been
chosen as internal can then be connected in @xmath ways. The other legs
can be connected to the external legs in @xmath ways. Then the one-loop
effective potential @xmath is:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.24)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

By substituting @xmath we can replace the sum over @xmath by a sum over
@xmath . The sum over @xmath can then easily be done with help of the
binomial theorem. We find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.25)
                                @xmath   
  -- -------- -------- -------- -------- --------

For @xmath only the terms with @xmath and @xmath in the sum diverge.
These divergences are supposed to be cancelled by the counter terms. It
is easy to check that this indeed happens when we substitute the counter
terms ( 3.18 ) that we found before! After also expressing @xmath in
terms of the original field @xmath (exact relationship with the
renormalization conditions that we have chosen) we find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.26)
                                @xmath   
  -- -------- -------- -------- -------- --------

Now for @xmath and @xmath we have

  -- -------- -- --------
     @xmath      (3.27)
  -- -------- -- --------

so that we get

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.28)
                                @xmath   
  -- -------- -------- -------- -------- --------

What function this exactly is depends strongly on the dimension @xmath ,
so to find an explicit result we have to specify @xmath .

#### 3.2.1 @xmath

For @xmath we find:

  -- -------- -- --------
     @xmath      (3.29)
  -- -------- -- --------

In figure ( 3.1 ) @xmath and @xmath are plotted as a function of @xmath
for the case @xmath , @xmath , @xmath .

It is easy to check that the minima of this 1-loop effective potential
are still at @xmath , like our renormaliztion conditions ( 3.15 )
ensures. Expanding around the minimum @xmath one finds:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.30)
                                @xmath   
  -- -------- -------- -------- -------- --------

Indeed there is no tadpole term, and also the 4-point term is absent, as
imposed by our renormalization condition ( 3.15 ). From the 2-point term
one can read off a mass correction @xmath . However this is not the
correction to the physical mass @xmath ! This correction is given in (
3.22 ), and is in the case of @xmath :

  -- -------- -- --------
     @xmath      (3.31)
  -- -------- -- --------

Here we used the standard integral results given in appendix A .

So in our renormalization scheme the 2-point part of the effective
potential does not give the physical mass. The reason is very simple,
the one-loop correction to the effective potential is given by @xmath ,
whereas the one-loop correction to the physical mass is given by @xmath
, with @xmath as defined in ( 3.17 ). To extract the physical mass
@xmath from the effective action we need the complete effective action
including the dynamical part, not just the effective potential.

The 4-point part of our effective potential does give the physical
coupling constant however, simply because we put @xmath at zero incoming
momentum.

Now there seems to be a problem with this 1-loop effective potential (
3.29 ). The argument of the square root in ( 3.29 ) becomes negative
when

  -- -------- -- --------
     @xmath      (3.32)
  -- -------- -- --------

This means the 1-loop effective potential becomes complex where the
classical effective potential becomes non-convex, i.e. @xmath . Even in
the domain where the 1-loop effective potential is defined there is
something wrong, it can become non-convex ! In figure 3.1 @xmath is
indeed non-convex, however parameters can also be chosen such that it is
convex where it is defined. However according to our general argument it
should always be convex. As has already been discussed in the literature
it is no problem that one finds a non-convex effective potential in the
canonical approach, the proof for the convexity originates only in the
path-integral approach. Also, only in the path-integral approach one can
argue that the effective potential should be real and well-defined
everywhere (see chapter 2 ).

#### 3.2.2 @xmath

For the case @xmath we find, using ( 3.28 ):

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.33)
                                @xmath   
  -- -------- -------- -------- -------- --------

In figure ( 3.2 ) @xmath and @xmath are plotted as a function of @xmath
for the case @xmath , @xmath , @xmath .

The minima are again at @xmath . Expanding ( 3.33 ) around @xmath gives:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (3.34)
                                @xmath   
  -- -------- -------- -------- -------- --------

Again we see that there is no tadpole and 4-point part, in accordance
with our renormalization conditions ( 3.15 ).

The physical mass @xmath can again be calculated from ( 3.22 ). This
calculation is somewhat more involved now since we have divergences
occurring at intermediate steps in the calculation. By using the
standard integral results from appendix A we find:

  -- -------- -- --------
     @xmath      (3.35)
  -- -------- -- --------

Again, as in @xmath , at first sight there is a problem with ( 3.33 ).
For @xmath the argument of the logarithm becomes zero or negative, such
that the one-loop effective potential is complex in this domain. Also it
can become non-convex in this domain. Indeed the @xmath in figure 3.2 is
non-convex (although this might be a bit hard to see, it can be seen
more clearly by plotting the derivative of @xmath ).

### 3.3 Instantons

Instantons are classical solutions of the equations of motions,
i.e. configurations that minimize the classical action, which are not
constant (like ( 3.6 )), but which go from one minimum to the other.
Also these instantons should have a finite action. For a nice book on
these instantons see [ 28 ] .

So what about instantons in the @xmath linear sigma model? For dimension
1 it can easily be shown that there is a classical solution that takes
one from one minimum to the other and that has a finite action. So for
@xmath we should have included these instanton solutions in a complete
treatment. In [ 29 ] such a treatment for the @xmath linear sigma model
can be found. When including these instantons one will not find a
spontaneously broken theory. This is well known, in one dimension there
is no SSB, on account of tunneling.

However, it is shown in general, by Derrick [ 30 ] , that for @xmath no
instanton solutions exist. Of course there exist solutions of the
classical equations of motion that go from one minimum to the other, but
these solutions have infinite action. Since we are mostly interested in
higher dimensions, i.e. @xmath , we shall not include instantons at all
in this thesis.

## Chapter 4 The @xmath LSM: The Path-Integral Approach

In this chapter we discuss the path-integral approach to the @xmath
Euclidean linear sigma model. This means we take the path integral
seriously and take into account both minima in our calculations. These
calculations generally follow Fujimoto at al. [ 15 ] and Cooper at al. [
18 ] . We will calculate the effective potential, which will be convex
and well-defined. Also we will calculate some Green’s functions and say
something about the physics resulting from this approach.

The action we will use is:

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

Here, in contrast to the previous chapter, we have included a source
term in the action, to be able to compute the effective potential via
this source. In this action the field depends on the space-time
coordinates @xmath , and so does the source @xmath in general. We
however limit ourselves to the case where @xmath is constant over
space-time, since we are only interested in the effective potential and
not the complete effective action.

### 4.1 The Effective Potential

To find the renormalized generating functional and Green’s functions we
have to introduce renormalized quantities, as in ( 3.4 ). The source
@xmath is renormalized as:

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

By renormalizing @xmath in this way we ensure that by taking derivatives
with respect to @xmath one gets the renormalized Green’s functions. As
in the previous chapter we will drop the superscript R from now on. The
action becomes:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.3)
                                @xmath   
  -- -------- -------- -------- -------- -------

Now the two minima of the first line in ( 4.3 ) can be parameterized as:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (4.4)
  -- -------- -------- -------- -- -------

with @xmath , as in the previous chapter. We see that in this
parametrization

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

These limits are exactly the values of @xmath where one of the minima
becomes unstable. When this happens it is a good approximation to take
along only one minimum and the effective potential of the previous
chapter can be used in this region.

Now the action can be expanded around one of the minima @xmath :

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.6)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

The counter terms cannot depend on the source @xmath , so we can just as
well use the counter terms as derived in ( 3.18 ). These counter terms
will still make all results finite. However they will not make our
theory have the same physics as in the previous chapter, also because we
take into account both minima now. For now we use ( 3.18 ) and we will
see what physics we get.

The complete generating functional @xmath is given by

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

with

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

Now we take only the saddle-point approximation to @xmath , i.e. discard
all interaction terms (defined as all terms in the action of higher
order than @xmath ). Below we will see that this saddle-point
approximation will already produce the one-loop correction to the
effective potential, which we can then compare to our previous one-loop
effective potentials.

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (4.9)
                                @xmath   
  -- -------- -------- -------- -------- -------

This last line can be calculated as follows (We call the space-time
volume @xmath .):

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (4.10)
  -- -------- -------- -------- -- --------

Next we expand the logarithm around @xmath :

  -- -------- -- --------
     @xmath      
     @xmath      (4.11)
  -- -------- -- --------

The first term in this expansion can be discarded since it is merely a
constant, not depending on @xmath and thus unimportant for physical
quantities. Now the counter terms ( 3.18 ) can be inserted and ( 3.27 )
can be used to simplify the integrals in @xmath . After some algebra one
finds:

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

where @xmath is the zero-loop effective potential when one takes along
only one minimum, which is just the classical potential,

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

and @xmath is the one-loop effective potential when one takes along only
one minimum, which is given in ( 3.28 ). Notice that this @xmath has a
@xmath dependence through @xmath and @xmath .

Now one can also see that if we take into account only one minimum, e.g.
@xmath , we again get @xmath for the effective potential, like we got in
the previous chapter. This also demonstrates that the saddle-point
approximation to @xmath was enough to get the one-loop effective
potential. It also demonstrates that the canonical approach is in fact
equivalent to taking into account only one minimum in the path-integral
approach.

Continuing our calculation of @xmath and defining:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      (4.14)
  -- -------- -- --------

we find

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

and

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.16)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Now by inverting this @xmath we find @xmath , which is equal to the
derivative of the effective potential @xmath , where the superscript
‘2min’ denotes that we included both minima.

This derivative of @xmath is plotted in figure ( 4.1 ) for the case of
@xmath and @xmath , @xmath , @xmath , @xmath . Also the derivative of
the one-minimum effective potential ( 3.29 ) is plotted for comparison.

In figure ( 4.2 ) the derivative of @xmath is plotted for the case of
@xmath and @xmath , @xmath , @xmath , @xmath . Also the derivative of
the one-minimum effective potential ( 3.33 ) is plotted again.

By plotting the same case for larger and larger @xmath it is easy to see
that in the limit @xmath one gets an effective potential with a flat
bottom. This is the Maxwell construction of the one-minimum effective
potential. That one gets this Maxwell construction can also be seen from
( 4.16 ). It is easy to see that for small @xmath we have:

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

For @xmath this becomes a kink.

So indeed we get a convex and real effective potential in this case, as
dictated by our general arguments from chapter 2 . For finite space-time
volume @xmath it is even strictly convex.

For @xmath our effective potential is not strictly convex because in
this limit we have that

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

as will be shown in the next section. If we consider this as a matrix,
like we did in section ( 2.3 ), one can see that this matrix has
eigenvalues equal to infinity. A function @xmath and a value @xmath are
eigenfunction and eigenvalue of our matrix @xmath if:

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

If our matrix is just @xmath (at lowest order) one finds

  -- -------- -- --------
     @xmath      (4.20)
  -- -------- -- --------

which shows that all eigenvalues are infinite. If we include higher
order terms in @xmath (many of these are normalizable, i.e. give a
finite result when integrated over) the argument changes, but one will
still find at least one eigenvalue equal to infinity. This means that
the eigenvalues of the inverse matrix can become zero for infinite
volume and that the effective action is not strictly convex, but of
course still convex.

### 4.2 The Green’s Functions

Now we calculate the Green’s functions of the theory, to discover what
physics this theory gives. In section ( 2.2 ) we showed that the
functional derivatives of the effective action are related to the
Green’s functions of the theory. Because we find a flat bottom here, we
also get different Green’s functions than in the canonical approach.

First we compute the tadpole:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.21)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Here @xmath , @xmath , @xmath , @xmath , @xmath and @xmath are all
defined earlier in this chapter, and @xmath is given by:

  -- -------- -- --------
     @xmath      (4.22)
  -- -------- -- --------

This is just the @xmath -tadpole from the canonical approach. Now we
know:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (4.23)
  -- -------- -------- -------- -- --------

So we find

  -- -------- -- --------
     @xmath      (4.24)
  -- -------- -- --------

In the same way we can find the 2-point Green’s function.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (4.25)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Here @xmath is again just the @xmath -propagator from the canonical
approach. With the counter terms that we chose in this canonical
approach (and that we will use for the @xmath linear sigma model in the
whole of this thesis) we find, up to one-loop order:

  -- -------- -- --------
     @xmath      (4.26)
  -- -------- -- --------

with @xmath given in ( 3.20 ).

In the canonical approach we found for @xmath and @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (4.27)
  -- -------- -------- -------- -- --------

(Remember that we chose the positive minimum in the chapter 3 .)

Clearly the tadpole and the @xmath -propagator (it is questionable
whether one can still call this a propagator) are different than in the
canonical approach.

### 4.3 The Green’s Functions Near Another Particle

In the previous section we saw that the Green’s functions one finds in
the path-integral approach are very different from the Green’s functions
that one finds in the canonical approach. Now we can ask: What happens
to the field @xmath near another particle that it couples to like @xmath
(like the Higgs)? Near a @xmath -particle we have @xmath . This means
this @xmath -particle acts like a source-term. So to compute the Green’s
functions of the @xmath -field we can proceed as in the previous
section, not setting the source to zero now, but setting it to @xmath .
It should have become clear that when @xmath immediately one of the
minima is favored non-perturbatively. Then the Green’s functions become
what they are in the canonical approach.

This means that in this path-integral approach the @xmath -field acts
the same as in the canonical approach near other particles, however it
acts completely different far away from other particles. Far away from
other matter there is no SSB, and also the propagator is very different.
Near particles there is SSB, and the @xmath -field gives a mass to the
@xmath -particles. It is a very interesting, but difficult, question
what this exactly means for the physics involved in the @xmath -field
sector. Is this perhaps also a good mechanism to give masses to other
particles? In this thesis we shall not go into this question further.

## Chapter 5 The @xmath LSM: Fixing the Paths

In this chapter we will again discuss the Euclidean @xmath linear sigma
model from the path-integral viewpoint, however now we shall introduce
an extra constraint in the path integral. We will keep the paths fixed
at a certain time @xmath at some specific value @xmath over all of
space. In this way we hope to construct a path-integral model which has
the same physics (i.e. Green’s functions) as the canonical approach.

The idea of fixing the paths is very much like what Fukuda et al. [ 22 ]
, O’Raifeartaigh et al. [ 21 ] and Ringwald et al. [ 23 ] do in their
papers. However they fix some space-time average of the field to some
value, whereas we fix the field itself. The latter seems the more
natural thing to do, when trying to induce SSB. Also, in these articles
nothing has been said about the renormalizability of these models.

In the first section below we will show how to deal with a constraint in
the path integral in case of a free field theory. After that we will
proceed with the @xmath linear sigma model. We will show that this
model, together with the path fixing constraint, is renormalizable at
1-loop order. We will calculate the alternative effective potential at
lowest order and some Green’s functions, and find that indeed we recover
the physics as found also in the canonical approach.

### 5.1 The Free Theory with Fixed Paths

To get some feeling for what it means to have the paths in the path
integral fixed we consider a free field theory. The action of a
Euclidean free field theory, including source term, is:

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

Now, in the path integral, we are going to keep all paths fixed at
@xmath at time @xmath and over all of space:

  -- -------- -- -------
     @xmath      (5.2)
  -- -------- -- -------

By @xmath we mean the @xmath -vector containing all space coordinates.
The generating functional @xmath is given by:

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

To find the effective action and the Green’s functions we need to know
the @xmath -tadpole @xmath . To find this we can expand the action
around the classical solution. To compute the classical solution we must
find the minimum of the action, taking into account that we only accept
solutions satisfying the constraint ( 5.2 ). This constraint can be
built in by using a Lagrange multiplier field @xmath . Then the problem
reduces to minimizing

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

with respect to @xmath and @xmath . This means the classical solution
@xmath satisfies

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

and ( 5.2 ).

By passing to Fourier fields:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.6)
  -- -------- -------- -------- -- -------

equation ( 5.5 ) can easily be solved:

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

The Lagrange multiplier can be fixed with the constraint ( 5.2 )

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

Substituting this in the classical solution we found gives:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (5.9)
                                @xmath   
  -- -------- -------- -------- -------- -------

Now the new action ( 5.1 ) can be expanded around this classical
solution,

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

to obtain:

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

In this way the @xmath -tadpole @xmath can easily be calculated:

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

This simple relationship is of course caused by the fact that the path
integral just gives an overall constant, not depending on the source
@xmath . This is because we are working with a free theory here.

#### 5.1.1 The Green’s Functions

Now the @xmath -tadpole and propagator can be calculated. To obtain the
tadpole just set @xmath to zero in ( 5.12 ). To obtain the propagator
take a functional derivative with respect to @xmath and then put @xmath
to zero in ( 5.12 ). Taking more derivatives with respect to @xmath in (
5.12 ) gives zero, so higher connected Green’s functions are zero, as
expected in a free theory. We obtain the following results:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Indeed we have, as expected:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.14)
  -- -------- -------- -------- -- --------

#### 5.1.2 The Effective Action

To obtain the effective action we have to invert the relation ( 5.9 ).
This can be done by letting the operator @xmath work on both sides of (
5.9 ). One gets:

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

From this we see that @xmath has the form:

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

where @xmath is a some functional of the field @xmath . Now the @xmath
has to be fixed by inserting this @xmath in ( 5.15 ). However, when
doing this, one finds that @xmath drops out of the expression. Instead,
after some algebra, one gets a condition for @xmath :

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

This means we find the inverse @xmath to be ( 5.16 ), but this inverse
can only be found when the field @xmath satisfies the constraint ( 5.2
). This is expected, because the right hand side of ( 5.9 ) only gives a
result that obeys the constraint, if someone would come up with a @xmath
that does not satisfy ( 5.2 ), there would simply be no solution @xmath
that gives this @xmath .

Also @xmath remains undetermined, simply because adding a term like
@xmath to the source does not change the Green’s functions (i.e. the
physics) because the field is fixed at @xmath .

Finally, by integrating ( 5.16 ) with respect to the field @xmath , one
can find the effective action now. Clearly this effective action is not
unique. Here we find ourselves exactly in the loop-hole situation
described in the first section of chapter 2 . It can easily be seen that

  -- -------- -- --------
     @xmath      (5.18)
  -- -------- -- --------

is zero for the case

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

simply because of ( 5.14 ). This means @xmath is an eigenfunction of the
connected propagator with eigenvalue zero. So the connected propagator
has no unique inverse.

So clearly the effective action cannot be defined uniquely. We saw above
however that there are several functionals @xmath which are a solution
to ( 5.15 ). So in that sense several effective actions can be defined
in this case. However these are not necessarily convex, because the
argument for the convexity in chapter 2 assumes that there exists a
unique inverse. It is easy to construct an @xmath which gives a
non-convex effective action.

Also note that, if we choose one of the possible effective actions, it
is not possible to define an effective potential. Setting the field to a
constant, which is what one would normally do when finding the effective
potential from the effective action, is not possible in this case
because a constant field does not satisfy the constraint ( 5.2 ) in
general (except @xmath ). This would bring us outside the domain where
the effective action is defined.

What one can do, is define an alternative effective potential from (
5.16 ). If we consider ( 5.16 ) and the field @xmath for large @xmath ,
i.e. @xmath , then it is allowed to put the field @xmath to a constant.
If we then integrate ( 5.16 ) with respect to @xmath we have constructed
an alternative effective potential. In this free field theory this
alternative effective potential will be the same as the effective
potential of a free field theory without the path-fixing constraint.

#### 5.1.3 Conclusions

In the case of a model where we fix the paths in the path integral at
some value @xmath at some time @xmath over all of space we have the
following conclusions:

-   The effective action is defined on the domain of fields that satisfy
    the constraint, but this effective action is not unique and in
    general not convex.

-   The effective potential can not be defined in the ordinary way.

-   An alternative effective potential can be defined as the
    anti-derivative of @xmath for times @xmath .

This last definition of an effective potential we shall use whenever we
are dealing with a model with fixed paths.

### 5.2 The @xmath Linear Sigma Model

Now we proceed with the Euclidean @xmath linear sigma model. The action
of this model, including source term, is

  -- -------- -- --------
     @xmath      (5.20)
  -- -------- -- --------

Again we take all paths in the path integral fixed at @xmath at time
@xmath for all space-points @xmath :

  -- -------- -- --------
     @xmath      (5.21)
  -- -------- -- --------

We take the source @xmath in ( 5.20 ) to be a constant, first of all for
practical purposes, our calculations are simply too difficult when this
source is also space- and time-dependent. Secondly at the end of the day
we will only be interested in the alternative effective potential , for
which it is enough to consider only a constant source @xmath .

In terms of renormalized quantities the action ( 5.20 ) becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.22)
                                @xmath   
  -- -------- -------- -------- -------- --------

First of all the minimum, or in this case minima, of the classical
action (i.e. the first line of ( 5.22 )) have to be found. Because of
the boundary condition ( 5.21 ) this is far from trivial. Then the
action has to be expanded around one of these minima (later we will then
sum the contributions from all minima). The action will have three
parts: the classical action, the quantum fluctuations and the counter
terms. Because the classical solutions will be quite complicated, also
calculating the classical action will not be as easy as it sounds. Also
the path integral of the quantum fluctuations has to be calculated. In
our treatment we shall only take the saddle-point approximation around
each minimum, which means only Gaussian fluctuations are kept, all
interaction terms are discarded. Even in this approximation it is very
difficult to compute the path integral, as we shall see. We will only
look at the divergent parts, to see whether this theory is
renormalizable up to 1-loop. We will find that this is indeed the case.
Then, knowing that everything is finite we can calculate the alternative
effective potential at lowest order. Also we can compute the Green’s
functions and compare with the canonical approach.

To make all these remarks more concrete we work out mathematically what
we have to do. First we have to find the minima of the classical action,
i.e. the first line of ( 5.22 ), under the condition ( 5.21 ). To
implement this condition we add to the action a Lagrange multiplier term
and minimize this object with respect to the field @xmath and the
Lagrange multiplier @xmath . The action plus the Lagrange multiplier
term is given by:

  -- -------- -- --------
     @xmath      (5.23)
  -- -------- -- --------

Minimizing these two terms with respect to the field and the Lagrange
multiplier we find:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.24)
  -- -------- -------- -------- -- --------

Now the last term in the left hand side of the first equation forces the
classical solution @xmath to be time dependent, however there is nothing
that forces the solution to be dependent on the space-coordinates @xmath
. The true minima of the action will have no @xmath -dependence, since
this dependence will only increase the action. So we will limit
ourselves to find only classical solutions which only depend on time. In
this case the Lagrange multiplier necessarily has to be constant. So we
should solve:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.25)
  -- -------- -------- -------- -- --------

Solving this system will be the subject of the first section below.

When we found solutions to this system the action ( 5.22 ) can be
expanded around such a solution. Calling the classical solution @xmath
and the fluctuation around it @xmath we find:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Now we will make the saddle-point approximation, so we will only keep
terms up to order @xmath , i.e. order @xmath . Discarding all
interaction terms and recognizing that the first line in the expression
above is just the classical action @xmath we find:

  -- -------- -- --------
     @xmath      (5.27)
  -- -------- -- --------

With this action the generating functional around one minimum is given
by:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.28)
                                @xmath   
  -- -------- -------- -------- -------- --------

#### 5.2.1 The Classical Solutions

Now we solve the system ( 5.25 ). Of course we need more boundary
conditions than @xmath to solve this differential system. What we will
demand from our solutions is that, when @xmath , @xmath will converge to
one of the two static minima @xmath of the potential @xmath . This
means:

  -- -------- -- --------
     @xmath      (5.29)
  -- -------- -- --------

Of course we use these boundary conditions because we are looking for
solutions giving a finite, minimal action. Below these conditions will
appear to be sufficient to solve the differential system.

Before we start calculating note first that the differential system (
5.25 ) corresponds to a mechanical problem of a particle with unit mass
in a potential @xmath when @xmath . For @xmath the particle starts at
one of the static minima @xmath , then it travels such that it is at
@xmath at @xmath . Then the Lagrange multiplier term gives the particle
just such a kick that it reaches one of the static minima again for
@xmath . In this way we have a nice intuitive picture that helps us to
solve the differential system ( 5.25 ).

We divide our time domain in two intervals, region 1 where @xmath and
region 2 where @xmath . In these regions the delta-function term is
absent of course. First we consider region 1. From the first equation in
( 5.25 ) we find by multiplying by @xmath and integrating with respect
to time:

  -- -------- -- --------
     @xmath      (5.30)
  -- -------- -- --------

For @xmath @xmath should go to zero and @xmath should go to one of the
two static minima @xmath . We denote the minimum @xmath goes to for
@xmath by @xmath . With this we can immediately fix the constant of
integration @xmath :

  -- -------- -- --------
     @xmath      (5.31)
  -- -------- -- --------

So in region 1 we should find a solution to:

  -- -------- -- --------
     @xmath      (5.32)
  -- -------- -- --------

By dividing by the square root on both sides and integrating over time
again we find:

  -- -------- -- --------
     @xmath      (5.33)
  -- -------- -- --------

The constant @xmath can be fixed with the second equation in ( 5.25 ).
One finds:

  -- -------- -- --------
     @xmath      (5.34)
  -- -------- -- --------

And finally the solution in region 1 becomes:

  -- -------- -- --------
     @xmath      (5.35)
  -- -------- -- --------

Now one should worry a little about the roots of the argument of the
square root. In the corresponding mechanical problem this argument gives
(twice) the energy the particle has at time @xmath minus the potential
energy at position @xmath . This is just the kinetic energy of the
particle at position @xmath . Clearly the regions in @xmath where this
kinetic energy becomes negative are forbidden. Also the roots of the
argument can only be reached for @xmath , as can easily be seen in (
5.35 ). This means a solution @xmath always stays between two roots.

The solution ( 5.35 ) can be simplified by passing to a different
variable:

  -- -------- -- --------
     @xmath      (5.36)
  -- -------- -- --------

If we also define the new dimensionless quantities

  -- -------- -- --------
     @xmath      (5.37)
  -- -------- -- --------

then the integral equation ( 5.35 ) can be written as

  -- -------- -- --------
     @xmath      (5.38)
  -- -------- -- --------

The linear term in @xmath in the square root has dropped out because
@xmath satisfies @xmath .

Of course the same steps can be done in region 2, where @xmath . There
we obtain:

  -- -------- -- --------
     @xmath      (5.39)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.40)
  -- -------- -- --------

Now we can explicitly solve ( 5.38 ) and ( 5.39 ). We will demonstrate
the procedure for region 1, of course things go completely similar in
region 2. First remember that @xmath can never pass a root of the
argument in the square root. This means that for one solution, @xmath
always stays between two roots. For this reason we can write ( 5.38 ) as

  -- -------- -- --------
     @xmath      (5.41)
  -- -------- -- --------

Of course the @xmath in ( 5.41 ) can be a different @xmath than in (
5.38 ). Next we switch to a new variable @xmath :

  -- -------- -- --------
     @xmath      (5.42)
  -- -------- -- --------

Note that for @xmath , so @xmath , the argument of the square root
combines to @xmath and for @xmath the @xmath ’s in ( 5.42 ) cancel, such
that the variable substitution becomes nonsense. This just means that
later on we have to be a bit careful in setting @xmath . After this
variable substitution we do another one,

  -- -------- -- --------
     @xmath      (5.43)
  -- -------- -- --------

after which the integral in ( 5.41 ) becomes

  -- -------- -- --------
     @xmath      (5.44)
  -- -------- -- --------

Writing this expression in terms of the @xmath variables and
substituting the appropriate boundaries gives us

  -- -------- -- --------
     @xmath      (5.45)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.46)
  -- -------- -- --------

Now we know that for @xmath @xmath has to go to @xmath , so @xmath has
to go to zero. From ( 5.45 ) we see that @xmath has to go to @xmath in
this limit. So we have to choose the minus-sign in the exponential.

Finally solving ( 5.45 ) for @xmath gives

  -- -------- -- --------
     @xmath      (5.47)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.48)
  -- -------- -- --------

In region 2 we find likewise

  -- -------- -- --------
     @xmath      (5.49)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.50)
  -- -------- -- --------

Note that here we had to choose the plus sign in the exponential in
@xmath .

In figures 5.1 and 5.2 one can see the solution plotted for two nice
cases.

Notice that when @xmath and @xmath are not equal we obtain an
instanton-like solution, which takes the field from one static minimum
to another. For dimensions greater than one we know that instantons do
not contribute in the path integral (see Derrick [ 30 ] ). For this
reason we shall only consider classical solutions for which @xmath .
Then there are in general two solutions, both symmetric around @xmath .
However for some values of @xmath and @xmath it can happen that one of
these two solutions does not exist, which can easily be seen from the
corresponding mechanical problem.

#### 5.2.2 The Classical Action

The classical action can be written as:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Here we have used ( 5.30 ) in the last step.

Now for the solutions we are interested in, with @xmath , this
simplifies to:

  -- -------- -- --------
     @xmath      (5.52)
  -- -------- -- --------

The last term is the classical action of the @xmath linear sigma model
where one does not fix the paths. This term is

  -- -------- -- --------
     @xmath      (5.53)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.54)
  -- -------- -- --------

The first term is a little harder to calculate. Just inserting the
solution for @xmath ( 5.47 ) gives a very hard integral. However by
using a clever trick things become doable. Remember

  -- -------- -- --------
     @xmath      (5.55)
  -- -------- -- --------

for @xmath , where the plus sign has to be taken when @xmath and the
minus sign when @xmath . This means

  -- -------- -- --------
     @xmath      (5.56)
  -- -------- -- --------

With this variable substitution the integral can be written as:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.57)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

After some hard work this gives:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      (5.58)
  -- -------- -- --------

So finally we obtain for the classical action around the @xmath -minimum
(realizing that @xmath can be @xmath and @xmath can be @xmath ):

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

For @xmath the last two line vanish, as expected, because then the
classical solution just becomes a constant ( @xmath ).

#### 5.2.3 The Path Integral

Now we wish to calculate the path integral

  -- -------- -- --------
     @xmath      (5.60)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.61)
  -- -------- -- --------

Here @xmath can be any of the two classical solutions we found (starting
and ending at @xmath ).

To calculate this path integral we first perform a Fourier transform in
space. To do this neatly we take all coordinates in the domain @xmath .
Then @xmath can be written as

  -- -------- -- --------
     @xmath      (5.62)
  -- -------- -- --------

with the condition

  -- -------- -- --------
     @xmath      (5.63)
  -- -------- -- --------

to make @xmath real. From this condition one can see which variables are
independent. We shall choose the following set of independent variables:

  -- -------- -- --------
     @xmath      
     @xmath      (5.64)
  -- -------- -- --------

Now we can write:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (5.65)
  -- -------- -- --------

In the last step we defined @xmath as:

  -- -------- -- --------
     @xmath      (5.66)
  -- -------- -- --------

Finally the path integral @xmath becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.67)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Note that we have reduced the problem of calculating the @xmath
-dimensional path integral @xmath to the problem of calculating a
1-dimensional path integral.

Now focus on this 1-dimensional path integral, which we call @xmath :

  -- -------- -- --------
     @xmath      (5.68)
  -- -------- -- --------

where @xmath , in our case, is:

  -- -------- -- --------
     @xmath      (5.69)
  -- -------- -- --------

We will try to calculate this @xmath with the following formula for
Gaussian integrals:

  -- -------- -- --------
     @xmath      (5.70)
  -- -------- -- --------

where @xmath is an @xmath real symmetric matrix.

If we make the time interval @xmath discrete by defining

  -- -------- -- --------
     @xmath      (5.71)
  -- -------- -- --------

and if we define the discrete index @xmath as the index belonging to the
time @xmath :

  -- -------- -- --------
     @xmath      (5.72)
  -- -------- -- --------

then @xmath can be written as:

  -- -------- -- --------
     @xmath      (5.73)
  -- -------- -- --------

where @xmath is a vector of length @xmath :

  -- -------- -- --------
     @xmath      (5.74)
  -- -------- -- --------

and @xmath is the @xmath matrix:

  -- -------- -- --------
     @xmath      (5.75)
  -- -------- -- --------

Note that the @xmath in the lower left and upper right corner mean that
we have periodic boundary conditions in our path integral.

Now using ( 5.70 ) we find for @xmath :

  -- -------- -- --------
     @xmath      (5.76)
  -- -------- -- --------

Now it is easy to see that:

  -- -------- -- --------
     @xmath      (5.77)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.78)
  -- -------- -- --------

So now we are interested in @xmath in the limit of @xmath . This
quantity can be found as follows. For @xmath one can easily derive the
recursion relation:

  -- -------- -- --------
     @xmath      (5.79)
  -- -------- -- --------

where @xmath is a @xmath matrix with always @xmath in the upper left
corner, and:

  -- -------- -- --------
     @xmath      (5.80)
  -- -------- -- --------

Now define

  -- -------- -- --------
     @xmath      (5.81)
  -- -------- -- --------

Then, in the continuum limit the recursion relation ( 5.79 ) becomes a
differential equation:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.82)
  -- -------- -------- -------- -- --------

with boundary conditions

  -- -------- -- --------
     @xmath      (5.83)
  -- -------- -- --------

The 1-dimensional path integral @xmath is now (in the continuum) given
by:

  -- -------- -- --------
     @xmath      (5.84)
  -- -------- -- --------

In essence we have now proven the theorem (7.40) in Das’ book [ 29 ] .
There he states that the determinant of an operator @xmath , with
boundary conditions @xmath , is proportional to @xmath , where @xmath is
a solution to the differential equation

  -- -------- -- --------
     @xmath      (5.85)
  -- -------- -- --------

with boundary conditions @xmath . In our case the time is just shifted
because we do not have @xmath , but @xmath .

Now the big question is: How do we find a solution to the differential
system ( 5.82 ) & ( 5.83 )?

##### Trying to Solve (5.82)

So the differential equation we wish to solve has the form

  -- -------- -- --------
     @xmath      (5.86)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (5.87)
  -- -------- -- --------

Our differential equation can be transformed to a Riccati equation by
the transformation:

  -- -------- -- --------
     @xmath      (5.88)
  -- -------- -- --------

Then we get:

  -- -------- -- --------
     @xmath      (5.89)
  -- -------- -- --------

It is known that these Riccati type differential equations are very hard
to solve, so there is little hope to solve our differential system.

One last thing that can be done here is write @xmath in a more
convenient way, it appears this @xmath can also be written as:

  -- -------- -- --------
     @xmath      (5.90)
  -- -------- -- --------

for @xmath , where @xmath is the solution in region 1, as defined in (
5.36 ). For @xmath this @xmath should of course be replaced by the
@xmath from ( 5.40 ).

However, even with this simplification it is very hard to solve our
differential equation. If we would only have had the first @xmath terms
in ( 5.90 ), which are just a constant, the equation can easily be
solved. Also, if we would only have the last term in ( 5.90 ), then the
equation can also be solved for general @xmath , because of the specific
form of a triple derivative divided by a first derivative. However, when
we have both terms, as in our case, it is very hard to solve the
differential equation.

#### 5.2.4 The Divergences

As shown in the previous section it is very hard to compute our path
integral ( 5.60 ) exactly. One important thing we can do however, is
find the divergences hidden in this path integral and see whether they
can be cancelled by the counter terms, such that (the physical part of)
the generating functional ( 5.28 ) becomes finite. If we can indeed
cancel all divergences with the counter terms, then we know at least
that the corrections from the path integral to all physical quantities
are higher order, i.e. small. Therefore the classical approximation to
these physical quantities is already a good approximation.

So let’s see whether the divergences cancel. To this end we will compare
the infinite parts of

  -- -------- -- --------
     @xmath      (5.91)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (5.92)
  -- -------- -- --------

Here we have taken a derivative with respect to the source @xmath ,
since only the @xmath -dependent part of the generating functional is
important for physical quantities, so only in this part it is necessary
that all divergences cancel.

First consider the infinite part of the counter terms ( 5.91 ). We use
the counter terms that we found in the canonical approach ( 3.18 ). One
does not expect the counter terms to change just because one fixes the
paths. If we use these counter terms the infinite part of ( 5.91 )
becomes:

  -- -------- -- --------
     @xmath      
     @xmath      (5.93)
  -- -------- -- --------

Notice that it is far from obvious that divergences in here are going to
cancel against divergences from the path integral because of the time
dependent factors multiplying the divergences, i.e. the structure of the
divergent terms is very different here than in models without
path-fixing.

Now consider ( 5.92 ). Using what we found in the previous section this
( 5.92 ) can be written as:

  -- -- -- -------- -------- --------
           @xmath            (5.94)
           @xmath   @xmath   
           @xmath   @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- --------

Now, to find the divergent parts in this expression we can write down
the first few terms of the Taylor expansion of

  -- -------- -- --------
     @xmath      (5.95)
  -- -------- -- --------

around @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (5.96)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

So, to find these first two terms of the expansion we have to know:

  -- -------- -- --------
     @xmath      (5.97)
  -- -------- -- --------

These can all be found from the differential equation ( 5.82 ).

@xmath Can of course be found from ( 5.82 ) by just setting @xmath
everywhere in the differential equation. If we define the constant
@xmath as:

  -- -------- -- --------
     @xmath      (5.98)
  -- -------- -- --------

then the differential equation is

  -- -------- -- --------
     @xmath      (5.99)
  -- -------- -- --------

and the solution that satisfies the boundary conditions ( 5.83 ) can
easily be found to be

  -- -------- -- ---------
     @xmath      (5.100)
  -- -------- -- ---------

Now @xmath Can be found by first taking a functional derivative with
respect to @xmath in the differential equation ( 5.82 ) and then setting
@xmath everywhere. We find the differential equation:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

with boundary conditions:

  -- -------- -- ---------
     @xmath      (5.102)
  -- -------- -- ---------

This differential system can also be solved easily, we have to
distinguish the cases @xmath and @xmath however. In the case @xmath we
find:

  -- -------- --
     @xmath   
              
  -- -------- --

In the case @xmath we find:

  -- -------- --
     @xmath   
              
  -- -------- --

At @xmath we can write the solution for all cases as:

  -- -------- -- ---------
     @xmath      (5.105)
  -- -------- -- ---------

Finally @xmath can be found from the differential equation ( 5.82 ) by
taking two functional derivatives, with respect to @xmath and @xmath ,
and then putting @xmath everywhere. The differential equation one gets
then is:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Also this differential equation can be solved, now we have to
distinguish 6 different cases however. After a lot of algebra one finds
for the solution at @xmath :

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (5.107)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

where @xmath , @xmath and @xmath give respectively the smallest, middle
and largest variable in the set @xmath .

Now all the expressions we found should be inserted in the Taylor
expansion ( 5.96 ). Also remember that we are only interested in the
divergent part of ( 5.94 ). Divergences in ( 5.94 ) are of course caused
by the sum over the @xmath @xmath ’s, when the summand does not drop to
zero fast enough for large @xmath ’s. So, to find only the divergent
terms in ( 5.94 ), we should only keep the terms that do not go to zero
very fast in the Taylor expansion ( 5.96 ).

Now the first term in ( 5.96 ) is:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (5.108)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

The second term will not give a divergence under the sum, since large
@xmath ’s are exponentially damped. (For @xmath this exponential is of
course not there, however for @xmath the whole expressions ( 5.93 ) and
( 5.94 ) become zero because @xmath .) The first term will give a
divergence, and we shall only keep this term. When we insert this term
in ( 5.94 ) we get:

  -- -- -- -------- -------- ---------
           @xmath            (5.109)
           @xmath   @xmath   
           @xmath   @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- ---------

This cancels exactly the first term in the counter term part ( 5.93 ) of
the generating functional!

Now consider the second order term in the Taylor expansion ( 5.96 ).

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

After some hard work this can be written to:

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (5.111)
  -- -------- -- ---------

Now, all the terms, when worked out for large @xmath , will still
contain exponentials which dampen the large @xmath values in the sum.
The square of the first term between the straight brackets will also
contain such an exponential, however the argument of this exponential (
@xmath ) can become zero without @xmath or @xmath becoming @xmath . So
in the case of @xmath this first term will give a divergence. The other
terms in the expression above (when the square is worked out) will
always contain an exponential with arguments proportional to @xmath or
@xmath , such that these will only give divergences at @xmath or @xmath
, where the whole expression ( 5.94 ) becomes zero.

So let’s only keep the first term between the straight brackets and work
out what we get for large @xmath .

  -- -------- -- ---------
     @xmath      (5.112)
  -- -------- -- ---------

Substituting this in the Taylor expansion ( 5.96 ) and then in ( 5.94 )
we find:

  -- -------- -- ---------
     @xmath      (5.113)
  -- -------- -- ---------

As argued above, a divergence can only arise when @xmath , so when we
are only interested in this part we can safely set @xmath . Then we can
do the @xmath integral and we find:

  -- -- -- -------- -------- ---------
           @xmath            (5.114)
           @xmath   @xmath   
           @xmath   @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- ---------

And this cancels exactly the second and third term in the counter term
part ( 5.93 )!

So finally we have proven that the physical part of the 1-loop
generating functional can be made finite with the same counter terms as
in the canonical approach to the @xmath linear sigma model. Of course
also all 1-loop Green’s functions are finite then.

Notice that the cancellation of the divergences does not depend on the
specific form of @xmath . We have proven here that the divergences
cancel in all physical quantities independent of what the classical
solution looks like explicitly.

#### 5.2.5 The Alternative Effective Potential

Because we know now that the physical part of the generating functional
is finite a good approximation to this @xmath is the classical
approximation:

  -- -------- -- ---------
     @xmath      (5.115)
  -- -------- -- ---------

Actually this is the only approximation we can do to find @xmath , since
the 1-loop, or saddle-point, approximation would already involve the
difficult path integral ( 5.60 ). Defining @xmath and @xmath as

  -- -------- -- ---------
     @xmath      (5.116)
  -- -------- -- ---------

we have

  -- -------- -- ---------
     @xmath      (5.117)
  -- -------- -- ---------

Then we also have:

  -- -------- -- ---------
     @xmath      (5.118)
  -- -------- -- ---------

To find the alternative effective potential we have to know @xmath as a
functional of @xmath for large @xmath , i.e. @xmath . So we first have
to know @xmath as a function of @xmath for large @xmath . For large
@xmath this tadpole goes to a constant, which can be read off from the
formula above:

  -- -------- -- ---------
     @xmath      (5.119)
  -- -------- -- ---------

So indeed we see, to obtain the tadpole for large times it was only
necessary to do our calculations for constant source @xmath . From this
formula one can now find the inverse and construct the alternative
effective potential. In figure 5.3 the derivative of this alternative
effective potential is plotted for @xmath and @xmath , for the case
@xmath , @xmath , @xmath , @xmath , @xmath and @xmath . For comparison
we have also plotted the derivative of the effective potential from the
canonical approach. In figure 5.4 the derivative of the alternative
effective potential is plotted for @xmath and @xmath , for the case
@xmath , @xmath , @xmath , @xmath , @xmath and @xmath , also together
with the canonical result.

One can see that these alternative effective potentials come out to be
convex , which is not obvious beforehand. Also they converge to the
effective potentials from the path-integral approach without fixing in
the limit @xmath .

#### 5.2.6 The Green’s Functions

Now we compute the Green’s functions in this approach. Again, as in the
previous chapter, we have:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where

  -- -------- -- ---------
     @xmath      (5.121)
  -- -------- -- ---------

where @xmath is the action in ( LABEL:complaction ) and @xmath is the
classical solution @xmath around the @xmath -minumum.

Now we do not have @xmath , as in the previous chapter. Looking only at
the classical actions around each minimum we have (substituting @xmath
in LABEL:classactionfixed ):

  -- -------- -- ---------
     @xmath      (5.122)
  -- -------- -- ---------

The first term is the same for both minima, and thus unimportant. The
second term is not the same for both minima, and thus this term
determines which of the minima is non-perturbatively favored in the
infinite-volume limit. It is easy to see that:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.123)
  -- -------- -------- -------- -- ---------

So for @xmath the negative minimum is non-perturbatively suppressed,
whereas for @xmath the positive minimum is suppressed. So the minimum
closest to @xmath , i.e. the point where the paths are fixed, survives
in the infinite-volume limit, the other minimum is suppressed
non-perturbatively. We do not even have to know the quantum part of
@xmath to say this, since this quantum part is small with respect to the
classical part one can already see from the classical part which minimum
wins.

Now we choose @xmath . Then the tadpole becomes:

  -- -------- -- ---------
     @xmath      (5.124)
  -- -------- -- ---------

Notice that this is an exact expression for @xmath .

Now we will assume that for large @xmath , i.e. @xmath , the tadpole
@xmath does not notice the path-fixing and the time-dependent mass and
coupling constants anymore. Remember that, in the free field theory
considered at the beginning of this chapter, the tadpole and propagator
did indeed not notice the path-fixing anymore for large times. See (
LABEL:freefixedGreensfuncts ). This makes the current assumption
plausible.

Under this assumption we find for large @xmath :

  -- -------- -- ---------
     @xmath      (5.125)
  -- -------- -- ---------

where @xmath is defined as in ( 5.121 ), but without the path-fixing
constraint and with @xmath . This is the canonical result.

Now consider the @xmath -propagator. This propagator can be written as:

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

with

  -- -------- -- ---------
     @xmath      (5.127)
  -- -------- -- ---------

Again the minimum closest to the fixing point @xmath dominates
completely for @xmath . Since we took @xmath this propagator becomes:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (5.128)
  -- -------- -------- -------- -- ---------

Also this is an exact expression in the limit @xmath .

For large times @xmath , @xmath , again assuming that the @xmath
-propagator does not notice the path-fixing and the explicit time
dependence in the action, the connected propagator becomes:

  -- -------- -- ---------
     @xmath      (5.129)
  -- -------- -- ---------

where @xmath is defined as in ( 5.127 ) without the path fixing
constraint. This is the canonical propagator.

In this way all Green’s functions can be shown to be equal to the
canonical Green’s functions for times @xmath .

So, finally we have shown that in the path-integral approach with fixed
paths we get the same Green’s functions as in the canonical approach,
including SSB. Now we get a convex alternative effective potential
however.

## Chapter 6 The @xmath LSM: The Canonical Approach

In this chapter we will calculate the same things as in chapter 3 , now
for the @xmath linear sigma model. This Euclidean linear sigma model
with @xmath fields is defined by the bare action

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

We will outline the canonical treatment of this model for the case
@xmath , i.e. for the case with spontaneous symmetry breaking. Our
calculations will be much like those found in most textbooks, like
e.g. Peskin and Schroeder [ 8 ] .

### 6.1 Green’s Functions

To compute the renormalized Green’s functions of this theory we
introduce renormalized quantities as in ( 3.4 ). The action in terms of
these renormalized quantities is (again we suppress the @xmath
superscripts from now on):

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (6.2)
                                @xmath   
  -- -------- -------- -------- -------- -------

Now the classical action, i.e. the first line has its minima on the
circle

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

We choose

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

as the true minimum in this canonical approach. Then define

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

In terms of these @xmath fields the action becomes:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (6.6)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

Define again @xmath . Then the The Feynman rules are:

  -- -- -------- -------- -- -------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (6.7)
  -- -- -------- -------- -- -------

Now let’s calculate the momentum space Green’s functions of this theory,
up to one loop. Again we shall write the results in terms of the
standard integrals ( 3.10 ).

Notice that standard integrals like @xmath are zero in the dimensional
regularization scheme. We shall not specify the regularization scheme in
our calculations however, and keep everything general.

  -- -------- -------- -------- -------- -------
     @xmath   @xmath                     (6.8)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

  -- -------- -- -------
     @xmath      (6.9)
  -- -------- -- -------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.10)
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.11)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.13)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.15)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.17)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.19)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -- --------
     @xmath      (6.20)
  -- -------- -- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (6.21)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now, as in the case of the @xmath linear sigma model our theory contains
three free parameters, @xmath , @xmath and @xmath , which have to be
fixed by three renormalization conditions. We could try to use the same
renormalization conditions as in chapter 3 ( 3.15 ) (with the @xmath
-lines replaced by @xmath -lines):

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (6.22)
  -- -- -------- -------- -- --------

This is not a good idea however, because some of our amplitudes are
singular at zero incoming momentum. These singularities are of course
caused by loops with the Goldstone boson. If we would set the 4-point
1PI amplitude to @xmath at zero external momenta we would be absorbing
infrared divergences, which only occur for very specific external
momenta, in the counter terms. The most straightforward thing to do now
is change the renormalization point. However, this will complicate the
calculations greatly.

What we shall do is just remove these infrared divergences from our
counter term @xmath by hand.

This is somewhat similar to what is done in Peskin and Schroeder [ 8 ] ,
there they work in the dimensional regularization scheme, in which the
infrared divergences are invisible anyway. (Their renormalization point
is at @xmath however, but also at this point there occur IR
divergences.)

If we strictly use the conditions ( 6.22 ) the counter terms become, up
to order @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (6.23)
  -- -------- -------- -------- -- --------

Now we see that the second, fourth and sixth term in @xmath contain
infrared divergences, which we should not include. ( @xmath Is not IR
divergent for dimensions greater than 2.) The easiest thing to do is
introduce a mass in these terms, such that the infrared divergences are
regularized. We shall just use @xmath for this mass, to keep the
calculation as simple as possible. After this manual procedure the
counter terms are:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (6.24)
  -- -------- -------- -------- -- --------

The physical masses of the @xmath - and @xmath -particle, @xmath and
@xmath , can now be calculated from the Dyson summed propagators. The
Dyson summed @xmath propagator is

  -- -------- -- --------
     @xmath      (6.25)
  -- -------- -- --------

with

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.26)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

The location of the pole of ( 6.25 ) gives @xmath . Up to order @xmath
we can easily find this pole:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.27)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

For @xmath this @xmath is finite, for @xmath it is not, which shows that
the linear sigma model is non-renormalizable for @xmath .

Likewise we can obtain the physical mass of the @xmath particle @xmath .
The Dyson summed @xmath propagator is:

  -- -------- -- --------
     @xmath      (6.28)
  -- -------- -- --------

with

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.29)
                                @xmath   
  -- -------- -------- -------- -------- --------

Again the pole of ( 6.28 ) is easily found up to order @xmath :

  -- -------- -- --------
     @xmath      (6.30)
  -- -------- -- --------

This is an illustration of the Goldstone theorem, which states that in
the case of spontaneous symmetry breaking the mass of the Goldstone
boson remains zero at all orders.

Actually things are a bit trickier than they look here. The above result
for @xmath seems to hold for all dimensions below 5, where the theory is
renormalizable. This would mean that also for @xmath , where we know
that no spontaneous symmetry breaking can occur, @xmath would remain
zero up to order @xmath . This is not true in general. In general ( 6.30
) is wrong for @xmath because we put the momentum @xmath , flowing
through the propagator, to zero before we have done the loop integral.
Actually we have to compute the integral and only then put @xmath to
zero. The two operations do not commute. In case of the @xmath linear
sigma model it happens to be that ( 6.30 ) is correct after all, the
problem with setting @xmath to zero before doing the loop integrals only
shows up in 2-loop integrals. One can explicitly verify that at 2-loop
order @xmath is no longer zero for @xmath . For @xmath ( 6.30 ) is
always correct however, which is in complete agreement with the
Goldstone theorem. (Remember that @xmath is a special case, see Coleman
[ 31 ] and Coleman et al. [ 32 ] .

### 6.2 The Effective Potential

Now we want to calculate the effective potential. We will again use the
vacuum-graph formula ( 2.29 ), as we did in the @xmath linear sigma
model. However our calculation will be much more involved now because we
now have two types of lines, which complicates how we connect the lines
inside the loop.

To deal with this complication we consider the same vertex, of which a
different set of legs is going to be part of the loop, as different . In
this way each 1-loop diagram is characterized by 8 numbers, each
denoting the number of a certain type of vertices in the diagram. These
numbers are defined as follows:

  -- -- -- --------
           (6.31)
  -- -- -- --------

Here it is understood that the legs pointing to the right are going to
be part of the loop. Before we can write down the expression for the
1-loop effective potential, i.e. the sum of all 1-loop 1PI diagrams
weighed with the appropriate factors, we have to know in how many ways
we can connect the internal legs. If we denote the number of vertices
that give two solid lines to go into the loop as @xmath , the number of
vertices that give two dashed lines as @xmath and the number of vertices
that give one solid and one dashed line as @xmath , then the number of
ways to connect these vertices to give a loop is:

  -- -------- -- --------
     @xmath      (6.32)
  -- -------- -- --------

In our case we have of course @xmath . The 1-loop effective potential
@xmath is now given by:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.33)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

After a long calculation this can be written to:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

This result is identical to what Peskin and Schroeder [ 8 ] find in
their formula (11.74), of course taking into account differences in
definitions of coupling constants and counter terms.

#### 6.2.1 Zero Dimensions

There is a much quicker, though less straightforward, way to obtain the
1-loop effective potential ( LABEL:effpotN2 ). In zero dimensions it is
very easy to find the 1-loop effective action through the
Schwinger-Dyson equations. Of course in zero dimensions this effective
action is equal to the effective potential. The diagrammatic structure
of this 1-loop effective potential in zero dimensions is exactly the
same as in @xmath dimensions, only the mathematical expressions
corresponding to the diagrams is different. For the 1-loop case however
the difference in mathematical expression is not so big: the propagators
in the loop, which are @xmath in zero dimensions just become @xmath in
@xmath dimensions. So if we are able to find the zero-dimensional 1-loop
effective potential we can do this replacement to obtain the @xmath
-dimensional effective potential.

So we first have to calculate the zero-dimensional 1-loop effective
potential through the Schwinger-Dyson equations. We write the
zero-dimensional action of our @xmath linear sigma model generically as:

  -- -------- -- --------
     @xmath      (6.35)
  -- -------- -- --------

Notice that we have included a mass @xmath for the @xmath -particle now,
to be able to do the replacement @xmath later. (Also for @xmath the
propagator would not even exist in zero dimensions.)

In diagrammatic form the Schwinger-Dyson equations read:

  -- -- -------- -------- -------- --------
        @xmath                     
                 @xmath            
        @xmath                     (6.36)
                          @xmath   
  -- -- -------- -------- -------- --------

Here the little crosses indicate the vertices from the sources,
respectively @xmath and @xmath . If we denote the tadpoles by @xmath and
@xmath :

  -- -- -- --------
           (6.37)
  -- -- -- --------

and their derivatives by

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (6.38)
  -- -------- -------- -------- -- --------

then the Schwinger-Dyson equations read

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            
                       @xmath            
     @xmath   @xmath   @xmath            (6.39)
                                @xmath   
  -- -------- -------- -------- -------- --------

Now the definition of the effective action is

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (6.40)
  -- -------- -------- -------- -- --------

from which one can derive

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (6.41)
  -- -------- -------- -------- -- --------

Through these relations we can write the Schwinger-Dyson equations in
terms of (partial derivatives of) the effective action and the tadpole.
Then it appears one can solve these partial differential equations
iteratively up to some order to express the effective action in terms of
the tadpole. Assuming that the effective action starts with a term of
order @xmath , which is characteristic of the canonical approach, and
writing

  -- -------- -- --------
     @xmath      (6.42)
  -- -------- -- --------

we find:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (6.43)
  -- -------- -------- -------- -- --------

Here the constant @xmath is just a constant of integration, which is
unimportant for the physics. It is convenient to fix it however by
demanding that for a free theory @xmath , which gives @xmath .

Now to obtain the 1-loop effective potential in @xmath dimensions
(excluding counter terms) we have to make the replacements

  -- -------- -- --------
     @xmath      (6.44)
  -- -------- -- --------

in @xmath and add the integration @xmath .

If we do this, specify all the masses and coupling constants @xmath ,
@xmath and @xmath to the masses and coupling constants we have in the
@xmath linear sigma model, and write the @xmath - and @xmath -field in
terms of the @xmath - and @xmath -field again we find exactly (
LABEL:effpotN2 ), of course excluding the counter terms.

Also notice that ( 6.43 ) shows in general (for a 2-field theory) that
the effective potential becomes complex when the classical potential
@xmath becomes non-convex. Inside the logarithm in @xmath in ( 6.43 ) is
the Hessian of the function @xmath , which is negative where the
function @xmath is non-convex.

#### 6.2.2 Calculating The Effective Potential

To proceed calculating ( LABEL:effpotN2 ) we have to expand the
logarithms again to let any divergent parts cancel the divergences in
the counter terms. Of course when we expand the logarithm with the
@xmath a lot of infrared divergences are going to appear. These
divergences should later sum up to something finite again, but for the
moment we have to regularize them, which we do by introducing a mass
@xmath for the @xmath -particle. The 1-loop effective potential becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.45)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

In the first term the ultraviolet divergences cancel, we can write this
term as:

  -- -------- -- --------
     @xmath      
     @xmath      (6.46)
  -- -------- -- --------

Now using that for @xmath and @xmath we have

  -- -------- -- --------
     @xmath      (6.47)
  -- -------- -- --------

and for @xmath and @xmath we have

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

we find for the 1-loop effective potential

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.49)
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

We see that for @xmath all ultraviolet divergences cancel, which shows
again that the theory is renormalizable for @xmath .

To find a more explicit expression for @xmath we have to specify the
dimension @xmath .

#### 6.2.3 @xmath And @xmath

If one substitutes @xmath in ( 6.49 ), performs the sums and works
everything out one finds that the divergences for @xmath do not cancel.
The same happens for @xmath . This is generally known, in one and two
dimensions there is no SSB, which is manifested by the remaining
infrared divergences. See for example Coleman [ 31 ] and Coleman, Jackiw
and Politzer [ 32 ] .

#### 6.2.4 @xmath

In @xmath the infrared divergences do cancel and one finds:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (6.50)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

This result does not correspond to (11.79) in Peskin and Schroeder [ 8 ]
, simply because we use different renormalization conditions.

In figure 6.1 the complete effective potential (up to one loop) and the
classical potential are plotted for the case @xmath , @xmath , @xmath .

The minimum of the effective potential is at @xmath , as our tadpole
renormalization condition in ( 6.22 ) ensures. Also exactly at this
point the effective potential becomes complex because of the first
logarithm in ( 6.50 ). This shows again that the effective potential in
the canonical approach becomes complex where the classical potential
becomes non-convex. Because the effective potential becomes complex
exactly at the location of the minima we cannot compute the @xmath
-points Green’s functions from it. This is related to the fact that all
these @xmath -points Green’s functions suffer from infrared divergences
at zero incoming momentum.

Note that the effective potential we have computed here is convex where
it is defined. This is not always the case. We could easily have chosen
other renormalization conditions such that the minima of the effective
potential occur for @xmath (by for example adding a constant term to
@xmath ). Then there is a non-convex region between these minima and the
circle @xmath , where the effective potential becomes complex again. In
fact in Peskin and Schroeder [ 8 ] such an effective potential is found
in (11.79). They use the @xmath renormalization scheme. Their remark
that fortunately the minima of the effective potential occur outside the
region where it becomes complex is somewhat inappropriate, since we have
shown here that this is not always the case.

So also for the @xmath linear sigma model there is an apparent convexity
problem. Again, as has been thoroughly discussed in the @xmath -case
this problem is resolved by realizing that the canonical and
path-integral approach are not the same in the case of a non-convex
classical action.

## Chapter 7 The @xmath LSM: The Path-Integral Approach I

In this chapter we will discuss the path-integral approach to the
Euclidean @xmath linear sigma model. This means we want to calculate the
path integral of this model in some approximation. For the @xmath linear
sigma model we calculated the path integral (in chapter 4 ) with a
saddle-point approximation. This means we expand the generating
functional around each minimum and add all these generating functionals
to obtain the complete generating functional. In the @xmath -case this
is a good approximation because the minima lie far away from each other.
In the @xmath -case we can also use such a saddle-point approximation,
however now the minima form a continuous set and do not lie far apart.
So it is questionable whether expanding around each minimum and then
summing, or rather integrating, the contributions from each minimum
gives a reasonable approximation to the path integral.

Another questionable point is the perturbative expansion around each
minimum. When making this expansion one has replaced the, in principle
damped, @xmath -direction (i.e. tangential direction) by a non-damped
straight line. There is an @xmath -term that damps oscillations in the
@xmath -direction in principle, however in perturbation theory the
exponential of this term is expanded, and not all terms are kept. In
this way we loose the damping effect in the tangential direction, which
is actually there.

In this chapter we shall just use this naive saddle-point approximation,
even though the arguments above advise strongly against it. There is
also an argument in favor of this naive approach. We know that expanding
around one minimum (i.e. the canonical approach) gives a self-consistent
theory and the Green’s functions calculated in this way satisfy the
Schwinger-Dyson equations. Also the generating functional calculated by
including only one minimum satisfies the Schwinger-Symanzik equations.
Because the Schwinger-Dyson and Schwinger-Symanzik equations are linear
(in the full Green’s functions or generating functional) also the sum of
several full Green’s functions or generating functionals around
different minima are solutions to these equations. So we know at least
that the full Green’s functions and generating functional obtained by
summing or integrating over all minima are solutions to the
Schwinger-Dyson and Schwinger-Symanzik equations.

### 7.1 Green’s Functions

The renormalized action of the @xmath -dimensional @xmath linear sigma
model is:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (7.1)
                                @xmath   
  -- -------- -------- -------- -------- -------

The minima of the first line are given by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.2)
  -- -------- -------- -------- -- -------

with @xmath again. Now we expand the action around one of these minima:

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

When writing the action in terms of these @xmath -fields the Gaussian
part becomes non-diagonal in @xmath and @xmath . To make this part
diagonal again we introduce the @xmath -fields:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.4)
  -- -------- -------- -------- -- -------

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.5)
  -- -------- -------- -------- -- -------

In terms of these @xmath -fields the action reads (again defining @xmath
):

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (7.6)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

Notice that this action does not depend on @xmath anymore, as is
expected from the @xmath -invariance of this model. Also notice that the
action for the @xmath -fields is exactly the same as the action for the
@xmath -fields in the canonical approach ( 6.6 ). This means the @xmath
-Green’s functions are also identical to the @xmath -Green’s functions
in the canonical approach, and for these Green’s functions we can use
the results from the previous chapter.

Now we wish to obtain the @xmath -Green’s functions. As stated in the
introduction we are going to calculate these by just integrating over
the contributions from all minima, i.e. integrate over @xmath . One
should keep in mind here that the @xmath -Green’s functions do not
depend on @xmath anymore.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.8)
  -- -------- -------- -------- -- -------

In this last line we also used @xmath .

With the results of the previous chapter it is now easy to obtain the
@xmath - and @xmath -propagator up to 1-loop order. If we use the same
counter terms as in the canonical approach we have, up to 1-loop order
(using the tadpole renormalization condition ( 3.15 ) and the Dyson
summed propagators ( 6.25 ) and ( 6.28 )):

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.9)
  -- -------- -------- -------- -- -------

with @xmath and @xmath given in ( 6.26 ) and ( 6.29 ). Finally we find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.10)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

With the formulas ( 7.8 ) it is also easy to calculate the @xmath - and
@xmath -propagator up to order @xmath . All we need more is @xmath at
order @xmath . This quantity can easily be calculated with the Feynam
rules from chapter 6 . In this case we shall not specify the counter
terms, but keep them general. This will later be convenient when
comparing the upcoming result for the @xmath - and @xmath -propagator to
the result obtained from a calculation via the path integral in terms of
polar field variables. @xmath At order @xmath is now:

  -- -------- -------- -------- --
     @xmath   @xmath            
                       @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Here we have defined the following new two-loop standard integrals:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.12)
  -- -------- -------- -------- -- --------

Substituting this and the already obtained @xmath - and @xmath
-propagator in ( 7.8 ) gives:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.13)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Here we have defined another four standard integrals:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.14)
  -- -------- -------- -------- -- --------

### 7.2 The Effective Potential

Now we will try to find the effective potential of the @xmath linear
sigma model. To this end we introduce source terms in the action again.
Because we are only interested in the effective potential we shall take
the sources to be constant over space time. Including these source terms
the action is:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.15)
                                @xmath   
  -- -------- -------- -------- -------- --------

Now we have to find the minima of the first line again. Only for the
case @xmath we have a ring of minima, as found in the previous section.
For one of the sources non-zero however there is only one minimum (and
one saddle point). This means that when both sources are of order @xmath
taking into account one minimum is a good approximation. Below we shall
show that taking into account one minimum is equivalent to the canonical
approach, outlined in the previous chapter. However, when the sources
become of order @xmath the minimum becomes so unstable that quantum
fluctuations along the ring become important. Clearly in this regime it
is a bad approximation to take into account only this single minimum,
although it is the only true minimum (for @xmath ). In this regime we
have to take notice of all the points in the ring. What all the points
in the ring have in common is that they are minima in @xmath . So to
find these points, also for non-zero sources, we have to minimize the
classical action with respect to @xmath . Writing the classical field
as:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.16)
  -- -------- -------- -------- -- --------

we find the equation

  -- -------- -- --------
     @xmath      (7.17)
  -- -------- -- --------

Writing

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.18)
  -- -------- -------- -------- -- --------

and parameterizing @xmath as

  -- -------- -- --------
     @xmath      (7.19)
  -- -------- -- --------

we find the solution

  -- -------- -- --------
     @xmath      (7.20)
  -- -------- -- --------

So for each angle @xmath we have a point on the ring given by ( 7.20 ).

Again we should expand the action around the classical points ( 7.16 ).
To make the action diagonal we have to introduce the @xmath -fields
again:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.21)
  -- -------- -------- -------- -- --------

The action becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.22)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now we shall take the magnitude of the source @xmath to be of order
@xmath . To proceed further with the calculation one has to make an
approximation. The most straightforward option is to treat all terms of
order higher than @xmath in the action as a perturbation. This means we
should also expand @xmath in @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.23)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Then one can read off the Feynman rules from the action and calculate
the generating functional and the @xmath - and @xmath -tadpole with
Feynman diagrams. This is all straightforward, but at the end one finds
an infrared-divergent expression. One might have expected this from the
results of the previous chapter. There we saw that, in @xmath and @xmath
, the infrared divergences only sum up to something finite if we include
all 1-loop graphs. Because we take @xmath of order @xmath here it means
effectively that we cannot calculate any @xmath -points Green’s
functions from our generating functional. For this one would need to
know the exact @xmath -dependence. This in turn means we are not
including all 1-loop graphs and we cannot expect the infrared
divergences to disappear.

Another thing one can do, which is less straightforward, but gives
results without remaining infrared divergences, is ignore the term

  -- -------- -- --------
     @xmath      (7.24)
  -- -------- -- --------

in the action, because @xmath is small anyway. Then @xmath and @xmath
are of order @xmath and we shall only keep the Gaussian terms. Doing
this we find for the generating functional:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Notice that this generating functional depends on @xmath , as well as on
the sources @xmath and @xmath . With formula ( 4.10 ) one can compute
@xmath further. After some algebra one finds:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.26)
                                @xmath   
  -- -------- -------- -------- -------- --------

with @xmath the classical potential

  -- -------- -- --------
     @xmath      (7.27)
  -- -------- -- --------

and @xmath the 1-loop effective potential found in the canonical
approach, given in ( LABEL:effpotN2 ).

#### 7.2.1 Including One Minimum

Now we can see what happens if, for some reason, we would only include
the single minimum. For non-zero source this minimum is at @xmath and
@xmath given by ( 7.20 ). Notice that in this case it is correct to
discard the term ( 7.24 ), because @xmath . So in this case the
generating functional is given by @xmath and the @xmath - and @xmath
-tadpole can be calculated as follows.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Using

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.29)
  -- -------- -------- -------- -- --------

and

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.30)
  -- -------- -------- -------- -- --------

one finds

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.31)
  -- -------- -------- -------- -- --------

These equations can easily be inverted, up to order @xmath , to obtain
@xmath and @xmath as a function of @xmath and @xmath . One finds:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (7.32)
  -- -------- -------- -------- -- --------

This can be integrated to give for the effective potential, up to order
@xmath :

  -- -------- -- --------
     @xmath      (7.33)
  -- -------- -- --------

Indeed we see that including one minimum in the path integral gives the
canonical effective potential.

#### 7.2.2 Including All Minima

Including all minima, i.e. all points on the ring, means:

  -- -------- -- --------
     @xmath      (7.34)
  -- -------- -- --------

This generating functional can be calculated further. If we define the
function @xmath as

  -- -------- -- --------
     @xmath      (7.35)
  -- -------- -- --------

with @xmath defined in ( 7.23 ), the generating functional @xmath can be
written as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (7.36)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

For the tadpoles we find

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

In this last line the argument of the exponent is the same as in ( 7.36
).

We see that the magnitude of the @xmath -field only depends on the
magnitude of the sources @xmath , as expected because of the @xmath
-symmetry.

Now this last expression is only valid for small @xmath , because we
discarded the term ( 7.24 ). So we will expand our result (
LABEL:phiCartallmin ) also in @xmath and keep all terms up to order
@xmath . (Remember that @xmath is also of order @xmath .) We find:

  -- -------- -- --------
     @xmath      (7.39)
  -- -------- -- --------

This can be calculated analytically:

  -- -------- -- --------
     @xmath      (7.40)
  -- -------- -- --------

Here @xmath is the modified Bessel function of the first kind.

This result is plotted in figure 7.1 . The left curve is @xmath , so the
derivative of the effective potential, as a function of @xmath . The
right curve is the derivative of the canonical effective potential as a
function of @xmath . Both curves do not join at some point, the left
curve is only valid for very small @xmath , whereas the right curve is
only valid for large @xmath .

Apparently the way we calculate here, simply integrating over the ring
of minima (in @xmath ), is not a good way to cover the whole range of
@xmath , from small @xmath of order @xmath , to @xmath of order 1.
However we do find that the effective potential has a flat bottom in the
limit @xmath .

## Chapter 8 Path Integrals in Polar Variables

### 8.1 Introduction

In the next chapter we shall calculate the Green’s functions in the
@xmath linear sigma model via the path integral in terms of polar field
variables. These polar variables are the natural variables to describe
an @xmath -invariant model. Before we can do these calculations however,
we have to know how to transform to polar variables in a @xmath
-dimensional path integral.

When dealing with a normal integral a common technique to solve it is to
transform to a different integration variable. Since the path integral
is merely an infinite-dimensional integral, one should also be able to
transform to different integration variables in this case. In
particular, in the case of a path integral over two fields, @xmath and
@xmath , one can transform to polar field variables, @xmath and @xmath ,
defined as:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.1)
  -- -------- -------- -------- -- -------

It is this transformation to polar field variables that we shall study
in this chapter. We wish to emphasize here that not the space-time
coordinates, but the quantum fields @xmath and @xmath are transformed to
polar fields @xmath and @xmath .

The infinite dimensionality of the path integral makes such a variable
transformation very complicated. Several difficult questions immediately
pop up:

1.  In principle the whole path integral is only defined on a lattice,
    so the transformation should also be done with the path integral in
    discrete form. This means one cannot simply let the transformation
    work on the continuous action. Instead one has to write out the
    action in discrete form and only then let the transformation work.
    After this one gets a complicated action, with also terms
    proportional to the lattice spacing @xmath . These terms cannot be
    discarded, since one has to perform the path integration first and
    then take the continuum limit @xmath . It is not obvious that the
    terms proportional to @xmath will not give a finite contribution in
    this continuum limit. In fact, in this chapter we will see that they
    do give finite contributions to Green’s functions.

2.  After the transformation the domain of integration is not @xmath .
    For the @xmath -variables it is @xmath , whereas for the @xmath
    -variables it is @xmath . How does one evaluate such a path
    integral, especially because we can only compute path integrals with
    perturbation theory? To do perturbation theory we have to be able to
    identify a Gaussian part, and the fields in such a Gaussian part are
    always integrated from @xmath to @xmath .

3.  After the transformation one gets a Jacobian, how does one deal with
    this? Since we can only do perturbation theory we also have to
    identify the Gaussian part and the perturbative part of this
    Jacobian.

From these questions it is clear that transforming to polar variables in
a @xmath -dimensional path integral is very complicated. For
1-dimensional systems, i.e. quantum-mechanical systems, there is quite
some literature on the transformation to polar variables.

In his textbook [ 33 ] Lee derives the quantum-mechanical path integral
in curvilinear coordinates in chapter 19. The result (19.49) is a path
integral with a new action @xmath , which is not equal to the action one
would find by transforming to polar coordinates in the continuum action
(in Cartesian coordinates).

Edwards et al. [ 34 ] and Peak et al. [ 35 ] also transform to polar
coordinates in the discrete quantum-mechanical path integral. They find
that terms of order @xmath or higher, which arise when transforming to
polar coordinates in the discrete action (in Cartesian coordinates),
cannot all be neglected.

### 8.2 A Conjecture

From the above it should be clear that transforming a path integral in
terms of the normal (i.e. Cartesian) fields @xmath and @xmath to a path
integral in terms of polar fields is far from trivial. To be able to do
computations at all we will present a conjecture in this section. In the
next sections we will then try to make this conjecture plausible by
considering certain toy models where we can see that the conjecture
actually works.

The generic form of a @xmath -dimensional Euclidean path integral @xmath
in two fields is:

  -- -------- -- -------
     @xmath      
     @xmath      (8.2)
  -- -------- -- -------

Very naively, one could hope that the transformation to polar variables
works as:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.3)
  -- -------- -------- -------- -- -------

Here one has just extended the integration domains for @xmath and @xmath
to @xmath . In the fourth line one has just transformed the continuum
action to an action in terms of polar fields, disregarding the fact that
one should do this on the lattice, where the path integral is defined.

To make all these expressions completely continuous we still have to do
something about the Jacobian factor

  -- -------- -- -------
     @xmath      (8.4)
  -- -------- -- -------

since this is still a lattice expression. We shall write this Jacobian
as:

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (8.5)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

This is a continuum expression, which looks a lot like the exponential
of an action.

So, we might hope that the continuum form of a path integral in polar
field variables is given by making the substitutions

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.6)
  -- -------- -------- -------- -- -------

in the path integral in Cartesian form.

Now the conjecture we are going to make is:
Conjecture It is correct to transform to polar variables naively, as in
( 8.6 ), provided one does the calculation in a @xmath -dimensional way.
This seems a very strange conjecture, and with all the remarks we made
in the introduction it is hard to imagine how it can work. However in
the next two sections we shall demonstrate that indeed this conjecture
is true for two toy models. Also there we will demonstrate what is meant
exactly by ‘calculating in a @xmath -dimensional way’.

These two toy models are selected with the following two criteria:

1.  The model should have one minimum.

2.  This minimum should not be at @xmath .

The reason for the first criterion is that we want a toy model where we
can calculate Green’s functions both through the path integral in normal
(Cartesian) fields and through the path integral in polar fields. Only
then can we check whether the conjecture, used in the calculation
through polar fields, works. Notice that the @xmath linear sigma model
does not satisfy the first criterion, there we have an infinite set of
minima. In that case it is not clear whether a calculation through the
Cartesian path integral (as done in the previous chapter) is correct.
The reason for the second criterion is that at @xmath , i.e. @xmath ,
the transformation to polar fields becomes problematic. To be on the
safe side we simply avoid these difficulties by only considering toy
models which have their minimum away from @xmath , such that we can do
perturbation theory around a point where the transformation is
well-defined.

### 8.3 The Shifted Toy Model

In this section we shall calculate several Green’s functions in the
so-called shifted toy model. This model has an action

  -- -------- -- -------
     @xmath      (8.7)
  -- -------- -- -------

This is just the action of a free model with the @xmath -field shifted,
hence the name. We shifted this field such that the minimum of the
action is at @xmath .

To prove that the conjecture indeed works in the case of this model we
shall now calculate several Green’s functions through the normal,
Cartesian, path integral and through the path integral in terms of polar
fields. Then we can compare results.

#### 8.3.1 Cartesian Results

Because the shifted toy model is just a free theory with one field
shifted it is very easy to obtain the exact full Green’s functions. They
are:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.8)
  -- -------- -------- -------- -- -------

#### 8.3.2 Polar Results

Now we perform the transformation to polar fields in the path integral:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.9)
  -- -------- -------- -------- -- -------

Here we have used @xmath instead of @xmath to have a new angular
field-variable with also the dimensions of a field. This is purely a
matter of convenience.

To calculate the Green’s functions through the path integral in polar
fields now we will use the conjecture. According to this conjecture, the
new action we have to work with is:

  -- -------- -- --------
     @xmath      (8.10)
  -- -------- -- --------

The minimum of the action is at @xmath and @xmath . Expanding around
@xmath and writing

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

we get

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Expanding also around @xmath , i.e. expanding the cosine gives:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.13)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

The Jacobian gives, according to the conjecture:

  -- -- -- --------
           
           
           (8.14)
  -- -- -- --------

It is convenient to define also the standard integral @xmath :standard
integrals

  -- -------- -- --------
     @xmath      (8.15)
  -- -------- -- --------

Now can read off the Feynman rules from the action and the Jacobian, and
the conjecture states that we can calculate everything in the continuum,
provided we do a @xmath -dimensional calculation. The Feynman rules are
(up to order @xmath ):

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.16)
  -- -- -------- -------- -- --------

Here all momenta are counted as going into the vertex. With these rules
we can now compute Green’s functions up to order @xmath .

First we will demonstrate however what we mean exactly by ‘calculating
in a @xmath -dimensional way’. What we mean can most easily be seen in
the following ‘ @xmath -dimensional calculation’ of a tadpole diagram.

  -- -- -------- -------- --
        @xmath   @xmath   
                 @xmath   
        @xmath   @xmath   
                 @xmath   
        @xmath   @xmath   
                 @xmath   
                 @xmath   
                 @xmath   
  -- -- -------- -------- --

Now use

  -- -------- -- --------
     @xmath      (8.18)
  -- -------- -- --------

Then the tadpole diagram becomes:

  -- -- -- -------- -------- --------
           @xmath            (8.19)
                    @xmath   
                    @xmath   
                    @xmath   
                    @xmath   
           @xmath   @xmath   
                    @xmath   
                    @xmath   
                    @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- --------

In the above steps, and in all @xmath -dimensional calculations, one
essentially uses three rules: One writes dot-products from the vertices
in terms of the denominators of the propagators, to let them cancel as
much as possible, one can shift all loop momenta and one can set

  -- -------- -- --------
     @xmath      (8.20)
  -- -------- -- --------

Using these three rules is what we mean by a ‘ @xmath -dimensional
calculation’.

Notice that, for example in dimension 1, where @xmath becomes a simple
product, we could also have combined momenta coming from different
vertices and let them cancel denominators. This simplifies the
calculation of the tadpole diagram considerably, however this is not
what we mean by a ‘ @xmath -dimensional calculation’. The result in
terms of standard integrals is also different . Even the numerical
result is different because the diagram contains a divergence, also in
@xmath . (The divergence comes from @xmath .) In order for the
conjecture to work we have to perform a @xmath -dimensional calculation.

Now we compute @xmath , @xmath , @xmath , @xmath and @xmath via the
polar fields, up to order @xmath . To do this we first have to express
these Green’s functions in terms of the @xmath - and @xmath
-Green’s-functions.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            
              @xmath   @xmath            
     @xmath   @xmath   @xmath            
              @xmath   @xmath            
     @xmath   @xmath   @xmath            
              @xmath   @xmath            
                       @xmath            
                       @xmath            
                       @xmath            
     @xmath   @xmath   @xmath            
              @xmath   @xmath            
                       @xmath            
                       @xmath            
     @xmath   @xmath   @xmath            (8.21)
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Notice that in these formulas only the full @xmath - and @xmath
-Green’s-functions occur.

Now we compute all the @xmath - and @xmath -Green’s-functions that we
need, up to order @xmath . All results will be expressed in the standard
integrals again. One-loop standard integrals have already been defined
in ( 3.10 ). One would expect that we also need the two-loop standard
integrals here, since two-loop diagrams will occur in the @xmath
-tadpole at order @xmath . However it will appear that no two-loop
integrals occur in the final expressions for the tadpole diagrams, all
expressions can be written in terms of one-loop standard integrals,
probably because of the simple action of the shifted toy model. From the
Feynman rules we can also immediately see that any Green’s function with
an odd number of @xmath ’s is zero, we will not list them explicitly
below.

##### The @xmath-Tadpole

Below we list all the diagrams contributing to @xmath up to order @xmath
.

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.22)
  -- -- -------- -------- -- --------

The complete result for the @xmath -tadpole is finally:

  -- -------- -- --------
     @xmath      (8.23)
  -- -------- -- --------

Notice that all the (infinite) @xmath -integrals from the Jacobian have
nicely cancelled against identical terms from @xmath -loops.

##### The @xmath-Propagator

Below we list the diagrams contributing to the connected momentum-space
@xmath -propagator @xmath .

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.24)
  -- -- -------- -------- -- --------

For the connected @xmath -propagator we get:

  -- -------- -- --------
     @xmath      (8.25)
  -- -------- -- --------

##### The @xmath-Propagator

Below we list the diagrams contributing to the connected @xmath
-propagator @xmath .

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

  -- -------- -- --------
     @xmath      (8.27)
  -- -------- -- --------

##### Configuration-Space Green’s Functions

Knowing these @xmath - and @xmath -Green’s-functions we can write down
the configuration space Green’s functions needed in ( 8.21 ), up to
order @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Now, substituting all these results in ( 8.21 ) gives us finally:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.29)
  -- -------- -------- -------- -- --------

These are indeed the correct results for the Green’s functions. So the
conjecture is verified for several Green’s functions in the shifted toy
model up to order @xmath .

### 8.4 The Arctangent Toy Model

As another illustration of the conjecture we now consider the arctangent
toy model. The action of this model is:

  -- -------- -- --------
     @xmath      (8.30)
  -- -------- -- --------

This action has a single minimum at

  -- -------- -- --------
     @xmath      (8.31)
  -- -------- -- --------

We want to stress that this model is not at all a physical model. The
action has an infinite number of vertices (by expanding the arctangent),
which means this model is not renormalizable. We just want to use this
model as a toy model to test the conjecture. Especially because it is
not renormalizable, so no big cancellations can be expected to occur,
the arctangent toy model is a very good test of the conjecture.

#### 8.4.1 Cartesian Results

To find the Cartesian Green’s functions we expand the action around the
minimum ( 8.31 ):

  -- -------- -- --------
     @xmath      (8.32)
  -- -------- -- --------

Notice that also the arctangent in the action has to be expanded, this
term will give an infinite number of vertices. Up to order @xmath the
Feynman rules are:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.33)
  -- -- -------- -------- -- --------

Here the solid lines indicate the @xmath -particle, the dashed lines
indicate the @xmath -particle and @xmath is given by @xmath . (Notice
that this is a different definition of @xmath than in the rest of this
thesis, this definition will only be used in calculations in the
arctangent toy model.) With these Feynman rules we can now compute some
Green’s functions up to order @xmath . We shall not present all diagrams
here, since this Cartesian calculation is straightforward and quite
lengthy.

This time we will also get two-loop integrals in our expressions for the
Green’s functions. They don’t drop out in this case, as in they did in
the shifted toy model, because this model has a more complicated action.

Now the Green’s functions are, up to order @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
                       @xmath      
                       @xmath      
     @xmath   @xmath   @xmath      (8.34)
  -- -------- -------- -------- -- --------

#### 8.4.2 Polar Results

According to the conjecture we can just transform the continuum action (
8.30 ) to an action in terms of the polar field variables to obtain the
Feynman rules for the polar calculation. So the action becomes:

  -- -------- -- --------
     @xmath      (8.35)
  -- -------- -- --------

This can be expanded around @xmath again. Defining

  -- -------- -- --------
     @xmath      (8.36)
  -- -------- -- --------

we find the following Feynman rules for the @xmath - and @xmath -field
(up to order @xmath ). The vertices from the Jacobian are exactly the
same as in the shifted toy model.

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.37)
  -- -- -------- -------- -- --------

Here the solid lines denote the @xmath -field, the dashed lines denote
the @xmath -field and all momenta are counted into the vertex. Also we
have defined @xmath again, as in the Cartesian calculation. (Note that
this is a different definition of @xmath than in the rest of this
thesis.)

Now we can again compute the @xmath - and @xmath -Green’s-functions up
to order @xmath .

##### The @xmath-Tadpole

Below we list the diagrams contributing to the @xmath -tadpole up to
order @xmath .

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
                 @xmath      
                 @xmath      
        @xmath   @xmath      
                 @xmath      
                 @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.38)
  -- -- -------- -------- -- --------

The complete result for the @xmath -tadpole is finally:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.39)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

##### The @xmath-Propagator

The diagrams for the momentum-space @xmath -propagator are:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.40)
  -- -- -------- -------- -- --------

For the connected @xmath -propagator we get:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

##### The @xmath-Propagator

The diagrams contributing to the @xmath -propagator up to order @xmath
are:

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
                 @xmath   
                 @xmath   
                 @xmath   
        @xmath   @xmath   
                 @xmath   
        @xmath   @xmath   
  -- -- -------- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

##### Configuration-Space Green’s Functions

To compute the Cartesian @xmath - and @xmath -Green’s-functions we can
again use the expansions ( 8.21 ), since these expansions are model
independent. First we have to find the configuration-space @xmath - and
@xmath -Green’s functions however.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Now these results can be substituted in ( 8.21 ). Doing this one finds
again the results ( 8.34 ). So also in case of the arctangent toy model
the conjecture is verified for several Green’s functions up to order
@xmath .

### 8.5 Proof of the Conjecture

In the last two sections evidence for the truth of the conjecture has
accumulated. In this section we shall prove this conjecture for a
general model in @xmath space-time dimensions. A general action (in
terms of normal, Cartesian fields) for a @xmath -dimensional model with
two fields is given by:

  -- -------- -- --------
     @xmath      (8.45)
  -- -------- -- --------

Our proof will be based on the fact that the transformation to polar
field variables actually has to be performed in the path integral on the
lattice, i.e. in the path integral formulated in a discrete way. After
transforming to polar fields one gets a path integral in terms of polar
fields formulated on a lattice. This path integral gives a (complicated)
set of Feynman rules, and diagrams actually have to be calculated with
space-time still discrete. Only in the end result for the Green’s
function one should then take the continuum limit, i.e. @xmath .

Now a @xmath -dimensional continuum calculation is correct if one can
see that all the steps one performs there to calculate a diagram
correspond to a similar step in a discrete calculation. In a continuum
calculation one performs the following three steps when calculating any
diagram:

1.  One writes momentum-dependent factors from the vertices in terms of
    the denominators of propagators, such that one can let them cancel.
    For example:

      -- -------- -- --------
         @xmath      (8.46)
      -- -------- -- --------

2.  One shifts momenta, for example:

      -- -------- -- --------
         @xmath      (8.47)
      -- -------- -- --------

3.  When there is momentum dependence left in the numerator, which
    cannot cancel anything in the denominator anymore, one uses

      -- -------- -- --------
         @xmath      (8.48)
      -- -------- -- --------

    For example:

      -- -------- -- --------
         @xmath      
         @xmath      
         @xmath      (8.49)
      -- -------- -- --------

If we can somehow see that these steps are also valid in a discrete
calculation, then we have proven the conjecture. For then we know that
every operation one performs in the @xmath -dimensional continuum
calculation corresponds to a valid operation in a discrete calculation,
even though one writes down these steps in a continuum formalism.

Because we need the path integral on a lattice we define discrete
space-time variables @xmath as:

  -- -------- -- --------
     @xmath      (8.50)
  -- -------- -- --------

Notice that we have limited the space-time domain (each direction goes
from @xmath to @xmath ) and we have made this domain discrete (in every
direction there are @xmath lattice sites). The fields on the discrete
lattice are denoted by:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.51)
  -- -------- -------- -------- -- --------

For these fields we shall assume periodic boundary conditions in all
directions. For the 1-direction this means:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.52)
  -- -------- -------- -------- -- --------

The action ( 8.45 ), formulated on this lattice, is:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.53)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now we may transform to polar field variables, since now the path
integral is properly defined, it has become merely a @xmath -dimensional
integral. The transformation goes as follows:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.54)
  -- -------- -------- -------- -- --------

This can be substituted in the action above. To keep things readable we
define the shorthand notations:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

The action becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.56)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Now we will expand the cosines in the first two lines. Also we will
assume that the potential is such that the minimum of the complete
action is at @xmath , where @xmath is some nonzero constant (the same
@xmath that divides @xmath in the cosine). This assumption is necessary
to avoid difficulties with the singularity at @xmath in the
transformation ( 8.54 ). Because the minimum of the action is at @xmath
we also expand the action around this value:

  -- -------- -- --------
     @xmath      (8.57)
  -- -------- -- --------

The final form of the discrete action is:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.58)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Note that this expression is still exact, as long as we keep all the
terms in the sums coming from expanding the cosines. Our complete
discrete path integral @xmath (defined in ( 8.2 )), formulated in terms
of the polar fields, now looks like:

  -- -------- -- --------
     @xmath      (8.59)
  -- -------- -- --------

where the action @xmath is given by ( 8.58 ), @xmath is some product of
the @xmath -fields:

  -- -------- -- --------
     @xmath      (8.60)
  -- -------- -- --------

and @xmath still is a shorthand notation for @xmath . Here @xmath and
@xmath are discrete space-time coordinates. (By @xmath we actually mean
@xmath , as in ( LABEL:shorthand ).)

The product

  -- -------- -- --------
     @xmath      (8.61)
  -- -------- -- --------

is the Jacobian from the transformation to polar fields. This Jacobian
factor can be recast in the following form:

  -- -------- -- --------
     @xmath      (8.62)
  -- -------- -- --------

Also the domain of integration for the @xmath -fields can be extended
from @xmath to @xmath , because the whole integrand is periodic in the
@xmath -fields. Finally we can also extend the lower integration
boundary for the @xmath -fields from @xmath to @xmath , this shift will
only have non-perturbative effects.

So we have brought our path integral to the form

  -- -------- -- --------
     @xmath      (8.63)
  -- -------- -- --------

This is a normal path integral on a lattice, in the sense that it has
the same form of a path integral in terms of Cartesian fields. Such a
path integral we can calculate in the ordinary way, with perturbation
theory. The action of this path integral does have an infinite number of
vertices however, because the discrete action ( 8.58 ) has an infinite
number of interaction terms and also because the expansion of the
logarithm coming from the Jacobian has an infinite number of terms. But
it is still an exact expression, because we keep all terms.

Now we have to write down the (discrete) Feynman rules for the action we
have found. To write down the momentum-space Feynman rules we must first
transform the configuration-space fields @xmath and @xmath to
momentum-space fields @xmath and @xmath . In the continuum such a
transformation is given by:

  -- -------- -- --------
     @xmath      (8.64)
  -- -------- -- --------

and similar for the @xmath -field. The discrete analogue of this formula
is:

  -- -------- -- --------
     @xmath      (8.65)
  -- -------- -- --------

where we have used that the continuous momentum is related to the
discrete momentum as

  -- -------- -- --------
     @xmath      (8.66)
  -- -------- -- --------

The inverse transformation of ( 8.65 ) is

  -- -------- -- --------
     @xmath      (8.67)
  -- -------- -- --------

and similar for the @xmath -field. To see that this is indeed the
inverse transformation of ( 8.65 ) one can use the identity

  -- -------- -- --------
     @xmath      (8.68)
  -- -------- -- --------

From the relation ( 8.66 ) we can see that when we take @xmath the
momenta become a continuous set. Their domain is still finite however.
Because the discrete momenta are between @xmath and @xmath , the
continuous momenta are in the domain

  -- -- -- --------
           (8.69)
  -- -- -- --------

The finiteness of this domain reflects the discreteness of space-time.
From now on we shall understand that we have taken the limit @xmath ,
such that all sums over momenta become integrals. But of course @xmath
is still finite.

By using ( 8.67 ), in the limit @xmath , we can now express the discrete
action ( 8.58 ) in terms of the momentum-space fields @xmath and @xmath
. From this action one can then read of the discrete, momentum-space
Feynman rules. Notice that we did not specify the potential @xmath , so
we will not include the Feynman rules coming from this part of the
action. This potential @xmath will also determine the masses for the
@xmath - and @xmath -field. We shall keep these masses general, the
upcoming proof for the conjecture will not depend on the explicit form
of the potential @xmath and the masses. In the Feynman rules below we
will neither include the Feynman rules from the Jacobian, the proof of
the conjecture will also not depend on the exact form of these vertices.

The discrete, momentum-space Feynman rules are then:

  -- -- -------- -------- -------- --------
        @xmath   @xmath            
        @xmath   @xmath            
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath                     
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            (8.70)
                          @xmath   
                          @xmath   
                 @xmath            
  -- -- -------- -------- -------- --------

Here all the (continuum) momenta are counted incoming. Together with
these Feynman rules for the propagator and the vertices we have the rule
that every internal momentum should be integrated over from @xmath to
@xmath .

Now all these vertices can be written in a more convenient form. By
combining all the complex exponentials (i.e. writing out all products)
and using momentum conservation at the vertex one will notice that for
each exponential also its complex conjugate occurs. They can be combined
into a cosine, the same cosine that occurs in the discrete propagator.
In this way we can write the vertex expressions above in terms of the
denominator of the propagator. As a shorthand notation we denote the
denominators by @xmath and @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.71)
  -- -------- -------- -------- -- --------

To write the vertices into this more convenient form we also have to
define an operator @xmath . We denote the set consisting of the @xmath
components of the momenta @xmath by @xmath :

  -- -------- -- --------
     @xmath      (8.72)
  -- -------- -- --------

Then the operator @xmath working on @xmath returns the sum of @xmath
momenta chosen from the set @xmath . There are @xmath ways to choose
@xmath momenta from a set of @xmath momenta, so there are also @xmath
different operators @xmath . For example:

  -- -------- -- --------
     @xmath      (8.73)
  -- -------- -- --------

With these notations we can write the vertex expressions as follows.

  -- -- -------- -------- -------- --------
        @xmath   @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            
                 @xmath            
                 @xmath            
        @xmath                     
        @xmath   @xmath            (8.74)
                          @xmath   
                          @xmath   
                 @xmath            
  -- -- -------- -------- -------- --------

Notice that the bars are always placed on the terms with an operator
@xmath with @xmath even. For the sake of the argument it is convenient
to place these bars in this way. Whether or not a bar is placed on the
last term, with @xmath , thus depends on @xmath , whether @xmath is even
or odd. Above the bars are placed as if @xmath were even, but it should
be clear how they should be placed when @xmath is odd.

Now notice that these vertex rules look identical to the rules one would
use when doing a @xmath -dimensional continuum calculation. For example,
in the continuum the 3-vertex would be:

  -- -- -- --------
           (8.75)
  -- -- -- --------

To simplify the dot-product in a @xmath -dimensional calculation one
would write it as

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.76)
                                @xmath   
  -- -------- -------- -------- -------- --------

which corresponds exactly to the discrete vertex expression given in (
8.74 ) for the 3-vertex. So when one uses the continuum rules to rewrite
dot-products of momenta, as in the 3-vertex example above, one is
actually doing a correct calculation, although one is doing a continuum
calculation.

Another rule that one uses in a continuum calculation is that it is
allowed to shift the loop momenta. Also in a discrete calculation this
is allowed, because of the periodicity of the discrete propagators and
vertex expressions.

What then goes wrong in a continuum calculation? There is one more rule
that one uses in a continuum calculation that we have not mentioned up
to now. This rule is:

  -- -------- -- --------
     @xmath      (8.77)
  -- -------- -- --------

This rule, however, is not correct in a discrete calculation. For
example, in dimension 1, we have to realize that by @xmath and @xmath we
actually mean:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.78)
  -- -------- -------- -------- -- --------

So by the integral above we actually mean:

  -- -------- -- --------
     @xmath      (8.79)
  -- -------- -- --------

This shows that the rule ( 8.77 ) is not correct to use. The only
instances that one would use the rule ( 8.77 ) is when a @xmath (or
@xmath ) is left in the numerator, and cannot cancel anything in the
denominator anymore.

Below we shall show that all such terms, where a @xmath (or @xmath )
remains in the numerator, cancel when one adds all diagrams for a
certain Green’s function. To this end it is convenient to split up the
vertices in ( 8.74 ) as follows:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath               
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath               
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
                 @xmath      
                 @xmath      
        @xmath   @xmath      
        @xmath               
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
                 @xmath      
        @xmath   @xmath      (8.80)
                 @xmath      
  -- -- -------- -------- -- --------

Having written the vertices in this form it is clear where the problem
terms in a certain diagram come from. They come from a vertex with a dot
in the center or two vertices connected by a line with two dots. That a
dotted vertex is a source can immediately be seen from the vertex
expressions above. A line with two dots and momentum @xmath flowing
through it gets two @xmath ’s in the numerator, from the vertices, and
only one @xmath in the denominator, from the propagator.

It is now easy to derive the following recursion relation, valid for
@xmath :

  -- -- -- --------
           
           
           
           
           (8.81)
  -- -- -- --------

In these diagrams it is understood that the outgoing legs should be
connected in all possible ways. @xmath Is defined as:

  -- -------- -- --------
     @xmath      (8.82)
  -- -------- -- --------

Notice that the third and fourth line in the recursion relation above
are not there when @xmath , these diagrams simply do not exist.

We also have the following two recursion relations:

  -- -- -- --------
           
           
           
           
           (8.83)
  -- -- -- --------

In this recursion relation @xmath .

  -- -- -- --------
           
           
           
           
           (8.84)
  -- -- -- --------

In this recursion relation @xmath . The first two lines are not there
when @xmath .

With these recursion relations it is easy to see that the problem terms
always cancel in the complete set of diagrams for a certain Green’s
function. If somewhere in a diagram an internal line with two dots
occurs, then at this same point in the diagram also the dotted vertex
can occur. These diagrams then sum up to zero.

So finally we have proven that the problem terms cancel in the complete
set of diagrams for a certain Green’s function. If they cancel out
anyway it is also correct to treat these problem terms like one would in
the continuum. Of course one makes a mistake for each problem term, but
these mistakes cancel out again in the complete set of diagrams. So
there is nothing wrong with taking the continuum limit right from the
start and doing a @xmath -dimensional continuum calculation.

Notice that it is no problem to add the vertices coming from the
potential @xmath and the Jacobian to this argument. These vertices give
no problem terms themselves. They can be combined with the dotted
vertices, but the problem terms always come from a clear , separated
part of the diagram, either two vertices connected by a line with two
dots, or a dotted vertex.

Now we know it is correct to take the continuum limit @xmath
straightaway in the discrete Feynman rules ( 8.74 ). If we do this it is
easy to see that only the @xmath - and @xmath -vertex do not vanish. All
the other vertices go to zero, as can be seen from their expressions in
( 8.74 ), but also, and much quicker, from ( 8.70 ), because they all
have one or more factors of @xmath in front when the exponentials are
expanded.

So, finally we are left with the Feynman rules:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.85)
  -- -- -------- -------- -- --------

plus the Feynman rules coming from the potential @xmath and the
Jacobian. These are exactly the Feynman rules that one would have read
off from the continuum action:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.86)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Recapitulating the proof, we have done the following. The basis of our
proof is the discrete path integral in terms of the Cartesian fields
@xmath and @xmath . In this path integral on the lattice it is
completely legitimate to transform to polar fields. After this
transformation we get a very big, complicated action. Looking at the
discrete vertex expressions we find how we can simplify these
expressions, and how we can let them cancel against propagators in a
certain diagram. We notice that these rules are exactly the same as in a
@xmath -dimensional continuum calculation. All the rules that we would
use in a continuum calculation appear to be valid in a calculation on
the lattice as well, except for one: rule ( 8.77 ). The terms where we
would need to use this rule can then be shown to cancel in the complete
set of diagrams, by using the three recursion relations. So by using the
incorrect rule ( 8.77 ) we actually make a mistake, but all these
mistakes cancel in the complete set of diagrams. Thus we know that all
the rules that we use in @xmath -dimensional continuum calculation are
also valid in a correct, discrete calculation. This means we might as
well take the continuum limit directly in the discrete Feynman rules (
8.70 ). Then these Feynman rules simplify to ( 8.85 ), and we have
proven that a @xmath -dimensional continuum calculation with the action
( 8.86 ) is correct .

#### 8.5.1 An Example

To see explicitly how the mechanism described in the previous section
works we consider an example. Consider the 1-loop @xmath -propagator.
There are two types of diagrams (We do not include vertices from the
potential @xmath and the Jacobian, because such vertices will never give
problem terms.):

[]

and []

Here, dots should still be put on the lines or in the vertices. There
are a lot of diagrams, but it is easy to see that there are only two
diagrams that contain problem terms. These are:

  -- -- -------- -------- -------- --------
        @xmath   @xmath            
        @xmath   @xmath            
        @xmath   @xmath            (8.87)
                          @xmath   
                 @xmath   @xmath   
  -- -- -------- -------- -------- --------

Indeed these diagrams cancel, as is guaranteed by the recursion
relations derived in the previous section. The other diagrams,
contributing to this @xmath -propagator at 1-loop order, have their dots
in other places, or have vertices without dots, that can also come from
the potential @xmath . These diagrams can never have a problem term. And
thus the whole 1-loop propagator is free of problem terms, and the
continuum limit could have been taken right from the start.

#### 8.5.2 The Jacobian and @xmath-Loops

In the previous sections it has become clear that it is allowed to work
with the continuum Feynman rules ( 8.85 ), as the conjecture states.
Together with these Feynman rules we have of course the rules from the
arbitrary potential @xmath , and the rules from the Jacobian. From the
discrete calculation it is easy to see that the Jacobian can indeed be
rewritten as:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as the conjecture states. The Feynman rules coming from this Jacobian
are:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath               
        @xmath   @xmath      (8.89)
  -- -- -------- -------- -- --------

Here the standard integral @xmath has been defined earlier, in ( 8.15 ).

We see that all these vertices give strange integrals @xmath . In the
case of the shifted toy model and the arctangent toy model we already
saw that these integrals @xmath always cancelled against identical terms
coming from @xmath -loops. We shall now prove this in general.

Consider a @xmath -loop with only @xmath - and @xmath -vertices (as
given in ( 8.85 )) on it. So the diagrams we are calculating can only
have external @xmath -legs. Such a diagram would look like:

[]

Now these diagrams have a part which is going to cancel the @xmath
-integrals from the Jacobian. This part is exactly the worst divergent
part of the diagrams above. To calculate this worst divergent part the
masses and incoming momenta can be neglected.

In this case it is easy to write down the generating functional for such
diagrams. This generating functional is defined as:

  -- -- -- --------
           (8.90)
  -- -- -- --------

where the diagram symbolizes all 1-loop diagrams of this type with
@xmath outgoing @xmath -lines.

We denote the number of @xmath -vertices in the @xmath -loop by @xmath
and the number of @xmath -vertices by @xmath . Then the generating
functional @xmath for diagrams of this type is given by:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (8.91)
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

So we can read off that a @xmath -loop with @xmath outgoing @xmath
-lines has a worst divergent part given by:

  -- -------- -- --------
     @xmath      (8.92)
  -- -------- -- --------

This exactly cancels the vertices from the Jacobian. In any diagram,
wherever a dotted vertex from the Jacobian with @xmath legs occurs, also
a @xmath -loop with @xmath outgoing legs can occur, and their part that
contains the standard integral @xmath cancels!

#### 8.5.3 The Dimensional Regularization Scheme

In the case that one uses the dimensional regularization scheme one has
that:

  -- -------- -- --------
     @xmath      (8.93)
  -- -------- -- --------

which means that also our standard integral @xmath becomes zero:

  -- -------- -- --------
     @xmath      (8.94)
  -- -------- -- --------

This means that in the dimensional regularization scheme it becomes even
easier to work with a path integral in polar field variables. In this
case one can also completely forget about the Jacobian one gets from the
transformation. Also one can ignore the integrals @xmath that are
generated by @xmath -loops.

In this thesis we will keep everything general however, and not specify
a regularization scheme.

### 8.6 The 1-Dimensional Case

In section 8.5 we have proven the conjecture for a general model with
two fields in @xmath space-time dimensions. This conjecture, which is
promoted to a theorem by now, enables us to actually calculate things
via the path integral in terms polar fields for any @xmath -dimensional
model. In a @xmath -dimensional model the only analytical computations
we can do in practice are continuum calculations. Analytical discrete
calculations, i.e. calculations on the lattice, are in practice much too
hard to do. That is why we have not bothered to simplify the discrete
@xmath -dimensional path integral, hoping to do a discrete calculation
with this simplified form.

In one dimension analytical discrete calculations are sometimes possible
(as we will see in the next section). Therefore it is convenient to have
a reasonably simple, discrete path integral in terms of polar fields for
the case @xmath . It is this path integral that we shall derive in this
section.

By deriving this path integral we shall also make contact with the
literature on quantum mechanical (i.e. 1-dimensional) path integrals in
terms of polar fields [ 33 , 34 , 35 ] .

Our starting point will again be the discrete Feynman rules ( 8.70 ),
now specified to @xmath however. Also, for the sake of the argument, we
will split up the vertices as given below. The 1-dimensional Feynman
rules are then:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.95)
  -- -- -------- -------- -- --------

Looking at these vertex expressions we notice that only the vertices

  -- -- -- --------
           (8.96)
  -- -- -- --------

have a finite continuum limit, all the other vertices go to zero when
@xmath is sent to zero in the Feynman rules. First we are going to
consider all diagrams which have at least one of these vertices that
vanish in the continuum limit. The only way these vertices can survive a
continuum limit in a complete diagram is when there occur loops that
give a @xmath .

First consider 1-loop diagrams. All 1-loop diagrams can be built from
the vacuum diagram

  -- -- -- --------
           (8.97)
  -- -- -- --------

By attaching legs we can build any 1-loop diagram from these. Having an
@xmath -line in the loop will never give a @xmath , no matter which
vertices we use. If the whole loop is a @xmath -line this loop can give
@xmath ’s. If we construct a diagram from this vacuum graph with at
least one of the vertices that go to zero in the continuum limit, one
can verify easily that either the whole diagram goes to zero in the
continuum limit or diagrams cancel among each other in the complete set
of graphs for a certain process, such that the whole process is zero.

The same thing can now be done on 2-loop level. Here we can construct
all diagrams from the vacuum graphs

  -- -- -- --------
           (8.98)
  -- -- -- --------

One can see that the only diagrams surviving the continuum limit and
containing at least one of the vertices that vanish in the continuum
limit can be constructed from the following vacuum graphs by only
attaching lines with the vertices ( 8.96 ), because these vertices do
not give additional powers of @xmath .

  -- -- -- --------
           (8.99)
  -- -- -- --------

For the vacuum graphs we have the following expressions, excluding
vertex constants and symmetry factors. Only the discrete loop
integration is done and the worst behavior in @xmath is kept.

  -- -- -------- -------- -- ---------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (8.100)
  -- -- -------- -------- -- ---------

We now construct all 1PI diagrams from these vacuum graphs by attaching
lines with the vertices ( 8.96 ). Because we can only attach lines with
these vertices we can only get external @xmath -lines. We shall now
calculate the generating functional of all the diagrams that can be
constructed in this way:

  -- -- -- ---------
           (8.101)
  -- -- -- ---------

Now this @xmath , for the first vacuum graph, is given by:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.102)
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Here @xmath is the symmetry factor of the vacuum graph, @xmath and
@xmath denote respectively the number of @xmath - and @xmath -vertices
in the left loop and @xmath and @xmath denote the number of @xmath - and
@xmath -vertices in the right loop. Now we can read off

  -- -- -- ---------
           (8.103)
  -- -- -- ---------

for the first vacuum graph.

Also the contributions from the three other vacuum blobs can be
constructed in the same way. Their generating functions appear to cancel
each other. The reason for this shall become clear below. For now the
only 2-loop contribution we get is ( 8.103 ).

The @xmath -leg diagrams that we find in ( 8.103 ) are exactly the
vertices one would get from a term

  -- -------- -- ---------
     @xmath      (8.104)
  -- -------- -- ---------

in the action. This can easily be seen by substituting @xmath in this
term and expanding it in @xmath . This means, up to 2-loop level, one
can discard the vertices that go to zero in the continuum limit and
replace them by the vertices from ( 8.104 ). In the action this means
one is left with

  -- -------- -- ---------
     @xmath      (8.105)
  -- -------- -- ---------

Disregarding 3- and higher-loop level we have now proven that our
1-dimensional discrete path integral @xmath (defined in ( 8.2 )) is
equal to:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.106)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

This is a form that one can also find in the literature. This same path
integral is derived by Lee [ 33 ] in chapter 19, formula (19.49). Also
Edwards et al. [ 34 ] and Peak et al. [ 35 ] find a term ( 8.104 ).
However they start with the discrete path integral in terms of Cartesian
fields, transform to polar fields and actually perform the angular
integration. Only then they find the term ( 8.104 ). We have presented a
more general proof of this term here, like Lee [ 33 ] .

Up to now we have not proven that at 3- and higher-loop level there are
diagrams, containing at least on of the vertices that vanish in the
continuum limit, that can not be built also from vertices from the term
( 8.104 ). We shall not prove this in this thesis. In this thesis we are
mostly interested in @xmath -dimensional models, and the conjecture
needed to compute via polar fields in these models has already been
fully proven. It should be clear however that, to have agreement with
the literature, the path integral ( 8.106 ) is correct, up to all
orders. So, although we cannot prove it at this point, there are no
diagrams at 3- and higher-loop order that cannot also be constructed
with only the term ( 8.104 ).

##### Lee’s Proof

The strictly 1-dimensional (i.e. quantum mechanical) derivation of (
8.106 ) by Lee [ 33 ] is based on how quantum mechanical path integrals
are mostly derived in elementary textbooks. Note that Lee derives the
Minkowskian version of ( 8.106 ). Here we will shortly sketch Lee’s
proof.

One starts with a certain amplitude

  -- -------- -- ---------
     @xmath      (8.107)
  -- -------- -- ---------

that one wants to calculate, where @xmath is a state in the Heisenberg
picture. Here we have a two-dimensional space-time, the analog of this
in our quantum field theory is the two-dimensional field-space with
fields @xmath and @xmath . To derive the path integral one makes time
discrete and at each discrete time point @xmath one inserts the unit
operator

  -- -------- -- ---------
     @xmath      (8.108)
  -- -------- -- ---------

(Here @xmath is a state in the Schrödinger picture.) Working this out
one finds the path integral in Cartesian coordinates.

One might also have inserted the unit operator

  -- -------- -- ---------
     @xmath      (8.109)
  -- -------- -- ---------

at each discrete time point @xmath . Here the subscript @xmath denotes
that we are dealing with polar states, which are related to the
Cartesian states as:

  -- -------- -- ---------
     @xmath      (8.110)
  -- -------- -- ---------

We need the @xmath to have the proper normalization for the polar
states. Only with this @xmath we have that the operator ( 8.109 ) is a
unit operator.

At some point in the derivation towards the path integral we have to let
the Lagrangian density

  -- -------- -- ---------
     @xmath      (8.111)
  -- -------- -- ---------

operate on the polar states. Here @xmath and @xmath are the canonical
momenta conjugate to @xmath and @xmath . We know that these canonical
momenta operate on the Cartesian states as:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.112)
  -- -------- -------- -------- -- ---------

If we then define the canonical momenta conjugate to @xmath and @xmath
as

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.113)
  -- -------- -------- -------- -- ---------

we have

  -- -------- -- ---------
     @xmath      (8.114)
  -- -------- -- ---------

Here we see the emergence of the term ( 8.104 ) in this derivation of
the path integral in polar fields. This roughly sketches how ( 8.106 )
can also be derived in this way.

Notice that the term ( 8.104 ) is only found in a 1-dimensional
argument. In @xmath dimensions there is no hope that all the vertices
that vanish in the continuum can be replaced by a simple term like (
8.104 ).

##### Another Way to Derive (8.106)

Another way to derive the discrete 1-dimensional path integral ( 8.106 )
is by first using the conjecture. So one computes all diagrams in a
@xmath -dimensional way in the continuum, with the simple Feynman rules
from the continuum action, then one lets @xmath . To obtain the discrete
version of these diagrams one has to know what the difference is between
calculating in the continuum and calculating in the discrete. This
difference, we know, comes from the problem terms. If we formulate the
(continuum) @xmath and @xmath -vertex with the dots, as we did in
section 8.5 , then we have a clear source of problem terms. Because in
this case we only have the @xmath - and @xmath -vertex we also only have
the recursion relation:

  -- -- -- ---------
           (8.115)
  -- -- -- ---------

This recursion relation ensures that all problem terms from a @xmath
-line with two dots cancel against the dotted part of the @xmath
-vertex. So the problem terms from @xmath -lines are never going to give
a difference between a discrete and continuum calculation. All we have
to do is find the problem terms coming from @xmath -lines with two dots.

Now, as in the previous (partial) derivation of ( 8.106 ) we can build
all diagrams from the vacuum graphs. At 1-loop order there is no
difference between a continuum and discrete calculation. At 2-loop order
the only problem terms come from the vacuum graph

  -- -- -- ---------
           (8.116)
  -- -- -- ---------

Now we can understand why, in the other derivation of ( 8.106 ), the
generating functionals from the last three vacuum graphs in ( 8.99 )
cancelled. Only the first graph in ( 8.99 ) corresponds to the vacuum
graph above. This correspondence can be seen by pinching the dotted
@xmath -line in the vacuum graph above. The last three vacuum graphs in
( 8.99 ) correspond to problem terms from dotted @xmath -lines or a
dotted @xmath -vertex. These cancel among each other because of the
recursion relation ( 8.115 ).

Now the difference between a continuum and discrete calculation of the
graph ( 8.116 ) can be calculated. Also the generating functional of
diagrams where we connect any number of @xmath -legs via the @xmath -
and @xmath -vertices can be calculated. The result of this generating
functional is given by ( 8.102 ). In this way we find that, to
compensate for the differences that we get by doing a discrete instead
of a continuum calculation, we have to introduce the term ( 8.104 ) in
the action again.

Also in this way of deriving ( 8.106 ) we do not know how to show that
3- and higher-loop diagrams give no new differences.

### 8.7 A 1-Dimensional Illustration

In the previous section we have shown that, in the case of one
dimension, the path integral in polar field variables is given by (
8.106 ). In this section we give a specific example of how ( 8.106 ) can
be used in a discrete calculation. We will calculate @xmath and @xmath
in the arctangent toy model through this formula and compare the results
with the results we can find in a Cartesian calculation. The Cartesian
results for some @xmath -Green’s-functions have already been found in
section 8.4.1 .

#### 8.7.1 @xmath

According to ( 8.106 ) @xmath is given by:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.117)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

Here @xmath is the discrete coordinate corresponding to @xmath :

  -- -------- -- ---------
     @xmath      (8.118)
  -- -------- -- ---------

and @xmath is given by

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.119)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

First we shall focus our attention on the @xmath -part in ( 8.117 ).
This part we call @xmath , it is defined as:

  -- -------- -- ---------
     @xmath      (8.120)
  -- -------- -- ---------

This @xmath is a quantity depending on all @xmath ’s. It is this
dependence we have to know before we can do the @xmath -integrals.

We will now try to find this dependence by finding a set of @xmath
differential equations which are satisfied by @xmath . Then we will try
to solve these differential equations. If we are successful we will have
fixed @xmath up to a constant, which is unimportant. Such a set of
differential equations is readily found. If we let

  -- -------- -- ---------
     @xmath      (8.121)
  -- -------- -- ---------

operate on @xmath we get:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.122)
                                @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

This differential equation is satisfied by @xmath for @xmath . Here the
@xmath -average ( @xmath ) of some product of fields @xmath is given by:

  -- -- -- ---------
           (8.123)
  -- -- -- ---------

Before we can proceed we have to know the quantities

  -- -------- -- ---------
     @xmath      (8.124)
  -- -------- -- ---------

So first we will have to calculate the discrete @xmath -propagator
@xmath .

##### The Discrete @xmath-Propagator

The discrete @xmath -propagator is given by:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.125)
                                @xmath   
  -- -------- -------- -------- -------- ---------

We will find the @xmath -propagator through the discrete Schwinger-Dyson
equations. To find these Schwinger-Dyson equations we first have to know
the Schwinger-Symanzik equation for @xmath in discrete form. @xmath is
defined by

  -- -------- -- ---------
     @xmath      (8.126)
  -- -------- -- ---------

and the Schwinger-Symanzik equation it satisfies is

  -- -------- -- ---------
     @xmath      (8.127)
  -- -------- -- ---------

The part with the partial derivative of @xmath can be written out. When
doing this it is convenient to introduce the following discrete
derivative definitions:

  -- -------- -- ---------
     @xmath      (8.128)
  -- -------- -- ---------

where @xmath can be any quantity with a label @xmath .

The Schwinger-Symanzik equation becomes:

  -- -------- -- ---------
     @xmath      
     @xmath      (8.129)
  -- -------- -- ---------

Now, to obtain the Schwinger-Dyson equations for the @xmath -propagator,
let @xmath work on both sides of the Schwinger-Symanzik equation ( 8.129
) and put all @xmath ’s to zero. If we also divide by @xmath we get:

  -- -------- -- ---------
     @xmath      (8.130)
  -- -------- -- ---------

Now we have to find a solution that satisfies this discrete
Schwinger-Dyson equation. Because later we are only interested in the
continuum limit of our final result, this solution only has to satisfy
the Schwinger-Dyson equation up to order @xmath . The following solution
does the job:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.131)
  -- -------- -------- -------- -- ---------

To verify this one has to treat the cases @xmath , @xmath , @xmath ,
@xmath and @xmath separately. As an example we will verify the case
@xmath below. In this case, the average @xmath becomes:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.132)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Remember that @xmath is of order @xmath in one dimension. The average
@xmath becomes:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.133)
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

These results can now be substituted in the Schwinger-Dyson equation (
8.130 ) and we see that it is indeed satisfied.

Now we have our desired discrete solution and we can continue
calculating @xmath .

##### The Calculation Of @xmath

Now that we know the discrete @xmath -propagator we can use this result
in the differential equations for @xmath . In these differential
equations the two following quantities occur.

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.134)
  -- -------- -------- -------- -- ---------

With these results the differential equations for @xmath become:

  -- -------- -- ---------
     @xmath      (8.135)
  -- -------- -- ---------

or

  -- -------- -- ---------
     @xmath      (8.136)
  -- -------- -- ---------

We now have a set of @xmath uncoupled differential equations, which are
easily solved:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.137)
  -- -------- -------- -------- -- ---------

Here @xmath can depend on @xmath with @xmath . The complete @xmath is
then easily constructed:

  -- -------- -- ---------
     @xmath      (8.138)
  -- -------- -- ---------

We see that in the continuum limit the term of order @xmath between the
brackets in the exponential is unimportant, this verifies our earlier
statement that we only have to know the discrete @xmath -propagator up
to order @xmath . So the important part of @xmath is:

  -- -------- -- ---------
     @xmath      (8.139)
  -- -------- -- ---------

##### The Calculation Of @xmath

Now that we know @xmath we can actually calculate @xmath . Remember that
@xmath is given by:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Substituting our solution ( 8.139 ) for @xmath in here gives:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

What we have here is a normal path integral in @xmath . This means we
can do this path integral in the ordinary way by using Feynman diagrams.
At this point also the continuum limit can be taken in the action, since
we have no derivative couplings anymore. The continuum form of the
action is:

  -- -------- -- ---------
     @xmath      (8.142)
  -- -------- -- ---------

First we should find the minimum of the action. This minimum is not
exactly at @xmath , but is shifted a little because of the terms @xmath
has introduced in the action. The minimum @xmath satisfies:

  -- -------- -- ---------
     @xmath      (8.143)
  -- -------- -- ---------

Again we want to know @xmath up to order @xmath . The @xmath that
satisfies ( 8.143 ) up to order @xmath is:

  -- -------- -- ---------
     @xmath      (8.144)
  -- -------- -- ---------

The expectation value of @xmath becomes:

  -- -------- -- ---------
     @xmath      (8.145)
  -- -------- -- ---------

Now we should expand the action around the minimum @xmath and read off
the Feynman rules. To get @xmath correct up to order @xmath we have to
keep all terms of order @xmath and lower in the action. After the
expansion around the minimum the action becomes:

  -- -------- -- ---------
     @xmath      (8.146)
  -- -------- -- ---------

The Feynman rules are:

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
                          
  -- -- -------- -------- --

With these Feynman rules we have to compute @xmath up to order @xmath .
We get the following contributions.

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
                          
  -- -- -------- -------- --

Summing up these contributions we get:

  -- -------- -- ---------
     @xmath      (8.149)
  -- -------- -- ---------

For @xmath we finally get:

  -- -- -- ---------
           (8.150)
  -- -- -- ---------

From our Cartesian results in section 8.4.1 @xmath can easily be found
via the formula:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.151)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

Substituting the results from section 8.4.1 , specified to the case
@xmath , indeed gives the same result as ( 8.150 ). Here we used the
1-dimensional results for the standard integrals given in appendix A .

#### 8.7.2 The @xmath-Propagator

As a last illustration of the 1-dimensional path integral in terms of
polar fields we will calculate the @xmath -propagator. We have:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.152)
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

We calculate the six averages that occur one by one.

  -- -------- -- ---------
     @xmath      (8.153)
  -- -------- -- ---------

Here @xmath is, as in the calculation of @xmath , given by ( 8.144 ).
The quantity @xmath is already known from earlier calculations, it is
given by ( 8.149 ). So we only have to calculate @xmath . For this
average we get the following contributions.

  -- -- -------- -------- --
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
        @xmath   @xmath   
                          
  -- -- -------- -------- --

Summing these contributions gives:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.155)
                                @xmath   
  -- -------- -------- -------- -------- ---------

Now @xmath becomes:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.156)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

In the next five averages that we have to calculate, before we find our
final result for the @xmath -propagator, also @xmath ’s occur. These
@xmath ’s have to be taken into account in the @xmath -path integral
that we perform first in all our calculations. Fortunately we know the
@xmath -propagator already, so that this result can be used in these
calculations. We get:

  -- -------- -- ---------
     @xmath      (8.157)
  -- -------- -- ---------

Now we can substitute our result ( 8.156 ) up to order @xmath in here
and find:

  -- -------- -- ---------
     @xmath      (8.158)
  -- -------- -- ---------

In the same way we find:

  -- -------- -- ---------
     @xmath      (8.159)
  -- -------- -- ---------

In the next three averages products of four @xmath ’s occur. Because the
@xmath -path integral is Gaussian we can write this into a sum of
products of averages of two @xmath ’s:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            
     @xmath   @xmath   @xmath            
     @xmath   @xmath   @xmath            (8.160)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

For our last three averages we get:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (8.161)
  -- -------- -------- -------- -- ---------

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.162)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Finally we get for the @xmath -propagator:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.163)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

And again this matches the result we find in section 8.4.1 , specified
to @xmath . (To calculate the standard integrals use appendix A again.)

## Chapter 9 The @xmath LSM: The Path-Integral Approach II

The action of the Euclidean @xmath linear sigma model is given by:

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

In chapter 7 we already calculated the Green’s functions of this model
by naively calculating Green’s functions around each of the minima and
then integrating over all minima. It was not at all clear that this was
the correct thing to do, especially because in this approach one has to
do perturbation theory around each of the minima. Each time we expand
around one of these minima we pretend the ring of minima is actually an
infinite line. So in this way we ignore the damping in the @xmath
-direction (i.e. tangential direction), which is there because of the
@xmath -term. This damping effect is lost in perturbation theory because
the exponential of @xmath is expanded and not all terms are kept.

Also, by integrating over all minima we implicitly assume that the
minima do not communicate, which is not true at all.

In this chapter we will calculate the same Green’s functions via the
path integral in polar field variables. These polar variables are the
natural variables for a model with @xmath -symmetry. The action in terms
of polar field variables will not depend on the angular field @xmath ,
but only on @xmath . Therefore we have that:

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.2)
  -- -------- -------- -------- -- -------

The first relation merely states that all points on the ring of minima
have an equal weight in the path integral. This means it is also
incorrect to expand around @xmath , for which we would have to assume
that @xmath is small. This expansion is what we did in chapter 7 . From
the second relation we see that it is correct to expand in @xmath ,
because @xmath is small.

Because the action in terms of polar fields does not depend on @xmath
there is also no need to expand around @xmath in the formalism in terms
of polar fields. In this way we avoid doing perturbation theory in
@xmath , which was the big problem of chapter 7 .

In this chapter also the effective potential of the @xmath linear sigma
model will be calculated via the path integral in terms of polar fields.

### 9.1 Green’s Functions

According to the conjecture from the previous chapter the path integral
in terms of polar field variables for this model is given by

  -- -------- -- -------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.3)
  -- -------- -- -------

provided we perform the calculation in a @xmath -dimensional way. Here
@xmath given by

  -- -------- -- -------
     @xmath      (9.4)
  -- -------- -- -------

and @xmath given by

  -- -------- -- -------
     @xmath      (9.5)
  -- -------- -- -------

Because we are dealing with a @xmath -dimensional model divergences will
arise and we must renormalize the fields, masses and coupling constants.
First we rewrite the action in the form

  -- -------- -- -------
     @xmath      (9.6)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (9.7)
  -- -------- -- -------

as in the rest of this thesis. The fields, masses and coupling constants
are renormalized in the same way as in chapter 6 and 7 :

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.8)
  -- -------- -------- -------- -- -------

In terms of polar variables the field renormalization means:

  -- -------- -- -------
     @xmath      (9.9)
  -- -------- -- -------

the @xmath -field is not renormalized. We also define a new angular
field as

  -- -------- -- --------
     @xmath      (9.10)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (9.11)
  -- -------- -- --------

Making these substitutions in the action ( 9.1 ) we get (also defining
@xmath ):

  -- -------- -------- -- -------- --------
     @xmath   @xmath               (9.12)
                          @xmath   
  -- -------- -------- -- -------- --------

From here on we shall suppress the @xmath -superscripts, understanding
that we always work with renormalized fields, masses and coupling
constants.

Notice that the counter terms have nothing to do with the transformation
to polar fields, both in a Cartesian and polar formulation we have the
same counter terms.

To do perturbation theory we expand around the minimum of the first line
(i.e. the classical part) of the renormalized action:

  -- -------- -- --------
     @xmath      (9.13)
  -- -------- -- --------

Remember that we also have to include the Feynman rules from the
Jacobian. The procedure of renormalization does not change these rules.

The Feynman rules (in momentum space) up to order @xmath are:

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (9.14)
  -- -- -------- -------- -- --------

Here we have defined @xmath as in chapters 6 and 7 . Also all indicated
momenta flow into the vertex. The counter-term vertices have been
indicated by a big dot in the vertex, the vertices from the Jacobian
have been indicated by a small dot.

#### 9.1.1 @xmath- And @xmath-Green’s-Functions

Now we can compute all the @xmath - and @xmath -Green’s-functions.

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (9.15)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (9.16)
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (9.17)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

  -- -------- -------- -------- --
     @xmath   @xmath            
                       @xmath   
                       @xmath   
                       @xmath   
              @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

  -- -------- -------- -------- -------- --------
     @xmath   @xmath                     (9.19)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

#### 9.1.2 The @xmath-Green’s-Functions

The path integral for the @xmath -vacuum-expectation value is given by:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.20)
                                @xmath   
  -- -------- -------- -------- -------- --------

where @xmath is given by ( 9.12 ). This action only depends on @xmath ,
which reflects the @xmath -invariance of the @xmath linear sigma model.
This means that if we shift all @xmath -fields (i.e. the @xmath -fields
at all space-time points) by the same amount the action does not change.
Also the path-integral measure does not change. So we can show:

  -- -------- -- --------
     @xmath      (9.21)
  -- -------- -- --------

such that

  -- -------- -- --------
     @xmath      (9.22)
  -- -------- -- --------

For the same reason we have that

  -- -------- -- --------
     @xmath      (9.23)
  -- -------- -- --------

Notice that we have been able to show this through a non-perturbative
argument. This is the great merit of a calculation via the path integral
in terms of polar fields.

The @xmath - and @xmath -propagator can be calculated in a similar way:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
                       @xmath      
                       @xmath      
              @xmath   @xmath      
                       @xmath      
                       @xmath      
                       @xmath      
              @xmath   @xmath      
                       @xmath      
                       @xmath      
              @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.24)
  -- -------- -------- -------- -- --------

Here we could discard the cosine of the sum @xmath because this cosine
is not invariant under a global shift of the @xmath -field, i.e. this
cosine is not @xmath -invariant.

The cosine of the difference of two @xmath -fields can now be expanded,
because a difference of two @xmath ’s can always be written as an
integral over @xmath , which is small. (Remember @xmath .)

Then the @xmath - and @xmath -Green’s-functions we have calculated in
the previous section can be used to find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.25)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

If we compare this result to the result for the @xmath - and @xmath
-propagator ( 7.13 ), obtained in chapter 7 , we find that both results
agree. So, although it was far from obvious that the simple calculation
done in chapter 7 was correct, the result agrees with the proper
calculation done in this chapter.

#### 9.1.3 Schwinger-Dyson Check

We can check the result ( 9.25 ) by substituting it in the
Schwinger-Dyson equations of the @xmath linear sigma model. This check
is most conveniently done on the level of the unrenormalized action.

The Schwinger-Dyson equations for the propagator can be derived through
the Schwinger-Symanzik equations:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.26)
  -- -------- -------- -------- -- --------

Substituting the unrenormalized action of our @xmath linear sigma model,
operating on both sides of the first Schwinger-Symanzik equation with
@xmath and finally putting all sources to zero we find the
Schwinger-Dyson equation for the propagator:

  -- -------- -- --------
     @xmath      (9.27)
  -- -------- -- --------

Now we will check the result ( 9.25 ). First we have to know the
4-points Green’s functions however (not including counter terms).

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.28)
  -- -------- -- --------

Substituting the results from section 9.1.1 gives:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.29)
  -- -------- -- --------

Now, substituting this and the propagator ( 9.25 ) with all the counter
terms set to zero in the Schwinger-Dyson equation ( 9.27 ) we find that
the equation is satisfied.

#### 9.1.4 The Canonical @xmath-Propagator

From our path integral in terms of polar field variables we can also
recover the @xmath -propagator one would find in the canonical approach.
To this end we have to ignore the fact that

  -- -------- -- --------
     @xmath      (9.30)
  -- -------- -- --------

Instead we have to expand both cosines around @xmath , although this is
actually incorrect in the path-integral approach. Expanding the cosines
around @xmath here corresponds to doing perturbation theory around one
minimum, where we also ignore the damping in the @xmath -direction and
replace the ring by an infinite line. In this case we obtain:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.31)
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

This propagator agrees with the @xmath -propagator we found in the
canonical approach ( 6.10 ).

In this @xmath -propagator we can substitute the counter terms ( 6.24 )
that we found in chapter 6 . Then this result will satisfy the
renormalization conditions from chapter 6 .

Also this propagator can be substituted in the Schwinger-Dyson equation,
together with the result for @xmath in this approach, where we expand
around @xmath . These results also satisfy the Schwinger-Dyson equation.
This demonstrates that both the canonical and path-integral approach
give proper solutions to the Schwinger-Dyson equations of the @xmath
linear sigma model.

Now we can also clearly see the difference between results from the
canonical and path-integral approach. (Compare ( 9.31 ) to ( 9.25 ).)

### 9.2 1-Dimensional Calculation

In this section we shall calculate @xmath and the @xmath -propagator for
the 1-dimensional @xmath linear sigma model using the 1-dimensional path
integral in terms of polar fields ( 8.106 ). In section 8.7 we already
used this formula to compute some Green’s functions for the arctangent
toy model. We saw there that to compute Green’s functions we first have
to know @xmath and we calculated @xmath for the case of the arctangent
toy model. From this result we can easily get @xmath for the @xmath
linear sigma model. By looking at the definition of @xmath we see that
we can get @xmath for the sigma model by putting @xmath in the @xmath
for the arctangent toy model. So we find the simple result:

  -- -------- -- --------
     @xmath      (9.32)
  -- -------- -- --------

In this strictly 1-dimensional calculation we shall not renormalize.

#### 9.2.1 @xmath

For @xmath we thus find:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.33)
                                @xmath   
  -- -------- -------- -------- -------- --------

This is a normal one-dimensional path integral that we can calculate in
the continuum. The minimum of the action is at @xmath , where @xmath is
defined by:

  -- -------- -- --------
     @xmath      (9.34)
  -- -------- -- --------

We can calculate @xmath up to a certain order in @xmath . We want our
final answer of the expectation value of @xmath up to order @xmath .
Then we should also know @xmath up to this order. This is readily
calculated:

  -- -------- -- --------
     @xmath      (9.35)
  -- -------- -- --------

Now we use the saddle-point method and expand the action in ( 9.33 )
around @xmath :

  -- -------- -- --------
     @xmath      (9.36)
  -- -------- -- --------

In the action we can discard terms of order @xmath or higher. In the
continuum limit the action becomes:

  -- -------- -- --------
     @xmath      (9.37)
  -- -------- -- --------

Notice that the term of order @xmath ( @xmath ) exactly drops out of the
action.

Finally we get for @xmath :

  -- -------- -- --------
     @xmath      (9.38)
  -- -------- -- --------

The last term gives the following contributions (We define again @xmath
.):

  -- -- -------- -------- -- --------
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      
        @xmath   @xmath      (9.39)
  -- -- -------- -------- -- --------

Summing everything we get for @xmath :

  -- -------- -- --------
     @xmath      (9.40)
  -- -------- -- --------

Does this agree with the @xmath -dimensional continuum calculation? In
this @xmath -dimensional calculation @xmath is given by:

  -- -------- -- --------
     @xmath      (9.41)
  -- -------- -- --------

We have computed the @xmath -dimensional result for @xmath in section
9.1.1 . To compare we first have to set all counter terms in the @xmath
-dimensional result from section 9.1.1 to zero, because we did not
renormalize in the 1-dimensional case. Also we have to realize that the
@xmath -dimensional result contains infrared divergent loop integrals.
These infrared divergences have to be regularized. The most
straightforward way to regularize them is to introduce a mass @xmath for
the @xmath -field. However then we would have to do the computation of
@xmath in section 9.1.1 all over again. In @xmath from section 9.1.1 all
terms of order @xmath are absent, we need those terms now. For example a
term

  -- -------- -- --------
     @xmath      (9.42)
  -- -------- -- --------

will give a finite contribution in @xmath , it gives @xmath plus terms
of order @xmath .

A more convenient way to regularize the infrared divergences is to use
dimensional regularization. In this scheme we have, for @xmath :

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.43)
  -- -------- -------- -------- -- --------

Substituting these results and the results for the other standard
integrals for @xmath (see appendix A ) in @xmath from section 9.1.1 we
find indeed the same result as ( 9.40 ).

The results of the standard integrals above can be found conveniently by
the Mellin-Barnes technique. This technique is studied extensively in
the literature, see the book by Smirnov [ 36 ] and articles by Bollini
et al. [ 37 ] , Smirnov [ 38 ] , Tausk [ 39 ] , Czakon [ 40 ] and
Anastasiou et al. [ 41 ] .

#### 9.2.2 The @xmath-Propagator

Now we wish to calculate the @xmath -propagator. For this we need to
know @xmath . We shall use the following formula:

  -- -------- -- --------
     @xmath      (9.44)
  -- -------- -- --------

Now when we take the average over @xmath the last term will give zero
since it is not invariant under a global shift of the @xmath ’s. We get:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.45)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

We should calculate the quantities @xmath . Now, as can easily be seen
from the path integral the variables @xmath have a Gaussian
distribution. So the variables @xmath , which are sums of these
variables, also have a Gaussian distribution. So we can use the Wick
expansion for the averages @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.46)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Now we know @xmath :

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.47)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Here the prime denotes the discrete derivative again, as defined in (
8.128 ). Now we finally get:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.48)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Now the complete propagator becomes:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.49)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

We expand again around @xmath . Also the last exponent in ( 9.49 )
should be expanded:

  -- -- -- -------- -------- --------
           @xmath            (9.50)
           @xmath   @xmath   
           @xmath   @xmath   
  -- -- -- -------- -------- --------

Remember that we only wish to calculate everything up to order @xmath ,
so the terms which are indicated by the dots in ( 9.50 ) are unimportant
to us. For the @xmath -propagator we get:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.51)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (9.52)
  -- -------- -- --------

The fraction in this expression can be computed in the ordinary way by
using Feynman diagrams. In all @xmath ’s occurring in ( 9.51 ) there are
@xmath ’s. We should also expand all of these around @xmath .

  -- -------- -- --------
     @xmath      (9.53)
  -- -------- -- --------

We will not expand the exponential on the right-hand side around @xmath
but leave it as an overall factor. If we would expand this exponential
as well it would no longer be directly apparent that the propagator goes
to zero if the distance between @xmath and @xmath becomes large. All the
rest we will expand up to order @xmath .

  -- -- -- -------- -------- --------
           @xmath            (9.55)
           @xmath   @xmath   
                    @xmath   
                    @xmath   
           @xmath   @xmath   
                    @xmath   
                    @xmath   
                    @xmath   
                             
           @xmath   @xmath   
                    @xmath   
                    @xmath   
  -- -- -- -------- -------- --------

Finally we get for the complete @xmath -propagator:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Does this result agree with the @xmath -dimensional continuum
calculation? It does, however first we have to expand the exponential

  -- -------- -- --------
     @xmath      (9.57)
  -- -------- -- --------

because the @xmath -dimensional result ( 9.25 ) is a perturbative series
in @xmath , whereas the exponential above is not. Secondly we have to
set all counter terms in ( 9.25 ) to zero. Thirdly we have to realize
that ( 9.25 ) contains infrared divergences. These are most conveniently
regularized again in the dimensional regularization scheme. In this
scheme we have:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.58)
  -- -------- -------- -------- -- --------

These integrals can again easily be calculated with the Mellin-Barnes
technique. Substituting these results in ( 9.25 ) gives indeed the
result ( LABEL:onedimfprop ).

There is a difference between ( LABEL:onedimfprop ) and ( 9.25 )
however. In ( LABEL:onedimfprop ) we see that the propagator goes to
zero for large @xmath . Only when we expand the exponential that causes
this behavior we recover the result ( 9.25 ) we get from the @xmath
-dimensional continuum calculation specified to @xmath . How do we
recover the exponential from the @xmath -dimensional continuum
calculation?

#### 9.2.3 Recovering (LABEL:onedimfprop)

To recover the 1-dimensional result ( LABEL:onedimfprop ) completely
from the @xmath -dimensional continuum result ( 9.25 ) we actually also
need (parts of) higher order terms in ( 9.25 ). It will appear that the
momentum-space version of ( 9.25 ) has terms like:

  -- -------- -- --------
     @xmath      (9.59)
  -- -------- -- --------

when these higher order terms are included. (Here we have calculated in
the dimensional regularization scheme.) For @xmath these terms are
exactly what we get when transforming the exponential

  -- -------- -- --------
     @xmath      (9.60)
  -- -------- -- --------

to momentum space (in the dimensional regularization scheme). In this
way we can in principle recover the result ( LABEL:onedimfprop ) from
the @xmath -dimensional result ( 9.25 ), although in practice we can
never compute the terms of arbitrarily high order.

Considering the one-dimensional result, and knowing that we have to
re-sum part of it to obtain the true propagator, which drops to zero
nicely for large distances, a good question would be: Should we also
re-sum in @xmath dimensions? If this were the case, then our result (
9.25 ) would still be incomplete, in the sense that we also need higher
order terms to see the true physics. Fortunately this is not the case.
The reason is as follows.

In one dimension the terms ( 9.59 ) all come from the @xmath
-propagator. (Here we mean the @xmath -propagator from chapter 7 .)
These terms generate a mass for the @xmath -particle. In configuration
space this is mirrored by the exponential ( 9.60 ), from which we can
read off a mass

  -- -------- -- --------
     @xmath      (9.61)
  -- -------- -- --------

Now the Goldstone theorem tells us that if we have spontaneous symmetry
breaking, the Goldstone boson is massless, and stays massless at all
orders in perturbation theory. In our case @xmath is the Goldstone boson
in the canonical approach. For @xmath we do not have SSB (see [ 31 , 32
] ), so the Goldstone theorem does not forbid that a mass is generated
for the @xmath -particle. In fact, we have seen that a mass is
generated. For @xmath we do have SSB in the canonical approach, and the
Goldstone theorem forbids that a mass is generated. As a consequence the
terms

  -- -------- -- --------
     @xmath      (9.62)
  -- -------- -- --------

do not occur in the @xmath -propagator. And thus there is nothing to
re-sum, and the result ( 9.25 ) can be considered complete in the sense
that higher order terms will not cause the propagator to drop to zero
for large distances. This means we are not missing any important physics
by only having the @xmath - and @xmath -propagator up to order @xmath .

The case @xmath is a special case, see also [ 31 , 32 ] .

### 9.3 The Effective Potential

We can also calculate the effective potential via the path integral in
terms of polar fields. To this end we introduce source terms in the
renormalized action:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.63)
                                @xmath   
  -- -------- -------- -------- -------- --------

In chapter 7 we already computed the effective potential for the @xmath
linear sigma model. However there we had to discard the term ( 7.24 ) to
avoid ending up with an expression that contained infrared divergences
at order @xmath . Also we could not find the interpolation of the
effective potential between small @xmath (order @xmath ) and @xmath of
order 1 ( @xmath ). In this section we shall see if we can do a better
job by calculating in terms of polar fields.

According to the conjecture the action in terms of polar fields is

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.64)
                                @xmath   
  -- -------- -------- -------- -------- --------

provided we calculate in a @xmath -dimensional way in the continuum.

Introducing

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.65)
  -- -------- -------- -------- -- --------

the minimum of the first line of the action, i.e. the classical action,
is given by:

  -- -------- -- --------
     @xmath      (9.66)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (9.67)
  -- -------- -- --------

Expanding the action around the minimum,

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.68)
  -- -------- -------- -------- -- --------

we find:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

According to the conjecture the generating functional is now given by:

  -- -------- -- --------
     @xmath      (9.70)
  -- -------- -- --------

As can easily be seen from the action we have one minimum for @xmath ,
whereas we have a ring of minima for @xmath . This means that for @xmath
of order 1 it is correct to expand the cosine of @xmath . In that case
we recover the effective potential from the canonical approach. This is
expected because for large @xmath it is correct to take into account
only one minimum. For small @xmath , i.e. @xmath of order @xmath things
are a bit more difficult. For such small @xmath there is strictly
speaking still one minimum, but the ring is so flat that it is incorrect
to ignore the other points. We know this because when @xmath becomes
really zero the other points in the ring start to play an important
role. What we can do is the following. We write the generating
functional as:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.71)
                                @xmath   
  -- -------- -------- -------- -------- --------

with @xmath given by:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Note that in the new action @xmath only @xmath occurs. Now focus on the
part that we pulled out of the action:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.73)
  -- -------- -- --------

We are going to combine the cosines into a sum of single cosines.
Because the action @xmath only depends on @xmath only the @xmath
-invariant cosines are going to survive in the path integral. This
means, when combining the cosines, all cosines with an unequal number of
@xmath ’s and @xmath ’s are going to vanish under the path integral.

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Now we can expand the cosine, because it contains only differences of
two @xmath ’s. Such differences can be written as an integral over
@xmath . From the path integral it can be seen that @xmath is small (of
order @xmath ), such that it is indeed correct to expand the cosine.
Keeping the first and second term from the expansion of the cosine we
find:

  -- -------- -- --------
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      
     @xmath      (9.75)
  -- -------- -- --------

Here @xmath is a modified Bessel function of the first kind.

We can see clearly here that, if @xmath is of order 1, the first and
second term are of the same magnitude (both order 1). This means that
when @xmath is of order 1 we need all terms of the expansion of the
cosine. This mirrors the fact that for @xmath of order 1 there is one
clear minimum and the cosine plays a crucial role in determining where
this minimum is located. Keeping all the terms of the expansion of the
cosine is very hard in an actual computation, so the formula above is
not very convenient to find the generating functional for @xmath of
order 1.

It is convenient for @xmath of order @xmath however, in this case we see
that the first term above is of order 1, while the second term is of
order @xmath . This means discarding the higher order term seems to be a
good approximation. Discarding these terms means the generating
functional is correct up to order @xmath . Also discarding other terms
of higher order than @xmath we find for the generating functional:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (9.76)
                                @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

Here we have also expanded @xmath ,

  -- -------- -- --------
     @xmath      (9.77)
  -- -------- -- --------

and @xmath denotes the space-time volume. Also in the action @xmath
terms of higher order than @xmath should be discarded. (There is a
@xmath in front of the action.) In the Jacobian we should discard all
terms of order higher than @xmath .

From the formula above one could in principle calculate the generating
functional, and from it the @xmath - and @xmath -expectation-value, all
up to order @xmath . The expectation values are given by:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            
              @xmath   @xmath            
     @xmath   @xmath   @xmath            (9.78)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- --------

Notice that the generating functional does not depend on the direction
of the source @xmath . From these expectation values one can then find
the effective potential.

However, when calculating the generating functional one encounters
infrared divergences again. The reason is the same as in chapter 7 . The
formula above is only valid for small @xmath , whereas we saw already in
the canonical approach that to avoid the infrared singularities we need
all @xmath -points Green’s functions. So we also need to know @xmath for
all @xmath , which is very hard, as we saw above. In chapter 7 we could
find a result (up to order @xmath ) without infrared divergences by
discarding the term ( 7.24 ), which caused the infrared divergences at
order @xmath . In the formula above it is not clear what we can do to
avoid the infrared divergences.

It is however easy to find the @xmath - and @xmath -expectation-values
at lowest order from the formula for @xmath above. We find:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (9.79)
  -- -------- -------- -------- -- --------

and

  -- -------- -- --------
     @xmath      (9.80)
  -- -------- -- --------

which agrees with the results from chapter 7 .

The important thing however, even though we have not been able to
explicitly calculate the effective potential up to order @xmath in this
approach, or find the interpolating form of the effective potential
between the cases @xmath and @xmath , is that the effective potential we
find is flat at the origin. This means we find the Maxwell construction
of the effective potential from the canonical approach. And we find a
convex effective potential, as it should be in the path-integral
approach.

From the formula ( 9.80 ) one can also clearly see that it matters for
the 1-point Green’s function, or tadpole, in which order the limits
@xmath and @xmath are taken. If we first take @xmath , and then @xmath ,
then ( 9.80 ) becomes zero. This corresponds to the path-integral
approach.

If we first take @xmath , and only then @xmath , then ( 9.80 ) becomes
@xmath , which corresponds to the canonical approach.

## Chapter 10 Conclusions

The most fundamental theory of nature known at present day is the
‘Standard Model’. This theory agrees very well with experimental
results. All particles that are predicted in the Standard Model have
also been detected in experiments, except for one: the Higgs boson. The
existence of this Higgs boson in the Standard Model is derived within
this model via what we call ‘the canonical approach’.

In the canonical approach one takes a classical field theory and
quantizes it by imposing certain commutation or anti-commutation
relations on the fields. The particle content of the theory is found by
solving the time independent Schrödinger equation. One can find the
vacuum state, i.e. the lowest energy state, via this equation, and one
can build a whole Fock space on this vacuum state. The time evolution of
the states is governed by the time evolution operator. Via this time
evolution operator one can derive the Schwinger-Dyson equations. These
equations tell one about the probability amplitudes for certain physical
processes.

In the Higgs sector of the Standard Model the time independent
Schrödinger equation is too hard to actually solve. Therefore one
postulates some properties of the vacuum state, inspired by the
classical lowest energy state. For example, one assumes that the vacuum
expectation value of the Higgs field is non-zero, after which one can
construct the Fock space. This assumption is also very important when
solving the Schwinger-Dyson equations. These Schwinger-Dyson equations
can be solved iteratively. In this way one obtains a perturbative series
for the Green’s functions of the theory. Assuming that the vacuum
expectation value of the Higgs field is non-zero one finds the Green’s
functions of the canonical approach. This canonical approach is
completely self-consistent.

Another formulation of quantum field theory is the so-called
path-integral formulation. The path integral is merely a solution to the
Schwinger-Dyson equations, like the perturbative series mentioned above.
For ordinary theories the path-integral formulation is just another
formulation of the theory, it gives the same physical results. The
Green’s functions in both formulations come out to be the same.

However, in theories for which the canonical approach predicts
spontaneous symmetry breaking, it appears that both formulations of the
same quantum field theory do not yield identical results. This was the
central topic of this thesis. We have calculated Green’s functions for
two such theories, for which the canonical approach predicts SSB.
Surprisingly it appeared that, indeed, the path-integral approach gives
very different Green’s functions than the canonical approach.

For example, the effective potential in the canonical approach is not
convex, although one can derive, via the path-integral formulation that
an effective potential should always be convex. This is known as the
convexity problem. However, it is not really a problem, because the
convexity is derived in the path-integral formulation of the theory. If
we accept that the canonical approach and the path-integral approach are
different , then the problem is resolved.

The first model we have studied is the Euclidean version of the @xmath
linear sigma model. There we clearly saw that the Green’s functions from
the canonical approach and the path-integral approach are different .
The canonical Green’s functions can be obtained from the path integral
by, for some reason, only taking into account one minimum. We also saw
that the divergences in both approaches are identical, meaning that one
can use the same counter terms in both approaches to make everything
finite. We also calculated the effective potential in the path-integral
approach and found it to be well-defined and convex, as it should be on
grounds of general arguments.

We also studied the path-integral approach to this model where we now
fix the paths in the path integral at some point in time over all of
space. In this case we saw that we reproduce the canonical Green’s
functions. Thus it is possible to get the physics from the canonical
approach from a path-integral approach, however in order to obtain this
we have to fix the paths. Also in this case the divergences are the same
as in the canonical approach. We also found the (alternative) effective
potential, and found it to be convex.

The second model that we studied was the @xmath Euclidean linear sigma
model. Here we saw again that the Green’s functions obtained in the
canonical and path-integral approach are very different. Divergences are
identical in both approaches again. In chapter 7 we first tried a naive
approach, making some questionable steps, to take into account all
minima of the path integral. In chapter 9 we performed a more rigorous
calculation of the path integral, based on the path integral in terms of
polar fields. Results appeared to be the same. Also we obtained the
effective potential of the @xmath LSM within the path-integral approach
and found it to be convex.

With all these calculations we have established that, in the case of a
theory which exhibits SSB in the canonical approach, the path-integral
approach gives different Green’s functions, which may indicate different
physics. This brings up some interesting questions related to the Higgs
sector of the Standard Model. The prediction of the Higgs particle and
its interaction are all based on the canonical approach. What if we
treat the Higgs sector of the Standard Model not in the canonical way,
but instead via the path integral? What would the phenomenology of such
an approach be? Could we build a theory without a Higgs particle in this
way, or could we explain why the Higgs particle has not been found up to
now?

The first step to answer these questions would be to look at the
phenomenology of the @xmath LSM and the @xmath LSM. This is still
unknown territory, which marks the end of this thesis, but hopefully
also the beginning of a new quest to resolve the mysteries surrounding
‘the holy grail of particle physics’.

## Appendix A Standard Integrals

Throughout this thesis we have introduced the following standard
integrals:

  -- -------- -- -------
     @xmath      
                 (A.1)
  -- -------- -- -------

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (A.2)
     @xmath   @xmath   @xmath      (A.3)
     @xmath   @xmath   @xmath      (A.4)
     @xmath   @xmath   @xmath      (A.5)
     @xmath   @xmath   @xmath      (A.6)
     @xmath   @xmath   @xmath      (A.7)
     @xmath   @xmath   @xmath      (A.8)
  -- -------- -------- -------- -- -------

In this appendix we list several results for standard integrals, which
are used in our computations throughout this thesis.

### a.1 @xmath

For @xmath the standard integrals that we come across in calculations
are not divergent. Therefore it is not necessary to introduce a
regularization scheme. The following results are used in this thesis:

  -- -------- -------- -------- -------- --------
     @xmath   @xmath   @xmath            (A.9)
     @xmath   @xmath   @xmath            (A.10)
     @xmath   @xmath   @xmath            (A.11)
     @xmath   @xmath   @xmath            (A.12)
     @xmath   @xmath   @xmath            (A.13)
     @xmath   @xmath   @xmath            (A.14)
     @xmath   @xmath   @xmath            (A.15)
     @xmath   @xmath   @xmath            (A.16)
     @xmath   @xmath   @xmath            (A.17)
     @xmath   @xmath   @xmath            (A.18)
     @xmath   @xmath   @xmath            (A.19)
     @xmath   @xmath   @xmath            (A.20)
     @xmath   @xmath   @xmath            (A.21)
     @xmath   @xmath   @xmath            (A.22)
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- --------

### a.2 @xmath

For @xmath some of the standard integrals that we encounter are
divergent, and we have to introduce a regularization scheme. We will
calculate these integrals in the dimensional regularization scheme. The
following results are used in this thesis:

  -- -------- -------- -------- -- --------
     @xmath   @xmath   @xmath      (A.23)
     @xmath   @xmath   @xmath      (A.24)
     @xmath   @xmath   @xmath      (A.25)
     @xmath   @xmath   @xmath      (A.26)
  -- -------- -------- -------- -- --------

  -- -------- -- --------
     @xmath      (A.27)
  -- -------- -- --------

with

  -- -------- -- --------
     @xmath      (A.28)
  -- -------- -- --------