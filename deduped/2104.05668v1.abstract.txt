Zero-shot learning (ZSL) aims at recognizing unseen class examples (e.g.,
images) with knowledge transferred from seen classes. This is typically
achieved by exploiting a semantic feature space shared by both seen and unseen
classes, e.g., attributes or word vectors, as the bridge. In ZSL, the common
practice is to train a mapping function between the visual and semantic feature
spaces with labeled seen class examples. When inferring, given unseen class
examples, the learned mapping function is reused to them and recognizes the
class labels on some metrics among their semantic relations. However, the
visual and semantic feature spaces are generally independent and exist in
entirely different manifolds. Under such a paradigm, the ZSL models may easily
suffer from the domain shift problem when constructing and reusing the mapping
function, which becomes the major challenge in ZSL. In this thesis, we explore
effective ways to mitigate the domain shift problem and learn a robust mapping
function between the visual and semantic feature spaces. We focus on fully
empowering the semantic feature space, which is one of the key building blocks
of ZSL. In summary, this thesis targets fully empowering the semantic feature
space and design effective solutions to mitigate the domain shift problem and
hence obtain a more robust visual-semantic mapping function for ZSL. Extensive
experiments on various datasets demonstrate the effectiveness of our proposed
methods.