# Acknowledgements

I would like to thank my supervisor, Professor Matt Visser for his
guidance and support. I am lucky to have such an active and hard working
supervisor. I really appreciate the effort he made for my thesis, making
sure that things got done properly and on time.

I am grateful to the School of Mathematics, Statistics, and Operations
Research for providing me with an office and all the facilities, and the
Thai Government Scholarship that provided me with funding.

I also would like to say thanks to my family who were also very
supportive and listened to me.

Finally, I would like to extend my gratitude to my friends, Adisorn
Juntrasook, Nattakarn Kajohnwongsatit, Trin Sunathvanichkul, Jirayu
Chotimongkol, Narit Pidokrajt, Anon Khamwon, Celine Cattoen, and Garoon
Pongsart for always being there to listen to me. I am not sure that this
thesis would have been finished without the support they showed.

## Preface

This thesis looks at a number of problems related to the derivation of
rigorous bounds on transmission, reflection, and Bogoliubov
coefficients: To set the stage, we shall first briefly describe the
general ideas underlying the Schrödinger equation, and the concept of
the WKB approximation for barrier penetration probability. In addition,
we shall present a discussion of some general features of scattering
theory in one space dimension. By considering one-dimensional problems
involving an incident beam of particles, we shall derive an important
connection between reflection and transmission amplitudes. Furthermore,
we shall collect several known analytic results, and show how they
relate to the general results presented in this thesis. We shall also
review and concisely describe the concept of quasinormal modes , and see
how most of the concepts introduced here are important tools for
comparing the bounds derived in the body of the thesis with known
analytic results.

The technical heart of the thesis is this: We shall rewrite the
second-order Schrödinger equation as a set of two coupled first-order
linear differential equations (for which bounds can relatively easily be
established). Systems of differential equations of this type are often
referred to as Shabat–Zakharov systems or Zhakarov–Shabat systems. After
this initial investigation, we shall use this system of ODEs to derive
our first bound, and then continue by finding several slightly different
ways of recasting the Schrödinger equation as a 1st-order
Shabat–Zakharov system, in this way deriving a number of slightly
different bounds.

Regarding the chapter “Bounding the Bogoliubov coefficients”, we have
developed a distinct method for deriving general bounds on the
Bogoliubov coefficients, providing a largely independent derivation of
the key results; a seperate derivation that short-circuits much of the
technical discussion.

Proceeding further along this branch of our investigation, we shall
consider the Regge–Wheeler equation for excitations of a scalar field
defined on a Schwarzschild spacetime, and adapt the general analysis of
the previous chapters to this specific case. We shall demonstrate that
rigorous and explicit analytic bounds are indeed achievable. While these
bounds may not answer all the physical questions one might legitimately
wish to ask, they are definitely a solid step in the right direction.

We shall then use the Miller–Good transformation (which maps an initial
Schrödinger equation to a final Schrödinger equation for a different
potential) to significantly generalize the previous bound. Moreover, we
shall then use the Miller–Good transformation to generalize the bound to
make it more efficient.

Finally we shall consider analytic bounds on the transmission
probabilities obtained by comparing a simple “known” potential with a
more complicated “unknown” one. In this case we shall obtain yet another
(distinct) Shabat–Zakharov system and use it to (partially and formally)
“solve” the scattering problem. In this case we can derive both upper
and lower bounds on the transmission coefficients and related Bogoliubov
coefficients.

### Chapter by chapter outline

This thesis is divided into twelve main chapters. The first chapter is
devoted to describing the general ideas of the Schrödinger equation and
the concepts of WKB approximation for barrier penetration probability.
Furthermore, we introduce the concept of the classical turning point,
which is one of the key ideas in developing the WKB estimate. Moreover,
these general concepts are important for understanding the bounds we
will derive on transmission and reflection in Bogoliubov coefficients.

In chapter 2 , we shall introduce scattering theory in one space
dimension. This is an elegant topic that is mathematically simple and
physically transparent. We shall apply the Schrödinger equation to a
generic system to identify the potential-energy function. Furthermore,
we shall derive a significant relationship between reflection and
transmission amplitudes by considering one-dimensional problems with an
incident beam of particles.

In chapter 3 , we shall concentrate our attention on collecting several
known analytic results, and show how they relate to the general results
presented in this thesis. We shall review and briefly describe the
concept of quasinormal modes , and see how most of the concepts
introduced here are important for comparing the bounds we shall derive
with known analytic results. By taking specific cases of these bounds
and related results it is possible to reproduce many analytically known
results, such as those for the delta-function potential,
double-delta-function potential, square potential barrier, @xmath
potential, @xmath potential, asymmetric square-well potential, the
Poeschl–Teller potential and its variants, and finally the general
Eckart–Rosen–Morse–Poeschl–Teller potential.

The next two chapters, chapter 4 and chapter 5 , can be seen as two
deeply interconnected chapters. The key idea in chapter 4 is to recast
the Schrödinger equation as a 1st-order Shabat–Zakharov system. In
chapter 5 , we shall use the Shabat–Zakharov system of ODEs to derive
our first bound on the transmission, reflection, and Bogoliubov
coefficients.

In chapter 6 , we shall deal with some specific cases of these bounds
and develop a number of interesting specializations. We shall collect
together a large number of results that otherwise appear quite
unrelated, including reflection above and below the barrier. In
addition, we have divided the special case bounds we consider into five
special cases: special cases @xmath — @xmath , and “future directions”.
At the end of this chapter, we take further specific cases of these
bounds and related result to reproduce many analytically known results.

In chapter 7 , we shall re-cast and represent these bounds in terms of
the mathematical structure of parametric oscillations. This
time-dependent problem is closely related to the spatial properties of
the time-independent Schrödinger equation.

In chapter 8 , we shall re-assess the general bounds on the Bogoliubov
coefficients developed in [ 88 ] , providing a new and largely
independent derivation of the key results, one that short-circuits much
of the technical discussion in [ 88 ] .

In chapter 9 , we shall develop a complementary set of results— we shall
derive several rigorous analytic bounds that can be placed on the
greybody factors. Furthermore, we shall consider the greybody factors in
black hole physics, which modify the naive Planckian spectrum that is
predicted for Hawking radiation when working in the limit of geometrical
optics.

In chapter 10 , we shall use the Miller–Good transformation (which maps
an initial Schrödinger equation to a final Schrödinger equation for a
different potential) to significantly generalize the previous bound. At
the end of this chapter, we shall discuss the possibility of using the
Miller–Good transformation to derive generalized special-case bounds to
make them more efficient.

In chapter 11 , we shall develop a new set of techniques that are more
amenable to the development of both upper and lower bounds. Moreover, we
shall derive significantly different results (a number of rigorous
bounds on transmission probabilities for one dimensional scattering
problems), of both theoretical and practical interest.

In chapter 12 , we finally conclude with a brief discussion of lessons
learned from these rigorous bounds on transmission, reflection, and
Bogoliubov coefficients.

### Structure of the thesis

This thesis has been written with the goal of being accessible to people
with a basic background in non-relativistic quantum physics, especially
in transmission, reflection, and Bogoliubov coefficients.
Mathematically, the key feature is an analytic study of the properties
of second-order linear differential equations, and the derivation of
analytic bounds on the growth of solutions of these equations.

This thesis is made up of twelve chapters and five appendices. Four of
the appendices are papers published or submitted on work relating to
this thesis. All of them were produced in collaboration with my
supervisor, Professor Matt Visser. At the time of writing three papers
have been published [ 89 , 90 , 91 ] , and the latest has been submitted
for refereeing [ 92 ] .

### Use of references

Regarding referencing — For completely non controversial background
information (and only for completely noncontroversial items) we will
often just reference Wikipedia or similar reasonably definitive web
resources. For more technical information, especially recent research,
we will always directly cite the appropriate scientific literature.

###### Contents

-    Acknowledgements
-    Preface
-    1 General introduction
    -    1.1 Introduction
    -    1.2 The Schrödinger Equation
        -    1.2.1 The time-independent Schrödinger equation
        -    1.2.2 The time-dependent Schrödinger Equation
    -    1.3 WKB approximation
    -    1.4 Classical turning points
    -    1.5 Discussion
-    2 Scattering problems
    -    2.1 Introduction
    -    2.2 Reflection and Transmission Probabilities
    -    2.3 Probability currents
    -    2.4 Reflection and Transmission of Waves in unbound states
    -    2.5 Bogoliubov transformation
    -    2.6 Transfer matrix representation
    -    2.7 Discussion
-    3 Known analytic results
    -    3.1 Introduction
    -    3.2 Delta–function potential
    -    3.3 Double-delta-function potential
    -    3.4 Square barrier
    -    3.5 Tanh potential
    -    3.6 Sech @xmath potential
    -    3.7 Asymmetric Square-well potential
    -    3.8 Poeschl–Teller potential
    -    3.9 Eckart–Rosen–Morse–Poeschl–Teller potential
    -    3.10 Mobius potential
    -    3.11 Other potentials:
    -    3.12 Discussion
-    4 Shabat–Zakharov systems
    -    4.1 Introduction
    -    4.2 Ansatz
    -    4.3 Probability current
    -    4.4 SDE as a first order system
    -    4.5 Bounding the coefficients @xmath and @xmath
        -    4.5.1 Case: @xmath
        -    4.5.2 Case: @xmath
        -    4.5.3 Case: @xmath
    -    4.6 Discussion
-    5 First derivation of the bounds
    -    5.1 Introduction
    -    5.2 Shabat–Zakharov systems
    -    5.3 Bounds
    -    5.4 Transfer matrix representation
    -    5.5 Discussion
-    6 Bounds: Special cases
    -    6.1 Bounds: Special case 1
    -    6.2 Bounds: special case 2
    -    6.3 Reflection above the barrier
    -    6.4 Under the barrier?
    -    6.5 Special case 2-a
    -    6.6 Special case 2-b
    -    6.7 Special case 2-c
    -    6.8 Bounds: Special case 3
    -    6.9 Bounds: Special case 4
    -    6.10 Bounds: Future directions
    -    6.11 Discussion
-    7 Parametric oscillations
    -    7.1 Introduction
    -    7.2 Special case 1
    -    7.3 Special case 2
    -    7.4 Special case 2-a
    -    7.5 Special case 2-b
    -    7.6 Special case 2-c
    -    7.7 Bounds: Special case 3
    -    7.8 Discussion
-    8 Bounding the Bogoliubov coefficients
    -    8.1 Introduction
    -    8.2 The second-order ODE
    -    8.3 Bogoliubov coefficients
    -    8.4 Elementary bound:
    -    8.5 Lower bound on @xmath
    -    8.6 A more general upper bound
    -    8.7 The “optimal” choice of @xmath ?
    -    8.8 Sub-optimal but explicit bounds
    -    8.9 The “interaction picture”
    -    8.10 Conclusion
-    9 Bounding the greybody factors
    -    9.1 Introduction
    -    9.2 Hawking radiation
    -    9.3 Regge–Wheeler equation
    -    9.4 Bounds
    -    9.5 Discussion
-    10 The Miller–Good transformation
    -    10.1 Introduction
    -    10.2 Setting up the problem
    -    10.3 The Miller–Good transformation
    -    10.4 Improved general bounds
    -    10.5 Some applications and special cases
        -    10.5.1 Schwarzian bound
        -    10.5.2 Low-energy improvement
        -    10.5.3 WKB-like bound
        -    10.5.4 Further transforming the bound
    -    10.6 Summary and Discussion
-    11 Analytic bounds on transmission probabilities
    -    11.1 Introduction
    -    11.2 From Schrödinger equation to system of ODEs
        -    11.2.1 Ansatz
        -    11.2.2 Probability density and probability current
        -    11.2.3 Second derivatives of the wavefunction
        -    11.2.4 SDE as a first-order system
        -    11.2.5 Formal (partial) solution
        -    11.2.6 First set of bounds
        -    11.2.7 Bogoliubov coefficients
        -    11.2.8 Second set of bounds
        -    11.2.9 Transmission probabilities
    -    11.3 Consistency check
    -    11.4 Keeping the phases?
    -    11.5 Application: Small shift in the potential
        -    11.5.1 First-order changes
        -    11.5.2 Particle production
        -    11.5.3 Transmission probability
    -    11.6 Discussion
-    12 Discussion
    -    12.1 What we have achieved
    -    12.2 The main analysis: Structure of the thesis
    -    12.3 Further interesting issues

###### List of Figures

-    2.1 Transmission and reflection amplitudes
-    3.1 Scattering for a @xmath -function potential
-    6.1 Potential and wave-number for special case 1
-    6.2 Sharp corners maximize reflection
-    7.1 Parameteric oscillations and Bogoliubov coefficients

###### List of Tables

-    3.1 Some exactly solvable potentials for which the transmission
    probability is explicitly known
-    3.2 Inter-relationships between selected “exactly solvable”
    potentials
-    12.1 Several ways to derive bounds for arbitrary wave phenomena

## Chapter 1 General introduction

### 1.1 Introduction

This chapter is an introduction to the topic of developing rigorous
bounds on transmission, reflection, and Bogoliubov coefficients. We
shall introduce the basic ideas underlying the Schrödinger equation, and
its application to the wave-function that describes the wavelike
properties of a subatomic system.

We shall also review the concept of the WKB approximation, which is an
important and significant method to derive approximate solutions for the
wave function. For instance, as we shall show, the WKB approach can be
used as a “basis” for formally writing down the exact solutions. Most
physicists, and many mathematicians, have seen how important the WKB
approximation is for estimating barrier penetration probability.
Unfortunately, the WKB approximation is an example of an uncontrolled
approximation, and we do not know if the resulting estimate is high or
low. As part of the main work reported in this thesis, we modify,
improve, and extend the approach originally developed by Visser [ 88 ] .

We shall derive a number of rigourous bounds on transmission
probabilities (and reflection probabilities, and Bogoliubov
coefficients) for one-dimensional scattering problems. The derivation of
these bounds generally proceeds by rewriting the Schrödinger equation in
terms of some equivalent system of first-order equations, and then
analytically bounding the growth of certain quantities related to the
net flux of particles as one sweeps across the potential.

While over the last century or more considerable effort has been put
into the problem of finding approximate solutions for wave equations in
general, and quantum mechanical problems in particular, it appears that
as yet relatively little work seems to have been put into the
complementary problem of establishing rigorous bounds on the exact
solutions. We have in mind either bounds on parametric amplification and
the related quantum phenomenon of particle production (as encoded in the
Bogoliubov coefficients), or bounds on transmission and reflection
coefficients.

In this thesis, we introduce and prove several rigorous bounds on the
Bogoliubov coefficients associated with a time-dependent potential, and
also derive several rigorous analytic bounds that can be placed on
barrier transmission probabilities. As a specific application, we shall
then explore greybody factors in black hole physics, which modify the
naive Planckian spectrum that is predicted for Hawking radiation when
working in the limit of geometrical optics.

Additionally, we will extend these ideas to address topics of
considerable general interest in quantum physics, such as transmission
through a potential barrier, and the related issue of particle
production from a parametric resonance. This is an example of finding
new physics (and new mathematics) in an old and apparently
well-understood area.

To begin with, we need to briefly describe the concept of the
Schrödinger equation , and the rationale behind the WKB estimate for
barrier penetration probability, otherwise the rigorous bounds on
transmission, reflection, and Bogoliubov coefficients will be difficult
to understand.

### 1.2 The Schrödinger Equation

The Schrödinger equation was discovered by the Austrian physicist Erwin
Schrödinger in 1925, it describes the space – and time – dependence of
the quantum amplitude that characterizes quantum mechanical systems [ 1
] .

Both Erwin Schrödinger and Werner Heisenberg independently developed
different versions of the “modern” quantum theory. Schrödinger’s method
relates to partial differential equations, whereas Heisenberg’s method
uses infinite-dimensional matrices.

However, both methods were soon shown to be mathematically equivalent.
Furthermore, from the modern viewpoint it seems very clear that
Schrödinger’s equation has a clearer physical interpretation via the
classical wave equation. Indeed, the Schrödinger equation can be shown
to be a form of the wave equation applied to matter waves [ 2 ] .

It is apparent that this equation defines the behaviour of the wave
function that describes the wavelike properties of a subatomic system.
Furthermore, it deals with the kinetic energy and potential energy, both
of which contribute to the total energy. It is solved to derive the
different energy levels of the system. More generally, Schrödinger
applied the equation to the hydrogen atom, and its properties can be
predicted with remarkable precision. It should be remarked that the
equation is applied widely in atomic, nuclear, and solid-state physics [
5 ] .

Actually there are two slightly different equations which go by
Schrödinger’s name as follows:

#### 1.2.1 The time-independent Schrödinger equation

We start with the one-dimensional classical wave equation [ 2 ] ,

  -- -------- -- ---------
     @xmath      (1.2.1)
  -- -------- -- ---------

Let us consider the separation of variables

  -- -------- -- ---------
     @xmath      (1.2.2)
  -- -------- -- ---------

which then leads to

  -- -------- -- ---------
     @xmath      (1.2.3)
  -- -------- -- ---------

When we introduce one of the standard wave equation solutions @xmath
such as @xmath , we easily obtain

  -- -------- -- ---------
     @xmath      (1.2.4)
  -- -------- -- ---------

It is now easy to “derive” (in the sense of a physicist’s plausibility
argument) an ordinary differential equation describing the spatial
amplitude of the matter wave as a function of position. We note that the
energy of a particle is the sum of kinetic and potential parts

  -- -------- -- ---------
     @xmath      (1.2.5)
  -- -------- -- ---------

which can be solved for the momentum, @xmath , to obtain

  -- -------- -- ---------
     @xmath      (1.2.6)
  -- -------- -- ---------

We now see that it is convenient to use the de Broglie formula to get an
expression for the (position dependent) wavelength

  -- -------- -- ---------
     @xmath      (1.2.7)
  -- -------- -- ---------

If we recall @xmath and @xmath , then the term @xmath in equation (
1.2.4 ) can be rewritten in terms of @xmath :

  -- -------- -- ---------
     @xmath      (1.2.8)
  -- -------- -- ---------

Additionally, when this result is substituted into equation ( 1.2.4 ),
we also “derive” the well-known time-independent Schrödinger equation,

  -- -------- -- ---------
     @xmath      (1.2.9)
  -- -------- -- ---------

Let us now rewrite the above equation in a more standardized form, we
get

  -- -------- -- ----------
     @xmath      (1.2.10)
  -- -------- -- ----------

We now have all the important information about our system. Moreover,
this single-particle one-dimensional equation can clearly be extended to
the case of three dimensions, where it becomes

  -- -------- -- ----------
     @xmath      (1.2.11)
  -- -------- -- ----------

A two-body problem can also be treated by this equation if the mass
@xmath is replaced by the reduced mass @xmath :

  -- -------- -- ----------
     @xmath      (1.2.12)
  -- -------- -- ----------

Nevertheless, it is important to point out that this analogy with the
classical wave equation only goes so far. We cannot, for example,
“derive” the time-dependent Schrödinger equation in an analogous
fashion, at least not without several additional hypotheses. (For
instance, the time-dependent Schrödinger equation involves the partial
first derivative with respect to time instead of the partial second
derivative.) Finally, we would like to comment that historically,
Schrödinger presented his time-independent equation first, and then went
back and postulated the more general time-dependent equation [ 2 ] .

#### 1.2.2 The time-dependent Schrödinger Equation

In this section we now present the time-dependent version of the
Schrödinger equation. Although we were able to “derive” the
single-particle time-independent Schrödinger equation starting from the
classical wave equation and the de Broglie relation, the time-dependent
Schrödinger equation cannot be “derived” using elementary methods, and
is generally given as a postulate of quantum mechanics [ 2 ] .

In other words, we shall postulate the single-particle three-dimensional
time-dependent Schrödinger equation as

  -- -------- -- ----------
     @xmath      (1.2.13)
  -- -------- -- ----------

We now focus on the case where @xmath is assumed to be a real function,
which represents the potential energy of the system. It is very easy to
see that the time-dependent equation can be used to derive the
time-independent equation. If we write the wavefunction as a product of
spatial and temporal terms, @xmath , then equation ( 1.2.13 ) becomes

  -- -------- -- ----------
     @xmath      (1.2.14)
  -- -------- -- ----------

or

  -- -------- -- ----------
     @xmath      (1.2.15)
  -- -------- -- ----------

It is easy to see that the left and right hand sides must each equal a
constant @xmath when the left-hand side is a function of @xmath only and
the right hand side is a function of @xmath only. (This is just the
usual separation of variables technique.)

Alternatively, if we appropriately denote this separation constant by
@xmath , (since the right-hand side clearly must have the dimensions of
energy), then we extract two ordinary differential equations,
specifically

  -- -------- -- ----------
     @xmath      (1.2.16)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (1.2.17)
  -- -------- -- ----------

The equation ( 1.2.17 ) is once again the time-independent Schrödinger
equation. Furthermore equation ( 1.2.16 ) is easily solved to yield

  -- -------- -- ----------
     @xmath      (1.2.18)
  -- -------- -- ----------

Most generally, we can show that the Hamiltonian in equation ( 1.2.17 )
is a Hermitian operator, and that the eigenvalues of a Hermitian
operator must be real, so @xmath is real. This implies that the
solutions @xmath are purely oscillatory, since @xmath never changes in
magnitude [recall Euler’s formula @xmath ]. In the following if we set

  -- -------- -- ----------
     @xmath      (1.2.19)
  -- -------- -- ----------

then the total wave function @xmath differs from @xmath only by a phase
factor of constant magnitude.

We can easily show that the quantity @xmath is time independent as
follows:

  -- -------- -- ----------
     @xmath      (1.2.20)
  -- -------- -- ----------

Furthermore, if @xmath satisfies ( 1.2.19 ), then the expectation value
for any time-independent operator is also time-independent. Thus it is
easy to see that

  -- -------- -- ----------
     @xmath      (1.2.21)
  -- -------- -- ----------

Wave functions of the form ( 1.2.19 ) are called stationary states. The
state @xmath is “stationary”, but the particle it describes is not. It
is now easy to see that equation ( 1.2.19 ) represents a particular
solution to equation ( 1.2.13 ). The general solution to equation (
1.2.13 ) will be a linear combination of these particular solutions [ 2
]

  -- -------- -- ----------
     @xmath      (1.2.22)
  -- -------- -- ----------

In the next section, we shall introduce an important technique, the WKB
approximation , which will be used several times in the body of this
thesis.

### 1.3 WKB approximation

The WKB (Wentzel–Kramers–Brillouin) approximation is also known as the
WKBJ (Wentzel-Kramers-Brillouin-Jeffreys) approximation , or sometimes
the JWKB approximation. The basic idea is it estimates a real
Schrödinger wave function by a sinusoidal vibration whose phase is
presented by the space integral of the classical momentum, the phase
integral, and whose amplitude varies inversely as the fourth root of the
classical momentum. In fact, in its original 1800’s incarnation as the
Jeffreys approximation , the WKB approximation was already a meaningful
expression for the physical waves of optics, acoustics, and
hydrodynamics. After 1925, this approximation was rapidly applied to the
new Schrödinger probability waves [ 9 ] .

The WKB approximation is an important method to derive approximate
solutions and estimates for many physical problems. For instance, it is
mainly applicable to problems of wave propagation in which the frequency
of the wave is very high, or equivalently, the wavelength of the wave is
very short (compared to the typical distance over which the potential
varies). Despite the fact that the WKB solutions are approximate
solutions, sometimes they are amazingly accurate [ 10 ] .

Let us begin with the one-dimensional time-independent Schrödinger
equation [ 8 ]

  -- -------- -- ---------
     @xmath      (1.3.1)
  -- -------- -- ---------

which can be rewritten as

  -- -------- -- ---------
     @xmath      (1.3.2)
  -- -------- -- ---------

where @xmath second derivative with respect to @xmath , @xmath
Schrödinger wave function, @xmath energy and @xmath potential energy.

We can now write the wavefunction in terms of the exponential function
by putting it in the form [ 6 ]

  -- -------- -- ---------
     @xmath      (1.3.3)
  -- -------- -- ---------

Substituting @xmath into equation ( 1.3.2 ), we derive

  -- -------- -- ---------
     @xmath      (1.3.4)
  -- -------- -- ---------

By comparing the first two terms, we expect that the quasi-classical
region is given by

  -- -------- -- ---------
     @xmath      (1.3.5)
  -- -------- -- ---------

We take the real and imaginary parts of equation ( 1.3.4 ):

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (1.3.6)
     @xmath   @xmath               (1.3.7)
  -- -------- -------- -------- -- ---------

Now we are considering only one-dimensional problems, which of course
also include radial motion in central potentials. One can then express
equation ( 1.3.7 ) in the form

  -- -------- -- ---------
     @xmath      (1.3.8)
  -- -------- -- ---------

and one finds

  -- -------- -- ---------
     @xmath      (1.3.9)
  -- -------- -- ---------

In equation ( 1.3.6 ), let us neglect the term @xmath compared to @xmath
. (This is where the approximation is made.) The resulting equation

  -- -------- -- ----------
     @xmath      (1.3.10)
  -- -------- -- ----------

can then easily be integrated:

  -- -------- -- ----------
     @xmath      (1.3.11)
  -- -------- -- ----------

Substituting ( 1.3.9 ) and ( 1.3.11 ) into ( 1.3.3 ), one finds

  -- -------- -- ----------
     @xmath      (1.3.12)
  -- -------- -- ----------

with momentum

  -- -------- -- ----------
     @xmath      (1.3.13)
  -- -------- -- ----------

Now we introduce the notation

  -- -------- -- ----------
     @xmath      (1.3.14)
  -- -------- -- ----------

By the JWKB approximation, we derive

  -- -------- -- ----------
     @xmath      (1.3.15)
  -- -------- -- ----------

This shows that the JWKB approximation is a fruitful method of
calculation, that can be used to develop a perturbation theory.

### 1.4 Classical turning points

We can start by considering one of the most interesting aspects
regarding the WKB approximation ; that being what happens at the
classical turning points where @xmath . In fact it is easy to realize
that as long as we keep away from these points, the approximation works
very well indeed. To get near or pass through a turning point one has to
go beyond the WKB approximation. The most straightforward way to do so
is by using a linear approximation to the Taylor series expansion of the
potential in the vicinity of the classical turning point. The exact
solution to this approximate problem is given in terms of an Airy
function . ( Bessel function of order @xmath .) Using this, the standard
approach is now to derive a specific way of patching the wave functions
on either side of the turning point — this leads to the so-called
“connection conditions”. Finally, it is interesting to note that
historically the WKB approach to barrier penetration application very
quickly yielded significant achievements in terms of understanding alpha
decay lifetimes [ 3 ] .

### 1.5 Discussion

In this chapter, we introduced the Schrödinger equation, which is a
specific partial differential equation used in the development of the
“new” (1925) quantum theory. The Schrödinger equation was discovered by
the Austrian physicist Erwin Schrödinger in 1925, and describes the
space –and time– dependence of quantum mechanical systems [ 1 ] . In
addition, physicists quickly applied the WKB approximation to the new
Schrödinger probability waves. The WKB approximation is generally
applicable to problems of wave propagation in which the frequency of the
wave is very high, or equivalently, the wavelength of the wave is very
short.

The problem of finding approximate solutions for wave equations in
general, and quantum mechanical problems in particular, has been
extensively considered over the last century or two. However, it appears
that as yet relatively little work seems to have been put into the
complementary problem of establishing rigourous bounds on the exact
solutions.

As the theory of the WKB approximation , and the concept of the
time-independent Schrödinger equation, both underlie all our subsequent
analyses, we have presented a very general introduction to these
concepts first — so that the bounds we will soon derive on transmission,
reflection, and Bogoliubov coefficients will be easier to understand.

Finally we believe that this introduction has provided sufficient
context for the reader to appreciate the role played by the various
topics to be discussed in this thesis, and to place them into a wider
perspective. In brief, quantum mechanics is a generic tool for
addressing empirical reality, and in this thesis we are probing the
complementary problem of establishing rigorous bounds on the exact
solutions.

## Chapter 2 Scattering problems

### 2.1 Introduction

In this chapter we shall present quantum scattering theory in one space
dimension. It is a beautiful subject that is mathematically simple and
physically transparent. Moreover, it still contains various important
results [ 17 ] .

One-dimensional scattering problems appear in a vast variety of physical
contexts. For instance, in acoustics one might be interested in the
propagation of sounds waves down a long pipe, while in electromagnetism
one might be interested in the physics of wave-guides. Another important
context which we want to stress in this chapter is that in quantum
physics the canonical examples related to one-dimensional scattering
theory are barrier penetration and reflection. In contrast, in classical
physics an equivalent problem is the analysis of parametric resonances [
88 ] .

Furthermore, when considering the basic ideas of “reflection and
transmission probabilities”, we shall introduce a useful technique to
derive a connection between reflection and transmission coefficients,
showing that they are related via a conceptually simple formalism. This
technique will be used several times in the main part of this thesis.

In particular, at the end of this chapter we shall (purely as an
example) illustrate how to derive either transmitted or reflected
probability waves as a result of scattering of an object in the
delta-potential well. More generally, we are specifically interested in
the Schrödinger equation as shown below in equation ( 2.2.1 ) in
conditions where the potential @xmath is zero outside of a finite
interval—mathematically we are most interested in considering potentials
of compact support. (Though much of what we will have to say will also
apply to potentials with suitably rapid falloff properties as one moves
to spatial infinity.)

### 2.2 Reflection and Transmission Probabilities

Let us consider the one-dimensional time-independent Schrödinger
equation [ 37 ] – [ 51 ]

  -- -------- -- ---------
     @xmath      (2.2.1)
  -- -------- -- ---------

If the potential asymptotes to a constant,

  -- -------- -- ---------
     @xmath      (2.2.2)
  -- -------- -- ---------

then in each of the two asymptotic regions there are two independent
solutions to the Schrödinger equation

  -- -------- -- ---------
     @xmath      (2.2.3)
  -- -------- -- ---------

Here the @xmath distinguishes right-moving modes @xmath from left-moving
modes @xmath , while the @xmath specifies which of the asymptotic
regions we are in. Furthermore

  -- -------- -- ---------
     @xmath      (2.2.4)
  -- -------- -- ---------

To even begin to set up a scattering problem the minimum requirements
are that potential asymptote to some constant, and this assumption will
be made henceforth. The so-called Jost solutions [ 52 ] are exact
solutions @xmath of the Schrödinger equation that satisfy

  -- -------- -- ---------
     @xmath      (2.2.5)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (2.2.6)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (2.2.7)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (2.2.8)
  -- -------- -- ---------

###### Identifying the reflection and transmission coefficients.

There are unfortunately at least four distinct sets of conventions in
common use, depending on whether or not one absorbs factors of @xmath
into @xmath and @xmath respectively, and on whether one chooses to focus
on left-moving or right-moving waves as being primary. Let us, for the
current section, adopt the convention of not absorbing the factors of
@xmath into @xmath and @xmath . (We shall discuss the other convention a
little later in this chapter). We start by introducing a minor variant
of Messiah’s notation [ 51 ]

  -- -------- -- ---------
     @xmath      (2.2.9)
  -- -------- -- ---------

  -- -------- -- ----------
     @xmath      (2.2.10)
  -- -------- -- ----------

By comparing these two different forms for the asymptotic form of the
Jost function we see that in this situation the ratios of the amplitudes
are given by

  -- -------- -- ----------
     @xmath      (2.2.11)
  -- -------- -- ----------

Thus we obtain

  -- -------- -- ----------
     @xmath      (2.2.12)
  -- -------- -- ----------

We also derive (in this set of conventions)

  -- -------- -- ----------
     @xmath      (2.2.13)
  -- -------- -- ----------

∎

Thus we have demonstrated that @xmath and @xmath , the (right-moving)
Bogoliubov coefficients, are related to the (left-moving) reflection and
transmission amplitudes by

  -- -------- -- ----------
     @xmath      (2.2.14)
  -- -------- -- ----------

Without further calculation we can also deduce

  -- -------- -- ----------
     @xmath      (2.2.15)
  -- -------- -- ----------

The explicit occurrence of @xmath and @xmath is an annoyance, which is
why many authors adopt the alternative normalization we shall discuss
later on in this chapter.

In Bogoliubov language these conventions correspond to an incoming flux
of right-moving particles (incident from the left) being amplified to
amplitude @xmath at a cost of a backflow of amplitude @xmath . In
scattering language one should consider the complex conjugate @xmath —
this is equivalent to an incoming flux of left-moving particles
(incident from the right) of amplitude @xmath being partially
transmitted (amplitude unity) and partially scattered (amplitude @xmath
). If the potential has even parity, then the left-moving Bogoliubov
coefficients are just the complex conjugates of the right-moving
coefficients, however if the potential is asymmetric a more subtle
analysis is called for.

The second interesting issue is that we can deal exclusively with @xmath
and @xmath , dropping the suffix for brevity — if information about
@xmath and @xmath is desired simply work with the reflected potential
@xmath . It should also be borne in mind that the phases of @xmath and
@xmath are physically meaningless in that they can be arbitrarily
changed simply by moving the origin of coordinates (or equivalently,
physically moving the location of the potential). The phases of @xmath
and @xmath on the other hand do contain real and significant physical
information.

For completely arbitrary potentials, with no parity restriction (so the
potential is neither even nor odd), a Wronskian analysis yields (see for
example [ 51 ] , noting that an overall minus sign between Messiah and
the conventions above neatly cancels):

  -- -------- -- ----------
     @xmath      (2.2.16)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.17)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.18)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.19)
  -- -------- -- ----------

with equivalent relations for @xmath and @xmath . Then

  -- -------- -- ----------
     @xmath      (2.2.20)
  -- -------- -- ----------

and barrier transmission is independent of direction. We also have

  -- -------- -- ----------
     @xmath      (2.2.21)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (2.2.22)
  -- -------- -- ----------

with equivalent relations for @xmath and @xmath .

If we now adopt the (to our minds) more useful convention, by absorbing
factors of @xmath and @xmath into the definitions of @xmath and @xmath
then things simplify considerably: We restart the calculation by now
defining

  -- -------- -- ----------
     @xmath      (2.2.23)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.24)
  -- -------- -- ----------

By comparing these two different forms for the asymptotic form of the
Jost function we see that in this situation the ratios of the amplitudes
are given by the much simpler formulae

  -- -------- -- ----------
     @xmath      (2.2.25)
  -- -------- -- ----------

We now have

  -- -------- -- ----------
     @xmath      (2.2.26)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (2.2.27)
  -- -------- -- ----------

We see that by putting the factors of @xmath into the asymptotic form of
the Jost functions, where they really belong, the formulae for @xmath
and @xmath are suitably simplified.

For completely arbitrary potentials, with no parity restriction (so the
potential is neither even nor odd), a modified Wronskian analysis now
yields (in analogy with that reported by Messiah [ 51 ] ):

  -- -------- -- ----------
     @xmath      (2.2.28)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.29)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.30)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (2.2.31)
  -- -------- -- ----------

with equivalent relations for @xmath and @xmath . Then

  -- -------- -- ----------
     @xmath      (2.2.32)
  -- -------- -- ----------

and barrier transmission is independent of direction. Because they are
independent of any overall scaling by a real number, also retain the
previous results

  -- -------- -- ----------
     @xmath      (2.2.33)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (2.2.34)
  -- -------- -- ----------

with equivalent relations for @xmath and @xmath . It is this modified
set of conventions, because they have much nicer normalization
properties, that we shall prefer for the bulk of the thesis.

We shall now derive some very general bounds on @xmath and @xmath ,
which also lead to general bounds on the reflection and transmission
probabilities

  -- -------- -- ----------
     @xmath      (2.2.35)
  -- -------- -- ----------

### 2.3 Probability currents

The expressions for reflection and transmission coefficients were based
on the assumption that the intensity of a beam is the product of the
speed of its particles and their linear number density. In classical
physics, the assumption seems very natural, however, we should always be
careful about carrying over classical concepts into quantum physics [ 21
] .

Definition (Unbound state) : Provided @xmath , the Schrödinger equation
( 1.3.1 ) can be solved for any positive value of energy, when @xmath .
In addition, the positive energies can be shown to define a continuous
spectrum. Nevertheless, the corresponding eigenfunctions do not vanish
at infinity; their asymptotic behavior is analogous to that of the plane
wave @xmath . More accurately, the absolute value of wave functions (
@xmath ) approaches a non-zero constant when @xmath . Otherwise, the
absolute value oscillates indefinitely between limits, one of which at
least is not zero. It is clear that the particle does not remain
localized in any finite region. This type of wave function is commonly
applied to collision problems; the usual language is that one is dealing
with an unbound state , or stationary state of collision [ 51 ] .

### 2.4 Reflection and Transmission of Waves in unbound states

The Schrödinger equation also can be analyzed in terms of the functions
@xmath and @xmath , as defined by Messiah [ 51 ] , and their complex
conjugates @xmath and @xmath . Moreover, the Wronskian of any two such
solutions is independent of @xmath ; especially, it takes on the same
value in the two asymptotic regions. Actually our approach can be seen
as equating these two values; we now derive a relation between the
coefficients @xmath , or their complex conjugates. Six such relations
can be formed with the four functions @xmath and @xmath . From what we
have seen earlier it is clear that they are very basic relations which
must be maintained whatever the form of the potential function @xmath [
51 ] .

Specifically, we derive (in Messiah-like conventions)

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.4.1)
     @xmath   @xmath   @xmath      (2.4.2)
     @xmath   @xmath   @xmath      (2.4.3)
     @xmath   @xmath   @xmath      (2.4.4)
  -- -------- -------- -------- -- ---------

The equations ( 2.4.1 ) and ( 2.4.2 ) are called the relations of
conservation of flux . They should always be true, and this should be
verified in special cases. This name comes from the following statements
regarding the wave function @xmath of an unbound state in the asymptotic
region. We let @xmath be the expression of the wave function @xmath in
one of the asymptotic regions, for @xmath case.

The total flux of particles when passing a given point is the difference
between the flux @xmath of particles traveling in the positive sense,
and the flux @xmath of particles traveling in the negative sense. This
flux is equal, to within a constant, to the Wronskian @xmath [ 51 ] :

  -- -------- -- ---------
     @xmath      (2.4.5)
  -- -------- -- ---------

The equality of the Wronskian @xmath at both ends of the interval @xmath
, denotes that the number of particles entering the interaction region
per unit time is equal to the number which leave it. In accordance with
this interpretation, one or the other of equation ( 2.4.1 ) and ( 2.4.2
) can be written as:

  -- -------- -- ---------
     @xmath      (2.4.6)
  -- -------- -- ---------

Considering the same interpretation, we now can define the transmission
coefficient (transmission probability) @xmath as follows:

  -- -------- -- ---------
     @xmath      (2.4.7)
  -- -------- -- ---------

We have in particular

  -- -------- -- ---------
     @xmath      (2.4.8)
  -- -------- -- ---------

This result shows that the absolute values of the two sides of equation
( 2.4.3 ) are equal, and one obtains the equality

  -- -------- -- ---------
     @xmath      (2.4.9)
  -- -------- -- ---------

Thus the transmission coefficient of a wave at a given energy is
independent of the direction of travel. This is the reciprocity property
of the transmission coefficient . It is just as hard to traverse a
potential barrier in one direction as in the other.

The equality of the absolute values of the two sides of equation ( 2.4.4
), coupled with the conservation relations ( 2.4.1 ) and ( 2.4.2 ),
again yields the reciprocity relation ( 2.4.7 ) we also obtain relations
between the phases of the reflection and transmission amplitudes:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

The most interesting point for these relations is the fact (not further
investigated in this thesis) that the phases are related to
“retardation” effects in the propagation of the wave packets, with
equivalent relations for @xmath and @xmath .

As previously, we can re-scale @xmath and @xmath by absorbing
appropriate factors of @xmath , and so simplify the discussion as in the
previous section. (We will not repeat the details of the analysis, as it
is straightforward.) We shall now generalize some very general bounds on
@xmath and @xmath , which also lead to general bounds on the reflection
and transmission probabilities

  -- -------- -- ----------
     @xmath      (2.4.10)
  -- -------- -- ----------

Definition (Bound states) : Provided @xmath , when @xmath , the
Schrödinger equation ( 1.3.1 ) has solutions only for certain particular
values of energy forming a discrete spectrum. The eigenfunction @xmath
corresponding to it — or each of the eigenfunctions when several exist —
vanishes at infinity. More accurately, the integral @xmath extended over
the whole configuration space is convergent. There is a vanishing
probability of finding the particle at infinity and the particle remains
practically localized in a finite region. The particle can now be
defined to be in a bound state [ 51 ] .

### 2.5 Bogoliubov transformation

Definition (Bogoliubov transformation) : This is a unitary
transformation from a unitary representation of some canonical
commutation relation algebra or canonical anticommutation relation
algebra into another unitary representation [ 1 ] .

To see the import of this definition, let us consider the canonical
commutation relation for bosonic creation and annihilation operators in
the harmonic basis

  -- -------- -- ---------
     @xmath      (2.5.1)
  -- -------- -- ---------

Using this method we can derive a new pair of operators.

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.5.2)
     @xmath   @xmath   @xmath      (2.5.3)
  -- -------- -------- -------- -- ---------

where the equation ( 2.5.2 ) is the hermitian conjugate of the equation
( 2.5.3 ).

This transformation is a canonical transformation of these operators. It
is easy to find the conditions on the constants @xmath and @xmath . For
instance, the transformation remains canonical by extending the
commutator.

  -- -------- -- ---------
     @xmath      (2.5.4)
  -- -------- -- ---------

It can be seen that

  -- -------- -- ---------
     @xmath      (2.5.5)
  -- -------- -- ---------

is the condition for which the transformation is canonical. (This
normalization condition will occur and re-occur many times in the
calculations which follow.) Finally we note that since the form of this
condition is reminiscent of the hyperbolic identity

  -- -------- -- ---------
     @xmath      (2.5.6)
  -- -------- -- ---------

between @xmath and @xmath , the constants @xmath and @xmath are usually
parameterized as

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.5.7)
     @xmath   @xmath   @xmath      (2.5.8)
  -- -------- -------- -------- -- ---------

### 2.6 Transfer matrix representation

We can also investigate quantum mechanical tunneling by the so-called
“transfer matrix method” or “transfer matrix representation”.
Ultimately, of course, this is still equivalent to extracting the
transmission coefficient from the solution to the one-dimensional,
time-independent Schrödinger equation. As before, the transmission
coefficient is the ratio of the flux of particles that penetrate a
potential barrier to the flux of particles incident on the barrier. It
is related to the probability that tunneling will occur [ 15 ] . We
again consider a one-dimensional problem which is characterized by an
incident beam of particles that is either transmitted or reflected as a
result of scattering from an object [ 21 ] . For current purposes it is
easiest to work with potentials of compact support, where @xmath except
in some finite region @xmath .

As long as the potential @xmath is of compact support, it splits the
space in three parts ( @xmath ). In both @xmath and @xmath the potential
energy is zero. Moreover, in each of these two regions the solution of
the Schrödinger equation can be presented as a superposition of
exponentials by

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (2.6.1)
     @xmath   @xmath   @xmath      (2.6.2)
  -- -------- -------- -------- -- ---------

where @xmath and @xmath are at this stage unspecified, and @xmath . But
because @xmath and @xmath are solutions to the Schrödinger equation that
can be extended to the entire real line, and because the Schrödinger
equation is a second-order differential equation so that its solution
space is two-dimensional, there must be some linear relation between the
coefficients appearing in @xmath and @xmath — specifically, there must
be a @xmath matrix @xmath such that

  -- -------- -- ---------
     @xmath      (2.6.3)
  -- -------- -- ---------

The @xmath matrix @xmath depends, in a complicated way, on the potential
@xmath in the region @xmath . In the transfer matrix approach we shall
seek to extract as much information as possible without explicitly
calculating @xmath .

To now derive amplitudes for reflection and transmission for incidence
from the left, we put @xmath (incoming particles), @xmath (reflection),
@xmath (no incoming particle from the right) and @xmath (transmission)
in equations ( 2.6.1 ) and ( 2.6.2 ). We now derive

  -- -------- -- ---------
     @xmath      (2.6.4)
  -- -------- -- ---------

where @xmath is the left-moving reflection amplitude and on the right of
the potential

  -- -------- -- ---------
     @xmath      (2.6.5)
  -- -------- -- ---------

where @xmath is the left-moving transmission amplitude. This tells us
that

  -- -------- -- ---------
     @xmath      (2.6.6)
  -- -------- -- ---------

But since the Schrödinger equation ( 1.2.19 ) is real, the complex
conjugate of any solution is also a solution. Therefore the solution
which on the left has the form

  -- -------- -- ---------
     @xmath      (2.6.7)
  -- -------- -- ---------

must on the right have the form

  -- -------- -- ---------
     @xmath      (2.6.8)
  -- -------- -- ---------

and so we also have

  -- -------- -- ---------
     @xmath      (2.6.9)
  -- -------- -- ---------

These two matrix equations now imply

  -- -------- -- ----------
     @xmath      (2.6.10)
  -- -------- -- ----------

But by conservation of flux we must have

  -- -------- -- ----------
     @xmath      (2.6.11)
  -- -------- -- ----------

We just have seen an important connection between reflection and
transmission amplitudes. In addition, it is interesting to show how to
derive the above equation by following.

From the equation ( 2.6.4 ), we can see that this corresponds to a flux
in the positive @xmath direction. For @xmath this is of magnitude

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (2.6.12)
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ----------

and for @xmath , we similarly derive from equation ( 2.6.5 ) the fact
that we can write the flux corresponding to this equation is

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (2.6.13)
                                @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ----------

Definition : The probability current @xmath of the wave function @xmath
is defined as

@xmath (2.6.14)

in the position basis and satisfies the quantum mechanical continuity
equation

@xmath (2.6.15)

where @xmath is probability density [ 12 ] .

Since there is no time dependence in the problem, the conservation law
in equation ( 2.6.14 ) implies that @xmath is independent of @xmath .
Hence the flux on the left must be equal to the flux on the right, that
is, we expect that

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

therefore,

  -- -------- -- ----------
     @xmath      (2.6.16)
  -- -------- -- ----------

so

  -- -------- -- ----------
     @xmath      (2.6.17)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (2.6.18)
  -- -------- -- ----------

Similary, consider a wave moving in from the right

  -- -------- -- ----------
     @xmath      (2.6.19)
  -- -------- -- ----------

which then hits the potential, is partially reflected and partially
transmitted. In this case, on the right of the potential we have

  -- -------- -- ----------
     @xmath      (2.6.20)
  -- -------- -- ----------

where @xmath is the right-moving reflection amplitude and on the left of
the potential

  -- -------- -- ----------
     @xmath      (2.6.21)
  -- -------- -- ----------

where @xmath is the left-moving transmission amplitude. This tells us
that

  -- -------- -- ----------
     @xmath      (2.6.22)
  -- -------- -- ----------

Again, since the Schrödinger equation is real, the complex conjugate of
any solution is also a solution. Therefore a related interesting
solution which on the left can be cast in the form

  -- -------- -- ----------
     @xmath      (2.6.23)
  -- -------- -- ----------

must on the right have the form

  -- -------- -- ----------
     @xmath      (2.6.24)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (2.6.25)
  -- -------- -- ----------

But now these two matrix equations imply

  -- -------- -- ----------
     @xmath      (2.6.26)
  -- -------- -- ----------

Combining the information from left moving and right moving cases we
have first that

  -- -------- -- ----------
     @xmath      (2.6.27)
  -- -------- -- ----------

So we again derive the equality of the transmission amplitudes.

Similarly we see that

  -- -------- -- ----------
     @xmath      (2.6.28)
  -- -------- -- ----------

implying

  -- -------- -- ----------
     @xmath      (2.6.29)
  -- -------- -- ----------

Note that we cannot in general deduce @xmath . Indeed, in general this
is false.

So for any potential we have

  -- -------- -- ----------
     @xmath      (2.6.30)
  -- -------- -- ----------

implying (in the same manner as the previous argument) that the
transmission and reflection coefficients are independent on whether or
not the particle is incident from the left or the right — and we have
not made any assumption here about any symmetry for the potential @xmath
itself. We conclude

  -- -------- -- ----------
     @xmath      (2.6.31)
  -- -------- -- ----------

Note the key step in this general derivation: In any region where the
potential is zero we simply need to solve

  -- -------- -- ----------
     @xmath      (2.6.32)
  -- -------- -- ----------

for which the two independent solutions are

  -- -------- -- ----------
     @xmath      (2.6.33)
  -- -------- -- ----------

or more explicitly

  -- -------- -- ----------
     @xmath      (2.6.34)
  -- -------- -- ----------

To the left of the potential we have

  -- -------- -- ----------
     @xmath      (2.6.35)
  -- -------- -- ----------

while to the right of the potential we have

  -- -------- -- ----------
     @xmath      (2.6.36)
  -- -------- -- ----------

Even without knowing anything more about the potential @xmath , the
linearity of the Schrödinger ODE guarantees that there will be some
@xmath transfer matrix @xmath such that

  -- -------- -- ----------
     @xmath      (2.6.37)
  -- -------- -- ----------

This transfer matrix relates the situation to the left of the potential
with the wave-function to the right of the potential. For this reason we
shall now use this formalism, for instance, to think about the
propagation of electrons down a wire (approximately one-dimensional)
with @xmath used to describe various barriers placed in the path of the
electron. Moreover, similar matrices also occur in optics, where they
are referred to as “Jones matrices”.

The components of the transfer matrix @xmath will be some horrible
nonlinear function of the potential @xmath , but by linearity of the
Schrödinger ODE these matrix components must be independent of the
parameters @xmath and @xmath . In some particularly simple situations we
may be able to calculate the matrix @xmath explicitly (see in particular
the next chapter), but in general it will be a complicated mess.

From the above discussion we now understand, from at least two different
points of view, the basic concepts of transmission and reflection. The
probability that a given incident particle is reflected is called the
“reflection coefficient”, @xmath . While the probability that it is
transmitted is called the “transmission coefficient”, @xmath [ 21 ] .

### 2.7 Discussion

In this chapter, we have presented basic aspects of scattering theory in
one dimension. For a one-dimensional model, only one of the three
coordinates of 3-dimensional physical space is explicitly involved.
Specifically, we considered potentials of compact support, when the
potential @xmath is mathematically zero outside of a finite interval.
The situation where the potential is zero is referred to as “the free
particle”. These one-dimensional models provide solid examples
exhibiting all the basic features and ideas needed to derive the
properties of quantum states of definite energy @xmath .

A further step in our investigation is that we have just seen an
important connection between reflection and transmission amplitudes. In
particular, it is interesting to show how to derive them directly by
using scattering theory. Furthermore, we have now introduced the concept
of transmission and reflection. We called the probability that a given
incident particle is reflected as the “reflection coefficient”. While
the probability that it is transmitted is called the “transmission
coefficient”.

More importantly, we introduced the probability current to express the
reflection and transmission coefficients. The probability current is
based on the assumption that the intensity of a beam is the product of
the speed of its particles and their linear number density. It is then a
mathematical theorem that this probability current is conserved. We then
introduced important ideas of reflection and transmission of waves in
both unbound and bound states. By considering reflection and
transmission of waves in unbound states, we have seen that in principle
they are completely specified by the potential function @xmath .

For instance, the linearity of the Schrödinger ODE guarantees that there
will be some @xmath transfer matrix. Moreover, this transfer matrix can
be represented by investigating quantum mechanical tunneling by
extracting the transmission coefficient from the solution to the
one-dimensional, time-independent Schrödinger equation.

## Chapter 3 Known analytic results

### 3.1 Introduction

In this chapter we shall collect a number of known analytic results in a
form amenable to comparison with the general results presented in
subsequent chapters. We shall review and briefly describe the concept of
quasinormal modes , and see how most of the concepts introduced here are
important tools for comparing the bounds with known analytic results.
Furthermore, we shall reproduce many analytically known results, such as
the tunnelling probabilities and quasinormal modes [QNM] of the
delta-function potential, double-delta-function potential, square
potential barrier, @xmath potential, @xmath potential, asymmetric
square-well potential, the Poeschl–Teller potential and its variants,
and finally the Eckart–Rosen–Morse–Poeschl–Teller potential.

In the following, we shall first introduce the quasinormal modes , which
are the modes of energy dissipation of a perturbed object or field. In
particular, the most outstanding and well-known example is the
perturbation of a wine glass with a knife: the glass begins to ring, it
rings with a set, or superposition, of its natural frequencies – its
modes of sonic energy dissipation. In the absence of any damping, when
the glass goes on ringing forever, we can call these modes normal . In
the presence of damping, when the amplitude of oscillation decays in
time, we call the modes quasi-normal [ 14 ] .

To a very high degree of accuracy, quasinormal ringing can be
approximated by

  -- -------- -- ---------
     @xmath      (3.1.1)
  -- -------- -- ---------

where @xmath is the amplitude of oscillation, @xmath is the frequency
and @xmath is the decay rate. We can express the quasinormal frequency
in two numbers,

  -- -------- -- ---------
     @xmath      (3.1.2)
  -- -------- -- ---------

or more compactly

  -- -------- -- ---------
     @xmath      (3.1.3)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (3.1.4)
  -- -------- -- ---------

where for @xmath we are to understand that we are only interested in the
real part. In our explanation here, @xmath is generally referred to as
the quasinormal mode frequency . The most interesting point is that it
is a complex number with two pieces. One of them is a real part which
describes the temporal oscillation, and the other part is an imaginary
part which describes the temporal exponential decay. Formally,
quasinormal modes are most easily found by looking for complex
frequencies where the transmission amplitude becomes infinite.

In theoretical physics, a quasinormal mode is a formal solution of some
linear differential equations with a complex eigenvalue. In black hole
physics these linear differential equations typically come from
linearizing the full Einstein equations. It is important to note that
black holes have many quasinormal modes that express the exponential
decrease of asymmetry of the black hole in time as it evolves towards
the perfect spherical shape [ 14 ] . Experience obtained from black hole
physics and related fields has shown that it is quite common for QNM to
be approximately of the form

  -- -------- -- ---------
     @xmath      (3.1.5)
  -- -------- -- ---------

where @xmath is a complex number called the “offset” and @xmath is a
real number known as the “gap” [ 98 ] .

### 3.2 Delta–function potential

As a first approach to the comparison of the bounds with known analytic
results we can start by studying in detail the concept of the
delta–function potential. It is important to understand that the
delta–function potential is one limiting case of a square well. It is a
very narrow deep well, which can adequately be approximated by a
mathematical delta function when the range of variation of the wave
function is much greater than the range of the potential [ 24 ] .

The time–independent Schrödinger equation for the wave function @xmath
is

  -- -------- -- ---------
     @xmath      (3.2.1)
  -- -------- -- ---------

where @xmath is the Hamiltonian, @xmath is the (reduced) Planck
constant, @xmath is the mass, @xmath is the energy of the particle and
the potential @xmath is the delta function well with strength @xmath
concentrated at the origin. Without changing the physical results, any
other shifted position is also possible [ 25 ] , i.e.

For a delta function potential take

  -- -------- -- ---------
     @xmath      (3.2.2)
  -- -------- -- ---------

In this case the transmission coefficient is well known to be (see, for
instance, [ 38 , 39 ] )

  -- -------- -- ---------
     @xmath      (3.2.3)
  -- -------- -- ---------

Quasinormal modes: @xmath when

  -- -------- -- ---------
     @xmath      (3.2.4)
  -- -------- -- ---------

that is

  -- -------- -- ---------
     @xmath      (3.2.5)
  -- -------- -- ---------

Note that there is only one pair of complex conjugate QNM. Because the
width of the delta function is zero, the “gap” is infinite, and the
other QNM are driven off to imaginary infinity.

#### Deriving the amplitudes:

For completeness we will explicitly provide the calculations required to
deal with the delta potential barrier — this is a textbook problem of
quantum mechanics. Generally, the problem consists of solving the
time-independent Schrödinger equation for a particle in a delta function
potential in one dimension [ 25 ] .

We now consider particles entering from the left traveling to the right
with @xmath encountering a potential of the form [ 18 ]

  -- -------- -- ---------
     @xmath      (3.2.6)
  -- -------- -- ---------

We look for solutions of the time-independent Schrödinger equation

  -- -------- -- ---------
     @xmath      (3.2.7)
  -- -------- -- ---------

with @xmath . For @xmath in the region @xmath we have

  -- -------- -- ---------
     @xmath      (3.2.8)
  -- -------- -- ---------

with @xmath or @xmath (where @xmath ).

The most general solution is

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (3.2.9)
     @xmath   @xmath   @xmath      (3.2.10)
  -- -------- -------- -------- -- ----------

##### Boundary Conditions:

We must require @xmath to be continuous everywhere, and @xmath to be
continuous (except possibly where @xmath is infinite). Thus, at @xmath ,
we have @xmath which implies that @xmath .

Also notice that for @xmath we have

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Thus,

  -- -- -- ----------
           (3.2.12)
  -- -- -- ----------

which implies that @xmath .

Let us consider the second of these equations, which follows from
integrating the Schrödinger equation with respect to @xmath . The
boundary conditions thus give the following restrictions on the
coefficients [ 19 ]

  -- -------- -- ----------
     @xmath      (3.2.13)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (3.2.14)
  -- -------- -- ----------

##### Reflection and Transmission:

We shall see how to find the amplitudes for reflection and transmission
for incidence from the left, by putting in the equations ( 3.2.13 ) and
( 3.2.14 ); @xmath (incoming particle), @xmath (reflection), @xmath (no
incoming particle from the right) and @xmath (transmission). We obtain

  -- -------- -- ----------
     @xmath      (3.2.15)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (3.2.16)
  -- -------- -- ----------

To find the amplitudes for reflection and transmission for incidence
from the left, we now solve for @xmath and @xmath :

  -- -------- -- ----------
     @xmath      (3.2.17)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (3.2.18)
  -- -------- -- ----------

Now we can derive the probability for transmission and reflection (given
by the transmission coefficient and the reflection coefficient)

  -- -------- -- ----------
     @xmath      (3.2.19)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (3.2.20)
  -- -------- -- ----------

This confirms the result we previously quoted, and by looking for poles
of the transmission amplitudes, confirms the locations of the QNM.

### 3.3 Double-delta-function potential

For the double delta function

  -- -------- -- ---------
     @xmath      (3.3.1)
  -- -------- -- ---------

the transmission coefficient is known to be [ 47 ]

  -- -------- -- ---------
     @xmath      (3.3.2)
  -- -------- -- ---------

It is an easy exercise to check that this satisfies the bounds ( 6.1.6 )
and ( 6.1.8 ) that we shall derive later on in this thesis.
Quasinormal modes: @xmath when

  -- -------- -- ---------
     @xmath      (3.3.3)
  -- -------- -- ---------

which leads to quite horrible algebra, so that there is no explicit
formula for the QNM. Implicitly, working with the transmission amplitude
:

  -- -------- -- ---------
     @xmath      (3.3.4)
  -- -------- -- ---------

so that

  -- -------- -- ---------
     @xmath      (3.3.5)
  -- -------- -- ---------

#### Deriving the amplitudes

To derive the transmission and reflection amplitudes for the
double-delta-function potential, we now start by considering the
potential [ 17 ]

  -- -------- -- ---------
     @xmath      (3.3.6)
  -- -------- -- ---------

For a particle incident from the left we now have

  -- -------- -- ---------
     @xmath      (3.3.7)
  -- -------- -- ---------

Note that now we also have to explicitly consider the region between the
two delta-functions. Applying the same sort of boundary conditions we
now have four equations. From continuity at @xmath we have

  -- -------- -- ---------
     @xmath      (3.3.8)
  -- -------- -- ---------

while continuity at @xmath implies

  -- -------- -- ---------
     @xmath      (3.3.9)
  -- -------- -- ---------

Integrating across the delta functions leads to

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.10)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.11)
  -- -------- -- ----------

We rearrange this to obtain

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.12)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.13)
  -- -------- -- ----------

Some further rearrangements lead to

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.14)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.15)
  -- -------- -- ----------

Finally we have

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.16)
  -- -------- -- ----------

It is very useful to reduce clutter by defining

  -- -------- -- ----------
     @xmath      (3.3.17)
  -- -------- -- ----------

then

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.18)
  -- -------- -- ----------

in which case our four boundary conditions become:

  -- -------- -- ----------
     @xmath      (3.3.19)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (3.3.20)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      
     @xmath      
     @xmath      (3.3.21)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      
     @xmath      (3.3.22)
  -- -------- -- ----------

These are four simultaneous linear equations for four unknowns: @xmath ,
@xmath , @xmath , and @xmath (in terms of the known quantities @xmath ,
@xmath , and @xmath ). These can be solved, either by direct calculation
or by Maple or something similar. A little work then leads to

  -- -------- -- ----------
     @xmath      (3.3.23)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (3.3.24)
  -- -------- -- ----------

Note that @xmath is pure imaginary, in agreement with our general
argument regarding definite parity potentials. Furthermore note that

  -- -------- -- ----------
     @xmath      (3.3.25)
  -- -------- -- ----------

and so @xmath whenever

  -- -------- -- ----------
     @xmath      (3.3.26)
  -- -------- -- ----------

That is, the system exhibits “transmission resonances” where @xmath and
@xmath . If we work at fixed energy then these resonances occur at
equally spaced spatial separation for the two delta functions, namely:

  -- -------- -- ----------
     @xmath      (3.3.27)
  -- -------- -- ----------

If we hold @xmath fixed and vary @xmath then the location of the
resonances is determined by the transcendental equation

  -- -------- -- ----------
     @xmath      (3.3.28)
  -- -------- -- ----------

The existence of “transmission resonances” in one-dimensional scattering
is in fact widespread, it is not specific to this particular example. A
brief computation leads to the explicit transmission coefficient

  -- -------- -- ----------
     @xmath      (3.3.29)
  -- -------- -- ----------

or

  -- -------- -- ----------
     @xmath      (3.3.30)
  -- -------- -- ----------

which agrees with the preceding argument on the location of the
transmission resonances. Finally note @xmath and @xmath . After we look
at one more illustrative example, we will turn to the issue of obtaining
some general theorems governing one-dimensional scattering.

### 3.4 Square barrier

Let us now start by introducing another useful potential barrier — the
square barrier [ 11 ] :

  -- -------- -- ---------
     @xmath      (3.4.1)
  -- -------- -- ---------

In our particular case, we set @xmath . Tunneling over a square barrier
is an elementary problem which however is not always discussed in the
textbooks. In contrast, tunneling under a square barrier is much more
popular. The exact transmission coefficient is known to be

  -- -------- -- ---------
     @xmath      (3.4.2)
  -- -------- -- ---------

For more details see (for example) Landau and Lifshitz [ 37 ] , or
Schiff [ 45 ] . We can re-write this as

  -- -------- -- ---------
     @xmath      (3.4.3)
  -- -------- -- ---------

Quasinormal modes: @xmath when the numerator is nonzero and

  -- -------- -- ---------
     @xmath      (3.4.4)
  -- -------- -- ---------

which leads to hopeless algebra. Although @xmath is one solution, it
corresponds to the numerator vanishing and is not a transmission pole.
There is no simple explicit formula for the QNM.

#### Deriving the amplitudes:

We shall now consider a particle of mass @xmath and energy @xmath
interacting with the simple square potential barrier. Let us consider
@xmath in the regions to the left and to the right of the barrier, we
have

  -- -------- -- ---------
     @xmath      (3.4.5)
  -- -------- -- ---------

where @xmath . We choose the following solution of the above equation to
the left of the barrier (i.e., @xmath )

  -- -------- -- ---------
     @xmath      (3.4.6)
  -- -------- -- ---------

The composition of this solution is a plane-wave of unit amplitude
traveling to the right [since the time dependent wave function is
multiplied by a factor @xmath ], and a plane wave of complex amplitude
@xmath traveling to the left. Moreover it should be stressed that the
first plane wave is incoming particle. Indeed, the second plane wave is
a particle reflected by the potential barrier. Therefore @xmath is the
probability of reflection. This can also be seen by calculating the
probability current in the region @xmath , which takes the form

  -- -------- -- ---------
     @xmath      (3.4.7)
  -- -------- -- ---------

We choose the following solution to equation ( 3.4.5 ) to the right of
the barrier, that is, for @xmath :

  -- -------- -- ---------
     @xmath      (3.4.8)
  -- -------- -- ---------

We have seen that this solution consists of a plane wave of complex
amplitude @xmath traveling to the right. This implies that this solution
can be interpreted as a particle transmitted through the barrier.
Consequently, @xmath is the probability of transmission. In fact we can
write the probability current in the region @xmath as

  -- -------- -- ---------
     @xmath      (3.4.9)
  -- -------- -- ---------

If we set @xmath , then we derive

  -- -------- -- ----------
     @xmath      (3.4.10)
  -- -------- -- ----------

At this point is easy to see that inside the barrier @xmath , the
wavefunction @xmath satisfies

  -- -------- -- ----------
     @xmath      (3.4.11)
  -- -------- -- ----------

where

  -- -------- -- ----------
     @xmath      (3.4.12)
  -- -------- -- ----------

We consider the case where @xmath . In addition, the general solution to
equation ( 3.4.11 ) inside the barrier takes the form

  -- -------- -- ----------
     @xmath      (3.4.13)
  -- -------- -- ----------

where @xmath . From the continuity of @xmath and @xmath at the left edge
of the barrier @xmath we derive

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (3.4.14)
     @xmath   @xmath   @xmath      (3.4.15)
  -- -------- -------- -------- -- ----------

Moreover, continuity of @xmath and @xmath at the right edge of the
barrier, for @xmath gives

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (3.4.16)
     @xmath   @xmath   @xmath      (3.4.17)
  -- -------- -------- -------- -- ----------

It is now relatively easy to see that, (after considerable algebra), the
above four equations yield

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (3.4.18)
     @xmath   @xmath   @xmath      (3.4.19)
  -- -------- -------- -------- -- ----------

### 3.5 Tanh potential

For a smoothed step function of the form

  -- -------- -- ---------
     @xmath      (3.5.1)
  -- -------- -- ---------

the reflection coefficient is known analytically to be (see, for
instance, [ 37 ] ):

  -- -------- -- ---------
     @xmath      (3.5.2)
  -- -------- -- ---------

This certainly satisfies the general bounds ( 6.5.2 )–( 6.5.3 ) that we
shall derive later on in this thesis, see chapter 6 , and as @xmath
approaches and saturates the bound.
Quasinormal modes: @xmath when

  -- -------- -- ---------
     @xmath      (3.5.3)
  -- -------- -- ---------

that is

  -- -------- -- ---------
     @xmath      (3.5.4)
  -- -------- -- ---------

This leads to

  -- -------- -- ---------
     @xmath      (3.5.5)
  -- -------- -- ---------

that is

  -- -------- -- ---------
     @xmath      (3.5.6)
  -- -------- -- ---------

so that

  -- -------- -- ---------
     @xmath      (3.5.7)
  -- -------- -- ---------

Equivalently

  -- -------- -- ---------
     @xmath      (3.5.8)
  -- -------- -- ---------

Note the asympototic spacing as @xmath :

  -- -------- -- ---------
     @xmath      (3.5.9)
  -- -------- -- ---------

Note that as @xmath all the QNM are driven to imaginary infinity — this
is compatible with the behaviour of the step potential for which there
are no QNM.

### 3.6 Sech@xmath potential

For a sech @xmath potential of the form

  -- -------- -- ---------
     @xmath      (3.6.1)
  -- -------- -- ---------

the transmission coefficient is known analytically to be (see for
example [ 37 ] ):

  -- -------- -- ---------
     @xmath      (3.6.2)
  -- -------- -- ---------

provided @xmath . This satisfies the general bounds derived later in
this thesis, both the bound @xmath , and the separate bound @xmath .
(Though proving this is somewhat tedious.) Start by noting that for this
sech potential

  -- -------- -- ---------
     @xmath      (3.6.3)
  -- -------- -- ---------

and use the inequality @xmath

  -- -------- -- ---------
     @xmath      (3.6.4)
  -- -------- -- ---------

Then

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (3.6.5)
              @xmath   @xmath      (3.6.6)
  -- -------- -------- -------- -- ---------

Provided that the extremum is a peak, @xmath we can use the bound @xmath
to deduce

  -- -------- -- ---------
     @xmath      (3.6.7)
  -- -------- -- ---------

This is the particularization of the bound @xmath to the present case.
If @xmath we need a different analysis.
Quasinormal modes: @xmath when

  -- -------- -- ---------
     @xmath      (3.6.8)
  -- -------- -- ---------

which leads to

  -- -------- -- ---------
     @xmath      (3.6.9)
  -- -------- -- ---------

But then

  -- -------- -- ----------
     @xmath      (3.6.10)
  -- -------- -- ----------

and so

  -- -------- -- ----------
     @xmath      (3.6.11)
  -- -------- -- ----------

Therefore

  -- -------- -- ----------
     @xmath      (3.6.12)
  -- -------- -- ----------

leading to

  -- -------- -- ----------
     @xmath      (3.6.13)
  -- -------- -- ----------

Finally

  -- -------- -- ----------
     @xmath      (3.6.14)
  -- -------- -- ----------

Again note the asymptotic spacing as @xmath

  -- -------- -- ----------
     @xmath      (3.6.15)
  -- -------- -- ----------

Note that if @xmath is big, the offset term becomes real

  -- -------- -- ----------
     @xmath      (3.6.16)
  -- -------- -- ----------

Finally note what happens as @xmath becomes small,

  -- -------- -- ----------
     @xmath      (3.6.17)
  -- -------- -- ----------

In the limit only one pair of QNM survive

  -- -------- -- ----------
     @xmath      (3.6.18)
  -- -------- -- ----------

the others being driven off to infinity. This agrees with the result for
the single–delta–function potential.

#### Derivation of the amplitudes (sketch):

Let us sketch how to determine the transmission coefficient for a
potential barrier defined by the formula [ 37 ]

  -- -------- -- ----------
     @xmath      (3.6.19)
  -- -------- -- ----------

Comparing this with the analogous bound state computation, it is
necessary merely to alter the sign of @xmath and to regard the energy
@xmath now as positive. A calculation similar to that used for deriving
the bound states when @xmath [ 37 ] , now gives the solution

  -- -------- -- ----------
     @xmath      (3.6.20)
  -- -------- -- ----------

where

  -- -------- -- ----------
     @xmath      (3.6.21)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (3.6.22)
  -- -------- -- ----------

  -- -- -- ----------
           (3.6.23)
  -- -- -- ----------

and @xmath is a hypergeometric function. This solution satisfies the
condition that, as @xmath (i.e. as @xmath ), the wave function should
include only the transmitted wave @xmath . The asymptotic form of the
wave function as @xmath , @xmath is found by transforming the
hypergeometric function with the aid of formula

  -- -------- -- ----------
     @xmath      (3.6.24)
  -- -------- -- ----------

Taking the squared modulus of the ratio of coefficients in this
function, we obtain the following expression for the transmission
coefficient @xmath :

  -- -------- -- ----------
     @xmath      (3.6.25)
  -- -------- -- ----------

when @xmath .

### 3.7 Asymmetric Square-well potential

For the asymmetric square well

  -- -------- -- ---------
     @xmath      (3.7.1)
  -- -------- -- ---------

We now define @xmath . The transmission coefficient is (see for example
[ 51 ] ):

  -- -------- -- ---------
     @xmath      (3.7.2)
  -- -------- -- ---------

Then

  -- -------- -- ---------
     @xmath      (3.7.3)
  -- -------- -- ---------

Similarly to the case for the symmetric square well, the transmission
probability for the asymmetric square well oscillates between the bound
( 6.6.10 ) that we shall subsequently derive, and the unitarity limit
@xmath . For certain values of the width of the well @xmath the
transmission coefficient saturates the bound thus showing that this
bound cannot be improved unless additional hypotheses are made . Because
@xmath the bound @xmath is not applicable, at least not without
modification from its original form.

#### Derivation of the amplitudes (sketch):

As in the problem of the potential step, we build the eigenfunction of
the form [ 51 ]

  -- -------- -- ---------
     @xmath      (3.7.4)
  -- -------- -- ---------

The continuity conditions at points @xmath and @xmath give the values of
@xmath , @xmath , @xmath , and @xmath . Without entering into the
specific details of the calculation, we simply list the results
concerning the quantities @xmath and @xmath . We use the following
notation and conventions:

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

We now derive

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (3.7.5)
     @xmath   @xmath   @xmath      (3.7.6)
  -- -------- -------- -------- -- ---------

The wave is in general only partially transmitted, and we can define a
transmission coefficient (note that we are now using Messiah-like
conventions)

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

### 3.8 Poeschl–Teller potential

The Poeschl–Teller potential is most commonly written (see, e.g. , [ 59
] )

  -- -------- -- ---------
     @xmath      (3.8.1)
  -- -------- -- ---------

we have

  -- -------- -- ---------
     @xmath      (3.8.2)
  -- -------- -- ---------

The transmission coefficient is [ 59 ]

  -- -------- -- ---------
     @xmath      (3.8.3)
  -- -------- -- ---------

It is now a straightforward if tedious exercise to check this analytic
result against all the bounds derived in this thesis.

This Morse–Feshbach presentation of this potential [ 59 ] , as given
above, is rather difficult to interpret — it is much easier to first
translate the potential ( @xmath ) to obtain

  -- -------- -- ---------
     @xmath      (3.8.4)
  -- -------- -- ---------

expand

  -- -------- -- ---------
     @xmath      (3.8.5)
  -- -------- -- ---------

and then re-group terms as

  -- -------- -- ---------
     @xmath      (3.8.6)
  -- -------- -- ---------

to see that this is simply a linear combination of the “sech @xmath ”,
“tanh”, and “constant” potentials. So without loss of generality we can
re-write the Poeschl–Teller potential (with new definition for @xmath )
as:

  -- -------- -- ---------
     @xmath      (3.8.7)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (3.8.8)
  -- -------- -- ---------

in terms of which the analytically known transmission probability is

  -- -------- -- ---------
     @xmath      (3.8.9)
  -- -------- -- ---------

Of course we have already seen that this has at least two much simpler
limits: the @xmath and @xmath potentials. In particular if we let @xmath
and play with a few hyperbolic identities we recover the results for the
sech @xmath potential, while if we let @xmath and play with a few
hyperbolic identities we recover the results of the @xmath potential.
Quasinormal modes: @xmath when

  -- -------- -- ----------
     @xmath      (3.8.10)
  -- -------- -- ----------

That is

  -- -------- -- ----------
     @xmath      (3.8.11)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (3.8.12)
  -- -------- -- ----------

We now rearrange this as

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and note that it has appropriate limits for the tanh and sech @xmath
potentials. Finally, because this is a simple quadratic equation, we
solve for @xmath to obtain

  -- -------- -- ----------
     @xmath      (3.8.14)
  -- -------- -- ----------

By shifting @xmath by @xmath as appropriate we can re-write this as

  -- -------- -- ----------
     @xmath      (3.8.15)
  -- -------- -- ----------

This now has the appropriate limits to reproduce both tanh and sech
@xmath quasinormal modes. Note that asymptotically

  -- -------- -- ----------
     @xmath      (3.8.16)
  -- -------- -- ----------

in accordance with the general suspicions based on black hole QNMs [ 98
] .

### 3.9 Eckart–Rosen–Morse–Poeschl–Teller potential

Many of the potentials commonly encountered in the literature are
actually the same quantity in disguise. To start with, consider the
following three potentials:
Eckart (1930):

  -- -------- -- ---------
     @xmath      (3.9.1)
  -- -------- -- ---------

Rosen–Morse (1932):

  -- -------- -- ---------
     @xmath      (3.9.2)
  -- -------- -- ---------

Poeschl–Teller (1933):

  -- -------- -- ---------
     @xmath      (3.9.3)
  -- -------- -- ---------

To see that all three of these potentials are actually the same, note
that:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (3.9.4)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Furthermore

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (3.9.5)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

This is enough to show

  -- -------- --
     @xmath   
  -- -------- --

In fact in the article of Rosen and Morse [ 67 ] , they cite Eckart [ 69
] , and describe Eckart’s potential as begining “somewhat like” their
own, but without noticing that the two potentials are in fact identical
up to trivial redefinitions of the parameters.

Now, for the Poeschl–Teller potential, note that by a trivial shift
@xmath we have

  -- -------- -- ---------
     @xmath      (3.9.6)
  -- -------- -- ---------

which we can without loss of generality relabel as

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (3.9.7)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

This is enough to show

  -- -------- --
     @xmath   
  -- -------- --

and so all three potentials are completely identical up to trivial
relabeling of the parameters and a shift in the zero of energy. In fact,
including the offset, all three of these can be written in any one of
the four general forms below:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (3.9.8)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Note that there is some redundancy here, but it is a useful redundancy.
It makes it clear that the Eckart–Rosen–Morse–Poeschl–Teller potential
is generally a Mobius function of the variable @xmath . Thus implies
that without loss of generality we can set @xmath as some convenient
constant.

The “best” of these equivalent forms is arguably the Mobius form:

  -- -------- -- ---------
     @xmath      (3.9.9)
  -- -------- -- ---------

Comment: Many authors seem to use the phrase “Poeschl–Teller potential”
only to refer to the special case

  -- -------- -- ----------
     @xmath      (3.9.10)
  -- -------- -- ----------

This is historically inaccurate [ 65 ] , and we will have more to say on
this later.

### 3.10 Mobius potential

Overall, the “best” general version of the potentials considered above
is probably the Mobius form

  -- -------- -- ----------
     @xmath      (3.10.1)
  -- -------- -- ----------

If you want to solve the Schrödinger equation

  -- -------- -- ----------
     @xmath      (3.10.2)
  -- -------- -- ----------

or

  -- -------- -- ----------
     @xmath      (3.10.3)
  -- -------- -- ----------

then, absorbing the @xmath into a redefinition of @xmath and @xmath ,
what you need to do is to solve

  -- -------- -- ----------
     @xmath      (3.10.4)
  -- -------- -- ----------

This can either be solved “by hand”, or with the aid of symbolic
manipulation packages. For instance, Maple still needs a little help.
Without loss of generality, rescale @xmath , and rescale @xmath , and
demand @xmath . This makes the new @xmath and @xmath dimensionless and
we have:

  -- -------- -- ----------
     @xmath      (3.10.5)
  -- -------- -- ----------

This has an explicit solution in terms of hypergeometric functions.
Maple (after a little bit of convincing) gives

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where the suppressed arguments on the hypergeometric functions are:

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (3.10.7)
                                   
     @xmath   @xmath   @xmath      (3.10.8)
                                   
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ----------

and

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (3.10.10)
                                   
     @xmath   @xmath   @xmath      (3.10.11)
                                   
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- -----------

By looking up tabulated properties of the hypergeometric function one
can now determine the bound state eigenvalues, reflection and
transmission coefficients, etc.
In general, the Mobius potential exhibits both bound and free states.
(As it must , since after all the way we have derived it is by showing
that it is equivalent to any of the Manning–Rosen, Poeschl–Teller, or
Eckart potentials.) When the potential energy has a minimum but goes
asymptotically to some higher finite value at @xmath and @xmath , then
some of the allowed energies will be discrete values, corresponding to
states for which the particle is bound in the potential valley. For
other ranges of energy, higher than the minimum of the two asymptotic
values, all energies will be allowed, the particle being free to travel
to infinity.

For instance, consider the wave functions and allowed energies for a
particle of mass @xmath in a Mobius potential that is written in
Poeschl–Teller form [ 59 ]

  -- -------- -- -----------
     @xmath      (3.10.13)
  -- -------- -- -----------

For @xmath positive, this potential field has its minimum value @xmath
at @xmath . As @xmath is increased positive, the potential increases to
an asymptotic value @xmath for @xmath ; as @xmath is made negative,
@xmath also rises to an asymptotic value @xmath , for @xmath .
Classically, since in this form the potential is constrained to be
positive semidefinite, the particle could not have a negative energy;
for energies between zero and @xmath , @xmath , the particle would
oscillate back and forth in the potential valley; for energies between
@xmath and @xmath , the particle could come from @xmath , be reflected
by the potential rise to the right of the minimum, and go back to @xmath
and for energies greater than @xmath , the particle could move from
@xmath to @xmath or from @xmath to @xmath [ 59 ] .

### 3.11 Other potentials:

Furthermore, we would like to at least mention some other potentials:
Morse (1929)

  -- -------- -- ----------
     @xmath      (3.11.1)
  -- -------- -- ----------

The Morse potential is actually a somewhat odd limit of the Mobius
potential as various parameters go to unity or zero. In terms of the
Mobius potential above we need @xmath .
Manning–Rosen (1933)

  -- -------- -- ----------
     @xmath      (3.11.2)
  -- -------- -- ----------

Warning: The relevant citation [ 26 ] is only an abstract in a report of
a conference. To find it with online tools such as PROLA look up
Phys. Rev. 44 (1933)  951, and then manually scan for abstract @xmath .
The form actually given in the abstract is

  -- -------- -- ----------
     @xmath      (3.11.3)
  -- -------- -- ----------

which you can manipulate into the form above by noting

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and

  -- -------- -- ----------
     @xmath      (3.11.5)
  -- -------- -- ----------

Note that the Manning–Rosen potential can be obtained from the Eckart
potential by the substitution

  -- -------- -- ----------
     @xmath      (3.11.6)
  -- -------- -- ----------

In particular, Manning–Rosen can be written in the form

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (3.11.7)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ----------

We can get this from the general Mobius form of the Eckart potential by
appropriately choosing the parameters.
Hulthen @xmath

  -- -------- -- ----------
     @xmath      (3.11.8)
  -- -------- -- ----------

The Hulthen potential [ 70 ] is actually a special case of the
Manning–Rosen potential @xmath . We can also get this from the general
Mobius form of the Eckart potential by appropriately choosing the
parameters.
Tietz @xmath One version of the Tietz potential [ 71 ] is:

  -- -------- -- ----------
     @xmath      (3.11.9)
  -- -------- -- ----------

We can get this from the general Mobius form of the Eckart potential by
appropriately choosing the parameters.
Hua @xmath

  -- -------- -- -----------
     @xmath      (3.11.10)
  -- -------- -- -----------

We can get this [ 117 ] from the general Mobius form of the Eckart
potential by appropriately choosing the parameters. We note

  -- -------- -------- -------- -------- -----------
     @xmath   @xmath   @xmath            (3.11.11)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -----------

If @xmath define @xmath and @xmath .
If @xmath define @xmath and @xmath .
Then we see

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

So all of these potentials are either identical to the Mobius potential,
or special cases of the Mobius potential. To be historically accurate we
should really just call this whole collection of potentials the Eckart
potential, as Eckhart seems to have been the first author to have given
the general form. Unfortunately other names are now in such common use
that historical accuracy is difficult (if not impossible) to recover.

### 3.12 Discussion

Let us summarize the results that we have obtained from this chapter.

In this chapter, we collected many known analytic results in a form
amenable to comparison with the general results we shall soon derive. In
addition, we introduced the concept of quasinormal modes . We shall use
these tools for comparing the bounds with known analytic results.
Moreover, we reproduced some of the analytically known results, and
showed (or at least sketched) how to derive their scattering amplitudes,
and so calculate quantities such as the tunnelling probabilities and
quasinormal modes [QNM]. We did this explicitly for the delta–function
potential, double–delta–function potential, square potential barrier,
tanh potential, sech @xmath potential, asymmetric square-well potential,
the Poeschl–Teller potential and its variants, and finally the
Eckart–Rosen–Morse–Poeschl–Teller potential.

In addition, we are able to gain some deeper understanding by realizing
that the Eckart–Rosen–Morse–Poeschl–Teller potential is generally a
Mobius function of the variable @xmath . Furthermore, the Morse
potential is actually a specific limit of the Mobius potential as
various parameters go to unity or zero. We also demonstrate that the
Hulthen potential is actually a special case of the Manning–Rosen
potential @xmath .

As previously discussed, we have seen that a many of the “exactly
solvable” potentials commonly encountered in the literature are actually
the same quantity in disguise. For instance, we devoted that all of
these potentials are either identical to the Mobius potential, or
special cases of the Mobius potential. Moreover, we should really just
call this the Eckart potential, as he seems to have been the first
author to have given the general form. Unfortunately other names are now
in such common use that historical accuracy is difficult (if not
impossible) to recover.

## Chapter 4 Shabat–Zakharov systems

### 4.1 Introduction

In this chapter we shall present the general concept of the so-called
“Shabat–Zakharov systems”, (sometimes called “Zakharov–Shabat” systems).
We shall re-write the second-order Schrödinger equation as a particular
set of two coupled first order differential equations for which bounds
can be (relatively) easily established. In addition, we shall introduce
the idea of the probability current and demonstrate how to obtain the
probability current density. We shall then use the probability current
(or probability flux) to describe the flow of probability density.

Moreover, we shall present an “auxiliary condition” or “gauge condition”
that is used to relate two complex amplitudes @xmath and @xmath that we
shall soon introduce, and to eliminate @xmath in favour of @xmath . This
allows us to write @xmath in either of two equivalent forms, which is
key to developing a @xmath matrix formalism. We shall represent the wave
function in an inner product form which is the explicit general (but
formal) solution to the Schrödinger equation. The general solution
depends on three arbitrarily chosen functions @xmath , @xmath , and
@xmath , and a path-ordered exponential matrix.

We shall consider path ordering as an “elementary” process to derive the
holy grail of ODE theory (complete quadrature, albeit formal, of the
second-order linear ODE). We shall then use the freedom to independently
choose @xmath , @xmath , and @xmath to simplify the Bogoliubov
coefficients (both the relevant ODEs and the general bounds) as much as
possible.

### 4.2 Ansatz

Consider the one-dimensional time-independent Schrödinger equation [ 37
] – [ 51 ]

  -- -------- -- ---------
     @xmath      (4.2.1)
  -- -------- -- ---------

Introduce the notation

  -- -------- -- ---------
     @xmath      (4.2.2)
  -- -------- -- ---------

So we are really just trying to solve

  -- -------- -- ---------
     @xmath      (4.2.3)
  -- -------- -- ---------

or equivalently in the time domain

  -- -------- -- ---------
     @xmath      (4.2.4)
  -- -------- -- ---------

Motivated by the JWKB approximation,

  -- -------- -- ---------
     @xmath      (4.2.5)
  -- -------- -- ---------

the key idea is to re-write the second-order Schrödinger equation as a
set of two coupled first-order linear differential equations (for which
bounds can relatively easily be established).

Systems of differential equations of this type are often referred to as
Shabat–Zakharov [ 53 ] systems. A similar representation of the
Schrödinger equation is briefly discussed by Peierls [ 54 ] and related
representations are well-known, often being used without giving an
explicit reference (see e.g. [ 55 ] ). However an exhaustive search has
not uncovered prior use of the particular representation presented here,
(apart, of course, from [ 88 ] ), nor the idea of using the
representation to place bounds on one-dimensional scattering.

We will start by introducing two arbitrary auxiliary functions @xmath
and @xmath which may be either real or complex, though we do demand that
@xmath , and then defining

  -- -------- -- ----------
     @xmath      (4.2.10)
  -- -------- -- ----------

This representation effectively seeks to use quantities resembling the
“phase integral” wavefunctions as a basis for the true wavefunction [ 31
] . We will ultimately want to interpret @xmath and @xmath as
“position-dependent WKB-like coefficients”; in a scattering problem they
can be thought of as “position-dependent Bogoliubov coefficients”. This
representation is of course extremely highly redundant, since one
complex number @xmath has been traded for two complex numbers @xmath and
@xmath , plus two essentially arbitrary auxiliary functions @xmath and
@xmath .

To reduce this freedom, we introduce an “auxiliary condition” (or
“auxiliary constraint”, or “gauge condition”):

  -- -------- -- ----------
     @xmath      (4.2.11)
  -- -------- -- ----------

Here @xmath is yet a third arbitrary function of position. It is allowed
to be complex, and may be zero. The original analysis, published in [ 88
] corresponds to the special case @xmath and @xmath . Subject to this
gauge condition,

  -- -------- -- ----------
     @xmath      (4.2.12)
  -- -------- -- ----------

Repeated differentiation of this equation will soon lead to our desired
result.

### 4.3 Probability current

We use the probability current (or probability flux) to describe the
flow of probability density. The following equation is use to describe
the flow of a fluid, a process which occurs all the way through physics
and applied mathematics [ 13 ]

  -- -------- -- ---------
     @xmath      (4.3.1)
  -- -------- -- ---------

The above equation tells us that the rate of change in density is equal
to the negative of the difference between the amount of “stuff” (be it
water, air, or “probability”) flowing into the point and the amount
flowing out. Now in the context of the Schrödinger equation, we can
write the probability density in the following form

  -- -------- -- ---------
     @xmath      (4.3.2)
  -- -------- -- ---------

In quantum mechanics we can certainly describe the movement of
particles, however we also have an additional difficulty because our
particles are not classical. Therefore we can only talk about the
probability of the particle being at a certain place in time, now we can
talk about a probability current or flux. Consider the time–dependent
Schrödinger Equation and its complex conjugate:

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (4.3.3)
     @xmath   @xmath   @xmath      (4.3.4)
  -- -------- -------- -------- -- ---------

Now let us differentiate the probability density with respect to time

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.3.5)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Apply

  -- -------- -- ---------
     @xmath      (4.3.6)
  -- -------- -- ---------

So we obtain the probability current density

  -- -------- -- ---------
     @xmath      (4.3.7)
  -- -------- -- ---------

We can re-write this as

  -- -------- -- ---------
     @xmath      (4.3.8)
  -- -------- -- ---------

Here @xmath is just a normalization (that is often set @xmath for
convenience). There is nothing really important in this normalization
(unless we want to calculate experimental numbers), so we might as well
set

  -- -- -- ---------
           (4.3.9)
  -- -- -- ---------

Now at this stage @xmath and @xmath are completely arbitrary possibly
complex functions subject only to the constraint @xmath . For future
use, compute the probability current using our WKB-based ansatz in terms
of @xmath and @xmath :

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.3.13)
                       @xmath   @xmath   
                                         
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ----------

### 4.4 SDE as a first order system

We now re-write the Schrödinger equation in terms of two coupled
first-order differential equations for these position-dependent
WKB/Bogoliubov coefficients @xmath and @xmath . To do this we evaluate
@xmath in two different ways, making repeated use of the gauge
condition. First

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.4.3)
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

But then

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.4.4)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

So finally

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Now use the gauge condition to eliminate @xmath in favour of @xmath .
This permits us to write @xmath in either of the two equivalent forms

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.4.6)
                                @xmath   
  -- -------- -------- -------- -------- ---------

and

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.4.7)
                                @xmath   
  -- -------- -------- -------- -------- ---------

Now insert these formulae into the Schrödinger equation written in the
form

  -- -------- -- ---------
     @xmath      (4.4.8)
  -- -------- -- ---------

to deduce the first-order system:

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.4.9)
                                @xmath   
     @xmath   @xmath   @xmath            (4.4.10)
                                @xmath   
  -- -------- -------- -------- -------- ----------

It is easy to verify that this first-order system is compatible with the
“gauge condition” ( 4.2.11 ), and that by iterating the system twice
(subject to this gauge condition) one recovers exactly the original
Schrödinger equation. These equations hold for arbitrary @xmath , @xmath
, and @xmath , real or complex.

When written in @xmath matrix form, these equations exhibit a deep
connection with the transfer matrix formalism [ 56 ] . Let us define
quantities @xmath and @xmath , not necessarily real, as

  -- -------- -- ----------
     @xmath      (4.4.11)
  -- -------- -- ----------

We can then re-write the Shabat–Zakharov system in matrix form as

  -- -------- -- ----------
     @xmath      (4.4.12)
  -- -------- -- ----------

This has the formal solution

  -- -------- -- ----------
     @xmath      (4.4.13)
  -- -------- -- ----------

in terms of a generalized position-dependent “transfer matrix” [ 56 ]

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where the symbol @xmath denotes “path ordering”.

Path ordering: In theoretical physics, path–ordering is the procedure
(or meta-operator @xmath ) of ordering a product of many operators
according to the value of one chosen parameter [ 29 ] :

@xmath (4.4.15)

Here @xmath is a permutation that orders the parameters: @xmath . For
instance

@xmath (4.4.16)

Equivalently if we were to be working in the time domain we would have

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where @xmath would now be the well-known “time ordering” operator (more
usually encountered in quantum field theory) and we would now define

  -- -------- -- ----------
     @xmath      (4.4.18)
  -- -------- -- ----------

with @xmath , @xmath , and @xmath now being arbitrary functions of
@xmath rather than @xmath .

We can now write the wave function in inner product form

  -- -------- -- ----------
     @xmath      (4.4.19)
  -- -------- -- ----------

to yield a formal but completely general solution for the Schrödinger
equation

  -- -- -- ----------
           (4.4.20)
  -- -- -- ----------

Explicitly

  -- -------- -- ----------
     @xmath      (4.4.21)
                 
  -- -------- -- ----------

This is the explicit general solution to the Schrödinger equation. It
depends on the three arbitrarily chosen functions @xmath , @xmath , and
@xmath , and a path-ordered exponential matrix. If you consider path
ordering to be an “elementary” process, then this is indeed the holy
grail of ODE theory (complete quadrature, albeit formal, of the
second-order linear ODE).

### 4.5 Bounding the coefficients @xmath and @xmath

From

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (4.5.1)
                                @xmath   
                                         
     @xmath   @xmath   @xmath            (4.5.2)
                                @xmath   
  -- -------- -------- -------- -------- ---------

we see

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Therefore (now assuming for the rest of this section that @xmath ,
@xmath , @xmath are all real and @xmath )

  -- -------- -- ---------
     @xmath      (4.5.4)
  -- -------- -- ---------

This implies

  -- -------- -- ---------
     @xmath      (4.5.5)
  -- -------- -- ---------

But @xmath , so we have

  -- -------- -- ---------
     @xmath      (4.5.6)
  -- -------- -- ---------

implying

  -- -------- -- ---------
     @xmath      (4.5.7)
  -- -------- -- ---------

Thus

  -- -------- -- ---------
     @xmath      (4.5.8)
  -- -------- -- ---------

and so

  -- -------- -- ---------
     @xmath      (4.5.9)
  -- -------- -- ---------

Now if (as per our current assumption) @xmath , @xmath , @xmath are all
real, then it is easy to check that

  -- -------- -- ----------
     @xmath      (4.5.10)
  -- -------- -- ----------

so current conservation implies

  -- -------- -- ----------
     @xmath      (4.5.11)
  -- -------- -- ----------

Ultimately, it is this equation that allows us to interpret @xmath and
@xmath as “position dependent Bogoliubov coefficients”.

In view of the relation between @xmath and @xmath we have @xmath , so
that we can deduce

  -- -------- -- ----------
     @xmath      (4.5.12)
  -- -------- -- ----------

But this inequality can now be integrated. For convenience let us define

  -- -------- -- ----------
     @xmath      (4.5.13)
  -- -------- -- ----------

Then

  -- -------- -- ----------
     @xmath      (4.5.14)
  -- -------- -- ----------

But now

  -- -------- -- ----------
     @xmath      (4.5.15)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (4.5.16)
  -- -------- -- ----------

Now apply the boundary conditions: as @xmath we have chosen to set
things up so that we have a pure transmitted wave, so @xmath and @xmath
. On the other hand as @xmath we have chosen to set things up so that
@xmath and @xmath tend to @xmath and @xmath , the Bogoliubov
coefficients we are interested in calculating. Thus taking the double
limit @xmath and @xmath we see:

  -- -------- -- ----------
     @xmath      (4.5.17)
  -- -------- -- ----------

That is

  -- -------- -- ----------
     @xmath      (4.5.18)
  -- -------- -- ----------

This is the central result of this thesis — it can be modified and
rearranged in a number of ways, and related inequalities can be derived
under slightly different hypotheses, but all the applications we are
interested in will reduce in one way or another to an application of
this inequality or one of its close variants.

For notational convenience, we often find it is useful to adopt the
shorthand

  -- -------- -- ----------
     @xmath      (4.5.19)
  -- -------- -- ----------

since then

  -- -------- -- ----------
     @xmath      (4.5.20)
  -- -------- -- ----------

From the normalization condition ( 4.5.11 ) we immediately deduce

  -- -------- -- ----------
     @xmath      (4.5.21)
  -- -------- -- ----------

When translated into equivalent statements about transmission an
reflection probabilities, we find

  -- -------- -- ----------
     @xmath      (4.5.22)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (4.5.23)
  -- -------- -- ----------

Now one of the the points of the exercise (and of this thesis) is to use
the freedom to independently choose @xmath , @xmath , and @xmath to
simplify life as much as possible. Here are a few special cases, chosen
for their simplicity and the lessons they teach us.

#### 4.5.1 Case: @xmath

No one can prevent us from choosing

  -- -------- -- ----------
     @xmath      (4.5.24)
  -- -------- -- ----------

that is

  -- -------- -- ----------
     @xmath      (4.5.25)
  -- -------- -- ----------

which implies

  -- -------- -- ----------
     @xmath      (4.5.26)
  -- -------- -- ----------

Doing that greatly simplifies life since now the system of ODEs becomes

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (4.5.27)
                                   
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ----------

That is

  -- -- -- ----------
           (4.5.29)
  -- -- -- ----------

If you now let @xmath and @xmath be real, then the matrix above is
Hermitian; unfortunately this does not tell us all that much about the
evolution operator. (If we had @xmath times a Hermitian operator
appearing above, then the evolution operator would have been unitary.)
Using a specialization of the previous argument, we can easily deduce

  -- -------- -- ----------
     @xmath      (4.5.30)
  -- -------- -- ----------

We also have the same constraint

  -- -------- -- ----------
     @xmath      (4.5.31)
  -- -------- -- ----------

and so deduce

  -- -------- -- ----------
     @xmath      (4.5.32)
  -- -------- -- ----------

Defining

  -- -------- -- ----------
     @xmath      (4.5.33)
  -- -------- -- ----------

we have

  -- -------- -- ----------
     @xmath      (4.5.34)
  -- -------- -- ----------

This inequality can now be integrated in the manner discussed above,
though doing so gives us no additional information.

#### 4.5.2 Case: @xmath

No one can prevent us from choosing

  -- -------- -- ----------
     @xmath      (4.5.35)
  -- -------- -- ----------

in which case

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.5.36)
                                @xmath   
     @xmath   @xmath   @xmath            (4.5.37)
                                @xmath   
  -- -------- -------- -------- -------- ----------

The complicated phase structure has gone away, and we have

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.5.38)
                                @xmath   
  -- -------- -------- -------- -------- ----------

whence

  -- -------- -- ----------
     @xmath      (4.5.39)
  -- -------- -- ----------

Perhaps more to the point, we can derive ODEs for the sums and
differences:

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (4.5.40)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ----------

that is

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (4.5.42)
     @xmath   @xmath   @xmath      
  -- -------- -------- -------- -- ----------

While this system of ODEs is somewhat simpler than those derived above,
we have not been able to extract any significant improvement on or
previous results in equations ( 4.5.13 ) and ( 4.5.18 ).

#### 4.5.3 Case: @xmath

We include this case for historical reasons, as it was the first
generalization we obtained of the original result published in [ 88 ] .
The derivation is somewhat simpler than the full @xmath discussion
presented above, and the ultimate bound we extract is no weaker.

We introduce an arbitrary auxiliary function @xmath which may be either
real or complex, however we demand that @xmath , and then define

  -- -------- -- ----------
     @xmath      (4.5.44)
  -- -------- -- ----------

Again, to trim down the number of degrees of freedom it is useful to
impose what can be thought of as a “gauge condition” (“auxiliary
condition”)

  -- -------- -- ----------
     @xmath      (4.5.45)
  -- -------- -- ----------

Here @xmath is some arbitrary function of position. The original
analysis in [ 88 ] corresponds to the special case @xmath . Subject to
this gauge condition,

  -- -------- -- ----------
     @xmath      (4.5.46)
  -- -------- -- ----------

Now the Schrödinger equation can be rewritten in terms of two coupled
first-order differential equations for these position-dependent
Bogoliubov coefficients. We have to calculate @xmath making repeated use
of the gauge condition:

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.5.50)
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
              @xmath   @xmath            (4.5.51)
  -- -------- -------- -------- -------- ----------

Now use the gauge condition to eliminate @xmath in favour of @xmath .
Finally, this permits us to write @xmath in either of the two equivalent
forms

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
              @xmath   @xmath   
  -- -------- -------- -------- --

Now insert these formulae into the Schrödinger equation written in the
form

  -- -------- -- ----------
     @xmath      (4.5.54)
  -- -------- -- ----------

to deduce

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (4.5.55)
                                @xmath   
                                         
     @xmath   @xmath   @xmath            
                       @xmath            
  -- -------- -------- -------- -------- ----------

It is (again) easy to verify that this first-order system is compatible
with the “gauge condition” ( 4.5.45 ), and that by iterating the system
twice (subject to this gauge condition) one recovers exactly the orginal
Schrödinger equation. These equations hold for arbitrary @xmath and
@xmath , real or complex, and when written in matrix form, exhibit a
deep connection with the transfer matrix formalism [ 56 ] . Let us
define quantities @xmath and @xmath , not necessarily real, as

  -- -------- -- ----------
     @xmath      (4.5.57)
  -- -------- -- ----------

We can then re-write the Shabat–Zakharov system in matrix form as

  -- -------- -- ----------
     @xmath      (4.5.58)
  -- -------- -- ----------

This has the formal solution

  -- -------- -- ----------
     @xmath      (4.5.59)
  -- -------- -- ----------

in terms of a generalized position-dependent “transfer matrix” [ 56 ]

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

where the symbol @xmath denotes “path ordering”. (See the boxed text
earlier in this chapter for details.) Now we can write the wave function
in inner product form

  -- -------- -- ----------
     @xmath      (4.5.61)
  -- -------- -- ----------

and where

  -- -------- -- ----------
     @xmath      (4.5.62)
  -- -------- -- ----------

Therefore

  -- -------- -- ----------
     @xmath      (4.5.63)
  -- -------- -- ----------

to yield a formal but completely general solution for the Schrödinger
equation

  -- -------- -- ----------
     @xmath      (4.5.64)
  -- -------- -- ----------

Explicitly

  -- -------- -- ----------
     @xmath      
     @xmath      
     @xmath      (4.5.65)
  -- -------- -- ----------

This is the explicit general solution to the Schrödinger equation. It
depends on the two arbitrarily chosen functions @xmath and @xmath and a
path-ordered exponential matrix. If you consider path ordering to be an
“elementary” process, then this is (again) the holy grail of ODE theory
(complete quadrature, albeit formal, of the second-order linear ODE).

The development of bounds automatically follows as in the previous
discussion, and we can without further calculation assert that equations
( 4.5.13 ) and ( 4.5.18 ) hold in this situation as well.

### 4.6 Discussion

There are several ways to derive a number of rigourous bounds on
transmission probabilities (and reflection probabilities and Bogoliubov
coefficients) for one-dimensional scattering problems. The derivation of
these bounds generally proceeds by rewriting the Schrödinger equation in
terms of some equivalent system of first-order equations, and then
analytically bounding the growth of certain quantities related to the
net flux of particles as one sweeps across the potential. In this
chapter we obtained a number of significant bounds, considerably
stronger than those in [ 88 ] , of both theoretical and practical
interest.

Even though the calculations we have presented are sometimes somewhat
tedious, we feel however, they are more than worth the effort — since
there is a fundamental lesson to be learnt from them. Technically, we
demonstrated that the Schrödinger equation can be written as a
Shabat–Zakharov system, which can then be re-written in @xmath matrix
form. We rearranged this formation in terms of a generalized
position-dependent “transfer matrix” involving the symbol @xmath which
denotes “path ordering”. Therefore the wavefunction @xmath can be
written in inner product form. This is the explicit general solution to
the Schrödinger equation. It depends on the three arbitrarily chosen
functions @xmath , @xmath , and @xmath and a path-ordered exponential
matrix. If one considers path ordering to be an “elementary” process,
then this is the holy grail of ODE theory (complete quadrature, albeit
formal, of the second-order linear ODE). We have seen that it is often
convenient to use the freedom to independently choose @xmath , @xmath ,
and @xmath to simplify life as much as possible. Furthermore, we have
considered a few special cases. For instance, case @xmath , case @xmath
, and case @xmath . The bounds that we have derived on the Bogoliubov
coefficients @xmath and @xmath , and on the transmission and reflection
probabilities @xmath and @xmath , are the key results of this thesis —
the next few chapters will be devoted to developing several variants of
these bounds, developing independent proofs that might ultimately lead
to new bounds, and developing various applications of these bounds.

## Chapter 5 First derivation of the bounds

### 5.1 Introduction

In this chapter we shall review the analysis of [ 88 ] , developing
various techniques for estimating the scattering properties. We shall
review and briefly describe some very general bounds for reflection and
transmission coefficients for one-dimensional potential scattering, and
then indicate how the results of this thesis extend and expand on the
earlier results. Equivalently, these results may be phrased as general
bounds on the Bogoliubov coefficients, or statements about the transfer
matrix [ 88 ] .

Finally, we shall re-demonstrate the use of Shabat–Zakharov system of
ODEs (now in a greatly simplified context) to derive a first elementary
bound on the transmission, reflection, and Bogoliubov coefficients.

### 5.2 Shabat–Zakharov systems

Consider the one-dimensional time-independent Schrödinger equation [ 37
] – [ 51 ]

  -- -------- -- ---------
     @xmath      (5.2.1)
  -- -------- -- ---------

If the potential asymptotes to a constant,

  -- -------- -- ---------
     @xmath      (5.2.2)
  -- -------- -- ---------

then in each of the two asymptotic regions there are two independent
solutions to the Schrödinger equation

  -- -------- -- ---------
     @xmath      (5.2.3)
  -- -------- -- ---------

Here the @xmath distinguishes right-moving modes @xmath from left-moving
modes @xmath , while the @xmath specifies which of the asymptotic
regions we are in. Furthermore

  -- -------- -- ---------
     @xmath      (5.2.4)
  -- -------- -- ---------

To even begin to set up a scattering problem the minimum requirements
are that the potential asymptote to some constant, and this assumption
will be made henceforth.

The so-called Jost solutions [ 52 ] are exact solutions @xmath of the
Schrödinger equation that satisfy

  -- -------- -- ----------
     @xmath      (5.2.11)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (5.2.12)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (5.2.13)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (5.2.14)
  -- -------- -- ----------

Here @xmath and @xmath are the (right-moving) Bogoliubov coefficients,
which are related to the (right-moving) reflection and transmission
amplitudes by

  -- -------- -- ----------
     @xmath      (5.2.15)
  -- -------- -- ----------

These conventions correspond to an incoming flux of right-moving
particles (incident from the left) being partially transmitted and
partially scattered. The left-moving Bogoliubov coefficients are just
the complex conjugates of the right-moving coefficients, however it
should be borne in mind that the phases of @xmath and @xmath are
physically meaningless in that they can be arbitrarily changed simply by
moving the origin of coordinates. The phases of @xmath and @xmath on the
other hand do contain real physical information.

In this chapter we will derive some very general bounds on @xmath and
@xmath , which also lead to general bounds on the reflection and
transmission probabilities

  -- -------- -- ----------
     @xmath      (5.2.19)
  -- -------- -- ----------

The key idea is to re-write the second-order Schrödinger equation as a
particular type of Shabat–Zakharov [ 53 ] system: a particular set of
two coupled first-order differential equations for which bounds can be
easily established. A similar representation of the Schrödinger equation
is briefly discussed by Peierls [ 54 ] and related representations are
well-known, often being used without giving an explicit reference (see
e.g. [ 55 ] ). However an exhaustive search has not uncovered prior use
of the particular representation of this chapter, nor the idea of using
the representation to place bounds on one-dimensional scattering.

We start by introducing an arbitrary auxiliary function @xmath which may
be either real or complex, though we do demand that @xmath , and then
defining

  -- -------- -- ----------
     @xmath      (5.2.20)
  -- -------- -- ----------

This representation effectively seeks to use quantities resembling the
“phase integral” wavefunctions as a basis for the true wavefunction [ 72
] . This representation is of course highly redundant, since one complex
number @xmath has been traded for two complex numbers @xmath and @xmath
plus an essentially arbitrary auxiliary function @xmath . In order for
this representation to be most useful it is best to arrange things so
that @xmath and @xmath asymptote to constants at spatial infinity, which
we shall soon see implies that we should pick the auxiliary function to
satisfy

  -- -------- -- ----------
     @xmath      (5.2.21)
  -- -------- -- ----------

To trim down the number of degrees of freedom it is useful to impose a
“gauge condition”

  -- -------- -- ----------
     @xmath      (5.2.22)
  -- -------- -- ----------

Subject to this gauge condition,

  -- -------- -- ----------
     @xmath      (5.2.23)
  -- -------- -- ----------

We now re-write the Schrödinger equation in terms of two coupled
first-order differential equations for these position-dependent
Bogoliubov coefficients. To do this note that

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      (5.2.27)
  -- -------- -------- -------- -- ----------

(The last two relations use the “gauge condition”.) Now insert these
formulae into the Schrödinger equation written in the form

  -- -------- -- ----------
     @xmath      (5.2.28)
  -- -------- -- ----------

to deduce

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (5.2.29)
                                @xmath   
     @xmath   @xmath   @xmath            (5.2.30)
                                @xmath   
  -- -------- -------- -------- -------- ----------

It is easy to verify that this first-order system is compatible with the
“gauge condition” ( 5.2.22 ), and that by iterating the system twice
(subject to this gauge condition) one recovers exactly the original
Schrödinger equation. These equations hold for arbitrary @xmath , real
or complex, and when written in matrix form, exhibit a deep connection
with the transfer matrix formalism [ 73 ] .

### 5.3 Bounds

To obtain our bounds on the Bogoliubov coefficients we start by
restricting attention to the case that @xmath is a real function of
@xmath . (Since @xmath is an essentially arbitrary auxiliary function
this is not a particularly restrictive condition). Under this assumption
the probability current is

  -- -------- -- ---------
     @xmath      (5.3.1)
  -- -------- -- ---------

Now at @xmath the wavefunction is purely right-moving and normalized to
1, because we are considering one-dimensional Jost solutions [ 52 ] .
Then for all @xmath we have a conserved quantity

  -- -------- -- ---------
     @xmath      (5.3.2)
  -- -------- -- ---------

It is this result that makes it useful to interpret @xmath and @xmath as
position-dependent Bogoliubov coefficients relative to the auxiliary
function @xmath . Now use the fact that

  -- -------- -- ---------
     @xmath      (5.3.3)
  -- -------- -- ---------

and use equation ( 5.2.29 ) to obtain

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

That is

  -- -------- -------- -- --
     @xmath   @xmath      
  -- -------- -------- -- --

The right hand side can now be bounded from above, by systematically
using @xmath . This leads to

  -- -------- -- ---------
     @xmath      (5.3.6)
  -- -------- -- ---------

It is essential that @xmath be real to have @xmath which is the other
key ingredient above. Now define the non-negative quantity

  -- -------- -- ---------
     @xmath      (5.3.7)
  -- -------- -- ---------

and use the conservation law ( 5.3.2 ) to write

  -- -------- -- ---------
     @xmath      (5.3.8)
  -- -------- -- ---------

Integrate this inequality

  -- -------- -- ---------
     @xmath      (5.3.9)
  -- -------- -- ---------

Taking limits as @xmath and @xmath

  -- -------- -- ----------
     @xmath      (5.3.10)
  -- -------- -- ----------

That is

  -- -------- -- ----------
     @xmath      (5.3.11)
  -- -------- -- ----------

Which automatically implies

  -- -------- -- ----------
     @xmath      (5.3.12)
  -- -------- -- ----------

Since this result holds for all real choices of the auxiliary function
@xmath , (subject only to @xmath and @xmath as @xmath ), it encodes an
enormously wide class of bounds on the Bogoliubov coefficients. When
translated to reflection and transmission coefficients the equivalent
statements are

  -- -------- -- ----------
     @xmath      (5.3.13)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (5.3.14)
  -- -------- -- ----------

We shall soon turn this general result into more specific theorems in
chapter 6 .

### 5.4 Transfer matrix representation

The system of equations ( 5.2.29 )–( 5.2.30 ) can also be written in
matrix form. It is convenient to define

  -- -------- -- ---------
     @xmath      (5.4.6)
  -- -------- -- ---------

Then

  -- -- -- ---------
           (5.4.7)
  -- -- -- ---------

This has the formal solution

  -- -------- -- ---------
     @xmath      (5.4.8)
  -- -------- -- ---------

in terms of a generalized position-dependent “transfer matrix” [ 73 ]

  -- -------- --
     @xmath   
              
  -- -------- --

where the symbol @xmath denotes “path ordering”. In particular, if we
take @xmath and @xmath we obtain a formal but exact expression for the
Bogoliubov coefficients

  -- -------- --
     @xmath   
     @xmath   
  -- -------- --

The matrix @xmath is not unitary, though it does have determinant 1. It
is in fact an element of the group @xmath . Taking

  -- -------- -- ----------
     @xmath      (5.4.11)
  -- -------- -- ----------

then @xmath , and defining @xmath , it is easy to see

  -- -------- -- ----------
     @xmath      (5.4.12)
  -- -------- -- ----------

This is the analog of the invariance of the Minkowski metric for Lorentz
transformations in @xmath .

### 5.5 Discussion

In this chapter we have re-cast, re-analyzed, and described the first
derivation of scattering bounds as presented in [ 88 ] . The formalism
as developed here works in terms of one free function @xmath . In other
parts of this thesis we have established generalized bounds; some in
terms of two arbitrary functions @xmath and @xmath , and some in terms
of three arbitrary functions @xmath , @xmath , and @xmath . The
derivation of the present chapter is noteworthy because of its brevity
and simplicity — and this chapter has acted as a “seed”, suggesting and
hinting at generalizations that have ultimately become the content of
the previous chapter. Of course, the “simple” calculation reported in
this chapter is also the seed for the various published journal articles
that have already arisen from this thesis, articles which are displayed
in the appendices to the thesis.

## Chapter 6 Bounds: Special cases

In this chapter we shall deal with some specific cases of these general
bounds and develop a number of interesting specializations. We shall
collect together a large number of results that otherwise appear quite
unrelated, including reflection above and below the barrier. We have
divided the special case bounds we consider into five sub-cases: Special
cases 1–4, and “future directions”.

### 6.1 Bounds: Special case 1

We now reproduce the bounds of special case 1 in [ 88 ] .

Suppose now that the potential satisfies @xmath . Also, choose the phase
function @xmath to be @xmath and take @xmath . We also require @xmath ,
that is @xmath . This is the special case discussed in a different
context by Peierls [ 54 ] . Then the evolution equations simplify
tremendously.

We consider the quantity

  -- -------- -- ---------
     @xmath      (6.1.1)
  -- -------- -- ---------

which represents the generalization that we derived earlier in this
thesis, in equation ( 4.5.13 ), of the bound reported in [ 88 ] . When
@xmath , then @xmath , and if we additionally choose @xmath , then this
simplifies to

  -- -------- -- ---------
     @xmath      (6.1.2)
  -- -------- -- ---------

Inserting this into our general bound now reproduces case 1 of [ 88 ] as
desired.

Furthermore, we can calculate

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

From the previous chapters 4 and 5 , we derive

  -- -------- -- ---------
     @xmath      (6.1.3)
  -- -------- -- ---------

when @xmath , then @xmath . Now we can find

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as desired.

Similarly one can find @xmath in terms of @xmath . Note

  -- -------- -- ---------
     @xmath      (6.1.5)
  -- -------- -- ---------

Using @xmath , the bounds become

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.1.6)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

and

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.1.7)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

These bounds are exact non-perturbative results, however for high
energies it may be convenient to use the slightly less restrictive (but
analytically much more tractable) bounds obtained by simply taking the
first non-trivial term in the Taylor series.

When @xmath , using @xmath , the bounds become

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.1.8)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

and

  -- -------- -- ---------
     @xmath      (6.1.9)
  -- -------- -- ---------

This version of the bounds also holds for all energies, but is not very
restrictive for low energy. (Somewhat better low energy bounds are
developed in the chapter dealing with the Miller–Good transformation.
See also the chapter 9 on black hole greybody factors.) Note that the
bounds of this subsection make perfectly good sense for both scattering
“over the barrier” or “under the barrier”, there is no requirement on
the presence or absence of classical turning points.

The transfer matrices can be analyzed by checking that the evolution
equations simplify to

  -- -------- -- ----------
     @xmath      (6.1.10)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (6.1.11)
  -- -------- -- ----------

This can be written in matrix form as

  -- -- -- ----------
           (6.1.12)
  -- -- -- ----------

This version of the Shabat–Zakharov system [ 53 ] has a formal solution
in terms of the relatively simple transfer matrix

  -- -------- -- ----------
     @xmath      (6.1.13)
  -- -------- -- ----------

The formal but exact expression for the Bogoliubov coefficients is now

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Furthermore, the form of the system ( 6.1.10 )–( 6.1.11 ) suggests that
it might be useful to define

  -- -------- -- ----------
     @xmath      (6.1.15)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (6.1.16)
  -- -------- -- ----------

Then

we can substitute equations ( 6.1.15 ) and ( 6.1.16 ) into equation (
6.1.12 ). We derive

  -- -------- -- ----------
     @xmath      (6.1.17)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.1.18)
  -- -------- -- ----------

respectively. This representation simplifies some of the results, for
instance

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Also note that

  -- -------- -- ----------
     @xmath      (6.1.20)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (6.1.21)
  -- -------- -- ----------

This can be used as the basis of an approximation scheme for @xmath .
Suppose that for all @xmath we have @xmath , so that @xmath . Then

  -- -------- -- ----------
     @xmath      (6.1.22)
  -- -------- -- ----------

This may be immediately integrated to yield

  -- -------- -- ----------
     @xmath      (6.1.23)
  -- -------- -- ----------

This is immediately recognizable as the (first) Born approximation. If
we instead work in terms of the original definition @xmath we obtain a
slightly different approximation

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

This is one form of the distorted Born wave approximation.

In brief, the analysis of this chapter has so far collected together a
large number of results that otherwise appear quite unrelated. By taking
further specific cases of these bounds, and related results, it is
possible to reproduce many analytically known results, such as those for
delta-function potentials, double-delta-function potentials, square
wells, and @xmath potentials, as discussed later in this chapter.

### 6.2 Bounds: special case 2

Having developed a good understanding of the bounds for special case 1,
now we reconsider the bounds for special case 2 in [ 88 ] : Suppose now
we take @xmath and again set @xmath . This implies that we are choosing
our auxiliary function so that we use the @xmath approximation for the
true wavefunction as a “basis” for calculating the Bogoliubov
coefficients.

This choice is perfectly capable of dealing with the case @xmath , but
by reason of the assumed reality of @xmath is limited to considering
scattering the potential barrier. (This is the special case implicit in
a different context in [ 55 ] ). The evolution equations again simplify
tremendously.

When we substitute @xmath and @xmath into equation ( 4.5.55 ) and
equation ( 4.5.3 ), we obtain:

  -- -------- -- ---------
     @xmath      (6.2.1)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (6.2.2)
  -- -------- -- ---------

This form of the evolution equations can be related to the qualitative
discussion of scattering “over a potential barrier” presented by Migdal
[ 57 , 58 ] . For this choice of auxiliary functions we consider the
equation ( 6.1.1 ) to derive

  -- -------- -- ---------
     @xmath      (6.2.3)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (6.2.4)
  -- -------- -- ---------

and the bounds become

  -- -------- -- ---------
     @xmath      (6.2.5)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.2.6)
  -- -------- -- ---------

The relevant transfer matrix is now

  -- -------- -- ---------
     @xmath      (6.2.7)
  -- -------- -- ---------

The Bogoliubov coefficients are now

  -- -------- -- ---------
     @xmath      (6.2.8)
  -- -------- -- ---------

### 6.3 Reflection above the barrier

The system ( 6.2.1 )-( 6.2.2 ) can also be used as the basis of an
approximation scheme for @xmath . Suppose that for all @xmath we have
@xmath , so that @xmath . Then

  -- -------- -- ---------
     @xmath      (6.3.1)
  -- -------- -- ---------

This may be immediately integrated to yield

  -- -------- -- ---------
     @xmath      (6.3.2)
  -- -------- -- ---------

Or the equivalent

  -- -------- -- ---------
     @xmath      (6.3.3)
  -- -------- -- ---------

This result serves to clarify the otherwise quite mysterious discussion
of so-called “reflection above the barrier” given by Migdal [ 57 , 58 ]
. Even though the WKB wavefunctions are buried in the representation of
the wavefunction underlying the analysis leading to this approximation,
the validity of this result for @xmath does not require validity of the
WKB approximation.

If the shifted potential, @xmath , is “small” then we can recover the
Born approximation in the usual manner. In that case @xmath , while
@xmath . A single integration by parts then yields

  -- -------- -- ---------
     @xmath      (6.3.4)
  -- -------- -- ---------

This is now equivalent to the first Born approximation, in this
particular context.

### 6.4 Under the barrier?

What goes wrong when we try to extend this analysis into the classically
forbidden region? Analytically continuing the system ( 6.2.1 )–( 6.2.2 )
is trivial, replace

  -- -------- -- ---------
     @xmath      (6.4.1)
  -- -------- -- ---------

therefore

  -- -------- -- ---------
     @xmath      (6.4.2)
  -- -------- -- ---------

and (as required)

  -- -------- -- ---------
     @xmath      (6.4.3)
  -- -------- -- ---------

Now let

  -- -------- -- ---------
     @xmath      (6.4.4)
  -- -------- -- ---------

and write

  -- -------- -- ---------
     @xmath      (6.4.5)
  -- -------- -- ---------

We will now use these results to re-analyze the Shabat–Zakharov system.
Substitute the two above equations into equation ( 6.2.1 ), we obtain

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.4.6)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Similarly to the equation ( 6.2.2 ), we obtain

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.4.7)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Thus we are now violating our previous condition that @xmath be real,
though we still require @xmath . This is a perfectly good
Shabat–Zakharov system that works in the forbidden region. But you
cannot now use this to derive bounds on the transmission coefficient.
The fly in the ointment resides in the fact that the formula for the
probability current is modified, and that in the forbidden region the
probability current is

  -- -------- -- ---------
     @xmath      (6.4.8)
  -- -------- -- ---------

We can derive the above equation by combining

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (6.4.9)
  -- -------- -------- -------- -- ---------

and

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (6.4.10)
  -- -------- -------- -------- -- ----------

For a properly normalized flux in the allowed region @xmath , we have in
the forbidden region

  -- -------- -- ----------
     @xmath      (6.4.11)
  -- -------- -- ----------

While this does imply @xmath , the inequality is unfortunately in the
wrong direction to be useful for placing bounds on the transmission
coefficient. It is for this reason that we have gone to the trouble of
keeping track of the more general gauge condition represented by @xmath
— in the hope that we can use this to explore under the barrier.

A good rigorous bound (not just a WKB approximation) on transmission
under the barrier would be very useful. The best we have been able to do
along these lines is presented in chapter 10 discussing the Miller–Good
transformation.

### 6.5 Special case 2-a

Suppose now that @xmath is continuous and monotonic increasing or
decreasing, varying from @xmath to @xmath .

Suppose @xmath so there is no classical turning point. Then

  -- -- -- ---------
           (6.5.1)
  -- -- -- ---------

and the transmission and reflection probabilities satisfy

  -- -------- -- ---------
     @xmath      (6.5.2)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.5.3)
  -- -------- -- ---------

###### Calculation:

We consider

  -- -------- -- ---------
     @xmath      (6.5.4)
  -- -------- -- ---------

and the bounds become

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Remembering that

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (6.5.6)
  -- -------- -------- -------- -- ---------

and noting

  -- -------- -- ---------
     @xmath      (6.5.7)
  -- -------- -- ---------

we see that

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (6.5.8)
  -- -------- -------- -------- -- ---------

Therefore

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (6.5.9)
  -- -------- -------- -------- -- ---------

so we obtain

  -- -------- -- ----------
     @xmath      (6.5.10)
  -- -------- -- ----------

as required. We now consider

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as required. These bounds are instantly understandable as the exact
analytic results for a step-function potential [ 37 , 43 , 44 , 88 ] ,
and the result asserts that for arbitrary smooth monotonic potentials
the step function provides upper and lower bounds on the exact result.
If we are interested in physical situations such as a time-dependent
refractive index [ 60 , 61 ] , or particle production due to the
expansion of the universe [ 63 ] , this technique shows that sudden
changes in refractive index or size of the universe provide a strict
upper bound on particle production.

### 6.6 Special case 2-b

Suppose now that @xmath has a single unique extremum (either a peak or a
valley). Provided that @xmath so that there is no classical turning
point, then @xmath moves monotonically from @xmath to @xmath and then
back to @xmath . Under these circumstances we consider

  -- -------- -------- -------- -- ---------
     @xmath   @xmath               (6.6.1)
              @xmath   @xmath      (6.6.2)
              @xmath   @xmath      (6.6.3)
  -- -------- -------- -------- -- ---------

as required.

The bound ( 4.5.18 ) implies

  -- -------- -- ---------
     @xmath      (6.6.4)
  -- -------- -- ---------

and which yields

  -- -------- -- ---------
     @xmath      (6.6.5)
  -- -------- -- ---------

Numerous generalizations of these formulae are possible. For example, at
the cost of a little extra notation, we also already have enough
information to provide a bound on an asymmetric barrier or asymmetric
well, as long as it has only a single extremum (maximum or minimum) we
apply the previous equations to derive

  -- -- -- ---------
           (6.6.6)
  -- -- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.6.7)
  -- -------- -- ---------

###### Calculation:

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.6.8)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

as required.

In addition, we can derive

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.6.9)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

as required.

Translated into statements about the transmission and reflection
probabilities this becomes

  -- -------- -- ----------
     @xmath      (6.6.10)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.11)
  -- -------- -- ----------

###### Calculation:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Also

  -- -------- -------- -- -- ----------
     @xmath   @xmath         (6.6.13)
  -- -------- -------- -- -- ----------

But

  -- -------- -- ----------
     @xmath      (6.6.14)
  -- -------- -- ----------

therefore

  -- -------- -- ----------
     @xmath      (6.6.15)
  -- -------- -- ----------

implying

  -- -------- -- ----------
     @xmath      (6.6.16)
  -- -------- -- ----------

as required. @xmath

Equivalently

  -- -------- -- ----------
     @xmath      (6.6.17)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.18)
  -- -------- -- ----------

###### Calculation:

We consider

  -- -------- -- ----------
     @xmath      (6.6.19)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.20)
  -- -------- -- ----------

we substitute the above equations into equation ( 6.6.10 ) to derive
equation ( 6.6.17 ). Moreover, we substitute the above equation into
equation ( 6.6.11 ) to derive equation ( 6.6.18 ). @xmath

This can be compared, for example, with known analytic results for the
asymmetric square well.

To be more specific, if in addition @xmath , so that @xmath , then we
have

  -- -------- -- ----------
     @xmath      (6.6.21)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.22)
  -- -------- -- ----------

Translated into statements about the transmission and reflection
probabilities this becomes

  -- -------- -- ----------
     @xmath      (6.6.23)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.24)
  -- -------- -- ----------

Equivalently

  -- -------- -- ----------
     @xmath      (6.6.25)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (6.6.26)
  -- -------- -- ----------

For low energies, these results are weaker than the bounds derived under
special case 1, ( 6.1.6 , 6.1.7 ) and ( 6.1.8 , 6.1.9 ), but have the
advantage of requiring more selective information about the potential.
For high energies,

  -- -------- -- ----------
     @xmath      (6.6.27)
  -- -------- -- ----------

the present result (when it is applicable) leads to tighter bounds on
the transmission and reflection coefficients.

### 6.7 Special case 2-c

Suppose now that @xmath has a number of extrema, (both peaks and
valleys). We allow @xmath , but demand that for all extrema @xmath so
that there is no classical turning point.

For definiteness, suppose the ordering is: @xmath peak @xmath valley
…valley @xmath peak @xmath . Then

  -- -------- -------- -- -------- ---------
     @xmath   @xmath               (6.7.1)
                          @xmath   
  -- -------- -------- -- -------- ---------

Defining

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (6.7.2)
     @xmath   @xmath   @xmath      (6.7.3)
     @xmath   @xmath   @xmath      (6.7.4)
  -- -------- -------- -------- -- ---------

we see

  -- -- -- ---------
           (6.7.5)
  -- -- -- ---------

This bounds the Bogoliubov coefficients as

  -- -------- -- ---------
     @xmath      (6.7.6)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.7.7)
  -- -------- -- ---------

Then the transmission and reflection probabilities satisfy

  -- -------- -- ---------
     @xmath      (6.7.8)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (6.7.9)
  -- -------- -- ---------

In these formulae, peaks and valleys can be interchanged in the obvious
way, and by letting the initial or final peak sink down to @xmath as
appropriate we obtain bounds for sequences such as: @xmath valley @xmath
peak …valley @xmath peak @xmath , or: @xmath peak @xmath valley …peak
@xmath valley @xmath . In the case of one or zero extrema these formulae
reduce to the previously given results. [Equations ( 6.6.10 )–( 6.6.11
).] Further modifications of these formulae are still possible, the cost
is that more specific assumptions are needed to derive more specific
results.

### 6.8 Bounds: Special case 3

In the following we will consider the bounds in special case 3. In
particular, the most outstanding features of this case is:

Let @xmath , @xmath and pick

  -- -------- -- ---------
     @xmath      (6.8.1)
  -- -------- -- ---------

with @xmath defined by @xmath . Then we have

  -- -------- -- ---------
     @xmath      (6.8.2)
  -- -------- -- ---------

Note that there are step function discontinuities at @xmath , but no
delta-function contribution. It now follows that

  -- -------- -- ---------
     @xmath      (6.8.3)
  -- -------- -- ---------

that is

  -- -------- -- ---------
     @xmath      (6.8.4)
  -- -------- -- ---------

Consider

  -- -------- -- ---------
     @xmath      (6.8.5)
  -- -------- -- ---------

so

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.8.6)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

So collecting terms we have

  -- -------- -------- -- -- ---------
     @xmath   @xmath         (6.8.7)
  -- -------- -------- -- -- ---------

Now note

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.8.8)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

so that

  -- -------- -- ---------
     @xmath      (6.8.9)
  -- -------- -- ---------

where

  -- -------- -- ----------
     @xmath      (6.8.10)
  -- -------- -- ----------

when @xmath is still an adjustable parametric, though we definitely need
@xmath .

### 6.9 Bounds: Special case 4

For the fourth special case we want to derive something that looks
similar to the WKB approximation, but is a strict bound instead of being
an (uncontrolled) estimate.

Choose @xmath , @xmath and pick

  -- -------- -- ---------
     @xmath      (6.9.1)
  -- -------- -- ---------

Even for a potential with only a single hump there are now five regions
to analyze, the two allowed regions, the forbidden region, and two
transition regions enclosing the two the classical turning points. As
usual we shall define our notation so that in the forbidden region:

  -- -------- -- ---------
     @xmath      (6.9.2)
  -- -------- -- ---------

In the two allowed regions

  -- -------- -- ---------
     @xmath      (6.9.3)
  -- -------- -- ---------

In the two transition regions

  -- -------- -- ---------
     @xmath      (6.9.4)
  -- -------- -- ---------

Finally in the forbidden region

  -- -------- -- ---------
     @xmath      (6.9.5)
  -- -------- -- ---------

So in the forbidden region by the triangle inequality

  -- -------- -- ---------
     @xmath      (6.9.6)
  -- -------- -- ---------

Collecting these

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (6.9.7)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

Now in each of the transition regions

  -- -------- -- ---------
     @xmath      (6.9.8)
  -- -------- -- ---------

so

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (6.9.9)
              @xmath   @xmath      (6.9.10)
  -- -------- -------- -------- -- ----------

Here @xmath is the combined length of the transition regions @xmath .
That is, the integral coming from each transition region is bounded (up
to a constant) by the physical width of that transition region.
Furthermore in the forbidden region

  -- -------- -- ----------
     @xmath      (6.9.11)
  -- -------- -- ----------

so collecting terms we have

  -- -------- -- ----------
     @xmath      (6.9.12)
  -- -------- -- ----------

where L now denotes the combined total width of the two transition
regions. Now note

  -- -------- -- ----------
     @xmath      (6.9.13)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (6.9.14)
  -- -------- -- ----------

The bound is considerably weaker than could have been derived by making
more restrictive hypotheses, but has the advantage of elegance and
looking very similar to the WKB bound. Note the key requirements: We
must be dealing with a single-hump potential, and @xmath must be in the
range

  -- -------- -- ----------
     @xmath      (6.9.15)
  -- -------- -- ----------

The parameter @xmath is otherwise arbitrary, and so can be chosen to
maximize the prefactor.

One thing we could do is to choose a different value of @xmath at each
transition, call them @xmath and @xmath , and repeat the analysis
keeping careful track of the @xmath integration near the turning points.
Then

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

So far this is a rigorous bound; now we are going to adopt a linear
approximation near the turning points, so that near the first turning
point

  -- -------- -- ----------
     @xmath      (6.9.16)
  -- -------- -- ----------

with @xmath reaching the values @xmath at the positions @xmath .
Therefore @xmath . Then

  -- -------- -- ----------
     @xmath      (6.9.17)
  -- -------- -- ----------

Similarly

  -- -------- -- ----------
     @xmath      (6.9.18)
  -- -------- -- ----------

so that combining, and assuming the linear approximation is a good one

  -- -------- -- ----------
     @xmath      (6.9.19)
  -- -------- -- ----------

Extremize with respect to @xmath , then

  -- -------- -- ----------
     @xmath      (6.9.20)
  -- -------- -- ----------

and similarly for @xmath , then

  -- -------- -- ----------
     @xmath      (6.9.21)
  -- -------- -- ----------

and hence

  -- -------- -- ----------
     @xmath      (6.9.22)
  -- -------- -- ----------

Although such results are certainly a major advance in our standing of
the rigorous bounds, this particular bound is not @xmath rigorous due to
the linear approximation. This suggests that further exploration of
these ideas, with a view to obtaining a 100% rigorous bound, might be
profitable.

### 6.10 Bounds: Future directions

From the general definition

  -- -------- -- ----------
     @xmath      (6.10.1)
  -- -------- -- ----------

and the bound

  -- -------- -- ----------
     @xmath      (6.10.2)
  -- -------- -- ----------

there are many other special cases you could in principle derive. The
possibilities seem endless and the art is in finding something useful.

### 6.11 Discussion

In this chapter we dealt with some specific cases of the general bounds
and developed a number of interesting specializations. In addition, we
collected together a large number of results that otherwise appeared
quite unrelated, including reflection above and below the barrier. The
special case bounds were divided into five topics: special cases 1–4,
and “future directions”. In addition, all special cases were chosen for
their directness and simplicity.

Furthermore, special case @xmath , as presented in equations ( 6.1.6 )–(
6.1.7 ) and ( 6.1.8 )–( 6.1.9 ), has the advantage that it applies to
both scattering over the barrier and under the barrier. On the other
hand, special case @xmath , as presented in equations ( 6.2.5 )–( 6.2.6
) and their specializations, applies only to scattering over the barrier
but has the advantage of being much more selective in how much
information is needed concerning the scattering potential.

## Chapter 7 Parametric oscillations

### 7.1 Introduction

In this chapter we shall present the basic concept of a “parametric
oscillator”. This is a simple harmonic oscillator whose parameters (its
resonance frequency @xmath and damping time @xmath ) vary in time. The
other interesting way of understanding a parametric oscillator is that
it is a device that oscillates when one of its “parameters” (a physical
entity, like capacitance) is changed [ 119 ] .

We shall re-cast and represent the general bounds in terms of the
specific mathematical structure of parametric oscillations. This
time-dependent problem is closely related to the spatial properties of
the time-independent Schrödinger equation.

Although the discussion so far has been presented in terms of the
spatial properties of the time-independent Schrödinger equation, the
mathematical structure of parametrically excited oscillations is
identical, needing only a few minor translations to be brought into the
current form. For a parametrically excited oscillator we have

  -- -------- -- ---------
     @xmath      (7.1.1)
  -- -------- -- ---------

Just map @xmath , and @xmath . In the general analysis of equation (
6.1.1 ) the quantity @xmath should be replaced by

  -- -------- -- ---------
     @xmath      (7.1.2)
  -- -------- -- ---------

This is often written as

  -- -------- -- ---------
     @xmath      (7.1.3)
  -- -------- -- ---------

but this is purely a convention, a change in notation. (Physicists
typically use dots for time derivatives and primes for space
derivatives.) The analysis then parallels that of the Schrödinger
equation. Some key results are given below.

### 7.2 Special case 1

If @xmath , then by choosing the auxiliary function to be @xmath we can
use equations ( 5.3.7 )–( 5.3.14 ) to deduce

  -- -------- -- ---------
     @xmath      (7.2.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.2.2)
  -- -------- -- ---------

###### Calculation:

We now consider

  -- -------- -- ---------
     @xmath      (7.2.3)
  -- -------- -- ---------

We substitute equation ( 7.1.2 ) into equation ( 7.2.3 ), now we derive

  -- -------- -- ---------
     @xmath      (7.2.4)
  -- -------- -- ---------

Furthermore, under the stated assumptions we can simplify the above
integral to derive

  -- -------- -- ---------
     @xmath      (7.2.5)
  -- -------- -- ---------

which automatically implies

  -- -------- -- ---------
     @xmath      (7.2.6)
  -- -------- -- ---------

as required.

### 7.3 Special case 2

If @xmath and @xmath are both finite so that suitable asymptotic states
exist, and assuming @xmath so that the frequency is always positive,
then applying equations ( 6.2.5 )–( 6.2.6 ) to the case of parametric
resonance yields

  -- -------- -- ---------
     @xmath      (7.3.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.3.2)
  -- -------- -- ---------

### 7.4 Special case 2-a

Suppose now that @xmath is positive semidefinite, continuous, and
monotonic increasing or decreasing, varying from @xmath to some distinct
value @xmath . The Bogoliubov coefficients satisfy

  -- -------- -- ---------
     @xmath      (7.4.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.4.2)
  -- -------- -- ---------

###### Calculation:

We now consider

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as required. Similarly

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

as required.

### 7.5 Special case 2-b

Under the restriction @xmath , with the additional constraint that
@xmath has a single unique extremum (either a maximum or a minimum but
not both), and provided that @xmath so that we do not encounter complex
frequencies (no classical turning point), the Bogoliubov coefficients
satisfy

  -- -------- -- ---------
     @xmath      (7.5.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.5.2)
  -- -------- -- ---------

###### Calculation:

To prove the above equations, we consider

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (7.5.3)
              @xmath   @xmath      
              @xmath   @xmath      
  -- -------- -------- -------- -- ---------

This implies

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Furthermore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Suppose now that @xmath has a single unique extremum (either a peak or a
valley), but that we allow the two asymptotic frequencies to differ
@xmath , and suppose further that @xmath so that there is no classical
turning point. The Bogoliubov coefficients satisfy

  -- -------- -- ---------
     @xmath      (7.5.7)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.5.8)
  -- -------- -- ---------

###### Calculation:

We now show how to derive the above equations: For the moment we shall
consider

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

But this now yields

  -- -------- -- ----------
     @xmath      (7.5.10)
  -- -------- -- ----------

as required.

### 7.6 Special case 2-c

Suppose now that @xmath has a number of extrema (both peaks and
valleys). We allow @xmath , but demand that for all extrema @xmath so
that there is no classical turning point.

For definiteness, suppose the ordering is: @xmath peak @xmath valley
…valley @xmath peak @xmath . Define

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (7.6.1)
     @xmath   @xmath   @xmath      (7.6.2)
     @xmath   @xmath   @xmath      (7.6.3)
  -- -------- -------- -------- -- ---------

The Bogoliubov coefficients satisfy

  -- -------- -- ---------
     @xmath      (7.6.4)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.6.5)
  -- -------- -- ---------

In these formulae, peaks and valleys can be interchanged in the obvious
way, and by letting the initial or final peak sink down to @xmath as
appropriate we obtain bounds for sequences such as: @xmath valley @xmath
peak …valley @xmath peak @xmath , or: @xmath peak @xmath valley …peak
@xmath valley @xmath . In the case of one or zero extrema these formulae
reduce to the previously given results.

Again, further specializations of these formulae are still possible. As
always there is a trade-off between the strength of the result and its
generality.

###### Calculation:

We see

  -- -------- -- ---------
     @xmath      (7.6.6)
  -- -------- -- ---------

The Bogoliubov coefficients in this case are bounded by

  -- -------- -- ---------
     @xmath      (7.6.7)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (7.6.8)
  -- -------- -- ---------

### 7.7 Bounds: Special case 3

We let @xmath , @xmath , then we can choose

  -- -------- -- ---------
     @xmath      (7.7.1)
  -- -------- -- ---------

with @xmath defined by @xmath . Then we have

  -- -------- -- ---------
     @xmath      (7.7.2)
  -- -------- -- ---------

Note that there are step function discontinuities at @xmath , but no
delta-function contribution. It now follows that

  -- -------- -- ---------
     @xmath      (7.7.3)
  -- -------- -- ---------

That is

  -- -------- -- ---------
     @xmath      (7.7.4)
  -- -------- -- ---------

As usual we shall define our notation so that in the forbidden region:

  -- -------- -- ---------
     @xmath      (7.7.5)
  -- -------- -- ---------

So

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (7.7.6)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ---------

Collecting terms we have

  -- -------- -------- -------- -- ---------
     @xmath   @xmath   @xmath      (7.7.7)
  -- -------- -------- -------- -- ---------

and the bound on the Bogoliubov coefficients in this case become

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

and

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

which gives us our third special case bound. Then the transmission and
reflection probabilities satisfy

  -- -------- -- ----------
     @xmath      (7.7.10)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (7.7.11)
  -- -------- -- ----------

where

  -- -------- -- ----------
     @xmath      (7.7.12)
  -- -------- -- ----------

### 7.8 Discussion

Though the discussion in previous chapters has been presented in terms
of the spatial properties of the time-independent Schrödinger equation,
we have seen in this chapter that the mathematical structure of
parametrically excited oscillations is essentially identical, needing
only a few minor translations to be brought into the current form.

In summary, the bounds presented in this chapter are useful in
establishing qualitative analytic properties of parametric oscillators,
and as such are complementary to both explicit numerical investigations
and the guidance extracted from exact analytic solutions.

## Chapter 8 Bounding the Bogoliubov coefficients

### 8.1 Introduction

In this chapter we will again be considering (from a somewhat different
point of view) the problem of finding approximate solutions for wave
equations in general, and quantum mechanical problems in particular. It
appears that as yet relatively little work seems to have been put into
the complementary problem of founding rigorous bounds on the exact
solutions. We have in mind either bounds on parametric amplification and
the related quantum phenomenon of particle production (as encoded in the
Bogoliubov coefficients), or bounds on transmission and reflection
coefficients.

In the last section of appendix B , we introduce and discuss the time
ordering and give some more details of time-ordered exponentials — these
are a very convenient trick for formally solving certain matrix
differential equations. Practising physicists and applied mathematicians
will all have seen the WKB approximation for barrier penetration
probability. Unfortunately, the WKB approximation is an example of an
uncontrolled approximation, and in general we do not know if it is an
over-estimate or an under-estimate.

As part of the main work, we modify and improve an approach first
developed in [ 88 ] . We shall examine this question by developing a
formal but exact solution for the appropriate second-order linear ODE,
in terms of a time-ordered exponential of @xmath matrices, then relating
the Bogoliubov coefficients to certain invariants of this matrix. By
bounding the matrix in an appropriate manner, we can thereby bound the
Bogoliubov coefficients.

### 8.2 The second-order ODE

We would first like to present “the second-order ODE” techniques
developed in [ 88 ] , that are applicable to numerous physical
situations; situations which are both extremely interesting and
important. Consider the ODE

  -- -------- -- ---------
     @xmath      (8.2.1)
  -- -------- -- ---------

or its equivalent in the space domain [ 88 ]

  -- -------- -- ---------
     @xmath      (8.2.2)
  -- -------- -- ---------

It is easy to see that equation ( 8.2.1 ) can be viewed (in terms of the
time domain) as an example of parametrically excited oscillation; it
arises for instance when a wave propagates through a medium whose
refractive index is externally controlled to be a function of time
(though remaining spatially invariant). ¹ ¹ 1 For instance, situations
of this type have been used to model sonoluminescence [ 112 ] , and more
recently both quasiparticle production in analogue spacetimes [ 113 ]
and analogue signature change events [ 114 ] . In all these situations
it is extremely useful to have rigorous and largely model-independent
bounds on the amount of particle production that might reasonably be
expected. In contrast, the spatial version of this equation as presented
in ( 8.2.2 ) arises classically in situations where the refractive index
is spatially dependent (so called “index gradient” situations), or in a
quantum physics context when considering the Schrödinger equation for a
time-independent potential:

  -- -------- -- ---------
     @xmath      (8.2.3)
  -- -------- -- ---------

as long as one makes the translation

  -- -------- -- ---------
     @xmath      (8.2.4)
  -- -------- -- ---------

However they arise, equations ( 8.2.1 ) and ( 8.2.2 ) are central to the
study of both quantum physics and wave phenomena generally.

As the result of this central significance, over the last century or
more a vast body of work has gone into the question of finding
approximate solutions to equations ( 8.2.1 ) and ( 8.2.2 ). Most of
these approximations are typically based on JWKB techniques and their
variants (phase integral techniques, etc .) [ 115 ] . In contrast very
little work seems to have gone into the physically important question of
finding explicit bounds on the relevant Bogoliubov coefficients and/or
reflection and transmission coefficients [ 88 ] .

Index-gradient methods : So-called index gradient optics is the branch
of optics covering optical effects produced by a gradual spatial
variation of the refractive index of a material [ 102 ] . One can
analogously speak of index gradient acoustics when the speed of sound is
slowly varying as a function of position.

In this chapter we shall modify and streamline the analysis of [ 88 ] ;
presenting an alternative proof that is considerably more direct and
focussed than that in [ 88 ] . We can make this discussion appear to be
so simple and straightforward by assuming that @xmath (equivalently
@xmath ) outside some region of compact support @xmath (equivalently
@xmath ). That is, concentrating on the time-domain formulation of
equation ( 8.2.1 ), the quantity @xmath is a function of compact
support. ² ² 2 Of course, this “compact support” condition is not
strictly necessary, and at the cost of a little more analysis one can
straightforwardly extend the comments below to a situation where there
is a finite limit @xmath as @xmath [ 88 ] . At the cost of somewhat more
tedious additional work, there are also useful things that can be said
of the situation where @xmath , with @xmath , as @xmath [ 88 ] . Because
of this compact support property we know that everywhere outside the
region @xmath the exact solution of the wave equation ( 8.2.1 ) is given
by linear combinations of @xmath , and that the central question to be
investigated is the manner in which exact solutions on the initial
domain @xmath “connect” with exact solutions on the final domain @xmath
.

Our approach will be to focus on using the above definition as a guide
to the appropriate starting point. We can now systematically develop a
formal but exact solution for the appropriate second-order linear ODE in
terms of a time-ordered exponential of @xmath matrices, then relating
the Bogoliubov coefficients to certain invariants of this matrix.

We are interested in solving, exactly but possibly formally , the
second-order ODE

  -- -------- -- ---------
     @xmath      (8.2.6)
  -- -------- -- ---------

One way of proceeding is as follows: Define a momentum

  -- -------- -- ---------
     @xmath      (8.2.7)
  -- -------- -- ---------

and then rewrite the second-order ODE as a system of first-order ODEs

  -- -------- -- ---------
     @xmath      (8.2.8)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (8.2.9)
  -- -------- -- ---------

or in matrix notation (where we have carefully arranged all matrix
elements and vector components to carry the same engineering dimensions)

  -- -------- -- ----------
     @xmath      (8.2.10)
  -- -------- -- ----------

This matrix ODE always has a formal solution in terms of the so-called
“time-ordered exponential”

  -- -------- -- ----------
     @xmath      (8.2.11)
  -- -------- -- ----------

The meaning of the time-ordered exponential is somewhat tricky, but
ultimately is just a @xmath matrix specialization of the operator-valued
version of the “time-ordered exponential” familiar from developing
quantum field theoretic perturbation theory in the so-called
“interaction picture” [ 116 ] . Specifically, let us partition the
interval @xmath as follows:

  -- -------- -- ----------
     @xmath      (8.2.12)
  -- -------- -- ----------

and define the “mesh” as

  -- -------- -- ----------
     @xmath      (8.2.13)
  -- -------- -- ----------

Then define the time-ordered exponential as

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

### 8.3 Bogoliubov coefficients

We have already been introduced to the concept of Bogoliubov
coefficients, and also some ways to calculate them, in chapter 5 . Let
us now extract the Bogoliubov coefficients in the present situation.
Before @xmath , and after @xmath , the wave-function is just linear
combinations of @xmath . We can prepare things so that before @xmath the
wavefunction is pure @xmath ,

  -- -------- -- ---------
     @xmath      (8.3.1)
  -- -------- -- ---------

in which case after @xmath the wavefunction will be a linear combination

  -- -------- -- ---------
     @xmath      (8.3.2)
  -- -------- -- ---------

where the Bogoliubov coefficients @xmath and @xmath are to be
calculated. That is, we have

  -- -------- -- ---------
     @xmath      (8.3.3)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (8.3.4)
  -- -------- -- ---------

But we also have

  -- -------- -- ---------
     @xmath      (8.3.5)
  -- -------- -- ---------

implying

  -- -------- -- ---------
     @xmath      (8.3.6)
  -- -------- -- ---------

Solving these simultaneous linear equations we find

  -- -------- -- ---------
     @xmath      (8.3.7)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (8.3.8)
  -- -------- -- ---------

so that the Bogoliubov coefficients are simple linear combinations of
elements of the matrix @xmath . Then (remember the matrix @xmath is real
)

  -- -------- -- ---------
     @xmath      (8.3.9)
  -- -------- -- ---------

  -- -------- -- ----------
     @xmath      (8.3.10)
  -- -------- -- ----------

and so

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (8.3.11)
              @xmath   @xmath      (8.3.12)
  -- -------- -------- -------- -- ----------

thus verifying that, (thanks to the unit determinant condition), the
Bogoliubov coefficients are properly normalized. Particle production is
governed by the @xmath coefficient in the combination

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (8.3.13)
              @xmath   @xmath      (8.3.14)
              @xmath   @xmath      (8.3.15)
              @xmath   @xmath      (8.3.16)
  -- -------- -------- -------- -- ----------

Note that the transpose @xmath is now time-anti-ordered .

Similarly, we have

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (8.3.17)
              @xmath   @xmath      (8.3.18)
              @xmath   @xmath      (8.3.19)
              @xmath   @xmath      (8.3.20)
  -- -------- -------- -------- -- ----------

As a consistency check, it is now obvious that

  -- -------- -- ----------
     @xmath      (8.3.21)
  -- -------- -- ----------

### 8.4 Elementary bound:

Now consider the quantity

  -- -------- -------- -------- -------- ---------
     @xmath   @xmath   @xmath            (8.4.2)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ---------

This object satisfies the differential equation

  -- -------- -- ---------
     @xmath      (8.4.3)
  -- -------- -- ---------

with the boundary condition

  -- -------- -- ---------
     @xmath      (8.4.4)
  -- -------- -- ---------

Now note

  -- -------- -- ---------
     @xmath      (8.4.5)
  -- -------- -- ---------

Furthermore

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

and so we see

  -- -------- -- ---------
     @xmath      (8.4.7)
  -- -------- -- ---------

Therefore

  -- -------- -- ---------
     @xmath      (8.4.8)
  -- -------- -- ---------

Using this key result, and some very simple analysis, we shall now
derive our first elementary bound on the Bogoliubov coefficients.

-   For any 2 real numbers, using @xmath and @xmath , we have

      -- -------- -- ---------
         @xmath      (8.4.9)
      -- -------- -- ---------

    In particular, for any 4 real numbers this implies

      -- -------- -- ----------
         @xmath      (8.4.10)
      -- -------- -- ----------

-   But we also have

      -- -------- -------- -------- -- ----------
         @xmath   @xmath   @xmath      (8.4.11)
                                       
                  @xmath   @xmath      (8.4.12)
      -- -------- -------- -------- -- ----------

    thus, for any 4 real numbers

      -- -------- -- ----------
         @xmath      (8.4.13)
      -- -------- -- ----------

-   For the particular case we are interested in we additionally have
    the unit determinant condition @xmath , so the above implies

      -- -------- -- ----------
         @xmath      (8.4.14)
      -- -------- -- ----------

    whence

      -- -------- -- ----------
         @xmath      (8.4.15)
      -- -------- -- ----------

Then, collecting these results, we see

  -- -------- -- ----------
     @xmath      (8.4.16)
  -- -------- -- ----------

whence

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (8.4.17)
              @xmath   @xmath      (8.4.18)
  -- -------- -------- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (8.4.19)
  -- -------- -- ----------

This implies

  -- -------- -- ----------
     @xmath      (8.4.20)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (8.4.21)
  -- -------- -- ----------

We now have

  -- -------- -- ----------
     @xmath      (8.4.22)
  -- -------- -- ----------

so that

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (8.4.23)
              @xmath   @xmath      (8.4.24)
  -- -------- -------- -------- -- ----------

So finally

  -- -------- -- ----------
     @xmath      (8.4.25)
  -- -------- -- ----------

and consequently

  -- -------- -- ----------
     @xmath      (8.4.26)
  -- -------- -- ----------

These bounds are quite remarkable in their generality. A version of this
result was derived in [ 88 ] but the present derivation is largely
independent and has the virtue of being completely elementary — in
particular, the use of complex numbers has been minimized, and we have
absolutely eliminated the use of the “auxiliary functions” and “gauge
conditions” that were needed for the derivation in [ 88 ] . If one
translates this to the space domain, then the equivalent barrier
penetration coefficient is @xmath , and the equivalent reflection
coefficient is @xmath . Making the appropriate translations

  -- -------- -- ----------
     @xmath      (8.4.27)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.4.28)
  -- -------- -- ----------

### 8.5 Lower bound on @xmath

To obtain a lower bound on the @xmath Bogoliubov coefficient, consider
any real valued parameter @xmath . Then since the matrix @xmath is
itself real,

  -- -------- -- ---------
     @xmath      (8.5.1)
  -- -------- -- ---------

so that

  -- -------- -- ---------
     @xmath      (8.5.2)
  -- -------- -- ---------

whence

  -- -------- -- ---------
     @xmath      (8.5.3)
  -- -------- -- ---------

This bound is extremized for @xmath , whence

  -- -------- -- ---------
     @xmath      (8.5.4)
  -- -------- -- ---------

and so

  -- -------- -- ---------
     @xmath      (8.5.5)
  -- -------- -- ---------

This is certainly a bound, but it is not as useful as one might hope. It
is useful only if @xmath . But

  -- -- -- ---------
           (8.5.6)
  -- -- -- ---------

So using the unit determinant condition, @xmath can be seen to require
@xmath , that is, @xmath . But when does this happen? For the real
matrix

  -- -------- -- ---------
     @xmath      (8.5.7)
  -- -------- -- ---------

with unit determinant the eigenvalues are

  -- -------- -- ---------
     @xmath      (8.5.8)
  -- -------- -- ---------

The condition @xmath is thus equivalent to the condition that the
eigenvalues are real. Unfortunately there seems to be no simple way to
then relate this to the properties of the function @xmath .

### 8.6 A more general upper bound

Now let @xmath be an arbitrary everywhere real and nonzero function of
@xmath with the dimensions of frequency. Then we can rewrite the
Schrödinger ODE ( 8.2.1 ) as:

  -- -------- -- ---------
     @xmath      (8.6.1)
  -- -------- -- ---------

Again all the matrix elements have been carefully chosen to have the
same engineering dimension. Again we can formally solve this in terms of
the time-ordered product:

  -- -------- -- ---------
     @xmath      (8.6.2)
  -- -------- -- ---------

The new @xmath matrix is

  -- -------- -- ---------
     @xmath      (8.6.3)
  -- -------- -- ---------

Note that the matrix @xmath is still real, and that because

  -- -------- -- ---------
     @xmath      (8.6.4)
  -- -------- -- ---------

it still follows that @xmath has determinant unity:

  -- -------- -- ---------
     @xmath      (8.6.5)
  -- -------- -- ---------

This means that much of the earlier computations carry through without
change. In particular as long as at the initial and final times we
impose @xmath as @xmath and @xmath , we still have

  -- -------- -- ---------
     @xmath      (8.6.6)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (8.6.7)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (8.6.8)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (8.6.9)
  -- -------- -- ---------

Now consider the quantity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

This now satisfies the differential equation

  -- -------- -- ----------
     @xmath      (8.6.11)
  -- -------- -- ----------

with the boundary condition

  -- -------- -- ----------
     @xmath      (8.6.12)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.6.13)
  -- -------- -- ----------

A brief computation yields

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

  -- -------- -- ----------
     @xmath      (8.6.15)
  -- -------- -- ----------

Then taking the trace, there is now one extra term

  -- -------- -- ----------
     @xmath      (8.6.16)
  -- -------- -- ----------

Note that if @xmath then @xmath and we recover the ODE of the
“elementary” bound. In this more general setting we now proceed by using
the following facts:

-   As previously we note

      -- -------- -------- -------- --
         @xmath   @xmath   @xmath   
                  @xmath   @xmath   
      -- -------- -------- -------- --

    which implies

      -- -------- -- ----------
         @xmath      (8.6.18)
      -- -------- -- ----------

    that is

      -- -------- -- ----------
         @xmath      (8.6.19)
      -- -------- -- ----------

-   Additionally, we use

      -- -------- -- ----------
         @xmath      (8.6.20)
      -- -------- -- ----------

    implying

      -- -------- -- ----------
         @xmath      (8.6.21)
      -- -------- -- ----------

In particular, combining these observations, this means that we can find
an angle @xmath (which is in general some complicated real function of
@xmath , @xmath , @xmath , @xmath ) such that

  -- -------- -- ----------
     @xmath      (8.6.22)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (8.6.23)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (8.6.24)
  -- -------- -- ----------

But for any real @xmath we certainly have by the Cauchy–Schwartz
inequality

  -- -------- -- ----------
     @xmath      (8.6.25)
  -- -------- -- ----------

implying

  -- -------- -- ----------
     @xmath      (8.6.26)
  -- -------- -- ----------

Therefore

  -- -------- -- ----------
     @xmath      (8.6.27)
  -- -------- -- ----------

implying

  -- -------- -- ----------
     @xmath      (8.6.28)
  -- -------- -- ----------

whence

  -- -------- -- ----------
     @xmath      (8.6.29)
  -- -------- -- ----------

so that

  -- -------- -- ----------
     @xmath      (8.6.30)
  -- -------- -- ----------

Using the general formulae for @xmath and @xmath in terms of @xmath ,
and simplifying, we see

  -- -------- -- ----------
     @xmath      (8.6.31)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.6.32)
  -- -------- -- ----------

This result is completely equivalent to the corresponding result in [ 88
] ; though again note that the derivation is largely independent and
that it no longer requires one to introduce any “gauge fixing”
condition, nor need we introduce any WKB-like ansatz. The current proof
is much more “direct”, and at worst uses simple inequalities and
straightforward ODE theory. If we work in the space domain instead of
the time domain and make the translations @xmath , @xmath , we see

  -- -------- -- ----------
     @xmath      (8.6.33)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.6.34)
  -- -------- -- ----------

This is perhaps physically more transparent in terms of the equivalent
transmission and reflection coefficients

  -- -------- -- ----------
     @xmath      (8.6.35)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.6.36)
  -- -------- -- ----------

### 8.7 The “optimal” choice of @xmath?

What is the optimal choice of @xmath that one can make leading to the
most stringent bound on the Bogoliubov coefficients? The bound we have
just derived holds for arbitrary @xmath , subject to the two boundary
conditions @xmath and the overall constraint @xmath . Since both @xmath
and @xmath are convex functions, finding the most stringent constraint
on @xmath and @xmath is thus a variational calculus problem equivalent
to minimizing the action

  -- -------- -- ---------
     @xmath      (8.7.1)
  -- -------- -- ---------

The relevant Euler–Lagrange equations are quite messy, and progress (at
least insofar as there is any practicable progress) is better made by
using an indirect attack. The Lagrangian is

  -- -- -- ---------
           (8.7.2)
  -- -- -- ---------

and so the corresponding canonical momentum can be evaluated as

  -- -------- -- ---------
     @xmath      (8.7.3)
  -- -------- -- ---------

From the boundary conditions we can deduce

  -- -------- -- ---------
     @xmath      (8.7.4)
  -- -------- -- ---------

The Hamiltonian is now

  -- -------- -- ---------
     @xmath      (8.7.5)
  -- -------- -- ---------

Unfortunately the Hamiltonian is explicitly time-dependent [via @xmath ]
and so is not conserved. The best we can say is that at the endpoints of
the motion

  -- -------- -- ----------
     @xmath      (8.7.12)
  -- -------- -- ----------

By solving for @xmath as a function of @xmath and @xmath we can also
write

  -- -------- -- ----------
     @xmath      (8.7.13)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.7.14)
  -- -------- -- ----------

Note that @xmath at the endpoints cannot in general be explicitly
evaluated in terms of the boundary conditions.

An alternative formulation which slightly simplifies the analysis is to
change variables by writing

  -- -------- -- ----------
     @xmath      (8.7.15)
  -- -------- -- ----------

where the boundary conditions are now

  -- -------- -- ----------
     @xmath      (8.7.16)
  -- -------- -- ----------

and the action is now rewritten as

  -- -------- -- ----------
     @xmath      (8.7.17)
  -- -------- -- ----------

Then, in terms of this new variable we have

  -- -------- -- ----------
     @xmath      (8.7.18)
  -- -------- -- ----------

with (dimensionless) conjugate momentum

  -- -------- -- ----------
     @xmath      (8.7.19)
  -- -------- -- ----------

and boundary conditions

  -- -------- -- ----------
     @xmath      (8.7.20)
  -- -------- -- ----------

The (non-conserved) Hamiltonian is

  -- -------- -- ----------
     @xmath      (8.7.21)
  -- -------- -- ----------

subject to

  -- -------- -- ----------
     @xmath      (8.7.22)
  -- -------- -- ----------

Inverting, we see

  -- -------- -- ----------
     @xmath      (8.7.23)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (8.7.24)
  -- -------- -- ----------

This has given us a somewhat simpler variational problem, unfortunately
the Euler–Lagrange equations are still too messy to provide useful
results.

Overall, we see that while solving the variational problem would indeed
result in an optimum bound, there is no explicit general formula for
such a solution. In the tradeoff between optimality and explicitness, we
will have to accept the use of sub-optimal but explicit bounds.

### 8.8 Sub-optimal but explicit bounds

From our general bounds

  -- -------- -- ---------
     @xmath      (8.8.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (8.8.2)
  -- -------- -- ---------

the following special cases are of particular interest:

 @xmath  :  

    In this case we simply obtain the “elementary” bound considered
    above.

 @xmath  :  

    This case only makes sense if @xmath is always positive. (Otherwise
    @xmath and hence @xmath becomes imaginary in the “classically
    forbidden” region; the matrix @xmath then becomes complex, and the
    entire formalism breaks down). Subject to this constraint we find

      -- -------- -- ---------
         @xmath      (8.8.3)
      -- -------- -- ---------

    and

      -- -------- -- ---------
         @xmath      (8.8.4)
      -- -------- -- ---------

    This case was also considered in [ 88 ] .

 @xmath  :  

    This case again only makes sense if @xmath is always positive.
    Subject to this constraint we find

      -- -- -- ---------
               (8.8.5)
      -- -- -- ---------

    and

      -- -- -- ---------
               (8.8.6)
      -- -- -- ---------

    This nicely interpolates between the two cases given above, which
    correspond to @xmath and @xmath respectively.

  Triangle inequality:  

    Since @xmath we see that

      -- -------- -- ---------
         @xmath      (8.8.7)
      -- -------- -- ---------

    and

      -- -------- -- ---------
         @xmath      (8.8.8)
      -- -------- -- ---------

These bounds, because they are explicit, are often the most useful
quantities to calculate.

### 8.9 The “interaction picture”

Interaction picture (sometimes called the Dirac picture) : This is an
intermediate between the Schrödinger picture and the Heisenberg picture.
Whereas in the other two pictures either the state vector or the
operators carry time dependence, in the interaction picture both carry
part of the time dependence of observables. Equations that include
operators acting at different times, which hold in the interaction
picture, do not necessarily hold in the Schrödinger or the Heisenberg
picture. This is because time-dependent unitary transformations relate
operators in one picture to the analogous operators in the others [ 109
] . For our purposes the interaction picture is useful because it lets
us develop a perturbation theory.

If we split the function @xmath into an exactly solvable piece @xmath
and a perturbation @xmath then we can develop a formal perturbation
series for the transfer matrix @xmath , in close analogy to the
procedures for developing quantum field theoretic perturbation theory in
the interaction picture. Specifically let us write

  -- -------- -- ---------
     @xmath      (8.9.1)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (8.9.2)
  -- -------- -- ---------

Now defining

  -- -------- -- ---------
     @xmath      (8.9.3)
  -- -------- -- ---------

we shall develop a formal solution for @xmath . Consider

  -- -------- -- ---------
     @xmath      (8.9.4)
  -- -------- -- ---------

and compare it with

  -- -------- -- ---------
     @xmath      (8.9.5)
  -- -------- -- ---------

Therefore

  -- -------- -- ---------
     @xmath      (8.9.6)
  -- -------- -- ---------

whence

  -- -------- -- ---------
     @xmath      (8.9.7)
  -- -------- -- ---------

For the full transfer matrix @xmath we have

  -- -------- -- ---------
     @xmath      (8.9.8)
  -- -------- -- ---------

and we have succeeded in splitting it into an exact piece @xmath plus a
distortion due to @xmath . This can now be used as the starting point
for a perturbation expansion. (The analogy with quantum field theoretic
perturbation theory in the interaction picture should now be completely
clear.)

To develop some formal bounds on the Bogoliubov coefficients it is
useful to suppress (currently) unnecessary phases by defining

  -- -------- -- ---------
     @xmath      (8.9.9)
  -- -------- -- ---------

  -- -------- -- ----------
     @xmath      (8.9.10)
  -- -------- -- ----------

The virtue of these definitions is that for @xmath they satisfy a simple
composition rule which can easily be verified via matrix multiplication.
From @xmath we have

  -- -- -- ----------
           (8.9.11)
  -- -- -- ----------

Then some simple linear algebra leads to

  -- -------- -- ----------
     @xmath      (8.9.12)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (8.9.13)
  -- -------- -- ----------

But then

  -- -------- -- ----------
     @xmath      (8.9.14)
  -- -------- -- ----------

that is

  -- -------- -- ----------
     @xmath      (8.9.15)
  -- -------- -- ----------

or the equivalent

  -- -------- -- ----------
     @xmath      (8.9.16)
  -- -------- -- ----------

Similarly

  -- -------- -- ----------
     @xmath      (8.9.17)
  -- -------- -- ----------

that is

  -- -------- -- ----------
     @xmath      (8.9.18)
  -- -------- -- ----------

or the equivalent

  -- -------- -- ----------
     @xmath      (8.9.19)
  -- -------- -- ----------

The benefit now is that one has bounded the Bogoliubov coefficient in
terms of the (assumed known) exact coefficient @xmath and the
contribution from the perturbation @xmath . Suitably choosing the split
between exact and perturbative contributions to @xmath , one could in
principle obtain arbitrarily accurate bounds.

### 8.10 Conclusion

In this chapter we again considered rigorous bounds on transmission,
reflection, and Bogoliubov coefficients. In particular, the most
outstanding features of this chapter are:

-   We have re-considered the general bounds on the Bogoliubov
    coefficients developed in [ 88 ] . Additionally, we have seen how to
    extend the bounds in [ 88 ] in many different ways. Moreover, we do
    not need to “gauge fix”, nor do we need to appeal to any “WKB-like
    ansatz” to get the discussion started.

-   We have formulated some rigorous bounds that we can place on barrier
    penetration probabilities, or equivalently on the Bogoliubov
    coefficients associated with a time-dependent potential.
    Furthermore, we have not seen anything like these bounds anywhere
    else.

-   In addition, probably there are “optimal” bounds still waiting to be
    discovered.

-   It is apparent that the current bounds are not the best that can be
    achieved, and we strongly suspect that it may be possible to develop
    yet further extensions to the current formalism.

Considering the fundamental importance of the questions we are asking,
it is remarkable how little work on this topic can currently be found in
the literature.

Possible extensions might include somehow relaxing the reality
constraint on @xmath without damaging too much of the current formalism,
a better understanding of the variational problem defining the “optimal”
bound (thus hopefully leading to an explicit form thereof), or using
several “probe functions” [instead of the single function @xmath ] to
more closely bound the Bogoliubov coefficients.

## Chapter 9 Bounding the greybody factors for Schwarzschild black holes

### 9.1 Introduction

Black hole greybody factors are important because they modify the
spectrum of Hawking radiation seen at spatial infinity [ 74 ] , so that
it is not quite Planckian [ 75 ] . (That is, it is no longer exactly
“blackbody radiation”, which is why [with slight abuse of language], it
is called “greybody”.) There is a vast scientific literature dealing
with estimates of these black-hole greybody factors, using a wide
variety of techniques [ 90 ] .

Unfortunately, most of these calculations adopt various approximations
that move one away from the physically most important regions of
parameter space. Sometimes one is forced into the extremal limit,
sometimes one is forced to asymptotically high or low frequencies,
sometimes techniques work only away from (3+1) dimensions, sometimes the
nature of the approximation is uncontrolled. As a specific example,
monodromy techniques fail for @xmath (photons) [ 77 ] , which is
observationally one of the most important cases one would wish to
consider.

Faced with these limitations, in this chapter we ask a slightly
different question: Restricting attention to the physically most
important situations (Schwarzschild black holes, (3+1) dimensions,
intermediate frequencies, unconstrained spin and angular momentum) is it
possible to at least place rigorous (and hopefully simple) analytic
bounds on the greybody factors?

By now considering the Regge–Wheeler equation for excitations around
Schwarzschild spacetime, and adapting the general analysis discussed in
earlier sections of this thesis, and published in references [ 88 , 89 ]
, we shall demonstrate that rigorous analytic bounds are indeed
achievable. While it is certainly true that these bounds may not answer
all the physical questions one might legitimately wish to ask, they are
definitely a solid step in the right direction.

Before starting the detailed calculations for this chapter, we should
stress some important issues related to the greybody factors in
Schwarzschild black holes:

-   Hawking radiation was originally derived in the geometric optics
    approximation where it can be shown to be described by ideal black
    body radiation — a black body is an object that absorbs all light
    that falls on it. No electromagnetic radiation passes through it and
    none is reflected. Because no light is reflected or transmitted, the
    object appears black when it is cold [ 121 ] . This derivation led
    to a calculation of the temperature and entropy of a black hole.

-   In this chapter, we shall try to rigorously solve for bounds on the
    transmission probabilities for waves moving through the region of
    space outside of a Schwarzschild black hole — Schwarzschild black
    holes are the simplest type, one that is described as a spherically
    symmetric body with no (electric or magnetic) charge or angular
    momentum (no rotation).

-   The most important issue is to realise that “greybody factor” is
    actually a synonym for “transmission probability”. Indeed, the
    phrase “greybody factor” is used more in the thermodynamics and
    spectroscopy communities, while the phrase “transmission
    probability” is used more in the quantum mechanics community, but
    these communities are referring to the same concept.

-   The greybody factor describes the emissivity of the black hole which
    is not that of a perfect blackbody.

-   As a black hole radiates energy by Hawking radiation, energy
    conservation implies that it will lose mass.

### 9.2 Hawking radiation

A black body is an object that absorbs all light that falls on it. No
electromagnetic radiation passes through it and none is reflected.
Because no light is reflected or transmitted, the object appears black
when it is cold [ 121 ] . The light emitted by a black body is called
black body radiation .

Hawking radiation is an approximately thermal radiation with an
approximately black body spectrum predicted to be emitted by black holes
due to quantum effects. It was discovered by Stephen Hawking who
provided the theoretical argument for its existence in 1974, and is
closely related to work by the physicist Jacob Bekenstein who predicted
that black holes should have a finite, non-zero entropy [ 122 ] .

Greybody factors in black hole physics modify the naive Planckian
spectrum that is predicted for Hawking radiation when working in the
limit of geometrical optics. We shall consider the Schwarzschild
geometry in (3+1) dimensions, and analyze the Regge–Wheeler equation for
arbitrary particle spin @xmath and wave-mode angular momentum @xmath ,
deriving rigorous bounds on the greybody factors as a function of @xmath
, @xmath , wave frequency @xmath , and the black hole mass @xmath .

### 9.3 Regge–Wheeler equation

The well-known Regge–Wheeler equation describes the axial perturbation
of Schwarzschild metric in the linear approximation [ 95 ] . In terms of
the tortoise coordinate @xmath the Regge–Wheeler equation ( @xmath ) is

  -- -------- -- ---------
     @xmath      (9.3.1)
  -- -------- -- ---------

where for the specific case of a Schwarzschild black hole

  -- -------- -- ---------
     @xmath      (9.3.2)
  -- -------- -- ---------

and the Regge–Wheeler potential is

  -- -------- -- ---------
     @xmath      (9.3.3)
  -- -------- -- ---------

Here @xmath is the spin of the particle and @xmath is the angular
momentum of the specific wave mode under consideration, with @xmath .
Thus @xmath outside the horizon, where @xmath . The greybody factors we
are interested in are just the transmission probabilities for wave modes
propagating through this Regge–Wheeler potential.

Tortoise coordinate: In a Schwarzschild spacetime the so-called
“tortoise coordinate” is defined by [ 126 ] :

@xmath (9.3.4)

The tortoise coordinate @xmath approaches @xmath as “ @xmath ”
approaches the Schwarzschild radius @xmath . It satisfies

@xmath (9.3.5)

If we watch an object fall towards the Schwarzschild radius, then in
terms of the @xmath coordinate the object seems to slow down and
(asymptotically) stop at the horizon. In contrast,

@xmath (9.3.6)

remains finite. In some vague analogy with the fable of the “tortoise
and the hare”, the @xmath coordinate has come to be known as the
“tortoise” coordinate.

-   Despite comments often encountered in the literature, one can
    explicitly solve for @xmath as a function of the tortoise coordinate
    @xmath — in terms of the Lambert @xmath function we have the exact
    result

      -- -------- -- ---------
         @xmath      (9.3.7)
      -- -------- -- ---------

    whereas

      -- -------- -- ---------
         @xmath      (9.3.8)
      -- -------- -- ---------

    Unfortunately this formal result, while certainly correct and exact,
    is less useful than one might suppose. (We have not been able to
    turn this observation into any useful calculation.)

-   Despite other comments often encountered in the literature, one can
    also explicitly solve the Regge–Wheeler equation — now in terms of
    Heun functions [ 95 ] . Unfortunately this is again less useful than
    one might suppose, this time because relatively little is known
    about the analytical behaviour of Heun functions — this is an area
    of ongoing research in mathematical analysis [ 96 ] .

### 9.4 Bounds

The general bounds developed earlier in this thesis, and published in
references [ 88 , 89 ] , can, in the current situation, be written as

  -- -------- -- ---------
     @xmath      (9.4.1)
  -- -------- -- ---------

Here @xmath is the transmission probability (greybody factor), and
@xmath is the function

  -- -------- -- ---------
     @xmath      (9.4.2)
  -- -------- -- ---------

where, @xmath is some positive function, @xmath , satisfying the limits
@xmath , which is otherwise arbitrary. Two different derivations of this
general result, and numerous consistency checks, can be found in earlier
chapters 5 and 8 of this thesis, and in references [ 88 , 89 ] .

(These bounds were originally developed as a technical step when
studying the completely unrelated issue of sonoluminescence [ 112 ] ,
and since then have also been used to place limits on particle
production in analogue spacetimes [ 83 ] and resonant cavities [ 84 ] ,
to investigate qubit master equations [ 85 ] , and to motivate further
general investigations of one-dimensional scattering theory [ 86 ] .)
For current purposes, the most useful practical results are obtained by
considering two special cases:

1.  If we set @xmath then

      -- -------- -- ---------
         @xmath      (9.4.3)
      -- -------- -- ---------

    whence

      -- -------- -- ---------
         @xmath      (9.4.4)
      -- -------- -- ---------

    Therefore, since the remaining integral is trivial, we obtain our
    first explicit bound:

      -- -------- -- ---------
         @xmath      (9.4.5)
      -- -------- -- ---------

    That is:

      -- -------- -- ---------
         @xmath      (9.4.6)
      -- -------- -- ---------

    Note that this bound is meaningful for all frequencies. This is
    sufficient to tell us that at high frequencies the Regge–Wheeler
    barrier is almost fully transparent, while even at arbitrarily low
    frequencies some nonzero fraction of the Hawking flux will tunnel
    through. A particularly nice feature of this first bound is that it
    is so easy to write down for arbitrary @xmath and @xmath .

2.  If we now set @xmath , which in this case implicitly means that we
    are not permitting any classically forbidden region, then

      -- -------- -- ---------
         @xmath      (9.4.7)
      -- -------- -- ---------

    Since for arbitrary @xmath and @xmath the Regge–Wheeler potential is
    easily seen to have a unique peak at which it is a maximum, this
    becomes

      -- -------- -------- -------- -- ---------
         @xmath   @xmath   @xmath      (9.4.8)
                  @xmath   @xmath      (9.4.9)
      -- -------- -------- -------- -- ---------

    which is easily seen to be monotonic decreasing as a function of
    @xmath . However calculating the location of the peak, and value of
    the Regge–Wheeler potential at the peak is somewhat more tedious
    than evaluating the previous bound ( 9.4.5 ). Note that the present
    bound fails, and gives no useful information, once @xmath ,
    corresponding to a classically forbidden region. More explicitly,
    the bound can be rewritten as:

      -- -------- -- ----------
         @xmath      (9.4.10)
      -- -------- -- ----------

The most interesting point of the study of black hole greybody factors [
90 ] , and (once one moves into the complex plane), the closely related
problem of locating the quasinormal modes [ 77 , 97 , 98 ] , is a
subject that has attracted a wide amount of interest. In particular,
quasinormal modes are poles of the transmission coefficient and reflect
the black hole’s ringdown reaction to a perturbation [ 77 ] .
Unfortunately, as a specific example, monodromy techniques fail for
@xmath (photons) [ 77 ] , which is observationally one of the most
important cases one would wish to consider. It is for this reason that
we resort to our general bounds to extract as much information as
possible.

Let us now consider various sub-cases:

-   For @xmath (ie, photons) the situation simplifies considerably.
    (Remember, this is the case for which monodromy techniques fail [ 77
    ] .) For @xmath we always have @xmath and

      -- -------- -- ----------
         @xmath      (9.4.11)
      -- -------- -- ----------

    Consequently, from ( 9.4.10 )

      -- -------- -- ----------
         @xmath      (9.4.12)
      -- -------- -- ----------

    In almost the entire region where this bound applies ( @xmath ) it
    is in fact a better bound than ( 9.4.5 ) above.

-   For @xmath (ie, scalars) and @xmath (the @xmath -wave), we have
    @xmath and

      -- -------- -- ----------
         @xmath      (9.4.13)
      -- -------- -- ----------

    Consequently

      -- -------- -- ----------
         @xmath      (9.4.14)
      -- -------- -- ----------

    In a large fraction of the region where this bound applies it is in
    fact a better bound than ( 9.4.5 ) above.

-   For @xmath but @xmath it is easy to see that throughout the black
    hole exterior, @xmath , we have

      -- -------- -- ----------
         @xmath      (9.4.15)
      -- -------- -- ----------

    which is the @xmath potential with the replacement @xmath . This
    bound on the potential has its maximum at @xmath , implying

      -- -------- -- ----------
         @xmath      (9.4.16)
      -- -------- -- ----------

    Therefore the monotonicity of the bound on the greybody factor
    implies

      -- -------- -- ----------
         @xmath      (9.4.17)
      -- -------- -- ----------

    (for @xmath , @xmath , and @xmath held fixed, and subject to @xmath
    ).

-   For @xmath it is easy to see that throughout the black hole
    exterior, @xmath , keeping @xmath held fixed, we have @xmath .
    Therefore

      -- -------- -- ----------
         @xmath      (9.4.18)
      -- -------- -- ----------

    Therefore the monotonicity of the bound on the greybody factor
    implies

      -- -------- -- ----------
         @xmath      (9.4.19)
      -- -------- -- ----------

    (for @xmath , @xmath , and @xmath held fixed, and subject to @xmath
    ).

-   More generally, it is useful to define

      -- -------- -- ----------
         @xmath      (9.4.20)
      -- -------- -- ----------

    Excluding the case @xmath , which was explicitly dealt with above,
    the remainder of the physically interesting region is confined to
    the range @xmath . Then a brief computation yields

      -- -------- -- ----------
         @xmath      (9.4.21)
      -- -------- -- ----------

    and

      -- -------- -- ----------
         @xmath      (9.4.22)
      -- -------- -- ----------

    In fact one can show that

      -- -------- -- ----------
         @xmath      (9.4.23)
      -- -------- -- ----------

    over the physically interesting range. (This bound on @xmath is
    tightest for @xmath , corresponding to @xmath , where it provides a
    better than @xmath estimate, and becomes progressively weaker as one
    moves to @xmath .) This then implies

      -- -------- -- ----------
         @xmath      (9.4.24)
      -- -------- -- ----------

    As always there is a trade-off between strength of the bound and the
    ease with which it can be written down.

While this second set of bounds has required a little more case by case
analysis, we should in counterpoint observe that this second set of
bounds provides much stronger information at very high frequencies,
where in fact

  -- -------- -- ----------
     @xmath      (9.4.25)
  -- -------- -- ----------

Unfortunately this second set of bounds is (because of details in the
derivation, see earlier chapters in this thesis, and [ 88 , 89 ] ) not
capable of providing information once the frequency has dropped low
enough for the scattering problem to develop classical turning points —
in other words a scattering problem with a classically forbidden region
is not amenable to treatment using bounds of the second class considered
above. For sufficently low frequencies, bounds of the form ( 9.4.5 ) are
more appropriate, with

  -- -------- -- ----------
     @xmath      (9.4.26)
  -- -------- -- ----------

What we have not done, at least not yet, is to use the full generality
implicit in equation ( 9.4.2 ). Subject to rather mild constraints,
there is a freely specifiable function @xmath available that can
potentially be used to extract tighter bounds. Work along these lines is
continuing.

### 9.5 Discussion

The study of black hole greybody factors [ 90 ] , and (once one moves
into the complex plane), the closely related problem of locating the
quasinormal modes [ 77 , 97 , 98 ] , is a subject that has attracted a
wide amount of interest in both the general relativity and particle
physics communities. In addition, we wish emphasize some specific
features in this chapter:

-   In this chapter, we have developed a complementary set of results —
    we have sought and obtained several rigorous analytic bounds that
    can be placed on the greybody factors.

-   Even though these bounds are not necessarily tight bounds on the
    exact greybody factors they do serve to focus attention on general
    and robust features of these greybody factors. Moreover they provide
    a new method of extracting physical information.

-   In the current formalism, (as opposed to, for instance, monodromy
    techniques [ 77 ] ), it is obviously clear that one does not have to
    know anything about what is going on inside the black hole in order
    to obtain information regarding the greybody factors. This is as it
    should be, since physically the greybody factors are simply
    transmission coefficients relating the horizon to spatial infinity,
    and make no intrinsic reference to the nature of the central
    singularity.

-   Looking further afield, here should be no intrinsic difficulty in
    extending these results to Reissner–Nordström black holes, dilaton
    black holes, or to higher dimensions — all that is really needed is
    an exact expression for the Regge–Wheeler potential.

Finally, it is perhaps more interesting to see if one can significantly
improve these bounds in some qualitative manner, perhaps by making a
more strategic choice for the essentially free function @xmath .

## Chapter 10 The Miller–Good transformation

### 10.1 Introduction

In this chapter, we shall consider further topics of general interest in
quantum physics, such as transmission through a potential barrier — the
potential being a region in a field of force where the force exerted on
a particle is such as to oppose the passage of the particle through that
region [ 129 ] — and the (formally) closely related issue of particle
production from a parametric resonance.

We have already developed a rather general bound on quantum transmission
probabilities, and in the previous chapter (chapter 9 ) have applied it
to bounding the greybody factors of a Schwarzschild black hole. In this
current chapter we shall take a different tack — we shall use the
Miller–Good transformation (which maps an initial Schrödinger equation
to a final Schrödinger equation for a different potential) to
significantly generalize the previous bound. Moreover, we shall see that
the Miller–Good transformation is an efficient method whereby to to
generalize the bound, to make it more efficient and powerful.

### 10.2 Setting up the problem

Consider the Schrödinger equation,

  -- -------- -- ----------
     @xmath      (10.2.1)
  -- -------- -- ----------

where @xmath . As long as @xmath leads to finite (possibly different)
constants @xmath on left and right infinity, then for @xmath one can set
up a one-dimensional scattering problem in a completely standard manner
— see for example [ 37 , 40 , 43 , 51 , 80 , 81 , 99 , 100 ] . The
scattering problem is completely characterized by the transmission and
reflection amplitudes ( @xmath and @xmath ), though the most important
aspects of the physics can be extracted from the transmission and
reflection probabilities ( @xmath and @xmath ). Relatively little work
has gone into providing general analytic bounds on the transmission
probabilities, (as opposed to approximate estimates), and the only known
result as far as we have been able to determine is this:

###### Theorem 10.1.

Consider the Schrödinger equation ( 10.2.1 ). Let @xmath be some
positive but otherwise arbitrary once-differentiable function. Then the
transmission probability is bounded from below by

  -- -------- -- ----------
     @xmath      (10.2.2)
  -- -------- -- ----------

To obtain useful information, one should choose asymptotic conditions on
the function @xmath so that the integral converges — otherwise one
obtains the true but trivial result @xmath . (There is of course a
related bound in the reflection probability, @xmath , and if one works
with the formally equivalent problem of parametric oscillations, a bound
on the resulting Bogoliubov coefficients and particle production.)

This quite remarkable bound was first derived in [ 88 ] , with further
discussion and an alternate proof being provided in chapter 5 (and
published in [ 89 ] ). These bounds were originally used as a technical
step when studying a specific model for sonoluminescence [ 112 ] , and
since then have also been used to place limits on particle production in
analogue spacetimes [ 83 ] and resonant cavities [ 84 ] , to investigate
qubit master equations [ 85 ] , and to motivate further general
investigations of one-dimensional scattering theory [ 86 ] . Most
recently, these bounds have also been applied to the greybody factors of
a Schwarzschild black hole (see previous chapter, and the related
publication [ 90 ] ).

A slightly weaker, but much more tractable, form of the bound can be
obtained by applying the triangle inequality. For @xmath :

  -- -------- -- ----------
     @xmath      (10.2.3)
  -- -------- -- ----------

Five important special cases are:

1.  If we take @xmath , where @xmath , then we have [ 88 , 89 ]

      -- -------- -- ----------
         @xmath      (10.2.4)
      -- -------- -- ----------

2.  If we define @xmath , and take @xmath to be any function that
    smoothly and monotonically interpolates between @xmath and @xmath ,
    then we have

      -- -------- -- ----------
         @xmath      (10.2.5)
      -- -------- -- ----------

    This is already more general than the most closely related result
    presented in [ 88 , 89 ] .

3.  If we have a single extremum in @xmath then

      -- -------- -- ----------
         @xmath      (10.2.6)
      -- -------- -- ----------

    This is already more general than the most closely related result
    presented in [ 88 , 89 ] .

4.  If we have a single minimum in @xmath , and choose @xmath , assuming
    @xmath , (but still permitting @xmath , so we are allowing for the
    possibility of a classically forbidden region), then

      -- -------- -- ----------
         @xmath      (10.2.7)
      -- -------- -- ----------

    This is already more general than the most closely related result
    presented in [ 88 , 89 ] .

5.  If @xmath has a single minimum and @xmath , then

      -- -------- -- ----------
         @xmath      (10.2.8)
      -- -------- -- ----------

    This is the limit of ( 10.2.7 ) above as @xmath , and is one of the
    special cases considered in [ 88 ] .

In this chapter we shall not be seeking to apply the general bound (
10.2.2 ), its weakened form ( 10.2.3 ), or any of its specializations as
given in ( 10.2.4 )–( 10.2.8 ) above. Instead we shall be seeking to
extend and generalize the bound to make it more powerful. The tool we
shall use to do this is the Miller–Good transformation [ 87 ] .

### 10.3 The Miller–Good transformation

Consider the Schrödinger equation ( 10.2.1 ), and consider the
substitution [ 87 ]

  -- -------- -- ----------
     @xmath      (10.3.1)
  -- -------- -- ----------

We will want @xmath to be our “new” position variable, so @xmath has to
be an invertible function. This implies (via, for instance, the inverse
function theorem) that we need @xmath . In reality, since the argument
will be smoothest if we arrange things so that the variables @xmath and
@xmath both agree as to which direction is left or right, we can without
loss of generality assert @xmath , whence also @xmath .

Now compute (using the notation @xmath ):

  -- -------- -- ----------
     @xmath      (10.3.2)
  -- -------- -- ----------

and

  -- -------- -- ----------
     @xmath      (10.3.3)
  -- -------- -- ----------

Insert this into the original Schrödinger equation, @xmath , to see that

  -- -------- -- ----------
     @xmath      (10.3.4)
  -- -------- -- ----------

which we can write as

  -- -------- -- ----------
     @xmath      (10.3.5)
  -- -------- -- ----------

with

  -- -------- -- ----------
     @xmath      (10.3.6)
  -- -------- -- ----------

That is, a Schrödinger equation in terms of @xmath and @xmath has been
transformed into a completely equivalent Schrödinger equation in terms
of @xmath and @xmath . We can also rewrite this as

  -- -------- -- ----------
     @xmath      (10.3.7)
  -- -------- -- ----------

The combination

  -- -------- -- ----------
     @xmath      (10.3.8)
  -- -------- -- ----------

shows up in numerous a priori unrelated branches of physics and is
sometimes referred to as the “Schwarzian derivative”.

-   As previously commented, to make sure the coordinate transformation
    @xmath is well defined we want to have @xmath , let us call this
    @xmath with @xmath . We can then write

      -- -------- -- -----------
         @xmath      (10.3.10)
      -- -------- -- -----------

    Let us suppose that @xmath ; then @xmath , so if @xmath has nice
    asymptotic behaviour allowing one to define a scattering problem,
    then so does @xmath .

-   Another possibly more useful substitution (based on what we saw with
    the Schwarzian derivative) is to set @xmath with @xmath in
    equation ( 10.3.6 ). When we let @xmath , we can then also write
    this as:

      -- -------- -------- -------- -- -----------
         @xmath   @xmath   @xmath      (10.3.11)
         @xmath   @xmath   @xmath      (10.3.12)
      -- -------- -------- -------- -- -----------

    We can then write

      -- -------- -- -----------
         @xmath      (10.3.13)
      -- -------- -- -----------

    Let us suppose that @xmath ; then @xmath , so if @xmath has nice
    asymptotic behaviour allowing one to define a scattering problem, so
    does @xmath .

###### Calculation:

We now substitute equations ( 10.3.11 )–( 10.3.12 ) above into ( 10.3.6
), then we have

  -- -------- -------- -------- -------- -----------
     @xmath   @xmath   @xmath            (10.3.14)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -----------

as required.

###### Two theorems:

These observations about the behaviour at spatial infinity lead
immediately and naturally to the result:

###### Theorem 10.2.

Suppose @xmath , ( equivalently, @xmath ) . Then the “potentials” @xmath
and @xmath have the same reflection and transmission amplitudes, and
same reflection and transmission probabilities.

This is automatic since @xmath , so equation ( 10.2.1 ) and the
transformed equation ( 10.3.5 ) both have the same asymptotic plane-wave
solutions. Furthermore the Miller–Good transformation ( 10.3.1 ) maps
any linear combination of solutions of equation ( 10.2.1 ) into the same
linear combination of solutions of the transformed equation ( 10.3.5 ).
QED.

###### Theorem 10.3.

Suppose @xmath , ( equivalently, @xmath ) . What is the relation between
the reflection and transmission amplitudes, and reflection and
transmission probabilities of the two “potentials” @xmath and @xmath ?
This is also trivial — the “potentials” @xmath and @xmath have the same
reflection and transmission amplitudes, and same reflection and
transmission probabilities.

The only thing that now changes is that the properly normalized
asymptotic states are distinct

  -- -------- -- -----------
     @xmath      (10.3.15)
  -- -------- -- -----------

but map into each other under the Miller–Good transformation. QED.

### 10.4 Improved general bounds

We already know

  -- -------- -- ----------
     @xmath      (10.4.1)
  -- -------- -- ----------

Here @xmath is the transmission probability, and @xmath is the function

  -- -------- -- ----------
     @xmath      (10.4.2)
  -- -------- -- ----------

with @xmath . But since the scattering problems defined by @xmath and
@xmath have the same transmission probabilities, we also have

  -- -------- -- ----------
     @xmath      (10.4.3)
  -- -------- -- ----------

with

  -- -------- -- ----------
     @xmath      (10.4.4)
  -- -------- -- ----------

and

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (10.4.5)
              @xmath   @xmath      (10.4.6)
              @xmath   @xmath      (10.4.7)
  -- -------- -------- -------- -- ----------

That is: @xmath we now have (the first form of) the improved bound

  -- -------- -- ----------
     @xmath      (10.4.8)
  -- -------- -- ----------

Since this new bound contains two freely specifiable functions it is
definitely stronger than the result we started from, ( 10.2.2 ). The
result is perhaps a little more manageable if we work in terms of @xmath
instead of @xmath . We follow the previous logic but now set

  -- -------- -- ----------
     @xmath      (10.4.9)
  -- -------- -- ----------

and

  -- -------- -- -----------
     @xmath      (10.4.10)
  -- -------- -- -----------

That is: @xmath we have (the second form of) the improved bound

  -- -------- -- -----------
     @xmath      (10.4.11)
  -- -------- -- -----------

A useful further modification is to substitute @xmath , then @xmath we
have (the third form of) the improved bound by the following argument:
When we let @xmath , then we derive

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (10.4.12)
  -- -------- -------- -------- -- -----------

We now substitute above equations into ( 10.4.11 ), implying that @xmath
is greater than

  -- -------- -- -----------
     @xmath      (10.4.13)
  -- -------- -- -----------

We can simplify the above equation, and so we now also derive

  -- -------- -- -----------
     @xmath      (10.4.14)
  -- -------- -- -----------

Equations ( 10.4.8 ), ( 10.4.11 ), and ( 10.4.14 ), are completely
equivalent versions of our new bound.

### 10.5 Some applications and special cases

We can now use these improved general bounds, ( 10.4.8 ), ( 10.4.11 ),
and ( 10.4.14 ), to obtain several more specialized bounds that are
applicable in more specific situations.

#### 10.5.1 Schwarzian bound

First, take @xmath in equation ( 10.4.11 ), then

  -- -------- -- ----------
     @xmath      (10.5.1)
  -- -------- -- ----------

In order for this bound to convey nontrivial information we need the
limit @xmath , otherwise the integral diverges and the bound trivializes
to @xmath . The further specialization of this result reported in [ 88 ,
89 ] and equation ( 10.2.4 ) above corresponds to @xmath , which clearly
is a weaker bound than that reported here. In the present situation we
can without loss of generality set @xmath in which case

  -- -------- -- ----------
     @xmath      (10.5.2)
  -- -------- -- ----------

We now need @xmath in order to make the integral converge. If @xmath ,
so that there is no classically forbidden region, then we can choose
@xmath , in which case

  -- -------- -- ----------
     @xmath      (10.5.3)
  -- -------- -- ----------

#### 10.5.2 Low-energy improvement

We could alternatively set @xmath in equation ( 10.4.14 ), to derive

  -- -------- -- ----------
     @xmath      (10.5.4)
  -- -------- -- ----------

In order for this bound to convey nontrivial information we need to
enforce @xmath , while @xmath , and @xmath . Otherwise the integral
diverges and the bound trivializes to @xmath . Thus

  -- -------- -- ----------
     @xmath      (10.5.5)
  -- -------- -- ----------

Again, the further specialization of this result reported in [ 88 , 89 ]
and equation ( 10.2.4 ) above corresponds to @xmath , which clearly is a
weaker bound than that reported here. To turn this into something a
little more explicit, since @xmath we can without any loss of generality
write

  -- -------- -- ----------
     @xmath      (10.5.6)
  -- -------- -- ----------

where @xmath is unconstrained. This permits is to write

  -- -------- -- ----------
     @xmath      (10.5.7)
  -- -------- -- ----------

Then by the triangle inequality

  -- -------- -- ----------
     @xmath      (10.5.8)
  -- -------- -- ----------

A further application of the triangle inequality yields

  -- -------- -- ----------
     @xmath      (10.5.9)
  -- -------- -- ----------

Now if @xmath , (this is not that rare an occurrence, in a
non-relativistic quantum scattering setting, where @xmath and we have
normalized to @xmath , it corresponds to scattering from a potential
that is everywhere positive), then we can choose @xmath so that

  -- -------- -- -----------
     @xmath      (10.5.10)
  -- -------- -- -----------

Assuming a unique maximum for @xmath (again not unreasonable, this
corresponds to a single hump potential) this implies

  -- -------- -- -----------
     @xmath      (10.5.11)
  -- -------- -- -----------

This is a new and nontrivial bound, which in quantum physics language,
where @xmath , corresponds to

  -- -------- -- -----------
     @xmath      (10.5.12)
  -- -------- -- -----------

If under the same hypotheses we choose @xmath , then the bound reported
in [ 88 , 89 ] and equation ( 10.2.4 ) above corresponds to

  -- -------- -- -----------
     @xmath      (10.5.13)
  -- -------- -- -----------

Thus for sufficiently small @xmath the new bound in equation ( 10.5.12 )
is more stringent than the old bound in equation ( 10.5.13 ) provided

  -- -------- -- -----------
     @xmath      (10.5.14)
  -- -------- -- -----------

#### 10.5.3 WKB-like bound

Another option is to return to equation ( 10.5.9 ) and make the choice
@xmath , so that @xmath in the classically forbidden region @xmath ,
while @xmath in the classically allowed region @xmath . But then
equation ( 10.5.9 ) reduces to

  -- -------- -- -----------
     @xmath      (10.5.15)
  -- -------- -- -----------

Key points here are the presence of @xmath , the barrier penetration
integral that normally shows up in the standard WKB approximation to
barrier penetration, @xmath the height of the barrier, and @xmath the
width of the barrier. These is also a contribution from the classically
allowed region (as in general there must be, potentials with no
classically forbidden region still generically have nontrivial
scattering). Compare this with the standard WKB estimate:

  -- -------- -- -----------
     @xmath      (10.5.16)
  -- -------- -- -----------

This form of the WKB approximation for barrier penetration is derived,
for instance, in Bohm’s classic textbook [ 82 ] , and can also be found
in many other places. Under the usual conditions applying to the WKB
approximation for barrier penetration we have @xmath , in which case one
obtains the more well-known version

  -- -------- -- -----------
     @xmath      (10.5.17)
  -- -------- -- -----------

The bound in equation ( 10.5.15 ) is the closest we have so far been
able to get to obtaining a rigorous bound that somewhat resembles the
standard WKB estimate. Again we do not expect the bound in equation (
10.5.15 ) to be optimal, and are continuing to search for improvements
on this WKB-like bound.

#### 10.5.4 Further transforming the bound

In an attempt to strengthen the inequalities ( 10.5.11 ) and ( 10.5.12
), we again use the fact that @xmath to (without any loss of generality)
write @xmath , where @xmath is unconstrained. The general bound in
equation ( 10.4.14 ) can then be transformed to: For all @xmath , for
all @xmath :

  -- -------- -- -----------
     @xmath      (10.5.18)
  -- -------- -- -----------

This leaves us with considerable freedom. Regardless of the sign of
@xmath , we can always choose to enforce @xmath , and so eliminate
either @xmath or @xmath , obtaining

  -- -------- -- -----------
     @xmath      (10.5.19)
  -- -------- -- -----------

(subject to @xmath and @xmath ), and

  -- -------- -- -----------
     @xmath      (10.5.20)
  -- -------- -- -----------

(subject to @xmath ), respectively. Finding an explicit bound is now
largely a matter of art rather than method. For example if we take

  -- -------- -- -----------
     @xmath      (10.5.21)
  -- -------- -- -----------

then from either equation ( 10.5.19 ) or equation ( 10.5.20 ), again
under the restriction that we are dealing with a single-hump positive
potential, we obtain

  -- -------- -- -----------
     @xmath      (10.5.22)
  -- -------- -- -----------

Note that @xmath is a free parameter which could in principle be chosen
to optimize the bound, however the resulting integral equation is too
messy to be of any practical interest. This bound is somewhat similar to
that reported in equations ( 10.2.7 ) and ( 10.5.11 ), but there are
some very real differences.

### 10.6 Summary and Discussion

The bounds presented in this chapter are generally not “WKB-like” —
apart from the one case reported in equation ( 10.5.15 ) there is no
need (nor does it seem useful) to separate the region of integration
into classically allowed and classically forbidden regions. In fact it
is far from clear how closely these bounds might ultimately be related
to WKB estimates of the transmission probabilities, and this is an issue
to which we hope to return in the future.

We should mention that if one works with the formally equivalent problem
of a parametric oscillator in the time domain then the relevant
differential equation is

  -- -------- -- ----------
     @xmath      (10.6.1)
  -- -------- -- ----------

and instead of asking questions about transmission amplitudes and
probabilities one is naturally driven to ask formally equivalent
questions about Bogoliubov coefficients and particle production. The key
translation step is to realize that there is an equivalence [ 88 , 89 ]
:

  -- -------- -- ----------
     @xmath      (10.6.2)
  -- -------- -- ----------

This leads to bounds on the number of particles produced that are of the
form @xmath , thereby implying

  -- -------- -- ----------
     @xmath      (10.6.3)
  -- -------- -- ----------

To be more explicit about this, our new improved bound can be written in
any of three equivalent forms:

1.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.4)
      -- -------- -- ----------

2.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.5)
      -- -------- -- ----------

3.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.6)
      -- -------- -- ----------

The equivalent statements about particle production are:

1.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.7)
      -- -------- -- ----------

2.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.8)
      -- -------- -- ----------

3.  For all @xmath , for all @xmath ,

      -- -------- -- ----------
         @xmath      (10.6.9)
      -- -------- -- ----------

In closing, we reiterate that these general bounds reported in equations
( 10.4.8 ), ( 10.4.11 ), and ( 10.4.14 ), their specializations in
equations ( 10.5.2 ), ( 10.5.3 ), ( 10.5.11 ), ( 10.5.12 ), ( 10.5.15 ),
and ( 10.5.22 ), and the equivalent particle production bounds in
equations ( 10.6.7 )–( 10.6.9 ), are all general purpose tools that are
applicable to a wide variety of physical situations [ 83 , 84 , 85 , 86
, 90 , 112 ] . Furthermore we strongly suspect that further
generalizations of these bounds are still possible.

## Chapter 11 Analytic bounds on transmission probabilities

### 11.1 Introduction

In this chapter, we shall develop some additional and novel analytic
bounds on transmission probabilities (and the related reflection
probabilities and Bogoliubov coefficients) for generic one-dimensional
scattering problems. We shall review the basic concepts underlying this
fascinating topic by rewriting the Schrödinger equation for some
complicated potential whose properties we are trying to investigate in
terms of some simpler potential whose properties are assumed known plus
a (possibly large) “shift” in the potential. Doing so permits us to
extract considerable useful information without having to exactly solve
the full scattering problem.

In earlier chapters of this thesis, and in several published papers [ 88
, 89 , 90 , 91 ] , we have derived a number of rigorous bounds on
transmission probabilities (and reflection probabilities, and Bogoliubov
coefficients) for one-dimensional scattering problems. The derivation of
these bounds generally proceeds by rewriting the Schrödinger equation in
terms of some equivalent system of first-order equations, and then
analytically bounding the growth of certain quantities related to the
net flux of particles as one sweeps across the potential.

In this chapter we shall obtain significantly different results, of both
theoretical and practical interest. While a vast amount of effort has
gone into studying the Schrödinger equation and its scattering
properties [ 37 , 40 , 43 , 51 , 80 , 81 , 82 , 99 , 100 ] , it appears
that relatively little work has gone into providing general analytic
bounds on the transmission probabilities, (as opposed to approximate
estimates). The only known results as far as we have been able to
determine are presented in [ 88 ] , in the earlier chapters of this
thesis, and the related publications [ 89 , 90 , 91 ] based on work
reported in this thesis. Several quite remarkable bounds were first
derived in [ 88 ] , with further discussion and an alternate proof being
provided in [ 89 ] .

These bounds were originally used as a technical step when studying a
specific model for sonoluminescence [ 112 ] , and since then have also
been used to place limits on particle production in analogue spacetimes
[ 83 ] and resonant cavities [ 84 ] , to investigate qubit master
equations [ 85 ] , and to motivate further general investigations of
one-dimensional scattering theory [ 86 ] . Recently, these bounds have
also been applied to the greybody factors of a Schwarzschild black hole
[ 90 ] . Most recently, significant extensions of the original bounds
have been developed by adapting the Miller–Good transformations [ 91 ] .

In this chapter we shall return to this problem, developing a new set of
techniques that are more amenable to the development of both upper and
lower bounds. For technical reasons the new techniques are also more
amenable to investigating behavior “under the barrier”. The basic idea
is to re-cast the Schrödinger equation for some complicated potential
whose properties we are trying to investigate in terms of some simpler
potential whose properties are assumed known, plus a “shift” in the
potential.

### 11.2 From Schrödinger equation to system of ODEs

We are interested in the scattering properties of the Schrödinger
equation,

  -- -------- -- ----------
     @xmath      (11.2.1)
  -- -------- -- ----------

where @xmath . As long as @xmath tends to finite (possibly distinct)
constants @xmath on left and right infinity, then for @xmath one can set
up a one-dimensional scattering problem in a completely standard manner
— see, for example, standard references such as [ 37 , 40 , 43 , 51 , 80
, 81 , 82 , 99 , 100 ] , and the background discussion presented in
earlier chapters of this thesis. The scattering problem is completely
characterized by the transmission and reflection amplitudes (denoted
@xmath and @xmath ), although the most important aspects of the physics
can be extracted from the transmission and reflection probabilities (
@xmath and @xmath ).

#### 11.2.1 Ansatz

The idea is to try to say things about exact solutions to the ODE

  -- -------- -- ----------
     @xmath      (11.2.2)
  -- -------- -- ----------

by comparing this ODE to some “simpler” one

  -- -------- -- ----------
     @xmath      (11.2.3)
  -- -------- -- ----------

for which we are assumed to the know exact solutions @xmath . In a
manner similar to the analysis in references [ 88 , 89 ] , we will start
by introducing the ansatz

  -- -------- -- ----------
     @xmath      (11.2.4)
  -- -------- -- ----------

This representation is of course extremely highly redundant, since one
complex number @xmath has been traded for two complex numbers @xmath and
@xmath . This redundancy allows us, without any loss of generality, to
enforce one auxiliary constraint connecting @xmath and @xmath . We find
it particularly useful to enforce the auxiliary condition

  -- -------- -- ----------
     @xmath      (11.2.5)
  -- -------- -- ----------

Subject to this auxiliary constraint on the derivatives of @xmath and
@xmath , the derivative of @xmath takes on the especially simple form

  -- -------- -- ----------
     @xmath      (11.2.6)
  -- -------- -- ----------

(This ansatz is largely inspired by the techniques of references [ 88 ,
89 ] , where JWKB estimates for the wave function were similarly used as
a “basis” for formally writing down the exact solutions.)

#### 11.2.2 Probability density and probability current

For the probability density we have:

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.2.7)
              @xmath   @xmath      (11.2.8)
              @xmath   @xmath      (11.2.9)
              @xmath   @xmath      (11.2.10)
  -- -------- -------- -------- -- -----------

Furthermore, for the probability current:

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.2.11)
              @xmath               (11.2.12)
              @xmath   @xmath      (11.2.13)
              @xmath   @xmath      (11.2.14)
              @xmath   @xmath      (11.2.15)
  -- -------- -------- -------- -- -----------

Under the conditions we are interested in, (which correspond to a
time-independent solution of the Schrödinger equation), we have @xmath ,
and so @xmath . (And similarly @xmath , so @xmath .) That is, @xmath and
@xmath are position-independent constants, an observation which then
puts a constraint on the amplitudes @xmath and @xmath . Applying an
appropriate boundary condition, which we can take to be @xmath , @xmath
, we then see

  -- -------- -- -----------
     @xmath      (11.2.16)
  -- -------- -- -----------

This observation justifies interpreting @xmath and @xmath as
“position-dependent Bogoliubov coefficients”. Furthermore without any
loss in generality we can choose the normalizations on @xmath and @xmath
so as to set the net fluxes to unity: @xmath .

#### 11.2.3 Second derivatives of the wavefunction

We shall now re-write the Schrödinger equation in terms of two coupled
first-order differential equations for these position-dependent
Bogoliubov coefficients @xmath and @xmath . To do this, evaluate @xmath
making repeated use of the auxiliary condition ( 11.2.5 )

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.2.17)
              @xmath   @xmath      (11.2.18)
              @xmath   @xmath      (11.2.19)
              @xmath   @xmath      (11.2.20)
              @xmath   @xmath      (11.2.21)
              @xmath   @xmath      (11.2.22)
  -- -------- -------- -------- -- -----------

Where in the last line we have finally used our normalization choice
@xmath . This is one of the two relations we wish to establish. Now use
the gauge condition to eliminate @xmath in favour of @xmath to obtain a
second relation for @xmath . This now permits us to write @xmath in
either of the two equivalent forms

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.2.23)
              @xmath   @xmath      (11.2.24)
  -- -------- -------- -------- -- -----------

#### 11.2.4 SDE as a first-order system

Now insert these formulae for the second derivative of the wavefunction
into the Schrödinger equation written in the form

  -- -------- -- -----------
     @xmath      (11.2.25)
  -- -------- -- -----------

to deduce the pair of first-order ODEs:

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.2.26)
     @xmath   @xmath   @xmath      (11.2.27)
  -- -------- -------- -------- -- -----------

It is easy to verify that this first-order system is compatible with the
auxiliary condition ( 11.2.5 ), and that by iterating the system twice
(subject to this auxiliary condition) one recovers exactly the original
Schrödinger equation. We can re-write this 1st-order system of ODEs in
matrix form as

  -- -- -- -----------
           (11.2.28)
  -- -- -- -----------

#### 11.2.5 Formal (partial) solution

Define magnitudes and phases by

  -- -------- -- -----------
     @xmath      (11.2.33)
  -- -------- -- -----------

Calculate

  -- -------- -- -----------
     @xmath      (11.2.34)
  -- -------- -- -----------

whence

  -- -------- -- -----------
     @xmath      (11.2.35)
  -- -------- -- -----------

Similarly we also have

  -- -------- -- -----------
     @xmath      (11.2.36)
  -- -------- -- -----------

Now take the real part of both these equations, whence

  -- -------- -- -----------
     @xmath      (11.2.37)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.38)
  -- -------- -- -----------

Therefore

  -- -------- -- -----------
     @xmath      (11.2.39)
  -- -------- -- -----------

That is

  -- -------- -- -----------
     @xmath      (11.2.40)
  -- -------- -- -----------

whence

  -- -------- -- -----------
     @xmath      (11.2.41)
  -- -------- -- -----------

Now apply the boundary conditions: At @xmath we have both @xmath , and
@xmath . Therefore

  -- -------- -- -----------
     @xmath      (11.2.42)
  -- -------- -- -----------

and so

  -- -------- -- -----------
     @xmath      (11.2.43)
  -- -------- -- -----------

In particular

  -- -------- -- -----------
     @xmath      (11.2.44)
  -- -------- -- -----------

or equivalently

  -- -------- -- -----------
     @xmath      (11.2.45)
  -- -------- -- -----------

Of course this is only a formal solution since @xmath and @xmath are,
(at least at this stage), “unknown”. But we shall argue that this
formula still contains useful information. In particular, in view of the
normalization conditions relating @xmath and @xmath , and the parity
properties of @xmath and @xmath , we can also write

  -- -------- -- -----------
     @xmath      (11.2.46)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.47)
  -- -------- -- -----------

#### 11.2.6 First set of bounds

To determine the first elementary set of bounds on @xmath and @xmath is
now trivial. We just note that

  -- -------- -- -----------
     @xmath      (11.2.48)
  -- -------- -- -----------

Therefore

  -- -------- -- -----------
     @xmath      (11.2.49)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.50)
  -- -------- -- -----------

What does this now tell us about the Bogoliubov coefficients?

#### 11.2.7 Bogoliubov coefficients

The slightly unusual thing, (compared to our earlier work in this thesis
and in references [ 88 , 89 , 91 ] ), is that now the “known” function
@xmath may also have its own Bogoliubov coefficients. Let us assume we
have set our boundary conditions so that for the “known” situation

  -- -------- -- -----------
     @xmath      (11.2.51)
  -- -------- -- -----------

and

  -- -------- -- -----------
     @xmath      (11.2.52)
  -- -------- -- -----------

Then the way we have set things up, for the “full” problem we still have

  -- -------- -- -----------
     @xmath      (11.2.53)
  -- -------- -- -----------

whereas

  -- -------- -------- -------- -------- -----------
     @xmath   @xmath   @xmath            (11.2.55)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -----------

That is, the overall Bogoliubov coefficients satisfy

  -- -------- -- -----------
     @xmath      (11.2.56)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.57)
  -- -------- -- -----------

These equations relate the Bogoliubov coefficients of the “full” problem
@xmath to those of the simpler “known” problem @xmath , plus the
evolution of the @xmath and @xmath coefficients. Now observe that

  -- -------- -- -----------
     @xmath      (11.2.58)
  -- -------- -- -----------

But we can define

  -- -------- -- -----------
     @xmath      (11.2.59)
  -- -------- -- -----------

in terms of which

  -- -------- -- -----------
     @xmath      (11.2.60)
  -- -------- -- -----------

That is: Since we know

  -- -------- -- -----------
     @xmath      (11.2.61)
  -- -------- -- -----------

we can deduce

  -- -------- -- -----------
     @xmath      (11.2.62)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.63)
  -- -------- -- -----------

#### 11.2.8 Second set of bounds

A considerably trickier inequality, now leading to a lower bound on the
Bogoliubov coefficients, is obtained by considering what the phases
would have to be to achieve as much destructive interference as
possible. That implies

  -- -------- -- -----------
     @xmath      (11.2.64)
  -- -------- -- -----------

whence

  -- -------- -- -----------
     @xmath      (11.2.65)
  -- -------- -- -----------

Therefore, using @xmath , it follows that as long as @xmath , one can
deduce

  -- -------- -- -----------
     @xmath      (11.2.66)
  -- -------- -- -----------

(If on the other hand @xmath , then one only obtains the trivial bound
@xmath .) Another way of writing these bounds is as follows

  -- -------- -- -----------
     @xmath      (11.2.67)
  -- -------- -- -----------

  -- -------- -- -----------
     @xmath      (11.2.68)
  -- -------- -- -----------

with the tacit understanding that the bound remains valid only so long
as argument of the hyperbolic function is positive.

#### 11.2.9 Transmission probabilities

As usual, the transmission probability (barrier penetration probability)
is related to the Bogoliubov coefficient by

  -- -------- -- -----------
     @xmath      (11.2.69)
  -- -------- -- -----------

whence

  -- -------- -- -----------
     @xmath      (11.2.70)
  -- -------- -- -----------

That is

  -- -------- -- -----------
     @xmath      (11.2.71)
  -- -------- -- -----------

or even

  -- -------- -- -----------
     @xmath      (11.2.72)
  -- -------- -- -----------

Furthermore, as long as the argument of the @xmath is positive, we also
have the upper bound

  -- -------- -- -----------
     @xmath      (11.2.73)
  -- -------- -- -----------

If one wishes to make the algebraic dependence on @xmath clearer, by
expanding the hyperbolic functions these formulae may be recast as the
statement that @xmath is greater than

  -- -- -- -----------
           (11.2.74)
  -- -- -- -----------

and (as long as the numerator is positive before squaring), that @xmath
is less than

  -- -- -- -----------
           (11.2.75)
  -- -- -- -----------

### 11.3 Consistency check

There is one special case in which we can easily compare with the
previous results of chapters 5 and 8 of this thesis, and references [ 88
, 89 ] . Take @xmath to be independent of position, so that our
comparison problem is a free particle. In that case

  -- -------- -- ----------
     @xmath      (11.3.1)
  -- -------- -- ----------

Then the bounds derived above simplify to

  -- -------- -- ----------
     @xmath      (11.3.2)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (11.3.3)
  -- -------- -- ----------

This is “Case I” of reference [ 88 ] , and the “elementary bound” of
reference [ 89 ] , which demonstrates consistency whenever the
formalisms overlap. (Note that it is not possible to obtain “Case II” of
reference [ 88 ] or the “general bound” of reference [ 88 , 89 ] from
the present analysis — this is not a problem, it is just an indication
that this new bound really is a different bound that only partially
overlaps with the previous results of references [ 88 , 89 , 91 ] .)

A second (elementary) check is to see what happens if we set @xmath ,
effectively assuming that the full problem is analytically solvable. In
that case @xmath , (and similarly both @xmath and @xmath ), as indeed
they should.

### 11.4 Keeping the phases?

We can extract a little more information by taking the imaginary parts
of equations ( 11.2.35 ) and ( 11.2.36 ) to obtain:

  -- -------- -- ----------
     @xmath      (11.4.1)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (11.4.2)
  -- -------- -- ----------

Subtracting

  -- -------- -- ----------
     @xmath      (11.4.3)
  -- -------- -- ----------

This is now a differential equation that only depends on the difference
in the phases — the overall average phase @xmath has completely
decoupled. (Moreover, in determining the transmission and reflection
probabilities, this average phase also neatly decouples). To see how far
we can push this observation, let us now define a “nett” phase

  -- -------- -- ----------
     @xmath      (11.4.4)
  -- -------- -- ----------

Furthermore, as per the previous subsections, we retain the definitions

  -- -------- -- ----------
     @xmath      (11.4.5)
  -- -------- -- ----------

Then equation ( 11.2.43 ) becomes

  -- -------- -- ----------
     @xmath      (11.4.6)
  -- -------- -- ----------

while the “nett” phase satisfies

  -- -------- -- ----------
     @xmath      (11.4.7)
  -- -------- -- ----------

We can even substitute for @xmath and thus rewrite this as a single
integro-differential equation for @xmath :

  -- -------- -------- -------- -------- ----------
     @xmath   @xmath   @xmath            (11.4.8)
                                @xmath   
  -- -------- -------- -------- -------- ----------

This equation is completely equivalent to the original Schrödinger
equation we started from. Unfortunately further manipulations seem
intractable, and it does not appear practicable to push these
observations any further.

### 11.5 Application: Small shift in the potential

Let us now consider the situation

  -- -------- -- ----------
     @xmath      (11.5.1)
  -- -------- -- ----------

for @xmath “sufficiently small”.

#### 11.5.1 First-order changes

To be consistent with previous notation ( 1.3.14 ) let us define

  -- -------- -- ----------
     @xmath      (11.5.2)
  -- -------- -- ----------

Using equation ( 11.2.43 ) we obtain the preliminary estimates

  -- -------- -- ----------
     @xmath      (11.5.3)
  -- -------- -- ----------

and similarly

  -- -------- -- ----------
     @xmath      (11.5.4)
  -- -------- -- ----------

It is now useful to change variables by introducing some explicit phases
so as to define

  -- -------- -- ----------
     @xmath      (11.5.5)
  -- -------- -- ----------

  -- -------- -- ----------
     @xmath      (11.5.6)
  -- -------- -- ----------

Doing so modifies the system of differential equations ( 11.2.26 ,
11.2.27 ) so that it becomes

  -- -------- -------- -------- -- ----------
     @xmath   @xmath   @xmath      (11.5.7)
     @xmath   @xmath   @xmath      (11.5.8)
  -- -------- -------- -------- -- ----------

The advantage of doing this is that in the current situation we can now
estimate

  -- -------- -------- -------- -- -----------
     @xmath   @xmath   @xmath      (11.5.9)
     @xmath   @xmath   @xmath      (11.5.10)
  -- -------- -------- -------- -- -----------

Integrating

  -- -------- -- -----------
     @xmath      (11.5.11)
  -- -------- -- -----------

This is not the standard Born approximation, though it can be viewed as
an instance of the so-called “distorted wave Born approximation” [ 27 ]
. In terms of the absolute values we definitely have

  -- -------- -- -----------
     @xmath      (11.5.12)
  -- -------- -- -----------

#### 11.5.2 Particle production

When it comes to considering particle production we note that

  -- -------- -- -----------
     @xmath      (11.5.13)
  -- -------- -- -----------

so, since @xmath , the change in the number of particles produced is

  -- -------- -- -----------
     @xmath      (11.5.14)
  -- -------- -- -----------

In particular

  -- -------- -- -----------
     @xmath      (11.5.15)
  -- -------- -- -----------

Since

  -- -------- -- -----------
     @xmath      (11.5.16)
  -- -------- -- -----------

can also write as

  -- -------- -- -----------
     @xmath      (11.5.17)
  -- -------- -- -----------

Note that one will only get an order @xmath change in the particle
production if the “known” problem @xmath already results in nonzero
particle production.

#### 11.5.3 Transmission probability

To see how a small shift in the potential affects the transmission
probability we note

  -- -------- -- -----------
     @xmath      (11.5.18)
  -- -------- -- -----------

But then

  -- -------- -- -----------
     @xmath      (11.5.19)
  -- -------- -- -----------

implying

  -- -------- -- -----------
     @xmath      (11.5.20)
  -- -------- -- -----------

So the change in the transmission probability is

  -- -------- -- -----------
     @xmath      (11.5.21)
  -- -------- -- -----------

Taking absolute values one obtains

  -- -------- -- -----------
     @xmath      (11.5.22)
  -- -------- -- -----------

Note that one will only get an order @xmath change in the transmission
probability if the “known” problem @xmath already results in nonzero
transmission (and nonzero reflection).

### 11.6 Discussion

We wish emphasize the advantages of the particular bounds derived in
this chapter:

-   They are very simple to derive — the algebra is a lot less
    complicated than some of the other approaches that have been
    developed in earlier chapters of this thesis, and published in
    several papers [ 88 , 89 , 90 , 91 ] . (And a lot less complicated
    than some of the blind alleys we have explored.)

-   Under suitable circumstances the procedure of this chapter yields
    both upper and lower bounds. Obtaining both upper and lower bounds
    is in general very difficult to do — see in particular the attempts
    in [ 89 ] .

-   All of the other bounds we have developed in earlier chapters of
    this thesis, and published in several papers [ 88 , 89 , 90 , 91 ]
    needed some condition on the phase of the wave-function, (some
    condition similar to @xmath ), which had the ultimate effect of
    making it difficult to make statements about tunnelling “under the
    barrier”. There is no such requirement in the present analysis. (The
    closest analogue is that we need @xmath , which we normalize without
    loss of generality to @xmath .) In particular this means that there
    should be no particular difficulty in applying the bound in the
    classically forbidden region — the “art” will lie in finding a
    suitable form for @xmath which is simple enough to carry out exact
    computations while still providing useful information.

In closing, we reiterate the fact that generic one-dimensional
scattering problems, which have been extensively studied for close to a
century, nevertheless still lead to interesting features and novel
results.

## Chapter 12 Discussion

### 12.1 What we have achieved

In this chapter we shall discuss the overall concept and achievements of
this thesis. To a large extent much of the work has already has
summarised at the end of each section. This thesis has been written with
the goal of making it fully accessible to people with a basic background
in non-relativistic quantum physics, especially in the physics of
transmission, reflection, and Bogoliubov coefficients. Mathematically,
the key feature is an analytic study of the properties of certain
second-order linear differential equations, and the derivation of
analytic bounds on the growth of solutions of these equations (as a
function of position and/or time). In this thesis we divided our efforts
into analyzing four separate problems relating to rigorous bounds on
transmission, reflection, and Bogoliubov coefficients — these are
considered under four separate themes:

1.  Bounding the Bogoliubov coefficients,

2.  Bounding the greybody factors for Schwarzschild black holes,

3.  Transmission probabilities and the Miller–Good transformation, and

4.  Analytic bounds on transmission probabilities.

In addition, all four of these separate themes which are reported in
this thesis, are also the seeds for the various published journal
articles (plus one submitted article) that have already arisen from this
thesis.

This thesis is divided into twelve main chapters. In the following, we
shall summarise and anaylse the main work we derived in each chapter.

### 12.2 The main analysis: Structure of the thesis

We first provided sufficient context for the reader to appreciate the
role played by the various topics to be discussed in this thesis, and to
place them into a wider perspective. Firstly, we introduced the
Schrödinger equation — a specific partial differential equation used in
the development of the “new” (1925) quantum theory. Secondly, we
provided the basic theory underlying the WKB approximation , and the
concept of the time-independent Schrödinger equation — both are
foundations for all our subsequent analyses. We have presented a very
general introduction to these concepts first — so that the bounds we
derived on transmission, reflection, and Bogoliubov coefficients were
easier to understand.

We mainly considered the scattering theory in one space dimension —
because it is mathematically simple and physically transparent.

In particular, it is interesting to show how to derive the basic ideas
of transmission and reflection directly by using scattering theory. In
addition, we have just seen an important connection between reflection
and transmission amplitudes. We called the probability that a given
incident particle is reflected as the “reflection coefficient”. While
the probability that it is transmitted is called the “transmission
coefficient”.

In chapter 3 , we collected many known analytic results in a form
amenable to comparison with the general results we subsequently derived.
In addition, we also introduced the concept of quasinormal modes [QNM].
We used these tools for comparing the bounds with known analytic
results. Moreover, we reproduced some of the analytically known results,
and showed (or at least sketched) how to derive their scattering
amplitudes, and so calculate quantities such as the tunnelling
probabilities and quasinormal modes. We did this explicitly for the
delta–function potential, double–delta–function potential, square
potential barrier, tanh potential, sech @xmath potential, asymmetric
square-well potential, the Poeschl–Teller potential and its variants,
and finally the Eckart–Rosen–Morse–Poeschl–Teller potential.

We also obtained a number of significant bounds, considerably stronger
than those in [ 88 ] , of both theoretical and practical interest. Even
though the calculations we have presented are sometimes somewhat
tedious, we feel however, they are more than worth the effort — since
there is a fundamental lesson to be learnt from them. Technically, we
demonstrated that the Schrödinger equation can be written as a
Shabat–Zakharov or a Zakharov–Shabat system, which can then be
re-written in @xmath matrix form.

In chapter 5 , we have again moved our attention back to a
Shabat–Zakharov system of ODEs by re-casting and describing the first
derivation of scattering bounds as presented by Visser in reference [ 88
] . The formalism as developed here works in terms of one free function
@xmath . In other parts of this thesis we have established generalized
bounds; some in terms of two arbitrary functions @xmath and @xmath , and
some in terms of three arbitrary functions @xmath , @xmath , and @xmath
. The derivation of this chapter is noteworthy because of its brevity
and simplicity.

All of the above techniques from chapter 5 are important to develop a
number of interesting bounds in chapter 6 . We dealt with some specific
cases of these bounds and develop a number of interesting
specializations. We have collected together a large number of results
that otherwise appear quite unrelated, including reflection above and
below the barrier. In addition, we have divided the special case bounds
we considered into five special cases: special cases 1–4, and “future
directions”. Finally, we took further specific cases of these bounds and
related results to reproduce many analytically known results.

Consequently, we have re-cast and represented these bounds (from chapter
6 ) in terms of the mathematical structure of parametric oscillations.
This time-dependent problem is closely related to the spatial properties
of the time-independent Schrödinger equation.

In chapter 8 , we re-assessed the general bounds on the Bogoliubov
coefficients developed in earlier chapters of this thesis, and published
in reference [ 88 ] , providing a new and largely independent derivation
of the key results, one that short-circuits much of the technical
discussion in chapter 5 , and published in reference [ 88 ] .

After this investigation about bounding the Bogoliubov coefficients and
their techniques we have moved to study the greybody factors in
Schwarzschild black hole. The “greybody factor” is actually a synonym
for “transmission probability”. Indeed, the phrase “greybody factor” is
used more in the thermodynamics and spectroscopy communities, while the
phrase “transmission probability” is used more in the quantum mechanics
community, but they are referring to the same concept. In this thesis,
we developed a complementary set of results — we derived several
rigorous analytic bounds that can be placed on the greybody factors.
Even though these bounds are not necessarily tight bounds on the exact
greybody factors, they do serve to focus attention on general and robust
features of these greybody factors. Moreover they provide a new method
of extracting physical information. Furthermore, we considered the
greybody factors in black hole physics, which modify the naive Planckian
spectrum that is predicted for Hawking radiation when working in the
limit of geometrical optics.

We used the Miller–Good transformation (which maps an initial
Schrödinger equation to a final Schrödinger equation for a different
potential) to significantly generalize the previous bound. Moreover, we
shall see that the Miller–Good transformation is an efficient process to
generalize the bound, to make it more efficient and powerful.

Finally, we have again shifted our attention back to the analytic bounds
and transmission probabilities context. We developed a new set of
techniques that are more amenable to the development of both upper and
lower bounds. Moreover, we derived significantly different results (a
number of rigorous bounds on transmission probabilities for one
dimensional scattering problems), of both theoretical and practical
interest.

Instead of explaining the details of the analysis yet again,

we would like to stress a few points that we believe are useful to
understand the overall concept of the thesis:

-   The Schrödinger equation describes the space –and time– dependence
    of quantum mechanical systems, and its application to the wave
    function are the basic idea that describes the wavelike properties
    of a subatomic system.

-   The probability current express the reflection and transmission
    coefficients. The probability current is based on the assumption
    that the intensity of a beam is the product of the speed of its
    particles and their linear number density. It is then a mathematical
    theorem that this probability current is conserved.

-   The WKB approximation is generally applicable to problems of wave
    propagation in which the frequency of the wave is very high or
    equivalently, the wavelength of the wave is very short.

-   The ideas of reflection and transmission of waves in both unbound
    and bound states are important. By considering reflection and
    transmission of waves in unbound states, we have seen that in
    principle they are completely specified by the potential function
    @xmath .

-   The quasinormal modes [QNM] are the modes of energy dissipation of a
    perturbed object or field. In particular, the most outstanding and
    well-known example is the perturbation of a wine glass with a knife:
    the glass begins to ring, it rings with a set, or superposition, of
    its natural frequencies – its modes of sonic energy dissipation. As
    previously explained, when the glass went on ringing forever, we can
    call these modes normal. For instance, here the amplitude of
    oscillation decays in time, so we call its modes quasi-normal [ 14 ]
    .

-   The Schrödinger equation can be written as a Shabat–Zakharov system,
    which can then be re-written in @xmath matrix form. We rearranged
    this formation in terms of a generalized position-dependent
    “transfer matrix” involving the symbol @xmath which denotes “path
    ordering”.

-   A “parametric oscillator” is a simple harmonic oscillator whose
    parameters (its resonance frequency @xmath and damping time @xmath )
    vary in time. The other interesting way of understanding a
    parametric oscillator is that it is a device that oscillates when
    one of its “parameters” (a physical entity, like capacitance) is
    changed.

### 12.3 Further interesting issues

There are some interesting ways this thesis could be extended in future
work. We would like to wrap-up by providing a list of things that we
believe are interesting to continue to analyze:

-   This present research certainly deserves more work on how to extend
    the bounds in many different ways. While we have already established
    several powerful techniques to derive rigorous bounds on
    transmission, reflection, and Bogoliubov coefficients, we feel,
    however, that there are probably “optimal” bounds still waiting to
    be discovered.

-   In particular, it is apparent that the current bounds in chapter 8
    are not the best that can be achieved, and we strongly suspect that
    it may be possible to develop yet further extensions to the current
    formalism. It is in fact possible that the “more general” bounds are
    close to being discovered and will have further development in the
    near future.

-   The bounds presented in chapter 10 are generally not “WKB-like” —
    apart from the one case reported in equation ( 10.5.15 ) there is no
    need (nor does it seem useful) to separate the region of integration
    into classically allowed and classically forbidden regions. In fact
    it is far from clear how closely these bounds might ultimately be
    related to WKB estimates of the transmission probabilities, and this
    is an issue to which we hope to return in the future.

-   Finally, we have seen that even though the topic considered in this
    thesis is ultimately a quantum mechanics subject, dating back to
    1925, this does not mean that everything has already been done. It
    is conceivable that the new techniques in this project help us to
    derive more rigorous and tighter bounds for the barrier penetration
    probability.

All the above suggestions would be interesting and feasible, although
some of them would be more tedious to work on than others.

In summary, this thesis provides a platform for better understanding the
rigorous bounds that one can place on the Bogoliubov coefficients
associated with a time-dependent potential, and the several rigorous
analytic bounds that can be placed on the greybody factors. This thesis
developed a way of looking for nice and accurate bounds. Furthermore,
one primary goal of this thesis was to explore the best way of finding
barrier penetration probability. In conclusion, we can say that this
project will be another step to improving our understanding of quantum
mechanics, in particular, non-relativistic quantum physics, especially
in regard to transmission, reflection, and Bogoliubov coefficients.