# Preface

The work presented in this thesis was carried out in the Theoretical
Physics Group, Imperial College, between October 2007 and September
2011. The supervisor was Prof. Jonathan J. Halliwell.

The results presented in Chapters 3 and 7 were published in Journal of
Physics A [ 99 ] and Physical Review A [ 100 ] respectively. The work
presented in Chapter 4 was done in collaboration with Jonathan Halliwell
and published in Journal of Physics A [ 51 ] . Chapters 5 and 6 are
based on work done in collaboration with Jonathan Halliwell and
published in Physical Review A [ 49 ] and Physics Letters A [ 50 ] . The
work presented in Chapter 8 was done in collaboration with Delius Downs,
Jonathan Halliwell and Anna Hashagen and was published in Physical
Review A [ 101 ] .

I am grateful to Carl Bender, Adolfo del Campo, Fay Dowker, Bei-Lok Hu,
Seth Lloyd, Gonzalo Muga, Lawrence Schulman and Antony Valentini for
their comments and suggestions on the material contained in this thesis.

Some of the work in this thesis was carried out during a short stay at
the Apuan Alps Centre for Physics at the Towler Institute, Italy during
the conference “21st Century directions in de Broglie-Bohm theory and
beyond.” I would like to thank Mike Towler and the other conference
organisers for their hospitality.

In addition I would like to thank Kate Clements, Ben Hoare, Steven
Johnston, Sam Kitchen, Johannes Knoller, Noppadol ‘Omega’ Mekareeya, Tom
Pugh and David Weir for many useful, informative and occasionally even
relevant discussions.

None of the work set out in this thesis would have been possible without
the limitless support and encouragement of my supervisor, Jonathan
Halliwell. I am grateful for all his help over the four years of my PhD
here at Imperial and I consider myself incredibly fortunate to have had
him as a teacher and collaborator.

###### Contents

-    Preface
-    \thechapter Introduction
    -    1 A Brief History of Time in Quantum Theory
    -    2 The Quantum Zeno Effect
    -    3 The Backflow Effect
    -    4 The Arrival Time Problem in Quantum Mechanics
        -    4.1 General Theory
        -    4.2 Standard Forms of the Arrival Time Distribution
    -    5 The Decoherent Histories Approach to Quantum Theory
    -    6 The Decoherent Histories Approach to the Arrival Time
        Problem: Introduction and History
    -    7 Summary and Overview of the Rest of This Thesis
-    \thechapter The Path Decomposition Expansion (PDX)
    -    8 Introduction
    -    9 The Path Decomposition Expansion (PDX)
    -    10 Using the PDX: Scattering States for a Complex Step
        Potential
    -    11 A Semiclassical Approximation
-    \thechapter The Propagator for the Step and Delta Function
    Potentials, using the PDX
    -    12 Introduction
    -    13 The Brownian Motion Definition of the Propagator
    -    14 The Step Potential
    -    15 The Delta Function Potential
-    \thechapter On the Relationship between Complex Potentials and
    Strings of Projection Operators
    -    16 Introduction
    -    17 Review and Extension of Earlier Work
    -    18 Detailed Formulation of the Problem
    -    19 Exact Analytic Results
    -    20 Asymptotic Limit
    -    21 A Time Averaged Result
    -    22 Numerical Results
    -    23 Timescales
    -    24 Summary and Discussion
-    \thechapter Arrival Times, Complex Potentials and Decoherent
    Histories
    -    25 Introduction
    -    26 The Classical Arrival Time Problem via a Complex Potential
    -    27 Calculation of the Arrival Time Distribution via a Complex
        Potential
    -    28 Decoherent Histories Analysis for a Single Large Time
        Interval
    -    29 Decoherent Histories Analysis for an Arbitrary Set of Time
        Intervals
        -    29.1 Class Operators
        -    29.2 An Important Simplification of the Class Operator
        -    29.3 Probabilities for Crossing
        -    29.4 Decoherence of Histories and the Backflow Problem
        -    29.5 The Decoherence Conditions
        -    29.6 Checking the Decoherence Condition for Wavepackets
    -    30 Summary and Conclusions
-    \thechapter Arrival Times, Crossing Times and a Semiclassical
    Approximation
    -    31 Introduction
    -    32 Semiclassical Derivation of the Arrival Time Class Operators
    -    33 Arrival Times, Crossing Times and First Crossing Times
    -    34 Crossing Class Operators in Decoherent Histories
    -    35 Crossing Time Probabilities and Decoherence of Crossing
        Histories
    -    36 Summary and Discussion
-    \thechapter Quantum Arrival Time for Open Systems
    -    37 Introduction
    -    38 Arrival Time for Open Quantum Systems
    -    39 Quantum Brownian Motion
    -    40 Properties of the Arrival Time Distribution in Quantum
        Brownian Motion
    -    41 The Decoherent Histories Approach to the Arrival Time
        Problem
    -    42 Decoherence of Arrival Times in Quantum Brownian Motion
        -    42.1 General Case
        -    42.2 The Near-Deterministic Limit
    -    43 Summary and Discussion
-    \thechapter Quantum Arrival and Dwell Times via an Ideal Clock
    -    44 Introduction
        -    44.1 Opening Remarks
        -    44.2 Dwell Time
        -    44.3 Clock Model
        -    44.4 Connections to Earlier Work
        -    44.5 This Chapter
    -    45 Arrival Time Distribution from an Idealised Clock
        -    45.1 Weak Coupling Regime
        -    45.2 Strong Coupling Regime
            -    45.2.1 Special Case: @xmath
            -    45.2.2 General Case
    -    46 Dwell Time Distribution from an Idealised Clock
    -    47 Conclusion
-    \thechapter Summary and Some Open Questions
    -    48 Summary
    -    49 Open Questions and Future Work
-    Appendix: Some Properties of the Current

###### List of Figures

-    1 Probabilities for Space-like and Time-like Surfaces
-    2 The Arrival Time Problem
-    3 The Path Decomposition Expansion (PDX)
-    4 A Typical Path From @xmath to @xmath On Our Lattice.
-    5 The Bijection Between @xmath and @xmath .
-    6 The Path Decomposition Expansion for @xmath .
-    7 A Plot Comparing the Functions @xmath and @xmath .
-    8 Plot of the Exact Value of @xmath Compared With an Analytic
    Approximation.
-    9 A Plot of the Function @xmath .
-    10 Recap of the Arrival Time Problem.
-    11 Plot of the Function @xmath .
-    12 The Arrival Time of a Superposition of Two Wavepackets.
-    13 Crossing Times
-    14 Crossing Times and First Crossing Times
-    15 Arrival Times in Terms of Initial States and Propagators.
-    16 The Arrival Time Problem Defined Using a Model Clock.
-    17 The Dwell Time Problem, Defined Using a Model Clock.
-    18 The PDX Used for the Dwell Time Problem.

## Chapter \thechapter Introduction

  The time is out of joint; O curséd sprite,
  That ever I was born to set it right!

  Shakespeare, Hamlet

### 1 A Brief History of Time in Quantum Theory

The treatment of time observables is an important loose end in quantum
theory [ 81 , 80 ] . Whilst there is no indication of any disagreement
between the predictions of quantum theory and the outcomes of
experiment, time observables constitute a class of quantities that are
observables in classical mechanics, but for which no satisfactory
treatment exists in standard quantum theory.

As well as being an important topic in its own right, a consistent
treatment of time observables might also shed light on problems in
quantum gravity and quantum cosmology. One of the most tricky problems
faced by any attempt to quantise gravity is that of the problem of time
[ 64 ] . In essence the symmetries of general relativity prevent the
identification of any variable to play the role of time in quantum
gravity. Whilst there is no generally agreed way of tackling this
problem one school of thought holds that any approach to quantising
gravity must proceed by treating time and space on an equal footing. A
theory treating time and space in a truly symmetric way would have as
observables probabilities for entering given regions of spacetime rather
than, for example, statements about the position of a particle at a
fixed moment of time. Since these are not the kind of probabilities one
normally deals with in quantum theory it is instructive to see if the
same exercise can be performed in non-relativistic quantum theory. That
is, can one assign probabilities to questions of the form, “What is the
probability of finding a particle in a given region of space, @xmath ,
in a given interval of time, @xmath ?”

Asking questions of this sort quickly leads us to another problem in
non-relativistic quantum theory, which is this: “What exactly is the
status of the variable @xmath that appears in Schrödinger’s equation?”
It should be clear immediately that it is not related to any operator on
the Hilbert space of the system. Indeed it is not really a quantum
quantity at all and is probably best thought of as referring to some
external classical clock. This hybrid approach to dynamics, having a
quantum wavefunction depend on an external classical clock variable,
could be seen as troubling. An operationalist might reply that the
co-ordinate @xmath also refers to an external classical world, but this
line of reasoning is over simplistic for three reasons. The first is
that both position and its conjugate variable, momentum, appear as
operators in quantum mechanics, whereas energy is represented by an
operator in quantum mechanics, but time is not. There is therefore a
lack of symmetry in the treatment. The second reason is that quantum
mechanics may be written in a representation-free manner in terms of
abstract vectors in Hilbert space. Here there need be no mention of
position or momentum, and yet the Schrödinger equation for evolution in
this abstract space still includes the time coordinate. The final reason
is the most profound, and again touches on the lack of symmetry in the
treatment of space and time coordinates. In non-relativistic quantum
mechanics, the object,

  -- -------- -- -----
     @xmath      (1)
  -- -------- -- -----

gives the probability of finding the particle in the interval @xmath at
the time @xmath . What is the corresponding probability for finding the
particle at the position @xmath in the interval @xmath ? It is not given
by

  -- -------- -- -----
     @xmath      (2)
  -- -------- -- -----

since finding the particle at a position @xmath at the times @xmath or
@xmath are not exclusive alternatives, see Fig.( 1 ). Yet in the
standard interpretations of quantum mechanics the wavefunction is
supposed to contain all the information about a given system [ 67 ] . If
the square norm of a general wavefunction is not a probability
distribution on a set of times does this mean there can be no
satisfactory treatment of time observables in standard quantum theory?

To get a better idea of where the difficulty lies it is instructive to
look more closely at the classical case. Here the solution of a
particular problem may be expressed in terms of an equation of motion
for the particle, of the form,

  -- -------- -- -----
     @xmath      (3)
  -- -------- -- -----

where @xmath represents the initial condition. This is the solution to
the question: “Where is the particle at time @xmath ?” Under general
conditions one may invert this equation of motion to give,

  -- -------- -- -----
     @xmath      (4)
  -- -------- -- -----

which is the solution to the question: “When is the particle at position
@xmath ?” Crucial to this analysis is the concept of a trajectory and
that the particle will with certainty be found somewhere on this
trajectory, at any time. This concept is of course lacking in quantum
theory.

In classical mechanics observables are given by functions on phase
space, and so Eq.( 4 ) is equivalent to some phase space function,

  -- -------- -- -----
     @xmath      (5)
  -- -------- -- -----

Crucially, unlike classical observables like the energy or angular
momentum, construction of Eq.( 5 ) requires knowledge of the equations
of motion, Eq.( 3 ). Strictly speaking then, even in classical mechanics
questions such as “When does the particle reach the origin?” have a
different character to questions like “What is the energy of the
particle?”. The observable coresponding to the former is a function on
phase space which is constructed using the equations of motion. In a
sense, therefore, the surprise is not that quantum theory struggles to
deal with time observables, but that classical mechanics deals with them
so easily. This is essentially a consequence of the realist nature of
classical physics.

Approaches to the problem of defining time observables in quantum theory
fall roughly into three camps. Although it is not the intention of this
thesis to provide a complete overview of the literature on time
observables (see Ref. [ 77 ] for a detailed review in the case of
arrival time), the following characterisations will be useful in
understanding how the approaches taken in this work relate to previous
studies.

#### Trajectory Before Quantisation

These are approaches which in some way borrow the classical structure of
a trajectory and use it in the quantum analysis. One way to do this is
to begin with the classical description, in terms of Eq.( 3 ) and use
this to construct the classical phase space observable Eq.( 5 ), as
outlined above. One then tries to quantise this quantity to obtain the
operator,

  -- -------- -- -----
     @xmath      (6)
  -- -------- -- -----

This category of approaches includes the Aharanov-Bohm time operator [ 3
] . Apart from the obvious issues surrounding whether Eq.( 6 ) is well
defined for a given classical observable, there is something troubling
about this analysis. Since the quantum system we are trying to analyse
will not be explicable in terms a particle following a single
trajectory, it is not clear whether using the classical trajectory to
obtain the operator Eq.( 6 ) is a valid procedure. Even if the resulting
operator is well defined the relation between this observable and the
results of measurement remains unclear. Since this is essentially the
question of how to understand the quantisation of a given classical
system we are unlikely to make much headway with this issue here. It
does, however, motivate trying to find an alternative way to proceed.

Other approaches that fall into this category include the analysis of
Kijowski and its variants, see eg Refs. [ 68 , 61 ] . Here one begins by
deciding what properties one would expect the quantum probability
distribution to possess, such as time translation covariance or
positivity, based on the properties of the classical observable. One
then uses this “wish list” of properties to determine the correct
operator, with the eventual hope that a sufficiently detailed list of
properties might uniquely determine this operator. It is not clear that
this approach should work in all cases however: it is easy to think of
quantum observables, such as angular momentum or the energy levels of a
harmonic oscillator, that have a very different character from their
classical counterparts.

The general attitude of this thesis is that whilst any of the analyses
above might arrive at the correct definition of a time observable in a
particular case, they cannot be relied upon to do so in all cases.

#### Trajectory After Quantisation

These approaches include those based on the de Broglie-Bohm (dBB)
interpretation of quantum theory [ 63 ] , analyses based on the WKB
approximation [ 40 ] and also the decoherent histories approach
presented in this thesis. Here one first quantizes the system and then
looks for structures to play the role of the classical trajectories used
to define the classical observables. For example for gaussian states the
center of the wavepacket will follow simple curve in configuration
space. Provided one does not perform measurements that disturb this
state this limited notion of trajectory can be used to find approximate
arrival and dwell times for the particle, limited by the width of the
wavepacket. Of course these states form only a limited class of possible
states, and it is a general feature of this category of approaches that
they may fail for highly non-classical states.

In the DH approach, described in more detail below, the aim is to assign
probabilities to coarse grained histories of a quantum system. Provided
these probabilities can be assigned consistently one can then use these
histories in much the same way as the classical trajectories to discus
time observables.

In the dBB interpretation, the wavefunction is supplemented by a real
particle following a trajectory computed from the wavefunction. Since a
quantum particle always comes equipped with a unique trajectory
computation of time observables is, at least conceptually, as trivial as
in the classical case. The price one pays, however, is that the behavior
of these trajectories generally depends on whether or not one choses to
carry out a measurement on the system. Thus although in dBB
probabilities for time observables can be obtained without the need for
an observer, the probabilities obtained in this way do depend on whether
or not there is an observer. We will not have much to say in this thesis
about dBB, for more information see Ref. [ 63 ] .

#### Trajectory Free Approaches

These approaches may also be called “operational.” Here one takes a
completely different tack and instead looks for other ways to define
time observables classically, and then tries to repeat this analysis
quantum mechanically.

These approaches include studies based on model clocks, see Ref. [ 88 ]
and Chapter 8 of this thesis. Here the idea is to couple the system we
wish to measure to some additional degrees of freedom which function as
a clock. In this context a clock is simply a quantum system coupled to
our system of interest in such a way that the final state of the clock
is correlated with the time observable we wish to measure. More details
about this scheme can be found in Chapter 8.

In classical mechanics many time observables can be defined by imposing
absorbing boundary conditions on the system. See Chapter 5 for a full
discussion in the arrival time case. The analogue of these absorbing
boundary conditions in quantum theory in the inclusion of a complex
absorbing potential, see Ref. [ 76 ] and also Chapter 5 of this thesis.

Typically the probability distributions obtained from these approaches
are complicated functions of the properties of both the particle and
measuring apparatus. There may or may not exist limits in which
dependence on the measurement parameters drops out, depending on the set
up.

As well as the technical differences between these approaches the
different approaches display very different attitudes towards the
observables we are trying to define. In particular the first and third
approaches assume that an observable such as the arrival time of a
particle is always a well defined quantity and that for any system one
may obtain the probability distribution of that observable. The second
class of approaches, in contrast, are based on recovering the classical
notion of trajectory after quantisation, and thus they are generally
only well defined for semiclassical systems. Proponents of these
approaches would claim that quantities such as the arrival time
distribution are only defined for suitably classical systems ¹ ¹ 1 In
much the same way as it is claimed that time itself is only emergent ,
from an ultimately timeless theory of quantum gravity [ 13 ] . .

An obvious question is whether there is anything linking these three
different approaches to time observables. This is an important question,
firstly since although any particular approach might claim to have the
solution to these problems the validity of these approaches themselves
is questionable. If we could demonstrate that for a particular time
observable the same results are obtained via a number of approaches this
would give us confidence that this result is correct. Secondly, the
different approaches discussed above have their roots in different
interpretations of quantum theory. Although we will try and avoid
philosophical questions about the foundations of quantum theory in this
thesis if we were to show that, for example, expressions for time
observables in de Broglie-Bohm theory were identical to those obtained
via decoherent histories this might shed interesting light on the
relationship between different interpretations of quantum theory ² ² 2
Not to mention the fact that although any interpretation of quantum
theory is constrained by the requirement that it must agree with the
predictions of standard Copenhagen quantum theory, since Copenhagen
quantum theory struggles to incorporate many time observables there is a
possibility that different interpretations of quantum theory may be free
to make different predictions for time observables. There may therefore
be experimental tests that could be done to distinguish between them.
Exciting as this line of thought is, we shall not dwell on it in this
thesis. .

### 2 The Quantum Zeno Effect

There are a number of interesting quantum effects relevant to the
definition of time observables, the most important of which is probably
the quantum Zeno effect. The effect was first noticed by Allcock in his
seminar series of papers on the arrival time problem [ 6 ] , but the
first serious study was undertaken by Misra and Sudershan in Ref. [ 74 ]
.

The quantum Zeno effect is often expressed as a “freezing” of evolution
due to repeated measurement. Much has been learned about the phenomenon
since the early investigations however and it is now understood that
there is more to the effect than simply preventing evolution. Repeated
projections onto a subspace allow for unitary evolution within that
subspace, the effect of the repeated measurement being simply equivalent
to imposing “hard-wall” boundary conditions, preventing the particle
from leaving the subspace [ 27 ] . It is also known that there also
exists an “anti-Zeno” effect, that is, a speeding up of evolution due to
repeated measurement [ 26 ] , although we shall have nothing to say
about the anti-Zeno effect in this thesis.

The quantum Zeno effect plays an important role in study of time
observables because, at least for the “trajectory after quantisation”
and “trajectory free” approaches outlined in the previous section, the
definition of these observables involves statements about the state of
the system at multiple times. This means one has to consider sequential
measurements on the system of interest, if these are performed too
frequently the quantum Zeno effect will result. However the situation is
complicated by the fact that most discussions of the quantum Zeno effect
take place in a setting appropriate for quantum optics or quantum
information, ie a system with a small number of discrete energy levels,
not in the context of particles in 1D. In the rest of this section we
therefore outline the standard discussion of the quantum Zeno effect and
the way in which this discussion might be modified to make it relevant
to time observables. Our discussion will be brief, since the details of
the Zeno limit in the arrival time problem etc are worked out more
thoroughly in Chapter 4.

We begin by introducing the Zeno effect in the way it appears in the
original discussion of Misra and Sudarshan, Ref. [ 74 ] . The idea is to
utilise some form of product formula to show that the repeated process
of evolution followed by measurement is equivalent to restricted
evolution in the subspace defined by the measurement. We consider a
system with initial state @xmath which evolves under a Hamiltonian
@xmath for a total time @xmath , interspersed with @xmath projective
measurements @xmath . The state at time @xmath is given by,

  -- -------- -------- -------- -------- -----
     @xmath   @xmath   @xmath            (7)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -----

One then considers the limit @xmath , and one can show, under certain
conditions on @xmath and @xmath ,

  -- -------- -- -----
     @xmath      (8)
  -- -------- -- -----

where the Zeno hamiltonian @xmath . This shows that evolution under
repeated measurement leads to unitary evolution in the subspace defined
by the measurements.

If we consider the evolution in Eq.( 7 ), with @xmath and @xmath the
free hamiltonian for a particle in 1D, we have a simple model of the
type of measurement set up we might use to determine the time at which
the particle arrived at @xmath . Without concerning ourselves too much
with the details, since these are covered in Section 4 and the rest of
this thesis, it is clear that the Zeno effect sets a lower limit on the
resolution with which we can define an arrival time using this set up.

Although this analysis is mathematically precise this precision is
obtained at the expense of providing any great physical insight. A key
question concerns the time scale on which the Zeno effect begins to
occur. That is, what is the minimum spacing between measurements, @xmath
, that I can take without causing significant reflection from the
measuring aparatus. This is important since we can hardly expect to
achieve @xmath in the real word. One way to approach this is to look for
the time scale on which the state may be said to leave the subspace
defined by @xmath . The idea is that projections more frequent than this
will “interrupt” the state in the process of exiting the region, so that
this time scale provides an upper bound on the separation between
projections necessary to give rise to the Zeno effect. We follow the
analysis of Peres [ 87 ] and consider an initial state, with evolution
for a time @xmath followed by a measurement which projects back onto the
original state. The survival probability, @xmath , is given by,

  -- -------- -------- -------- -------- -----
     @xmath   @xmath   @xmath            (9)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -----

where we have defined the ‘‘Zeno time’’ ³ ³ 3 Note that there are many
different notions of the time it takes a system to make a transition.
See [ 92 ] for a more detailed discussion. ,

  -- -------- -- ------
     @xmath      (10)
  -- -------- -- ------

We see from this expression that the short time behaviour is quadratic
in @xmath , thus we confirm that in the limit of infinitely frequent
measurements the state does not evolve. Secondly, we see that there is a
characteristic time scale, @xmath , on which the evolution takes place.

Although we have arrived here at what is normally called the “Zeno”
time, it is not clear that this really is the time scale on which the
projections give rise to reflection and thus the Zeno effect. For a
minimum uncertainty gaussian wavepacket with spatial width @xmath peaked
around some momentum @xmath Eq.( 10 ) gives @xmath . This is indeed the
time scale on which the state crosses the origin, however this is an
essentially classical timescale and it seems unlikely that this is
relevant for reflection, which is a quantum effect. It is also worth
pointing out that if we really are limited in the accuracy of our
description by the time scale @xmath then it is impossible to formulate
a description of crossing time probabilities in the normal sense. This
is because our minimum temporal resolution is the same order as the time
taken for our wavepacket to cross the origin, so the probabilities for
crossing will essentially be 1 for one time interval and 0 for the rest.

Projecting back onto the original state captures the notion of the time
on which the state changes, and this is certainly the same as leaving
some subspace of the full Hilbert space, but we are interested in a
particular subspace, that of states with support only in @xmath and this
analysis does not capture that. There is another problem, which is that
Eq.( 9 ) is a Taylor expansion of the initial state about @xmath . It is
known that for general wavefunctions the behaviour may not be analytic
at @xmath . Put another way, the Zeno time is expressed in terms of
moments of the wavefunction, and these may not exist for general
wavefunctions. This is particularly apparent when one tries to extend
this analysis to more general measurements.

One of the major achievements in this thesis is to show, in Chapter 4,
that the minimum temporal resolution is in fact set by @xmath , where
@xmath is the energy of the system, and not by Eq.( 10 ).

### 3 The Backflow Effect

Another quantum effect relevant to the understanding of time observables
is the backflow effect [ 12 , 25 ] . Consider an initial state @xmath
consisting entirely of negative momenta evolved freely for a time @xmath
and compute the standard Schrödinger probability current at the origin,
defined in such a way that classically it should be positive. This can
be written in operator form as,

  -- -------- -- ------
     @xmath      (11)
  -- -------- -- ------

(We will discuss the current in much more detail in later sections.) Now
the operator @xmath is not positive, even when restricted to act on
states with negative momentum. This means although Eq.( 11 ) should be
positive classically, it need not be quantum mechanically. What is
remarkable is that very little is known about this effect. One thing
that is known is that the amount of probability that can flow backwards
is bounded, in the sense that,

  -- -------- -- ------
     @xmath      (12)
  -- -------- -- ------

where @xmath is some dimensionless constant computed numerically to be
@xmath [ 25 ] . The existence of such a bound is somewhat unexpected,
Bracken and Melloy in Ref. [ 12 ] conjecture that it is a “new
dimensionless quantum number.” Certainly there is no dependence on
@xmath in this constant and as such it has no obvious classical limit.

One interesting set of questions concern the state for which this bound
is obtained, does it have an analytical expression? Does it have an
obvious physical interpretation? Another question concerns the
typicality, or otherwise, of backflow. Do relatively standard
wavefunctions such as gaussian wavepackets or superpositions of these
give backflow, or do we require more pathalogical states? If we can
indeed produce backflow with more familiar states, is it possible to get
close to the maximum amount of backflow?

Some work towards addressing these questions is in progress [ 102 ] ,
but much remains unclear. A better understanding of the backflow effect
would shed much light on the problem of defining time observables in
quantum theory. This is because, together with the Zeno effect, it is
these quantum effects that provide the fundamental limitation on the
accuracy with which time observables can be defined.

### 4 The Arrival Time Problem in Quantum Mechanics

#### 4.1 General Theory

Much of this thesis will be concerned, directly or otherwise, with the
question of analysing the arrival time problem in quantum theory,
pictured in Fig.( 2 ). It therefore seems useful to give a brief account
of the problem here and also discuss some of the features any solution
must posses.

The classical “arrival time problem” is the following, “Given a free
particle which, at @xmath has position @xmath and momentum @xmath , what
is the time at which the particle crosses the origin?” The solution, of
course, is that the particle crosses at a time,

  -- -------- -- ------
     @xmath      (13)
  -- -------- -- ------

In order to compare the definition of time observables in classical and
quantum physics it is useful to work in terms of classical phase space
distributions. For a free classical particle in 1D the phase space
probability distribution @xmath obeys the following,

  -- -------- -- ------
     @xmath      (14)
  -- -------- -- ------

The solutions of this equation are of the form,

  -- -------- -- ------
     @xmath      (15)
  -- -------- -- ------

so that evolution is just a linear transformation in phase space.

We can write the probability of crossing at a time @xmath in terms of
this distribution as,

  -- -------- -- ------
     @xmath      (16)
  -- -------- -- ------

For states consisting of entirely negative momenta this may also be
written as,

  -- -------- -- ------
     @xmath      (17)
  -- -------- -- ------

which can be seen by using Eq.( 14 ) in Eq.( 17 ) and then integrating
by parts.

Eqs.( 16 ), ( 17 ) express the arrival time distribution in two distinct
ways. Eq.( 16 ) tells us the arrival time distribution is the
expectation value of a certain phase space distribution, whilst Eq.( 17
) tells us the arrival time distribution can be defined in terms of the
“survival probability.” More precisely the arrival time probability is
just the rate at which probability leaves the region @xmath , ie the
flux across @xmath . We will see below that these two expressions
suggest different ways of obtaining the quantum arrival time
distribution.

The quantum arrival time problem is essentially the following question,
“For a given wavefunction what is the probability distribution on the
set of times at which the system may be said to arrive at @xmath ?” For
most situations of interest we can put the following extra constraints
on the wavefunction; at some initial time @xmath the wavefunction
consists only of negative momenta and the particle is concentrated in
@xmath .

The challenge is to understand the correct quantum analogue, @xmath , of
Eqs.( 16 ), ( 17 ), if indeed it exists. We need to do this subject to
the following constraints,

-   @xmath must be a valid probability distribution, ie @xmath and
    @xmath .

-   We must recover Eqs.( 16 ), ( 17 ) in some classical limit.

There are other constraints we could impose, indeed in Ref. [ 68 ] is
was shown that demanding that @xmath satisfy some set of conditions
abstracted from the classical case is, almost, enough to fix it
identically. This is an example of a “trajectory before quantisation”
approach, see Section 1 .

In some ways the most natural way to quantise @xmath is via Eq.( 16 ).
This suggests the (formal) quantum expression,

  -- -------- -- ------
     @xmath      (18)
  -- -------- -- ------

where the arrival time operator,

  -- -------- -- ------
     @xmath      (19)
  -- -------- -- ------

is some quantisation of Eq.( 13 ). We hit a problem, however, which is
that it has proven surprisingly difficult to find a way of defining
@xmath as a self-adjoint operator. This means Eq.( 18 ) is merely formal
and cannot be used to define @xmath . Work has been done to try and get
round this problem [ 77 , 3 ] , but we will not consider this further in
this thesis. At any rate, the criticisms inherent to any approach of
this type, as laid out in Section 1 apply here.

#### 4.2 Standard Forms of the Arrival Time Distribution

We review here some of the standard, mainly semiclassical, formulae for
arrival time. It is useful to collect these expressions in one place as
we will refer to them repeatedly throughout this thesis. None of these
semiclassical expressions are entirely satisfactory, but any more
fundamental approach to defining arrival times must reproduce these
expressions for some suitable class of states and time intervals.

We consider a free particle described by an initial wavepacket with
entirely negative momenta concentrated in @xmath . A widely discussed
candidate for the distribution @xmath is the natural quantum version of
Eq.( 17 ), the integrated probability current density [ 77 , 78 , 49 ] ,

  -- -------- -- ------
     @xmath      (20)
  -- -------- -- ------

Defining @xmath , and introducing the Wigner function [ 10 ] , defined
for a state @xmath by

  -- -------- -- ------
     @xmath      (21)
  -- -------- -- ------

@xmath can be written in any of the following forms:

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (22)
                       @xmath   @xmath   
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

This probability is normalised to 1 when @xmath and @xmath , and has the
correct semiclassical limit [ 49 ] . This expression arises from
considering the survival probability, that is, the probability that the
particle is still in @xmath at some time @xmath ,

  -- -------- -- ------
     @xmath      (23)
  -- -------- -- ------

The rate at which probability leaves @xmath is then given by Eq.( 22 )
and this is a candidate for the arrival time probability distribution.
There is a problem with Eq.( 22 ) however, which is that it need not be
positive, even for states consisting entirely of negative momenta. This
is the backflow effect, discussed in Section 4 . This means we cannot
regard Eq.( 20 ) as the correct arrival time distribution.

The backflow effect arises because of interference between portions of
the state that have crossed the origin, and that part which has yet to
cross. In a limited sense then, this problem is similar to that of
defining an arrival time distribution for a classical particle in a
potential, where the particle may cross the origin and then re-cross at
some later time. In the classical problem one imposes absorbing boundary
conditions to remove that part of the state that has crossed the origin.
The analogue in the quantum case is the use of complex absorbing
potentials. This is an example of a “trajectory free” approach, as
outlined in Section 1 . Under suitable conditions this approach does
indeed yield the the arrival time distribution as Eq.( 20 ). See Chapter
5 for a detailed discussion of this.

Note however that wavefunctions consisting of a single gaussian
wavepacket never display backflow. This means that Eq.( 20 ) may indeed
be valid for these states. These wavefunctions are also WKB states and
the WKB interpretation, an example of a “trajectory after quantisation”
approach as laid out in Section 1 , does indeed give Eq.( 20 ) as the
correct arrival time distribution, at least for these states.

We mention here briefly that the arrival time analysis of Kijowski [ 68
] gives,

  -- -------- -- ------
     @xmath      (24)
  -- -------- -- ------

which can be obtained by an operator re-ordering of @xmath , but which
has the virtue of being positive. We will not have anything to say about
this distribution in this thesis, since it seems to be unrelated either
to the histories analysis, Chapter 5, or to the behavior of ideal
clocks, Chapter 8. Other authors have, however, shown that the
distribution Eq.( 24 ) does arise naturally in analyses of the time of
arrival based on POVMs, see Ref. [ 24 ] for details.

For arrival time probabilities defined by measurements, considered later
in this thesis, one might expect a very different result in the regime
of strong measurements, since most of the incoming wavepacket will be
reflected at @xmath . This is the essentially the Zeno effect [ 74 ] .
It was found in a complex potential model that the arrival time
distribution in this regime is the kinetic energy density

  -- -------- -- ------
     @xmath      (25)
  -- -------- -- ------

where @xmath is a constant which depends strongly on the underlying
measurement model [ 23 , 41 ] . (See Ref. [ 82 ] for a discussion of
kinetic energy density.) However because the majority of the incoming
wavepacket is reflected, it is natural to normalise this distribution by
dividing by the probability that the particle is ever detected, that is,

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (26)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

where @xmath is the average momentum of the initial state. This
normalised probability distribution does not depend on the details of
the detector. This suggests that the form Eq.( 26 ) may be the generic
result in this regime, although a general argument for this is yet to be
found.

It is found in practice that measurement models for arrival times lead
to distributions depending on both the initial state of the particle and
the details of the clock or measuring device, typically of the form

  -- -------- -- ------
     @xmath      (27)
  -- -------- -- ------

where @xmath is one of the ideal distributions discussed above and the
response function @xmath is some function of the clock variables. (In
some cases this expression will be a convolution). However, it is of
interest to coarse grain by considering probabilities @xmath for arrival
times lying in some interval @xmath . The resolution function @xmath
will have some resolution time scale associated with it, and if the
interval @xmath is much larger than this time scale, we expect the
dependence on @xmath to drop out, so that

  -- -------- -- ------
     @xmath      (28)
  -- -------- -- ------

This is the sense in which many different models are in agreement with
semi-classical formulae at coarse-grained scales.

In addition to a lack of positivity, there is a more fundamental problem
with Eq.( 20 ), which is that probabilities in quantum theory should be
expressible in the form [ 84 ]

  -- -------- -- ------
     @xmath      (29)
  -- -------- -- ------

Here @xmath is a projection operator, or more generally a POVM,
associated with the outcome @xmath . Eq.( 20 ) cannot be expressed in
this form and we therefore conclude that it is not a fundamental
expression in quantum theory.

The conclusion then is that whilst there is no axiomatic approach that
yields Eq.( 20 ) as the correct arrival time distribution, there is
extremely good evidence for it from semiclassical and other approaches.
One aim of this thesis is to show how Eq.( 20 ) may be derived from an
underlying axiomatic approach to quantum theory, thus providing the
justification for these semiclassical and operational approaches.

### 5 The Decoherent Histories Approach to Quantum Theory

The following is a brief review of the aspects of the decoherent
histories approach to quantum theory relevant for this thesis. More
extensive discussions can be found Refs. [ 30 , 31 , 37 , 85 , 41 , 22 ]
.

Alternatives at fixed moments of time in quantum theory are represented
by a set of projection operators @xmath , satisfying the conditions

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      (30)
     @xmath   @xmath   @xmath      (31)
  -- -------- -------- -------- -- ------

where we take @xmath to run over some finite range. In the decoherent
histories approach to quantum theory histories are represented by class
operators @xmath which are time-ordered strings of projections,

  -- -------- -- ------
     @xmath      (32)
  -- -------- -- ------

or sums of such strings ⁴ ⁴ 4 The proper framework in which expressions
such as Eq.( 32 ) are to be understood is the temporal logic framework
of Isham and coworkers [ 65 ] . Note also that class operators may be
defined involving an infinite number of times, provided appropriate care
is taken over the definition of the infinite products involved [ 66 ] .
[ 65 ] . Here the projections are in the Heisenberg picture and @xmath
denotes the string @xmath . All class operators satisfy the condition

  -- -------- -- ------
     @xmath      (33)
  -- -------- -- ------

Note that in the same way that Eqs.( 30 ), ( 31 ) do not define a unique
decomposition of the state of a system at a moment of time, Eqs.( 32 ),
( 33 ) do not define a unique decomposition of the possible set of
histories of the system. It is important to decide upon the set @xmath
to be used at the beginning of the analysis, and to avoid working with
class operators from more than one set ⁵ ⁵ 5 Strictly speaking, one
cannot generate logical contradictions by considering class operators
from more than one set but doing so can nevertheless lead to confusion.
This is similar to the choice of a family of projectors at a single
time, Eq.( 31 ). Consider a single spin- @xmath particle. Suppose one
finds that,

@xmath (34)

where @xmath is the probability that the spin will be measured to be
“up” in the @xmath -direction. One cannot conclude from this that @xmath
for example. In the same way, consider two different decoherent sets of
histories represented by class operators @xmath and @xmath . Now suppose
that using the first set we can conclude that @xmath and using the
second that @xmath . There is no difficulty here. The two sets of
histories provide complimentary , not contradictory descriptions of the
system. Note also that Eq.( 35 ) implies that the probability of a given
history is independent of the set of histories in which it appears, and
so we could never derive the genuinely contradictory result that @xmath
is 1 in one set of histories and 0 in another. [ 38 ] .

Probabilities are assigned to histories via the formula

  -- -------- -- ------
     @xmath      (35)
  -- -------- -- ------

These probabilities are clearly real and positive, however probabilities
assigned in this way do not necessarily obey the probability sum rules,
because of quantum interference. We therefore introduce the decoherence
functional

  -- -------- -- ------
     @xmath      (36)
  -- -------- -- ------

which may be thought of as a measure of interference between pairs of
histories. We require that sets of histories satisfy the condition of
decoherence, which is

  -- -------- -- ------
     @xmath      (37)
  -- -------- -- ------

Decoherence implies the weaker condition of consistency, which is that

  -- -------- -- ------
     @xmath      (38)
  -- -------- -- ------

and this is equivalent to the requirement that the above probabilities
satisfy the probability sum rules. In most situations of physical
interest both the real and imaginary parts of @xmath vanish for @xmath ,
and so we shall require Eq.( 37 ) throughout this thesis. This condition
is related to the existence of records [ 31 , 43 ] . Decoherence is only
approximate in general which raises the question of how to measure
approximate decoherence. The decoherence functional satisfies the
inequality [ 22 ]

  -- -------- -- ------
     @xmath      (39)
  -- -------- -- ------

This suggests that a sensible measure of approximate decoherence is

  -- -------- -- ------
     @xmath      (40)
  -- -------- -- ------

We note briefly that when there is decoherence Eq.( 33 ) and Eq.( 37 )
together imply that the probabilities @xmath are given by the simpler
expressions

  -- -------- -- ------
     @xmath      (41)
  -- -------- -- ------

Decoherence ensures that @xmath is real and positive, even though it is
not in general.

A few comments are in order about the place of decoherent histories in
the foundations of quantum theory. Although some early workers tried to
present decoherent histories as an “interpretation” of quantum theory,
see in particular [ 37 , 85 ] , the more modern view is rather that the
histories approach is a valuable tool in understanding how to apply
quantum theory to closed systems, but not an “interpretation” in the
usual sense. The histories approach does not try to explain the
contextual, non-local nature of quantum theory in the way that, for
example, the de Broglie-Bohm approach does, nor does it try to introduce
new physics to solve the problems inherent in the quantum description of
measurement, in the way that collapse theories do. Rather the histories
approach is one in which there is no contridiction between the essential
quantum nature of reality and the existence of a classical realm of our
experience. The histories approach sees classical physics, together with
classical logic, as emergent from the true quantum description of our
world. One can of course carry out any particular measurement at any
time and thereby obtain information about the properties of a system at
one or more times, however the histories approach gives the conditions
under which one may reason classically with these properties. In
particular, if a set of histories satisfies the condition of
decoherence, then one may treat the system as if ⁶ ⁶ 6 Whist again we
stress that it is beyond the scope of this thesis to enter into a
detailed discussion of the philosophical underpinnings of quantum
mechanics in general and the decoherent histories approach in
particular, the choice of words is important here. Claiming that it is
consistent to act as if a system possesses one of a number of properties
is not the same as claiming that it really does possess them. it
possesses the properties associated with these histories, regardless of
whether one carries out a measurement to check this or not.

For more details of the way in which decoherent histories may be thought
of as an “interpretation” of quantum theory see [ 38 , 39 ] .

### 6 The Decoherent Histories Approach to the Arrival Time Problem:
Introduction and History

Now that we have introduced the general framework of decoherent
histories, we turn to the question of applying it to the specific case
of time observables. The aim is to derive the correct class operators
for questions such as “Did the particle cross the origin in the interval
@xmath ?” Since the solution to this problem is the subject of Chapter 5
of this thesis, we will not present the correct class operators here,
but rather we will discuss in general terms how they may be defined.
This is partly to motivate the use of the histories approach, since it
will quickly become apparent that time observables are easily framed in
this language. We also wish, however, to discuss the history of the
decoherent histories approach to the arrival time problem and in
particular some of the misleading results that have been obtained in the
past by considering class operators defined via path integrals. We will
see that the reason for these previous misunderstandings was a lack of
appreciation of the role of the Zeno effect in the definition of class
operators for time observables and it is a major goal of this thesis to
correct these issues.

Let us begin with the general issue of defining class operators for
entering some region of spacetime @xmath . Some early papers on the
decoherent histories approach gave the following analysis of the problem
[ 59 , 72 , 54 , 97 , 98 ] . Consider the propagator between two general
spacetime points, considered as a path integral. Partition the set of
paths summed over according to whether they ever enter the region @xmath
or not,

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (42)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

where @xmath denotes the sum over all paths that enter @xmath , and
@xmath denotes the sum over all paths that do not enter @xmath . Here
@xmath is the restricted propagator, defined as a sum over all paths
which never enter the region @xmath . The path integral over paths that
do enter @xmath would appear to be the class operator we are looking
for. We may therefore define the class operators for entering and not
entering @xmath as,

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      (43)
     @xmath   @xmath   @xmath      (44)
  -- -------- -------- -------- -- ------

These definitions were used by earlier worker on decoherent histories,
in particular in the series of papers by Yamada and Takagi [ 98 ] .

However there is a problem with these definitions, which is that they
suffer from the Zeno effect. To see why this is the case consider the
specific example of the arrival time problem. Let @xmath denote the
projection onto the positive @xmath -axis. The restricted propagator in
this case may be written as,

  -- -------- -- ------
     @xmath      (45)
  -- -------- -- ------

so is unitary in the Hilbert space of states with support only in @xmath
[ 95 , 27 ] . Compare Eq.( 45 ) with Eq.( 8 ).

Differently put, an incoming wave packet evolving according to the
restricted propagator undergoes total reflection, so never crosses
@xmath . This means the probability of not crossing the origin is 1,
whatever the initial state. In the work of Yamada and Takagi [ 98 ] and
also in later work by Wallden [ 95 ] this manifests itself as the
inability to assign probabilities to anything other than states
symmetric about the origin, for which the arrival probabilities vanish.
Clearly these results are unphysical.

A moment’s reflection reveals that this result is not that suprising. We
are demanding that the class operator for not crossing is a sum over
paths that spend exactly zero time in @xmath . Our intuition would
suggest that this restriction is too sharp and that we should instead
sum over all paths spending a time less than some time @xmath in @xmath
.

These heuristic notions are very difficult to make precise in the path
integral formulation of decoherent histories however. Instead, it is
more helpful to attempt to define @xmath in the manner of Eq.( 32 ). A
natural starting point is

  -- -------- -- ------
     @xmath      (46)
  -- -------- -- ------

where there are @xmath projectors and @xmath . We recover the restricted
propagator if we take the limit @xmath , compare Eq.( 46 ) with Eq.( 7
). In light of this, one idea is to simply decline to take the limit
@xmath and define the class operator for not crossing to be Eq.( 46 )
for some @xmath . Clearly if @xmath is large enough the system will be
monitored sufficiently infrequently to let the wave packet cross @xmath
without too much reflection. Eq.( 46 ) is an important expression for
the rest of this thesis, however as it stands this proposal is somewhat
vague. It is a major goal of this thesis to turn this heuristic proposal
into a concrete way of defining class operators. The key question
concerns the timescale @xmath . These issues will form the subject of
Chapter 4.

A second option is to take the limit of @xmath in Eq.( 46 ), but
“soften” the projections to POVMs, that is, to replace @xmath with a
function which is approximately @xmath for large positive @xmath ,
approximately @xmath for large negative @xmath , and with a smooth
transition in between. Although we have introduced the decoherent
histories approach to quantum theory in Section 5 above in terms of
projection operators, the discussion is readily generalised to include
POVMs ⁷ ⁷ 7 The reason we have not discussed POVMs is the following.
Consider two distinct histories, @xmath , defined by strings of
projection operators. Now turn the projection operators into POVMs by
smearing them with a gaussian of finite width and call these new
histories @xmath . These smeared histories are no longer distinct and so
even if @xmath we will have @xmath . This makes it very hard to decide
between histories that interfere, and histories that simply overlap. .
It would be interesting to pursue this idea, but we shall not do so in
this thesis ⁸ ⁸ 8 In fact in some ways we do exactly this in later
sections, since the complex potential introduced in Chapters 4 and 5 is
very much like a POVM. Our motivation for introducing it there is rather
different, however. .

### 7 Summary and Overview of the Rest of This Thesis

The major goal of this thesis is to give a decoherent histories analysis
of the arrival time problem, that will point to the way to a description
of general time observables in quantum theory. We wish firstly to know
what the correct quantum analogues of Eqs.( 16 ), ( 17 ) are, and how
they may be obtained from first principles. We also wish to understand
how the semiclassical result, Eq.( 20 ), emerges in some limit from this
quantum result.

The key question concerns the definition of the appropriate class
operators for these observables. In Section 5 we saw that the Zeno
effect limits the usefulness of the path integral definitions of the
class operators, so our challenge is to work with class operators
defined in the manner of Eq.( 46 ). These class operators represent
evolution in the presence of pulsed measurements. One of the major
achievements of this thesis will come in Chapter 4, where we will show
that such evolution is, under appropriate conditions, equivalent to
evolution under continuous measurement in the form of a complex step
potential. Before we can do this we will need some results about
propagation in the presence of these step potentials and Chapters 2 and
3 will be devoted to explaining the necessary path integral methods.

Complex potentials also arise in other standard approaches to the
arrival time problem in classical and quantum mechanics. These
potentials are generally of the form @xmath , where @xmath is the
characteristic function of some region of configuration space. If we are
to work with these complex potentials we must be able to deal with the
propagator between two arbitary points in configuration space in the
presence of these simple complex potentials. In Chapter 2 we introduce
the Path Decomposition Expansion (PDX), a useful technique for
evaluating path integrals with piecewise defined potentials. In Chapter
\thechapter we then use this technique to evaluate the propagator for
the step and Dirac delta function potentials. As well as introducing the
full expression for the PDX, which is exact, we also introduce a useful
semi-classical approximation, valid when the height of the potential is
small compared with the energy of the incoming state.

In Chapter 4 we ask the following question: Are the schemes of pulsed
and continuous measurement, represented by complex potentials and
strings of projection operators respectively, in any sense equivalent?
We will find that the two approaches are indeed related, in the sense
that the propagators for evolution under the two measurement schemes are
equivalent under certain conditions.

In Chapter 5 of this thesis we use the results of Chapters 2, 3 and 4 to
attack the arrival time problem. Once we have proven that evolutions
under pulsed and continuous measurements are equivalent we use this to
replace the class operator, Eq.( 46 ) with evolution in the presence of
a complex potential. In Chapter 5 this will allow us to undertake a
thorough examination of the arrival time problem and to obtain the
arrival time distribution @xmath .

However, despite the apparent complexity of the approach, the final
results will be remarkably simple and will suggest that there may be a
less rigorous but more intuitive way to arrive at them. In Chapter 6 we
will therefore present a simplified derivation of the class operators
for the arrival time problem, using only a semiclassical approximation.
We will also show how these class operators may be extended in a
straightforward way to situations where there are states incident on the
origin with both positive and negative momenta.

With the main goal of this thesis achieved, in Chapters 7 and 8 we turn
to some related questions that lie somewhat outside the main scope of
this work. In Chapter 7 we look at arrival times for open quantum
systems, trying to understand the way in which the current, Eq.( 20 ),
emerges as the classical arrival time distribution, both in general
terms, and by extending the decoherent histories analysis to this
situation. In Chapter 8 we turn to the issue of arrival and dwell times
defined via ideal clocks, finding agreement with the decoherent
histories analysis in the appropriate limit, but also achieving an
understanding of the emergence of the current as the correct arrival
time distribution for a very general class of model clocks.

We summarize the results of this thesis in Chapter 9, and outline some
possible areas for further study.

## Chapter \thechapter The Path Decomposition Expansion (PDX)

  There is surely no greater wisdom than to mark well the beginnings and
  endings of things.

  Francis Bacon, Essays 1625, Of Delays

### 8 Introduction

In this chapter we describe some useful path integral techniques. We
will make frequent use of the results in this chapter throughout the
rest of this thesis. Since this chapter is essentially technical
background, the majority of the material presented here is not original
research. In Section 2.2 we introduce the Path Decomposition Expansion,
then in Section 2.3 we use this to compute the scattering states for a
complex step potential. In Section 2.4 we then introduce a useful
semiclassical approximation, valid when the height of the potential is
small compared with the energy of the incoming state.

### 9 The Path Decomposition Expansion (PDX)

In this section we introduce the Path Decomposition Expansion (PDX), a
useful technique for evaluating path integrals with piecewise defined
potentials. Although for the most part the application of these results
will be to the simple situation where we have a particle incoming on an
imaginary potential of step function form, in this chapter we will deal
with real potentials and we will begin by assuming the more general form
@xmath .

We wish to evaluate the propagator

  -- -------- -- ------
     @xmath      (47)
  -- -------- -- ------

for arbitrary @xmath and @xmath . This may be calculated using a sum
over paths,

  -- -------- -- ------
     @xmath      (48)
  -- -------- -- ------

where

  -- -------- -- ------
     @xmath      (49)
  -- -------- -- ------

and the sum is over all paths @xmath from @xmath to @xmath .

To deal with the step function form of the potential we need to split
off the sections of the paths lying entirely in @xmath or @xmath . The
way to do this is to use the path decomposition expansion or PDX [ 8 , 9
, 48 , 42 ] . Consider first paths from @xmath to @xmath . A typical
such path may cross @xmath many times, but the set of paths may be
partitioned by their first or last crossing times. We therefore split
every path into three parts: (A) a restricted part that starts at @xmath
and does not cross @xmath , but that ends on @xmath at time @xmath , (B)
an unrestricted part from @xmath to @xmath that may cross @xmath many
times and, (C) a further restricted part from @xmath to @xmath that does
not re-cross @xmath , Fig.( 3 ). As a consequence of this, it is
possible to derive the formula,

  -- -------- -- ------
     @xmath      (50)
  -- -------- -- ------

Here, @xmath is the restricted propagator given by a sum over paths of
the form ( 48 ) but with all paths restricted to @xmath . It vanishes
when either end point is the origin but its derivative at @xmath is
non-zero (and in fact the derivative of @xmath corresponds to a sum over
all paths in @xmath which end on @xmath [ 48 ] ).

It is also useful to record a PDX formula involving the last crossing
time @xmath , for @xmath and @xmath ,

  -- -------- -- ------
     @xmath      (51)
  -- -------- -- ------

These two formulae may be combined to give a first and last crossing
version of the PDX,

  -- -------- -- ------
     @xmath      (52)
  -- -------- -- ------

This is clearly very useful for a step potential since the propagator is
decomposed in terms of propagation in @xmath and in @xmath , essentially
reducing the problem to that of computing the propagator along @xmath ,
@xmath . (See Figure 3 )

For paths with @xmath and @xmath , Eq.( 50 ) is modified by the addition
of a term @xmath , corresponding to a sum over paths which never cross
@xmath , so we have

  -- -------- -- ------
     @xmath      (53)
  -- -------- -- ------

Again a further decomposition involving the last crossing, as in Eq.( 52
) can also be included. In general the usefulness of these expressions
relies on the various partial propagators that occur in the PDX formulae
being easier to compute than the full propagator. This depends crucially
on the form of the potential, from now on we will assume that @xmath in
the above expressions, and thus that the potential is of simple step
function form.

The various elements of these expressions are easily calculated for a
potential of simple step function form @xmath . The restricted
propagator in @xmath is given by the method of images expression

  -- -------- -- ------
     @xmath      (54)
  -- -------- -- ------

where @xmath denotes the free particle propagator

  -- -------- -- ------
     @xmath      (55)
  -- -------- -- ------

It follows that

  -- -------- -- ------
     @xmath      (56)
  -- -------- -- ------

The restricted propagator in @xmath is given by an expression similar to
Eq.( 54 ), multiplied by @xmath .

Note that this means that Eqs.( 50 ), ( 51 ) and ( 52 ) can be written
as,

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (57)
              @xmath   @xmath            (59)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- ------

where @xmath and @xmath denotes a position eigenstate @xmath at @xmath .
These operator forms of the PDX are the ones we shall use most often.

The only complicated propagator to calculate is the propagation from the
origin to itself along the edge of the potential. We will show in the
next chapter that in the case @xmath this is given by [ 99 ] ,

  -- -------- -- ------
     @xmath      (60)
  -- -------- -- ------

However as well as allowing us to obtain exact results for the
propagator in certain cases, the PDX also suggests some semiclassical
approximations we could make to simplify calculation for a more general
class of potentials. We will discuss this in Section 11 .

### 10 Using the PDX: Scattering States for a Complex Step Potential

In this Section we use the PDX to derive the standard representations of
the scattering solutions to the Schrödinger equation with the simple
complex potential @xmath . These are known results but this derivation
confirms the validity of the PDX method and also allows a certain
heuristic path integral approximation to be tested. The results will
also be useful for the decoherent histories analysis in Chapter 5.

The transmitted and reflected wave functions are defined by

  -- -------- -- ------
     @xmath      (61)
  -- -------- -- ------

Here, @xmath is the transmitted wave function and is given by the
propagation of the initial state @xmath using the PDX formulae Eq.( 50 )
or Eq.( 52 ). For large @xmath , a freely evolving packet moves entirely
into @xmath so that the free part, @xmath is zero, leaving just the
transmitted and reflected parts. Following the above definition, the
transmitted wave function is given by

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (62)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

where @xmath denotes the position eigenstate @xmath at @xmath . Also, we
have introduced @xmath and @xmath , and @xmath is the total Hamiltonian.
The scattering wave functions concern the regime of large @xmath , so we
let the upper limit of the integration ranges extend to @xmath .

Writing the initial state as a sum of momentum states @xmath , and
introducing @xmath , we have

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (63)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

To evaluate the @xmath integral, we use the formula [ 92 ] ,

  -- -------- -- ------
     @xmath      (64)
  -- -------- -- ------

from which it follows by differentiation with respect to @xmath and
setting @xmath that

  -- -------- -- ------
     @xmath      (65)
  -- -------- -- ------

The @xmath integral may be evaluated using the explicit expression for
the propagator along the edge of the potential, Eq.( 60 ), together with
the formula,

  -- -------- -- ------
     @xmath      (66)
  -- -------- -- ------

We thus obtain the result,

  -- -------- -- ------
     @xmath      (67)
  -- -------- -- ------

where

  -- -------- -- ------
     @xmath      (68)
  -- -------- -- ------

Note that in this final result, it is possible to identify the specific
effects of the different sections of propagation: the propagation along
the edge of the potential corresponds to the coefficient in the
transmission amplitude Eq.( 68 ) (which is equal to @xmath when @xmath
), and the propagation from final crossing to the final point produces
the @xmath dependence of the exponent. These observations will be useful
below.

The reflected wave function @xmath is defined above using the PDX Eq.(
53 ) (rewritten using Eq.( 52 ). The first term in Eq.( 53 ), the
crossing part, is the same as the transmitted case, Eq.( 63 ), except
that @xmath in the last segment of propagation, from @xmath to the final
point, and also the sign of @xmath is reversed. We must also add the
effects of the reflection part of the restricted propagator, and this
simply subtracts the reflection of the incoming wave packet. The
reflected wave function is therefore given by,

  -- -------- -- ------
     @xmath      (69)
  -- -------- -- ------

where

  -- -------- -------- -------- -------- ------
     @xmath   @xmath   @xmath            (70)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- ------

We thus see that the PDX very readily gives the standard stationary wave
functions [ 6 ] , without having to use the usual (somewhat cumbersome)
technique of matching eigenfunctions at @xmath . In fact, this procedure
is in some sense already encoded in the PDX.

### 11 A Semiclassical Approximation

In this section we discuss a useful semiclassical approximation that
allows us to obtain the approximate propagator for evolution under
simple step potentials of the form @xmath for @xmath real or imaginary,
under the condition that @xmath is small compared with the energy of the
system.

Pictorially, the PDX equation Eq.( 52 ) says that propagation from
@xmath to @xmath may be considered in three parts, initial propagation
to @xmath , propagation along @xmath and propagation away from @xmath ,
see Fig.( 3 ). Classically however, assuming we can neglect reflection,
we expect the propagator to be dominated by the single classical path.
This path is a simple straight line that crosses @xmath only once. One
might therefore expect that the propagator for the final segment from
@xmath to @xmath in Eq.( 50 ) is given approximately by

  -- -------- -- ------
     @xmath      (71)
  -- -------- -- ------

and similarly that,

  -- -------- -- ------
     @xmath      (72)
  -- -------- -- ------

It is not entirely clear that this is the case, however. On the one
hand, the usual semiclassical approximation indicates that paths close
to the straight line paths dominate, but on the other hand, paths in
@xmath are suppressed, so maybe the wiggly paths that spend less time in
@xmath make a significant contribution. Since this approximation is
potentially a useful one, it is useful to compare with the exact result
for the transmitted wave packet calculated above.

We therefore evaluate the following approximate expression for the
transmitted wave function,

  -- -------- -- ------
     @xmath      (73)
  -- -------- -- ------

This is the PDX, Eq.( 50 ), in operator form with the semiclassical
approximation described above and we have set @xmath . We now take
@xmath in the integration and evaluate. The key integral is,

  -- -------- -- ------
     @xmath      (74)
  -- -------- -- ------

where we have used Eq.( 64 ) (and recall that @xmath ). The resulting
expression for the transmitted wave function is of the form Eq.( 67 ),
with

  -- -------- -- ------
     @xmath      (75)
  -- -------- -- ------

This agrees with the exact expression for the transmission coefficient
Eq.( 68 ) only when @xmath , with the difference of order @xmath for
small @xmath . This establishes that the approximation is valid for
@xmath much less than the energy scale of the initial state.

Crucial to the usefulness of this approximation, however, is that the
form of the transmitted wavefunction is reproduced exactly, the
discrepancy being in the prefactor. In the situations where we make use
of this semiclassical approximation we are always assuming refection may
be neglected, and thus the prefactor is in fact irrelevant, since it can
be obtained by normalization. This makes this semiclassical
approximation a very useful one.

We make some brief comments here about the significance of the
semiclassical approximation in the arrival time problem. The classical
phase space distribution representing the current,

  -- -------- -- ------
     @xmath      (76)
  -- -------- -- ------

does not have a unique quantisation, because of the ambiguity in the
operator ordering of @xmath and @xmath . The standard Schrödinger
current comes from the symmetric choice

  -- -------- -- ------
     @xmath      (77)
  -- -------- -- ------

Now in the PDX one can write the propagator from a point @xmath to a
point @xmath in either of the forms

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      (78)
              @xmath   @xmath      (79)
  -- -------- -------- -------- -- ------

These two integrals are equal, but the integrands are not. They differ
in in terms of whether it is the incoming or outgoing paths which are
restricted. However the semiclassical approximation says that the
integrands, thought of as path integrals, are dominated by paths which
cross only once and are therefore in effect “restricted” on both sides.
This means we have,

  -- -------- --
     @xmath   
  -- -------- --

Because the times and positions are arbitrary this approximation means
that there is essentially no difference between the terms @xmath and
@xmath . This means the semiclassically any result obtained by using the
first crossing PDX, say, could equally well be obtained using the last
crossing formula.

## Chapter \thechapter The Propagator for the Step and Delta Function
Potentials, using the PDX

  The journey of a thousand miles begins with one step.

  Lao Tzu

### 12 Introduction

One of the standard approaches to defining the time of entry to a given
region of configuration space in quantum theory is to introduce a
complex potential localised in the region of interest, and to define the
arrival time probabilities in terms of the rate at which the
wavefunction is absorbed by the potential [ 6 ] . In the simplest case
of the arrival time problem in 1D this means using a complex potential
of the form @xmath . If we are to extract the arrival time probability
from this set up we must be able to solve for the propagator in the
presence of simple complex potentials. In fact, close inspection reveals
that the propagator for a particle in the presence of a complex
potential can generally be obtained by first considering the equivalent
real potential, and then analytically continuing the result. This means
our task is to consider propagators for a particle in the presence of a
real step potential. Delta function potentials may be used in a similar
way.

Calculations involving step and delta function potentials also occur in
many other branches of physics. Step potentials can be used to represent
“hard wall” boundary conditions, and are also involved in tunneling
calculations. Delta function potentials can be used to model point
interactions, especially in the low energy limit where the details of
the process are largely independent of the form of the scattering
potential [ 5 ] .

We wish to compute the following propagator,

  -- -------- -- ------
     @xmath      (80)
  -- -------- -- ------

where

  -- -------- -- ------
     @xmath      (81)
  -- -------- -- ------

and the potential @xmath is either a step potential @xmath , or a delta
function potential, @xmath .

In this Chapter we present a derivation of the propagators in the
vicinity of these potentials by making use of the path decomposition
expansion presented in the previous chapter. The problem of calculating
the full propagator therefore reduces to that of calculating the partial
propagator for the interval where the path crosses the origin, @xmath .
We will show how these partial propagators may be derived using the
Brownian motion definition of the path integral [ 57 , 89 ] . The full
propagators may then be obtained with the help of Eq.( 52 ).

For the step potential the full propagator has been derived in Refs. [
15 , 11 , 16 , 17 ] , but we shall derive the partial propagator, and
then direct the reader to Ref. [ 15 ] for details of the use of the path
decomposition expansion to recover the full propagator. The partial
propagator we will derive is given by

  -- -------- -- ------
     @xmath      (82)
  -- -------- -- ------

This result was used in Chapter 2 to compute the scattering states for a
complex step potential.

For the delta function potential we will derive the full propagator and
we quote the result from Ref. [ 28 ]

  -- -------- -- ------
     @xmath      (83)
  -- -------- -- ------

where

  -- -------- -- ------
     @xmath      (84)
  -- -------- -- ------

is the free propagator. This chapter is based on Ref. [ 99 ] .

### 13 The Brownian Motion Definition of the Propagator

We begin with a review of some of the details of the Brownian motion
approach to computing propagators. For more details see Refs. [ 57 , 89
] . The first step is to switch to working with the Euclidean propagator
@xmath by means of a Wick rotation and we specialise immediately to the
case of @xmath . That is, we wish to calculate

  -- -------- -- ------
     @xmath      (85)
  -- -------- -- ------

where @xmath is the Euclidean action given by

  -- -------- -- ------
     @xmath      (86)
  -- -------- -- ------

This propagator may be viewed as a conditional probability density for a
random walk on the real line. The second step is then to make this
integral over paths into a concrete object by defining it as the
continuum limit of a discrete sum on a lattice.

To establish conventions and demonstrate the basic ideas we compute the
case of a free particle, following closely the treatment in Ref. [ 57 ]
. We consider a rectangular lattice with spacing in the time direction
of @xmath , spacing in the @xmath direction of @xmath and we consider
propagation for a time @xmath , so we have @xmath steps in our paths
(the reason for this choice is that it simplifies a number of later
expressions, and avoids clumsy factors of 1/2). The conditional
probability @xmath to start at (0,0) and end at (0,T) is given by the
number of paths connecting the start and end points, divided by the
total number of possible paths. The set of paths from @xmath to @xmath
is bounded by the extremal paths that take @xmath steps to the
left/right, followed by @xmath steps to the right/left, see Fig.( 4 ).
Since a path must have the same number of steps to the right as to the
left to end up back at @xmath we find,

  -- -------- -- ------
     @xmath      (87)
  -- -------- -- ------

The Euclidean propagator @xmath is then defined as the continuum limit
of @xmath where we take @xmath , @xmath , keeping @xmath and @xmath
fixed. That is,

  -- -------- -- ------
     @xmath      (88)
  -- -------- -- ------

which is the expected result for the Euclidean free propagator.

### 14 The Step Potential

The propagator along the edge of a step potential is given by Eqs.( 85 )
and ( 86 ), with @xmath . We can write this as

  -- -------- -- ------
     @xmath      (89)
  -- -------- -- ------

which is similar to the free particle case except that paths are
weighted by a factor @xmath where

  -- -------- -- ------
     @xmath      (90)
  -- -------- -- ------

is the length of time spent in @xmath . In the lattice case the
corresponding conditional probability @xmath is given by a sum of paths,
each weighted by a similar factor. This may be written as

  -- -------- -- ------
     @xmath      (91)
  -- -------- -- ------

where @xmath is the number of paths spending a time @xmath in the region
@xmath . Expresions for these @xmath are known and are in fact
independent of @xmath [ 70 ] . They are equal to the Catalan numbers

  -- -------- -- ------
     @xmath      (92)
  -- -------- -- ------

where @xmath is the total number of time steps. We can see this as
follows. First, note that the number of paths that never enter @xmath is
given by @xmath , this being one definition of the Catalan numbers. Next
consider the following mapping on any path spending a time @xmath in
@xmath , Fig.( 5 ).

1.  Start from t=0, and follow the path until it first crosses @xmath
    (if it doesn’t cross then stop, the path is in the set of
    non-crossing paths.)

2.  Follow the path until it comes back to @xmath again, note the step
    at which this happens.

3.  Swap the section of path before this step with the section after it.

4.  The new path will now spend 2 fewer time steps in @xmath .

By repeated application of this mapping, any path can be transformed
into one which never crosses @xmath . The important point about this
mapping however, is that it is bijective [ 70 ] , which proves that the
number of paths spending time @xmath in @xmath must equal the number of
paths that never cross, for any value of @xmath . This shows that @xmath
for all @xmath .

So we now have

  -- -------- -------- -------- -- ------
     @xmath   @xmath   @xmath      (93)
              @xmath   @xmath      (94)
  -- -------- -------- -------- -- ------

This coincides with the free particle case if @xmath . Since we plan to
take the continuum limit we can Taylor expand the exponential in the
denominator to first order in @xmath , and use the following useful
assymptotic form for @xmath [ 70 ]

  -- -------- --
     @xmath   
  -- -------- --

to get,

  -- -------- --
     @xmath   
  -- -------- --

Now take the continuum limit as in Section 3.2 to obtain, after some
simple algebra,

  -- -------- -- ------
     @xmath      (95)
  -- -------- -- ------

which implies

  -- -------- -- ------
     @xmath      (96)
  -- -------- -- ------

This is our first result, the propagator along the edge of a step
potential. The full propagator from @xmath to @xmath may now be obtained
by making use of Eq.( 52 ) [ 15 ] . Note also that this result may be
analytically continued in a simple way to imaginary potentials.

### 15 The Delta Function Potential

We now wish to evaluate Eqs.( 85 ) and ( 86 ) with the potential given
by @xmath . In a similar way as for the step potential, we can write
this as,

  -- -------- -- ------
     @xmath      (97)
  -- -------- -- ------

which is again similar to the free particle case except that paths are
weighted by a factor @xmath where

  -- -------- -- ------
     @xmath      (98)
  -- -------- -- ------

is the number of times a given path crosses @xmath . We model the delta
function as a square potential of width @xmath , and height @xmath so
that every crossing of @xmath is weighted by a factor of @xmath . Since
@xmath , we can rewrite this as @xmath . We take the potential to be
located on the left of @xmath so that to start and end at @xmath
involves an even number of crossings. Such choices are only made for
convenience and have no significance in the continuum limit. The
conditional probability density @xmath may be partitioned in a similar
way to that for the step potential. However now the partitioning is with
respect to the number of times a path crosses the square potential.
Since the number of crossings will always be even we partition into
classes of paths that cross @xmath times, so the conditional probability
is

  -- -------- -- ------
     @xmath      (99)
  -- -------- -- ------

Where @xmath is the number of paths of @xmath steps that cross the delta
potential @xmath times. It is known that these @xmath are given by the
@xmath convolution of the Catalan numbers [ 96 ] , this can be
demonstrated by writing a general path in terms of sums over
non-crossing paths. These convolutions form the diagonal elements in
Catalan’s triangle [ 96 , 86 , 94 ] . We need to know the @xmath element
in the @xmath diagonal from the right, which will give us @xmath .

From the formula for the elements of Catalan’s triangle [ 96 ] ,

  -- -------- -- -------
     @xmath      (100)
  -- -------- -- -------

it follows that

  -- -------- -- -------
     @xmath      (101)
  -- -------- -- -------

where we have extracted the binomial factor for later convenience. We
cannot perform the summation in Eq.( 99 ) directly as we did for the
step function potential, so we take the continuum limit first to leave
ourselves with an integral. In order to do this we need a simpler form
for the @xmath ’s. We need the asymptotic form for @xmath , but plotting
Eq.( 101 ) as a function of @xmath shows that the dominant contribution
comes from taking @xmath as well. It is possible to derive the following
asymptotic form,

  -- -------- -- -------
     @xmath      (102)
  -- -------- -- -------

and as this form shows, the maximum value of @xmath occurs when @xmath
is of order @xmath . This is a consequence of the Brownian motion origin
of the paths, which therefore have Hausdorff dimension 2 [ 1 ] . The
statement that a typical path crosses the origin an infinite number of
times is a consequence of this fractal nature of a typical path.

If we use the asymptotic form for the @xmath ’s, Eq. ( 102 ) and make
the change of variable in the partitioning, Eq. ( 99 ), @xmath we can
turn the summation into an integral,

  -- -------- -- -------
     @xmath      (103)
  -- -------- -- -------

We now take the continuum limit as in Section 3.2 to obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (104)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

which, after rotating back to real time, yields

  -- -------- -- -------
     @xmath      (105)
  -- -------- -- -------

We can now use the path decompsition expansion to obtain the propagator
for paths which start at @xmath and end at @xmath . There are 4 cases,
depending on the signs of @xmath and @xmath , we shall present one case
here, the others follow in a very similar fashion. First note that PDX
formulae in Chapter 2 tell us that the free propagator obeys the
following,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (106)
              @xmath   @xmath      (107)
  -- -------- -------- -------- -- -------

provided @xmath . (where @xmath denotes the free propagator, and @xmath
is the signum function.) (If the start and end points have the same sign
then there are paths between the two that never cross @xmath , so the
expression for the path decomposition expansion has to be modified as in
Eq.( 53 ) [ 48 ] .)

Secondly note the following identities,

  -- -------- -- -------
     @xmath      (108)
  -- -------- -- -------

which are just expressions of the symmetry of the free propagator.

Consider the case where @xmath and @xmath , noting that @xmath we first
use Eq. ( 106 ) to attach the leg from @xmath ,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (109)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where we have used Eq. ( 108 ) to obtain the second line. Since @xmath
we have that @xmath , so we can attach a leg to @xmath using Eq.( 107 ),

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (110)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

as expected. Calculation in the other cases proceeds in a very similar
manner, and confirms that Eq.( 110 ) is valid in all cases.

## Chapter \thechapter On the Relationship between Complex Potentials
and Strings of Projection Operators

  Time’s a strange fellow;
  more he gives than takes
  (and he takes all)nor any marvel finds
  quite disappearance but some keener makes
  losing,gaining
  -love!if a world ends
  more than all worlds begin to(see?)begin

  E.E. Cummings

### 16 Introduction

In Chapter 1 we argued that in decoherent histories the class operator
describing histories which remain in some region defined by a projector
@xmath is given by @xmath , where,

  -- -------- -- -------
     @xmath      (111)
  -- -------- -- -------

(Here, there are @xmath projection operators and @xmath and we use units
in which @xmath ). Such an object also describes the evolution of an
initial states under pulsed measurements.

We are interested in the specific case of a free particle with @xmath
taken to be the projection onto the positive @xmath -axis, @xmath . For
sufficiently small @xmath , Eq.( 111 ) is then a candidate for the
amplitude to remain in @xmath during the time interval @xmath . In this
Chapter we examine the object in Eq.( 111 ) without particular reference
to it’s relavence in the arrival time problem. Our aim will be to show
that evolution under Eq.( 111 ) is equivalent to evolution under a
particular form of continuous measurement. We will then use this result
in Chapter 5 to address the arrival time problem.

It is of interest to explore the properties of this Eq.( 111 ) for a
range of values of the time spacing @xmath . It is known that as @xmath
, we approach the Zeno limit, in which the state becomes entirely
confined to the Hilbert subspace of states with support only in @xmath ,
so that an incoming wave packet from the right is totally reflected [ 74
, 95 , 27 ] . However, it is of greater physical interest to explore the
regime of non-zero @xmath , in which the system is monitored
sufficiently well to get some idea of whether the particle is in @xmath
, yet not monitored so much that an incoming state is significantly
reflected at @xmath . An important question in this regime is to
determine the value of @xmath for which reflection becomes significant.
For an initial state with energy width @xmath , a timescale held to be
significant is the Zeno time,

  -- -------- -- -------
     @xmath      (112)
  -- -------- -- -------

which is the timescale on which the state becomes significantly
different from its initial value under unitary evolution [ 87 ] . For a
wave packet of momentum @xmath and spatial width @xmath , the Zeno time
is of order @xmath which is the timescale on which the wave packet
crosses the origin. This indicates that the Zeno time for wave packets
is an essentially classical timescale and, in Eq.( 111 ), relates only
to the rate of removal of probability through projection. By contrast,
reflection in Eq.( 111 ) arises as a result of the increase in
uncertainty in momentum resulting from position projection, an obviously
quantum process, so one would expect it to have a different timescale,
which could be much shorter than then Zeno time. It would be of interest
to compute this timescale. One reason it is important is that there
appears to be interesting physics very close to the Zeno limit [ 23 , 82
, 45 ] .

A significant result in this area is due to Echanobe, del Campo and
Muga, who claimed that for finite @xmath the string of projection
operators in Eq.( 111 ) is approximately equivalent to evolution in the
presence of a complex potential [ 23 ] . That is,

  -- -------- -- -------
     @xmath      (113)
  -- -------- -- -------

They assert that this result is valid if, for a given @xmath , @xmath is
chosen such that two conditions

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (114)
     @xmath   @xmath   @xmath      (115)
  -- -------- -------- -------- -- -------

are satisfied. This is a very useful result since Eq.( 111 ) is not easy
to evaluate analytically but the Schrödinger equation with a complex
step potential in Eq.( 113 ) can be solved straightforwardly.
Furthermore, such complex potentials have been studied extensively in
the literature and can often be linked to particular detection methods [
76 ] .

Given the connection Eq.( 113 ), one can determine the conditions under
which reflection becomes important. Known results on scattering with the
complex potential in Eq.( 113 ) show that, for an incoming state with
energy scale @xmath , reflection becomes significant when @xmath [ 6 ,
49 ] . Reflection is avoided, therefore, when @xmath , or equivalently,
from Eq.( 114 ), when

  -- -------- -- -------
     @xmath      (116)
  -- -------- -- -------

This is much less than the Zeno time for a state strongly peaked in
energy. There is therefore an interesting regime, namely

  -- -------- -- -------
     @xmath      (117)
  -- -------- -- -------

in which the projections in Eq.( 111 ) are sufficiently frequent to have
a significant effect on the system, yet not so frequent that there is
significant reflection.

Eq.( 116 ) is a very useful result, but it has been derived on the basis
of the claimed approximate relationship Eq.( 113 ). The derivation of
Eq.( 113 ) given by Echanobe et al is very plausible (and was also
hinted at by Allcock [ 6 ] ), but it is rather heuristic, and the
deduced connection Eq.( 114 ) between @xmath and @xmath is rather loose.
There is therefore considerable scope for a more detailed and
substantial derivation.

The purpose of this chapter is to give a more substantial derivation of
the equivalence Eq.( 113 ) and to deduce a more precise relationship
between @xmath and @xmath . We will do this by computing the
configuration space propagators associated with each side of Eq.( 113 )
and show that they are approximately equal in certain regimes. The
propagator associated with the complex potential is in fact known
already, so the bulk of the work consists of an approximate evaluation
of the propagator associated with pulsed measurements, the left-hand
side of Eq.( 113 ).

This is certainly not a rigorous mathematical proof of Eq.( 113 ),
involving operator norms, error bounds and the like, but a theoretical
physicists style of proof involving the approximate evaluation of
propagators. A rigorous proof would certainly be of interest to
construct and the work described in this chapter may give some hints in
that direction.

We begin in Section 17 with a brief summary of the derivation of
Echanobe et al, with a small extension of it that turns out to be
important and yields an equality relating @xmath and @xmath , thereby
improving on Eq.( 114 ). We then in Section 4.3 give a detailed
formulation of the problem and how we solve it. The key idea is to use
the path decomposition expansion in which the propagators associated
with each side of Eq.( 113 ) are factored across the surface @xmath [ 8
, 9 , 48 , 42 ] . The problem of proving the equivalence Eq.( 113 )
thereby reduces to proving it for propagation between points at @xmath
for different times. Since the propagator for the complex potential is
known, the main work is to evaluate this propagator for pulsed
measurements. This is actually rather difficult to do directly, but a
good approximate analytic expression can be obtained for it by attacking
the problem from a number of different angles. This is described in
Sections 4.4, 4.5, 4.6 and 4.7. In Section 4.8 we give a detailed
discussion of the timescales involved for the approximations to be
valid. We summarize and conclude in Section 4.9. This chapter is based
on Ref. [ 51 ] .

### 17 Review and Extension of Earlier Work

We first review and extend the derivation of Echanobe et al [ 23 ] .
They first note that

  -- -------- -- -------
     @xmath      (118)
  -- -------- -- -------

where, recall, @xmath and @xmath . It follows that

  -- -------- -- -------
     @xmath      (119)
  -- -------- -- -------

as long as the parameter

  -- -------- -- -------
     @xmath      (120)
  -- -------- -- -------

is sufficiently large that

  -- -------- -- -------
     @xmath      (121)
  -- -------- -- -------

Eq.( 113 ) then follows from the approximate equivalence,

  -- -------- -- -------
     @xmath      (122)
  -- -------- -- -------

which will hold as long as

  -- -------- -- -------
     @xmath      (123)
  -- -------- -- -------

where the average is taken in the initial state. Echanobe et al put an
upper bound on the left-hand side using the Schrödinger-Robertson
inequality and Eq.( 123 ) may then be written in either of the two
equivalent forms

  -- -------- -- -------
     @xmath      (124)
  -- -------- -- -------

or

  -- -------- -- -------
     @xmath      (125)
  -- -------- -- -------

which implies that the time between projections is much less than the
Zeno time, the typical timescale on which the state undergoes
significant change [ 87 ] . (The conditions Eqs.( 120 ), ( 121 ), ( 124
) are a more precise version of the originally stated conditions Eqs.(
114 ), ( 115 )).

Since the parameter @xmath need only satisfy an inequality , Eq.( 121 ),
the relationship Eq.( 120 ) between @xmath and @xmath is not uniquely
determined. However, it turns out that the above derivation can be
extended somewhat to give an equality between @xmath and @xmath . This
turns out to be relevant to the more substantial derivation given in the
rest of this chapter.

The above result may be written,

  -- -------- -- -------
     @xmath      (126)
  -- -------- -- -------

under the conditions given above. Now suppose @xmath is an integer and
write @xmath , where

  -- -------- -- -------
     @xmath      (127)
  -- -------- -- -------

Then, since @xmath , we may approximate Eq.( 126 ) by

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (128)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

as long as the contribution from the commutator terms between @xmath and
@xmath is sufficiently small. There will be of order @xmath such terms,
hence the error in this approximation is of order @xmath and from Eq.(
124 ), this error is much less than @xmath . The key point here is that
even the longer timescale @xmath is still much less than the Zeno time
and, since nothing changes on this timescale, there is essentially no
difference between Eqs.( 126 ) and ( 128 ).

We therefore see that the desired result Eq.( 113 ) actually holds for
much smaller time steps, defined by the equality Eq.( 127 ). This is
different to the original claim of Echanobe et al, since they require
the inequality Eq.( 114 ). However, the above argument shows that the
restriction Eq.( 114 ) is in fact stronger than necessary and in the
following pages our more detailed derivation will show that Eq.( 113 )
does indeed hold with a timespacing of order @xmath .

### 18 Detailed Formulation of the Problem

In this chapter, we will prove the relationship Eq.( 113 ) in a much
more substantial way by proving the approximate equivalence of the
propagators

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (129)
     @xmath   @xmath   @xmath      (130)
  -- -------- -------- -------- -- -------

for some relationship between the parameters @xmath and @xmath , to be
determined. Note that in Eq.( 130 ), we have chosen the initial and
final time spacings to be @xmath and @xmath , with

  -- -------- -- -------
     @xmath      (131)
  -- -------- -- -------

This turns out to be necessary for the most general proof of Eq.( 113 ).
For the special case @xmath , we may also write

  -- -------- -- -------
     @xmath      (132)
  -- -------- -- -------

Each of the above propagators may be represented by a path integral,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (133)
     @xmath   @xmath   @xmath      (134)
  -- -------- -------- -------- -- -------

where in both cases the paths are from @xmath to @xmath and in the
second case, Eq.( 134 ), @xmath denotes that the paths are restricted to
be in the positive @xmath -axis at times @xmath , @xmath .

A closely related object that will be important is the restricted
propagator,

  -- -------- -- -------
     @xmath      (135)
  -- -------- -- -------

where again the paths are from @xmath to @xmath but with @xmath for all
times in @xmath . This is clearly equivalent to @xmath in Eq.( 134 ), in
the limit @xmath , @xmath with @xmath constant. If we take the same
limit in the equivalent expression for @xmath , Eq.( 130 ), one obtains
the following convenient operator form of the restricted propagator:

  -- -------- -- -------
     @xmath      (136)
  -- -------- -- -------

The restricted propagator satisfies the Schrödinger equation in @xmath
subject to the boundary conditions that it vanishes when either end of
the propagator sits on @xmath . For the free particle, considered here,
one can easily solve for the restricted propagator using the method of
images and the result is

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (137)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

The restricted propagator, in any of the above forms, describes the
regime of “Zeno dynamics”, in which all states are confined entirely to
the Hilbert subspace of states with support only in @xmath [ 27 ] .

The restricted propagator plays an important role here since not only
does @xmath in the limit @xmath , @xmath with @xmath constant, but also
@xmath as @xmath . It follows that @xmath and @xmath become arbitrarily
close to each other for sufficiently large @xmath and @xmath , since
they both tend to the same limit. This is the underlying reason why we
expect the approximate equivalence Eq.( 113 ) should hold.

The propagators @xmath and @xmath may be decomposed using the path
decomposition expansion (PDX), which we discussed in detail in Chapter
2. There are two cases to consider.

We consider first the case in which the initial and final points are on
the same side of the surface in @xmath . Recall from Chapter 2 that the
corresponding PDX has the form

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (138)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

This is depicted in Figure 6 .

Eq.( 138 ) holds for both @xmath and @xmath , but the restricted part
@xmath is the same in each case and equal to Eq.( 137 ) above, since the
restriction on paths defining @xmath and the presence of the complex
potential in @xmath in Eqs.( 133 ), ( 134 ) are both redundant if @xmath
.

It follows from the above that @xmath and @xmath could differ only in
terms of their propagation along @xmath , hence to prove the approximate
equivalence of the propagators Eqs.( 129 ), ( 130 ), we need to prove
that

  -- -------- -- -------
     @xmath      (139)
  -- -------- -- -------

Note that, unlike @xmath , @xmath is not covariant under time
translation, that is,

  -- -------- -- -------
     @xmath      (140)
  -- -------- -- -------

although it has an approximate covariance on timescales much greater
than @xmath , as we will see below.

The second case is that in which the initial and final points are on
opposite sides of the surface, @xmath and @xmath . In this case we have
for @xmath ,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (141)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

since the last section of the paths is in @xmath where the complex
potential acts. For @xmath , if @xmath , since the paths must be in
@xmath at the given discrete set of times, the last crossing time @xmath
cannot be less than the last time @xmath at which the projectors act,
hence

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (142)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Again we will have to prove that Eq.( 139 ) holds, but these two
expressions Eqs.( 141 ), ( 142 ) also differ in the form of the @xmath
integral. However, since @xmath , the form of the exponential in Eq.(
141 ) effectively squeezes @xmath to lie approximately within @xmath of
@xmath , so we have

  -- -------- -- -------
     @xmath      (143)
  -- -------- -- -------

and Eqs.( 141 ) and ( 142 ) are approximately the same.

We see that both cases reduce to proving Eq.( 139 ). In Chapter 3 we
showed that the propagator along the boundary of the complex potential
is given by,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (144)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

The main purpose of the remainder of this chapter is to calculate the
propagator with projection operators along the boundary,

  -- -------- -- -------
     @xmath      (145)
  -- -------- -- -------

and show that the approximation Eq.( 139 ) holds, under conditions to be
determined. (Here, @xmath denotes a position eigenstate @xmath at @xmath
).

In what follows, our main result is to show that, to a good
approximation,

  -- -------- -- -------
     @xmath      (146)
  -- -------- -- -------

where @xmath is a kind of saw-tooth function – a piecewise linear
function with peaks immediately followed by troughs at @xmath , @xmath .
Approaching @xmath from below, there is a peak of value

  -- -------- -- -------
     @xmath      (147)
  -- -------- -- -------

and approaching @xmath from above there is a trough of half that size.
That is

  -- -------- -- -------
     @xmath      (148)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (149)
  -- -------- -- -------

The functions @xmath and @xmath are shown in Figure 7 . We see that
@xmath oscillates with period @xmath about @xmath , as long as we choose
@xmath so that @xmath lies between the peaks and troughs of @xmath .
That is, for large @xmath , we require that

  -- -------- -- -------
     @xmath      (150)
  -- -------- -- -------

Since @xmath , @xmath will lie approximately midway between the peaks
and troughs of @xmath if

  -- -------- -- -------
     @xmath      (151)
  -- -------- -- -------

Recalling that the propagator is attached through the PDX Eq.( 138 ) to
an initial state, the oscillations, and hence the differences between
@xmath and @xmath , will be smoothed out as long as @xmath is chosen to
be smaller than the timescale of variation of the initial state. With
some qualifications (discussed further in Section 4.8), this timescale
is the Zeno time, @xmath . The desired approximation Eq.( 139 ) will
therefore hold in a time-averaged sense, and we thus have significant
agreement with the extended version of the original argument of Echanobe
et al described in Section 4.2.

In the following sections, we evaluate Eq.( 145 ) and confirm the form
Eq.( 148 ) of @xmath . In Section 4.4 we evaluate Eq.( 145 ) exactly for
the cases of one, two and three projections. We also show why in general
the troughs of @xmath are exactly half the size of the peaks by
considering the limit @xmath of Eq.( 145 ). In Section 4.5 we use a
lattice method to derive the magnitude of the peaks of @xmath for large
@xmath . These results are substantiated in Section 4.6, where we use an
S-matrix expansion to derive some exact results for a certain
time-averaged version of Eq.( 145 ). In Section 4.7, we fill in some of
the gaps in these regimes and approximations by computing Eq.( 145 )
using numerical methods.

We will find in the numerical and analytic solutions that the function
interpolating between the troughs and peaks of @xmath is not in fact a
linear function in general. It is interesting however, that, because of
the slow time variation of the initial state in comparison to @xmath ,
the precise form of this function turns out to be unimportant, and this
is what makes the problem more tractable than one might expect. All that
is important is the location of the peaks and troughs of the saw-tooth
function and the period of their oscillation. It is this separation of
timescales that also restores an approximate time translation covariance
to @xmath , even though it does not hold exactly in general, Eq.( 140 ).

### 19 Exact Analytic Results

In this section we carry out an exact evaluation of Eq.( 145 ) for the
case of one, two and three projections. For simplicity, we take the
initial time interval @xmath to be @xmath and for the case of three
projections we are able to carry out the calculation only in when the
final time @xmath . We thus compute the objects

  -- -------- -- -------
     @xmath      (152)
  -- -------- -- -------

We will show that

  -- -------- -- -------
     @xmath      (153)
  -- -------- -- -------

thereby confirming the approximate form of the saw-tooth function, Eq.(
148 ), for the first few projections. These expressions all have the
property that the value of @xmath drops to half its value immediately
after a projection and we show why this is true in general at the end of
this section.

To compute Eq.( 152 ) it turns out to be useful to consider more general
objects, in which the projections may be @xmath , @xmath or the
identity. We therefore consider the object

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (154)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Here @xmath symbolically stands for the integration ranges of the @xmath
, eg @xmath means @xmath etc. Performing a Wick rotation, @xmath and
changing variables yields

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
                                   
              @xmath   @xmath      (156)
  -- -------- -------- -------- -- -------

The cases of no projection and one projection are trivially evaluated,
and we easily obtain the first two equations in Eq.( 153 ). For the case
of two projections, we need to evaluate the object

  -- -------- -- -------
     @xmath      (157)
  -- -------- -- -------

(a slight generalization of the @xmath defined in Eq.( 156 )). Changing
variables to @xmath , @xmath gives,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (158)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Where @xmath , @xmath , @xmath . Now use the change of variables,

  -- -------- -- -------
     @xmath      (159)
  -- -------- -- -------

to obtain

  -- -------- -- -------
     @xmath      (160)
  -- -------- -- -------

Noting that @xmath , and using the standard integral [ 36 ]

  -- -------- -- -------
     @xmath      (161)
  -- -------- -- -------

we find finally

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (162)
  -- -------- -------- -------- -- -------

Setting @xmath and @xmath it follows that

  -- -------- -- -------
     @xmath      (163)
  -- -------- -- -------

for @xmath , so we confirm the third equation in Eq.( 153 ).

It will be useful for the three projection case below to record the
following related results. A similar analysis to that above yields

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (164)
                                @xmath   
  -- -------- -------- -------- -------- -------

In particular we then have

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (165)
     @xmath   @xmath   @xmath      (166)
     @xmath   @xmath   @xmath      (167)
  -- -------- -------- -------- -- -------

We are able to evaluate the three projection case only in the situation
where all time intervals are equal, so we set @xmath in the definition
of @xmath in Eq.( 156 ). In this case, @xmath possesses a number of
helpful symmetries. The first is “reflection” symmetry: if we define
@xmath by the string obtained by letting @xmath then

  -- -------- -- -------
     @xmath      (168)
  -- -------- -- -------

The second symmetry is “time reversal”: if we define @xmath by the
string obtained by reversing the order of @xmath , then we have

  -- -------- -- -------
     @xmath      (169)
  -- -------- -- -------

In addition we have the simple property that

  -- -------- -- -------
     @xmath      (170)
  -- -------- -- -------

These properties imply the following for the three projection case. On
the one hand we have,

  -- -------- -- -------
     @xmath      (171)
  -- -------- -- -------

but we also have,

  -- -------- -- -------
     @xmath      (172)
  -- -------- -- -------

Combining these expressions gives,

  -- -------- -- -------
     @xmath      (173)
  -- -------- -- -------

For each of the objects on the right, we may carry out the full range
integral, to leave ourselves with an object of the form @xmath computed
above. For example we have that @xmath . Each of these objects may then
be evaluated using Eq.( 162 ) and Eq.( 164 ), and combined to give,

  -- -------- -- -------
     @xmath      (174)
  -- -------- -- -------

It follows that

  -- -------- -- -------
     @xmath      (175)
  -- -------- -- -------

when @xmath , thus confirming the fourth equation in Eq.( 153 ).

To end this section, we confirm our claim in Section 4.3 that the
function @xmath drops to half its value immediately after a projection.
On the face of it, this involves interpreting the expression @xmath
which is ambiguous, so must be defined by a limiting procedure (where,
recall @xmath denotes @xmath at @xmath ). We thus consider the limit
@xmath in the expression

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (176)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We seek to show that the result obtained by this limit is half the
result obtained when the final projection is absent. We write

  -- -------- -- -------
     @xmath      (177)
  -- -------- -- -------

so that

  -- -------- -- -------
     @xmath      (178)
  -- -------- -- -------

The first term on the right-hand side yields the sought after factor of
a half as @xmath , so it remains to show that the second term is zero.
We have

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (179)
  -- -------- -------- -------- -- -------

where we have used the fact that

  -- -------- -- -------
     @xmath      (180)
  -- -------- -- -------

(for the free particle, considered here). As @xmath , @xmath and the
pair of terms in brackets on the right-hand side cancel in Eq.( 179 ),
so we obtain zero as required.

### 20 Asymptotic Limit

We now consider the asymptotic evaluation of @xmath for large @xmath in
the case @xmath . This will give the values of the peaks of @xmath ,
Eq.( 147 ).

Recall that in the limit @xmath and @xmath with @xmath fixed, @xmath
tends to the restricted propagator @xmath . To obtain the asymptotic
form of @xmath for large @xmath we therefore need to determine the
lowest non-trivial correction to this result. It is clear from the
definition Eq.( 130 ) of @xmath that, close to the limit, we have the
general form

  -- -------- -- -------
     @xmath      (181)
  -- -------- -- -------

for some function @xmath . Since the restricted propagator vanishes if
either @xmath or @xmath , the object we need to calculate is

  -- -------- -- -------
     @xmath      (182)
  -- -------- -- -------

A standard and convenient way to do this is to rotate to imaginary time
@xmath (we use tilde to denote Euclideanized time) and then write @xmath
as a Euclidean path integral. This is then defined in terms of the
continuum limit of probabilities of random walks on a space time lattice
of temporal spacing @xmath and spatial spacing @xmath . The details of
this construction are very conveniently given by Hartle [ 59 ] so we
will give only the briefest account here. Using this language, @xmath is
then the continuum limit of the object @xmath , where @xmath is the
probability for a random walk on the lattice starting at the origin and
ending at the origin at time @xmath , with the restriction that the
walker is in the positive @xmath -axis at the intermediate times @xmath
(where @xmath ).

The calculation of @xmath defined in this way, for values of @xmath
generally greater than the lattice spacing @xmath , is in fact a known
problem in combinatorics called the tennis ball problem. It appears to
have a formal solution, but this solution is too implicit for us to
extract a useful result [ 73 ] .

Fortunately, however, for the purposes of calculating the limit Eq.( 182
) the results of Ref. [ 59 ] are sufficient. For this case, we set
@xmath and @xmath is then the probability for a random walk from the
origin to itself, with the restriction that the walker is in the
positive @xmath -axis at every intermediate step. On a finite lattice
Hartle’s calculations give the result,

  -- -------- -- -------
     @xmath      (183)
  -- -------- -- -------

to leading order for small @xmath , @xmath [ 59 ] . We may use this
result to compute the limit Eq.( 182 ), which, continued back to real
time, is

  -- -------- -- -------
     @xmath      (184)
  -- -------- -- -------

Through Eq.( 181 ), this confirms Eq.( 147 ) for large @xmath .

### 21 A Time Averaged Result

We have argued that at the peak values of @xmath with @xmath
projections, we have the approximate result

  -- -------- -- -------
     @xmath      (185)
  -- -------- -- -------

We showed above that this is exact for @xmath and true asymptotically
for large @xmath . Some interesting exact results for any @xmath may be
obtained by considering a more general version of this object in which
the projections are not restricted to act at the given set of times,
@xmath .

On the one hand, Eq.( 144 ) may be expanded as a power series in powers
of @xmath :

  -- -------- -- -------
     @xmath      (186)
  -- -------- -- -------

On the other hand, the evolution operator with complex potential may be
expanded in the usual S-matrix expansion,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (187)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where @xmath denotes time ordering, @xmath and @xmath . It follows that

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (188)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Equating powers of @xmath in Eqs.( 186 ) and ( 188 ) and writing out the
time ordering explicitly, we deduce that

  -- -------- -- -------
     @xmath      (189)
  -- -------- -- -------

We would like to write this in a form involving @xmath , instead of
@xmath . We introduce the reflection operator

  -- -------- -- -------
     @xmath      (190)
  -- -------- -- -------

and note that @xmath , the Hamiltonian @xmath commutes with @xmath , and
@xmath (where, recall, @xmath denotes @xmath at @xmath ). It follows
that

  -- -------- -- -------
     @xmath      (191)
  -- -------- -- -------

so that Eq.( 189 ) holds with all the @xmath ’s replaced with @xmath ’s.
Noting that

  -- -------- -- -------
     @xmath      (192)
  -- -------- -- -------

we see that Eq.( 189 ) is of the desired general form, Eq.( 185 ), but
time-averaged over the times of the projections.

The question is now to what extent the time-averaged expression on the
left-hand side of Eq.( 189 ) is close to Eq.( 185 ). We may take this
further in two different ways.

First, note that for a real-valued function @xmath of @xmath variables,
we have the mean value theorem

  -- -------- -- -------
     @xmath      (193)
  -- -------- -- -------

for some set of numbers @xmath in the interval @xmath . The integral in
Eq.( 189 ) is easily made into a real integral over a real-valued
function by analytic continuation, and we therefore deduce the exact
result

  -- -------- -- -------
     @xmath      (194)
  -- -------- -- -------

for some set of projection times @xmath in the interval @xmath .

Second, we may expand the integrand in the left-hand side of Eq.( 189 )
about the values @xmath , to get some insight into why these particular
values have any special significance. We have

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (195)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Inserting in Eq.( 189 ), and noting that

  -- -------- -- -------
     @xmath      (196)
  -- -------- -- -------

(where, recall, @xmath ) we see the first order term in the expansion
Eq.( 195 ) averages to zero in Eq.( 189 ). This is clearly only true for
expansion about the special values @xmath . We therefore obtain the
desired result Eq.( 185 ) up to second order corrections. This suggests
that the values @xmath are significant because they give the best
approximation to the average in Eq.( 189 ). These results give evidence
that Eq.( 147 ) holds approximately for all @xmath , including the
intermediate values not covered in the previous two sections.

### 22 Numerical Results

To support the analytic results described in the previous sections we
evaluate Eq.( 145 ) numerically for up to @xmath projections and confirm
the conjectured form Eq.( 146 ), ( 148 ). It is convenient to define a
sequence of functions @xmath defined by

  -- -------- -- -------
     @xmath      (197)
  -- -------- -- -------

for @xmath and

  -- -------- -- -------
     @xmath      (198)
  -- -------- -- -------

for @xmath where @xmath . The desired object Eq.( 145 ) (with, for
convenience, @xmath ), is then given by

  -- -------- -- -------
     @xmath      (199)
  -- -------- -- -------

The sequence @xmath may be calculated using the recursion relation,

  -- -------- -- -------
     @xmath      (200)
  -- -------- -- -------

Using a new time coordinate @xmath defined by @xmath , rotating to
imaginary time, and defining @xmath , we have

  -- -------- -- -------
     @xmath      (201)
  -- -------- -- -------

for @xmath .

We have attempted to find an approximate analytic solution to Eq.( 201 )
for large @xmath , but without success. However, a numerical solution is
straightforward and yields all the information we require. This was done
using a simple mid-point rule. The lattice size was chosen to be of
order @xmath , and the results were checked for robustness against
changes in lattice size.

The numerical result for @xmath (defined in Eq.( 146 ) in terms of
@xmath ) is plotted in Figure 8 , along with our claimed approximate
analytic expression for @xmath , Eq.( 148 ). We see that there is
excellent agreement. The values at the peaks and troughs appear to agree
perfectly. The only small discrepancy is that the interpolating
functions between the peaks and troughs are not exactly linear. This
discrepancy is only noticeable for intermediate values of @xmath and in
any event since, as argued, the curve is effectively averaged over time
in the PDX, this discrepancy is insignificant. We therefore find
substantial numerical confirmation for our our main result, Eqs.( 146 ),
( 148 ).

The apparently perfect agreement of numerical results with the
approximate analytic expression Eq.( 148 ) at the peaks and troughs is
striking. We wonder if the approximate analytic expression is in fact
exact at these points, but we have not been able to prove this, except
for the cases @xmath and for large @xmath .

A useful way of seeing even more precisely the relationship between
@xmath and @xmath is to define the function

  -- -------- -- -------
     @xmath      (202)
  -- -------- -- -------

so that

  -- -------- -- -------
     @xmath      (203)
  -- -------- -- -------

This is plotted in Figure 9 . It is a simple function oscillating around
zero between @xmath with period @xmath . In terms of @xmath , the
relationship between @xmath and @xmath then has the particularly simple
form

  -- -------- -- -------
     @xmath      (204)
  -- -------- -- -------

This relationship is perhaps the most concise summary of the
sought-after connection between the propagators.

### 23 Timescales

We now give a more detailed explanation as to the timescales involved in
proving the approximate equivalence of @xmath and @xmath . We broadly
expect that the appropriate timescale is the Zeno time of the initial
state, @xmath . However, we have derived a very precise connection
between evolution in the presence of a complex potential and evolution
with projection operators so we are in a position to investigate the
specific way in which an initial state may discriminate between these
two types of evolution.

We have argued that the equivalence boils down to proving the
equivalence of propagation along the boundary, Eq.( 139 ), and we have
shown that @xmath oscillates around @xmath with period @xmath . Suppose
we have an initial state @xmath . Let us consider the change in the wave
function arising from replacing @xmath with @xmath using the PDX, Eq.(
138 ). It is

  -- -------- -- -------
     @xmath      (205)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (206)
  -- -------- -- -------

The important part of this expression is the @xmath integral, which we
expect will be small if the initial state is sufficiently slowly varying
in time.

The results of Section 4.3 and 4.8 show that @xmath oscillates around
zero with period @xmath . In particular, Eq.( 204 ) shows that

  -- -------- -- -------
     @xmath      (207)
  -- -------- -- -------

The explicit form of @xmath is given in Figure 9 , but its important
qualitative feature is its oscillation with period @xmath , so for
simplicity, @xmath may be loosely modelled by the function @xmath . To
be definite we take the initial state @xmath to be a Gaussian wave
packet, so we have

  -- -------- -- -------
     @xmath      (208)
  -- -------- -- -------

where @xmath , @xmath is a normalization factor, and we have ignored
wave packet spreading effects in evolving the state. For such a state
the Zeno time is @xmath . In Eq.( 205 ) the differentiation of @xmath
produces a prefactor which does not contribute to the leading order
evaluation of the time integral, and if the range of integration is much
greater than @xmath , we obtain the order of magnitude result

  -- -------- -- -------
     @xmath      (209)
  -- -------- -- -------

If @xmath , the right-hand side is clearly very small if @xmath . If
@xmath , the right-hand side if bounded from above by @xmath so again
will be small if @xmath . Hence the Zeno time of the initial state is
indeed the timescale controlling the validity of the approximation, as
expected. Note also that Eq.( 209 ) goes to zero as @xmath , as it must,
since @xmath and @xmath become exactly equal (and equal to @xmath ) in
this limit.

The only problematic case is that in which the initial state has energy
@xmath . In this case, the right-hand side of Eq.( 209 ) is not
necessarily small and the approximation may fail. This is not surprising
since it is the case in which the oscillations in time of the incoming
state are comparable to the temporal spacing of the projections, so that
the state can “see” the difference between the complex potential and
projections at a discrete set of times.

Hence, apart from the above exception, Eq.( 139 ) holds for @xmath . As
outlined in the Introduction to this chapter, reflection from the
complex potential is negligible if @xmath which is equivalent to @xmath
. Therefore there is an interesting regime, namely

  -- -------- -- -------
     @xmath      (210)
  -- -------- -- -------

in which the approximate equivalence Eq.( 139 ) holds, yet there is
negligible reflection. This regime is important in, for example, study
of the arrival time problem using complex potentials [ 49 ] , and we
will make use of it in Chapter 5 of this thesis. (See also Ref. [ 92 ]
for an interesting discussion of timescales in the Zeno effect.)

### 24 Summary and Discussion

This chapter was physically motivated by the desire to understand the
effect of periodically acting projections onto the positive @xmath -axis
for a free particle, Eq.( 111 ). A valuable way to proceed is to use the
conjectured relationship Eq.( 113 ) with a complex potential first put
forward by Echanobe et al. This connection, together with known results
on scattering, establishes the timescale under which significant
reflection occurs in Eq.( 111 ). We noted that the arguments for the
relationship Eq.( 113 ) are only heuristic and there is scope for a more
substantial proof.

We proved Eq.( 113 ) by considering the associated propagators Eqs.( 129
), ( 130 ). We noted that an approximate equivalence between these
propagators is expected since both propagators tend to the restricted
propagator @xmath in the limits @xmath , @xmath and @xmath . The path
decomposition expansion reduced the proof of equivalence of these
propagators to the simpler case of propagation between points lying on
the origin, Eq.( 139 ). The propagator along the origin for the complex
potential @xmath is already known, Eq.( 144 ), so the bulk of the proof
was to derive the analogous result for the propagator with projections,
@xmath . Our main result was to prove that this propagator has the
approximate form Eqs.( 146 ), ( 148 ), which we proved using a variety
of analytic and numerical methods. In effect, the main achievement of
this chapter has therefore been to obtain a good approximate analytic
expression for the propagator @xmath that appears in Eq.( 111 ).

We found that @xmath oscillates with period @xmath around @xmath as long
as @xmath , a result most concisely summarized in Eq.( 204 ). The
approximate equivalence Eq.( 139 ) of these propagators then holds in a
time-averaged sense as long as the timescale @xmath between projections
is much smaller than the Zeno time of the initial state, @xmath (but may
fail in the special case when the incoming state is peaked about energy
@xmath ). These conditions agree in essence with those of an extended
version of the results of Echanobe et al, with an advantage over their
results that a definite relationship between @xmath and @xmath is
obtained. We noted that their restriction Eq.( 114 ) relating @xmath and
@xmath is in fact stronger than required and the equality @xmath derived
here gives the best approximate equivalence between @xmath and @xmath .

Let us make some comments here on the possible generality of the
connection Eq.( 113 ). We first note that it may in fact be written

  -- -------- -- -------
     @xmath      (211)
  -- -------- -- -------

where @xmath . We have proved Eq.( 211 ) for the case in which the
projections are onto the positive @xmath -axis, but it seems reasonably
clear that the relationship will hold for projections onto any region
@xmath of the @xmath -axis (as long as it is not too small) and indeed
for regions of configuration space in a many-dimensional model. Such a
potential has been used recently in the decoherent histories analysis of
quantum cosmological models [ 47 ] . Moreover, although the proof of
Eq.( 211 ) given in this chapter relied heavily on the fact that @xmath
projects onto position, the form Eq.( 211 ) and the heuristic argument
for it in Section 4.2 do not rely on the particular form of @xmath . We
therefore conjecture that Eq.( 211 ) may hold for a wider variety of
projection operators, not just projectors onto position. This will be
pursued elsewhere.

Finally we note that the left hand side of Eq.( 211 ) is a class
operator in the decoherent histories (DH) approach to quantum theory
outlined in Chapter 1. The equivalence expressed in Eq.( 211 ) means we
can also use the right hand side as a class operator. The practical
value of this is that it opens the way to dealing with time observables
in DH by replacing strings of projectors, which may be hard to work
with, with complex potentials which are much simpler. However on a more
fundamental level, it also suggest new ways to construct class operators
which would not have been obvious starting from the exposition in
Chapter 1. We will pursue this in the next chapter.

## Chapter \thechapter Arrival Times, Complex Potentials and Decoherent
Histories

  Tomorrow, and tomorrow, and tomorrow, Creeps in this petty pace from
  day to day

  Shakespeare

### 25 Introduction

We saw in the Introduction, Chapter 1, that there are many different
approaches to the arrival time problem in quantum theory, (see Fig.( 10
) for a recap of conventions).

The approach we wish to pursue in the next two chapters is based on the
decoherent histories approach to quantum theory, as outlined in Sections
4 and 5 . We saw in Section 5 that the key objects for this analysis are
the class operators for crossing and not crossing the origin during a
given time interval. The class operator for not crossing was determined
to be,

  -- -------- -- -------
     @xmath      (212)
  -- -------- -- -------

where @xmath , there are @xmath projections and @xmath . In order to
avoid the Zeno effect we need to leave @xmath finite. However in Section
5 we concluded that this object was somewhat problematic, firstly
because we could not determine the required timescale @xmath , and
secondly because this object is difficult to work with analytically.

However, armed now with the results of Chapter 4 we are able to make
progress. The results of Chapter 4 tell us that evolution with the class
operator above, Eq.( 212 ), is equivalent to evolution in the presence
of a complex potential,

  -- -------- -- -------
     @xmath      (213)
  -- -------- -- -------

where @xmath , @xmath and @xmath . Eq.( 213 ) holds provided

  -- -------- -- -------
     @xmath      (214)
  -- -------- -- -------

This means we can compute the probabilities and the decoherence
functional by replacing class operators of the form Eq.( 212 ) with
evolution under the complex potential, and this simplifies the
calculations enormously. The equivalence in Eq.( 213 ) also tells us
that we must have @xmath , where @xmath is the energy of the incoming
state, if we are to avoid reflection.

Of course the results of Chapter 4 as they stand only give us the class
operator for not crossing during a given time interval. We also require
the class operator for crossing. We shall compute this in this chapter,
as well as calculating the probabilities and decoherence functional for
questions such as, “Did the particle cross during the time interval
@xmath ?” Our end result will be a complete analysis of the arrival time
problem in the language of decoherent histories. Before we do this,
however, it is useful to explore some aspects of the arrival time
distribution defined using complex potentials. This will help us to
understand the key features of our final result.

The first aim of this chapter is to look in some detail at the
calculation and properties of the arrival time distribution defined
using a complex potential. In particular, we will use path integral
methods, which in some ways are more concise and transparent than
previous derivations. The second aim of this chapter is to carry out a
decoherent histories analysis of the arrival time problem, using the
equivalence between strings of projection operators and complex
potentials demonstrated in Chapter \thechapter .

Our main result is that for intervals of size @xmath , these class
operators are given approximately by

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (215)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Significantly, the dependence on the complex potential has dropped out
entirely. We will show that there is decoherence for an interesting
class of states, and, for such states the probabilities are then given
by

  -- -------- -- -------
     @xmath      (216)
  -- -------- -- -------

This, we will show, coincides with the expected result Eq.( 8 ), when
@xmath is integrated over a range of time much greater than @xmath .
Hence there is complete agreement with standard results on the arrival
time distribution at sufficiently coarse-grained timescales.
Furthermore, our results shed some light on the problem of backflow – we
find that the situations when Eq.( 216 ) is negative are those in which
there is no decoherence in which case probabilities cannot be assigned.

In the next Chapter, we compute the crossing class operators in a
simpler but more heuristic way, by exploring a semiclassical
approximation to Eq.( 212 ) keeping @xmath finite. The results are
essentially the same.

The rest of this Chapter is arranged as follows: In Section 26 we
consider the classical arrival time defined via a complex potential.
This well help us understand how the probabilities we obtain depend on
the choice of @xmath , or equivalently @xmath , in Eq.( 213 ). In
Section 27 we then repeat this analysis for the quantum case, using the
PDX to calculate the arrival time distribution function. We make heavy
use in this section of the results of Chapter 2. In Sections 28 and 29 ,
we use the results of the previous sections to carry out the decoherent
histories analysis. We summarize and conclude in Section 30 . This
chapter is based on Ref. [ 49 ] .

### 26 The Classical Arrival Time Problem via a Complex Potential

Before looking at the quantum arrival time problem it is enlightening to
look at the corresponding classical arrival time problem defined using
an absorbing potential. This gives some understanding of the expected
form of the result in the quantum case. In particular since the complex
potential is a simple measurement model we expect the probabilities
obtained in this way to be of the form Eq.( 27 ), which include an
“apparatus response function.” We will see in this section that exactly
the same thing happens in the classical case, and in fact the response
functions are the same in the quantum and classical cases. This means
the complex potential is acting like a classical measuring device, and
all dependence on it can be removed by coarse-graining, in the manner of
Eq.( 28 ).

We consider a classical phase space distribution @xmath , with initial
value @xmath concentrated entirely in @xmath with only negative momenta.
This distribution evolves in the presence of a complex potential @xmath
. The equation of motion is,

  -- -------- -- -------
     @xmath      (217)
  -- -------- -- -------

This form may be deduced, for example, by computing the evolution
equation of the Wigner function with this complex potential and dropping
the higher order terms (involving powers of @xmath ). Eq.( 217 ) is
readily solved and has solution

  -- -------- -- -------
     @xmath      (218)
  -- -------- -- -------

The survival probability, that is the probability of not having been
absorbed by the complex potential by a time @xmath , is

  -- -------- -- -------
     @xmath      (219)
  -- -------- -- -------

The arrival time distribution is therefore

  -- -------- -- -------
     @xmath      (220)
  -- -------- -- -------

where we have made use of Eq.( 217 ). This expression is conveniently
rewritten by noting that, again using Eq.( 217 ), @xmath obeys the
equation

  -- -------- -- -------
     @xmath      (221)
  -- -------- -- -------

This may be solved to yield

  -- -------- -- -------
     @xmath      (222)
  -- -------- -- -------

From Eq.( 218 ), we see that

  -- -------- -- -------
     @xmath      (223)
  -- -------- -- -------

but since the momenta are all negative the exponential factor makes no
contribution. We thus obtain

  -- -------- -- -------
     @xmath      (224)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (225)
  -- -------- -- -------

The current @xmath is the usual classical arrival time distribution that
we would have expected in the absence of the absorbing potential.

Eq.( 224 ) has the same form as the expressions for the quantum arrival
time we expect to obtain from a measurement model, Eq.( 27 ). The
response function is given by the quantity,

  -- -------- -- -------
     @xmath      (226)
  -- -------- -- -------

In Chapter 1 we noted that @xmath is related to a sort of coarse
graining in time, we now demonstrate this for this specific case. Eq.(
224 ) gives the probability @xmath for arriving during the infinitesimal
time interval @xmath . Supposer we consider the probability for arriving
during a finite time interval, @xmath . This is given by

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (227)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Rearranging the order of integration and integrating over @xmath yields,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (229)
                                @xmath   
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

@xmath plays a role as a fundamental short timescale in the problem, so
now suppose we assume that @xmath , @xmath and @xmath are all much
greater than @xmath . It follows that all the exponential terms may be
dropped in Eq.( 229 ) and we obtain the very simple result,

  -- -------- -- -------
     @xmath      (230)
  -- -------- -- -------

That is, all dependence on the resolution function @xmath and the
complex potential parameter @xmath completely drops out when we look at
probabilities defined on timescales much greater than @xmath . This
result is very relevant to the decoherent histories analysis considered
later where it is natural to look at the arrival time during a finite
time interval much greater than @xmath .

### 27 Calculation of the Arrival Time Distribution via a Complex
Potential

We now repeat the analysis of the previous section for the quantum case.
The analogue of Eq.( 217 ) is the inclusion of the complex potential,

  -- -------- -- -------
     @xmath      (231)
  -- -------- -- -------

in the Schrödinger equation. With such a potential, the state at time
@xmath is

  -- -------- -- -------
     @xmath      (232)
  -- -------- -- -------

where @xmath is the free Hamiltonian. In a similar way to the classical
case the idea is that the part of the wave packet that reaches the
origin during the time interval @xmath should be absorbed, so that

  -- -------- -- -------
     @xmath      (233)
  -- -------- -- -------

is the probability of not crossing @xmath during the time interval
@xmath . The probability of crossing between @xmath and @xmath is then

  -- -------- -- -------
     @xmath      (234)
  -- -------- -- -------

Complex potentials such as Eq.( 231 ) were originally considered by
Allcock in his seminal work on arrival time [ 6 ] and have subsequently
appeared in detector models [ 44 , 18 ] . (See also Ref. [ 76 , 62 ] for
further work with complex potentials). From the results of Chapter
\thechapter we see that evolution according to Eq.( 232 ) is essentially
the same as evolution under pulsed measurements.

For large @xmath , the wave function defined by the evolution Eq.( 232 )
undergoes significant reflection, with total reflection in the “Zeno
limit”, @xmath [ 74 ] . Here, we are interested in the opposite case of
small @xmath , where there is small reflection and Eq.( 234 ) can give
reasonable expressions for the arrival time distribution. A number of
different authors [ 6 , 18 , 62 ] indicate that the resulting
distribution is of the form

  -- -------- -- -------
     @xmath      (235)
  -- -------- -- -------

where @xmath is the current,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (236)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

and,

  -- -------- -- -------
     @xmath      (237)
  -- -------- -- -------

It is therefore closely related to the current @xmath but also includes
the influence of the complex potential via the “apparatus resolution
function” @xmath . Our aim in this section is to prove this claim.

With the complex potential Eq.( 231 ), the arrival time distribution
Eq.( 234 ) is given by

  -- -------- -- -------
     @xmath      (238)
  -- -------- -- -------

where

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (239)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

(so we use @xmath to denote the total non-Hermitian Hamiltonian). We are
interested in calculating this expression for the case in which @xmath
is much smaller than the energy scale of the initial state. (The very
different limit, of @xmath , the Zeno limit, has been explored elsewhere
[ 45 ] ).

One way to evaluate Eq.( 238 ) is to use the transmitted wave functions,
Eq.( 63 ). However, we give here instead a different and more direct
derivation using the PDX. We use the first crossing PDX, written in
operator form, Eq.( 59 ),

  -- -------- -- -------
     @xmath      (240)
  -- -------- -- -------

Now note that the operator @xmath has the simple property that for any
operator @xmath

  -- -------- -- -------
     @xmath      (241)
  -- -------- -- -------

(where, recall, @xmath denotes the position eigenstate @xmath at @xmath
). Inserting Eq.( 240 ) in Eq.( 238 ), together with the property Eq.(
241 ) and the change of variables @xmath , @xmath , yields

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (242)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We are aiming to show that this coincides with Eq.( 235 ) with the
current Eq.( 236 ), and the main challenge is to show how the @xmath
combination turns into the combination @xmath in the current Eq.( 236 ).

Consider first the @xmath integral. Since we are assuming small @xmath ,
we may use the semiclassical approximation Eq.( 71 ), which reads

  -- -------- -- -------
     @xmath      (243)
  -- -------- -- -------

The @xmath integral may now be carried out, with the result,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (244)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where @xmath denotes the free evolution of the initial state.

We now carry out one of the time integrals. Note that,

  -- -------- -- -------
     @xmath      (245)
  -- -------- -- -------

In the first integral, we set @xmath , @xmath , and in the second
integral we set @xmath , @xmath . We thus obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (246)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

The factors of @xmath in front of each term come from a careful
consideration of the square root in the free propagator prefactor (and
must have this form because @xmath is real).

We will assume that @xmath , which means that the integrals are
concentrated around @xmath . This means that we may take the upper limit
of the @xmath integral to be @xmath , and it may be carried out, to
yield,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (247)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where the operator @xmath is given by

  -- -------- -- -------
     @xmath      (248)
  -- -------- -- -------

For @xmath much less than the energy scale,

  -- -------- -- -------
     @xmath      (249)
  -- -------- -- -------

so @xmath is simply the sign function of the momentum, which is @xmath
in this case, since the initial state consists entirely of negative
momenta. Finally, writing @xmath , we obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (250)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We therefore have precise confirmation of the classical result Eq.( 224
), and also agreement with the expected quantum result, Eq.( 235 ).

Some comments are in order concerning the positivity of the result for
@xmath . The expression ( 247 ) is positive because it was derived from
the manifestly positive expression Eq.( 242 ). (Two approximations were
used: the semiclassical approximation Eq.( 243 ), and the condition
@xmath , neither of which affect the positivity of the result.)

However, to obtain the final result Eq.( 250 ) we took the limit @xmath
in the current part only of Eq.( 247 ), leaving behind the @xmath
-dependent term in the exponential part, and the resulting expression is
not guaranteed to be positive. In Eq.( 250 ), @xmath is not always
positive due to the backflow effect [ 78 , 12 ] and integration over
time does not necessarily remedy the situation. (See the Appendix for a
more thorough discussion of this point). The lack of positivity for a
@xmath obtained in this way is not surprising since taking the limit
@xmath in one part of the expression Eq.( 247 ) only but not the other
will not necessarily preserve its property of positivity. The violation
of positivity is generally small, however, so Eq.( 250 ) may still be a
good approximation to the manifestly positive expression Eq.( 247 ).

It should also be added that it would be misleading to explore the first
order corrections in @xmath in going from Eq.( 247 ) to Eq.( 250 ),
since comparable correction terms have already been dropped in using the
semiclassical approximation Eq.( 243 ).

### 28 Decoherent Histories Analysis for a Single Large Time Interval

We turn now to the decoherent histories analysis of the arrival time
problem. The important question we wish to answer is; What is the
probability of arriving during some general time interval @xmath ? We
answer this question in detail in the next section, here we address a
simpler question; What are the probabilities for crossing or not
crossing during the large time interval @xmath ? The reason for tackling
this question first is that it gives us useful insight into the more
general case and also suggests an interesting way of thinking about the
situations in which we might have decoherence.

The class operators for not crossing and crossing during this time
interval are

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (251)
     @xmath   @xmath   @xmath      (252)
  -- -------- -------- -------- -- -------

and they satisfy

  -- -------- -- -------
     @xmath      (253)
  -- -------- -- -------

We are interested in the probabilities for not crossing and crossing,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (254)
     @xmath   @xmath   @xmath      (255)
  -- -------- -------- -------- -- -------

and the off-diagonal term of the decoherence functional,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (256)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

These quantities obey the relation

  -- -------- -- -------
     @xmath      (257)
  -- -------- -- -------

We look for situations where there is decoherence,

  -- -------- -- -------
     @xmath      (258)
  -- -------- -- -------

(which is usually only approximate), in which case the probabilities
then sum to @xmath ,

  -- -------- -- -------
     @xmath      (259)
  -- -------- -- -------

It is useful to relate some of these expressions to the standard
expressions for arrival time @xmath defined in Eqs.( 233 ), ( 234 ). To
do this, note that @xmath is in fact the same as the survival
probability, @xmath defined in Eq.( 233 ), and that @xmath obeys the
trivial identity

  -- -------- -- -------
     @xmath      (260)
  -- -------- -- -------

since @xmath . It follows that

  -- -------- -- -------
     @xmath      (261)
  -- -------- -- -------

When there is decoherence, Eq.( 259 ) holds and we may deduce that

  -- -------- -- -------
     @xmath      (262)
  -- -------- -- -------

Hence the decoherent histories analysis is compatible with the standard
result, but only when there is decoherence.

We turn now to the calculation of the decoherence functional. Following
the general pattern described in Eqs.( 32 ), ( 33 ), consider the
quantity,

  -- -------- -- -------
     @xmath      (263)
  -- -------- -- -------

From Eq.( 256 ), we see that the decoherence functional may be written,

  -- -------- -- -------
     @xmath      (264)
  -- -------- -- -------

This means that @xmath when there is decoherence. Or to put it the other
way round, decoherence of histories may be checked by comparing @xmath
with @xmath and this is what we now do. Recall that @xmath is given by
Eqs.( 260 ), ( 261 ) (which hold in the absence of decoherence). We may
write @xmath in a similar form:

  -- -------- -- -------
     @xmath      (265)
  -- -------- -- -------

The integrand is similar to @xmath defined in Eq.( 238 ), so we define

  -- -------- -- -------
     @xmath      (266)
  -- -------- -- -------

We now have that

  -- -------- -- -------
     @xmath      (267)
  -- -------- -- -------

It then follows that the decoherence functional is

  -- -------- -- -------
     @xmath      (268)
  -- -------- -- -------

To compute the decoherence functional we need to calculate @xmath ,
which is given by

  -- -------- -- -------
     @xmath      (269)
  -- -------- -- -------

This is almost the same as @xmath except that the exponential on the
left involves only @xmath and not the complex potential (and also an
overall factor of @xmath ). We therefore follow the calculation of
@xmath in Section 5.3 with small modifications. With a little care, one
may see that the final result is the same as that for @xmath , Eq.( 250
), except that @xmath is replaced with @xmath , that is,

  -- -------- -- -------
     @xmath      (270)
  -- -------- -- -------

This result holds for timescales greater than @xmath and under the
semiclassical approximation (which required @xmath so is equivalent to
the requirement of negligible reflection encountered above). Finally, a
calculation similar to that of Eqs.( 227 )-( 230 ) implies that

  -- -------- -- -------
     @xmath      (271)
  -- -------- -- -------

as long as @xmath . Since this result is independent of @xmath , @xmath
will satisfy the same relation. We thus deduce that

  -- -------- -- -------
     @xmath      (272)
  -- -------- -- -------

hence there is decoherence, under the above conditions.

This analysis gives us an interesting way of thinking about decoherence.
Decoherence is achieved if Eq.( 270 ) is equal to Eq.( 250 ). This will
be the case if the current varies on a timescale that is long compared
with @xmath , where @xmath is the energy of the wavepacket. The
timescale on which the current varies is given, for a gaussian
wavepacket, as @xmath . In Chapter 4 we noted that whereas the timescale
given by @xmath is genuinely quantum, @xmath is in fact a classical
timescale. This means we will have decoherence if there is a large
separation between the quantum and classical timescales associated with
the incoming wavepacket, a satisfying result.

### 29 Decoherent Histories Analysis for an Arbitrary Set of Time
Intervals

We now turn to the more complicated question of much more refined
histories, that may cross the origin at any one of a large number of
times, during the time interval @xmath . This corresponds more directly
to the standard crossing probability, @xmath , the probability that the
particle crosses during an infinitesimal time interval @xmath .

#### 29.1 Class Operators

We have defined class operators Eqs.( 251 ), ( 252 ) describing crossing
or not crossing during a time interval @xmath . We now split this time
interval into @xmath equal parts of size @xmath , so @xmath and we seek
class operators describing crossing or not crossing during any one of
the @xmath intervals. We first note that

  -- -------- -- -------
     @xmath      (273)
  -- -------- -- -------

where @xmath and @xmath are defined as in Eqs.( 251 ), ( 252 ) except
that here they are for a time interval @xmath . We now use this to
decompose @xmath into the desired class operators. We have

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (274)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Repeating the same steps on the first term, this yields,

  -- -------- -- -------
     @xmath      (275)
  -- -------- -- -------

Repeating more times eventually yields,

  -- -------- -- -------
     @xmath      (276)
  -- -------- -- -------

From this expression, we see that the class operator for crossing @xmath
for the first time during the time interval @xmath is given by the
summand of the second term,

  -- -------- -- -------
     @xmath      (277)
  -- -------- -- -------

We will not in fact work with the class operator Eq.( 277 ), since a
more useful similar but alternative expression can also be found. Taking
the continuum limit of Eq.( 276 ) (and inserting the explicit expression
for @xmath , we obtain,

  -- -------- -- -------
     @xmath      (278)
  -- -------- -- -------

(where, recall, @xmath ). This indicates that the class operator for
first crossing during the infinitesimal time interval @xmath , is

  -- -------- -- -------
     @xmath      (279)
  -- -------- -- -------

We do not, however, expect histories characterized by such precise
crossing time to be decoherent, so it is natural to consider
coarser-grained class operators,

  -- -------- -- -------
     @xmath      (280)
  -- -------- -- -------

which represents crossing during one of the @xmath time intervals @xmath
of size @xmath , where @xmath with @xmath and @xmath . The complete set
of class operators @xmath for crossing and not crossing is the set of
@xmath operators

  -- -------- -- -------
     @xmath      (281)
  -- -------- -- -------

and Eq.( 278 ) implies that they satisfy

  -- -------- -- -------
     @xmath      (282)
  -- -------- -- -------

To check for decoherence of histories we need to calculate two types of
decoherence functional

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (283)
     @xmath   @xmath   @xmath      (284)
  -- -------- -------- -------- -- -------

and this will be carried out below.

#### 29.2 An Important Simplification of the Class Operator

There turns out to be a very useful simplification in the class operator
Eq.( 279 ). Consider the amplitude

  -- -------- -- -------
     @xmath      (285)
  -- -------- -- -------

for any @xmath . The right-hand side is very similar to Eq.( 238 ),
except that there is no complex potential in one of the exponential
terms and also the “final” state is @xmath not @xmath . (And there is
also an overall factor of @xmath different). Despite these differences,
we may once again make use of the details of the calculation of Section
5.3, and we deduce from the analogous result Eq.( 250 ), that

  -- -------- -- -------
     @xmath      (286)
  -- -------- -- -------

Like the derivation of Eq.( 250 ), this is valid under the conditions
that all energy scales are much greater than @xmath and all time scales
much greater than @xmath . Now we integrate this over time to obtain the
coarse-grained crossing time operator, Eq.( 280 ), and again use
approximations of the form Eqs.( 227 )-( 230 ) (again using the
assumption of timescales much greater than @xmath ), to yield, the
remarkably simple and appealing form,

  -- -------- -- -------
     @xmath      (287)
  -- -------- -- -------

This may also be written even more simply

  -- -------- -- -------
     @xmath      (288)
  -- -------- -- -------

#### 29.3 Probabilities for Crossing

The above expressions for the crossing time class operator are the most
important results of this Chapter and provide an immediate connection to
the standard expression for the arrival time distribution. Supposing for
the moment that there is decoherence of histories, we may assign
probabilities to the histories. The probability for crossing during the
time interval @xmath is

  -- -------- -- -------
     @xmath      (289)
  -- -------- -- -------

However, as noted in Eqs.( 32 ), ( 33 ) when there is decoherence of
histories, this expression for the probabilities for histories is equal
to the simpler expression,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (290)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

which is precisely the standard result! The expression for the
probability @xmath is not positive in general (although is real in this
case, as it happens), but when there is decoherence, it is equal to
@xmath , which is positive. Hence the decoherent histories result
coincides with the standard result under the somewhat special conditions
of decoherence of histories.

#### 29.4 Decoherence of Histories and the Backflow Problem

There is an interesting connection between decoherence of histories and
backflow. To see this, consider the following simple case. We consider
histories which either cross or do not cross the origin during the time
interval @xmath . So the crossing and not crossing class operators are
@xmath and @xmath , where

  -- -------- -- -------
     @xmath      (291)
  -- -------- -- -------

where we have adopted the notation @xmath (and for convenience we have
dropped the exponential factor which is just a matter of definition and
drops out of all expression of interest). The decoherence functional is

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (292)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

This may also be written

  -- -------- -- -------
     @xmath      (293)
  -- -------- -- -------

a form we will use below to check decoherence. When there is
decoherence, @xmath and the probability for crossing is

  -- -------- -- -------
     @xmath      (294)
  -- -------- -- -------

As noted above, @xmath is the standard result, Eq.( 290 ), for the
probability of crossing.

There is an interesting connection here between backflow and
decoherence. If there is decoherence, @xmath is zero so @xmath must
cancel @xmath in Eq.( 292 ), which means that @xmath , so there is no
backflow. Or we may make a logically equivalent statement: if there is
backflow, @xmath , then there cannot be decoherence, since @xmath is
then greater than the probability @xmath . Hence, states with backflow
do not permit decoherence of histories. (Note that absence of backflow,
@xmath , is not itself enough to guarantee decoherence – the stronger
condition @xmath must be satisfied).

This is an important result. The quantity @xmath is regarded as the
“standard” result for the arrival time probability and its possible
negativity is disturbing. Here, the decoherent histories approach sheds
new light on this issue. In the decoherence histories apporach, the true
probability for crossing is the manifestly positive quantity @xmath and
this is equal to @xmath only when there is decoherence. In particular,
when there is significant backflow, there cannot be decoherence, so
probabilities cannot be assigned and @xmath is not equal to @xmath .

#### 29.5 The Decoherence Conditions

The crossing probabilities described above are only valid when all
components of the decoherence functional, Eqs.( 283 ), ( 284 ), are
zero. We therefore address the issue of finding those states for which
these conditions hold.

The most important decoherence condition is that @xmath defined in Eq.(
283 ) vanishes, so we focus on that. We write the class operator Eq.(
288 ) for crossing during the time interval @xmath as

  -- -------- -- -------
     @xmath      (295)
  -- -------- -- -------

For an initial state @xmath , the quantity @xmath is a quantum state
representing the property of crossing of the origin in the time interval
@xmath . The decoherence condition @xmath is simply the condition that
the “crossing states” @xmath for different time intervals have
negligible interference. The states @xmath consist of an initial state
which has been localized to a range of time at @xmath . This is closely
related to the interesting question of diffraction in time [ 75 ] and
this connection will be explored in more detail elsewhere [ 53 ] .

The decoherence functional is given by

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (296)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where without loss of generality we take @xmath . It is a sum of terms
each of the form,

  -- -------- -- -------
     @xmath      (297)
  -- -------- -- -------

where @xmath . Note that

  -- -------- -- -------
     @xmath      (298)
  -- -------- -- -------

The key thing is that @xmath has the form of a probability – it is the
probability to find the particle in @xmath at @xmath and then in @xmath
at @xmath . Semiclassical expectations suggest that this is small in
general for the states considered here, which are left-moving wave
packets, and indeed the classical limit of this probability is zero. So
this is a useful object to calculate in terms of checking decoherence.
(Although it may not be small for states with backflow). Note that it
also implies that the other parts of the decoherence functional, Eq.(
296 ) will also be small. In detailed calculations, the upper bound Eq.(
298 ) must be compared with the probabilities, as in Eq.( 40 ).

#### 29.6 Checking the Decoherence Condition for Wavepackets

Decoherence starts to become lost as the the size @xmath of the time
intervals @xmath is reduced to close to @xmath . This is because the
“localisation in time” produces a corresponding spreading in energy, and
thus momentum, and for sufficiently small time intervals this is enough
to give rise to positive momenta with significant probability. We will
see in a specific example how this works.

For simplicity we work with the simple wavepacket initial states, more
general initial states require an environment to produce decoherence and
will be considered in Chapter 7. We take the initial state to be,

  -- -------- -- -------
     @xmath      (299)
  -- -------- -- -------

where @xmath , @xmath and @xmath . We note that the decoherence
functional Eq.( 293 ) satisfies

  -- -------- -- -------
     @xmath      (300)
  -- -------- -- -------

with @xmath given by Eq.( 298 ) with @xmath , @xmath . We need some
probabilities to compare this with. We have that

  -- -------- -- -------
     @xmath      (301)
  -- -------- -- -------

The interesting case is that in which the crossing probability @xmath is
somewhat less than @xmath , less than about @xmath , say, in which case
the non-crossing probability @xmath will be of order @xmath . It is
therefore sufficient to compare @xmath with @xmath . Now note that

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (302)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

This means that @xmath is in fact equal to the probability,

  -- -------- -- -------
     @xmath      (303)
  -- -------- -- -------

up to terms which vanish when @xmath . This is useful since it is now
identical in form to the expression for @xmath and our goal is to show
that

  -- -------- -- -------
     @xmath      (304)
  -- -------- -- -------

It is useful to work in the Wigner representation [ 10 ] , defined, for
a state @xmath by

  -- -------- -- -------
     @xmath      (305)
  -- -------- -- -------

The probabilities @xmath and @xmath are then given by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (306)
     @xmath   @xmath   @xmath      (307)
  -- -------- -------- -------- -- -------

Here, @xmath is the Wigner function of the initial state, evolved in
time to @xmath ,

  -- -------- -- -------
     @xmath      (308)
  -- -------- -- -------

The objects @xmath and @xmath are the Wigner transforms of the @xmath
-function combinations appearing in Eqs.( 298 ), ( 303 ) and are given
by

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (309)
     @xmath   @xmath   @xmath      (310)
  -- -------- -------- -------- -- -------

where

  -- -------- -- -------
     @xmath      (311)
  -- -------- -- -------

We see that the only difference between the expressions for @xmath and
@xmath is in the sign in the @xmath -functions.

The integral

  -- -------- -- -------
     @xmath      (312)
  -- -------- -- -------

may be expressed in terms of the Sine integral function @xmath ,

  -- -------- -- -------
     @xmath      (313)
  -- -------- -- -------

but its properties are not hard to see directly. For large negative
@xmath , @xmath , at @xmath , @xmath , and for large positive @xmath ,
@xmath goes to zero, oscillating around @xmath . (See Figure 11 .)

We now compare the size of @xmath and @xmath .We assume that the wave
packet is spatially broad, so @xmath is large and the Wigner function
Eq.( 308 ) is therefore concentrated strongly about @xmath . We
therefore integrate out @xmath and set @xmath throughout. The most
important case to check is that in which the wave packet is reasonably
evenly divided between @xmath and @xmath at time @xmath so that both
@xmath and @xmath have a chance of being reasonably large. This means
that @xmath should be close to zero (to within a few widths @xmath ), so
for simplicity we take it to be exactly zero.

With these simplifications, we have

  -- -------- -- -------
     @xmath      (314)
  -- -------- -- -------

Here, since @xmath and @xmath , we have @xmath . We can evaluate this
expression by examining the comparative effects of @xmath and the
exponential term. From the plot of @xmath (see Figure 11 ), we see that
it drops to zero at @xmath (which is of order @xmath ) and oscillates
rapidly around zero for @xmath , so we expect the integral to be
dominated by values of @xmath for which @xmath . The value @xmath
corresponds to @xmath where

  -- -------- -- -------
     @xmath      (315)
  -- -------- -- -------

where @xmath . In the complex potential calculations, we have assumed
that @xmath and we also assumed that all timescales are much greater
than @xmath , and these together imply that @xmath . We may therefore
expand the square root to leading order and obtain

  -- -------- -- -------
     @xmath      (316)
  -- -------- -- -------

We have assumed that the wave packet is sufficiently broad that @xmath ,
and this means that

  -- -------- -- -------
     @xmath      (317)
  -- -------- -- -------

This in turn means that @xmath is significantly different from zero only
in the range @xmath , and most importantly, in this range, the
exponential term in Eq.( 314 ) is approximately constant. We may
therefore evaluate Eq.( 314 ) by ignoring the exponential term,
integrating from @xmath to @xmath and approximating @xmath as

  -- -------- -- -------
     @xmath      (318)
  -- -------- -- -------

We thus obtain the simple result,

  -- -------- -- -------
     @xmath      (319)
  -- -------- -- -------

In the expression for @xmath , there is a key difference in that @xmath
which means that @xmath can be positive or negative. Introducing

  -- -------- -- -------
     @xmath      (320)
  -- -------- -- -------

(where @xmath is the Zeno time) we see that @xmath for @xmath and @xmath
for @xmath . We therefore have

  -- -------- -------- -- -------- -------
     @xmath   @xmath               (321)
                          @xmath   
  -- -------- -------- -- -------- -------

Here, @xmath in the first term, differing from this value only in a
region of size @xmath close to @xmath . In the second term @xmath will
tend to be small except for a small region of size @xmath around the
origin.

If @xmath , (that is, @xmath ), the second term in @xmath is
exponentially suppressed and in the first term the integration range is
effectively @xmath to @xmath , so we obtain

  -- -------- -- -------
     @xmath      (322)
  -- -------- -- -------

This is the expected result, since under the above assumptions on the
wave packet, half of it will cross @xmath if the time interval is
sufficiently large. Clearly @xmath in this case so there is decoherence.

If @xmath , the first term in @xmath is of order @xmath and the second
of order @xmath , the same order of magnitude as @xmath . Hence in this
case we have decoherence if

  -- -------- -- -------
     @xmath      (323)
  -- -------- -- -------

which is equivalent to,

  -- -------- -- -------
     @xmath      (324)
  -- -------- -- -------

Crucially this is equivalent to the condition that there be negligible
reflection from the complex potential.

In brief, we therefore get decoherence of histories for a single wave
packet under a wide variety of circumstances. It is easily seen that
similar results also hold for orthogonal superpositions of gaussian
wavepackets, see Fig.( 12 ). More general states will require an
environment to ensure decoherence. This will be addressed in Chapter 7.

The condition Eq.( 324 ) has previously been obtained in studies of the
accuracy with which a quantum system can be used as a clock [ 88 , 4 ]
(see also Chapter 8.) In these studies it was proposed that @xmath is a
fundamental limitation of the accuracy with which times can be defined
in quantum theory. One weakness of those studies, however, is that it is
always possible that the limitation is just an artifact of the
particular choice of clock model. It is therefore very interesting that
the same condition arises as a decoherence condition in the study of the
arrival time problem presented here. The fact that what is, on the face
of it, a very different analysis of the problem nevertheless arrives at
the same limitation on the accuracy of the definition of arrival times
adds weight to the idea that Eq.( 324 ) really is a fundamental limit in
quantum theory.

### 30 Summary and Conclusions

We considered the arrival time problem using a complex potential to kill
paths entering @xmath . In Section 5.2 we gave a classical analysis of
the problem. We derived a result of the expected form exposing the
resolution function as an essentially classical effect summarizing the
role of the complex potential. We also showed that coarse graining over
time scales much greater than @xmath produces a formula for the arrival
time of expected form and which is independent of the complex potential.
This is an important result for the rest of the paper.

In Section 5.3, we used the PDX to rederive the standard form of the
arrival time distribution with a complex potential, in the limit of weak
potential. The form of this calculation turned out to be useful for the
subsequent work on the decoherent histories approach.

In Section 5.4, we considered the decoherent histories analysis for the
simple case of a particle crossing or not crossing @xmath during a large
time interval @xmath . We found the simple and expected result that the
histories are decoherent as long as reflection by the complex potential
is negligible. The resultant probabilities are consistent with the
standard result for the arrival time.

The main part of the decoherent histories analysis was given in Section
5.5, where we first derived the class operators described crossing
@xmath for an arbitrary set of small time intervals. Here we obtained
our most important result: the crossing class operator Eq.( 287 ) for
timescales much greater than @xmath . This form of the class operator
gives an immediate connection with the standard result for probabilities
when there is decoherence. Indeed, one may have guessed the form of the
class operator from the standard form of the probabilities, and this is
pursued in the next chapter. However, it is also gratifying that it can
be derived in some detail using the complex potential approach used
here.

To assign probabilities, the decoherence functional must be diagonal and
we considered this condition. We found a variety of states for which
there is decoherence, under certain more detailed conditions, which we
discussed.

We also noted an interesting and important relationship between
decoherence and backflow: If there is decoherence, the probabilities for
crossing must be positive so there cannot be any backflow. If there is
no decoherence, the integrated current may still be positive, but one
can say that if there is backflow there will definitely be no
decoherence. This means that the decoherent histories approach brings
something genuinely new to the arrival time problem: it establishes the
conditions under which probabilities can be assigned and in particular
forbids the assignment of probabilities in cases where there is
backflow.

## Chapter \thechapter Arrival Times, Crossing Times and a Semiclassical
Approximation

  Some historians hold that history … is just one damned thing after
  another.

  Arnold Toynbee

### 31 Introduction

We have seen in the previous chapter that arrival time probabilities can
indeed be defined via decoherent histories, with the class operators
defined in terms of complex potentials. However probably the single most
important result was that the class operators corresponding to arriving
in a time interval @xmath can be written as,

  -- -------- -- -------
     @xmath      (325)
  -- -------- -- -------

with @xmath , provided @xmath where @xmath is the energy around which
the state is strongly peaked. In this limit, all dependence on the
complex potential has dropped out and the class operator is exceedingly
simple. This strongly suggests that there is some simple approximation
that can lead us to these class operators, without having to resort to
complex potentials. The calculations in the previous chapter would then
be important only to establish the conditions under which this
approximation holds. One aim of this chapter is to present such a
derivation.

Eq.( 325 ) was derived for the special case of a wavepacket incoming
from the right, with entirely negative momentum. This analysis can be
changed in a simple way to allow for states consisting entirely of
positive momenta, but it is less clear how to handle states with momenta
of both signs.

This is important for the following reason. Consider the case where the
initial state is a superposition of two wave packets, identical except
that one is the mirror image of the other, ie @xmath . The symmetry here
implies that the current at the origin is always zero, even though we
would like to say that both wave packets cross the origin. This suggests
that crossing probabilities cannot in general be simply related to the
current, and it is of interest to know how they may be defined instead.

Useful insight can be gained by looking at the classical case. There if
one has momenta of both signs one can seperate the classical
trajectories into ones that cross the origin from the left and ones that
cross from the right [ 77 , 19 ] . The crossing time distribution,
@xmath can therefore be written as

  -- -------- -- -------
     @xmath      (326)
  -- -------- -- -------

where the current associated with the positive momentum components of
the system is given by

  -- -------- -- -------
     @xmath      (327)
  -- -------- -- -------

and similarly for @xmath . Here @xmath is the classical phase space
distribution function. This can be written in the alternative form

  -- -------- -- -------
     @xmath      (328)
  -- -------- -- -------

where @xmath is the signum function.

In the quantum case, however, we do not have a description in terms of
trajectories. This means that we cannot justify the procedure used in
the classical case. In fact it turns out that even if we could, we would
not arrive at an acceptable arrival time distribution. This is because
the quantum analogue of Eq.( 328 ) would be

  -- -------- -- -------
     @xmath      (329)
  -- -------- -- -------

where @xmath is the Wigner function of the system. However unlike the
classical phase space distribution function, the Wigner function need
not be positive. Therefore in general this expression will not be
positive, so cannot be a probability distribution. It is important to
note that this negativity is not due to any “trajectories moving
backwards” since the modulus of the momentum has been taken. Rather this
negativity is the result of quantum interference between wave packets
moving in different directions. The second aim of this chapter
therefore, is to find the correct class operators to describe arrival
times where the initial state is a superposition of left and right
moving wavepackets, to compute the crossing probabilities thus obtained,
and to check the conditions under which we have decoherence. Our aim
will be to demonstrate that if we have a left and a right moving
wavepacket for which the arrival time histories would individually
decohere according to the analysis of Chapter 5, then the crossing time
histories of a superposition of such wavepackets will also be
decoherent.

Our analysis follows from the simple observation that although in
standard quantum theory there is no notion of trajectory, in decoherent
histories the concept of a history is very similar to that of a
trajectory. We will use this insight to show how an analysis similiar to
the classical case can lead us to an expression for the object
representing the probability of crossing a surface from either side.

The rest of this chapter is arranged as follows. In Section 32 we
present a semiclassical derivation of the crossing class operators
previously derived via complex potentials in Chapter 5. In Section 33 we
address some issues relating to the differences between arrival times
and crossing times that are relevant for the rest of this chapter. In
Section 34 we introduce the crossing time class operators, and then
simplify them using a similar semiclassical aproximation to that used in
Section 32 . In Section 35 we compute the crossing probabilities and
decoherence conditions using these crossing class operators. We conclude
in Section 36 . The first part of this chapter, Section 32 , is based on
Ref. [ 50 ] .

### 32 Semiclassical Derivation of the Arrival Time Class Operators

In this section we give a semiclassical derivation of Eq.( 325 )
following Ref. [ 50 ] . We wish to see if there is a simpler way of
arriving at the main results of Chapter 5, without recourse to the
machinery of complex potentials. Instead we see if some semiclassical
approximation can lead to the same conclusions.

We consider an initial state at @xmath with @xmath concentrated in
@xmath . Suppose the state crosses the origin during a large time
interval @xmath . It is useful to introduce a discrete set of times
@xmath , where @xmath and @xmath . We also define the projection
operators

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (330)
     @xmath   @xmath   @xmath      (331)
  -- -------- -------- -------- -- -------

Consider first the class operator for remaining in @xmath (i.e., not
crossing @xmath ) during the time interval @xmath . We assert that the
appropriate class operator is

  -- -------- -- -------
     @xmath      (332)
  -- -------- -- -------

This corresponds to the statement that the particle is in @xmath at the
discrete set of times @xmath , but its location is unspecified at
intermediate times. We know from our studies of the Zeno effect that we
must have @xmath to avoid reflection.

We construct the first crossing class operator by partitioning the
histories according to whether they are in @xmath or @xmath at the
discrete set of times @xmath and noting that the class operators must
sum to the identity. We write

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (333)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Repeating inductively, we obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (334)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

We thus identify the first crossing class operator as

  -- -------- -- -------
     @xmath      (335)
  -- -------- -- -------

for @xmath , with @xmath . This clearly describes histories which are in
@xmath at times @xmath and in @xmath at time @xmath , so, to within the
accuracy set by @xmath , describe a first crossing between @xmath and
@xmath . The last term in Eq.( 334 ) is the non-crossing class operator,
@xmath . We will actually assume that @xmath is sufficiently large that
the wave packet ends up entirely in @xmath at large times, so @xmath is
essentially zero. This means that we effectively have

  -- -------- -- -------
     @xmath      (336)
  -- -------- -- -------

as required. We will generally be interested in class operators
describing crossing in intervals @xmath of size @xmath , where @xmath is
a positive integer, and these class operators are simply obtained by
summing,

  -- -------- -- -------
     @xmath      (337)
  -- -------- -- -------

Last crossing class operators are similarly constructed but will not be
required, as we shall see below.

Consider the strings of identical projection operators @xmath at
different times appearing in Eq.( 332 ) (and similarly in Eq.( 335 )).
Given that the final projection @xmath is onto @xmath and also that the
initial state is localized in @xmath , it seems reasonable to suppose
that the projections at times @xmath to @xmath do not disturb the
evolving state too much, under the condition @xmath discussed above. It
therefore seems reasonable to make the approximation

  -- -------- -- -------
     @xmath      (338)
  -- -------- -- -------

This is easy to understand in a path integral representation. The
right-hand side is in essence the amplitude from an initial state
concentrated in @xmath to a final point in @xmath at time @xmath (up to
overall unitary factors). The sum over paths will be dominated by the
straight line path, which lies entirely in @xmath at all intermediate
times. It will therefore be little affected by the insertion of
additional projections onto @xmath at intermediate time.

Using this approximation, the crossing class operator Eq.( 335 )
operating on the given initial state may be approximated as

  -- -------- -- -------
     @xmath      (339)
  -- -------- -- -------

Rearranging and using the approximation Eq.( 338 ) a second time we
obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (340)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Which is precisely what we set out to show. We have therefore shown that
a simple semiclassical approximation, Eq.( 338 ), can yield the correct
class operators without recourse to complex potentials. However, it is
not clear from the analysis above when this semiclassical approximation
is valid. For this we do need the results of the previous chapter, which
tell us that we must have @xmath . We also note that the semiclassical
approximation used above means that there is no distinction between
first and last crossing, so a last crossing class operator would yield
the same result, see the remarks at the end of Section 11

### 33 Arrival Times, Crossing Times and First Crossing Times

Given the results of the previous section, it is straightforward to
write down the class operators corresponding to crossing or not crossing
from either side of the origin. Before we do this however we wish to
pause a moment to address a subtle issue in the arrival time problem,
which is the difference between crossing times and first crossing times.
In classical mechanics, for a particle in a potential, a particle may
cross the surface @xmath many times. One generally defines the arrival
time as the first crossing of @xmath . In fact constructing even the
classical arrival time distribution for a particle in a confining
potential is somewhat involved. Generally one imposes absorbing boundary
conditions on the system, and the arrival time distribution can then be
taken as the flux at @xmath for the modified system with these boundary
conditions. For the case of a free particle, of course, the particle
only crosses @xmath once, and so there is no distinction between
crossing and first crossing.

In the quantum case, a similar problem arises for a particle in a
potential and presumably we could also tackle this problem using the
complex potential analysis used in Chapter 5, at least for suitably
smooth potentials. However even for a free particle in quantum theory,
the set of possible paths summed over in the path integral definition of
the propagator is dominated by those that cross @xmath an infinite
number of times (see Chapter 3.) This means that we must distinguish
between notions of crossing and first crossing even for a free particle
in quantum theory.

In practice, however, this issue is unlikely to cause real problems.
Since we know from the Zeno effect that we can only define arrival times
up to some accuracy @xmath , it seems reasonable to assume that we will
not resolve multiple crossings of the origin by a free particle ⁹ ⁹ 9
This assumes that the timescale on which these effects are important is
given by @xmath . Since for a wavepacket this is the genuine quantum
timescale this seems reasonable, but this will be studied further
elsewhere. .

The consequence of this is that although we presented the derivation of
the class operators above as if we used a single semiclassical
approximation, in fact there are two different approximations being
used. The first is the approximation,

  -- -------- -- -------
     @xmath      (341)
  -- -------- -- -------

As claimed, this is based on the idea that the propagator is dominated
by the straight line path. Alternatively this may be thought of as
expressing the equivalence of first crossing and crossing times. In fact
this object is an exact class operator, but for a slightly different
question, which is “What is the probability that the particle crossed
the origin from the right during the interval @xmath ?” See Fig.( 14 )
for an illustration of this.

The second approximation we made was the one leading to Eq.( 353 ),

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (342)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

This is not so much a semiclassical approximation (it is not true in the
general classical case), rather it depended on us having an entirely a
left moving wavepacket. In fact the arrival time class operator Eq.( 342
) can be written exactly as,

  -- -------- -- -------
     @xmath      (343)
  -- -------- -- -------

so that the approximation Eq.( 342 ) corresponds to ignoring crossings
from the left.

These remarks will be important when we come to analyse the class
operator for crossing from either side of the origin.

### 34 Crossing Class Operators in Decoherent Histories

We turn now to the questions of defining class operators for crossing
the origin when we have momenta of both signs. The class operators for
crossing the origin from the right, @xmath and from the left, @xmath are
clearly given by,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (344)
     @xmath   @xmath   @xmath      (345)
  -- -------- -------- -------- -- -------

These expressions are simply Eq.( 339 ) and its obvious analogue for the
case of a right moving wavepacket. Our provisional class operators for
crossing and not crossing from either side during the interval @xmath
are thus,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (346)
                       @xmath   @xmath   
     @xmath   @xmath   @xmath            (347)
  -- -------- -------- -------- -------- -------

Note that, in light of the comments made above, we cannot simplify Eqs.(
344 ) and ( 345 ) in the manner of Eq.( 342 ).

In principle Eqs.( 346 ) and ( 347 ) provide all the information we need
to define crossing probabilities in quantum theory. In practice however
these objects are somewhat awkward to work with. What we want is to use
the same sort of semiclassical approximations we used to simplify the
arrival time class operators to write these crossing class operators in
a more useful form.

We begin by defining new class operators which are simply the real part
of Eqs.( 346 ) and ( 347 ),

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (348)
     @xmath   @xmath   @xmath      (349)
  -- -------- -------- -------- -- -------

The use of the Hermitian class operators, Eqs.( 348 , 349 ) is not
strictly necessary, since decoherence will ensure that, when defined,
the probabilities computed from the class operators Eqs.( 346 ), ( 347 )
are real. However using the Hermitian class operators makes it easier to
compare the probabilities with the standard results.

Now consider the class operator for crossing from the right during the
interval @xmath , Eq.( 344 ). Crossing from the right is,
semiclassically, the same as restricting to negative momentum and what
we want to show is that Eq.( 344 ) is equivalent to some simpler class
operator which includes a restriction on the momentum. We begin by
noting that Eq.( 344 ) can be written as,

  -- -------- -- -------
     @xmath      (350)
  -- -------- -- -------

We claim that, semiclassically,

-   @xmath ,

-   @xmath .

The second approximation follows from Section 32 . The first one is
clearly true classically, and will be approximately true in the quantum
case provided @xmath where @xmath is the energy of the incoming state.
These two approximations mean we can write,

  -- -------- -- -------
     @xmath      (351)
  -- -------- -- -------

Using the same approximations in @xmath , we can write down a
semiclassical approximation to @xmath ,

  -- -------- -- -------
     @xmath      (352)
  -- -------- -- -------

Finally then we take the real part of this expression to obtain, after
some rearranging,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (353)
     @xmath   @xmath   @xmath      (354)
  -- -------- -------- -------- -- -------

Eqs.( 353 ) and ( 354 ) are the desired class operators for crossing and
not crossing the origin from either side during the time interval @xmath
.

As an aside, it is interesting to note that that Eq.( 346 ) may also be
obtained from Eq.( 343 ) by the following argument: Start with the class
operator corresponding to the integrated current, Eq.( 343 ). Notice
that the second term on the right of Eq.( 343 ) is associated with
crossing the origin in the opposite direction to the first term. Flip
the sign of this second term to correct for this. This leads us to Eq.(
346 ). This is exactly the same argument as leads to Eq.( 326 ) in the
classical case.

Let us state this argument again in a different way. The object, @xmath
is the operator representing the integrated current in standard quantum
theory, and is thus the candidate for the arrival or crossing time
distribution. Eq.( 343 ) is an identity, but neither of the objects on
the right hand side has an obvious interpretation in standard quantum
theory (one would have to talk about measurements to give them meaning.)
However in decoherent histories we can easily identify these objects as
class operators for crossing from the right and from the left. We can
therefore perform the classical trick of changing the sign in front of
the second term, to arrive at Eq.( 346 ), which is the crossing time
class operator. Eqs.( 346 ) and ( 347 ) may therefore be derived either
from first principles, or by splitting the object representing the
integrated current, Eq.( 342 ) into two objects representing crossing
from the left and from the right and then making the change of sign in
analogy with the classical case, Eq.( 326 ).

### 35 Crossing Time Probabilities and Decoherence of Crossing Histories

Now we have the class operators for crossing, we can ask about the
probabilities for crossing the origin. The easiest way to approach this
is to express these probabilities in terms of the momentum
representation of the density matrix. For comparison we note that the
current can be written in this way as

  -- -------- -- -------
     @xmath      (355)
  -- -------- -- -------

For a decoherent set of histories, the probabilities are given by,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath                     (356)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

This means that the probabilities are in fact functions not of the full
density matrix, but rather of the quantity,

  -- -------- -- -------
     @xmath      (357)
  -- -------- -- -------

This is somewhat unexpected, but very appealing. For a superposition of
left and right moving states, our arrival time probabilities are just
the sum of the probability for the arrival of the left moving state and
that for the right moving one. Interference terms between left and right
moving states do not appear. Note the close similarity between the way
our class operators partition the current into left and right moving
parts and the classical expression, Eq.( 326 ).

We turn now to the question of for which states and intervals we have
decoherence. Decoherence between crossing and not crossing during an
interval @xmath requires,

  -- -------- -- -------
     @xmath      (358)
  -- -------- -- -------

which can also be written as

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (359)
                                @xmath   
                                @xmath   
     @xmath   @xmath   @xmath            (360)
                                @xmath   
  -- -------- -------- -------- -------- -------

The first line is the decoherence functional for crossing from the
right, and the second line is the decoherence functional for crossing
from the left. This means that a sufficient condition for decoherence of
the crossing probabilities is that our initial state is a superposition
of a left moving and a right moving wavepacket, each of which satisfy
the conditions for decoherence of their corresponding arrival time
probabilities. But this is exactly what we set out to prove. Detailed
calculation of the two terms in Eq.( 360 ) has been carried out in
Chapter 5, and we simply quote the result, that we have decoherence for
gaussian wavepackets, and orthogonal superpositions of these, provided
they are tightly peaked in momentum, and subject to the requirement

  -- -------- -- -------
     @xmath      (361)
  -- -------- -- -------

where @xmath is the mean energy of the wavepacket. For more general
wavepackets we require an environment to ensure decoherence of the
arrival time probabilities [ 100 ] and we suspect that the same will be
true here. This issue will be addressed elsewhere.

### 36 Summary and Discussion

Our aims in this chapter were twofold. Firstly we wished to understand
whether the origin of the arrival time class operators might be
understood by some intuitive argument. We saw that this is indeed the
case. Secondly we wished to see how the class operators for the arrival
time problem might be extended to deal with wavepackets incident from
both sides of the origin. Again we saw that this is possible and that
the probabilities defined in this way have the nice feature of being
insensitive to the interference terms involving left and right moving
wavepackets. What is interesting about the analysis of crossing times is
that it is not obvious how to do this in the language of complex
potentials, yet it seems relatively simple in terms of the class
operators defined via strings of projection operators. In particular it
is gratifying that the use of decoherent histories provides a
justification for some simple semiclassical manipulations, such as the
derivation of Eq.( 346 ), and this suggests it may be usefully employed
to address the definition of other time observables. This will be
pursued elsewhere.

## Chapter \thechapter Quantum Arrival Time for Open Systems

  Tempora mutantur, et nos mutamur in illis.
  Times change, and we change with them.

  William Harrison

### 37 Introduction

In the previous two chapters we have discussed how the arrival time
distribution may be derived in the framework of decoherent histories. We
found that the arrival time distribution may, under the conditions of
decoherence, be written as the integral of the current at the origin,
thus providing justification for the semiclassical expression we wrote
down in Chapter 1, Eq.( 20 ). Recall this was,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (362)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

with

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (363)
  -- -------- -------- -------- -- -------

where @xmath , we denote the state at time @xmath by @xmath and the
Wigner function @xmath is defined by Eq.( 21 ). Recall also the three
problems with Eq.( 362 ),

1.  It is not generally positive, even when it would be expected to be
    so classically.

2.  It was not derived but postulated.

3.  It is not of the general form of the trace of the density matrix
    times a projection operator or POVM, Eq.( 29 ).

Chapters 5 and 6 sought to address these issues by deriving the arrival
time distribution from decoherent histories and showing how it reduces
to Eq.( 362 ) in the case where we have decoherence. We succeeded in
addressing the first and second points, but no mention was made of the
third. In addition we generated the new problem that we could only
demonstrate decoherence of histories for particular initial states.

In this chapter we look at the definition of arrival times for open
quantum systems, that is for a particle coupled to some environment. One
aim of this is to extend the decoherent histories analysis to a general
initial state and we discuss this in more detail below. However the
first aim of this chapter is to see whether the semiclassical expression
Eq.( 362 ) is any less problematic for a particle coupled to an
environment. An interesting clue is provided by the expression for the
current in terms of the Wigner function, Eq.( 22 ). Negativity of the
Wigner function is a neccessary condition for the negativity of the
current (in the sense of backflow, as discussed in [ 49 ] ), but it is
known that evolution in the presence of an environment typically renders
the Wigner function positive after a short time [ 21 ] . This suggests
that something like Eq.( 362 ) may be an acceptable, if still heuristic,
arrival time distribution for a system coupled to an environment, at
least after some time. The first aim of this chapter is to derive the
correct analogue of Eq.( 363 ) for a system coupled to an environment,
and to prove that it can indeed be regarded as an arrival time
distribution after a short time. In particular we show that the arrival
time probabilities computed in this way may be written as the trace of
the density matrix times a POVM. This then addresses the first and third
points above.

However although this may allow us to interpret the current as the
arrival time distribution, we are still left with the task of deriving
Eq.( 362 ) from some more fundamental quantity. This was achieved in
Chapters 5 and 6 in the context of the decoherent histories approach to
quantum theory [ 30 , 31 , 37 , 85 , 41 , 22 ] , for the case of a free
particle and the derivation was shown to hold for states and intervals
exhibiting sufficient decoherence. However it was also shown that there
exist states for which decoherence of histories cannot be obtained for
reasonable levels of coarse graining, and for which therefore we cannot
assign a time of arrival probability distribution. States exhibiting
backflow are good examples of this.

Lack of decoherence for a general state is a situation frequently
encountered in the literature on decoherent histories. The solution lies
in the observation that realistic systems are always coupled to an
environment and that as such they are most fundamentally described by
open system dynamics. Because by definition an environment consists of
degrees of freedom about which we have no knowledge, and over which we
have no control, it is natural to coarse-grain over these degrees of
freedom. Such coarse-graining generally results in the recovery of
approximate classical behaviour, and thus decoherence. We therefore
anticipate that decoherence of histories corresponding to arrival times
may be achieved for a generic state, provided that particle is coupled
to a suitable environment. The second aim of this chapter is to examine
this scheme. We show that the probabilities calculated in this way are
approximately decoherent and approximately equal to those computed via
the analogue of Eq.( 363 ), valid in the case of an environment.

Once we introduce an environment, however, the correspondence is with a
classical stochastic theory, rather than with a deterministic one. The
classical trajectories may now cross the origin many times due to
fluctuations. The arrival time distribution for such a classical theory
was computed in Ref. [ 54 ] , and is given by

  -- -------- -- -------
     @xmath      (364)
  -- -------- -- -------

where @xmath is the initial phase space distribution, evolved with a
type of restricted propagator valid in the case of an environment, with
boundary conditions, [ 54 ]

  -- -------- -- -------
     @xmath      (365)
  -- -------- -- -------

In Ref. [ 54 ] Halliwell and Zafiris presented a decoherent histories
analysis of the corresponding quantum case. Although the conclusion they
reach is sensible their analysis actually contains a small error. This
was the result of a lack of appreciation of the role of the quantum Zeno
effect in these calculations, as outlined in Chapter 1 Section 1.6. We
will show in this chapter how the analysis can be corrected to give a
correct expression for the arrival time probability in decoherent
histories. We shall be interested in a particular limit of this general
case where the stochastic trajectories are sharply peaked about the
deterministic trajectories we would have in the absence of any
environment. In this case the restricted propagator may be replaced with
an unrestricted one, and we will show that quantisation in this limit
yields an expression of the form Eq.( 362 ), but with the Wigner
function evolved in the presence of an environment.

It will eventually be necessary to specialise to a particular model of
system-environment coupling in order to obtain quantitative results, but
we will begin by considering general models which can be written in
terms of a master equation of Lindblad form. This kind of system has
been extensively studied in the decoherence literature and the
properties of such evolution, such as suppression of interference
effects, loss of entanglement and an approximate recovery of classical
behaviour have been discussed in [ 21 , 56 , 55 , 33 ] .

This chapter is arranged as follows, in Section 38 we explore some
properties of the arrival time distribution for general open systems of
Lindblad form, our aim being to derive the corrections to the current
resulting from the environmental dynamics. In Section 39 we discuss
quantum Brownian motion and specialise the results of Section 38 to this
case. In Section 40 we derive some properties of the arrival time
distribution for quantum Brownian motion, in particular we prove that
the current becomes positive after a finite time. In Sections 41 we
briefly recap the expressions for the arrival time distribution that
arise in decoherent histories, in particular we show that the
decoherence condition is closely linked to the semiclassical
approximation. In Section 42 we then examine whether histories
corresponding to arriving in different intervals of time are decoherent.
We summarise our results in Section 43 . This chapter is based on Ref. [
100 ] .

### 38 Arrival Time for Open Quantum Systems

We consider an open quantum system consisting of a free particle coupled
to an environment with master equation of the following Lindblad form [
69 ] ,

  -- -------- -- -------
     @xmath      (366)
  -- -------- -- -------

where @xmath are the Lindblad operators and @xmath is the free
hamiltonian plus a possible extra term that depends on the @xmath .
(This term gives rise to frequency renormalisation in oscillating
systems.) (In this chapter we explicitly write factors of @xmath to help
us see the difference between classical and quantum terms in equations.)
Specific forms for the @xmath may be computed for particular models, but
for the moment we leave this general. The Lindblad equation represents
the most general master equation for a Markovian system which preserves
the properties of the density matrix, in particular positivity.

We now extend the derivation of Eq.( 362 ) to this system. The
probability of crossing during the interval @xmath is

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (367)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

where @xmath . The first term is the standard current expression,
although with the state evolved according to Eq.( 366 ), and we
therefore recover Eq.( 362 ) when all the @xmath are 0. The second and
third terms depend on the Lindblad operators, @xmath and thus on the
form of the system-environment coupling.

To proceed further we specialise to the case where @xmath is a linear
combination of @xmath and @xmath , @xmath , where @xmath and @xmath are
real constants. The master equation Eq.( 366 ) is then

  -- -------- -- -------
     @xmath      (368)
  -- -------- -- -------

Note that this equation is also identical in form to the exact master
equation for a particle in a gas environment, given in [ 20 ] .

To derive the arrival time distribution we could simply substitute
@xmath into Eq.( 367 ), but the algebra is somewhat clumsy, and there
are a number of terms which vanish for reasons not immediately apparent
from this expression. An equivalent approach is to start from Eq.( 368
), multiplying this expression by @xmath and taking the trace. Because
the second and third terms on the right of this expression have the form
@xmath their contribution is proportional to

  -- -------- --
     @xmath   
  -- -------- --

so that only the first and last terms on the right hand side of Eq.( 368
) contribute. The final term on the right of Eq.( 368 ) gives a
contribution,

  -- -------- -- -------
     @xmath      (369)
  -- -------- -- -------

so we arrive at the expression,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (370)
                                @xmath   
  -- -------- -------- -------- -------- -------

The second term in this expression has a somewhat unusual form and its
significance is not immediately clear. We will see below that this term
is related to diffusion in position. There is a connection here to a
recent paper by Genkin, Ferro and Lindroth [ 32 ] , in which the authors
sought to examine the effects of an environment on the arrival time
distribution. In that paper the authors used the standard expression for
the current valid in the unitary case, Eq.( 363 ), ignoring the extra
terms that arise because of the environment. Although this may be a good
approximation when we can neglect the effects of dissipation, it is
clear that there may be significant corrections to the current for
strong dissipation. They also pointed out that these corrections are
equivalent to the presence of extra terms in the continuity equation,
although they did not compute these explicitly. For the sake of
completeness, and also because it helps to understand the nature of the
extra terms in Eq.( 370 ) we will derive them here.

To derive the continuity equation we multiply Eq.( 368 ) by @xmath and
perform the trace. If we neglect the final three terms on the right we
arrive at the standard result,

  -- -------- -- -------
     @xmath      (371)
  -- -------- -- -------

with @xmath defined by an obvious extension of Eq.( 363 ). Turning to
the extra terms that result from the inclusion of the environment, the
second and third terms vanish in exactly the same way as for the current
above, and the correction term is therefore given by,

  -- -------- -- -------
     @xmath      (372)
  -- -------- -- -------

so the continuity equation now reads,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (373)
  -- -------- -------- -------- -- -------

where we have identified the diffusive current,

  -- -------- -- -------
     @xmath      (374)
  -- -------- -- -------

This is a specific example of a modification to a conservation equation
resulting from open system dynamics. For a more general discussion of
these issues see [ 29 ] .

The analysis presented above can also be phrased in terms of phase space
distributions. The Wigner function corresponding to @xmath is defined as
[ 10 ]

  -- -------- -- -------
     @xmath      (375)
  -- -------- -- -------

The Wigner transform of the master equation Eq.( 368 ) is

  -- -------- -- -------
     @xmath      (376)
  -- -------- -- -------

The first term is the standard unitary term, whilst the second term
represents dissipation, and the third and fourth terms represent
diffusion. The arrival time distribution can be written in terms of the
Wigner function by taking the Wigner transform of Eq.( 370 )

  -- -------- -- -------
     @xmath      (377)
  -- -------- -- -------

Eqs.( 370 ) and ( 377 ) are the sought for generalisation of Eq.( 362 )
for the case of a particle coupled to an environment.

### 39 Quantum Brownian Motion

Quantum Brownian motion [ 14 , 56 , 55 ] is a commonly used form for the
environment of an open system, partly because it is exactly solvable and
partly because in many cases it is a good approximation to a realistic
environment. For the quantum Brownian motion model [ 56 ] we have Eq.(
368 ) with

  -- -------- -- -------
     @xmath      (378)
  -- -------- -- -------

Here @xmath , where @xmath is the temperature of the environment, and
@xmath is a phenomenological damping constant, see [ 14 ] . Eq.( 368 )
may be written as

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (379)
                                @xmath   
  -- -------- -------- -------- -------- -------

Although we could in principle work with this general case, it is useful
to specialise to the case of negligible dissipation. There are two
reasons for this, the first is that the analysis is considerably
simplified, and this helps us to see the important effects more clearly.
The second is that we have a particular aim in mind here, and that is to
understand how a sensible classical result emerges from the quantum
case. The classical case we have in mind is that of a heavy particle
following an essentially classical, deterministic trajectory, but
subject to small quantum fluctuations. We therefore restrict our
analysis to timescales much shorter than the relaxation time @xmath , so
we can drop the final two terms in the master equation above.

This master equation may then be solved in terms of the propagator [ 55
] ,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (380)
     @xmath   @xmath   @xmath            (381)
                                @xmath   
  -- -------- -------- -------- -------- -------

Taking the same limit in the equation for the Wigner function, Eq.( 376
), gives

  -- -------- -- -------
     @xmath      (382)
  -- -------- -- -------

Evolution of the Wigner function may also expresed in terms of a
propagator [ 55 ] ,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (383)
     @xmath   @xmath   @xmath            (384)
                                @xmath   
  -- -------- -------- -------- -------- -------

where @xmath and @xmath are given by

  -- -------- -- -------
     @xmath      (385)
  -- -------- -- -------

For later convenience we note that we can make the simple change of
variables here, @xmath , so that

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (386)
     @xmath   @xmath   @xmath      
     @xmath   @xmath   @xmath      (387)
  -- -------- -------- -------- -- -------

This form makes it clear that the evolution consists of two effects. The
first is a shifting along the classical trajectories, whilst the second
is a spreading in phase space.

It is useful to consider this process in more detail. In the presence of
an environment the width of the momentum distribution becomes time
dependent, and we have,

  -- -------- --
     @xmath   
  -- -------- --

where @xmath is the momentum width of the initial state. We recognise an
immediate difficulty here. Even for initial distributions consisting
entirely of left moving momenta, @xmath will develop support on @xmath
under evolution. This means we cannot strictly regard the current as an
arrival time distribution, since a typical trajectory will now cross the
origin many times. Differently put, the arrival time distribution is
strictly a measurement of the first passage time and this is no longer
simply related to the current. (Note that although this result is
similar to the problems created by backflow, the reasons behind it are
very different. The spreading of momentum induced by evolution in an
environment is a purely classical effect.)

However, all is not lost. Although the current is no longer strictly the
arrival time distribution, it may be a very good approximation to it.
This is because the deviation of the current from the “true” arrival
time distribution will be related to the probability that the state has
the “wrong” sign momenta. This means that, provided we are in the
“near-deterministic” limit,

  -- -------- -- -------
     @xmath      (388)
  -- -------- -- -------

where @xmath is the momentum around which the initial state is tightly
peaked, the current will still be a very good approximation to the true
arrival time distribution. The timescale on which this analysis breaks
down is given by the “stochastic” time,

  -- -------- --
     @xmath   
  -- -------- --

After this time we must therefore revert to using the exact expression
for the arrival time given by Eq.( 364 ). We see from the definition of
@xmath that,

  -- -------- -- -------
     @xmath      (389)
  -- -------- -- -------

for the states we are interested in. This means the stochastic time
@xmath is much longer than the relaxation time @xmath , so that working
in the near-deterministic limit does not impose any further constraints
compared with neglecting dissipation.

Returning to our arrival probability, in the limit of negligible
dissipation Eq.( 370 ), becomes,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (390)
     @xmath   @xmath   @xmath      (391)
  -- -------- -------- -------- -- -------

This expression is now identical to the unitary case, Eq.( 363 ), but
with the Wigner function evolved under quantum Brownian motion.

We now turn to the question of whether inclusion of an environment helps
ensure the positivity of Eq.( 390 ).

### 40 Properties of the Arrival Time Distribution in Quantum Brownian
Motion

In the introduction to this chapter we noted that evolution in an
environment typically renders @xmath positive after a short time. We now
wish to examine the effect of this on our candidate arrival time
distribution Eq.( 390 ). To this end we introduce the notation [ 21 ]

  -- -------- -- -------
     @xmath      (392)
  -- -------- -- -------

and also the class of Gaussian phase space functions

  -- -------- -- -------
     @xmath      (393)
  -- -------- -- -------

where @xmath is a @xmath positive definite matrix, with determinant
@xmath . @xmath will be a Wigner function if and only if

  -- -------- -- -------
     @xmath      (394)
  -- -------- -- -------

A useful result is that

  -- -------- -- -------
     @xmath      (395)
  -- -------- -- -------

In this notation we can write the propagation of the Wigner function,
Eq.( 383 ), as

  -- -------- -- -------
     @xmath      (396)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (397)
  -- -------- -- -------

Since

  -- -------- -- -------
     @xmath      (398)
  -- -------- -- -------

after a time

  -- -------- -- -------
     @xmath      (399)
  -- -------- -- -------

@xmath will be a Wigner function, and thus @xmath will be positive
because it is equal to the convolution of two Wigner functions. Here
@xmath is the localisation time.

This is a useful result. Expressing the current Eq.( 391 ) in this new
notation,

  -- -------- -- -------
     @xmath      (400)
  -- -------- -- -------

we see that after the time given in Eq.( 399 ), because @xmath the
current Eq.( 400 ) will be positive if the state consists purely of
negative momenta. This means that after this time Eq.( 390 ) will be a
positive arrival time distribution. This holds provided times involved
are much smaller than @xmath , as per the discussion below Eq.( 387 ).

Now we turn to examining the properties of the current. We wish to find
an expression for the current in the form @xmath , where @xmath is a
projector or POVM. This would allow us to express the heuristic arrival
time distribution, Eq.( 362 ), in the same form as other probabilities
in quantum theory. Starting from Eq.( 400 ) it is useful to write,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (401)
  -- -------- -------- -------- -- -------

using Eq.( 396 ). We can deconvolve the propagator into two gaussians
using Eq.( 395 ), in particular we will let @xmath , where @xmath is a
minimum uncertainty gaussian, and @xmath is the remainder.

  -- -------- -- -------
     @xmath      (402)
  -- -------- -- -------

  -- -------- -- -------
     @xmath      (403)
  -- -------- -- -------

Here @xmath is some real number. Using the convolution property Eq.( 395
) we can write the current Eq.( 400 ) as

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (404)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where @xmath is the Q-function [ 90 ] , and we have undone the change of
variables implied in Eq.( 387 ). The Q-function can be written as

  -- -------- --
     @xmath   
  -- -------- --

We can therefore express the current as,

  -- -------- -- -------
     @xmath      (405)
  -- -------- -- -------

where

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (406)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

and we have defined the POVM

  -- -------- -- -------
     @xmath      (407)
  -- -------- -- -------

which is clearly a phase space operator localised around @xmath . @xmath
is therefore a smeared version of the object used to compute the current
classically, @xmath . This holds for times

  -- -------- -- -------
     @xmath      (408)
  -- -------- -- -------

Assume for a moment that @xmath , and so @xmath . The current would then
be given by

  -- -------- -- -------
     @xmath      (409)
  -- -------- -- -------

Since the Q-function is positive by construction the current computed in
this way will be positive to the extent that the Q-function has
vanishing support on @xmath ( @xmath cannot strictly vanish for @xmath
but it can be exponentially small, and this suffices here. See the
comments below Eq.( 387 ).) For @xmath the Q-function is simply smeared
further, and this will preserve the property of positivity. In fact one
could imagine postulating Eq.( 409 ) as the definition of the arrival
time even in the unitary case, since it clearly satisfies all the
conditions required.

The probability of arriving in the interval @xmath is given by the
integral of Eq.( 405 ), and because @xmath is time dependent (via @xmath
) this will not in general have a simple form. However there is a
separation of time scales here, the time scale of evolution of @xmath is
seen from Eq.( 398 ) to be @xmath . So, if @xmath we have approximately

  -- -------- -- -------
     @xmath      (410)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (411)
  -- -------- -- -------

is a POVM representing arrival at @xmath between @xmath and @xmath .
Compare this expression with Eq.( 362 ), which may be written,

  -- -------- -- -------
     @xmath      (412)
  -- -------- -- -------

The two expressions are very similar, but crucially Eq.( 411 ) is
positive for @xmath (ie @xmath ). In this case therefore, the effect of
the environment is simply to smear the unitary result over a region of
phase space, given by @xmath computed at @xmath .

Eqs.( 410 ) and ( 411 ) form the first significant result of this
chapter. Eq.( 410 ) expresses the heuristic arrival time distribution,
Eq.( 362 ), as the trace of an operator times a POVM, and thus has the
same form as standard expressions for probability in quantum theory. The
POVM, Eq.( 411 ), arises because the environment effectively measures
the system.

We have therefore discovered a range of times for which the current,
Eq.( 400 ), gives a positive arrival time distribution. After a time of
order @xmath interference effects vanish and we can regard Eq.( 400 ) as
the arrival time distribution, which can also be written in the form
Eq.( 405 ). Eventually, however, on a time scale of order @xmath the
environment causes diffusion in momentum to such an extent that the
trajectories of the particle are no longer sharply peaked around the
classical trajectory computed in the absense of an environment. Since
the particle is still behaving classically after this time there will
exist an arrival time distribution of the form Eq.( 364 ), but our
simpler expression Eq.( 400 ) will no longer be a good approximation to
this. It is easy to show that @xmath where @xmath is the energy of the
initial state, and thus these expressions are valid for an large
interval if @xmath .

### 41 The Decoherent Histories Approach to the Arrival Time Problem

We turn now to the question of defining arrival times for open systems
via decoherent histories. In Chapters 5 and 6 the class operators
corresponding to a first crossing of the origin in the time interval
@xmath were claimed to be

  -- -------- -- -------
     @xmath      (413)
  -- -------- -- -------

for @xmath , with @xmath and where @xmath . These clearly describe
histories which are in @xmath at times @xmath and in @xmath at time
@xmath , so, approximately, describe a first crossing between @xmath and
@xmath .

In Chapter 6 these class operators were then simplified with the help of
the following semiclassical approximation

  -- -------- -- -------
     @xmath      (414)
  -- -------- -- -------

From this we obtain the class operators for first crossing between
@xmath and @xmath as

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      (416)
  -- -------- -------- -------- -- -------

where we use the semiclassical approximation again to arrive at the last
line.

The key step in making contact with the simple heuristic result of Eq.(
362 ) was the approximation of the class operators Eq.( 413 ) by Eq.(
416 ). We now want to further explore this approximation, and prove that
it is in fact closely related to the decoherence condition. The aim here
is partly to make the the argument in Section 35 more precise and partly
to check whether the inclusion of an environment adds anything new.

For a free particle, the error in the semiclassical approximation comes
from spreading in momentum caused by the chopping of the wavepacket. We
have seen in Chapter 4 however, that for projections spaced by a time
greater than @xmath the probability of the measurements causing the
particle to be reflected is very low.

We want to find some way of quantifying the error induced by this
approximation, for this purpose it is sufficient to consider the
approximation as used to go from Eq.( 41 ) to Eq.( 416 ). Writing this
in terms of the density matrix,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

where the last line defines the semi-classical approximation. Noting
that, with @xmath

  -- -------- -- -------
     @xmath      (417)
  -- -------- -- -------

A sufficient condition for the validity of the semi-clasical
approximation is therefore that the object

  -- -------- -- -------
     @xmath      (418)
  -- -------- -- -------

is much smaller than 1 for all @xmath .

Now assume for a moment that the semiclassical approximation holds, so
that the class operators are given by Eq.( 416 ). The probability of
first crossing between @xmath and @xmath is given by

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

However since we are assuming that the semi-classical approximation
holds, the last three terms cancel and we obtain

  -- -------- --
     @xmath   
  -- -------- --

Furthermore, consider a general off-diagonal term in the decoherence
functional, where without loss of generality we take @xmath

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (419)
                                @xmath   
  -- -------- -------- -------- -------- -------

We see that this vanishes if the semi-classical approximation holds.

What we have shown therefore, is that the semi-classical condition and
the decoherence conditions are closely related. If the object given in
Eq.( 418 ) is much smaller than 1 then both conditions are satisfied.
This means firstly that the class operators are approximately given by
Eq.( 416 ) and secondly that the histories described by these class
operators are approximately decoherent.

In general, the probabilities for time of arrival as computed by
decoherent histories differ from the heuristic ones obtained by the
standard quantum mechanical analysis. We don’t expect agreement since,
as discussed in the Introduction to this chapter, the heuristic formula,
Eq.( 362 ), is not in general of the canonical form required for genuine
quantum mechanical probabilities. It is also the case that decoherent
histories only ascribes probabilities to certain sets of histories.
However if the object @xmath is small, then we have shown that the
decoherent histories analysis reproduces the probabilities computed in
the standard, heuristic, way.

As well as clarifying the analysis of [ 50 ] and Chapter 6, note that
all of the statements above apply to the case of a particle coupled to
an environment. In this case the trace is to be taken over the system
and environment, and @xmath is a projection onto the degrees of freedom
of the system, @xmath , tensored with the identity operator on the
environmental degrees of freedom, @xmath . This is the case of interest
in this chapter.

Since the object @xmath plays a central role in our analysis it is
interesting to ask if it has any physical interpretation. The answer is
that it does. Recall that our class operator for crossing between @xmath
and @xmath is given by Eq.( 416 ). In Chapter 6 Eq.( 343 ) we noted that

  -- -------- -- -------
     @xmath      (420)
  -- -------- -- -------

The approximation leading from Eq.( 41 ) to Eq.( 416 ) is equivalent to
dropping the second term on the right hand side of Eq.( 420 ). The error
in this approximation can be estimated by computing the probability
associated with the class operator @xmath . We see

  -- -------- --
     @xmath   
  -- -------- --

However Eq.( 420 ) has a simple physical interpretation: it is the
decomposition of the total current into right and left moving parts. The
object @xmath is therefore just the probability associated with the
right moving current. Classically this is small by construction, since
we will choose to work with wavepackets tightly peaked in negative
momentum. Quantum mechanically however this term need not be small,
indeed the existence of the backflow effect [ 12 ] shows that this term
can sometimes be larger than the left moving current, even for
wavepackets composed entirely of negative momenta.

The semiclassical condition we are imposing, and by extension the
decoherence condition, is therefore stronger than the condition for the
current to be positive. Decoherence requires the absence of interference
between crossings at different times, whilst the standard heuristic
analysis includes some interference effects, provided they are not so
large as to render the arrival time probabilities negative. This is a
consequence of the fact that although for a suitably semiclassical state
histories peaked about the classical trajectories are decoherent, the
set of sets of decoherent histories contains many more histories than
simply the classical ones. The significance of this will be explored
elsewhere.

### 42 Decoherence of Arrival Times in Quantum Brownian Motion

#### 42.1 General Case

In the previous section we have shown that an arrival time distribution
may be derived from decoherent histories and that it agrees with the
current provided there is decoherence. We therefore turn now to the
question of determining for which states and intervals decoherence is
achieved. Recall that our aim is to show that the inclusion of an
environment gives rise to decoherence of arrival time probabilities for
generic initial states of the system. We will start our decoherent
histories analysis with a discussion of the general case considered in
Ref. [ 54 ] , but most of our detailed results will concern the
near-deterministic limit discussed in the introduction and in the
discussion of the Wigner function above.

The decoherence functional may be written in path integral form as

  -- -------- -- -------
     @xmath      (421)
  -- -------- -- -------

where @xmath represent the restriction to paths that are, for example,
in @xmath at @xmath and in @xmath at @xmath . @xmath is the
Feynman-Veron influence functional phase which summarises the effect of
the environment, and is given in the case of negligible dissipation by

  -- -------- -- -------
     @xmath      (422)
  -- -------- -- -------

It is this phase which is responsible for the suppression of
interference between paths @xmath and @xmath that differ greatly, and
produces decoherence.

The decoherent histories analysis we are about to perform was first
attempted by Halliwell and Zafiris in Ref. [ 54 ] . Their conclusions
are reasonable, but the analysis leading to them in fact contains a
small error. This error arose due to a lack of appreciation of the role
of the Zeno effect, as discussed in the Introduction. We aim to show
here how the analysis may be modified in line with the treatment of the
arrival time problem presented here and in Ref. [ 50 ] .

We start from the expression for the density matrix for states that do
not cross the origin in a time interval @xmath (Ref. [ 54 ] , Eq.(4.34))

  -- -------- -- -------
     @xmath      (423)
  -- -------- -- -------

Here the restriction is interpreted as @xmath at times @xmath . The
probability that the state does not cross the origin in this interval is
then given by the trace of this expression. There are two interesting
limits to be taken here. The first is letting @xmath , and this recovers
the notion of the restricted propagator. The second limit is that of
strong decoherence effects, so that we can assume that the path integral
is tightly peaked in @xmath , this recovers the classical limit. The
claim in Ref. [ 54 ] is that we can take these limits simultaneously. To
see why this is problematic we write the restricted path integral as a
product of propagators,

  -- -------- -- -------
     @xmath      (424)
  -- -------- -- -------

where @xmath , @xmath , @xmath . Changing variables to @xmath , @xmath
gives

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (425)
                                @xmath   
  -- -------- -------- -------- -------- -------

Now in order for the product of propagators to be equal to a restricted
propagator, we need to take @xmath . However to recover the classical
result we need to replace the limits of integration for @xmath with
@xmath , which requires that @xmath where @xmath is some length scale.
Clearly these two limits are incompatible for finite @xmath .

We see the difficulty here immediately, trying to take @xmath will lead
to the Zeno effect. We know from Chapter 4 that for a free particle
projections separated by times greater than @xmath will not give rise to
the Zeno effect, but the issue is more subtle here, since we have
non-unitary evolution. One would expect that the time scale on which
projections give rise to reflection to be reduced in the present case,
since a generic system coupled to an environment tends to display
classical behavior and the Zeno effect should vanish in the classical
limit. The claim in Ref. [ 54 ] is essentially (although they did not
express it in this way), that the inclusion of the environment is enough
to eliminate the Zeno effect entirely. This seems unlikely to be true.
This issue will be taken up elsewhere [ 52 ] . The more general point is
that it is not possible to take @xmath and still get a good account of
arrival times, we should always expect to have to settle for some
minimum resolution. For the purposes of recovering classical behaviour,
however, this is of no significance, since the timescale on which a
classical “wavepacket” would cross the origin is @xmath and this is much
longer than @xmath . We therefore do not loose anything classically by
leaving @xmath small but not zero.

In any case it seems clear that there exists a short timescale on which
we can still approximate the limits in the @xmath integrals above in the
manner indicted, but that is short enough to give non-trivial crossing
probabilities. Following the steps in Ref. [ 54 ] then gives

  -- -------- -- -------
     @xmath      (426)
  -- -------- -- -------

where the Wigner function, @xmath obeys,

  -- -------- -- -------
     @xmath      (427)
  -- -------- -- -------

where @xmath is the “restricted” propagator, defined by

  -- -------- -- -------
     @xmath      (428)
  -- -------- -- -------

with @xmath . However because we are now dealing with an essentially
classical system, this propagator is well approximated by its continuum
limit. Understood in this sense, we see that the conclusions of Ref. [
54 ] are in fact correct, even if the argument leading to them is not.
The interesting subtleties that arise in this argument relate to the
classical limit of the Zeno effect, this will be explored elsewhere [ 52
] .

As important as this general case is, it is of interest to examine the
simpler case of near-deterministic evolution, where the classical limit
of the arrival time probability is simply expected to be the time
integral of the current density. The analysis in this case simplifies
considerably and we will explicitly exhibit decoherence of histories for
suitable intervals.

#### 42.2 The Near-Deterministic Limit

We have previously seen that, in the near-deterministic limit, if there
is decoherence then the arrival time probabilities derived from
decoherent histories agree with those computed from the current. We
therefore turn now to discussing the conditions under which we have
decoherence of crossing probabilities. The general picture we have in
mind is illustrated in Fig.( 15 ), we have an initial wavepacket defined
at @xmath , evolved in the presence of an environment until time @xmath
, and then we wish to compute the probability of crossing between @xmath
and @xmath .

Our task is to compute the off-diagonal elements of Eq.( 421 ), and this
will be rather involved in general. However we are saved from having to
do this by the observation in Section 41 about the relation between the
semiclassical condition and the decoherence condition. It suffices
therefore to compute the quantity @xmath defined in Eq.( 418 ), in the
presence of an environment. We anticipate that this will be small simply
from the form of Eq.( 421 ). This is because the effect of the
environment is to cause the density matrix to become tightly peaked
around the classical path and classically, for @xmath the probability
given by @xmath is zero. We will see how this works in a specific
example below.

We take @xmath without loss of generality, and we drop the subscript
from now on

  -- -------- -- -------
     @xmath      (429)
  -- -------- -- -------

where the histories @xmath are those that start at @xmath and finish at
@xmath . In terms of the density matrix propagator, Eq.( 381 )

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

Transforming to new variables

  -- -------- -- -------
     @xmath      (430)
  -- -------- -- -------

and writing the density matrix in terms of the Wigner function via

  -- -------- -- -------
     @xmath      (431)
  -- -------- -- -------

we obtain

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (432)
                                @xmath   
  -- -------- -------- -------- -------- -------

We see from this expression that there is a time scale, @xmath , set by
the environment on which localisation effect are important. This
timescale is the same as that on which the current becomes positive, as
we saw earier.

There are three cases to explore here, the first is where there is no
environment, @xmath . This is the case covered in Ref. [ 49 ] . The
second case is the intermediate one, @xmath but @xmath . This is the
most general case in which we can expect to have environmentally induced
decoherence. The final case is where @xmath . This is the case of very
strong environmental coupling.

For the free case, @xmath the integrals over @xmath and @xmath in Eq.(
432 ) may be carried out to give,

  -- -------- -- -------
     @xmath      (433)
  -- -------- -- -------

where

  -- -------- -- -------
     @xmath      (434)
  -- -------- -- -------

This expression for @xmath is now identical to Eq.( 307 ) of Chapter 5
and the same conclusions apply. We briefly repeat the analysis here
however, since it turns out to be relevant for the second case.

We note firstly that @xmath . Now we assume that our state at @xmath is
of the form

  -- -------- -- -------
     @xmath      (435)
  -- -------- -- -------

and that @xmath is large, so the state is tightly peaked in momentum. We
can therefore integrate out @xmath , setting @xmath to obtain,

  -- -------- -- -------
     @xmath      (436)
  -- -------- -- -------

In Chapter 5 it was noted that this type of integral is dominated by
values of @xmath for which

  -- -------- -- -------
     @xmath      (437)
  -- -------- -- -------

providied that @xmath , and in this range the exponential term is
approximately constant. We can approximate this integral then by
intergrating from @xmath to @xmath , taking @xmath in the exponential
term and approximating,

  -- -------- -- -------
     @xmath      (438)
  -- -------- -- -------

This gives

  -- -------- -- -------
     @xmath      (439)
  -- -------- -- -------

there will therefore be decoherence for gaussian wavepackets tightly
peaked in momentum, provided their momentum is such that @xmath , ie
@xmath . In Chapter 5 it was argued that this conclusion also holds for
orthogonal superpositions of gaussians.

Turning to the intermediate case, since @xmath we can set @xmath in Eq.(
432 ) and we obtain Eq.( 433 ) again. Now however, @xmath is the initial
state evolved with an environment, and since @xmath this should be
significant. To proceed we write the Wigner function at time @xmath in
terms of the initial state at @xmath using Eq.( 383 )

  -- -------- -- -------
     @xmath      (440)
  -- -------- -- -------

  -- -------- -- -------
     @xmath      (441)
  -- -------- -- -------

Because the Wigner function propagator is a gaussian the analysis is
similar to the first case. Recall that we are assuming @xmath and so
@xmath , this means we can integrate out @xmath , setting @xmath . This
gives us

  -- -------- -- -------
     @xmath      (442)
  -- -------- -- -------

where, @xmath are defined in Eq.( 385 ). Now,

  -- -------- -- -------
     @xmath      (443)
  -- -------- -- -------

implies that

  -- -------- -- -------
     @xmath      (444)
  -- -------- -- -------

so that for @xmath , @xmath . This means, again like the case of @xmath
, that the exponential term is roughly constant compared to @xmath .
Since we have @xmath , we follow the same procedure as the @xmath case,
arriving finally at

  -- -------- -- -------
     @xmath      (445)
  -- -------- -- -------

The value of @xmath now depends on the relationship between the width of
the initial state @xmath and @xmath . However we can obtain an upper
bound by ignoring the effects of the exponential term in @xmath , this
gives

  -- -------- -- -------
     @xmath      (446)
  -- -------- -- -------

Finally we have the case of strong system-environment coupling. Since
@xmath the integral over @xmath in Eq.( 432 ) will be peaked around
@xmath , and we can therefore extend the limits of integration to @xmath
. This integral and the one over @xmath may then be carried out and we
obtain

  -- -- -- -------
           (447)
  -- -- -- -------

where @xmath is the complementary error function [ 2 ] . For large
positive values of the argument we have that,

  -- -------- -- -------
     @xmath      (448)
  -- -------- -- -------

Therefore, since the Wigner function is peaked around @xmath , @xmath
will be very small, provided @xmath . This gives us an upper bound on
the time interval, @xmath , rather than a lower one. The lower time
scale is provided by the condition @xmath . This lower time scale is
compatible with the condition that the current be positive.

Note however that this lower limit is state independent. There will be
states for which arrival time probabilities decohere on much shorter
time scales than this, for example the simple cases which decohere in
the absence of any environment will continue to do so in the presence of
an environment, at least until a time @xmath .

The key point is that whether or not one can assign arrival time
probabilities in decoherent histories depends on the form of the state
at the time it crosses the origin. Environmentally induced decoherence
produces mixtures of gaussian states from generic initial ones and thus,
after a short time, arrival time probabilities can be defined whatever
the initial state. Crucially however it is not necessary for the system
to be monitored whilst it is crossing the origin. The smallest time
interval, @xmath , over which we can define a decoherent arrival time
probability is therefore set by the energy of the system and not the
details of the environment and we must have @xmath . This is in
agreement with Chapter 5 and Ref. [ 49 ] , and also with the results of
earlier works, concerning the accuracy with which a quantum system may
be used as a clock [ 88 ] .

In conclusion then, for a general state, decoherence of histories
requires that we evolve for a time much greater than @xmath before the
first crossing time. This is because this is the time scale on which
quantum correlations disappear and our initial state begins to resemble
a mixture of gaussian states. After this time, we may define arrival
time probabilities to an accuracy @xmath , provided only that @xmath .
States which start as gaussians may be assigned arrival time
probabilities without this initial period of evolution. This is in line
with the general result that some coarse-graining is always required to
achieve a decoherent set of histories in quantum theory.

### 43 Summary and Discussion

In this chapter we have been concerned with deriving an arrival time
distribution for open quantum systems and comparing this with the
classical result. We began by discussing the generalisation of the
current, which is the classical arrival time distribution, to open
quantum systems and in particular to the case of quantum Brownian
motion. We found that in general the inclusion of an environment leads
to extra terms appearing in the expressions for the current, compared
with the those valid in the unitary case. However we have shown that in
the limit of negligible dissipation these correction terms may be
dropped. We then explored the resulting arrival time distribution and
showed that it is non-negative after a time of order @xmath and that
after this time it can be written as the trace of the density matrix
times a POVM.

We then turned to the question of deriving this arrival time
distribution from the decoherent histories approach to quantum theory.
We extended the decoherent histories analysis of the arrival time
problem to the case of a particle coupled to an environment. As
expected, the inclusion of an environment produces decoherence of
arrival time probabilities for a generic initial state. There are,
however, some limitations to the permitted class of histories. For a
generic state arrival times can only be specified after an initial time
@xmath . Even after this time arrival times cannot be specified with
arbitrary precision, coarse graining over intervals @xmath is required
to ensure decoherence. We showed that the decoherence condition is very
closely related to a semiclassical approximation for the evolution of
the state, and that both conditions are satisfied if the time between
projections is sufficiently large. This is a specific case of a more
general connection between decoherence and classical behavior.

Our approach has proceeded at two levels. At the heuristic level the
simple generalisation of Eq.( 363 ) to the case of a particle coupled to
an environment, Eq.( 400 ), is a positive arrival time distribution
after a time of order @xmath . This can also be written as the
expectation value of a POVM, Eq.( 405 ), and thus has the same form as
other probabilities in quantum theory. On a more fundamental level,
these expressions can be derived from the decoherent histories approach
to quantum theory, where they are seen to be valid for times much later
than @xmath .

Although the arrival time probabilities computed from decoherent
histories agree with the heuristic ones when we have decoherence, their
derivation in this way represents a significant advance in our
understanding. The great difficulty with regarding the current as the
arrival time distribution is the arbitrary way in which one accepts
these “probabilities” when they are positive, but declines to do so when
they are not. Because decoherence is an essential part of the histories
formalism, this arbitrariness is replaced with a consistent set of rules
governing when probabilities may or may not be assigned. Whilst this may
be of no consequence in the setting of a laboratory, it may prove hugely
important in the analysis of closed systems, in particular the study of
quantum cosmology [ 47 ] .

Another very interesting result we have presented is that the current
becomes strictly positive after a finite time whilst assignment of
probabilities in decoherent histories is only possible asymptotically.
In some ways this difference between the heuristic analysis and
decoherent histories is to be expected. Indeed, the current represents a
linearly positive history [ 35 ] , and it is essentially the condition
of linear positivity that we have proven holds after a time of order
@xmath . It is known that linear positivity is a weaker condition than
decoherence [ 60 , 46 ] , and thus it is not surprising that demanding
decoherence leads to a stricter limit on the assignment of probabilities
than the heuristic analysis. It would be interesting to examine what is
gained in this context by imposing decoherence rather than linear
positivity.

There are similarities here with the relationship between the current
and Kijowski’s arrival time distribution [ 68 ] , which may be shown to
agree in the classical limit, but not more generally. Indeed because it
is manifestly positive, one might expect the arrival time distribution
computed from decoherent histories to be more closely related to
Kijowski’s distribution on shorter time scales. These issues will be
discussed elsewhere.

## Chapter \thechapter Quantum Arrival and Dwell Times via an Ideal
Clock

  But what minutes! Count them by sensation, and not by calendars, and
  each moment is a day.

  Benjamin Disraeli

### 44 Introduction

#### 44.1 Opening Remarks

So far in this thesis we have been concerned with defining time
observables without reference to the specific mechanisms by which they
might be measured. This is of course reasonable, we do not need to
specify the means by which the position of a particle is to be measured,
for example, to be able to state that the probability distribution for
finding it at a given point @xmath at time @xmath is @xmath . However
since obtaining a satisfactory definition of these observables has
proven rather tricky, it is worth asking to what extent the ideal
quantities we have been discussing so far are related to the measured
quantities obtained in some particular measurement set up. As well as
this, we mentioned in Chapter 1 that one way of defining time
observables was via a particular measurement model. The basic theory is
outlined in Section 1.5, we look for an arrival or dwell time
distribution of the form Eq.( 27 ), and then try to extract the ideal
distribution which is independent of the measurement model. In this
chapter we use a clock model to define arrival and dwell times and
compare the results with standard semiclassical expressions.

#### 44.2 Dwell Time

Although we have talked at length in this thesis about the arrival time
problem, we have not so far mentioned the dwell time problem in any
detail. Since we will use our model clock in this chapter to look at
both arrival and dwell times, it is useful to summerise some basic facts
about dwell time here. For more details see Ref. [ 83 ] .

The dwell time distribution is the probability @xmath that the particle
spends a time between @xmath in the interval @xmath . One approach to
defining this is to use the dwell time operator,

  -- -------- -- -------
     @xmath      (449)
  -- -------- -- -------

where @xmath is the characteristic function of the region @xmath [ 83 ]
. Since @xmath is self-adjoint the distribution @xmath can then be
written as

  -- -------- -- -------
     @xmath      (450)
  -- -------- -- -------

In the limit @xmath , where @xmath is the momentum of the incoming
state, the dwell time operator has the approximate form @xmath so that
the expected semiclassical form for the dwell time distribution is

  -- -------- -- -------
     @xmath      (451)
  -- -------- -- -------

This is the form against which we shall compare our clock model.

#### 44.3 Clock Model

In this chapter we will derive arrival and dwell time distributions by
coupling the particle to a model clock. We denote the particle variables
by @xmath and those of the clock by @xmath . We denote the initial
states of the particle and clock by @xmath , @xmath , respectively, and
the total system state by @xmath . We couple this clock to the particle
via the interaction @xmath . The total Hamiltonian of the system plus
clock is therefore given by,

  -- -------- -- -------
     @xmath      (452)
  -- -------- -- -------

where @xmath is the Hamiltonian of the particle. Here @xmath is the
characteristic function of the region where we want our clock to run, so
that @xmath for the arrival time problem and @xmath for the dwell time
problem. The operator,

  -- -------- -- -------
     @xmath      (453)
  -- -------- -- -------

describes the details of the dynamics of the clock and we assume that it
is such that the clock position @xmath is the measured time. The
physical situation is depicted in Figure ( 16 ).

For the moment we will assume only that the clock Hamiltonian is self
adjoint, so that it may be written in the following form,

  -- -------- -- -------
     @xmath      (454)
  -- -------- -- -------

where the @xmath form an orthonormal basis for the Hilbert space of the
clock. Later on we will restrict @xmath further by considering the
accuracy of the clock. We will also quote some results for the special
choice of @xmath , whose action is to simply shift the pointer position
@xmath of the clock in proportion to time. This is the simplest and most
frequently used choice for the clock Hamiltonian. The physical relevance
of this and other clock models is discussed in Refs. [ 71 , 88 ] .

Our aim, for both arrival and dwell times, is to first solve for the
evolution of the combined system of particle and clock. We write this as

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (455)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

and we then solve for the propagator in the integrand using path
integral methods. We will take the total time @xmath to be sufficiently
large that the wave packet has left the region defined by @xmath . We
will then compute the final distribution of the pointer variable @xmath
, which is

  -- -------- -- -------
     @xmath      (456)
  -- -------- -- -------

Our main aim is to show that the predictions of the clock model Eq.( 456
) reduce, in certain limits, to the standard forms described above. Our
main tools in solving Eq.( 455 ) will be those we have used throughout
this thesis, namely the path decomposition expansion and the
semiclassical approximation it suggests. These results are covered in
Chapter 2.

#### 44.4 Connections to Earlier Work

Clock models of the type Eq.( 452 ) for arrival and dwell times have
been studied by numerous previous authors, including Peres [ 88 ] ,
Aharanov et al [ 4 ] , Hartle [ 58 ] and Mayato et al [ 71 ] . These
studies are largely focused on the characteristics of clocks. Refs. [ 88
, 4 ] are the works perhaps most closely related to the present work.
They concentrate on the case of a clock Hamiltonian linear in momentum,
with some elaborations on this basic model in the case of Ref. [ 4 ] .
Here, we focus on a different issue not addressed by these works, namely
the dependence of the distribution Eq.( 456 ) on the initial state of
the particle, for reasonably general clock Hamiltonians. In particular,
we determine the extent to which the standard semiclassical forms
derived above are obtained for general initial states of the particle.
We also use path integral methods to perform the calculations, in
contrast to the scattering methods used in most of the previous works.

#### 44.5 This Chapter

The rest of this chapter is arranged as follows. In Section 45 we
compute Eqs.( 455 ), ( 456 ) for the arrival time problem, and similarly
in Section 46 for the dwell time problem. We conclude in Section 47 .
This chapter is based on Ref. [ 101 ] .

### 45 Arrival Time Distribution from an Idealised Clock

We now turn to the calculation of the arrival time distribution, Eq.(
456 ), recorded by our model clock. Using the path decomposition
expansion in the form Eq.( 59 ) the state of the system Eq.( 455 ) can
be written as,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (457)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

We can simplify this expression in two different regimes, the weak
coupling regime of @xmath , and the strong coupling regime of @xmath .

#### 45.1 Weak Coupling Regime

In the limit @xmath we can make use of the semiclassical approximation
to the PDX formula. This yields,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (458)
                                @xmath   
  -- -------- -------- -------- -------- -------

This means that the arrival time distribution is

  -- -------- -------- -- -------- -------
     @xmath   @xmath               (459)
                          @xmath   
                          @xmath   
  -- -------- -------- -- -------- -------

To proceed, we first note that for any operator @xmath , we have

  -- -------- -- -------
     @xmath      (460)
  -- -------- -- -------

Using this in Eq.( 459 ) gives,

  -- -------- -------- -- -------- -------
     @xmath   @xmath               (461)
                          @xmath   
                          @xmath   
  -- -------- -------- -- -------- -------

We see here the appearance of the combination @xmath , and the main
challenge is to show how this turns into the current operator, @xmath .

Next we rewrite the integrals using

  -- -------- -- -------
     @xmath      (462)
  -- -------- -- -------

In the first term we set @xmath , @xmath , and in the second we set
@xmath , @xmath to obtain,

  -- -------- -------- -------- --
     @xmath   @xmath            
                       @xmath   
                       @xmath   
  -- -------- -------- -------- --

Since we take the time @xmath to be large, we can extend the upper
limits of the integrals to infinity. The integral over @xmath can then
be carried out, to give,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            
                       @xmath            
     @xmath   @xmath   @xmath            (464)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where

  -- -------- -- -------
     @xmath      (465)
  -- -------- -- -------

is the wavefunction of the clock, and @xmath is the current, Eq.( 22 ).

This form shows that, in the weak coupling limit, our arrival time
probability distribution yields the current, but smeared with a function
depending on the clock state. We thus get agreement with the expected
result, Eq.( 27 ). Note that the physical quantity measured, the
current, is not affected by the form of the clock Hamiltonian.

Although the form Eq.( 464 ) holds for a wide class of clock
Hamiltonians, not all choices make for equally good clocks. To further
restrict the coupling @xmath we require that different arrival times may
be distinguished up to some accuracy @xmath . For this to be the case we
require that the clock wavefunctions corresponding to different arrival
times are approximately orthogonal, so that

  -- -------- -- -------
     @xmath      (466)
  -- -------- -- -------

We easily see that,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (467)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where @xmath . Clearly this expression is equal to 1 if @xmath . Suppose
now that @xmath is peaked around some value @xmath with width @xmath .
This integral will approximately vanish if

  -- -------- -- -------
     @xmath      (468)
  -- -------- -- -------

and so the resolution of the clock is given by @xmath . The relationship
between @xmath and the pointer variable @xmath will depend on the
specific model. It is easily seen that a clock with good characteristics
may be obtained using, for example, a free particle with a Gaussian
initial state. But clocks with more general Hamiltonians can also be
useful if they evolve an initial Gaussian along an approximately
classical path (as many Hamiltonians do). See Refs. [ 88 , 4 , 58 , 71 ]
for further discussion of clock characteristics.

For the special case @xmath , @xmath , the expression for the arrival
time distribution simplifies, since

  -- -------- -- -------
     @xmath      (469)
  -- -------- -- -------

The time is related to @xmath by @xmath and the expected form Eq.( 27 )
then becomes a simple convolution.

#### 45.2 Strong Coupling Regime

##### 45.2.1 Special Case: @xmath

We now turn to the limit of strong coupling between the particle and
clock. The analysis of the case of general clock Hamiltonian is rather
subtle, so before we tackle this we first examine the special case where
the clock Hamiltonian is linear in the momentum. That is, we have,

  -- -------- -- -------
     @xmath      (470)
  -- -------- -- -------

We start from Eq.( 457 ), and insert a complete set of momentum states
for the particle, @xmath to obtain,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (471)
                                @xmath   
  -- -------- -------- -------- -------- -------

where @xmath is the initial momentum space wavefunction of the clock,
and @xmath is the kinetic energy of the particle. Note the appearance of
the momentum @xmath in the integrand. The expression involving the
integral over @xmath has been computed previously using the final
crossing PDX [ 41 , 49 ] . In the limit @xmath it is given by,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

We can now write our probability distribution for @xmath . Carrying out
the @xmath integral we obtain,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (472)
                                @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

Using the formula @xmath , we can carry out the @xmath integral to give,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      
              @xmath   @xmath      
              @xmath   @xmath      (474)
  -- -------- -------- -------- -- -------

where @xmath is some constant whose explicit form is not required, and
we have used the fact that @xmath . We see therefore that in this limit
the probability of finding the clock at a position @xmath is given by
the kinetic energy density of the system at the time @xmath , in
agreement with Eqs.( 25 ) and ( 26 ).

Note that there is no response function involved in this case, as one
might have expected from the general form Eq.( 27 ). (A similar feature
was noted in the complex potential model of Ref. [ 41 ] ). It seems
likely that this is because the strong measurement prevents the particle
from leaving @xmath until the last moment, so that the response function
@xmath is effectively a delta-function concentrated around the latest
time.

##### 45.2.2 General Case

As well as the approximations valid for @xmath , the key to the analysis
in the special case presented above is that the position space
eigenfunction of the clock Hamiltonian with eigenvalue @xmath takes the
simple form,

  -- -------- -- -------
     @xmath      (475)
  -- -------- -- -------

This greatly simplifies the resulting calculation. For the case of a
more general clock Hamiltonian, the eigenstates will not have this
simple form. Instead we make a standard WKB approximation for the
eigenstates of the clock,

  -- -------- -- -------
     @xmath      (476)
  -- -------- -- -------

where @xmath is the Hamilton Jacobi function of the clock at fixed
energy. This means Eq.( 45.2.1 ) becomes,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (477)
                       @xmath   @xmath   
                                @xmath   
  -- -------- -------- -------- -------- -------

where we have used,

  -- -------- -- -------
     @xmath      (478)
  -- -------- -- -------

which is valid for @xmath .

We now suppose that the clock state is a simple Gaussian in @xmath , or
equivalently in @xmath . It follows that it will be peaked in @xmath
about some value @xmath . This means that the integral over @xmath in
Eq.( 477 ) may be carried out. The result for @xmath will again be
proportional to the kinetic energy density, of the form Eq.( 25 ), where
the relationship between @xmath and the pointer variable @xmath is
defined by the equation

  -- -------- -- -------
     @xmath      (479)
  -- -------- -- -------

as one might expect from Hamilton-Jacobi theory [ 34 ] . Hence the
arrival time distribution has the expected general form, Eq.( 25 ) (and
therefore Eq.( 26 ) also holds), but the precise definition of the time
variable depends on the properties of the clock.

### 46 Dwell Time Distribution from an Idealised Clock

We now turn to the related issue of dwell times. Here the aim is to
measure the time spent by the particle in a given region of space which,
for simplicity, we take to be the region @xmath . This is portrayed in
Figure ( 17 ). In this section we will work exclusively in the weak
coupling regime where @xmath .

The starting point is the final state of the particle plus clock, Eq.(
455 ), which we write as

  -- -------- -- -------
     @xmath      (480)
  -- -------- -- -------

where @xmath . We wish to re-express this using the path decomposition
in a similar way to Eq.( 457 ). For this case we need a PDX which is
more general than the one used for the arrival time, since there are now
crossings of two surfaces. One way to proceed is to use the path
integral expression for the first crossing of @xmath and @xmath , which
is

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                       @xmath   
  -- -------- -------- -------- --

This is shown in Figure ( 18 ).

However there are other choices we could make. We could consider the
first crossing of @xmath and the last crossing of @xmath for example. In
the semiclassical limit these choices lead to equivalent expressions for
the dwell time. It would be interesting to explore what differences do
arise in other regimes. This will be addressed elsewhere.

It will prove more useful to work with the wavefunction in position
space for the clock and momentum space for the particle. Changing to
this representation, and making use of the semiclassical approximation
we obtain,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (481)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

Now we make the standard scattering approximation of letting the upper
limits of the integrals go to infinity. This means we can carry out the
@xmath and @xmath integrals to obtain,

  -- -------- -------- -------- -- -------
     @xmath   @xmath   @xmath      (482)
  -- -------- -------- -------- -- -------

where we have used the standard integral [ 49 ] ,

  -- -------- -- -------
     @xmath      (483)
  -- -------- -- -------

and

  -- -- -- -------
           (484)
  -- -- -- -------

Here, we have neglected the term involving @xmath since this corresponds
to reflection, which will be negligible in this semiclassical limit. We
have also use the fact that @xmath . We therefore obtain the
distribution for @xmath as,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (485)
                       @xmath   @xmath   
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

where,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (486)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

is the clock wavefunction. We may rewrite this as

  -- -------- -- -------
     @xmath      (487)
  -- -------- -- -------

It is therefore of precisely the desired form, Eqs.( 451 ), ( 27 ), with
@xmath playing the role of the response function. The discussion of
clock characteristics is then exactly the same as the arrival time case
discussed in Section 3.

### 47 Conclusion

We have studied the arrival and dwell time problems defined using a
model clock with a reasonably general Hamiltonian. We found that in the
limit of weak particle-clock coupling, the time of arrival probability
distribution is given by the probability current density Eq.( 22 ),
smeared with some function depending on the initial clock wave function,
Eq.( 27 ). This is expected semiclassically, agrees with previous
studies and is independent the precise form of the clock Hamiltonian.

In the regime of strong coupling, we found that the arrival time
distribution is proportional to the kinetic energy density of the
particle, in agreement with earlier approaches using a complex
potential. The fact that two very different models give the same result
in this regime suggests that the form Eq.( 26 ) is the generic result in
this regime, independent of the method of measurement. It would be of
interest to develop a general argument to prove this. (See Ref. [ 23 ]
for further discussion of this regime).

For the case of dwell time, we have shown that the dwell time
distribution measured by our model clock may be written in terms of the
dwell time operator in semiclassical form, smeared with some convolution
function, Eqs.( 451 ), ( 27 ).

In all of these cases, the precise form of the clock Hamiltonian and
clock initial state determine the relationship between time @xmath and
the pointer variable @xmath and they determine the form of the response
function @xmath in the general form Eq.( 27 ). These are particularly
simple for the special case @xmath explored previously. However, what is
important is that, once the definition of the time variable is fixed,
the clock characteristics do not effect the form of the underlying
distributions – the @xmath in Eq.( 27 ). The @xmath are always one of
the general forms Eqs.( 22 ), ( 25 ) and ( 451 ), no matter what the
clock characteristics are. This means that these general forms will
always play central role, irrespective of how they are measured.

## Chapter \thechapter Summary and Some Open Questions

  This is the first thing
  I have understood:
  Time is the echo of an axe
  Within a wood.

  Philip Larkin

### 48 Summary

The main result presented in this thesis is an analysis of the arrival
time problem in the framework of decoherent histories. This analysis has
given us an axiomatic way of understanding how probabilities may be
assigned to this observable, as well as the conditions under which these
probabilities are meaningful. We have carried out this analysis both for
a free particle, where decoherence is achieved for a limit class of
states, and for a particle coupled to a environment, where decoherence
is achieved for a general class of states after a given time. The main
tool which allowed us to proceed was the equivalence between pulsed and
continuous measurements set out in Chapter 4. This result allows us to
construct the appropriate class operators either by writing them in
terms of complex potentials, or by giving us the confidence to use
semiclassical approximations provided the energies and times involved
satisfy the conditions laid out in Chapters 4 and 5. The major advance
achieved compared to previous work is a decoherent histories based
framework that respects the Zeno limit. In addition we have also shown
how the semiclassical, heuristic formulae may be derived from framework.
In Chapter 8 we also demonstrated that the probabilities obtained via
decoherent histories agree with those computed from model clocks. This
general scheme of decoherent histories, using path integral methods and
complex potentials to define class operators, seems to be general enough
to encompass any time observable in quantum theory. We encourage the
reader to test this for themselves.

### 49 Open Questions and Future Work

We list here, with some short comments, a few obvious questions which
arise from the work presented in this thesis, but which time constraints
have prevented the author from studying in any depth. The majority of
these questions would form the basis of interesting further study.

#### Decoherent Histories Analysis of the Dwell Time Problem

The most obvious question one might ask of the work presented here is
whether it can be extended to cover other time observables. The most
obvious such extension would be to the definition of dwell times. Dwell
times were discussed very briefly in Chapter 8 where they were defined
using a model clock, but no attempt has been made here to perform a
decoherent histories analysis. The key step in carrying this out lies in
the construction of the relevant class operators. One might imagine
doing this either via the introduction of a suitable complex potential
or potentials in the manner of Chapter 5, or via some semiclassical
approximation in the manner of Chapter 6. What is particularly
interesting about the dwell time problem is that there exists a
relatively straightforward operator formalism, see Ref. [ 83 ] , and it
is not clear at the moment how the decoherent histories analysis fits in
with this.

#### Quantum Zeno Effect for Open Systems

Another topic which we touched on briefly in Chapter 7 was the
occurrence of the quantum Zeno effect in an open system. Whilst we
studied the evolution of a particle undergoing continuous measurement in
detail in Chapter 4, it seems at first sight a difficult task to extend
the analysis to a particle coupled to some environment. As we pointed
out in Chapter 7, this is an important question since it is the Zeno
effect that limits the accuracy with which we can define time
observables in quantum theory. On the face of it one might expect that
the Zeno effect should somehow vanish in the classical limit, so that
inclusion of an environment should reduce the “Zeno time” from @xmath .
However it is not at all obvious how this might come about, since one
generally assumes that all time scales associated with the environment
are much longer than @xmath . In part, this is related to the issues
that for a genuine step potential the reflection and transmission
coefficients, Eqs.( 68 ) and ( 70 ), do not depend on @xmath and thus
have no naive classical limit (see Chapter 2).

#### Time Observables and the Backflow Effect

Another question which we have encountered but not discussed in any
detail in this thesis concerns the role of the backflow effect in the
definition of time observables. The backflow effect causes the current
Eq.( 22 ) to be negative even when classically it should be positive,
and thus prevents decoherence of histories, see Section 29.4 . However
unlike the quantum Zeno effect, we do not have a good grasp of the time
scale on which this effect occurs. Whilst it is true that one can always
find a state which displays backflow for an arbitrarily long period of
time [ 12 ] , one suspects that for a given state this time interval is
determined by some property of the state such as the moments of the
Hamiltonian. Since it it the backflow effect and the Zeno effect that
together determine the accuracy with which time observables may be
defined, further investigation of these effects would be useful. Work on
this has already begun [ 102 ] .

## Appendix: Some Properties of the Current

We have derived the expression

  -- -------- -- -------
     @xmath      (488)
  -- -------- -- -------

as the approximate probability for crossing the origin during the time
interval @xmath , where @xmath is the usual quantum-mechanical current.
The current itself is not necessarily positive due to backflow. Here we
explore the possibility that averaging it over time might improve the
situation. On the one hand, the results of Bracken and Melloy [ 12 ]
show that there is always some state for which @xmath defined above is
negative, for any @xmath . On the other hand, for a given state, one
might hope that @xmath will be positive for sufficiently large @xmath .
Here we give a brief argument for this, which also makes contact with
the negativity of the Wigner function.

The current can be written in terms of the Wigner function @xmath as

  -- -------- -- -------
     @xmath      (489)
  -- -------- -- -------

The Wigner function evolves freely according to @xmath . We assume it
has support only on negative momentum states, with average momentum
@xmath and momentum width @xmath .

Consider a time interval @xmath over which backflow occurs. It is clear
that in order for this to occur the Wigner function must be negative for
at least some of this interval. We can write,

  -- -------- -------- -------- -------- -------
     @xmath   @xmath   @xmath            (490)
                       @xmath   @xmath   
  -- -------- -------- -------- -------- -------

So @xmath is given by the average of the Wigner function over a region
of phase space. We now recall a standard property of the Wigner function
which is that, broadly speaking, it will tend to be positive when
averaged over a region of phase space of size greater than order @xmath
(in the units used here where @xmath ). This region is of size of order
@xmath in the @xmath -direction but infinite in the @xmath -direction.
However, the Wigner function has momentum spread @xmath , so the
effective size averaged over is @xmath which is approximately the same
as @xmath . This means that we expect that @xmath will be positive as
long as

  -- -------- -- -------
     @xmath      (491)
  -- -------- -- -------

Hence, as expected, the integrated current will be positive for @xmath
sufficiently large and the key timescale is the Zeno time. This
heuristic argument will be revisited in more detail elsewhere.