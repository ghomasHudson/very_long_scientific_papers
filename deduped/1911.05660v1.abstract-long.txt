Programmability, performance portability, and resource efficiency have
emerged as critical challenges in harnessing complex and diverse
architectures today to obtain high performance and energy efficiency.
While there is abundant research, and thus significant improvements, at
different levels of the stack that address these very challenges, in
this thesis, we observe that we are fundamentally limited by the
interfaces and abstractions between the application and the underlying
system/hardware—specifically, the hardware-software interface. The
existing narrow interfaces poses two critical challenges. First,
significant effort and expertise are required to write high-performance
code to harness the full potential of today’s diverse and sophisticated
hardware. Second, as a hardware/system designer, architecting faster and
more efficient systems is challenging as the vast majority of the
program’s semantic content gets lost in translation with today’s
hardware-software interface. Moving towards the future, these challenges
in programmability and efficiency will be even more intractable as we
architect increasingly heterogeneous and sophisticated systems.

This thesis makes the case for rich low-overhead cross-layer
abstractions as a highly effective means to address the above
challenges. These abstractions are designed to communicate higher-level
program information from the application to the underlying system and
hardware in a highly efficient manner, requiring only minor additions to
the existing interfaces. In doing so, they enable a rich space of
hardware-software cooperative mechanisms to optimize for performance. We
propose 4 different approaches to designing richer abstractions between
the application, system software, and hardware architecture in different
contexts to significantly improve programmability, portability, and
performance in CPUs and GPUs: (i) Expressive Memory: A unifying
cross-layer abstraction to express and communicate higher-level program
semantics from the application to the underlying system/architecture to
enhance memory optimization; (ii) The Locality Descriptor: A cross-layer
abstraction to express and exploit data locality in GPUs; (iii) Zorua: A
framework to decouple the programming model from management of on-chip
resources and parallelism in GPUs; (iv) Assist Warps: A helper-thread
abstraction to dynamically leverage underutilized compute/memory
bandwidth in GPUs to perform useful work. In this thesis, we present
each concept and describe how communicating higher-level program
information from the application can enable more intelligent resource
management by the architecture and system software to significantly
improve programmability, portability, and performance in CPUs and GPUs.
