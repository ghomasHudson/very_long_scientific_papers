##### Contents

-    1 introduction
-    2 The Riemann-Zeta function, Parseval’s identity and the Fourier
    Series to generate @xmath
    -    2.1 Preface list of data and proof’s used in the calculations
        -    2.1.1 The Fourier Series
        -    2.1.2 Parseval’s Identity
        -    2.1.3 Proof of orthongonality in the Fourier Series
        -    2.1.4 The extraction of @xmath from the Fourier series
    -    2.2 Generating a value for @xmath (2)
    -    2.3 Generating a value for @xmath (4)
    -    2.4 Generating a value for @xmath (6)
    -    2.5 Generating a value for @xmath (8)
-    3 The Wallis Product
-    4 Continued Fractions
    -    4.1 Preface list of data and proof’s used in the calculations
        -    4.1.1 The Taylor Series
        -    4.1.2 Euler’s Continued Fraction Formula
        -    4.1.3 The Natural Logarithm in Continued Fractions
    -    4.2 A Continued Fraction for @xmath
-    5 The Gregory-Leibniz Series
    -    5.1 Preface list of data and proof’s used in the calculations
        -    5.1.1 The Taylor Series
    -    5.2 @xmath
-    6 The Newtons Series expansion of the Arcsine Function
    -    6.1 Preface list of data and proof’s used in the calculations
        -    6.1.1 The Taylor Series
    -    6.2 @xmath
-    7 Viete’s Formula with Nested Radicals
-    8 Analysis with Data Tables and Graphs of the various methods
    -    8.1 The Wallis Product
    -    8.2 The Gregory-Leibniz Series
    -    8.3 Newtons Arcsine Expansion Series for @xmath
    -    8.4 Continued Fractions for @xmath
    -    8.5 Viete’s Formula of Nested Fractions for @xmath
    -    8.6 The Zeta Function
-    9 Conclusions
    -    9.1 Conclusion: The Wallis Product
    -    9.2 Conclusion: Eulers Continued Fractions
    -    9.3 Conclusion: The Gregory-Leibniz Series
    -    9.4 Conclusion: Newtons Arcsine Series Expansion
    -    9.5 Conclusion: Vieta’s Nested Radical Formula
    -    9.6 Conclusion: The Reimann-Zeta Function
-    10 Comparisons of the different methods
    -    10.1 The Gregory-Leibniz Series VS Newtons Series: The Arcsine
        Expansion
    -    10.2 Vieta’s Nested Radicals VS Eulers Continued Fraction
    -    10.3 The Wallis Product VS Newtons Series: The Arcsine
        Expansion
    -    10.4 The Wallis Product VS The @xmath Series
    -    10.5 Newton’s Arcsine Expansion VS The @xmath Series
-    11 Appendix
    -    11.1 Mathematic Iteration code: The Wallis Product
        -    11.1.1 Mathematic Iteration code: The Wallis Product
            Percentage Error
    -    11.2 Mathematic Iteration code: The Gregory-Leibniz Series
        -    11.2.1 Mathematic Iteration code: The Gregory-Leibniz
            Series Percentage Error
    -    11.3 Mathematic Iteration code: Newtons Arcsine Expansion
        Series
        -    11.3.1 Mathematic Iteration code:Newtons Arcsine Series
            Percentage Error
-    12 Mathematic Iteration code: Continued Fractions for @xmath
    -    12.1 Mathematic Iteration code: Continued Fractions for @xmath
        Percentage Error
-    13 Mathematic Iteration code: Viete’s Nested Radicals Formula for
    @xmath
    -    13.1 Mathematic Iteration code: Viete’s Nested Radicals
        Percentage Error
-    14 Mathematic Iteration code: Zeta (2),(4),(6),(8)
    -    14.1 Mathematic Iteration code: Zeta (2),(4),(6),(8)
-    15 Bibliography

## 1 introduction

In today’s society, @xmath is used everyday by almost everyone in some
way or another. Wether it be a mathematician doing complex integrals, an
engineer calculating the volume of spherical shapes or a clock maker
designing a new pendulum for a new clock. It is clear that @xmath
underlies most of the modern day achievements and developments. However,
the reality is that only a small percentage of the population who use
this constant have any idea where it comes from.

In the beginning, Pi was first investigated using a trigonometric method
in ”250BC by the famous mathematician Archimedes” [ 7 ] who investigated
interior and exterior polygons around a circle creating both upper and
lower bounds for a value of @xmath which were then averaged to give a
value correctly to 7 decimal places [ 7 ] . Moving swiftly through the
decades, another mathematician named Vieta in 1579 used nested radicals
to further find a product of nested radicals which would converge to
@xmath and gave a value of @xmath correct to 9 deicmal places. Lastly,
with the development of calculus, rapidly converging series were
developed. A clear example of this is when newton in 1748 developed his
arcsine expansion with the Taylor Series which gave a value of @xmath
which ”only needed 22 terms for 16 decimal places for @xmath ” [ 5 ] .

However, with the mathematical knowledge we have today, there are
endless ways to arrive at this world renown constant of @xmath . From
the simplest application of this constant in the formula @xmath to
attain a value for the area of a circle to the more complex application
towards the other end of the spectrum in calculus. My research question:
“An investigation of the comparative efficiency of the different methods
in which @xmath is calculated” aims to distinguish and set aside the
different methods of calculating and approaching the value of this
constant by contrasting how efficient a variety of different numerical
methods are in calculating this constant correct to 15 decimal places.
This will be achieved by exploring different methods in which @xmath is
calculated and contrasting their rates of convergence by increasing the
amount of terms @xmath and further observing the rate at which each
method converges towards @xmath . A series of graphical displays and
Data tables will be used to calculate and compare the convergence
towards @xmath and where there is an error by comparing it to a ”True”
value.

## 2 The Riemann-Zeta function, Parseval’s identity and the Fourier
Series to generate @xmath

### 2.1 Preface list of data and proof’s used in the calculations

#### 2.1.1 The Fourier Series

  -- -------- --
     @xmath   
  -- -------- --

#### 2.1.2 Parseval’s Identity

  -- -------- --
     @xmath   
  -- -------- --

#### 2.1.3 Proof of orthongonality in the Fourier Series

First consider

  -- -------- --
     @xmath   
  -- -------- --

Case (I) Note: @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Case (II) Note: @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Firstly, consider the case where @xmath

  -- -------- --
     @xmath   
  -- -------- --

Secondly, consider the case where @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Case (III) note: @xmath = @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Case (i): If @xmath then,

  -- -------- --
     @xmath   
  -- -------- --

Case (ii): If @xmath then,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore, we can deduce that in general:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

#### 2.1.4 The extraction of @xmath from the Fourier series

From the Fourier series, by applying integration on f(x) directly and
realizing that the terms consisting of @xmath and @xmath are equal to
zero, we are able to attain a value for the constant term @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

To find a value of @xmath , multiply all the terms in the Fourier series
by cos(nx) as @xmath will only exist where f(x) is even because the term
in @xmath will be the only one to be non-zero following the integration
over the range from @xmath to @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Note that @xmath where @xmath and @xmath where @xmath

Now note that there only exists @xmath where @xmath

  -- -------- --
     @xmath   
  -- -------- --

In addition, when we multiply all terms by sin(nx) we can yield a resut
respecitvly for @xmath

  -- -------- --
     @xmath   
  -- -------- --

Also, note that in all cases dealt with @xmath and @xmath is only
defined for @xmath

### 2.2 Generating a value for @xmath (2)

Consider the simplest odd function where @xmath
Therefore, since @xmath is an odd function then @xmath where @xmath

Now consider @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, by substituting @xmath back into the Fourier Series we obtain:

  -- -------- --
     @xmath   
  -- -------- --

Then, consider Parsevals Identity where:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Firstly, consider the left hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Secondly, consider the right hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Lastly, equate the left hand side to the right hand side of Parseval’s
Identity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, using the definition of the zeta function we then see that

  -- -------- --
     @xmath   
  -- -------- --

Multiplying by 6 and square rooting we attain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

### 2.3 Generating a value for @xmath (4)

Consider the simplist even function where @xmath
Therefore, since f(x) is an even function then @xmath where @xmath

First consider @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Then consider @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, by substituting @xmath and @xmath back into the Fourier Series we
obtain:

  -- -------- --
     @xmath   
  -- -------- --

Then, consider Parsevals Identity where:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Firstly, consider the left hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Secondly, consider the right hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Lastly, equate the left hand side to the right hand side of Parseval’s
Identity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, using the definition of the zeta function we then see that

  -- -------- --
     @xmath   
  -- -------- --

Multiplying by 90 and taking the 4th root we attain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

### 2.4 Generating a value for @xmath (6)

Consider the odd function where @xmath
Therefore, since @xmath is an odd function then @xmath where @xmath =
1,2,3 …

Now consider @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, by substituting @xmath back into the Fourier Series we obtain:

  -- -------- --
     @xmath   
  -- -------- --

Then, consider Parsevals Identity where:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Firstly, consider the left hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Secondly, consider the right hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Lastly, equate the left hand side to the right hand side of Parseval’s
Identity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, using the definition of the zeta function we then see that

  -- -------- --
     @xmath   
  -- -------- --

Multiplying by 945 and taking the 6th root we attain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

### 2.5 Generating a value for @xmath (8)

Consider the even function where @xmath
Therefore, since f(x) is an even function then @xmath where @xmath =
1,2,3 …

First consider @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Then consider @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, by substituting back @xmath and @xmath back into the Fourier Series
we obain:

  -- -------- --
     @xmath   
  -- -------- --

Then, consider Parsevals Identity where:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Firstly, consider the left hand side of Parseval’s Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Secondly, consider the right hand side of Parsevals Identity:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Lastly, equate the left hand side to the right hand side of Parseval’s
Identity

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, using the definition of the zeta function we then see that

  -- -------- --
     @xmath   
  -- -------- --

Multiplying by 9450 and taking the 8th root we attain:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

## 3 The Wallis Product

Consider the function in which @xmath

  -- -------- --
     @xmath   
  -- -------- --

By evaluating this integral we obtain the following:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now it is possible to generate values that are either even or odd. To
generate even values, consider the following:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

To generate odd values, consider the following: By letting @xmath in
@xmath , we attain the following:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now we can consider the product of values for both even and odd
functions

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

Note: for I(2n), @xmath is substitued into [1]

  -- -------- --
     @xmath   
  -- -------- --

Note: for I(2n+1), @xmath is substituted into [2]

  -- -------- --
     @xmath   
  -- -------- --

For even functions, consider I(2n) and expand further by repeating the
iterative process.

  -- -------- --
     @xmath   
  -- -------- --

For odd functions, consider I(2n+1) and expand further by repeating the
iterative process.

  -- -------- --
     @xmath   
  -- -------- --

Therefore,

  -- -------- --
     @xmath   
  -- -------- --

From this, we can deduce the following as @xmath :

  -- -------- --
     @xmath   
     @xmath   
     @xmath   
     @xmath   
  -- -------- --

Then, by substituting @xmath for

  -- -------- --
     @xmath   
  -- -------- --

we obtain:

  -- -------- --
     @xmath   
  -- -------- --

Now consider the Squeeze Theorem which states the following:

  -- -------- -------- -------- --
                                
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

In this case, the lower limit would be the following:

  -- -------- --
     @xmath   
  -- -------- --

Now, consider the limit of @xmath ,

  -- -------- --
     @xmath   
  -- -------- --

Henceforth, since both @xmath and @xmath tend towards the same limit
which in this case is 1 then @xmath must also tend towards 1 by the
squeeze theorem which is shown below.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

And lastly,

  -- -------- --
     @xmath   
  -- -------- --

It is also important to acknowledge that this method to calculate @xmath
was different to the other methods used to calculate @xmath because it
is a different type of infinite decent. Unlike Newtons Arcsine function
with the usage of an infinite sum, The Wallis product is a unique
infinite product that convereges towards @xmath which was made without
Infinitesimal calculus as it did not exist at the time.

## 4 Continued Fractions

### 4.1 Preface list of data and proof’s used in the calculations

#### 4.1.1 The Taylor Series

Provided that @xmath is infinitely differentiable at x=a,

  -- -------- --
     @xmath   
  -- -------- --

#### 4.1.2 Euler’s Continued Fraction Formula

  -- -------- --
     @xmath   
  -- -------- --

#### 4.1.3 The Natural Logarithm in Continued Fractions

Let @xmath and then consider the Taylor Expansion of the function to
develop an infinite series

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Then, by letting @xmath in and expanding through the Taylor Series the
following is obtained:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

By extracting the series formed in the previous calculation:

  -- -------- --
     @xmath   
  -- -------- --

The following Continued Fraction can be produced by using Eulers Formula

  -- -------- --
     @xmath   
  -- -------- --

### 4.2 A Continued Fraction for @xmath

Consider the complex number where @xmath = i (By muliplying by the
conjugate)

Now, consider the complex number in Euler Form,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Letting z = i in Eulers Continued Fraction formula for the Natural
Logarithm we can attain the following continued fraction

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- --
     @xmath   
  -- -------- --

  -- -- --
        
  -- -- --

And by repeating this process the following is eventually attained:

  -- -------- --
     @xmath   
  -- -------- --

Now, by multiplying by @xmath , the following is attained:

  -- -------- --
     @xmath   
  -- -------- --

## 5 The Gregory-Leibniz Series

### 5.1 Preface list of data and proof’s used in the calculations

#### 5.1.1 The Taylor Series

Provided that @xmath is infinitely differentiable at x=a,

  -- -------- --
     @xmath   
  -- -------- --

### 5.2 @xmath

Consider the function @xmath , By using the Taylor expansion, we can
develop this function into an infinite series.

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

With further expansion through the Taylor Series with @xmath , the
following can be obtained:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, consider when @xmath .

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

## 6 The Newtons Series expansion of the Arcsine Function

### 6.1 Preface list of data and proof’s used in the calculations

#### 6.1.1 The Taylor Series

Provided that @xmath is infinitely differentiable at x=a,

  -- -------- --
     @xmath   
  -- -------- --

### 6.2 @xmath

Consider the function @xmath , By using the Taylor expansion, we can
develop this function into an infinite series

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

With further expansion through the Taylor Series with @xmath , the
following can be obtained:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, consider when @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

## 7 Viete’s Formula with Nested Radicals

First, Start by recalling the simple trigonometric identity in which
@xmath

Now consider @xmath ,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
                                
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Now, let @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now, let @xmath for the above and obtain the following:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now consider the following, by re-arranging the half cosine formula, we
obtain an identity for @xmath

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Now by using this in the originial product after applying @xmath , the
following is obtained:

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Using n=3 and n=4 respectivly as examples,

  -- -------- --
     @xmath   
  -- -------- --

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
              @xmath   @xmath   
  -- -------- -------- -------- --

So,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Therefore,

  -- -------- --
     @xmath   
  -- -------- --

## 8 Analysis with Data Tables and Graphs of the various methods

### 8.1 The Wallis Product

The following data tables have been generated using excel and the
calculations have been done in code using wolfram mathematica. There is
very high accuracy in these values because mathematica has the ability
to calculate with to 31 decimal places however the accuracy of the
attained values for the percentage errors decrease as the values of n
increase because as each method converges towards @xmath the percentage
error becomes more susceptible to rounding errors and at large n values
the percentage error becomes so small that Mathematica has trouble
calculating and a rounding error is produced as the percentage error is
only taken to 5 decimal places. However, this error is insignificant and
therefore will not effect the results drastically.

### 8.2 The Gregory-Leibniz Series

### 8.3 Newtons Arcsine Expansion Series for @xmath

### 8.4 Continued Fractions for @xmath

### 8.5 Viete’s Formula of Nested Fractions for @xmath

### 8.6 The Zeta Function

See pages 1,2,3,4,5,6,7,8,9 of A.pdf

## 9 Conclusions

### 9.1 Conclusion: The Wallis Product

The Wallis product provides a partially slow method of convergence
towards @xmath . It can be seen from the data table and percentage error
that the Wallis Product does not oscillate between two values but
instead converges at a slower rate shown by the shallowness of the curve
of Fig.1. The Values of @xmath generated are always increasing therefore
the graph attained can be deemed plausible and correct as it curves
upward in Fig.1 . The percentage error shows that even when @xmath the
actual value of @xmath attained contains an error at only the 7th
decimal place.
In addition, the @xmath error in Fig.2 gives rise to a curve which
starts off with a steep fairly high percentage error and which decreases
rapidly and then the rate at which the values attained become more
accurate is slowed as the curve becomes much more shallow. On inspection
of the error curve from n=5 and n=10 with a comparison to n=55 and n=60
this hypothesis can be proven correct.
An explanation of this lies within the fact that the product only has
small increments of numbers for example:

Here, it can be seen that the fact that the Wallis product converges so
slowly is due to the fact that it is being increased by such minor
values that it would require a large amount of iterations to approach
the true value of @xmath at 15 decimal places

### 9.2 Conclusion: Eulers Continued Fractions

The Continued fraction used in this method for calculating @xmath is one
of the slowest continued fractions formula used to calculate pi. An
explanation for this inefficiency (Fig.9) lies in the fact that the
values of @xmath per iteration alternate and oscillate between the
positive and negative regions about the line @xmath very slowly and in
turn this results for a very slow convergence.
By inspecting the data from the table and the graph in Fig.10, the
percentage error’s clearly illustrate how inefficient and inappropriate
the method is for calculating accurate values of @xmath as when n = 1
the percentage error is quite significant with a large 15.1%.
Furthermore, the gradient and drop in percentage error is not as fast as
the other methods which accounts for the very shallow curve of
convergence towards 0%.
If we look at the actual continued fraction formula itself, the value of
each section grows very slowly and therefore has a very slow impact on
the value of the whole continued fraction itself. This accounts for part
of the inefficiency of this method. In addition, the continued fraction
that Euler developed his so slow that it requires ”roughly @xmath terms
to achieve n-decimal precision” [ 11 ] .

### 9.3 Conclusion: The Gregory-Leibniz Series

The Gregory-Leibniz Series illustrates an out of date and inefficient
infinite series which will converge to @xmath at a very slow rate. Some
partial reasoning behind this is the fact that the actual infinite sum
contains @xmath in the numerator and therefore causes the partial sums
to oscillate between the positive and negative regions above and below
the line @xmath . This can be seen through Fig.3 that the attained
@xmath values which alternate between every @xmath value either going
far much above the required value or too far below.
Both the Table of Data and the graph emphasize the inefficiency of the
infinite sum. Fig.3 illustrates the slow convergence towards @xmath as
the graph is not very steep at the start and becomes even more shallow
as the n values increase which is also supported by the fact that
”Calculating @xmath to 10 correct decimal places using direct summation
of the series requires about 5,000,000,000 terms” [ 4 ] .
In inspecting the inefficiency, it is important to note that that even
though Mathematica would display a percentage error of 0.00000% at the
@xmath @xmath term there is still a margin of error as the infinite
series makes an error at only the 8th decimal point. Taking into account
that it was discovered in 1670’s where mathematical analysis was not yet
fully developed and that it was the ”first ever found infinite series
for @xmath ” [ 4 ] , It would have been a tremendous discovery by James
Gregory and Gottfried Wilhelm Von Leibniz at the time. Furthermore, ”In
order to achieve 100 accurate decimal places, one would have to go
through @xmath iterations of the series” [ 4 ] which illustrates how it
cannot satisfy modern needs for the computation and calculation of
accurate values of @xmath shown in Fig.4.

### 9.4 Conclusion: Newtons Arcsine Series Expansion

Newton’s Arcsine Expansion provides a rapidly converging infinite series
which attains an accurate value of @xmath between n=20 and n=10. An
explanation for this accelerated convergence can be seen within the
actual infinite function. If one pays close attention to the components
of the infinite series, it can be seen that @xmath and @xmath are
present on the numerator and denominator respectively. The actual values
of these factorials expand rapidly as @xmath increases. This can be
shown in the sub-table below:

Of course the value of (2n)! will increase at a much more rapid rate
which also converges to a limit fold which would further then explain
the shape of the convergence graph as curving upwards exponentially as
it approaches the value of @xmath in Fig.5. Also, not that the middle
binomial coefficient is present in Newton’s Arcsine expansion which is
@xmath and this also has a high numerical value as n becomes large which
accounts for the rapid convergence.
In addition, by inspecting the both the data tables and Fig.6 for
Newton’s Arcsine expansion, it can be seen that between the terms in
which n=5 and n=10 the series assumes a percentage error of less that
0.00005% which accounts for the extremly steep slope in the graph for
percentage error and the extremely fast convergence in the graph
displaying the corresponding @xmath values. Alternatively, Sterling’s
approximation could also be used here to investigate the rate of
convergence.

### 9.5 Conclusion: Vieta’s Nested Radical Formula

Vieta’s Formula consists of nested radicals which provide a fairly fast
convergence towards @xmath . From the table, it can be seen that at the
start with the first iteration at the first n value there is
approximately 2.55% error and provides an incorrect value at the first
decimal point. However it can be seen through the steepness of the
percentage error in Fig.8 between @xmath and @xmath that the error
rapidly decreases which can be seen by thorough inspection at the second
percentage error where n=2 has decreased by approximately a factor of 4.
Furthermore, by considering the n value in which Vieta’s Formula
provides an accurate value of @xmath it can be seen that between @xmath
and @xmath the re-iterative values reach the correct display of @xmath
for 15 decimal places which remains consistent for the rest of the
iterations.
Furthermore, the explanation behind this lies within the function
itself. The whole use of nested radicals allows the function to not
fluctuate between the positive and negative regions about the line
@xmath and only use the positive region. Furthermore, if we consider the
following part of Vieta’s Formula:

  -- -------- --
     @xmath   
  -- -------- --

Then, by squaring both sides of the equation,

  -- -------- -------- -------- --
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
     @xmath   @xmath   @xmath   
  -- -------- -------- -------- --

Since @xmath must be positive, @xmath

From this, if we now consider the whole form of Vieta’s Formula:

  -- -------- --
     @xmath   
  -- -------- --

Therefore, as @xmath increases the value of @xmath will increase and the
value of @xmath nested roots two radicals will approach two and the
value of the square root will decrease. However, it is important to note
that the speed at which @xmath increases will be faster than the speed
that the nested roots approach 2. This in turn explains the shape of the
graph as it provides evidence that the graph should rapidly accelerate
upwards because at first the rate at which @xmath increases will be much
greater than the rate of decrease in the nested radicals. Then, as shown
in fig.7, the curve should flatten as the rates increase of both terms
equal out until they are balanced at which n tends towards infinity
@xmath and the exact value of @xmath is obtained.

### 9.6 Conclusion: The Reimann-Zeta Function

The series developed by the Reimann-Zeta Function for @xmath show an
increase in accuracy as the the value of @xmath in the Zeta function
increases. This in turn provides evidence for the attained graphs for
the different @xmath values. For example, by looking at Fig. 11 for
@xmath one can notice that the gradient flattens out at a much slower
rate than which accounts for a slower rate of convergence compared to
Fig.13 where there is a much steeper gradient at the start and the rate
at which the series converges is much faster.
Furthermore, by considering the various graphical displays for the error
values, one can notice as expected that as the value of @xmath
increases, the amount of error in the series decreases at a much faster
rate. Take for example the error in Fig.15 with the graph of @xmath ,
Here it is evident that the gradient at the start is quite steep and
begins to touch close to 0% at about @xmath Similarly, if one examine’s
the graph of error in @xmath through Fig.18 it can be seen that the
gradient is much steeper at the start which signifies how accurate this
method is in calculating @xmath .
The explanation behind this lies in the Zeta function itself. Firstly,
consider how the nature of how @xmath is defined. The series is based on
having a square root of the summation of series with fractions with a
numerator of 1 and denominator of @xmath . Because of this, each
additional fraction added in the series will have less of an influence
on the value of @xmath attained and in turn part of the series accounts
for a slower convergence towards @xmath in Fig.11. Contrastingly, if one
pays close attention to the series obtained by @xmath , it is evident
that here, the square root is raised to a power of 8 and each additional
fraction added in the summation has a numerator of 1 and denominator of
@xmath . Because of this, each additional fraction added becomes even
less influential to the value of @xmath attained which can be seen in
the table below. Conclusively, this accounts for the shape of the error
curves in the Figures 12 and 18 as Fig.12 is takes an @xmath value above
@xmath to drop below 0.3% error but for @xmath , between @xmath and
@xmath the% error already drops to 0.0% which shows a much steeper curve
in Fig.18.

## 10 Comparisons of the different methods

### 10.1 The Gregory-Leibniz Series VS Newtons Series: The Arcsine
Expansion

  -- -------- --
     @xmath   
  -- -------- --

The infinite series on the left represents the Gregory-Leibniz series
and the infinite series on the right represents Newtons infinite series
for the arcsine function. By paying close attention to the terms in
common and only considering the terms that are not in common we obtain
the following (as @xmath in the Gregory-Leibniz Series and @xmath in
Newton’s Arcsine Expansion:

  -- -------- --
     @xmath   
  -- -------- --

Considering this, it is obvious that the second infinite sum will
converge much faster than the first because as previously stated in the
analysis for Newtons infinite series, the value of @xmath will converge
at a much faster rate because the use of @xmath and @xmath allows the
series to converge towards a value much faster than the infinite series
containing @xmath because there is no fluctuation.
Furthermore, by having a close look at Fig.19, The graph of comparison
clearly confirms the fact that Newton’s arcsine expansion from previous
reasoning is a much more efficient way to achieve an accurate value of
pi as by n=30, the Newton’s arcsine expansion curve is practically
linear whilst the Gregory-Leibniz oscillations are still oscillating in
wide amounts.
Also, Fig.20 yet again emphasizes how accurate and efficient the arcsine
expansion is compared to the Gregory-Leibniz series as the red plot is
always underneath the blue plot. It is important to note that there is
some percentage error and the line @xmath is an asymptote as there will
always be some error however Mathematica was not able to calculate to
that precision.

### 10.2 Vieta’s Nested Radicals VS Eulers Continued Fraction

  -- -------- --
     @xmath   
  -- -------- --

Vieta’s Nested radicals provide a much faster convergence than Eulers
Continued fraction for @xmath because Euler’s continued fraction
provides a very slow increase in numerators of the continued fractions
as they increase by the unique sequence of odd numbered squares. By
considering how the nested @xmath radicals work we can see that the fact
that as n = 3 the nested fractions are already near complete convergence
at 1.96157 and approaching towards 2 which proves why nested radicals
are more efficient in calculating @xmath
Using graphical evidence, Fig.22 provides evidence for the previously
mentioned hypothesis as said before Vieta’s nested radicals converges at
a much faster rate than Eulers continued Fractions. While Vieta’s
continued fractions have reached n=25, Euler’s continued fraction is
still oscilating above and below the line @xmath Also, Fig.21
illustrates how there is virtually no percent error for Vieta’s nested
fractions past n=25 but at n=25 Euler’s continued fractions still
obtains a percentage error of 1.5 @xmath . Also, it becomes more
difficult to calculate the actual values for Vieta’s square roots
because each additional square root increase the likelyhood for a
rounding error.

### 10.3 The Wallis Product VS Newtons Series: The Arcsine Expansion

  -- -------- --
     @xmath   
  -- -------- --

The product on the left represents the wallis product for pi and the
infinite series on the right represents Newtons Arcsine expansion. Here
it is clear that Newtons Arcsine expansion will give a much faster
convergence rate. Take the transition between @xmath @xmath @xmath and
@xmath to @xmath as examples. The value of the numerator of the wallis
product will increase by 104 (See Calculation 1.00) and the denominator
by a factor of 13x15 which is a minor increment compared to the
numerator in the Arcsine function which increases by @xmath . The power
of the factorial allows for a faster convergence then by multiplication
hence the reason why the infinite series will converge faster than the
product.

  -- -------- --
     @xmath   
  -- -------- --

As shown in Fig.23, The speed of convergence for Newton’s Arcsine still
remains unparalleled as it is able to converge much more rapidly than
the Wallis product as the blue plot is linear and the purple plot
remains as a curve. Fig.24 also illustrates the accuracy of Newton’s
arcsine expansion as the percentage error values are constantly far
below the percentage error values of the Wallis Product

### 10.4 The Wallis Product VS The @xmath Series

  -- -------- --
     @xmath   
  -- -------- --

The product on the left is the Wallis Product for @xmath and the
infinite series on the right represents the infinite series created at
@xmath which in turn converges towards @xmath . Here it is clear that
the series for @xmath converges at a slightly slower rate than the
Wallis Product because of the fact that firstly the infinite series
makes use of multiplication of 2 instead whilst the Wallis Product have
a larger multiplication increment between each n value which is greater
than 2 and secondly because of the fact that a square root is used in
place of multiplication which causes the @xmath series to be slower.

By examining the graphical display in Fig.25, it is clear that the
Wallis Product will converge at a faster rate which is shown as the
graph representing the @xmath infinite series is always slightly below
the graph of the Wallis Product. Furthermore, by taking into
consideration the @xmath error in each of the methods, the results shown
in Fig.26 consolidate what was previously mentioned as at all values for
@xmath , the graph of the infinite series with @xmath is always above
the graph of the Wallis Product which in turn shows that the rate of
accuracy increases at a much larger rate in the Wallis product. Also, by
taking into account the gradient of the percentage error curves, between
values @xmath and @xmath one can see that the gradient of the line for
the Wallis Product is much steeper than the gradient of the line for
@xmath which emphasizes the fact that the rate of accuracy for the
Wallis Product increases at a slightly faster pace than the rate of
accuracy for the infinite series.

### 10.5 Newton’s Arcsine Expansion VS The @xmath Series

  -- -------- --
     @xmath   
  -- -------- --

The infinite series on the left represents one of the most efficient
ways to attain a value of @xmath developed by Newton and his expansion
of arcsine. The series on the right is the fastest way in attaining a
value of @xmath covered in this thesis which is the infinite series
formed using @xmath . In this case, it is clear that not only does
Newton’s arcsine expansion makes use of rapidly increasing factorial
values shown in @xmath and @xmath but also uses high valued exponentials
such as @xmath . However, these factor’s are outweighed by the infinite
series developed from the Reimann-Zeta Function of value @xmath because
here there is not only multiplication by 9450 but also makes use of the
8th square root and every proceeding term in the summation begins to
affect the final product less and less at a much faster rate that the
summation of Newton’s Arcsine Expansion.
Furthermore, if we consider the graphical display in Fig.27 and Fig.28
at @xmath , the produced value the @xmath series where @xmath is much
closer to @xmath than the produced value produced by Newtons Arcsine
Expansion. Also, The % error where @xmath for @xmath is 26 times smaller
than the produced value than the % error given through newtons arcsine
expansion which emphasizes the degree of accuracy that the infinite
series that @xmath has over the series from Newton’s Arcsine expansion.

See pages 1,2,3,4 of B.pdf

## 11 Appendix

### 11.1 Mathematic Iteration code: The Wallis Product

”Wallis Product” For[i = 0, i ¡= 100, i = i + 5, Print[i ” SymbA ”,
NumberForm[N[2 /!/( /*UnderoverscriptBox[/(/[Product]/), /(k = 1/),
/(i/)]/(( /*FractionBox[/(2 k/), /(2 k - 1/)] /*FractionBox[/(2 k/), /(2
k + 1/)])/)/)], 16]]]

5 SymbA 3.002175954556907

10 SymbA 3.067703806643499

15 SymbA 3.091336888596228

20 SymbA 3.103516961539234

25 SymbA 3.11094516690154

30 SymbA 3.115948285887959

35 SymbA 3.119547206305518

40 SymbA 3.122260326421437

45 SymbA 3.124378835915516

50 SymbA 3.126078900215411

55 SymbA 3.127473350412857

60 SymbA 3.128637797891591

65 SymbA 3.129624812079802

70 SymbA 3.130472076319065

75 SymbA 3.131207308587379

80 SymbA 3.131851351372613

85 SymbA 3.132420179022906

90 SymbA 3.132926240627509

95 SymbA 3.133379381619937

100 SymbA 3.133787490628162

1000 SymbA 3.140807746030395

10000 SymbA 3.141514118681922

100000 SymbA 3.141584799657247

1000000 SymbA 3.141591868192124

10000000 SymbA 3.141592575049982

#### 11.1.1 Mathematic Iteration code: The Wallis Product Percentage
Error

-   1 - N[3.002175954556907/π, 15] N[0.044377713601277735‘*100, 15]
    4.43777

-   N[(3.067703806643499/π), 15] 1 - 0.9764804495382736‘
    0.02351955046172638‘ *100 = 2.35196

-   3.091336888596228/π 1 - 0.9840030931648189‘ 0.01599690683518107‘*100
    1.59969

-   3.103516961539234/π 1 - 0.9878801307970174‘ 0.01211986920298258*100
    1.21199

-   3.110945166901554/π 1 - 0.9902446020004474‘
    100*0.009755397999552606‘ 0.97554

-   3.115948285887959/π 1 - 0.9918371442355739‘
    100*0.008162855764426102‘ 0.81629

-   1 - 0.9929827161840716‘ 100*0.007017283815928366‘ 0.701728

-   3.122260326421437/π 1 - 0.9938463291393728‘
    100*0.006153670860627236‘ 0.615367

-   3.124378835915516/π 1 - 0.9945206716553123‘
    100*0.005479328344687673‘ 0.547933

-   3.126078900215411/π 1 - 0.9950618189291169‘
    100*0.004938181070883063‘ 0.493818

-   3.127473350412857/π 1 - 0.9955056862127551‘
    100*0.004494313787244852‘ 0.449431

-   1 - 3.128637797891591/π 100*0.004123658 642822159‘ = 0.412366

-   3.129624812079802/ π 1 - 0.996190517731089‘
    100*0.0038094822689109797‘ 0.380948

-   3.130472076319065/π 1 - 0.9964602103146565‘
    100*0.0035397896853435196‘ 0.353979

-   3.131207308587379/π 1 - 0.9966942420143022‘
    100*0.003305757985697766‘ 0.330576

-   3.131851351372613/π 1 - 0.9968992471999675‘
    100*0.0031007528000325246‘ 0.310075

-   3.132420179022906/π 1 - 0.9970803106645905‘
    100*0.0029196893354095366‘ 0.291969

-   3.132926240627509/π 1 - 0.9972413950763536‘
    100*0.002758604923646435‘ 0.27586

-   3.133379381619937/π 1 - 0.9973856343340787‘
    100*0.0026143656659213255‘ 0.261437

-   3.133787490628162/π 1 - 0.9975155394660373‘
    100*0.0024844605339626735‘ 0.248446

-   3.140807746030395/π 1 - 0.9997501561641032‘
    100*0.00024984383589676806‘ 0.0249844

-   3.141514118681922/π 1 - 0.9999750015624141‘
    100*0.000024998437585854738‘ 0.00249984

-   3.141584799657247/π 1 - 0.9999975000156252‘ 100*2.4999843748485517‘*
    0.000249998

### 11.2 Mathematic Iteration code: The Gregory-Leibniz Series

For[i = 0, i ¡= 100, i = i + 5, Print[i ” SymbA ”, NumberForm[N[4 /!(/
/*UnderoverscriptBox[/(/[Sum]/), /(n = 0/), /(i/)] /*FractionBox[
SuperscriptBox[/((/(-1/))/), /(n/)], /(2 n + 1/)]/)], 16]]]

5 SymbA 2.976046176046176

10 SymbA 3.232315809405593

15 SymbA 3.079153394197426

20 SymbA 3.189184782277595

25 SymbA 3.103145312886011

30 SymbA 3.173842337190749

35 SymbA 3.113820229023573

40 SymbA 3.165979272843215

45 SymbA 3.119856090062712

50 SymbA 3.161198612987056

55 SymbA 3.123736933726277

60 SymbA 3.157984995168666

65 SymbA 3.126442007766234

70 SymbA 3.155676462307475

75 SymbA 3.128435328236984

80 SymbA 3.153937862272616

85 SymbA 3.129965139593801

90 SymbA 3.152581332875124

95 SymbA 3.131176269454981

100 SymbA 3.151493401070910

1000 SymbA 3.142591654339543

10000 SymbA 3.141692643590543

100000 SymbA 3.141602653489794

1000000 SymbA 3.141591868192127

10000000 SymbA 3.141592653518272

#### 11.2.1 Mathematic Iteration code: The Gregory-Leibniz Series
Percentage Error

-   2.976046176046176/π 1 - 0.9473049195749638‘
    100*0.052695080425036234‘ 5.26951

-   3.232315809405593/π 1 - 1.0288780774019617‘
    100*-0.028878077401961688‘ -2.88781

-   3.079153394197426/π 1 - 0.9801249664494155‘ 100*0.01987503355058451‘
    1.9875

-   3.189184782277595/π 1 - 1.0151490450658587‘
    100*-0.01514904506585868‘ -1.5149

-   3.103145312886011/π 1 - 0.9877618313565096‘
    100*0.012238168643490366‘ 1.22382

-   3.173842337190749/π 1 - 1.0102653931164836‘
    100*-0.010265393116483557‘ -1.02654

-   3.113820229023573/π 1 - 0.9911597626972786‘
    100*0.008840237302721432‘ 0.884024

-   3.165979272843215/π 1 - 1.0077625019989642‘
    100*-0.007762501998964222‘ -0.77625

-   3.119856090062712/π 1 - 0.993081036937668‘ 100*0.006918963062331973‘
    0.691896

-   3.161198612987056/π 1 - 1.0062407707042669‘
    100*-0.006240770704266874‘ -0.624077

-   3.123736933726277/π 1 - 0.9943163478425145‘
    100*0.005683652157485453‘ 0.568365

-   3.157984995168666/π 1 - 1.0052178443822568‘
    100*-0.005217844382256809‘ -0.521784

-   3.126442007766234/π 1 - 0.9951773996522919‘
    100*0.004822600347708095‘ 0.48226

-   3.155676462307475/π 1 - 1.0044830155499596‘
    100*-0.004483015549959557‘ -0.448302

-   3.128435328236984/π 1 - 0.9958118932644642‘
    100*0.004188106735535824‘ 0.418811

-   3.129965139593801/π 1 - 0.9962988473433353‘
    100*0.003701152656664708‘ 0.370115

-   3.152581332875124/π 1 - 1.0034978052526238‘
    100*-0.0034978052526237757‘ -0.349781

-   3.131176269454981/π 1 - 0.9966843619516014‘
    100*0.003315638048398628‘ 0.331564

-   3.151493401070910/π 1 - 1.003151505803849‘
    100*-0.0031515058038489308‘ -0.315151

-   3.142591654339543/π 1 - 1.0003179918149503‘
    100*-0.0003179918149502914‘ -0.0317992

-   3.141692643590543/π 1 - 1.0000318278057583‘
    100*-0.000031827805758277705‘ -0.00318278

-   100*-1.00000318306703‘*15 1.00000318306703‘*100 0.00001

### 11.3 Mathematic Iteration code: Newtons Arcsine Expansion Series

For[i = 0, i ¡= 100, i = i + 5, Print[i ” SymbA”, NumberForm[N[6 /!/(
/*UnderoverscriptBox[/([/Sum]/), /(n = 0/), /(i/)]
/*FractionBox[/(/(/((2 n)/)!/) /*SuperscriptBox[/((1/2)/), /(2 n +
1/)]/), /( /*SuperscriptBox[/(2/), /(2 n/)]
/*SuperscriptBox[/(((/n!)/)/), /(2/)] /((2 n + 1)/))]/)], 16]]]

5 SymbA 3.141576715774866

10 SymbA 3.141592646875561

15 SymbA 3.141592653585951

20 SymbA 3.141592653589791

25 SymbA 3.141592653589793

30 SymbA 3.141592653589794

35 SymbA 3.141592653589793

40 SymbA 3.141592653589793

45 SymbA 3.141592653589793

50 SymbA 3.141592653589793

55 SymbA 3.141592653589793

60 SymbA 3.141592653589794

65 SymbA 3.141592653589793

70 SymbA 3.141592653589793

75 SymbA 3.141592653589794

80 SymbA 3.141592653589794

85 SymbA 3.141592653589793

90 SymbA 3.141592653589794

95 SymbA 3.141592653589793

100 SymbA 3.141592653589794

1000 SymbA 3.142591654339543

10000 SymbA 3.141692643590543

100000 SymbA 3.141692643590543

1000000 SymbA 3.141692643590543

#### 11.3.1 Mathematic Iteration code:Newtons Arcsine Series Percentage
Error

-   3.141592653585951/π 1 - 0.999999999998777‘
    100*1.2230216839270724‘*-12 1.22302*10*-10

-   3.141592646875561/π 1 - 0.9999999978627935‘
    100*2.1372065228675297‘*-9 2.13721*10*-7

-   3.141576715774866/π 1 - 0.9999949268359446‘
    100*5.073164055402479‘*-6 0.000507316

## 12 Mathematic Iteration code: Continued Fractions for @xmath

g[n,x] = (2 n + 1)*2/(2 + x) NumberForm[4./(1 + g[0, g[1, g[2, g[3,
g[4]]]]]), 16] ‘™ TagBox[ InterpretationBox[””3.331601731601732’”,
3.3316017316017317‘, AutoDelete-¿True], NumberForm[, 16] ]
NumberForm[4./( 1 + g[0, g[1, g[2, g[3, g[4, g[5, g[6, g[7, g[8,
g[9]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.042842125195067, 3.0428421251950666‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13,
g[14]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.207889026381334”, 3.207889026381334,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.091748884841698¿”, 3.0917488848416976‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23,
g[24]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.181512659824787”, 3.1815126598247874‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.108305614026907”, 3.108305614026907,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33,
g[34]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.170134928816534¿”, 3.1701349288165344‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3,g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38,
g[39]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.11661218423562”, 3.1166121842356196‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43,
g[44]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.163801158726882¿”, 3.1638011587268817‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48,
g[49]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.121602653391091¿”, 3.1216026533910908‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54,
g[55]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]] ), 16] ‘™

TagBox[ InterpretationBox[””3.12374262842223¿”, 3.1237426284222303‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54, g[55, g[56, g[57, g[58,
g[59]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]] ]]]]), 16]
‘™

TagBox[ InterpretationBox[””3.12493177388015”, 3.1249317738801503‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62, g[63,
g[64]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.156972717366711¿”, 3.1569727173667115‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14,
g[15,g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26,
g[27, g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38,
g[39, g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50,
g[51, g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62,
g[63, g[64, g[65, g[66, g[67, g[68,
g[69]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.127333523307754¿”, 3.127333523307754,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14,
g[15,g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26,
g[27, g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38,
g[39, g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50,
g[51, g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62,
g[63, g[64, g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73,
g[74]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.154923023986425¿”, 3.1549230239864245‘,
AutoDelete-¿True], NumberForm[, 16 ] NumberForm[ 4./(1 + g[0, g[2, g[3,
g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15, g[16,
g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27, g[28,
g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39, g[40,
g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51, g[52,
g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62, g[63, g[64,
g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73, g[74, g[75, g[76,
g[77, g[78, g[79]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]
]]]]]]]]]]]]]]]]]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.129095094977018¿”, 3.1290950949770178‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14,
g[15,g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26,
g[27, g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38,
g[39, g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50,
g[51, g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62,
g[63, g[64, g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73, g[74,
g[75, g[76, g[77, g[78, g[79, g[80, g[81, g[82, g[83,
g[84]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.153355324069958¿”, 3.153355324069958,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62, g[63,
g[64, g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73, g[74, g[75,
g[76, g[77, g[78, g[79, g[80, g[81, g[82, g[83, g[84, g[85, g[86, g[87,
g[88,
g[89]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.130483257145759¿”, 3.1304832571457593‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62, g[63,
g[64, g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73, g[74, g[75,
g[76, g[77, g[78, g[79, g[80, g[81, g[82, g[83, g[84, g[85, g[86, g[87,
g[88, g[89, g[90, g[91, g[92, g[93,
g[94]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.152117511448855”, 3.152117511448855,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[ 4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8, g[9, g[10, g[11, g[12, g[13, g[14, g[15,
g[16, g[17, g[18, g[19, g[20, g[21, g[22, g[23, g[24, g[25, g[26, g[27,
g[28, g[29, g[30, g[31, g[32, g[33, g[34, g[35, g[36, g[37, g[38, g[39,
g[40, g[41, g[42, g[43, g[44, g[45, g[46, g[47, g[48, g[49, g[50, g[51,
g[52, g[53, g[54, g[55, g[56, g[57, g[58, g[59, g[60, g[61, g[62, g[63,
g[64, g[65, g[66, g[67, g[68, g[69, g[70, g[71, g[72, g[73, g[74, g[75,
g[76, g[77, g[78, g[79, g[80, g[81, g[82, g[83, g[84, g[85, g[86, g[87,
g[88, g[89, g[90, g[91, g[92, g[93, g[94, g[95, g[96, g[97, g[98,
g[99]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]),
16] ‘™

TagBox[ InterpretationBox[””3.131593903583553”, 3.1315939035835534‘,
AutoDelete-¿True], NumberForm[, 16] ] ”Numbers 1-4 From the Function
n=1-4”

NumberForm[4./(1 + g[0]), 16] ‘™

TagBox[ InterpretationBox[””2.666666666666667¿”, 2.6666666666666665‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[4./(1 + g[0, g[1]]),
16] ‘™

TagBox[ InterpretationBox[””2.8¿”, 2.8, AutoDelete-¿True], NumberForm[,
16] ] NumberForm[4./(1 + g[0, g[1, g[2]]]), 16] ‘™

TagBox[ InterpretationBox[”3.428571428571428¿”, 3.4285714285714284‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[4./(1 + g[0, g[1, g[2,
g[3]]]]), 16] ‘™

TagBox[ InterpretationBox[”2.911111111111111¿”, 2.911111111111111,
AutoDelete-¿True], NumberForm[, 16] ]

”Numbers 6-9 from the Function n=6-9”

NumberForm[4./(1 + g[0, g[1, g[2, g[3, g[4, g[5]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””2.980708180708181¿”, 2.9807081807081808‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.280808080808081”, 3.2808080808080806‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.280808080808081”, 3.2808080808080806‘,
AutoDelete-¿True], NumberForm[, 16] ] NumberForm[4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7]]]]]]]]), 16] ‘™

TagBox[ InterpretationBox[””3.019032601385542¿”, 3.0190326013855424‘,
AutoDelete-¿True], NumberForm[, 16]] NumberForm[4./(1 + g[0, g[1, g[2,
g[3, g[4, g[5, g[6, g[7, g[8]]]]]]]]]), 16] ‘™

### 12.1 Mathematic Iteration code: Continued Fractions for @xmath
Percentage Error

-   In[152]:= 2.666666666666667/π In[153]:= 1 - 0.8488263631567753‘
    In[154]:= 100*0.1511736368432247‘ Out[154]= 15.1174

-   InIn[155]:= 2.800000000000000/π In[156]:= 1 - 0.8912676813146139‘
    In[157]:= 100*0.10873231868538613‘ Out[157]= 10.8732

-   InIn[158]:= 3.428571428571428/π In[159]:= 1 - 1.091348181201568‘
    In[160]:= 100*-0.09134818120156796‘ Out[160]= -9.13482

-   InIn[161]:= 2.9111111111111111/π In[162]:= 1 - 0.9266354464461461‘
    In[163]:= 100*0.07336455355385385‘ Out[163]= 7.33646

-   InIn[164]:= 3.331601731601732/π In[165]:= 1 - 1.0604817679958674‘
    In[166]:= 100*-0.06048176799586735‘ Out[166]= -6.04818

-   InIn[167]:= 2.980708180708181/π In[168]:= 1 - 0.948788881748315‘
    In[169]:= 100*0.051211118251685006‘ Out[169]= 5.12111

-   InIn[170]:= 3.280808080808081/π In[171]:= 1 - 1.044313646792881‘
    In[172]:= 100*-0.04431364679288108‘ Out[172]= -4.43136

-   InIn[173]:= 3.019032601385542/π In[174]:= 1 - 0.9609879237321854‘
    In[175]:= 100*0.039012076267814555‘ Out[175]= 3.90121

-   InIn[176]:= 3.250989945726788/π In[177]:= 1 - 1.0348222396089417‘
    In[178]:= 100*-0.03482223960894171‘ Out[178]= -3.48222

-   InIn[179]:= 3.042842125195067/π In[180]:= 1 - 0.9685667305460856‘
    In[181]:= 100*0.03143326945391445‘ Out[181]= 3.14333

-   InIn[182]:= 3.207889026381334/π In[183]:= 1 - 1.0211027908776735‘
    In[184]:= 100*-0.021102790877673527‘ Out[184]= -2.11028

-   InIn[185]:= 3.091748884841698/π In[186]:= 1 - 0.9841342356428227‘
    In[187]:= 100*0.015865764357177348‘ Out[187]= 1.58658

-   InIn[188]:= 3.181512659824787/π In[189]:= 1 - 1.012706932641117‘
    In[190]:= 100*-0.012706932641117108‘ Out[190]= -1.27069

-   InIn[191]:= 3.108305614026907/π In[192]:= 1 - 0.9894044062253424‘
    In[193]:= 100*0.010595593774657575‘ Out[193]= 1.05956

-   InIn[194]:= 3.170134928816534/π In[195]:= 1 - 1.0090852883788504‘
    In[196]:= 100*-0.009085288378850365‘ Out[196]= -0.908529

-   InIn[197]:= 3.116612184235621/π In[198]:= 1 - 0.9920484696430558‘
    In[199]:= 100*0.00795153035694418‘ Out[199]= 0.795153

-   InIn[200]:= 3.163801158726882/π In[201]:= 1 - 1.007069186742499‘
    In[202]:= 100*-0.007069186742499012‘ Out[202]= -0.706919

-   InIn[203]:= 3.121602653391091/π In[204]:= 1 - 0.9936369853119372‘
    In[205]:= 100*0.006363014688062774‘ Out[205]= 0.636301

-   InIn[206]:= 3.123742628422234/π In[207]:= 1 - 0.9943181605205365‘
    In[208]:= 100*0.005681839479463546‘ Out[208]= 0.568184

-   InIn[209]:= 3.124931773880152/π In[210]:= 1 - 0.9946966772759024‘
    In[211]:= 100*0.005303322724097614‘ Out[211]= 0.530332

-   InIn[212]:= 3.156972717366711/π In[213]:= 1 - 1.0048956263503301‘
    In[214]:= 100*-0.00489562635033014‘ Out[214]= -0.489563

-   InIn[215]:= 3.127333523307754/π In[216]:= 1 - 0.9954611778628444‘
    In[217]:= 100*0.004538822137155618‘ Out[217]= 0.453882

-   InIn[218]:= 3.154923023986425/π In[219]:= 1 - 1.0042431886837397‘
    In[220]:= 100*-0.00424318868373974‘ Out[220]= -0.424319

-   InIn[221]:= 3.129095094977018/π In[222]:= 1 - 0.9960219035403924‘
    In[223]:= 100*0.003978096459607561‘ Out[223]= 0.39781

-   InIn[224]:= 3.153355324069958/π In[225]:= 1 - 1.0037441743017588‘
    In[226]:= 100*-0.0037441743017587736‘ Out[226]= -0.374417

-   InIn[227]:= 3.130483257145759/π In[228]:= 1 - 0.9964637692823288‘
    In[229]:= 100*0.003536230717671174‘ Out[229]= 0.353623

-   InIn[230]:= 3.152117511448855/π In[231]:= 1 - 1.0033501663072186‘
    In[232]:= 100*-0.003350166307218627‘ Out[232]= -0.335017

-   InIn[233]:= 3.131593903583553/π In[234]:= 1 - 0.9968172990235336‘
    In[235]:= 100*0.003182700976466446‘ Out[235]= 0.31827

## 13 Mathematic Iteration code: Viete’s Nested Radicals Formula for
@xmath

”Viete Formula” @xmath @xmath For[i = 0, i ¡= 100, i = i + 5, Print[i ”
SymbA ” Text[Style[Row[[N[p[i], a[i]]]]]]]]For[i = 0, i ¡= 10, i = i +
1, Print[i ” SymbA ” Text[Style[Row[N[p[i], a[i]]]]]]]

1 ” SymbA ” 3.061467458921242

2 ” SymbA ” 3.121445152263491

3 ” SymbA ” 3.136548490541725

4 ” SymbA ” 3.140331156952385

5 ” SymbA ” 3.141277250932773

6 ” SymbA ” 3.141513801175428

7 ” SymbA ” 3.141572940255612

8 ” SymbA ” 3.141587725373528

9 ” SymbA ” 3.141591413562714

10 ” SymbA ” 3.141592345570118

15 ” SymbA ” 3.141592653288993

20 ” SymbA ” 3.141592653589499

25 ” SymbA ” 3.141592653589793

30 ” SymbA ” 3.141592653589793

35 ” SymbA ” 3.141592653589793

40 ” SymbA ” 3.141592653589793

45 ” SymbA ” 3.141592653589793

50 ” SymbA ” 3.141592653589793

55 ” SymbA ” 3.141592653589793

60 ” SymbA ” 3.141592653589793

65 ” SymbA ” 3.141592653589793

70 ” SymbA ” 3.141592653589793

75 ” SymbA ” 3.141592653589793

80 ” SymbA ” 3.141592653589793

85 ” SymbA ” 3.141592653589793

90 ” SymbA ” 3.141592653589793

95 ” SymbA ” 3.141592653589793

100 ” SymbA” 3.141592653589793

### 13.1 Mathematic Iteration code: Viete’s Nested Radicals Percentage
Error

-   3.061467458921242/π 1 - 0.9744953584045994‘
    100*0.025504641595400557‘ 2.55046

-   3.121445152263491/π 1 - 0.993586851145937‘ 100*0.006413148854062967‘
    0.641315

-   3.136548490541725/π 1 - 0.9983943930342769‘
    100*0.0016056069657230942‘ 0.160561

-   3.140331156952385/π 1 - 0.9995984531489255‘
    100*0.00040154685107451904‘ 0.0401547

-   3.141277250932773/π 1 - 0.9998996042161419‘
    100*0.00010039578385812042‘ 0.0100396

-   3.141513801175428/π 1 - 0.9999749004969581‘
    100*0.000025099503041858817‘ 0.00250995

-   3.141572940255612/π 1 - 0.9999937250508405‘
    100*6.274949159501553‘*-6 0.000627495

-   3.141587725373528/π 1 - 0.9999984313000415‘
    100*1.5686999584874073‘*-6 0.00015687

-   3.141591413562714/π 1 - 0.9999996052871216‘
    100*3.9471287838210856‘*-7 0.0000394713

## 14 Mathematic Iteration code: Zeta (2),(4),(6),(8)

N[Sqrt[6*Sum[1/k2, k, 1, 5]], 15] 3.09466952411370 N[Sqrt[6*Sum[1/k2, k,
1, 10]], 15] 3.04936163598207 N[Sqrt[6*Sum[1/k2, k, 1, 15]], 15]
3.07938982603209 N[Sqrt[6*Sum[1/k2, k, 1, 20]], 15] 3.09466952411370
N[Sqrt[6*Sum[1/k2, k, 1, 25]], 15] 3.10392339170058 N[Sqrt[6*Sum[1/k2,
k, 1, 30]], 15] 3.11012872814126 N[Sqrt[6*Sum[1/k2, k, 1, 35]], 15]
3.11457886229313 N[Sqrt[6*Sum[1/k2, k, 1, 40]], 15] 3.11792619829938
N[Sqrt[6*Sum[1/k2, k, 1, 45]], 15] 3.12053546308708 N[Sqrt[6*Sum[1/k2,
k, 1, 50]], 15] 3.12262652293373 N[Sqrt[6*Sum[1/k2, k, 1, 55]], 15]
3.12433980504914 N[Sqrt[6*Sum[1/k2, k, 1, 60]], 15] 3.12576920214052
N[Sqrt[6*Sum[1/k2, k, 1, 65]], 15] 3.12697987310384 N[Sqrt[6*Sum[1/k2,
k, 1, 70]], 15] 3.12801845342065 N[Sqrt[6*Sum[1/k2, k, 1, 75]], 15]
3.12891920064047 N[Sqrt[6*Sum[1/k2, k, 1, 80]], 15] 3.12970784547462
N[Sqrt[6*Sum[1/k2, k, 1, 85]], 15] 3.13040408931831 N[Sqrt[6*Sum[1/k2,
k, 1, 90]], 15] 3.13102327252367 N[Sqrt[6*Sum[1/k2, k, 1, 95]], 15]
3.13157751780151 N[Sqrt[6*Sum[1/k2, k, 1, 100]], 15] 3.13207653180911

N[Surd[90*Sum[1/k4, k, 1, 5], 4], 15] 3.14016117947426
N[Surd[90*Sum[1/k4, k, 1, 10], 4], 15] 3.14138462246697
N[Surd[90*Sum[1/k4, k, 1, 15], 4], 15] 3.14152783068467
N[Surd[90*Sum[1/k4, k, 1, 20], 4], 15] 3.14156460959141
N[Surd[90*Sum[1/k4, k, 1, 25], 4], 15] 3.14157807684660
N[Surd[90*Sum[1/k4, k, 1, 30], 4], 15] 3.14158413278489
N[Surd[90*Sum[1/k4, k, 1, 35], 4], 15] 3.14158724909022
N[Surd[90*Sum[1/k4, k, 1, 40], 4], 15] 3.14158901347572
N[Surd[90*Sum[1/k4, k, 1, 45], 4], 15] 3.14159008631043
N[Surd[90*Sum[1/k4, k, 1, 50], 4], 15] 3.14159077577492
N[Surd[90*Sum[1/k4, k, 1, 55], 4], 15] 3.14159123889581
N[Surd[90*Sum[1/k4, k, 1, 60], 4], 15] 3.14159156142938
N[Surd[90*Sum[1/k4, k, 1, 65], 4], 15] 3.14159179291850
N[Surd[90*Sum[1/k4, k, 1, 70], 4], 15] 3.14159196334879
N[Surd[90*Sum[1/k4, k, 1, 75], 4], 15] 3.14159209159432
N[Surd[90*Sum[1/k4, k, 1, 80], 4], 15] 3.14159218993944
N[Surd[90*Sum[1/k4, k, 1, 85], 4], 15] 3.14159226661411
N[Surd[90*Sum[1/k4, k, 1, 90], 4], 15] 3.14159232727297
N[Surd[90*Sum[1/k4, k, 1, 95], 4], 15] 3.14159237588858
N[Surd[90*Sum[1/k4, k, 1, 100], 4], 15] 3.14159241530737

N[Surd[945*Sum[1/k6, k, 1, 5], 6], 15] 3.14157300346359
N[Surd[945*Sum[1/k6, k, 1, 10], 6], 15] 3.14159185608168
N[Surd[945*Sum[1/k6, k, 1, 15], 6], 15] 3.14159253913011
N[Surd[945*Sum[1/k6, k, 1, 20], 6], 15] 3.14159262524305
N[Surd[945*Sum[1/k6, k, 1, 25], 6], 15] 3.14159264406125
N[Surd[945*Sum[1/k6, k, 1, 30], 6], 15] 3.14159264969505
N[Surd[945*Sum[1/k6, k, 1, 35], 6], 15] 3.14159265176594
N[Surd[945*Sum[1/k6, k, 1, 40], 6], 15] 3.14159265264583
N[Surd[945*Sum[1/k6, k, 1, 45], 6], 15] 3.14159265306227
N[Surd[945*Sum[1/k6, k, 1, 50], 6], 15] 3.14159265327654
N[Surd[945*Sum[1/k6, k, 1, 55], 6], 15 3.14159265339440
N[Surd[945*Sum[1/k6, k, 1, 60], 6], 15] 3.14159265346284
N[Surd[945*Sum[1/k6, k, 1, 65], 6], 15] 3.14159265350444
N[Surd[945*Sum[1/k6, k, 1, 70], 6], 15] 3.14159265353070
N[Surd[945*Sum[1/k6, k, 1, 75], 6], 15] 3.14159265354784
N[Surd[945*Sum[1/k6, k, 1, 80], 6], 15] 3.14159265355935
N[Surd[945*Sum[1/k6, k, 1, 85], 6], 15] 3.14159265356727
N[Surd[945*Sum[1/k6, k, 1, 90], 6], 15] 3.14159265357284
N[Surd[945*Sum[1/k6, k, 1, 95], 6], 15] 3.14159265357684
N[Surd[945*Sum[1/k6, k, 1, 100], 6], 15] 3.14159265357975

N[Surd[9450*Sum[1/k8, k, 1, 5], 8], 15] 3.14159231269578
N[Surd[9450*Sum[1/k8, k, 1, 10], 8], 15] 3.14159264970117
N[Surd[9450*Sum[1/k8, k, 1, 15], 8], 15] 3.14159265333235
N[Surd[9450*Sum[1/k8, k, 1, 20], 8], 15] 3.14159265355327
N[Surd[9450*Sum[1/k8, k, 1, 25], 8], 15] 3.14159265358185
N[Surd[9450*Sum[1/k8, k, 1, 30], 8], 15] 3.14159265358752
N[Surd[9450*Sum[1/k8, k, 1, 35], 8], 15] 3.14159265358901
N[Surd[9450*Sum[1/k8, k, 1, 40], 8], 15] 3.14159265358948
N[Surd[9450*Sum[1/k8, k, 1, 45], 8], 15] 3.14159265358966
N[Surd[9450*Sum[1/k8, k, 1, 50], 8], 15] 3.14159265358973
N[Surd[9450*Sum[1/k8, k, 1, 55], 8], 15] 3.14159265358976
N[Surd[9450*Sum[1/k8, k, 1, 60], 8], 15] 3.14159265358977
N[Surd[9450*Sum[1/k8, k, 1, 65], 8], 15] 3.14159265358978
N[Surd[9450*Sum[1/k8, k, 1, 70], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 75], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 80], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 85], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 90], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 95], 8], 15] 3.14159265358979
N[Surd[9450*Sum[1/k8, k, 1, 100], 8], 15] 3.14159265358979

### 14.1 Mathematic Iteration code: Zeta (2),(4),(6),(8)

-   3.09466952411372/ 3.141592653589793 1 - 0.985063903997084
    0.01493609600291601‘*100 1.49361

-   3.04936163598207/3.141592653589793 1 - 0.9706419552826705‘
    0.0293580447173295‘*100 2.9358

-   3.07938982603209/3.141592653589793 1 - 0.9802002250397976‘
    100*0.019799774960202354‘ 1.97998

-   3.09466952411378/3.141592653589793 1 - 0.985063903997103‘
    100*0.014936096002897026‘ 1.49361

-   3.10392339170058/3.141592653589793 1 - 0.9880095015354172‘
    100*0.011990498464582777‘ 1.19905

-   3.11012872814126/3.141592653589793 1 - 0.9899847214715822‘
    100*0.01001527852841777‘ 1.00153

-   3.11457886229313/3.141592653589793 1 - 0.9914012431669665‘
    100*0.00859875683303346‘ 0.859876

-   3.11792619829938/3.141592653589793 1 - 0.9924667333101348‘
    100*0.007533266689865203‘ 0.753327

-   3.12053546308708/3.141592653589793 1 - 0.993297288087731‘
    100*0.00670271191226901‘ 0.670271

-   3.12262652293373/3.141592653589793 1 - 0.9939628931095217‘
    100*0.0060371068904783165‘ 0.603711

-   3.12433980504914/3.141592653589793 1 - 0.9945082477446786‘
    100*0.0054917522553213916‘ 0.549175

-   3.12576920214052/3.141592653589793 1 - 0.9949632389701472‘
    100*0.005036761029852843‘ 0.503676

-   3.12697987310384/3.141592653589793 1 - 0.9953486075066875‘
    100*0.004651392493312478‘ 0.465139

-   3.12801845342065/3.141592653589793 1 - 0.9956791978891241‘
    100*0.004320802110875932‘ 0.43208

-   3.12891920064047/3.141592653589793 1 - 0.9959659146341453‘
    100*0.0040340853658547005‘ 0.403409

-   3.12970784547462/3.141592653589793 1 - 0.996216948081543‘
    100*0.003783051918456959‘ 0.378305

-   3.13040408931831/3.141592653589793 1 - 0.9964385693801843‘
    100*0.003561430619815731‘ 0.356143

-   3.13102327252367/3.141592653589793 1 - 0.9966356615158093‘
    100*0.00336433848419071‘ 0.336434

-   3.13157751780151/3.141592653589793 1 - 0.9968120832671165‘

-   100*0.0031879167328835445‘ 0.318792

-   3.13207653180911/3.141592653589793 1 - 0.9969709243590797‘
    100*0.0030290756409202535‘ 0.302908

## 15 Bibliography