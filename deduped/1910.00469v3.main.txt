## Introduction

  The history of science is rich in the example of the fruitfulness of
  bringing two sets of techniques, two sets of ideas, developed in
  separate contexts for the pursuit of new truth, into touch with one
  another.

  – J. Robert Oppenheimer

### The problem of quantum gravity

Quantum mechanics – including quantum field theory as the generalization
to systems with an infinite number of degrees of freedom – and the
general theory of relativity are the two cornerstones on which our
current understanding of the physical world is founded. Besides
providing us with a beautiful geometrical picture of gravitation,
general relativity has found physical applications e.g. in cosmology and
astrophysics. The numerous accomplishments of quantum mechanics arguably
culminate in the extraordinary empirical success of the standard model
of particle physics.

However, despite being supported by vast amounts of experimental
evidence, the fact remains that general relativity and quantum mechanics
are fundamentally inconsistent with each other. On one hand,
conventional quantum field theories describe excitations of quantum
fields propagating over a fixed, non-dynamical background spacetime. On
the other hand, one of the central elements of general relativity is the
idea that spacetime itself is a dynamical entity. The geometry of
spacetime is encoded in the metric tensor, which is a dynamical field,
its dynamics being governed by the Einstein equation. In turn, quantum
theory has taught us that any dynamical field is inherently a quantum
object, and the excitations of the field appear as discrete quanta.

Taken together, the ideas of general relativity and quantum mechanics
therefore suggest that spacetime itself should be quantized, with the
quantum nature of spacetime presumably becoming apparent at sufficiently
small distance scales. General relativity’s picture of spacetime as a
smooth classical manifold would then be only an approximate notion,
which could not be expected to continue being valid down to arbitrarily
small scales. The singularities which are present in general relativity,
for example in black holes and in the beginning of the universe, can be
taken as a hint that this is indeed the case. That is, the singularities
should not be seen as legitimate predictions of general relativity, but
rather as indications that in these extreme physical circumstances the
classical description of spacetime provided by general relativity simply
breaks down, and the theory is not able to give a reliable account of
the situation.

This state of affairs therefore opens up a fascinating challenge: To
understand general relativity and quantum mechanics in terms of a
single, consistent underlying framework. This problem, the problem of
quantum gravity, is arguably the most significant unsolved problem in
fundamental theoretical physics today.

Historically, the methods of conventional quantum field theory were
brought to bear on the problem of quantum gravity soon after they had
found great success in the case of quantum electrodynamics. A line of
research led by DeWitt attempted to formulate a quantum theory of
gravity by employing a perturbative expansion of the metric around flat
Minkowski spacetime (or possibly some other fixed background metric).
However, it was eventually determined that the divergences from which
the resulting theory suffers are non-renormalizable, and therefore the
theory itself is not a satisfactory candidate for a fundamental theory
of physics.

In hindsight, the failure of conventional quantum field theory to
produce a sensible theory of quantum gravity is perhaps not very
surprising. It simply seems to confirm that the conflict is irreparably
large between the fundamental ideas of general relativity and the
assumptions inherent in the framework of perturbative quantum field
theory. A theory in which the quantized gravitational field is
represented as something like a graviton field propagating over a flat
background spacetime seems rather questionable in light of the fact that
spacetime is dynamical in general relativity – in a sense, the
gravitational field is nothing but the geometry of spacetime itself.

The above considerations present a rather strong reason to expect that a
successful theory of quantum gravity, which conforms to the basic
lessons learned from general relativity, should be formulated as a
background independent quantum field theory. That is, the theory should
be expressed in a way in which no reference is made to any fixed,
non-dynamical background spacetime.

### Loop quantum gravity

Loop quantum gravity is a promising and relatively well-developed
proposal for a manifestly background independent theory of quantum
gravity. Essentially, loop quantum gravity is an attempt to answer the
question of whether we can find a common framework which is able to
accommodate the fundamental ideas of both general relativity and quantum
mechanics. In this sense, loop quantum gravity is less ambitious than
certain other approaches to the problem of quantum gravity, most notably
string theory, which seek to formulate a theory of quantum gravity by
developing a unified theory of all the fundamental interactions.

Nevertheless, the strategy of taking two well-established theories and
asking what they imply when considered together has repeatedly proven to
be tremendously successful in the history of physics, often leading to
insights far beyond what could have been inferred on the basis of either
theory alone. Special relativity was born out of combining Galilean
relativity with Maxwell’s electrodynamics, quantum field theory resulted
from merging non-relativistic quantum mechanics with special relativity,
while combining quantum electrodynamics and the theory of weak
interactions into a unified description of the electroweak interaction
was a crucial step in the development of the standard model of particle
physics. In the same way, loop quantum gravity can be seen as the result
of combining quantum mechanics and general relativity.

The kinematical framework of loop quantum gravity is essentially the
outcome of a straightforward canonical quantization of the Ashtekar
formulation of general relativity, following the ideas laid out by Dirac
on the quantization of generally covariant theories. Thus, the only
basic inputs which go into the construction of the theory are quantum
mechanics and general relativity, including in particular the idea that
background independence is of fundamental importance. Loop quantum
gravity does not require the introduction of any radically new physical
assumptions -- such as additional spacetime dimensions which would have
to be compactified in an ad hoc manner, or the existence of
supersymmetric particles which continue to evade the best efforts of the
experimentalists to detect them -- for the internal consistency of the
theory ¹ ¹ 1 On the other hand, the existence of extra dimensions or
supersymmetry can be incorporated into loop quantum gravity, as shown in
[ 43 , 44 , 45 , 46 , 47 , 48 , 49 ] . .

At the kinematical level, the structure of loop quantum gravity is well
understood. The kinematical Hilbert space of the theory is spanned by
the so-called spin network states, which have a compelling physical
interpretation as states describing discrete, quantized spatial
geometries ² ² 2 This interpretation is derived by studying the
eigenvalue problem of operators corresponding to geometric quantities
such as volumes of regions and areas of surfaces. The discrete nature of
spatial geometry is therefore a result of the theory; it is not a
hypothesis inserted by hand during the construction of the formalism. .
In this way, loop quantum gravity is able to provide a concrete
realization of the idea of the quantized gravitational field as a
dynamical object, whose excitations are the elementary quanta out of
which spacetime itself is built.

### The issue of dynamics

While the kinematics of loop quantum gravity is by now well established,
the question of formulating the dynamics of the theory in a satisfactory
manner has proven to be a source of considerable difficulties. According
to Dirac’s quantization algorithm, the dynamics should be specified by
promoting the Hamiltonian constraint of classical general relativity
into an operator in the quantum theory and looking for the states which
are annihilated by this operator. The states belonging to the kernel of
the constraint operator form the physical Hilbert space of the theory,
and the dynamics is determined by the scalar product on the physical
Hilbert space, which defines transition amplitudes between physical
states.

The first step of the program, namely the construction a well-defined
Hamiltonian constraint operator, was accomplished by Thiemann already
more than twenty years ago. However, to this day very little concrete
knowledge has been established concerning the structure of the physical
Hilbert space defined by Thiemann’s constraint operator, or any of its
variants constructed later by other authors. From a practical
perspective, the task of deriving any non-trivial solutions of the
constraint in explicit form (let alone ”interesting” solutions, to which
one could associate a clear physical interpretation) has turned out to
be extremely challenging.

The difficulties encountered in working with the Hamiltonian constraint
have motivated many practitioners of loop quantum gravity to look for
alternative ways of formulating the dynamics of the theory. Perhaps the
most popular among these is the spin foam formalism, also often referred
to as covariant loop quantum gravity, which completely abandons the
canonical formulation of the dynamics, introducing instead a particular
implementation of the path integral for general relativity, which
enables one to define the dynamics by associating transition amplitudes
to spin network states.

In this work, the problem of dynamics is considered within the framework
of the canonical theory, and the main tool used for trying to find an
adequate solution is the so-called method of deparametrization. In
practice, this consists of considering loop quantum gravity coupled to a
suitable scalar field, and using the scalar field as a physical,
relational time variable, with respect to which the dynamics of the
gravitational field is described.

On a technical level, a deparametrized model of loop quantum gravity
trades the Hamiltonian constraint for a physical Hamiltonian operator,
which generates time evolution of spin network states with respect to
the time defined by the reference scalar field. Thus, most of the
problems associated with extracting solutions of the constraint and
understanding the structure of the physical Hilbert space are bypassed
in the deparametrized context. Conceptually, deparametrization can be
seen as a particular way of circumventing the infamous ”problem of time”
in general relativity. While no physically meaningful information is
contained in the evolution of the geometric degrees of freedom with
respect to an essentially arbitrary time coordinate, the way in which
spatial geometry changes in relation to the value of the scalar field
nevertheless has an intrinsic, physically significant meaning.

The problem of dynamics is certainly not the only open issue in loop
quantum gravity today. Among the other challenges, we may mention the
problem of the continuum limit of the theory, i.e. understanding how a
seemingly smooth classical geometry can be recovered from the
fundamentally discrete quantum states of loop quantum gravity.
Extracting falsifiable physical predictions from the formalism is
another problem which is poorly understood at the moment, but which must
necessarily be dealt with in order to ascertain whether loop quantum
gravity is not only a mathematically consistent theory of quantum
gravity, but also provides a physically correct description of the
observable world. However, interesting as these questions are, they are
outside the scope of the present work. As far as the open problems of
loop quantum gravity go, this thesis is confined to the issue of looking
for a satisfactory formulation of the dynamics in the context of the
canonical theory.

Moreover, even though this work is entirely concerned with loop quantum
gravity, our discussion would be distinctly incomplete if we did not at
least mention the other principal lines of research within which an
answer to the question of quantum gravity is currently being sought.
Asymptotic safety, causal dynamical triangulations, causal sets, group
field theory, noncommutative geometry, and others are all motivated by
their respective philosophies, and come with their own sets of strengths
and weaknesses. Each of them has the potential to contribute valuable
insights to the problem at hand, even if they ultimately turn out to not
be the correct answer to the question of the quantum theory of gravity.

### Outline of this thesis

The central theme of this thesis is the use of deparametrized models of
general relativity, in which a scalar field plays the role of a physical
time variable for the dynamics of the gravitational field, as a tool for
formulating the dynamics of loop quantum gravity in a satisfactory
manner. In the author’s opinion, there are two main criteria which a
model of loop quantum gravity has to satisfy in order to be considered
”satisfactory”. On one hand, it is certainly necessary to pay a certain
level of attention to mathematical details while constructing the model,
so as to ensure that the resulting model will not suffer from any
serious mathematical inconsistencies. On the other hand, it is equally
important for the structure of the model to be simple enough that there
can be at least a reasonable hope that the model could one day be used
to make concrete calculations in order to investigate the physical
content of the model and assess its viability as a theory of physics.
For a physicist, having a model with which one cannot make calculations
about physics is hardly better than having no model at all.

A presentation of the author’s scientific work on the dynamics of
deparametrized models of loop quantum gravity could certainly have been
accomplished in far fewer pages than this thesis actually contains. The
discrepancy is explained by the secondary purpose of this work: To
provide a reasonably self-contained overview of loop quantum gravity in
its canonical formulation. In particular, it is my hope that parts of
this thesis could serve as an accessible introduction to the more
practical aspects of canonical loop quantum gravity ³ ³ 3 As far as the
mathematical and conceptual aspects of the theory are concerned, several
excellent expositions, such as the books of Thiemann [ 122 ] and Rovelli
[ 106 ] , are already available. for students who are entering the
field, or are otherwise interested in learning the elements of the
subject in a deeper than superficial level. (Sometimes it feels like it
was only yesterday that I was in that situation myself.)

With the above considerations in mind, the material in this work (after
the present introductory chapter) is divided into four parts. The first
part comprises the first ten chapters of the thesis, and primarily
serves as an introduction to the kinematical framework of loop quantum
gravity. Chapters 1 and 2 set the classical foundations for the quantum
theory by presenting the relevant canonical formulations of general
relativity, and the proper choice of classical variables to be
quantized. Chapters 3 and 4 introduce the kinematical Hilbert space of
loop quantum gravity and the elementary operators thereon. Chapter 5
deals with gauge invariance, and Chapter 6 describes the basic structure
of the spin network states, which are the elementary gauge invariant
quantum states of the theory. The implementation of diffeomorphism
invariance is discussed in Chapter 7 . In Chapter 8 we introduce
operators corresponding to basic geometric quantities: areas, volumes,
angles and lengths.

In Chapter 9 we present the complexifier coherent states introduced to
loop quantum gravity by Thiemann. This sets the stage for Chapter 10 ,
which concludes the first part of the thesis, and in which we use the
ideas of ”coherent state quantization” to propose an alternative
prescription to define the basic operators of loop quantum gravity, and
study the properties of the operators constructed in this way. The
results presented in Chapter 10 were obtained by the author together
with collaborators, and they have been published in the article [ C ] .
They are not directly relevant to the main topic of this thesis, but
they have been included anyway, since it is reasonable to expect that
the techniques developed in Chapter 10 could be used to investigate the
dynamics of loop quantum gravity once the technology associated with
coherent states in the theory becomes more fully developed.

The second part of this work consists of Chapters 11 – 18 , and deals
with the issue of dynamics in canonical loop quantum gravity,
particularly in the context of deparametrized models. Chapter 11
contains a general introduction to the problem of dynamics. Chapter 12
gives a concise presentation of the classical theory of the
deparametrized models which are considered later in the work; in
particular, it establishes the form of the physical Hamiltonian which
must be quantized in order to define the dynamics of the quantum theory.
Chapter 13 reviews Thiemann’s construction of the Hamiltonian constraint
operator. On one hand, this provides as a prototype for how Hamiltonians
for loop quantum gravity can be constructed. On the other hand, by
studying Thiemann’s Hamiltonian we uncover the reason why it cannot
serve as a mathematically consistent physical Hamiltonian in
deparametrized models, and hence motivate the need to search for an
alternative way of constructing the physical Hamiltonian.

The main results of this thesis, which are presented in Chapters 14 – 18
, are as follows:

-   Construction of a physical Hamiltonian operator for loop quantum
    gravity deparametrized with respect to a free scalar field. The
    essential new feature of the construction is a new technique for
    regularizing the Euclidean part of the Hamiltonian. The new
    regularization ensures that the adjoint of the Euclidean part is
    available as a densely defined operator, making it possible to
    construct a symmetric Hamiltonian, which can be a mathematically
    consistent candidate for the generator of physical time evolution.
    Another aspect of the construction is the use of the curvature
    operator introduced earlier by members of the Warsaw group in place
    of the Lorentzian part of Thiemann’s Hamiltonian. This step leads to
    a considerable simplification in the structure of the Hamiltonian.
    (Chapter 14 )

-   Extension of the ideas introduced in Chapter 14 to the case of the
    Hamiltonian constraint. The constraint operator can be consistently
    defined on the so-called vertex Hilbert space proposed by
    Lewandowski and Sahlmann. The resulting operator not only serves as
    the constraint operator in the vacuum theory, but also provides a
    physical Hamiltonian operator for loop quantum gravity
    deparametrized with respect to non-rotational dust. (Chapter 15 )

-   An explicit computation of the matrix elements of the Hamiltonian
    (or, more precisely, the individual operators out of which the
    Hamiltonian is constructed) in the spin network basis. The
    recoupling theory of @xmath , and in particular the associated
    graphical formalism, is the central tool used in the calculations.
    (Chapter 16 )

-   Development of approximation methods which can be used to compute
    time evolution in deparametrized models, even if an exact knowledge
    of the spectrum of the physical Hamiltonian is not available. The
    main approximation scheme is based on the observation that for
    sufficiently large values of the Barbero–Immirzi parameter, the
    Euclidean part of the Hamiltonian can be considered as a
    perturbation over the comparatively much simpler curvature operator.
    Standard time-independent perturbation theory can then be used to
    approximate the spectrum of the entire Hamiltonian in terms of the
    numerically accessible eigenvalues and eigenstates of the curvature
    operator. (Chapter 17 )

-   A novel description of intertwiners in loop quantum gravity, based
    on projecting intertwiners onto the basis of angular momentum
    coherent states instead of the conventional basis of magnetic
    indices. Within this formalism, intertwiners can be expressed as
    polynomials of certain complex variables, while operators in loop
    quantum gravity, in particular the Hamiltonian, can be formulated as
    differential operators acting on these variables. The main
    motivation for this work is the hope that the action of the
    Hamiltonian could become more transparent when it is expressed
    geometrically, in the language of the unit vectors associate to the
    spin coherent states, as opposed to non-intuitive expressions
    involving combinations of the Wigner @xmath -symbols of @xmath
    recoupling theory. (Chapter 18 )

In the third part of this thesis, we summarize the work presented in it,
and assess the significance of the results obtained. We also point out
the central questions which have been left unanswered in this work, and
mention other possible directions for future research. The fourth part
of the thesis consists of an appendix in which we give a self-contained
presentation of those aspects of @xmath representation and recoupling
theory which are relevant to practical calculations in loop quantum
gravity. In particular, we present a detailed introduction to the
graphical methods which constitute an invaluable tool for computing
matrix elements of loop quantum gravity operators in the spin network
basis.

The material presented in Chapters 14 , 15 , 17 and 18 is based on the
work published respectively in the articles [ A ] , [ B ] , [ E ] and [
D ] . The details of computing matrix elements of the Hamiltonian have
not previously been published anywhere, though the matrix elements given
in Chapter 16 formed the basis for the numerical calculations presented
in [ E ] . In addition to the articles mentioned above, various aspects
of the author’s work on the dynamics of canonical loop quantum gravity
have also been discussed in the conference proceedings [ F ] , [ G ] and
[ H ] .

@xmath

Part 1

The kinematical framework of
loop quantum gravity

  How did I get here? Trickle becomes stream; tributaries run together,
  gathering force. The march of ideas carves channels into the landscape
  – ideas borne by individuals who are in turn swept away by its
  current. This river is our history. We walk in paths worn down by
  those who came before us. Each of us arrives midstream, joining a
  procession so entrenched as to appear as that’s just how it is. From
  deep within these grooves, it’s hard to imagine people just like us
  set it all in motion.

  – Nick Sousanis

## 1 Canonical formulations of general relativity

The classical theory of general relativity is encoded in the
Einstein-Hilbert action

  -- -------- -- -------
     @xmath      (1.1)
  -- -------- -- -------

which leads to the Einstein equations upon variation with respect to the
metric @xmath . The fundamental symmetry of general relativity is
diffeomorphism invariance, which is reflected as the invariance of the
action ( 1.1 ) under general coordinate transformations @xmath . In
particular, a natural notion of time does not exist in the theory.
”Time” is simply one of the spacetime coordinates @xmath ; as such, it
is subject to arbitrary reparametrizations and lacks any physically
distinguished meaning.

### 1.1 Foliation of spacetime

The absence of ”time” in general relativity means that a necessary
prelude for a canonical quantization of the theory is to artificially
introduce a time variable into the formalism. To achieve the splitting
of the spacetime manifold @xmath into ”space” and ”time”, one introduces
a set of spacelike hypersurfaces @xmath , which foliate the entire
manifold @xmath . On each spatial surface @xmath , we have the induced
metric

  -- -------- -- -------
     @xmath      (1.2)
  -- -------- -- -------

where @xmath is the unit normal of @xmath (i.e. @xmath ). The metric
@xmath is determined uniquely by the conditions @xmath , and @xmath for
any vector @xmath tangent to @xmath . Taken in the form @xmath , the
induced metric acts as a projection operator, whose action on any vector
removes the component orthogonal to @xmath .

By itself, the decomposition of spacetime into the surfaces @xmath does
not enable one to view fields on spacetime as fields on space evolving
with respect to the artificial time parameter labeling the surfaces,
even if the surfaces are defined as the constant surfaces of some time
function @xmath on spacetime. What is lacking from the picture is a
well-defined way of associating points on different surfaces @xmath to
each other. Such an association can be provided by choosing a
”time-evolution vector field” @xmath , which must satisfy @xmath , and
whose integral curves identify points on different surfaces @xmath as
the same spatial point at different moments of time. Once the vector
field @xmath is chosen, time derivatives of spatial tensor fields are
naturally defined as

  -- -------- -- -------
     @xmath      (1.3)
  -- -------- -- -------

(where the projections are typically necessary to ensure that the
resulting tensor is again spatial).

In general, the time-evolution vector field can be decomposed into
components orthogonal and tangential to the spatial surface as

  -- -------- -- -------
     @xmath      (1.4)
  -- -------- -- -------

The freedom in choosing @xmath is now parametrized by the lapse function
@xmath and the shift vector @xmath . The freedom to choose arbitrary
coordinates in the spacetime formulation of general relativity is
reflected as the ability to choose the lapse and the shift arbitrarily.

To express the spacetime metric in this formalism, we start from

  -- -------- -- -------
     @xmath      (1.5)
  -- -------- -- -------

Writing this as a matrix, in coordinates where @xmath and @xmath , we
find

  -- -------- -- -------
     @xmath      (1.6)
  -- -------- -- -------

The inverse of this matrix is given by

  -- -------- -- -------
     @xmath      (1.7)
  -- -------- -- -------

and hence the spacetime metric takes the form

  -- -------- -- -------
     @xmath      (1.8)
  -- -------- -- -------

Here we see explicitly that spacetime geometry, described by the ten
components of @xmath , has been traded for the geometry of the spatial
surfaces, described by the six components of @xmath , together with the
four functions @xmath encoding the way in which the spatial surfaces are
embedded in spacetime.

### 1.2 Curvature of the spatial surfaces

The spatial metric @xmath has its associated covariant derivative, which
is determined by the compatibility condition @xmath . Equivalently, the
spatial covariant derivative is given by the projection of the spacetime
covariant derivative down to the spatial surface:

  -- -------- -- -------
     @xmath      (1.9)
  -- -------- -- -------

Recalling that @xmath , we can verify that

  -- -------- -- --------
     @xmath      (1.10)
  -- -------- -- --------

Furthermore, for any scalar function @xmath on @xmath , we have

  -- -------- -- --------
     @xmath      (1.11)
  -- -------- -- --------

where @xmath are the Christoffel symbols of the spacetime metric @xmath
. Therefore @xmath is indeed the unique torsionless covariant derivative
compatible with @xmath .

The spatial covariant derivative defines a spatial curvature tensor
through the relation

  -- -------- -- --------
     @xmath      (1.12)
  -- -------- -- --------

The tensor @xmath measures the intrinsic curvature of the spatial
surface. Information about the curvature associated with the way in
which the spatial surface is embedded in spacetime is contained in the
extrinsic curvature tensor

  -- -------- -- --------
     @xmath      (1.13)
  -- -------- -- --------

Equivalently, the extrinsic curvature can be defined as the Lie
derivative of the spatial metric along the normal vector @xmath :

  -- -------- -- --------
     @xmath      (1.14)
  -- -------- -- --------

This shows that @xmath is a symmetric tensor. Furthermore, the time
derivative of the spatial metric is related to the extrinsic curvature
by ⁴ ⁴ 4 For reasons of space, we refrain from displaying the proofs of
several statements made in this chapter. They can be found e.g. in [ 50
] or [ 122 ] , from which most of the material in this chapter has been
gathered.

  -- -------- -- --------
     @xmath      (1.15)
  -- -------- -- --------

There exist various curvature theorems relating the intrinsic and
extrinsic curvature of the spatial surface to the four-dimensional
spacetime curvature tensor. We have the Gauss equation

  -- -------- -- --------
     @xmath      (1.16)
  -- -------- -- --------

the Codazzi equation

  -- -------- -- --------
     @xmath      (1.17)
  -- -------- -- --------

and the Ricci equation

  -- -------- -- --------
     @xmath      (1.18)
  -- -------- -- --------

where @xmath . Furthermore, contraction of the Ricci equation yields

  -- -------- -- --------
     @xmath      (1.19)
  -- -------- -- --------

where @xmath and @xmath .

### 1.3 The ADM formulation

With the help of the curvature theorems of the previous section, the
Einstein–Hilbert action can be rewritten by eliminating the spacetime
metric in favour of the variables associated with the 3+1 decomposition
of spacetime. Using Eqs. ( 1.16 ) and ( 1.19 ), and exploiting the
symmetries of the Riemann tensor, we find

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      
              @xmath      
              @xmath      (1.20)
  -- -------- -------- -- --------

Noting also that @xmath , and neglecting the boundary term arising from
the last term in Eq. ( 1.20 ), we conclude that the Lagrangian of the
Einstein–Hilbert action becomes

  -- -------- -- --------
     @xmath      (1.21)
  -- -------- -- --------

with a ”kinetic term” involving the extrinsic curvature, and a
”potential term” depending only on the spatial metric. Considering the
spatial metric as the configuration variable, the associated canonical
momentum can be extracted as

  -- -------- -- --------
     @xmath      (1.22)
  -- -------- -- --------

The canonical Hamiltonian

  -- -------- -- --------
     @xmath      (1.23)
  -- -------- -- --------

then comes out in the form

  -- -- -- --------
           (1.24)
  -- -- -- --------

Since the Lagrangian ( 1.21 ) does not contain time derivatives of
@xmath or @xmath , the lapse and the shift appear as Lagrange
multipliers in the Hamiltonian ( 1.24 ). The equations of motion of
@xmath and @xmath are equivalent to the constraint equations @xmath and
@xmath , where

  -- -------- -- --------
     @xmath      (1.25)
  -- -------- -- --------

is called the diffeomorphism constraint (or vector constraint), while

  -- -------- -- --------
     @xmath      (1.26)
  -- -------- -- --------

is the Hamiltonian constraint (or scalar constraint). Only the
components of the spatial metric @xmath have a dynamical equation of
motion, given by @xmath . In fact, by considering contractions of the
Gauss and Codazzi equations, one finds

  -- -------- -- --------
     @xmath      (1.27)
  -- -------- -- --------

where @xmath is the Einstein tensor. This shows that the constraint
equations @xmath and @xmath are equivalent to the four Einstein
equations @xmath and @xmath , while the equations @xmath are encoded in
the equations of motion of the spatial metric.

The total Hamiltonian

  -- -------- -- --------
     @xmath      (1.28)
  -- -------- -- --------

is only a linear combination of the constraints, and therefore vanishes
when the equations of motion are satisfied. This is a general feature in
the mechanics of reparametrization-invariant systems, and is a
reflection of the fact that evolution with respect to the time parameter
@xmath is not a true, physical time evolution, but merely a kind of
gauge transformation, since the time parameter can be arbitrarily
redefined through coordinate transformations.

### 1.4 Analysis of the constraints

To uncover the geometric significance of the diffeomorphism and
Hamiltonian constraint, it is convenient to study them in the smeared
form

  -- -------- -------- -- --------
     @xmath   @xmath      (1.29)
     @xmath   @xmath      (1.30)
  -- -------- -------- -- --------

Straightforward calculations show that the Poisson brackets between the
canonical variables and the diffeomorphism constraint are given by

  -- -------- -- --------
     @xmath      (1.31)
  -- -------- -- --------

indicating that the diffeomorphism constraint indeed generates
diffeomorphisms along the spatial surface. For the Hamiltonian
constraint, it is still relatively simple to find

  -- -------- -- --------
     @xmath      (1.32)
  -- -------- -- --------

However, a much more involved calculation, a detailed outline of which
is given in [ 122 ] , is required to establish the result

  -- -------- -- --------
     @xmath      (1.33)
  -- -------- -- --------

Therefore the Hamiltonian constraint generates diffeomorphisms in the
direction orthogonal to the spatial surface, though this interpretation
is valid only when the equations of motion are satisfied.

The Poisson brackets of the constraints among themselves are given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.34a)
     @xmath   @xmath      (1.34b)
     @xmath   @xmath      (1.34c)
  -- -------- -------- -- ---------

where in the last equation we have the phase space dependent vector
field

  -- -------- -- --------
     @xmath      (1.35)
  -- -------- -- --------

We see that the algebra of the constraints closes, in the sense that the
Poisson brackets between the constraints involve only the constraints
themselves. This means that the ”constraint surface” (i.e. the region of
phase space in which the constraints are satisfied) is preserved under
the action of the constraints. In other words, the evolution generated
by the Hamiltonian ( 1.28 ) preserves the constraint surface, and no
further constraints arise from having to require that the constraints
imposed at some initial time will continue to hold at later times. In
the language of Dirac’s theory of constrained systems [ 66 ] , the set
of constraints @xmath is first class.

The canonical formulation of general relativity described in this and
the previous section was developed in 1962 by Arnowitt, Deser and Misner
[ 10 , 11 ] , whose work was largely motivated by the desire to find a
satisfactory classical starting point for a canonical quantization of
general relativity. A substantial amount of work was subsequently done
on the quantization of the ADM formulation, particularly by DeWitt [ 62
, 63 , 64 ] . In the quantum theory, the momenta @xmath act as
functional derivatives on wave functionals of the spatial metric, and
therefore major problems arise both from the highly non-polynomial way
in which the Hamiltonian constraint ( 1.26 ) depends on the canonical
variables, and from insufficient mathematical understanding of the
”space of metrics” on which wave functionals of the form @xmath are
defined. In fact, no mathematically rigorous quantization of the ADM
formulation has ever emerged, prompting the search for alternative, more
easily quantizable formulations of canonical general relativity.

### 1.5 An intermediate formulation

A new set of variables for canonical general relativity was introduced
by Ashtekar in 1986 [ 12 , 13 ] . The formulation of general relativity
in Ashtekar’s variables is the classical starting point underlying loop
quantum gravity. Following [ 122 ] , we will make our way from the ADM
variables @xmath to the Ashtekar variables by means of an appropriate
canonical transformation. ⁵ ⁵ 5 The Ashtekar variables can also be
derived by performing a 3+1 decomposition of the Holst action [ 80 ]

Here the first term is the Palatini action in the tetrad formalism, and
the second term (with an arbitrary coupling constant @xmath ) vanishes
identically when @xmath is the Riemann curvature, and therefore has no
effect on the classical equations of motion. For details of the
derivation, see e.g. [ 50 ] . The transformation is carried out in two
steps. The first step starts with the introduction of an orthonormal
triad @xmath for the spatial metric,

  -- -------- -- --------
     @xmath      (1.36)
  -- -------- -- --------

the goal being to use (a suitably modified version of) the triad as one
half of the new pair of canonical variables. The co-triad @xmath is the
inverse of @xmath both with respect to the spatial index and the
internal index:

  -- -------- -- --------
     @xmath      (1.37)
  -- -------- -- --------

The spatial metric and its inverse can then be expressed in terms of the
triad as @xmath and @xmath .

We then define the densitized triad

  -- -------- -- --------
     @xmath      (1.38)
  -- -------- -- --------

as the prospective new canonical variable. The inverse spatial metric is
related to the densitized triad by

  -- -------- -- --------
     @xmath      (1.39)
  -- -------- -- --------

By taking the time derivative of this equation, one finds

  -- -------- -- --------
     @xmath      (1.40)
  -- -------- -- --------

which can be used to show that the canonical term in the ADM action
becomes

  -- -------- -- --------
     @xmath      (1.41)
  -- -------- -- --------

where @xmath is the extrinsic curvature in the form

  -- -------- -- --------
     @xmath      (1.42)
  -- -------- -- --------

This suggests that @xmath can indeed be taken as a canonical momentum,
with the corresponding configuration variable being @xmath .

For a more precise demonstration of this claim, one must show that the
Poisson brackets

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.43a)
     @xmath   @xmath      (1.43b)
     @xmath   @xmath      (1.43c)
  -- -------- -------- -- ---------

are equivalent to the canonical Poisson brackets of the ADM variables,
namely

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.44a)
     @xmath   @xmath      (1.44b)
     @xmath   @xmath      (1.44c)
  -- -------- -------- -- ---------

It turns out that ( 1.44a ) and ( 1.44c ) are automatically satisfied,
but the remaining bracket ( 1.44b ) is reproduced only if the constraint

  -- -------- -- --------
     @xmath      (1.45)
  -- -------- -- --------

(which fixes @xmath to be a symmetric tensor) holds. The new constraint,
known as the Gauss constraint, can be written in the equivalent form

  -- -------- -- --------
     @xmath      (1.46)
  -- -------- -- --------

which suggests that it is the generator of rotations associated with the
invariance of the spatial metric under internal @xmath rotations of the
triad. Further calculations show that the diffeomorphism and Hamiltonian
constraints are expressed in terms of the new variables as

  -- -------- -- --------
     @xmath      (1.47)
  -- -------- -- --------

and

  -- -- -- --------
           (1.48)
  -- -- -- --------

### 1.6 Ashtekar variables

In order to pass from the intermediate variables @xmath to the proper
Ashtekar variables, we start by defining a covariant derivative in the
internal space as

  -- -------- -- --------
     @xmath      (1.49)
  -- -------- -- --------

The explicit form of the connection @xmath is determined by the
requirement that the covariant derivative is compatible with the triad,

  -- -------- -- --------
     @xmath      (1.50)
  -- -------- -- --------

From @xmath we construct the so-called spin connection

  -- -------- -- --------
     @xmath      (1.51)
  -- -------- -- --------

Its explicit expression in terms of the densitized triad reads

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (1.52)
  -- -------- -------- -- --------

(where @xmath is the inverse of @xmath ). The Ashtekar connection is
then defined as

  -- -------- -- --------
     @xmath      (1.53)
  -- -------- -- --------

In Ashtekar’s original formulation, the value of the parameter @xmath
was fixed to @xmath , since this choice turns out to significantly
simplify the form of the Hamiltonian constraint. However, this comes at
the price of having to impose reality conditions, which turn out to be
difficult to deal with, especially in the context of quantum theory. The
connection ( 1.53 ) with arbitrary values of @xmath was considered later
by Immirzi [ 83 ] (for complex @xmath ) and Barbero [ 27 ] (for real
@xmath ). For this reason the parameter @xmath , which is now taken to
be real-valued but otherwise arbitrary, is known as the Barbero–Immirzi
parameter.

The Ashtekar connection turns out to be canonically conjugate to the
densitized triad, even though this certainly does not seem obvious at a
first sight, when looking at the explicit form of the spin connection (
1.52 ). A hint that @xmath and @xmath might be a pair of canonical
variables can be derived by considering the antisymmetric part of Eq. (
1.50 ),

  -- -------- -- --------
     @xmath      (1.54)
  -- -------- -- --------

Taking the time derivative of this equation and contracting suitably
with the triad, one can show that

  -- -------- -- --------
     @xmath      (1.55)
  -- -------- -- --------

Hence @xmath is a total derivative, so up to a boundary term we have

  -- -------- -- --------
     @xmath      (1.56)
  -- -------- -- --------

suggesting that @xmath and @xmath are canonically conjugate. To verify
this, one must check that the canonical Poisson brackets

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.57a)
     @xmath   @xmath      (1.57b)
     @xmath   @xmath      (1.57c)
  -- -------- -------- -- ---------

follow from the brackets ( 1.43 ) of the intermediate variables. The
only bracket which is not trivially satisfied is the first one,

  -- -------- -- --------
     @xmath      (1.58)
  -- -------- -- --------

We see that a sufficient condition for the right-hand side to vanish is
that the spin connection @xmath can be derived from a generating
function @xmath as @xmath . A generating function which does the trick
is given by @xmath , since Eq. ( 1.55 ) indicates that the variation
@xmath is a total derivative. This concludes the demonstration that the
variables @xmath and @xmath are canonical.

### 1.7 Constraints in the Ashtekar formulation

We will now translate the constraints ( 1.46 )–( 1.48 ) into the
Ashtekar variables. Defining the covariant derivative of the Ashtekar
connection as

  -- -------- -- --------
     @xmath      (1.59)
  -- -------- -- --------

we can write the Gauss constraint in the form

  -- -------- -- --------
     @xmath      (1.60)
  -- -------- -- --------

since @xmath is constant with respect to the covariant derivative of the
spin connection.

The key to expressing the diffeomorphism and Hamiltonian constraint in
terms of the Ashtekar variables is the identity

  -- -------- -- --------
     @xmath      (1.61)
  -- -------- -- --------

which relates to each other the curvature tensors of the spin connection
and the Ashtekar connection,

  -- -------- -------- -- --------
     @xmath   @xmath      (1.62)
     @xmath   @xmath      (1.63)
  -- -------- -------- -- --------

For the diffeomorphism constraint ( 1.47 ), we contract Eq. ( 1.61 )
with @xmath , obtaining

  -- -------- -- --------
     @xmath      (1.64)
  -- -------- -- --------

The last term on the right-hand side is proportional to the Gauss
constraint ( 1.46 ), and we will therefore ignore it. For the second
term on the right, the structure equations @xmath and @xmath imply
@xmath , from which it follows that @xmath . Hence Eq. ( 1.64 )
indicates that the diffeomorphism constraint ( 1.47 ) is expressed in
terms of the Ashtekar variables as

  -- -------- -- --------
     @xmath      (1.65)
  -- -------- -- --------

For the Hamiltonian constraint, contraction of Eq. ( 1.61 ) with @xmath
gives

  -- -------- -- --------
     @xmath      (1.66)
  -- -------- -- --------

where a term involving the Gauss constraint has again been dropped.
Using Eq. ( 1.66 ), we can eliminate either one of the terms in Eq. (
1.48 ) in favour of the other. In this way we obtain the two equivalent
expressions

  -- -------- -- --------
     @xmath      (1.67)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (1.68)
  -- -------- -- --------

for the Hamiltonian constraint in the Ashtekar variables. (In Eq. ( 1.67
), @xmath should of course be understood as a function of the variables
@xmath and @xmath .) Eq. ( 1.67 ) is the more well-known form of the
constraint, at least in the loop quantum gravity literature, but Eq. (
1.68 ) will play a significant role later in this work, providing an
important ingredient for a new formulation of the dynamics in loop
quantum gravity.

The smeared Gauss constraint

  -- -------- -- --------
     @xmath      (1.69)
  -- -------- -- --------

generates local @xmath gauge transformations on the canonical variables.
This is indicated by the Poisson brackets

  -- -------- -- --------
     @xmath      (1.70)
  -- -------- -- --------

where the expressions on the right-hand side are the variations of the
@xmath -valued objects @xmath and @xmath under an infinitesimal version
of the gauge transformation @xmath , @xmath .

Diffeomorphisms along the spatial surface are generated by the modified
diffeomorphism constraint

  -- -------- -- --------
     @xmath      (1.71)
  -- -------- -- --------

in which a multiple of the Gauss constraint has been subtracted from (
1.65 ). The Poisson brackets of the canonical variables with the
modified constraint ( 1.71 ) read

  -- -------- -- --------
     @xmath      (1.72)
  -- -------- -- --------

The Poisson brackets of the constraints ( 1.69 ) and ( 1.71 ) and the
Hamiltonian constraint @xmath between themselves are given by

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (1.73a)
     @xmath   @xmath      (1.73b)
     @xmath   @xmath      (1.73c)
     @xmath   @xmath      (1.73d)
     @xmath   @xmath      (1.73e)
     @xmath   @xmath      (1.73f)
  -- -------- -------- -- ---------

In the first equation @xmath is the @xmath commutator, and in the last
equation

  -- -------- -- --------
     @xmath      (1.74)
  -- -------- -- --------

and an explicit expression for the function @xmath can be found e.g. in
[ 19 ] . We see that the algebra of the constraints is again first class
in Dirac’s terminology.

## 2 The elementary classical variables

The quantization of any classical theory must start with the choice of
an appropriate set of elementary variables on the classical phase space,
which form the starting point for the construction of the quantum
theory. In the case of general relativity, these variables should be
defined in a background-independent manner, without reference to a
metric or any other fixed background structures on the spatial manifold
@xmath . Further desirable properties of the chosen variables would be
simple behavior under spatial diffeomorphisms and internal gauge
transformations, as well as sufficient smearing so that the Poisson
bracket between the basic variables (which is to be promoted into a
commutator in the quantum theory) is non-singular.

The Ashtekar variables @xmath do not provide a suitable starting point
for quantization by themselves. However, natural geometric objects
related to the Ashtekar connection and the densitized triad are
holonomies of the connection along curves, and fluxes of the triad
through surfaces in the spatial manifold. Loop quantum gravity is based
on the choice of these holonomies and fluxes as the elementary classical
variables. This choice turns out to fulfill all the requirements
outlined above. Moreover, it has the additional advantage that similar
variables are well-known in the context of lattice gauge theories, so
any insights that have been gained there may potentially be useful also
in the case of loop quantum gravity.

### 2.1 The holonomy

The holonomy @xmath is the @xmath -valued parallel propagator of the
Ashtekar connection @xmath along a curve @xmath in the spatial manifold
@xmath . In other words, if @xmath is parametrized by a parameter @xmath
, and if @xmath is any (constant) vector in the @xmath representation
space, the covariant derivative of the vector @xmath along @xmath must
vanish. From this it follows that the holonomy satisfies the
differential equation

  -- -------- -- -------
     @xmath      (2.1)
  -- -------- -- -------

with the initial condition @xmath . Here @xmath , with @xmath the
anti-Hermitian generators of @xmath (normalized according to @xmath ).
Integrating the above equation from 0 to @xmath gives

  -- -------- -- -------
     @xmath      (2.2)
  -- -------- -- -------

By repeatedly iterating this equation and evaluating the solution at
@xmath , we find the explicit expression

  -- -------- -- -------
     @xmath      (2.3)
  -- -------- -- -------

or

  -- -------- -- -------
     @xmath      (2.4)
  -- -------- -- -------

@xmath denoting the path-ordered exponential, with smaller values of the
path parameter ordered to the right.

From Eq. ( 2.4 ) it is immediate to see that the holonomy satisfies the
property

  -- -------- -- -------
     @xmath      (2.5)
  -- -------- -- -------

where @xmath denotes @xmath taken with the opposite orientation.
Moreover, if @xmath and @xmath are two curves such that the endpoint of
@xmath coincides with the beginning point of @xmath , we have

  -- -------- -- -------
     @xmath      (2.6)
  -- -------- -- -------

where @xmath is the curve composed of @xmath followed by @xmath .

A further property of the holonomy, which we will need later on, is the
relation between the holonomy around a small closed loop and the
curvature of the Ashtekar connection. This relation can be extracted
from the basic formula ( 2.3 ) as follows. Suppose that @xmath is a
closed loop of infinitesimal coordinate area @xmath . By Eq. ( 2.3 ),
the holonomy around the loop is given by

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (2.7)
  -- -------- -------- -- -------

For concreteness, let us choose coordinates such that @xmath lies in the
@xmath -plane and passes through the origin of the coordinate system.
Then we can expand the connection around the point @xmath as @xmath
(throughout the calculation we are dropping terms which will not
contribute to the final result at lowest nontrivial order). Inserting
this into Eq. ( 2.7 ) and evaluating the integrals @xmath and @xmath ,
we find

  -- -------- -- -------
     @xmath      (2.8)
  -- -------- -- -------

The integral @xmath is evidently antisymmetric in @xmath and @xmath , so
we can write

  -- -------- -- -------
     @xmath      (2.9)
  -- -------- -- -------

Now the remaining integral @xmath simply gives the area enclosed by the
loop @xmath , i.e. @xmath . Therefore we conclude

  -- -------- -- --------
     @xmath      (2.10)
  -- -------- -- --------

which is the relation we were looking for (and of course at lowest order
in @xmath , the curvature may be evaluated at any point on or inside of
@xmath ). The infinitesimal relation ( 2.10 ) can be seen as a special
case of the non-Abelian Stokes’ theorem (see e.g. [ 53 ] ), which
relates the path-ordered exponential of the connection around an
arbitrary loop to the so-called surface-ordered exponential of the
curvature over a surface bounded by the loop (the surface ordering
becoming irrelevant in the limit where the size of the loop shrinks to
zero).

### 2.2 The flux

The conjugate variable to the holonomy is given by the flux of the
densitized triad @xmath across a (two-dimensional) surface @xmath in
@xmath . Introducing coordinates @xmath on the surface, so that the
location of the surface in @xmath is given by @xmath , the flux is
defined as

  -- -------- -- --------
     @xmath      (2.11)
  -- -------- -- --------

with @xmath the normal one-form on @xmath . (Note that no metric on
@xmath is needed in order to define @xmath .) More generally, making use
of an @xmath -valued function @xmath , we may consider the smeared flux
variable

  -- -------- -- --------
     @xmath      (2.12)
  -- -------- -- --------

Notice that in the definitions Eq. ( 2.4 ) and Eq. ( 2.11 ) the
connection and the densitized triad are integrated respectively against
one-dimensional curves and two-dimensional surfaces. Hence the total
degree of smearing is just enough to absorb the delta function present
in the Poisson bracket @xmath , making the Poisson bracket between the
holonomy and the flux non-singular.

### 2.3 Poisson bracket of the elementary variables

In order to compute the Poisson bracket between the holonomy and the
flux, we must first find the functional derivative of the holonomy with
respect to the connection. This can be done by considering the
functional derivative of the defining equation ( 2.1 ) [ 91 ] :

  -- -------- -- --------
     @xmath      (2.13)
  -- -------- -- --------

This can be solved with the ansatz

  -- -------- -- --------
     @xmath      (2.14)
  -- -------- -- --------

which gives, after inserting into Eq. ( 2.13 ) and using Eq. ( 2.1 )

  -- -- -- --------
           (2.15)
  -- -- -- --------

By inspection, the solution of this equation is

  -- -------- -- --------
     @xmath      (2.16)
  -- -------- -- --------

and the requirement @xmath shows that the constant is equal to zero.
Setting then @xmath and introducing the notation @xmath for the segment
of @xmath extending from parameter value @xmath to parameter value
@xmath , we obtain the result

  -- -------- -- --------
     @xmath      (2.17)
  -- -------- -- --------

With the help of Eq. ( 2.17 ), and following [ 106 ] , we may now
compute the Poisson bracket between @xmath and @xmath . We have

  -- -------- -- --------
     @xmath      (2.18)
  -- -------- -- --------

Here the integral clearly vanishes if the curve @xmath does not
intersect the surface @xmath . The integral also vanishes if @xmath
intersects @xmath tangentially, in which case the tangent vector @xmath
is orthogonal to the normal @xmath at the intersection point. In the
case of a single transversal intersection, the factor

  -- -------- -- --------
     @xmath      (2.19)
  -- -------- -- --------

is the Jacobian of the coordinate transformation @xmath around the
intersection point. After performing the change of variables, we find
that the integral is equal to @xmath , the sign depending on the
relative orientation of @xmath and @xmath . We have therefore shown that
⁶ ⁶ 6 We have assumed that the point where @xmath intersects @xmath is
not the beginning or ending point of @xmath . In case it is, the result
( 2.20 ) is multiplied by @xmath , because the delta function in ( 2.18
) now gets integrated only over half of its domain.

  -- -------- -- --------
     @xmath      (2.20)
  -- -------- -- --------

where @xmath is the value of the curve parameter at the intersection
point, and the factor @xmath is defined as

  -- -------- -- --------
     @xmath      (2.21)
  -- -------- -- --------

If @xmath and @xmath intersect at multiple points, then each
intersection contributes a term of the form ( 2.20 ).

For the purpose of choosing appropriate classical variables for the
construction of the quantum theory, the most important feature of the
result ( 2.20 ) is that the algebra of the holonomy and the flux closes,
in the sense that their Poisson bracket depends on a finite number of
the basic variables. As can be seen from Eq. ( 2.18 ), this would not be
the case if one had chosen a three-dimensional smearing of the
densitized triad.

### 2.4 Gauge transformations and diffeomorphisms

Let us then consider the behavior of the holonomy and the flux under
@xmath gauge transformations and spatial diffeomorphisms. Under a local
gauge transformation given by the group element @xmath , the
corresponding non-smeared variables transform as

  -- -------- -- --------
     @xmath      (2.22)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (2.23)
  -- -------- -- --------

To find the transformation law of the holonomy, suppose that the vector
@xmath satisfies the equation

  -- -------- -- --------
     @xmath      (2.24)
  -- -------- -- --------

from which it follows that @xmath . If we introduce the gauge
transformed vector @xmath , then a direct calculation shows that @xmath
satisfies

  -- -------- -- --------
     @xmath      (2.25)
  -- -------- -- --------

with the gauge transformed connection @xmath . It follows that @xmath ,
from which we obtain, after setting @xmath , inserting @xmath and
rearranging,

  -- -------- -- --------
     @xmath      (2.26)
  -- -------- -- --------

where @xmath and @xmath denote respectively the beginning point (source)
and endpoint (target) of the curve @xmath .

The transformation law of the flux is the most simply stated in terms of
the smeared flux variable ( 2.12 ). Observing that @xmath , we
immediately find

  -- -------- -- --------
     @xmath      (2.27)
  -- -------- -- --------

For a diffeomorphism @xmath on the spatial manifold @xmath , it is
straightforward to show that

  -- -------- -------- -- --------
     @xmath   @xmath      (2.28)
     @xmath   @xmath      (2.29)
  -- -------- -------- -- --------

We therefore see that the holonomy and the flux have simple and natural
transformation properties under gauge transformations and
diffeomorphisms. The non-local transformation law of the flux under
gauge transformations turns out to not present a problem for
constructing gauge-invariant operators in the quantum theory, ultimately
because all ”interesting” operators can be expressed in terms of fluxes
associated to infinitesimally small surfaces.

### 2.5 Parallel transported flux variable

We close this chapter on the choice of classical variables by mentioning
a possible alternative definition of the flux variable. This definition
requires us to choose a set of curves @xmath which connect each point
@xmath on @xmath (or at least each point on the surface @xmath ) to a
fixed point @xmath , which may lie on @xmath or outside of it. The
”parallel transported” flux variable is then defined as

  -- -------- -- --------
     @xmath      (2.30)
  -- -------- -- --------

The main advantage of this definition is the local behavior of the
parallel transported flux under gauge transformations: under the
transformation ( 2.22 )–( 2.23 ) we simply have

  -- -------- -- --------
     @xmath      (2.31)
  -- -------- -- --------

Even so, the variable ( 2.30 ) is probably not an ideal choice for the
variable on which the construction of the quantum theory is based, since
the presence of holonomies makes it technically more complicated, and
the choice of the paths @xmath introduces a considerable amount of
arbitrariness into the construction. The operator corresponding to the
variable ( 2.30 ) will nevertheless be a useful quantity in the quantum
theory obtained by choosing the holonomy and the simple flux ( 2.11 ) as
the fundamental classical variables.

## 3 The kinematical Hilbert space

A general framework for quantizing classical theories with constraints
has been formulated by Dirac in [ 66 ] . The first step of Dirac’s
algorithm is to define a kinematical Hilbert space, on which the Poisson
brackets between the elementary classical variables – given by Eq. (
2.20 ) in the case of loop quantum gravity – are represented by the
commutation relations between the corresponding elementary operators.
The following step of the program consists of imposing the constraints
in the quantum theory by constructing operators corresponding to the
constraints and looking for the sector of the kinematical Hilbert space
which is annihilated by all of the constraint operators. Once the
physical Hilbert space has been constructed in this way, information
about the physical content of the theory will be encoded in the set of
physical observables (i.e. operators commuting with all the
constraints), and in the scalar product of the physical Hilbert space,
which defines transition amplitudes between the physical states.

### 3.1 Cylindrical functions

The kinematical Hilbert space of loop quantum gravity is defined in
terms of so-called cylindrical functions of a (generalized,
distributional) connection @xmath (see [ 19 ] and references therein).
Suppose @xmath is a graph consisting of @xmath oriented edges @xmath ,
embedded in the spatial manifold @xmath . Then a cylindrical function is
a functional of the form

  -- -------- -- -------
     @xmath      (3.1)
  -- -------- -- -------

where @xmath is any (complex-valued) function on @xmath . More
precisely, the function @xmath is called cylindrical with respect to the
graph @xmath . We denote the set of all functions cylindrical with
respect to @xmath by @xmath , and the set of all cylindrical functions
(with respect to any graph) by @xmath .

There is considerable freedom in choosing the graph on which a given
cylindrical function is defined. In particular, any function that is
cylindrical with respect to a graph @xmath is also cylindrical with
respect to any larger graph @xmath which contains all the edges of
@xmath . Explicitly, the function ( 3.1 ) can be written as a
cylindrical function on @xmath as

  -- -------- -- -------
     @xmath      (3.2)
  -- -------- -- -------

where @xmath are the edges of @xmath that are not contained in @xmath ,
and the function @xmath is equal to @xmath regardless of the values of
the arguments @xmath . We may also consider reversing the orientation of
an edge in @xmath , as well as artificially splitting a single edge into
two by introducing a ”trivial” bivalent node. The properties ( 2.5 ) and
( 2.6 ) indicate that these operations correspond respectively to
replacing a @xmath with @xmath , and replacing a pair of arguments
@xmath , @xmath with the single argument @xmath , in the function @xmath
of Eq. ( 3.1 ).

### 3.2 Scalar product on @xmath

A scalar product on @xmath can be naturally defined using the
(normalized) Haar measure on @xmath [ 14 , 15 ] . To begin with, for two
functions of the form ( 3.1 ), both cylindrical with respect to the same
graph @xmath , we may simply define

  -- -------- -- -------
     @xmath      (3.3)
  -- -------- -- -------

In order to define the scalar product between two functions @xmath and
@xmath , cylindrical with respect to two different graphs @xmath and
@xmath , we note that the freedom described above allows us to take any
graph @xmath that contains both @xmath and @xmath as subgraphs, and view
@xmath and @xmath as cylindrical functions on @xmath . The scalar
product between the two functions can then be defined as

  -- -------- -- -------
     @xmath      (3.4)
  -- -------- -- -------

with the right-hand side given by Eq. ( 3.3 ). The normalization of the
Haar measure guarantees that the value of @xmath does not depend on how
the graph @xmath is chosen. Moreover, the transformation laws ( 2.26 )
and ( 2.28 ) of the holonomy, together with the left and right
invariance of the Haar measure, imply that the scalar product defined
here is gauge and diffeomorphism invariant. The kinematical Hilbert
space of loop quantum gravity is then defined as the Cauchy completion
of @xmath with respect to the norm arising from the scalar product ( 3.3
):

  -- -------- -- -------
     @xmath      (3.5)
  -- -------- -- -------

### 3.3 Decomposition into orthogonal subspaces

The space of all cylindrical functions can clearly be decomposed into
subspaces of functions cylindrical with respect to a given graph, i.e.
@xmath . However, because any cylindrical function can be considered as
cylindrical with respect to many different graphs, the subspaces @xmath
are not orthogonal to each other. A decomposition into orthogonal
subspaces can nevertheless be obtained by suitably restricting the set
of graphs included in the decomposition, as well as the set of functions
belonging to the subspace associated to each graph [ 20 ] .

First of all we note that reversing the orientation of any number of
edges of a graph does not produce independent cylindrical functions,
since the matrix elements of an inverse @xmath matrix @xmath are not
independent from those of @xmath , but are related to them by @xmath .
Therefore graphs which differ from each other only by orientation of
some of their edges should not be counted as two different graphs in the
orthogonal decomposition of @xmath .

Secondly we must remove the redundancy which arises from being able to
arbitrarily enlarge the graph on which a cylindrical function is
defined. Due to the freedom to introduce trivial edges into the graph,
the subspace of a graph @xmath should only contain functions that have a
non-trivial dependence on each holonomy associated with the edges of
@xmath . Furthermore, the freedom to split an edge into two by
introducing a trivial bivalent node dictates that if the graph does
contain a bivalent node at which two edges @xmath and @xmath meet, then
the corresponding cylindrical function must depend on the holonomies of
the two edges in some other way and not only through the matrix product
@xmath . (If the dependence on the two holonomies were only through
their product, then the function would be cylindrical also with respect
to the smaller graph from which the bivalent node is absent.)

Hence we have argued that a decomposition of @xmath into orthogonal
subspaces is given by

  -- -------- -- -------
     @xmath      (3.6)
  -- -------- -- -------

where the union is taken over equivalence classes @xmath of graphs up to
orientation of the edges, and the space @xmath contains only those
functions ( 3.1 ) for which @xmath is not constant with respect to any
of its arguments, and which do not contain any trivial bivalent nodes of
the type described above.

### 3.4 Basis states

The form of the scalar product ( 3.3 ) implies that @xmath , the space
of cylindrical functions based on a single edge @xmath , is essentially
the space @xmath . Therefore we can find a basis on @xmath by using the
Peter-Weyl theorem, which says that an orthonormal basis on @xmath ,
with @xmath any compact Lie group, is given by (suitably normalized)
matrix elements of the irreducible representation matrices of the group.
In the case of @xmath , the functions

  -- -------- -- -------
     @xmath      (3.7)
  -- -------- -- -------

provide an orthonormal basis on @xmath . Since the space @xmath is
essentially a tensor product of the spaces @xmath over the edges of
@xmath , it follows that an orthonormal basis on @xmath is formed by
products of the functions ( 3.7 ),

  -- -------- -- -------
     @xmath      (3.8)
  -- -------- -- -------

Let us then introduce a useful generalization of the basis ( 3.8 ),
which can be used, among other things, to find a convenient orthonormal
basis on the reduced space @xmath , and consequently on the entire space
@xmath . Suppose the spin labels belonging to the edges of @xmath are
fixed, and consider a node of @xmath with @xmath incoming edges @xmath
carrying spins @xmath , and @xmath outgoing edges @xmath carrying spins
@xmath . To this node we associate a set of tensors of the form @xmath
(carrying a lower index for each edge coming in to the node and an upper
index for each edge going out of the node), which are required to form
an orthonormal basis of the space @xmath but can be otherwise chosen
arbitrarily. After such an assignment of tensors is carried out at each
node of the graph, we may define the functions

  -- -------- -- -------
     @xmath      (3.9)
  -- -------- -- -------

where the contraction of @xmath indices is carried out according to the
structure of the graph @xmath . (That is, for each @xmath , the index
@xmath corresponds to one index of the tensor @xmath at the ending node
of @xmath , with which it is contracted. The index @xmath is similarly
contracted with the tensor at the beginning node of @xmath .) The
functions ( 3.9 ) also form an orthonormal basis of @xmath , and in fact
the previous basis ( 3.8 ) can be obtained from ( 3.9 ) by making a
suitable (and rather simple) choice of the tensors @xmath .

The conditions by which the space @xmath is reduced to @xmath are
particularly simple to state in terms of the functions ( 3.9 ). The
space @xmath is spanned by those states of the form ( 3.9 ) for which
none of the spins associated to the edges of the graph are equal to
zero. Furthermore, for each bivalent node of the graph, the tensor
associated to the node must not be proportional to the unit tensor.
Equivalently, using the language of @xmath recoupling theory, the spins
of the two edges which meet at the bivalent node must not be coupled to
total spin zero by the tensor at the node.

## 4 Operators on @xmath

In this chapter we will introduce a number of basic operators on the
kinematical Hilbert space. In particular, we will define operators
corresponding to holonomies and fluxes, and show that their commutator
correctly reproduces the fundamental classical Poisson bracket ( 2.20 ).

### 4.1 Holonomy operator

The holonomy operator acts on cylindrical functions by multiplication:

  -- -------- -- -------
     @xmath      (4.1)
  -- -------- -- -------

Note that the character of the result depends on whether the edge @xmath
is among the edges of the graph @xmath . If @xmath is not contained in
@xmath , then the right-hand side of ( 4.1 ) is a cylindrical function
on the graph @xmath ; in effect, the action of the holonomy operator has
added a new edge to the graph on which the cylindrical function is
based. If @xmath coincides with one of the edges of @xmath , the
function ( 4.1 ) is still an element of @xmath . In this case, the basic
tool for computing the explicit action of the holonomy operator in the
basis ( 3.8 ) or ( 3.9 ) is the Clebsch–Gordan series of @xmath :

  -- -------- -- -------
     @xmath      (4.2)
  -- -------- -- -------

where @xmath and @xmath denote the @xmath Clebsch--Gordan coefficients ⁷
⁷ 7 This somewhat unusual notation is chosen in order to display the
correct index structure of equations involving @xmath magnetic indices.
For a full discussion of this point, we refer the reader to the
Appendix. Briefly, letting @xmath and @xmath denote the ”uncoupled” and
”coupled” states in @xmath , the Clebsch–Gordan coefficient is given by
@xmath ; therefore the index @xmath is a dual (or upper) index. In usual
physics literature the inverse coefficient @xmath is normally not
distinguished from @xmath , because the two are numerically equal to
each other when standard phase conventions are used. . The remaining
case, where @xmath partially overlaps with an edge (or multiple edges)
of @xmath , can be reduced to the two cases discussed above by using the
multiplicative property ( 2.6 ) of the holonomy. Naturally any
cylindrical function of @xmath also gives rise to a well-defined
multiplicative operator on @xmath .

On the other hand, the connection @xmath itself does not exist as a
well-defined operator on the kinematical Hilbert space. Since the
holonomy of the connection along a path @xmath of infinitesimal
coordinate length @xmath is given by @xmath , one could try to define a
connection operator in the quantum theory through a suitable limit of
the form

  -- -------- -- -------
     @xmath      (4.3)
  -- -------- -- -------

However, the action of the operator @xmath on the function @xmath will
always modify either the graph @xmath over which the function is
cylindrical, or the spin quantum number associated to an edge of @xmath
(depending on whether @xmath coincides with an edge of @xmath ). For
this reason, the function @xmath will typically be orthogonal to @xmath
under the scalar product ( 3.3 )–( 3.4 ) even for arbitrarily small
values of @xmath , and therefore the limit ( 4.3 ) fails to exist in
general.

### 4.2 The operator @xmath

At this point it is convenient to define several auxiliary operators,
which will facilitate the discussion of the flux operator – i.e. the
operator corresponding to the classical variable ( 2.11 ) – and later
turn out to be useful in other ways as well. To begin with, we define
the so-called left- and right-invariant vector fields,

  -- -------- -- -------
     @xmath      (4.4)
  -- -------- -- -------

which are operators on @xmath (or @xmath ). In the literature one
sometimes also encounters the operators

  -- -------- -- -------
     @xmath      (4.5)
  -- -------- -- -------

where @xmath is an arbitrary element of @xmath .

Using the left- and right-invariant vector fields, we further define a
set of very useful operators @xmath on @xmath . Each of these operators
carries an @xmath vector index @xmath and is labeled by a point @xmath
and an edge @xmath such that @xmath is either the beginning or the
ending point of @xmath . The action of these operators on cylindrical
functions is defined in the following way. If @xmath is a graph which
contains @xmath as one of its edges, then the operator @xmath is
declared to act on elements of @xmath as

  -- -------- -- -------
     @xmath      (4.6)
  -- -------- -- -------

where @xmath and @xmath act on the holonomy @xmath . In the case where
@xmath is not an edge of @xmath , or @xmath is not a node of @xmath , we
set @xmath

It is immediate to see that the action of the operators @xmath on
holonomies is given by

  -- -------- -- -------
     @xmath      (4.7)
  -- -------- -- -------

Furthermore, they satisfy the @xmath algebra

  -- -------- -- -------
     @xmath      (4.8)
  -- -------- -- -------

Of course, using @xmath and @xmath in place of @xmath and @xmath , we
may also define the operators @xmath .

### 4.3 Flux operator

We are now ready to discuss the flux operator, i.e. the operator
resulting from quantizing the classical function ( 2.11 ). Let us try to
compute the action of the operator on a basis state of the form ( 3.8 ).
Applying the quantization rule @xmath , we obtain

  -- -------- -- -------
     @xmath      (4.9)
  -- -------- -- -------

Recalling Eq. ( 2.17 ), it is evident that each edge which intersects
the surface @xmath will contribute a term of the form

  -- -------- -- --------
     @xmath      (4.10)
  -- -------- -- --------

The integral appearing here has already been encountered in Eq. ( 2.18
), and is equal to @xmath or @xmath , depending on whether the edge
@xmath intersects @xmath at its beginning point or endpoint. As before,
edges intersecting @xmath tangentially, or not intersecting it at all,
do not give a contribution. Comparing the result with the definition of
@xmath , we see that the action of the flux operator can be expressed in
the form

  -- -------- -- --------
     @xmath      (4.11)
  -- -------- -- --------

where the geometric factor @xmath is defined as

  -- -------- -- --------
     @xmath      (4.12)
  -- -------- -- --------

Here ”above” and ”below” are understood with respect to the direction
defined by the normal vector of the surface. The uncountable sum over
all the points of @xmath may look unsettling at a first sight, but the
expression ( 4.11 ) is nevertheless well defined, since the sum receives
non-vanishing contributions only from the finite number of points at
which the edges of the graph @xmath intersect the surface @xmath .

On the other hand, the densitized triad @xmath is not a well-defined
operator on @xmath (precisely as was the case with the holonomy and the
connection). This is because the functional derivative @xmath , given by
Eq. ( 2.17 ), contains a delta function and is therefore not a
normalizable element of the kinematical Hilbert space.

Using Eqs. ( 4.1 ) and ( 4.11 ), it is a simple calculation to verify
that the commutator between the holonomy and flux operators is correctly
related to the Poisson bracket between the corresponding classical
variables. For example, in the case where the edge @xmath has a single
intersection with the surface @xmath , one finds

  -- -------- -- --------
     @xmath      (4.13)
  -- -------- -- --------

(where, as in Eq. ( 2.20 ), @xmath is the value of the curve parameter
at the intersection point).

### 4.4 Generalizations of the flux operator

By following the steps that led to Eq. ( 4.11 ), one may also construct
the operators corresponding to the smeared and parallel transported flux
variables ( 2.12 ) and ( 2.30 ). For the smeared flux operator, an
entirely similar calculation that led to ( 4.11 ) produces the result

  -- -------- -- --------
     @xmath      (4.14)
  -- -------- -- --------

In the case of the parallel transported flux, we take

  -- -------- -- --------
     @xmath      (4.15)
  -- -------- -- --------

as the classical variable to be quantized. In order to derive the form
of the resulting operator, it is convenient to start by using the
relation

  -- -------- -- --------
     @xmath      (4.16)
  -- -------- -- --------

where @xmath is the @xmath rotation matrix corresponding to the @xmath
element @xmath , to rewrite the variable ( 4.15 ) as

  -- -------- -- --------
     @xmath      (4.17)
  -- -------- -- --------

To find the action of the operator on a holonomy, it now suffices to
essentially repeat the calculation performed in the previous section
(assuming a factor ordering where the functional derivative is ordered
to the right). For instance, if the beginning point of @xmath lies on
@xmath , we find

  -- -------- -- --------
     @xmath      (4.18)
  -- -------- -- --------

where Eq. ( 4.16 ) has been used in reverse to eliminate the rotation
matrix. From this (and the corresponding calculation for the case where
the edge @xmath ends on @xmath ) we may conclude that the parallel
transported flux operator takes the form

  -- -------- -- --------
     @xmath      (4.19)
  -- -------- -- --------

Note that this operator is given in terms of operators @xmath where
@xmath is an @xmath -dependent function. Therefore, while the operator
@xmath maps each space @xmath into itself (in other words, preserves the
graph of the cylindrical function on which it acts), the same might not
always be the case for the operator @xmath .

### 4.5 Uniqueness of the kinematical representation

The kinematical representation of holonomies and fluxes, described in
this and the preceding chapter and commonly referred to as the
Ashtekar–Lewandowski representation, has several peculiar properties.
For example, an operator representing the Ashtekar connection does not
exist, and as we will see later, geometric operators corresponding to
quantities such as areas of surfaces and volumes of regions in the
spatial manifold @xmath , turn out to have purely discrete spectra. On
the other hand, the construction of the representation may seem somewhat
arbitrary, so it is natural to ask how much freedom there would be in
possibly constructing different, inequivalent kinematical
representations for loop quantum gravity.

An answer to this question is provided by a uniqueness theorem – the
so-called LOST theorem [ 92 , 73 ] – which states that under certain
rather general assumptions, the Ashtekar–Lewandowski representation is
(up to unitary equivalence) the only representation of the holonomy-flux
algebra. Diffeomorphism invariance, which enters through the assumption
that the kinematical Hilbert space contains at least one diffeomorphism
invariant state, plays a crucial role in the proof of the theorem. This
result is all the more remarkable if one recalls that no corresponding
uniqueness theorem holds in conventional quantum field theories, in
which many different, inequivalent representations may generally exist.

Alternative kinematical representations for loop quantum gravity have
nevertheless been introduced by circumventing one or more of the
assumptions of the LOST theorem. The Koslowski–Sahlmann representation [
86 , 113 ] violates the LOST theorem’s assumptions about diffeomorphisms
by introducing a fixed, classical background geometry. The flux
representation of Dittrich and Geiller [ 67 , 68 , 25 ] is based on an
altogether different choice of elementary classical variables.

## 5 Gauge invariance

The kinematical Hilbert space of loop quantum gravity and the elementary
operators on it having been set, the next stage of the quantization
program consists of imposing the Gauss, diffeomorphism and Hamiltonian
constraints. In other words, one is looking for a precise way of
implementing the steps indicated by the schematic diagram

  -- -------- --
     @xmath   
  -- -------- --

The first two steps of the diagram, corresponding to the Gauss and
diffeomorphism constraints, are well understood. On the other hand,
finding a satisfactory and practically manageable way to deal with the
Hamiltonian constraint has proven rather elusive, and forms the main
subject of the second part of this work. In this chapter we take the
relatively simple example of the Gauss constraint as an opportunity to
illustrate the various possible approaches to the problem of solving a
given constraint. The diffeomorphism constraint will be discussed in
Chapter 7 .

### 5.1 Solution by inspection

The ideal situation would be that the gauge transformations generated by
the constraint are understood in sufficient detail that the set of
states invariant under these transformations can simply be written down
by inspection. In the case of the Gauss constraint, the associated gauge
transformations are local @xmath gauge transformations. We recall that
under a transformation specified by the gauge function @xmath , the
holonomy transforms as

  -- -------- -- -------
     @xmath      (5.1)
  -- -------- -- -------

Using this, we may consider how a gauge transformation affects a generic
state such as the state @xmath of Eq. ( 3.9 ). Let us focus on a
specific node @xmath of @xmath . Eq. ( 5.1 ) shows that each edge ending
at @xmath contributes a @xmath , while each edge starting from @xmath
contributes a @xmath , where @xmath is the value of the gauge function
at the node. Hence the gauge transformation effectively replaces the
tensor @xmath with the gauge transformed tensor

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (5.2)
  -- -------- -------- -- -------

at each node of the graph, but otherwise preserves the form of the state
@xmath .

From these considerations it is clear that a set of gauge invariant
states can be obtained by restricting the set of tensors @xmath to those
that satisfy @xmath for every @xmath . In particular, an orthonormal
basis on the gauge invariant subspace of @xmath , which we denote by
@xmath , is given by the states

  -- -------- -- -------
     @xmath      (5.3)
  -- -------- -- -------

provided that the tensors @xmath at each node @xmath are taken from any
orthonormal basis of the space @xmath , i.e. the subspace of @xmath
whose elements are invariant under @xmath in the sense of Eq. ( 5.2 ).
The space of all gauge invariant cylindrical functions, denoted by
@xmath , is then spanned by the states ( 5.3 ) on all possible graphs
@xmath , and finally the entire gauge invariant Hilbert space @xmath is
defined as the completion of @xmath (with respect to the norm arising
from the scalar product ( 3.3 )).

### 5.2 The Gauss constraint operator

The approach most in line with Dirac’s ideas on quantizing a constrained
theory is to systematically construct a quantum operator corresponding
to the constraint and then try to find all the states that are
annihilated by the operator. For the Gauss constraint, following the
treatment of [ 122 ] , we start by performing an integration by parts in
the classical expression @xmath , which leads us to consider the
operator

  -- -------- -- -------
     @xmath      (5.4)
  -- -------- -- -------

In order to derive the action of the operator on a generic cylindrical
function, let us first calculate how @xmath acts on a single holonomy.
Recalling Eq. ( 2.17 ), we find

  -- -------- -- -------
     @xmath      (5.5)
  -- -------- -- -------

the delta function arising from the functional derivative having been
absorbed by the integration over @xmath . Introducing the notation
@xmath and @xmath , we can write this as

  -- -- -- -------
           (5.6)
  -- -- -- -------

If we now use the holonomy equation ( 2.1 ) in the form

  -- -------- -- -------
     @xmath      (5.7)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (5.8)
  -- -------- -- -------

we see that Eq. ( 5.6 ) reduces to

  -- -------- -------- -- -------
     @xmath   @xmath      
              @xmath      (5.9)
  -- -------- -------- -- -------

From this we may deduce that the action of the Gauss constraint operator
on a general cylindrical function is given by

  -- -------- -- --------
     @xmath      (5.10)
  -- -------- -- --------

or

  -- -------- -- --------
     @xmath      (5.11)
  -- -------- -- --------

where the Gauss operator associated to a single node is

  -- -------- -- --------
     @xmath      (5.12)
  -- -------- -- --------

Having constructed the constraint operator @xmath , the following step
of the program is to try to find all the states which are annihilated by
the operator. Using Eq. ( 5.10 ) to act on the generic basis state ( 3.9
), we find that @xmath annihilates the state provided that the tensor
@xmath at each node satisfies the condition

  -- -------- -------- -- --------
     @xmath               
              @xmath      (5.13)
  -- -------- -------- -- --------

But this condition simply requires @xmath to be invariant under @xmath ,
since ( 5.13 ) is equivalent to ( 5.2 ) for an infinitesimal gauge
transformation, arising from a gauge function of the form @xmath . Hence
the more methodical approach has reproduced the states ( 5.3 ) as the
solutions of the Gauss constraint.

### 5.3 Group averaging

Yet another way to approach the problem of finding the solutions of a
constraint is the so-called procedure of group averaging [ 20 ] . A
particular virtue of this approach is that group averaging may possibly
be used even if a well-defined constraint operator cannot be constructed
for some reason. The idea is to construct solutions of the constraint by
suitably averaging arbitrary cylindrical functions with respect to the
action of the gauge transformations associated with the constraint. In
the example of the Gauss constraint, let us consider the (at this point
formal) projection operator

  -- -------- -- --------
     @xmath      (5.14)
  -- -------- -- --------

where @xmath is the unitary operator which implements gauge
transformations on cylindrical functions, and @xmath is some appropriate
integration measure constructed using the @xmath Haar measure. Due to
the group property of the operators @xmath and the invariance of the
Haar measure, the operator @xmath should satisfy @xmath . Therefore,
given any cylindrical function @xmath , we would expect the function
@xmath to be gauge invariant.

The gauge transformation of a cylindrical function on a graph @xmath is
completely determined by the values of the gauge function @xmath at the
nodes of @xmath . Therefore an appropriate definition of the operator (
5.14 ) on @xmath would be

  -- -------- -- --------
     @xmath      (5.15)
  -- -------- -- --------

Recalling the transformation law ( 5.1 ), we see that the function

  -- -------- -- --------
     @xmath      (5.16)
  -- -------- -- --------

is indeed gauge invariant.

In order to derive the form of the gauge invariant functions ( 5.3 )
from the group averaging approach, let us expand the function @xmath in
( 5.16 ) in the basis ( 3.8 ) as

  -- -------- -- --------
     @xmath      (5.17)
  -- -------- -- --------

Inserting this into Eq. ( 5.16 ) and using the identity

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (5.18)
  -- -------- -------- -- --------

where the sum over @xmath runs through any (real-valued) orthonormal
basis of the intertwiner space @xmath , we find that group averaging of
the function ( 5.17 ) indeed produces a function of the form

  -- -------- -- --------
     @xmath      (5.19)
  -- -------- -- --------

Thus we once again obtain the result that gauge invariant functions on
@xmath are given by linear combinations of the states ( 5.3 ).

## 6 Spin network states

The states

  -- -------- -- -------
     @xmath      (6.1)
  -- -------- -- -------

which span the gauge-invariant Hilbert space @xmath , are called spin
network states [ 110 , 23 , 24 ] . The ”quantum numbers” labeling a spin
network state are the graph @xmath , a spin @xmath on each edge of the
graph, and an intertwiner @xmath at each node of the graph, as shown in
Fig. 2 . We will also use the notation @xmath for the state ( 6.1 ) as
an abstract state vector in @xmath . A physical interpretation of spin
network states as states of quantized spatial geometry will be brought
out in Chapter 8 , where we study operators corresponding to various
geometric quantities on the spatial manifold @xmath .

### 6.1 The spin network decomposition

Spin network states form an orthonormal ⁸ ⁸ 8 With respect to the scalar
product defined by Eq. ( 3.3 ). Since the gauge invariant Hilbert space
is a proper subspace of the kinematical Hilbert space, the scalar
product on @xmath is immediately given by that on @xmath , and does not
require any further attention. basis on the gauge invariant Hilbert
space, provided that suitable restrictions, similar to those discussed
below Eq. ( 3.5 ), are put into place. If we require that

-   Two graphs differing from each other only by different orientation
    of some of their edges are identified with each other,

-   A graph containing a number of trivial bivalent nodes is identified
    with the graph obtained by removing the trivial nodes, and

-   A spin network state, some of whose edges carry zero spin, is
    identified with the corresponding state on the graph from which the
    @xmath edges are removed,

we have the orthogonal decomposition

  -- -------- -- -------
     @xmath      (6.2)
  -- -------- -- -------

where @xmath denotes equivalence classes of graphs up to orientation of
edges and removal of trivial bivalent nodes, and @xmath is the space of
spin network states which are based on the graph @xmath and carry a
non-trivial spin on each of their edges.

### 6.2 Intertwiners

In order to perform technical calculations in loop quantum gravity, it
is essential to have a detailed understanding of spin network states,
and in particular of intertwiners, or the invariant tensors residing at
the nodes of a spin network graph. The main tool for calculating with
spin networks is the recoupling theory of @xmath (see e.g. [ 52 , 127 ]
), which is well known to physicists in the context of angular momentum
in quantum mechanics. A comprehensive review of the subject is given in
the Appendix; here we will summarize some of its most important
elements.

The space of intertwiners associated to a three-valent node, @xmath , is
one-dimensional, provided that the spins @xmath , @xmath and @xmath
satisfy the Clebsch–Gordan conditions: @xmath and @xmath is an integer.
The single intertwiner which spans the space @xmath is given by the
Wigner 3 @xmath -symbol

  -- -------- -- -------
     @xmath      (6.3)
  -- -------- -- -------

which is known from the theory of angular momentum as the object which
couples three angular momenta into vanishing total angular momentum.

Indices of intertwiners can be raised and lowered using the epsilon
tensors @xmath and @xmath , which map between the spaces @xmath and
@xmath , and both of whose components with respect to the preferred
basis of @xmath are equal to @xmath . For example, the space @xmath is
spanned by the intertwiner

  -- -------- -- -------
     @xmath      (6.4)
  -- -------- -- -------

which is just the Clebsch–Gordan coefficient @xmath , up to a
multiplicative factor.

Intertwiners of higher valence can be built using the basic intertwiner
( 6.3 ) and the epsilon tensor. For example, by contracting two
three-valent intertwiners with epsilon, we obtain the four-valent
intertwiner

  -- -------- -- -------
     @xmath      (6.5)
  -- -------- -- -------

As the ”internal” spin @xmath ranges over all the values allowed by the
Clebsch–Gordan conditions, the intertwiners ( 6.5 ) form a basis in the
space of four-valent intertwiners @xmath . This basis is orthogonal but
not normalized, since the norm of the intertwiner ( 6.5 ) is equal to
@xmath . Another basis of the same intertwiner space can be obtained by
choosing to couple the spins @xmath and @xmath to the internal spin:

  -- -------- -- -------
     @xmath      (6.6)
  -- -------- -- -------

The bases ( 6.5 ) and ( 6.6 ) are related to each other by

  -- -------- -- -------
     @xmath      (6.7)
  -- -------- -- -------

where the object with curly brackets is the Wigner 6 @xmath -symbol.

By continuing to attach three-valent intertwiners to each other by
contraction with epsilon, one can obtain intertwiners of arbitrarily
high valence. In general, the basis of the @xmath -valent intertwiner
space @xmath constructed according to this scheme is labeled by @xmath
internal spins. In the language of angular momentum, the values of the
internal spins determine the eigenvalues of the operators @xmath ,
@xmath , @xmath , @xmath .

### 6.3 @xmath graphical calculus

A graphical notation, which has been developed for @xmath recoupling
theory, is tremendously powerful for calculations involving
intertwiners. The basic tensors @xmath and @xmath are represented
graphically by ⁹ ⁹ 9 The graphical diagrams used for @xmath calculations
should not be confused with generic drawings of spin network states,
such as Fig. 2 . In particular, the arrow representing the epsilon
tensor has nothing to do with the orientation of a spin network edge.

  -- -------- -------- -- -------
     @xmath   @xmath      (6.8)
     @xmath   @xmath      (6.9)
  -- -------- -------- -- -------

In such drawings each free end of a line carries a magnetic index; the
magnetic indices are usually not written explicitly. Contraction of
indices is carried out by joining the corresponding lines. The
properties of @xmath then imply that the arrow behaves according to the
rules

  -- -------- -------- -- --------
     @xmath   @xmath      (6.10)
     @xmath   @xmath      (6.11)
  -- -------- -------- -- --------

The 3 @xmath -symbol is represented by three lines joined together at a
node (with the free ends of the lines again carrying unwritten magnetic
indices):

  -- -------- -- --------
     @xmath      (6.12)
  -- -------- -- --------

Since the 3 @xmath -symbol is sensitive to non-cyclic permutations of
the columns, the ordering of the columns is indicated by a sign at the
node; the drawing ( 6.12 ) with a minus sign would represent the symbol
@xmath . From the symmetries of the 3 @xmath -symbol, we have

  -- -------- -- --------
     @xmath      (6.13)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (6.14)
  -- -------- -- --------

The 3 @xmath -symbol also satisfies the orthogonality relation

  -- -------- -- --------
     @xmath      (6.15)
  -- -------- -- --------

In graphical form, the four-valent intertwiner ( 6.5 ) is

  -- -------- -- --------
     @xmath      (6.16)
  -- -------- -- --------

The graphical representation of the 6 @xmath -symbol is given by

  -- -------- -- --------
     @xmath      (6.17)
  -- -------- -- --------

as can be verified by writing Eq. ( 6.7 ) graphically and contracting
both sides with @xmath

The @xmath generator @xmath is an unnormalized element of the
intertwiner space @xmath . The precise relation is

  -- -------- -- --------
     @xmath      (6.18)
  -- -------- -- --------

where @xmath .

We also introduce the graphical notation

  -- -------- -- --------
     @xmath      (6.19)
  -- -------- -- --------

for the Wigner matrices. Recalling that @xmath we then see that the
inverse matrix satisfies the graphical relation

  -- -------- -- --------
     @xmath      (6.20)
  -- -------- -- --------

Relations such as ( 5.1 ) suggest that the index @xmath of @xmath
belongs to the endpoint of the edge @xmath , while the index @xmath
belongs to the beginning point. Therefore the orientation of the
triangle in ( 6.19 ) is consistent with the orientation of the edge in
the graphical representation of a spin network state.

Using Eqs. ( 6.18 ) and ( 6.19 ), we may cast the action of @xmath on
holonomies into graphical form. From Eq. ( 4.7 ), we find

  ----- -------- -------- -- ---------
                             
        @xmath   @xmath      (6.21a)
  and                        
        @xmath   @xmath      (6.21b)
  ----- -------- -------- -- ---------

The seemingly trivial observation that tensors of the space @xmath can
be expanded with respect to any basis of the space leads to a set of
relations which are so useful in practical calculations that they would
deserve to be called the fundamental theorem of graphical calculus.
Letting a block with @xmath lines attached denote a general @xmath
-valent intertwiner, and using the observation for intertwiners of
valence two, three and four, we have

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (6.22a)
     @xmath   @xmath      (6.22b)
     @xmath   @xmath      (6.22c)
  -- -------- -------- -- ---------

and for intertwiners of higher valence an obvious generalization of Eq.
( 6.22c ) holds. The relations ( 6.22 ) are normally used to break down
complicated graphical expressions into simpler pieces.

## 7 Diffeomorphism invariance

The imposition of the diffeomorphism constraint is a crucial step in the
quantization program of loop quantum gravity, since it is at this point
that the essential requirement of background independence becomes fully
introduced into the formalism. At the technical level, the process of
solving the diffeomorphism constraint contains a couple of complications
which were absent in the case of the Gauss constraint.

The first complication is that, due to the nature of the scalar product
( 3.3 ) on the kinematical Hilbert space, the infinitesimal generator of
diffeomorphisms does not exist as a well-defined operator on @xmath . If
the infinitesimal generator did exist, it could be extracted from the
operator of finite diffeomorphisms by considering a limit of the kind

  -- -------- -- -------
     @xmath      (7.1)
  -- -------- -- -------

However, this limit does not exist in general, because the states @xmath
and @xmath are orthogonal to each other if the diffeomorphism @xmath
moves the graph @xmath even by an infinitesimally small amount. For this
reason it is not possible to solve the diffeomorphism constraint by
constructing a constraint operator on @xmath and looking for the states
which are annihilated by the operator. Instead, the diffeomorphism
invariant states must be sought by using an appropriately constructed
group averaging procedure.

The other difficulty is that since diffeomorphisms act on the graph of a
cylindrical function, the diffeomorphism invariant states cannot be
proper, normalizable elements of the kinematical Hilbert space. In fact,
the only diffeomorphism invariant element of @xmath is the constant
function (which can be viewed as a cylindrical function on a graph
consisting of no edges and no nodes). Therefore non-trivial
diffeomorphism invariant states should be searched for in the dual space
@xmath (i.e. the space of linear functionals on @xmath ). Of course this
is not very surprising, as the same situation occurs also in simple
examples in quantum mechanics. For example, solutions of the constraint
@xmath are not proper elements of the Hilbert space @xmath , but they do
belong to the dual space @xmath , since a function of the form @xmath
can be interpreted as a linear functional on @xmath .

After these preliminary remarks, let us move on to the construction of
the group averaging map ¹⁰ ¹⁰ 10 This map was first constructed in [ 20
] . Our presentation in this chapter follows that of [ 19 ] and [ 122 ]
. , which is supposed to map states in @xmath into diffeomorphism
invariant elements of @xmath . For a given graph @xmath , a
diffeomorphism may either leave the graph completely untouched, map the
graph into itself but bring about some non-trivial change such as
reversing the orientation of an edge, or move the graph around in @xmath
. The first kind of diffeomorphisms should clearly be ignored in the
group averaging of a cylindrical function @xmath , and it is convenient
to carry out the averaging separately with respect to the remaining two
kinds of diffeomorphisms.

To be more precise, denote by @xmath the group of diffeomorphisms which
map @xmath into itself, and by @xmath the subgroup of @xmath whose
action on @xmath is completely trivial. Then the (finite) quotient group

  -- -------- -- -------
     @xmath      (7.2)
  -- -------- -- -------

which we call the group of symmetries of @xmath , comprises the
diffeomorphisms of the second kind in the discussion above. Averaging of
a cylindrical function @xmath with respect to the symmetries of the
graph is then accomplished by using the projection operator @xmath ,
defined as

  -- -------- -- -------
     @xmath      (7.3)
  -- -------- -- -------

where @xmath is the number of elements in @xmath , and the factor of
@xmath is inserted to ensure that the averaging is done with ”total
weight” 1.

It then remains to average the state ( 7.3 ) with respect to
diffeomorphisms which move the graph around in the spatial manifold
@xmath . More precisely, the averaging should be done with respect to
the different ways that the graph can be transformed by a diffeomorphism
in @xmath , since if @xmath is a graph related to @xmath by a
diffeomorphism, then there are infinitely many diffeomorphisms for which
@xmath holds. Moreover, since the possible symmetries of the graph are
already dealt with in Eq. ( 7.3 ), the appropriate group for the
remaining part of the group averaging is @xmath , with @xmath denoting
the group of all diffeomorphisms on @xmath . This is an uncountably
infinite group, so the result of the averaging will not be a proper
cylindrical function, but only an element of @xmath . Hence we define

  -- -------- -- -------
     @xmath      (7.4)
  -- -------- -- -------

where the uncountable sum on the right-hand side is a well-defined
element of @xmath , because when acting on a cylindrical function, only
a finite number of terms in the sum will be non-vanishing. Note that the
operator @xmath , even though we denote it by the letter @xmath , is not
a true projection operator; rather, it is a so-called rigging map, which
maps elements of @xmath into (diffeomorphism invariant) elements of
@xmath . (The action of @xmath is extended by linearity to all elements
of @xmath .)

Eqs. ( 7.3 ) and ( 7.4 ) define the general solution of the
diffeomorphism constraint. The diffeomorphism invariance of the scalar
product on @xmath guarantees that the solution is consistent in the
sense that two cylindrical functions which are related to each other by
a diffeomorphism give rise to the same diffeomorphism invariant state
under the operator @xmath :

  -- -------- -- -------
     @xmath      (7.5)
  -- -------- -- -------

Even though the diffeomorphism invariant states are unnormalizable in
the scalar product on @xmath , a natural scalar product between them can
nevertheless be defined as

  -- -- -- -------
           (7.6)
  -- -- -- -------

where the right-hand side is defined by Eq. ( 7.4 ) and the scalar
product on @xmath .

By applying the operator @xmath to all cylindrical functions, one may
construct the space of all diffeomorphism invariant ”cylindrical
functionals” (i.e. diffeomorphism invariant elements of @xmath ). In
order to obtain simultaneous solutions of the Gauss and diffeomorphism
constraints, it suffices to restrict the set of initial cylindrical
functions to the gauge invariant subspace of @xmath . Therefore we
define the diffeomorphism invariant Hilbert space of loop quantum
gravity as

  -- -------- -- -------
     @xmath      (7.7)
  -- -------- -- -------

where @xmath is the space of gauge invariant cylindrical functions, and
the completion is with respect to the norm defined by the scalar product
( 7.6 ).

Well-defined operators on the space @xmath can be obtained from
diffeomorphism invariant operators on the kinematical Hilbert space. Any
diffeomorphism invariant operator @xmath on @xmath defines an operator
@xmath on @xmath through the prescription

  -- -- -- -------
           (7.8)
  -- -- -- -------

This definition is consistent with the scalar product on @xmath in the
sense that the operator @xmath is self-adjoint with respect to the
scalar product ( 7.6 ) precisely when @xmath is a self-adjoint operator
on @xmath .

Solving the diffeomorphism constraint is the key step in realizing the
crucial requirement of background independence in loop quantum gravity.
Loosely speaking, one can think of states in the diffeomorphism
invariant Hilbert space as spin networks of the form ( 6.1 ), but
instead of a graph embedded in @xmath , each state is labeled by an
equivalence class of graphs under diffeomorphisms – or a kind of
”semi-abstract” graph, which is not localized anywhere in @xmath , but
which still retains some diffeomorphism invariant information from the
original embedded graph (such as the possible knottedness of the graph,
and the differential structure of the edges at each node). This kind of
diffeomorphism invariant information is the only trace that remains of
the spatial manifold @xmath in the diffeomorphism invariant Hilbert
space.

However, an important caveat that goes with the intuitive picture
described above is that not every spin network state has a corresponding
state in the diffeomorphism invariant Hilbert space. In particular, some
non-trivial spin networks are annihilated by the projection operator
@xmath . A standard example is the state shown in Fig. 3 , which
consists of two loops connected to each other by a third edge. Using Eq.
( 6.20 ), one can show that the effect of a diffeomorphism which
reverses the orientation of one of the loops while leaving the rest of
the graph unchanged is to multiply the state by @xmath . Therefore this
state is mapped to zero by the operator @xmath whenever the spin @xmath
is odd; the state survives the averaging with respect to the symmetries
of the graph only if @xmath is even. When @xmath is odd, the state of
Fig. 3 does not exist in the diffeomorphism invariant Hilbert space.

Another subtlety related to the structure of the diffeomorphism
invariant Hilbert space arises in connection with the question of
separability of the space. The fact that diffeomorphism invariant states
”remember” the differential structure at the nodes of the graph implies
that states in @xmath containing nodes of sufficiently high valence
carry continuous, diffeomorphism invariant information, or so-called
”moduli”, at the nodes (see e.g. [ 72 ] ). For example, in an @xmath
-valent node there are @xmath angles between the tangent vectors of the
edges at the node. A diffeomorphism on @xmath acts on the tangent
vectors linearly as a @xmath -matrix, so there are only 9 free
parameters available to change the (continuous) values of these angles.
It follows that whenever @xmath , there exist families of uncountably
many graphs which differ from each other only within an infinitesimally
small neighborhood of a node, but which nevertheless cannot be
transformed into each other by a diffeomorphism. In other words, the
space @xmath contains uncountably many states which are all
diffeomorphically inequivalent and therefore orthogonal to each other;
hence @xmath is non-separable.

On the other hand, the continuous ”moduli” do not seem to have any
physical relevance, in that not any known operator in loop quantum
gravity is sensitive to their values (as pointed out by Thiemann in [
115 ] and [ 118 ] ). In practice one may therefore work with a separable
subspace of @xmath obtained by arbitrarily fixing the values of the
moduli. Such a subspace would be preserved by all known LQG operators,
and the result of any calculation would not depend on the arbitrary
choices made in selecting the subspace. In this sense it seems that any
set of practically relevant operators will always select a separable
subspace (or a ”superselection sector”) of @xmath , even though the
entire space @xmath is non-separable.

## 8 Geometric operators

The basic strategy for constructing operators in loop quantum gravity
out of classical functions of the variables @xmath is to re-express the
classical function in terms of holonomies and fluxes, which are the
elementary variables that can be promoted into well-defined operators in
LQG. In particular, operators corresponding to geometric quantities such
as areas of surfaces [ 17 , 109 ] and volumes of regions [ 18 , 109 ] in
the spatial manifold @xmath can be constructed in this way.

### 8.1 Area operator

The area of a two-dimensional surface @xmath on @xmath is given by
@xmath , with @xmath the determinant of the induced metric on @xmath .
If the equation of the surface is given in the form @xmath , where
@xmath are coordinates on the surface, then a more explicit expression
for the area is

  -- -------- -- -------
     @xmath      (8.1)
  -- -------- -- -------

To start rewriting this as a function of fluxes, we expand the
determinant within the integrand as

  -- -------- -- -------
     @xmath      (8.2)
  -- -------- -- -------

Now using the identity @xmath and recalling that the normal of the
surface is @xmath , we find

  -- -------- -- -------
     @xmath      (8.3)
  -- -------- -- -------

Here the area of @xmath is not yet expressed in terms of fluxes.
However, we see that the area of an infinitesimally small surface @xmath
is approximately given by

  -- -------- -- -------
     @xmath      (8.4)
  -- -------- -- -------

In the case of a surface of finite size, this suggests subdividing the
surface into a set of infinitesimal surfaces @xmath , whose size is
controlled by the parameter @xmath . By doing so, we get to write the
area of the surface as

  -- -------- -- -------
     @xmath      (8.5)
  -- -------- -- -------

This concludes the classical preparations for constructing the area
operator, since in Eq. ( 8.5 ) the area is expressed as a function of
fluxes only, and is therefore in a form which can readily be promoted
into an operator in the quantum theory.

In order to derive the action of the area operator on a spin network
state, we must study how the operator @xmath acts. As the subdivision of
@xmath into the surfaces @xmath becomes finer and finer, there
eventually remain two non-trivial cases to consider: (1) the surface
@xmath is intersected transversally by a single edge of the spin
network; or (2) a single node of the spin network lies on @xmath . In
case (1), letting @xmath denote the holonomy of the edge which
intersects @xmath , a simple calculation using Eqs. ( 4.11 ) and ( 4.7 )
shows that

  -- -------- -- -------
     @xmath      (8.6)
  -- -------- -- -------

Therefore in case (1) the spin network is simply an eigenstate of @xmath
with eigenvalue @xmath . Since the eigenvalue is positive, there is no
problem with taking the square root in Eq. ( 8.5 ).

Case (2), where the surface @xmath contains a node @xmath of the spin
network, is somewhat more complicated. Using the definition of the flux
operator, we find

  -- -------- -- -------
     @xmath      (8.7)
  -- -------- -- -------

where the sum runs over all pairs of edges at the node @xmath , and the
factor @xmath equals @xmath if either @xmath or @xmath intersects the
surface @xmath tangentially at @xmath , and otherwise equals @xmath or
@xmath depending on whether @xmath and @xmath lie on the same side of
the surface or on opposite sides of it. Defining now the operators

  -- -------- -- -------
     @xmath      (8.8)
  -- -------- -- -------

we can write the operator on the right-hand side Eq. ( 8.7 ) in the form

  -- -------- -- -------
     @xmath      (8.9)
  -- -------- -- -------

From this, the eigenvalues of the operator can be read off as

  -- -------- -- --------
     @xmath      (8.10)
  -- -------- -- --------

where the spins @xmath , @xmath and @xmath are subject to the
Clebsch–Gordan conditions. The eigenvalues are again positive, being the
eigenvalues of the manifestly positive operator @xmath , so there is no
problem in defining the square root in Eq. ( 8.5 ) through the spectral
decomposition of the operator. However, in this case a generic spin
network state is not necessarily an eigenstate of the area operator
(though it is always possible to choose a basis of intertwiners at the
node in which the operator ( 8.9 ) is diagonal).

To complete the definition of the area operator, it remains to take the
limit @xmath in Eq. ( 8.5 ). This step turns out to be easier than one
might have expected, since from the results of the above calculations we
can see that the limit is in fact trivial. Once the subdivision @xmath
is fine enough that each of the surfaces @xmath intersects the graph of
a spin network at most at a single point, then any further refinement of
the subdivision has no effect on the action of the regularized, @xmath
-dependent area operator on a spin network state. In other words, the
limit @xmath of the expression ( 8.5 ) is reached already at some finite
value of @xmath . That a regulator involved in constructing a quantum
operator out of a classical function can be removed trivially at the end
of the construction is a recurring theme in loop quantum gravity; it is
one of the distinctive, powerful features of the background-independent
framework of the theory.

In conclusion, we found that the classical area functional ( 8.1 ) can
be promoted into a well-defined operator on the Hilbert space of loop
quantum gravity. An explicit expression for the operator can only be
given separately within the subspaces associated to every possible
graph. We have

  -- -------- -- --------
     @xmath      (8.11)
  -- -------- -- --------

with @xmath and @xmath defined by Eq. ( 8.8 ). The operator is evidently
gauge invariant, though this can also be verified explicitly by checking
that @xmath commutes with the Gauss operator @xmath of Eq. ( 5.12 ).
Since the operator refers to the surface @xmath , it is not
diffeomorphism invariant, but it does transform covariantly under
diffeomorphisms: @xmath . The spectrum of the operator can be computed
explicitly; the scale of the area eigenvalues is determined by the
Planck length @xmath and the Immirzi parameter @xmath . In particular,
the so-called ”main sequence” of the spectrum, which arises from
intersections of the surface @xmath with isolated edges of a spin
network, has the form

  -- -------- -- --------
     @xmath      (8.12)
  -- -------- -- --------

where the sum runs over any arbitrary sequence of spins @xmath .
Remarkably, the spectrum is discrete (though practically
indistinguishable from a continuum at macroscopic values of the area),
even though discreteness of geometry is not imposed by hand at any point
in the development of the kinematical structure of loop quantum gravity.

### 8.2 Volume operator

Classically, the volume of a region @xmath in @xmath is given by

  -- -------- -- --------
     @xmath      (8.13)
  -- -------- -- --------

In broad outline, the steps leading from this expression to the quantum
volume operator are identical to those required for the area operator,
but there will appear a number of new technical details which were not
encountered in the case of the area operator.

As before, the first step is to rewrite the volume as a function of the
flux variable. To this end, let us consider an infinitesimal cubical
cell @xmath . The volume of the cell can be approximated as

  -- -------- -- --------
     @xmath      (8.14)
  -- -------- -- --------

where @xmath is a suitably chosen set of surfaces associated with the
cell. We assume that the surfaces are aligned along the coordinate axes,
so that on each surface @xmath the corresponding coordinate @xmath , and
require the areas of the surfaces to satisfy @xmath , at least to
leading order in @xmath . The volume of any region @xmath can then be
expressed in terms of fluxes by subdividing @xmath into a set of cells
@xmath :

  -- -- -- --------
           (8.15)
  -- -- -- --------

A vitally important feature of the regularized expression ( 8.15 ), just
as the expression ( 8.5 ) for the area, is that it does not depend
explicitly on the parameter @xmath , which controls the size of the
cells. This is a reflection of the fact that the integrand in Eq. ( 8.13
) is geometrically a density of weight one, and ultimately guarantees
that the regulator can be removed and the expression ( 8.15 ) promoted
into a well-defined operator in the quantum theory.

Compared to the case of the area operator, the first new aspect in the
construction of the volume operator is that there is a substantial
freedom in choosing the surfaces @xmath associated to the cells @xmath .
We will consider in detail only the so-called ”internal regularization”
due to Ashtekar and Lewandowski [ 18 ] , since the resulting operator is
the only volume operator that will be used later in this work. In the
internal regularization, the surfaces @xmath are taken to lie inside
their corresponding cell and are bounded by the faces of the cell.
Furthermore, the surfaces are adjusted separately to the graph of each
spin network state by imposing the following requirements:

-   If a cell @xmath contains a node of the graph, it must lie in the
    intersection point of the corresponding surfaces @xmath .

-   The surfaces @xmath of a cell containing a node intersect the graph
    only at the node.

-   If @xmath does not contain a node, then the graph intersects the
    surfaces @xmath at no more than two points.

Whenever the first requirement is satisfied, the remaining two can
immediately be met by sufficiently refining the subdivision @xmath .

To find the action of the resulting operator on spin networks, we must
start by considering (for each cell @xmath ) the operator

  -- -------- -- --------
     @xmath      (8.16)
  -- -------- -- --------

The third requirement and the antisymmetry of @xmath guarantee that the
operator @xmath gives zero when acting on a cell that does not contain a
node. If the cell does contain a node, we find (recalling the first two
requirements) that the operator acts as

  -- -- -- --------
           (8.17)
  -- -- -- --------

where @xmath , and each sum runs over all edges at the node, though the
antisymmetry of @xmath implies that non-zero terms arise only when the
edges @xmath are all distinct from each other.

Since the operator @xmath acts only on the nodes of a spin network as
soon as the three requirements above are satisfied, any further
refinement of the cells @xmath has no effect in Eq. ( 8.15 ), so it is
again trivial to take the limit @xmath . However, the resulting operator
is not yet a satisfactory operator, since it retains a dependence on the
details of the cells @xmath and the surfaces @xmath through the factor
@xmath . In order to obtain a background-independent volume operator,
one must therefore perform a suitable averaging over the background
structures used in the construction, as discussed in detail in [ 18 ] .
The conclusion is that such an averaging can be carried out, and the
form of the resulting operator is determined uniquely ¹¹ ¹¹ 11 Up to an
undetermined multiplicative factor, which we will ignore in what
follows. as

  -- -------- -- --------
     @xmath      (8.18)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (8.19)
  -- -------- -- --------

and the ”orientation factor” @xmath equals @xmath if the triple of
tangent vectors @xmath at the node @xmath is positively oriented, @xmath
if it is negatively oriented, and @xmath if the tangent vectors are not
linearly independent.

The other well-known construction of the volume operator was introduced
by Rovelli and Smolin [ 109 ] and studied further by De Pietri and
Rovelli [ 65 ] . Their construction is based on an ”external
regularization”, in which the faces of the cell @xmath are used as the
surfaces @xmath . The resulting operator still acts only on the nodes of
a spin network, but in order to achieve this, one must start by suitably
rewriting the classical expression ( 8.14 ) in terms of the parallel
transported flux variable of Eq. ( 2.30 ). (At the classical level this
can be done freely when considering an infinitesimal cell, since the
holonomies involved in the parallel transported flux reduce to
identities in the limit @xmath .) In the end the externally regularized
volume operator takes the form ( 8.18 ), but in place of @xmath one has
the operator

  -- -------- -- --------
     @xmath      (8.20)
  -- -------- -- --------

where the sum runs over all triples of three distinct edges at the node.
Therefore the main difference between the internally and externally
regularized volume operators (as discussed e.g. in [ 90 ] ) is that the
latter is not sensitive to the tangential structure of the edges at the
node.

### 8.3 Properties of the volume operator

The volume operator @xmath , just as the area operator, is gauge
invariant and transforms covariantly under diffeomorphisms. However, the
total volume of the spatial manifold @xmath , which we will denote
simply by @xmath , is diffeomorphism invariant, and is therefore a
well-defined operator on the space @xmath .

Due to the factor @xmath in ( 8.19 ), the volume operator gives zero
when acting on a bivalent node, or a node of higher valence where the
tangent vectors of all the edges are planar. A less obvious property is
that every trivalent node of a spin network state is also annihilated by
the volume operator. Using the gauge invariance condition @xmath and the
commutation relation ( 4.8 ), we find

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      
              @xmath      (8.21)
  -- -------- -------- -- --------

Therefore a four-valent node is the simplest node on which the volume
operator acts in a non-trivial way.

Gauge invariance can also be used to simplify the task of calculating
the action of the volume operator even when the result will not be
trivial. Let us illustrate this by considering the example of a
four-valent node. Introducing the notation

  -- -------- -- --------
     @xmath      (8.22)
  -- -------- -- --------

it would appear that one must compute the action of the operator

  -- -------- -- --------
     @xmath      (8.23)
  -- -------- -- --------

in which each of the four terms involves a distinct triple of the
operators @xmath . However, using gauge invariance, we can eliminate one
of the angular momentum operators from the calculation by writing @xmath
. Hence we find that we can equivalently calculate the action of the
simpler operator

  -- -------- -- --------
     @xmath      (8.24)
  -- -------- -- --------

which depends only on a single triple of the angular momentum operators.

In section 16.3 we will consider in detail the problem of computing the
action of the (squared) volume operator in the spin network basis. In
the literature, matrix elements of the volume have been calculated e.g.
in [ 116 , 65 , 57 , 55 , 56 ] . As the simplest non-trivial example, we
display here the action of the operator @xmath on a four-valent node, in
the (unnormalized) basis ( 6.5 ) of the four-valent intertwiner space:
¹² ¹² 12 Eq. ( 8.25 ) can be obtained from the more general result of
Eq. ( 16.55 ) by setting the spins @xmath and @xmath equal to zero and
using the equality [ 127 ]

@xmath

  -- -------- -- --------
     @xmath      
     @xmath      (8.25)
  -- -------- -- --------

Here @xmath , and the Wigner 6 @xmath - and 9 @xmath -symbols appear in
the matrix elements. The properties of the 9 @xmath -symbol imply that
the sum over @xmath runs only over the two values @xmath . Thus, in this
case the matrix of the squared volume operator has non-zero entries only
in the two diagonals immediately adjacent to the main diagonal.

The spectrum of the volume operator is clearly discrete, but in contrast
to the area operator, an analytic expression for the complete set of
eigenvalues is not known. The eigenvalue problem of the operator has
been solved explicitly only in certain relatively simple special cases
(see e.g. [ 55 , 56 ] , where the spectra corresponding to nodes of
valence up to 7 are studied numerically, and analytical results are also
given in the case of a four-valent node).

The basic structure of the area and volume operators is that the quantum
area of a surface receives a contribution from each edge of a spin
network intersecting the surface, while the quantum volume of a region
receives a contribution from each node of a spin network contained
inside the region. This naturally suggests a physical interpretation
where a spin network is a state of discrete, quantized spatial geometry,
consisting of quantized excitations of volume (at the nodes) separated
from each other by quantized excitations of area (at the edges). Within
this interpretation, the graph of a spin network state is seen as dual
to the quantized geometry defined by the state, each node of the graph
being dual to an elementary quantum of volume, while each edge is dual
to an elementary quantum of area.

After the diffeomorphism constraint is imposed through the operator
@xmath , the excitations of quantum geometry are not localized in any
background manifold. Hence the picture is truly background independent,
the only physically meaningful information being the relative
localization of the quanta of geometry with respect to each other. We
emphasize again that this intriguing picture seems to emerge naturally
as a result of quantizing general relativity according to the framework
of loop quantum gravity. Nowhere in the construction of the theory is
discreteness of spatial geometry taken as an assumption or imposed as a
postulate.

### 8.4 Angle operator

Since the geometry of the spatial surface @xmath is completely encoded
in the metric @xmath , any geometric quantity intrinsic to @xmath can be
expressed as a function of the triad @xmath , and could therefore (at
least in principle) be quantized following similar steps by which the
area and volume operators were constructed. In the remainder of this
chapter, we will briefly describe two further geometric operators, which
will be used later in this work.

The angle operator @xmath , introduced into loop quantum gravity by
Major [ 96 ] , acts on a pair of edges @xmath at a node @xmath of a spin
network as

  -- -------- -- --------
     @xmath      (8.26)
  -- -------- -- --------

where @xmath . As we will see shortly, it is straightforward to
determine the eigenvalues and eigenstates of the operator inside @xmath
, so the operator ( 8.26 ) can be defined through its spectral
decomposition without any problems.

The motivation for calling ( 8.26 ) the angle operator is provided by
the classical expression

  -- -- -- --------
           (8.27)
  -- -- -- --------

where again @xmath stands for @xmath , and whose quantization clearly
leads to the operator inside @xmath in Eq. ( 8.26 ), when the surfaces
are chosen such that each @xmath intersects only the edge @xmath .
(Precisely speaking, ( 8.27 ) must be quantized using the parallel
transported flux operator, in order to bring the action of the @xmath
-operators from the surfaces to the node.) In the limit where the
surfaces are infinitesimally small and located infinitesimally close to
the point @xmath , the fluxes in ( 8.27 ) can be approximated by @xmath
, with @xmath the coordinate area of the surface and @xmath the normal
covector. In this limit, Eq. ( 8.27 ) therefore reduces to

  -- -------- -- --------
     @xmath      (8.28)
  -- -------- -- --------

which shows that @xmath is a regularized expression for the cosine of
the angle between the surfaces @xmath and @xmath .

To determine the eigenvalues and eigenstates of the operator ( 8.26 ),
it is enough to note that

  -- -------- -- --------
     @xmath      (8.29)
  -- -------- -- --------

From this it is apparent that @xmath is diagonal whenever the
intertwiner at the node @xmath couples the spins @xmath and @xmath of
the edges @xmath and @xmath into a definite total spin @xmath :

  -- -------- -- --------
     @xmath      (8.30)
  -- -------- -- --------

with the corresponding eigenvalues being

  -- -------- -- --------
     @xmath      (8.31)
  -- -------- -- --------

In the ”monochromatic” case @xmath , we see that when the total spin is
@xmath (so that, in a sense, the fluxes of the surfaces dual to the
edges point in completely opposite directions), the angle eigenvalue is
@xmath , as one would expect. When the total spin has its maximal value
@xmath (describing a situation where the fluxes are as parallel as
possible), the eigenvalue @xmath is not exactly equal to zero, but does
approach zero in the limit of large @xmath .

### 8.5 Length operator

Two different length operators, due to Thiemann [ 115 ] and Bianchi [ 35
] , have been constructed in loop quantum gravity. The two operators
differ from each other not only technically but also conceptually:
Thiemann’s operator apparently measures the length of the edge of a spin
network, while Bianchi’s operator measures the length of the curve along
which two surfaces dual to two spin network edges intersect each other.
We will focus our discussion solely on the operator defined by Bianchi,
since it is the only length operator directly relevant to this work.

The starting point for the construction of a length operator is to
express the length of a curve @xmath in the spatial manifold @xmath as

  -- -------- -- --------
     @xmath      (8.32)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (8.33)
  -- -------- -- --------

Through a careful regularization of the expression ( 8.32 ), where the
curve @xmath is now taken to be the intersection between two surfaces
@xmath and @xmath dual to two edges @xmath and @xmath attached to the
same node @xmath of a spin network, Bianchi obtained the operator

  -- -------- -- --------
     @xmath      (8.34)
  -- -------- -- --------

Here the operator @xmath is defined as

  -- -------- -- --------
     @xmath      (8.35)
  -- -------- -- --------

and @xmath is a regularized inverse volume operator of the node @xmath .
The inverse operator @xmath can be defined by specifying its action on
the eigenstates of the standard volume operator ¹³ ¹³ 13 In this work we
depart slightly from Bianchi’s construction by using the
Ashtekar–Lewandowski volume operator, instead of the Rovelli–Smolin
operator used originally by Bianchi, to define the operator @xmath .
@xmath (restricted to the node @xmath ) as

  -- -------- -- --------
     @xmath      (8.36)
  -- -------- -- --------

(where @xmath is an eigenstate of @xmath with eigenvalue @xmath ). More
generally, one could define @xmath , where the parameter @xmath has a
small but finite value. This is known as the so-called Tikhonov
regularization of the inverse operator. The operator ( 8.36 ) results by
taking the limit @xmath of the operator @xmath .

The two ingredients that go into evaluating the action of the length
operator in the spin network basis are the matrix elements of the
operators @xmath and @xmath . While the matrix elements of @xmath are
generally accessible at most through numerical methods, deriving the
action of the operator @xmath on a spin network state is a
straightforward exercise in angular momentum algebra. (The calculation
could alternatively be carried out using the graphical techniques
outlined in section 6.3 , and described fully in the Appendix.) Using
the identity @xmath and the commutation relations of the angular
momentum operator, we can express the operator in question in the form

  -- -- -- --------
           (8.37)
  -- -- -- --------

From this we see that this operator, just as the angle operator, is
diagonalized by any intertwiner in which the edges @xmath and @xmath are
coupled to a definite total spin. The eigenvalue

in the diagonal action of the operator,

  -- -------- -- --------
     @xmath      (8.38)
  -- -------- -- --------

can be read off from Eq. ( 8.37 ). It is given by

  -- -------- -- --------
     @xmath      (8.39)
  -- -------- -- --------

where @xmath are the eigenvalues of the operator ( 8.29 ), namely

  -- -------- -- --------
     @xmath      (8.40)
  -- -------- -- --------

## 9 Coherent states

An important ingredient in the kinematical structure of any quantum
theory is the existence of coherent states, which describe nearly
classical configurations of the quantum system. The spin network states
of loop quantum gravity are very poor candidates for this task, since
some aspects of the quantized geometry described by a spin network state
are, in a sense, maximally far from classical. Being an eigenstate of
geometric operators such as the area or the volume, a typical spin
network state is completely spread with respect to the corresponding
conjugate variables. Coherent states for loop quantum gravity at the
kinematical level were first introduced by Thiemann [ 119 , 120 ] ,
building on related work by Hall [ 79 ] .

### 9.1 The complexifier method

A systematic algorithm for constructing coherent states is provided by
the so-called complexifier method [ 120 ] . The complexifier @xmath is a
function on the classical phase space, which is assumed to satisfy
certain requirements. In particular, the complexifier must be a positive
function, and must have a stronger than linear dependence on the
momentum variable. By canonically quantizing the classical function
@xmath , one obtains the corresponding quantum operator @xmath , which
we also refer to as the complexifier.

The complexifier is used to construct coherent states in the following
way. We start by applying the operator @xmath to the delta function of
the configuration variable, obtaining the function

  -- -------- -- -------
     @xmath      (9.1)
  -- -------- -- -------

The effect of the operator @xmath is to smooth out the delta function,
producing a function which has a peak of finite width concentrated
around the point @xmath . For example, considering the complexifier
@xmath in quantum mechanics, the action of the operator @xmath on the
delta function @xmath produces the Gaussian function @xmath . The
requirements imposed on the complexifier are necessary in order that the
function ( 9.1 ) can be a proper element of the Hilbert space of the
quantum theory.

The functions ( 9.1 ) are now made into coherent states by
”complexifying” the label @xmath , i.e. by analytically extending the
functions ( 9.1 ) to complex values of @xmath . Symbolically,

  -- -------- -- -------
     @xmath      (9.2)
  -- -------- -- -------

The precise way in which the label @xmath is ”complexified” into @xmath
is specified by the rule

  -- -------- -- -------
     @xmath      (9.3)
  -- -------- -- -------

where @xmath is the @xmath times iterated Poisson bracket, i.e. @xmath
with @xmath . Eq. ( 9.3 ) also provides the relation between the label
@xmath and the variables of the classical phase space, thereby defining
the point in the classical phase space on which the coherent state ( 9.2
) is supposedly peaked. Continuing the example from quantum mechanics,
we see that replacing @xmath in the function @xmath gives the standard
Gaussian coherent states @xmath .

The construction of the states ( 9.2 ) guarantees that they are
eigenstates of an annihilation operator @xmath , which is defined
through a quantum analog of the classical relation ( 9.3 ) as

  -- -------- -- -------
     @xmath      (9.4)
  -- -------- -- -------

with @xmath the @xmath times iterated commutator. Making use of Eq. (
9.2 ), a simple calculation shows that the state @xmath is an eigenstate
of the operator @xmath with the complex eigenvalue @xmath :

  -- -------- -- -------
     @xmath      (9.5)
  -- -------- -- -------

This result provides the main motivation for why the states ( 9.2 ) can
be expected to be legitimate coherent states. Indeed, the eigenvalue
equation ( 9.5 ) implies that the states ( 9.2 ) are optimally peaked
with respect to the Hermitian operators

  -- -------- -- -------
     @xmath      (9.6)
  -- -------- -- -------

in the sense that the equality sign in the uncertainty relation

  -- -------- -- -------
     @xmath      (9.7)
  -- -------- -- -------

is reached when the both sides of the inequality are evaluated in the
state ( 9.2 ). However, even though it is certainly reasonable to expect
the states @xmath to also possess other semiclassical properties, such
as @xmath for a set of ”reasonable” operators @xmath , such properties
are strictly speaking not guaranteed by the construction, and should be
checked separately in each case.

### 9.2 Heat kernel coherent states

In order to derive coherent states from the complexifier construction,
one must start by considering the form of the delta function on the
appropriate Hilbert space. For example, on the gauge-invariant Hilbert
space @xmath associated to a fixed graph @xmath , the corresponding
delta function @xmath should satisfy

  -- -------- -- -------
     @xmath      (9.8)
  -- -------- -- -------

where @xmath denotes the measure defined by Eq. ( 3.3 ) on the space
@xmath . It is easy to verify that the expansion of the delta function
in the spin network basis of @xmath is given by

  -- -------- -- -------
     @xmath      (9.9)
  -- -------- -- -------

An explicit expression for coherent states on @xmath can now be written
down, if we assume that the states @xmath are eigenstates of the
complexifier. Denoting the eigenvalues of the complexifier by @xmath ,
we have

  -- -------- -- --------
     @xmath      (9.10)
  -- -------- -- --------

Clearly the expression ( 9.10 ) is not of much practical use, unless an
explicit expression is available for the eigenvalues of the
complexifier. This requirement rules out the volume operator as a
possible complexifier, even though the total volume is a diffeomorphism
invariant operator, and would therefore appear to be a promising
candidate complexifier for constructing coherent states on the
diffeomorphism invariant Hilbert space. The spectrum of the volume
operator (particularly the frequency of zeros among the eigenvalues) is
not even known in sufficient detail to determine whether the expression
( 9.10 ) converges into a state of finite norm in @xmath .

Among the operators whose spectra are known in closed form, the area
operator seems like a natural candidate for a complexifier, due to the
simplicity of its action on spin networks – depending on the surface
@xmath , the action of the operator @xmath could possibly involve only a
single edge of the spin network ¹⁴ ¹⁴ 14 Note, however, that there exist
other operators, such as the angle operator or the operator ( 8.37 ),
whose eigenvalues and eigenstates in the spin network basis are known in
explicit form. These operators could therefore be used as prospective
complexifiers; however, to the author’s best knowledge, coherent states
resulting from complexifiers based on such operators have not been
studied anywhere. . Coherent states based on using (a suitable version
of) the area operator as the complexifier are commonly known as heat
kernel coherent states. They were introduced as coherent states for loop
quantum gravity by Thiemann [ 119 ] , after having been studied earlier
in a different context by Hall [ 79 ] . Their properties in loop quantum
gravity were investigated further in a series of papers by Thiemann and
Winkler [ 123 , 124 , 125 ] .

The specific complexifier chosen by Thiemann in [ 119 ] is a variant of
the squared area operator, defined in terms of the parallel transported
flux operator of Eq. ( 4.19 ). To each edge @xmath of a spin network
there is associated a corresponding surface @xmath , which intersects
@xmath but does not intersect any other edges of the spin network. Using
the surface @xmath , one then defines a parallel transported flux @xmath
, in which points on @xmath are transported to a fixed point @xmath on
the edge @xmath through a path which goes within @xmath (e.g. along a
straight line in the coordinates chosen on the surface) until the point
where @xmath intersects @xmath , and from there to @xmath along @xmath .
The complexifier associated to the edge is then defined as

  -- -------- -- --------
     @xmath      (9.11)
  -- -------- -- --------

where @xmath , and @xmath is a parameter, which turns out to control the
peakedness properties of the resulting coherent states. Since the
operator corresponding to @xmath acts only on the edge @xmath , it
suffices to carry out the construction of coherent states within the
Hilbert space @xmath of a single edge. After the construction is
completed, coherent states on a fixed graph can be obtained at the
non-gauge invariant level as tensor products of the single-edge coherent
states, and gauge invariant coherent states will be given by projections
of such tensor products onto the gauge invariant Hilbert space (see
section 9.5 ).

The standard expansion of the delta function on @xmath is given by

  -- -------- -- --------
     @xmath      (9.12)
  -- -------- -- --------

where @xmath is the character of the spin- @xmath representation of
@xmath . Since the complexifier operator @xmath acts on the spin- @xmath
subspace of @xmath diagonally, with the eigenvalue @xmath , we
immediately find the expression

  -- -------- -- --------
     @xmath      (9.13)
  -- -------- -- --------

for coherent states on @xmath . Here @xmath , which is the
complexification of the @xmath -element @xmath , is an element of @xmath
, as can be verified by computing @xmath from Eq. ( 9.3 ).

In order to evaluate

  -- -------- -- --------
     @xmath      (9.14)
  -- -------- -- --------

we note that the Poisson bracket of the parallel transported flux with
the holonomy of the edge is given by

  -- -------- -- --------
     @xmath      (9.15)
  -- -------- -- --------

where @xmath is the holonomy along the segment of @xmath from @xmath to
@xmath , and @xmath is defined similarly. In particular, when @xmath is
the beginning or ending point of @xmath , we have

  -- -------- -- --------
     @xmath      (9.16)
  -- -------- -- --------

Relabeling the variables as @xmath , @xmath and @xmath in order to
switch to the notation used in [ C ] , we find from Eq. ( 9.14 ) the two
equivalent expressions

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (9.17a)
     @xmath   @xmath      (9.17b)
  -- -------- -------- -- ---------

for the object @xmath . This confirms that @xmath is indeed an element
of @xmath , since the expressions ( 9.17 ) are the standard
decompositions of an @xmath element into a @xmath rotation and a boost.
The variables of the two decompositions are related to each other by

  -- -------- -- --------
     @xmath      (9.18)
  -- -------- -- --------

reflecting the relation @xmath between the two flux variables @xmath and
@xmath .

An orthonormal basis in @xmath is given by the states @xmath , whose
wave functions are defined as

  -- -------- -- --------
     @xmath      (9.19)
  -- -------- -- --------

(where the complex conjugation on the right-hand side is introduced in
order to be consistent with the convention chosen in [ C ] ). The basis
( 9.19 ) diagonalizes the left- and right-invariant vector fields ( 4.4
), as indicated by the eigenvalue equations

  -- -------- -------- -- ---------
                          
     @xmath   @xmath      (9.20a)
     @xmath   @xmath      (9.20b)
     @xmath   @xmath      (9.20c)
     @xmath   @xmath      (9.20d)
  -- -------- -------- -- ---------

From Eq. ( 9.13 ) we see that the expansion of the coherent state @xmath
in this basis reads

  -- -------- -- --------
     @xmath      (9.21)
  -- -------- -- --------

For later use, let us note the behaviour of the states @xmath under
local @xmath gauge transformations. We recall that under a
transformation described by a gauge function @xmath , the holonomy
transforms as

  -- -------- -- --------
     @xmath      (9.22)
  -- -------- -- --------

Making the replacement @xmath in the wave function ( 9.13 ), and
choosing either one of the parametrizations ( 9.17 ), we see that the
effect of a gauge transformation on a coherent state consists entirely
of a simple change in the labels @xmath and @xmath . For example, in the
parametrization ( 9.17a ), we have

  -- -------- -- --------
     @xmath      (9.23)
  -- -------- -- --------

where the @xmath rotation matrix @xmath is defined by @xmath . In the
other parametrization ( 9.17b ), we similarly find

  -- -------- -- --------
     @xmath      (9.24)
  -- -------- -- --------

The coherent states @xmath therefore remain coherent under gauge
transformations, simply becoming peaked on a different point of the
classical phase space.

### 9.3 Resolution of the identity

An important property of the coherent states @xmath is that they resolve
the identity on the space @xmath ,

  -- -------- -- --------
     @xmath      (9.25)
  -- -------- -- --------

and therefore provide an overcomplete basis on @xmath . In Eq. ( 9.25 ),
the integral is taken over the classical phase space, and integration
measure has the factorized form [ 123 ]

  -- -------- -- --------
     @xmath      (9.26)
  -- -------- -- --------

where @xmath is the Haar measure of @xmath , and the factor involving
@xmath is given by

  -- -------- -- --------
     @xmath      (9.27)
  -- -------- -- --------

where we denote @xmath .

In order to check that the operator ( 9.25 ) really is the unit operator
on @xmath , we compute its matrix elements @xmath in the basis ( 9.19 ).
After inserting the expression ( 9.21 ), the integral over @xmath can be
calculated immediately using the orthogonality theorem of the Wigner
matrices, and we are left with

  -- -------- -- --------
     @xmath      (9.28)
  -- -------- -- --------

Let us denote the remaining integral on the right-hand side as @xmath .
The key to evaluating the integral is to view it as a tensor in @xmath ,
and observe that the rotational invariance of the measure @xmath implies
that @xmath is invariant under the action of @xmath :

  -- -------- -- --------
     @xmath      (9.29)
  -- -------- -- --------

Hence @xmath is an element of the space @xmath , and so must be
proportional to @xmath , which is the only invariant tensor carrying one
upper and one lower index. The coefficient of proportionality in @xmath
can be determined by contracting both sides with @xmath . This leads to

  -- -------- -- --------
     @xmath      (9.30)
  -- -------- -- --------

where the trace @xmath was evaluated in the basis where @xmath is
diagonal, with eigenvalues @xmath , @xmath , @xmath , @xmath . Putting
everything together, we have shown that

  -- -------- -- --------
     @xmath      (9.31)
  -- -------- -- --------

from which we can conclude that ( 9.25 ) is indeed a correct expression
for the identity operator on @xmath .

### 9.4 Peakedness properties

As we have seen, the construction of the heat kernel coherent states (
9.13 ) guarantees that they are sharply peaked with respect to the
operators ( 9.6 ), where @xmath is now given by a quantization of the
classical variable @xmath . Therefore it is not immediately obvious
(though it is certainly very plausible) that the states are also
properly peaked on the holonomy and the flux, which are the operators
directly relevant to loop quantum gravity. The peakedness properties of
the states ( 9.13 ) with respect to the holonomy and the flux were
established by means of direct calculations by Thiemann and Winkler [
123 ] . In this section we will briefly summarize their results.

The possible peakedness of the states ( 9.13 ) with respect to the
holonomy is described by the probability distribution in ”holonomy
space”,

  -- -------- -- --------
     @xmath      (9.32)
  -- -------- -- --------

(where it is necessary to divide by the norm @xmath , since the state
@xmath is in general not normalized). If the state @xmath is properly
peaked on the holonomy, the function ( 9.32 ) should have a sharp peak
concentrated around the point @xmath (we recall that @xmath ). The
observation

  -- -------- -- --------
     @xmath      (9.33)
  -- -------- -- --------

allows one to replace the problem of showing that ( 9.32 ) is peaked on
@xmath with the equivalent problem of showing that

  -- -------- -- --------
     @xmath      (9.34)
  -- -------- -- --------

is peaked on @xmath independently of the value of @xmath . By going
through a long and tedious calculation, which we have little hope of
even outlining in the space available here ¹⁵ ¹⁵ 15 We merely note that
the essential tool in Thiemann and Winkler’s calculation is the Poisson
summation formula

@xmath

where @xmath denotes the Fourier transform of @xmath . The importance of
the Poisson summation formula to the present problem is that it allows
one to convert a sum like ( 9.13 ), which converges extremely slowly in
the limit @xmath , into a sum which typically is converging very rapidly
when @xmath , and which can be approximated very well by keeping only
the leading term. , Thiemann and Winkler managed to show that this is
indeed the case. The width of the peak is characterized by the parameter
@xmath , with the peak becoming sharp in the limit @xmath .

In order to study the peakedness of the state @xmath with respect to
flux operators, the state should be expanded in the eigenbasis ( 9.19 )
of the left- and right-invariant vector fields as

  -- -------- -- --------
     @xmath      (9.35)
  -- -------- -- --------

where the coefficients of the expansion are given by

  -- -------- -- --------
     @xmath      (9.36)
  -- -------- -- --------

The probability of the state @xmath to have a specific momentum
configuration is then described by the (discrete) probability
distribution

  -- -------- -- --------
     @xmath      (9.37)
  -- -------- -- --------

By making use of estimates based on the explicit expression ( A.70 ) for
the matrix elements @xmath , Thiemann and Winkler were able to obtain
the result ¹⁶ ¹⁶ 16 Precisely speaking, Eq. ( 9.38 ) is valid only when
neither @xmath nor @xmath is too close to 1. However, a very similar
estimation holds in the case @xmath or @xmath .

  -- -------- -- --------
     @xmath      (9.38)
  -- -------- -- --------

where @xmath and @xmath refer to the two decompositions ( 9.17 ) of the
@xmath element @xmath . The peakedness properties of the state @xmath
with respect to flux operators can be read off from Eq. ( 9.38 ). We see
that the probability distribution ( 9.37 ) is peaked on the values

  -- -------- -- --------
     @xmath      (9.39)
  -- -------- -- --------

and the peak becomes sharp in the limit of large @xmath – specifically,
when @xmath (the value of @xmath being fixed, for example, by the
requirement that the coherent state is sufficiently well peaked on the
holonomy).

Thiemann and Winkler also showed that the overlap function

  -- -- -- --------
           (9.40)
  -- -- -- --------

is peaked on @xmath , with the peak falling off exponentially fast
around the maximum, at least in the limit of small @xmath . Figuratively
speaking, if we view the coherent state @xmath as a state-vector valued
function on the classical phase space, then the peakedness of the
overlap function means that @xmath differs significantly from zero only
within a small neighborhood around the point @xmath .

### 9.5 Gauge invariant coherent states

So far our discussion of coherent states has been restricted to a single
spin network edge. However, the generalization of the construction to
coherent states on a fixed graph is rather trivial, at least at the
level of non-gauge invariant states. Coherent states based on a fixed
graph @xmath are given simply by tensor products of the single-edge
coherent states ( 9.13 ) over the edges of the graph:

  -- -------- -- --------
     @xmath      (9.41)
  -- -------- -- --------

Gauge invariant coherent states can be constructed by group averaging
the tensor product states ( 9.41 ) with respect to gauge transformations
at each node of the graph:

  -- -------- -- --------
     @xmath      (9.42)
  -- -------- -- --------

Inserting the expression ( 9.41 ), we obtain

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (9.43)
  -- -------- -------- -- --------

At each node of the graph we now have an integral of the form

  -- -------- -- --------
     @xmath      (9.44)
  -- -------- -- --------

which, viewed as an @xmath tensor, is essentially a normalized
projection operator onto the intertwiner space of the node. Therefore
the integral can be expressed as

  -- -------- -- --------
     @xmath      (9.45)
  -- -------- -- --------

where the sum runs over any orthonormal basis of the intertwiner space,
and the indices @xmath refer to edges coming in to the node, while
@xmath refer to edges going out of the node. Going back to Eq. ( 9.43 ),
we see that the gauge invariant coherent states can be written in the
form

  -- -------- -- --------
     @xmath      (9.46)
  -- -------- -- --------

where @xmath are the standard spin network states on the graph @xmath .

It is not immediately obvious how the group averaging operation affects
the peakedness properties of the coherent states. In their paper on
peakedness proofs [ 123 ] , Thiemann and Winkler argue that peakedness
of the gauge invariant coherent states with respect to holonomies, and
of the overlap function of gauge invariant coherent states, follow from
the corresponding properties of the non-gauge invariant coherent states.
The overlap between gauge invariant coherent states has also been
studied by Thiemann and Bahr [ 26 ] .

The situation with respect to flux operators becomes the most
transparent through a result obtained by Bianchi, Magliaro and Perini [
39 ] , which establishes a relation between the gauge-invariant coherent
states ( 9.46 ) and the so-called Livine–Speziale coherent intertwiners
[ 94 ] . The derivation of this result is based on the alternative
decomposition

  -- -------- -- --------
     @xmath      (9.47)
  -- -------- -- --------

of the @xmath element @xmath ; here @xmath is an arbitrary complex
number, and @xmath is an @xmath element of the specific form @xmath ,
where the rotation vector @xmath lies in the @xmath -plane. This
decomposition is particularly suited for discussing the limit of large
@xmath , which turns out to correspond to @xmath in the parametrization
of Eq. ( 9.47 ). When @xmath is large, the matrix elements of @xmath are
dominated by the largest, @xmath -matrix element:

  -- -------- -- --------
     @xmath      (9.48)
  -- -------- -- --------

Equivalently, the matrix @xmath is approximated by

  -- -------- -- --------
     @xmath      (9.49)
  -- -------- -- --------

with the correction being exponentially small relative to the leading
term.

Under the approximation ( 9.48 ), the trace in Eq. ( 9.41 ) becomes

  -- -------- -- --------
     @xmath      (9.50)
  -- -------- -- --------

with @xmath the standard coherent states of angular momentum [ 101 , 98
] . When Eq. ( 9.50 ) is used in Eqs. ( 9.41 ) and ( 9.42 ), the group
integration at each node produces the coherent intertwiner

  -- -------- -- --------
     @xmath      (9.51)
  -- -------- -- --------

where the ket on the left-hand side should be understood as an element
of the intertwiner space @xmath . In this way one finds that the gauge
invariant coherent states can be expressed as superpositions of spin
network states with coherent intertwiners at the nodes:

  -- -------- -- --------
     @xmath      (9.52)
  -- -------- -- --------

where @xmath . In particular, this result seems to establish peakedness
of the gauge invariant coherent states with respect to flux operators,
since the Livine–Speziale intertwiners are well known to have good
semiclassical properties with respect to the fluxes.

## 10 Coherent state operators

Our overview of the kinematical framework of loop quantum gravity will
be concluded in this chapter, in which we show how the complexifier
coherent states introduced in the previous chapter can be used to set up
an alternative, non-canonical prescription for systematically defining
kinematical operators (such as holonomy, flux, area and volume) in loop
quantum gravity. The results that are reviewed in this chapter were
obtained by the author in collaboration with Emanuele Alesci, Andrea
Dapor, Jerzy Lewandowski and Jan Sikorski, and have been published in
the article [ C ] .

The work presented in this chapter is based on the ideas of so-called
”coherent state quantization” (see e.g. [ 76 ] for an introduction), and
was inspired by the earlier work of Gazeau and collaborators, who
studied the construction of operators from coherent states in the
context of quantum mechanics [ 34 ] and quantum cosmology [ 32 , 33 ] .
However, similar ideas have been discussed in the literature already
much earlier, particularly by Berezin [ 31 ] and Klauder [ 84 , 85 ] .

It should be pointed out that the usual terminology of ”coherent state
quantization” is somewhat of a misnomer, since it might give the
impression that one is performing an entirely different quantization of
the classical theory. In reality, coherent state quantization simply
provides a mechanism by which coherent states labeled by points on a
classical phase space can be used to promote functions on the classical
phase space into operators on the Hilbert space spanned by the coherent
states. In other words, the Hilbert space of the quantum theory is
already given, and is the same space on which one would perform a
canonical quantization of the classical theory; one merely has a
different, non-canonical way of associating quantum operators to
classical phase space functions. For this reason, we prefer the
expression ”coherent state operators” over the potentially misleading
”coherent state quantization”.

Coherent state operators have several definite advantages in comparison
to their canonical counterparts. Most notably, once a family of coherent
states is chosen, the procedure associates a unique and unambiguous
operator to every classical function; there are no ordering ambiguities
which are often encountered in canonical quantization. Moreover, certain
properties of the classical function are automatically passed to the
corresponding coherent state operator, in contrast to the situation with
canonical quantization. For example, the operator corresponding to a
classical function which is real-valued, or positive, is guaranteed to
be symmetric, or positive-definite. A feature of the construction which
one might consider a disadvantage is that the commutator of coherent
state operators generally does not exactly reproduce the Poisson bracket
of the corresponding classical functions, even if one considers just the
elementary ”position” and ”momentum” operators.

In what follows, we will start by presenting the general recipe for
constructing coherent state operators in loop quantum gravity, using the
complexifier coherent states of the previous chapter. The nature of the
coherent states implies that the operators obtained from them will be
restricted to the Hilbert space of a single, fixed spin network graph.
Afterwards we will establish some general properties of the resulting
operators, and present a number of concrete examples of the
construction. We will consider in detail both the elementary holonomy
and flux operators, and the geometric operators of area, angle and
volume. The discussion will then be concluded with some closing remarks.

### 10.1 Construction of coherent state operators

The construction by which coherent states can be used to associate
quantum operators to classical phase space functions is based on the
resolution of identity in terms of the coherent states, which involves
an integration over the appropriate classical phase space. Restricting
our attention first to a single spin network edge, we have the
resolution of identity

  -- -------- -- --------
     @xmath      (10.1)
  -- -------- -- --------

on the Hilbert space of the edge. The object on the right-hand side can
be viewed as an integral over the classical phase space associated to
the edge ¹⁷ ¹⁷ 17 A detailed discussion of the classical phase space of
loop quantum gravity can be found in [ 74 ] . , the variables @xmath and
@xmath being interpreted respectively as the holonomy of @xmath along
the edge, and the flux of @xmath through a surface dual to the edge. In
fact, the behaviour of the variable @xmath under @xmath gauge
transformations, given by Eq. ( 9.23 ), suggests that @xmath should
precisely speaking be interpreted as the parallel transported flux
variable, where the parallel transport is taken to the beginning point
of the edge.

Given now any function @xmath on the corresponding classical phase
space, we can define a coherent state operator representing the function
by inserting @xmath into the integral in Eq. ( 10.1 ). In this way we
obtain the operator

  -- -------- -- --------
     @xmath      (10.2)
  -- -------- -- --------

This construction associates a unique operator on the single-edge
Hilbert space to every function on the classical phase space of the
edge.

It is straightforward to generalize the prescription ( 10.2 ) to obtain
operators on the Hilbert space of a fixed graph, which has the structure
of a tensor product of Hilbert spaces associated to each edge of the
graph. In particular, the identity operator on the Hilbert space of a
graph is resolved by the tensor product states @xmath (with respect to
the measure @xmath ). To any function @xmath on the classical phase
space of the graph, we therefore associate the operator

  -- -------- -- --------
     @xmath      (10.3)
  -- -------- -- --------

In practice a slightly modified version of the definition ( 10.3 ) must
be used in order to obtain an operator which accounts correctly for the
orientation of the graph, as we will now explain.

The classical interpretation of the variable @xmath as a parallel
transported flux indicates that @xmath belongs to the beginning point of
the corresponding edge. Similarly, the variable @xmath corresponding to
the decomposition @xmath is interpreted as the flux parallel transported
to the endpoint of the edge, and therefore belongs to the endpoint. This
interpretation is respected by the operator ( 10.3 ), in the sense that
whenever one takes a @xmath in the classical function @xmath and the
corresponding coherent state @xmath , the resulting operator will act on
the beginning point of the edge @xmath , whereas if one takes a @xmath
for the same edge, one gets an operator which acts on the endpoint of
the edge. (These claims are confirmed by the calculations made later in
this chapter; see in particular Eqs. ( 10.33 ) and ( 10.37 ).) In
particular this means that if one wants to construct an operator (such
as the volume operator) which acts on a single node of a spin network
state, one should put in Eq. ( 10.3 ) a @xmath for every edge oriented
away from the node, and a @xmath for every edge oriented into the node.

At this point one might be inclined to ask whether it would not be
better to take the gauge-invariant coherent states of Eq. ( 9.46 ),
rather than the simple tensor product states used in Eq. ( 10.3 ), as
the starting point for constructing coherent state operators,
considering that practical calculations in loop quantum gravity are
usually made at the gauge-invariant level, and not in the kinematical
Hilbert space. However, it is straightforward to see that if one uses
the operator to act exclusively on gauge-invariant states, then there
will be no difference between the operator ( 10.3 ) and the operator

  -- -------- -- --------
     @xmath      (10.4)
  -- -------- -- --------

constructed from the gauge invariant coherent states ( 9.46 ). Since the
states @xmath are obtained simply by applying the gauge invariant
projector @xmath to the tensor product states @xmath , it follows
immediately that if @xmath and @xmath are any two gauge invariant
states, the operators ( 10.3 ) and ( 10.4 ) have the same matrix
elements between these states:

  -- -------- -- --------
     @xmath      (10.5)
  -- -------- -- --------

This being the case, it is actually preferable to use the non-gauge
invariant tensor product states chosen in Eq. ( 10.3 ), since they will
be technically much easier to handle.

### 10.2 General properties

Before moving on to consider concrete examples of coherent state
operators in loop quantum gravity, we will establish some general
properties of operators constructed in this way. Let us first consider
the behaviour of the operator ( 10.3 ) under gauge transformations. In
particular, the result of this calculation will show that it is possible
to obtain gauge invariant operators from Eq. ( 10.3 ), even though the
coherent states used to construct the operator are not gauge invariant.

In the general case, where we may have associated either a @xmath or
@xmath to each edge of the graph, it is convenient to separate the two
types of momentum variables, writing the operator ( 10.3 ) as

  -- -------- -- --------
     @xmath      (10.6)
  -- -------- -- --------

Letting @xmath denote the action of a local @xmath gauge transformation
defined by the function @xmath , and recalling the action of a gauge
transformation on the coherent states from Eqs. ( 9.23 ) and ( 9.24 ),
we find

  -- -------- -- --------
     @xmath      
     @xmath      (10.7)
  -- -------- -- --------

where the @xmath invariance of the Haar measure and the rotational
invariance of the measure @xmath was used to move the action of the
gauge transformation from the coherent states to the function @xmath .
Therefore we see that it is indeed possible for the operator @xmath to
be gauge invariant, the condition for its gauge invariance being simply
that the function @xmath be invariant under a gauge transformation of
its arguments.

Another general property of the operator ( 10.3 ) concerns the case
where the function @xmath is strictly positive everywhere, except
possibly in a set of measure zero with respect to the measure @xmath .
Then all the eigenvalues of @xmath will be strictly positive, at least
if the corresponding eigenstates are proper, non-distributional states.

To prove this statement, let @xmath be a proper, normalizable eigenstate
of @xmath . Then the eigenvalue can be written as

  -- -------- -- --------
     @xmath      (10.8)
  -- -------- -- --------

We see immediately that the eigenvalue is non-negative. The only way in
which @xmath can be equal to zero is that @xmath everywhere except in a
set of measure zero, since we have assumed that the set where @xmath is
of measure zero. However, the condition for the eigenstate to be
normalized,

  -- -------- -- --------
     @xmath      (10.9)
  -- -------- -- --------

together with the assumption that @xmath is a non-distributional state,
so that the projections @xmath have finite values, is sufficient to
ensure that @xmath in a set of positive measure. It follows that the
integral on the right-hand side of Eq. ( 10.8 ) is strictly positive,
and therefore @xmath .

### 10.3 Holonomy operator

We will now study in detail the coherent state operators corresponding
to the elementary holonomy and flux operators of loop quantum gravity.
Starting with the holonomy, we take the function @xmath in Eq. ( 10.2 )
to be the Wigner matrix @xmath , thereby obtaining the operator

  -- -------- -- ---------
     @xmath      (10.10)
  -- -------- -- ---------

In order to understand the action of this operator, we compute its
matrix elements between two states @xmath of the basis ( 9.19 ). Using
Eq. ( 9.21 ) for the components of the coherent states with respect to
the basis ( 9.19 ), we get

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (10.11)
  -- -------- -------- -- ---------

Here the integral over @xmath gives

  -- -------- -- ---------
     @xmath      (10.12)
  -- -------- -- ---------

To evaluate the integral over @xmath , we start by applying the
Clebsch–Gordan series

  -- -------- -- ---------
     @xmath      (10.13)
  -- -------- -- ---------

which is valid also in the case that @xmath is an element of @xmath ,
even though it is better known as a relation between @xmath
representation matrices. ¹⁸ ¹⁸ 18 To prove this statement, we recall
that a general element of @xmath can be written in the form @xmath ,
where @xmath and @xmath , and @xmath is a diagonal matrix. Using this
decomposition, we have

@xmath @xmath @xmath

Here we can use the Clebsch–Gordan series of @xmath to couple the
representation matrices of @xmath and those of @xmath . Inserting also
@xmath , we obtain

@xmath @xmath @xmath

Now the condition @xmath on one of the Clebsch–Gordan coefficients
allows us to replace @xmath with @xmath , after which the sum over
@xmath and @xmath can be performed using the orthogonality properties of
Clebsch–Gordan coefficients. This leads to

@xmath

which completes the proof of Eq. ( 10.13 ), since @xmath . Noting that
the matrix @xmath is Hermitian, and using Eq. ( 10.13 ), we can write
the integrand in Eq. ( 10.11 ) as

  -- -------- -- ---------
     @xmath      (10.14)
  -- -------- -- ---------

It then remains to consider the integral

  -- -------- -- ---------
     @xmath      (10.15)
  -- -------- -- ---------

This integral is of the same type as the integral in Eq. ( 9.28 ), and
so we can repeat the arguments given below Eq. ( 9.28 ) to show that it
is proportional to @xmath , with the coefficient of proportionality
given by @xmath times the trace of the integral. The integral ( 10.15 )
is therefore equal to

  -- -- -- ---------
           (10.16)
  -- -- -- ---------

When Eqs. ( 10.12 ) and ( 10.14 ) are now inserted back into Eq. ( 10.11
), there appears a partial contraction of three Clebsch–Gordan
coefficients. Using the graphical representation of the Clebsch–Gordan
coefficient from Eq. ( C.15 ), a simple graphical calculation shows that
this contraction is equal to

  -- -------- -- ---------
     @xmath      (10.17)
  -- -------- -- ---------

Hence we have shown that the matrix elements of the coherent state
holonomy operator are given by

  -- -------- -- ---------
     @xmath      (10.18)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (10.19)
  -- -------- -- ---------

The result of Eq. ( 10.18 ) may be compared against the matrix elements
of the canonical holonomy operator, which read

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.20)
  -- -------- -------- -- ---------

We see that the matrix elements of the coherent state operator are
related to those of the canonical operator by the factor ( 10.19 ):

  -- -------- -- ---------
     @xmath      (10.21)
  -- -------- -- ---------

In the limit @xmath – where, as we recall from section 9.4 , the
coherent state @xmath becomes sharply peaked on @xmath – the function
@xmath becomes

  -- -------- -- ---------
     @xmath      (10.22)
  -- -------- -- ---------

This shows that the coherent state holonomy operator reduces to the
canonical holonomy operator in the limit in which the states used to
construct the coherent state operator are sharply peaked with respect to
the holonomy.

### 10.4 Left- and right-invariant vector fields

The variable @xmath , corresponding to the decomposition @xmath , is
invariant under left multiplication by @xmath , and is therefore a
natural candidate for the classical function from which the coherent
state operator corresponding to the left-invariant vector field could be
obtained. Let us therefore consider the operator

  -- -------- -- ---------
     @xmath      (10.23)
  -- -------- -- ---------

As with the holonomy operator, we proceed to compute the matrix elements
of this operator in the basis @xmath . We have

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.24)
  -- -------- -------- -- ---------

where the integral over the group immediately gives @xmath . We are then
left with

  -- -------- -- ---------
     @xmath      (10.25)
  -- -------- -- ---------

In order to compute this integral, it is convenient to express the
variable @xmath in terms of objects compatible with @xmath recoupling
theory by writing

  -- -------- -- ---------
     @xmath      (10.26)
  -- -------- -- ---------

In this way we obtain

  -- -------- -- ---------
     @xmath      
     @xmath      (10.27)
  -- -------- -- ---------

where Eq. ( 10.13 ) was used to couple the @xmath representation
matrices. By the same reasoning as before, the remaining integral is
equal to

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.28)
  -- -------- -------- -- ---------

In Eq. ( 10.27 ) we then have the contraction

  -- -- -- ---------
           (10.29)
  -- -- -- ---------

which is again convenient to evaluate graphically, recalling the
graphical representation ( C.16 ) for the @xmath generators. At this
point we have found

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.30)
  -- -------- -------- -- ---------

where we introduced the abbreviation

  -- -------- -- ---------
     @xmath      (10.31)
  -- -------- -- ---------

This result can be simplified further by performing the sum over @xmath
, which runs over the two values @xmath . Inserting the explicit
expressions for the 6 @xmath -symbols involved in the sum,

  -- -------- -- ---------
     @xmath      (10.32)
  -- -------- -- ---------

we conclude that the action of the coherent state left-invariant vector
field can be expressed in the form

  -- -------- -- ---------
     @xmath      (10.33)
  -- -------- -- ---------

where

  -- -------- -------- -- ---------
     @xmath   @xmath      
                          (10.34)
  -- -------- -------- -- ---------

For comparison, the action of the canonical left-invariant vector field
of Eq. ( 4.4 ) on the states @xmath is given by

  -- -------- -- ---------
     @xmath      (10.35)
  -- -------- -- ---------

Hence we see that the coherent state operator is again related to the
corresponding canonical operator simply by a multiplicative factor:

  -- -------- -- ---------
     @xmath      (10.36)
  -- -------- -- ---------

However, in this case the canonical operator is not recovered from the
coherent state operator by taking a limit with @xmath , but rather by
letting the coherent state operator act on a state @xmath having a
sufficiently large value of @xmath . Since the large- @xmath behaviour
of the multiplicative factor is @xmath (independently of the value of
@xmath ), the operator @xmath behaves approximately like the canonical
operator @xmath when it is restricted to the large- @xmath sector of the
space spanned by the states @xmath . This seems to be consistent with
the discussion of section 9.4 , according to which the coherent states
@xmath become sharply peaked on the momentum variable in the limit of
large @xmath .

The coherent state operator corresponding to the right-invariant vector
field can be derived by taking the variable @xmath of the decomposition
@xmath as the classical function from which the operator is constructed.
A calculation entirely similar to the one made above for the
left-invariant vector field shows that the operator

  -- -------- -- ---------
     @xmath      (10.37)
  -- -------- -- ---------

acts on the states @xmath as

  -- -------- -- ---------
     @xmath      (10.38)
  -- -------- -- ---------

Equivalently,

  -- -------- -- ---------
     @xmath      (10.39)
  -- -------- -- ---------

where @xmath is the canonical right-invariant vector field.

Now that the action of the coherent state operators corresponding to
holonomies and fluxes has been computed in explicit form, we may address
the question of whether the coherent state prescription has produced a
genuinely non-canonical quantization of holonomies and fluxes, or
whether we have merely obtained a non-standard representation of the
canonical holonomy-flux algebra. To this end, let us look at the
commutator between the operators @xmath and @xmath . Inserting a
resolution of identity in the states @xmath , and using the matrix
elements given by Eqs. ( 10.18 ) and ( 10.33 ), one can show that

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (10.40)
  -- -------- -------- -- ---------

The first term on the right-hand side matches with the commutator of the
canonical operators, which reads

  -- -------- -- ---------
     @xmath      (10.41)
  -- -------- -- ---------

The presence of additional terms means that the algebra of the coherent
state operators is indeed inequivalent to the algebra of canonical
holonomies and fluxes – however, the canonical algebra is approximately
reproduced if the coherent state operators are restricted to act on the
large- @xmath sector of the space spanned by the states @xmath .

### 10.5 Geometric operators

In this section we continue our series of examples by discussing the
coherent state counterparts of some of the geometric operators of loop
quantum gravity that were introduced in Chapter 8 .

#### Area operator

Classically, the area of a surface @xmath can be expressed as the
”length” of the associated flux variable, i.e. @xmath . Consequently, we
take the operator

  -- -------- -- ---------
     @xmath      (10.42)
  -- -------- -- ---------

as the coherent state operator describing the area dual to a spin
network edge. Following the calculation that lead from Eq. ( 10.23 ) to
Eq. ( 10.25 ), we see that the operator ( 10.42 ) has the matrix
elements

  -- -------- -- ---------
     @xmath      (10.43)
  -- -------- -- ---------

Here the integral is of the by now familiar form, and is proportional to
@xmath . Thus we conclude that the states @xmath are eigenstates of the
coherent state area operator

  -- -------- -- ---------
     @xmath      (10.44)
  -- -------- -- ---------

with the eigenvalues given by

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.45)
  -- -------- -------- -- ---------

where the error function is defined as @xmath .

The eigenvalues ( 10.45 ) are plotted in Fig. 4 as a function of @xmath
for various values of the parameter @xmath . For comparison, the
eigenvalues @xmath of the canonical area operator are also shown. We see
that as @xmath increases, the eigenvalues of the coherent state operator
approach those of the canonical operator, the convergence being faster
for larger values of @xmath . Indeed, for large values of @xmath the
eigenvalue ( 10.45 ) has the asymptotic behaviour

  -- -------- -- ---------
     @xmath      (10.46)
  -- -------- -- ---------

showing that the eigenvalues of the coherent state operator agree with
the canonical eigenvalues in the limit of large @xmath . For smaller
values of @xmath , the eigenvalues @xmath deviate noticeably from the
canonical eigenvalues, especially if the value of @xmath is not very
large, so that the coherent states used to construct the operator (
10.42 ) are not very sharply peaked on the flux variable. The
discrepancy is the most drastic for @xmath , since @xmath for all values
of @xmath , and so even an edge of spin zero carries a non-zero area
according to the coherent state area operator ¹⁹ ¹⁹ 19 As could have
been expected, keeping in mind the theorem proven in section 10.2 . .

#### Angle operator

Taking the function @xmath in Eq. ( 10.3 ) to be the angle between two
flux vectors, we obtain the coherent state angle operator

  -- -------- -- ---------
     @xmath      (10.47)
  -- -------- -- ---------

which acts on a pair of edges sharing a node in a spin network state.
Recalling the discussion after Eq. ( 10.3 ), we have assumed that both
edges are oriented out of the node. If an edge is oriented into the
node, the corresponding variable @xmath should be replaced with @xmath
in Eq. ( 10.47 ).

Let us study the action of the operator ( 10.47 ) on a state of the form

  -- -------- -- ---------
     @xmath      (10.48)
  -- -------- -- ---------

where the two edges are coupled into an internal spin @xmath by the
intertwiner at the node. Taking the matrix element of the operator
between two such states, and performing the immediate integrations over
@xmath , we get

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (10.49)
  -- -------- -------- -- ---------

The integral appearing here – let us denote it by @xmath – is of a form
not encountered so far, but it can be dealt with by a generalization of
the reasoning used to evaluate integrals earlier in this chapter. The
rotational invariance of the angle function implies that the integral is
invariant under the action of @xmath on its indices, in the sense that

  -- -------- -- ---------
     @xmath      (10.50)
  -- -------- -- ---------

This means that the integral, viewed as an @xmath tensor, is an element
of the intertwiner space @xmath . Expanding @xmath in a suitable basis
of this space, we can write

  -- -------- -- ---------
     @xmath      (10.51)
  -- -------- -- ---------

where the basis intertwiners are

  -- -------- -- ---------
     @xmath      (10.52)
  -- -------- -- ---------

and therefore

  -- -- -- ---------
           (10.53)
  -- -- -- ---------

Inserting now Eq. ( 10.51 ) back into Eq. ( 10.49 ), and using the
orthogonality relation ( B.18 ) of the 3 @xmath -symbols, we find

  -- -------- -- ---------
     @xmath      (10.54)
  -- -------- -- ---------

Hence we see that the coherent state angle operator (just as its
canonical counterpart) acts diagonally on the state ( 10.48 ):

  -- -------- -- ---------
     @xmath      (10.55)
  -- -------- -- ---------

where the eigenvalue is

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.56)
  -- -------- -------- -- ---------

It is not clear how one could try to derive an explicit, analytical
expression for the eigenvalues, so the integral ( 10.56 ) was evaluated
numerically in order to compare the coherent state angle operator with
the canonical operator, whose eigenvalue on the state ( 10.48 ) is

  -- -------- -- ---------
     @xmath      (10.57)
  -- -------- -- ---------

In Fig. 5 we show the results of a numerical calculation in the
”equilateral” case, in which @xmath , and the canonical eigenvalue is
equal to @xmath independently of the value of @xmath . The eigenvalues
for various values of @xmath are plotted as a function of the parameter
@xmath . We see that the eigenvalues converge to certain limiting values
with increasing @xmath , the limiting value being reached faster for
larger values of @xmath . As a function of @xmath , the eigenvalues of
the coherent state operator seem to approach the canonical eigenvalue as
the value of @xmath grows. The small fluctuations in the eigenvalues,
which are seen in the plot for larger values of @xmath , can be
attributed to numerical error and are not a genuine feature of the data.

In Fig. 6 we have the ”degenerate” case, where @xmath , and @xmath ,
with the value of @xmath being fixed to @xmath . The canonical
eigenvalue is now given by @xmath . We see that the eigenvalues of the
coherent state operator behave as a function of @xmath in a similar way
as the eigenvalues of the canonical operator, but with increasing @xmath
, the coherent state eigenvalues approach the canonical eigenvalues much
more slowly than in the equilateral case. Nevertheless, the relative
difference between the two sets of eigenvalues, shown in Fig. 7 , seems
to remaing roughly constant as @xmath increases, so it seems plausible
that the eigenvalues of the coherent state operator would approach zero,
and hence converge to the canonical eigenvalues, in the limit of large
@xmath .

#### Volume operator

A coherent state volume operator associated to an @xmath -valent spin
network node can be constructed as

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (10.58)
  -- -------- -------- -- ---------

where @xmath is some volume function defined by the vectors @xmath .
Naturally the remarks made in section 10.1 on the relation between the
variables @xmath and the orientation of the graph should be kept in mind
also here, and for each edge with an incoming orientation, the
corresponding @xmath in Eq. ( 10.58 ) should be understood as a @xmath .
It should also be noted that, pending the choice of the function @xmath
, Eq. ( 10.58 ) defines the coherent state volume operator in an
explicit form, in contrast to the situation with the canonical volume
operator, which can be defined only implicitly, as the square root of
another operator for which an explicit expression can be written down.

Computing the matrix elements of the operator ( 10.58 ) in the
intertwiner space of the node proceeds along the same lines as the
calculation made above for the angle operator, and leads to the result

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (10.59)
  -- -------- -- ---------

In particular, a three-valent spin network node, whose intertwiner space
is one-dimen-sional, is an eigenstate of the operator @xmath . The
eigenvalue is given by Eq. ( 10.59 ) with @xmath , and @xmath and @xmath
equal to the 3 @xmath -symbol with spins @xmath , @xmath and @xmath .
Recalling the theorem of section 10.2 , one should not expect the
eigenvalue to be zero, unless the volume function @xmath vanishes
identically.

The main obstacle against obtaining a satisfactory volume operator from
the definition ( 10.58 ) is due to the fact that the integrations in Eq.
( 10.58 ) place no restriction on the vectors @xmath , and consequently
it seems difficult to choose the volume function @xmath in a way that
would be compatible with the usual geometrical picture associated with a
spin network state, in which an @xmath -valent spin network node is
interpreted as an @xmath -faced ”quantum polyhedron”. If one were
willing to give up this interpretation, one could simply choose @xmath
to be the volume of the @xmath -faced polyhedron spanned by the vectors
@xmath (in the sense that the area and unit normal of the @xmath -th
face are given respectively by @xmath and @xmath ). Otherwise one might
have to look for a modified resolution of identity, which would express
the unit operator on the Hilbert space of a graph in such a way that the
condition @xmath would be enforced at every node of the graph, since the
polyhedron spanned by the vectors @xmath would then have only @xmath
faces.

A very similar situation arises with the Livine–Speziale coherent
intertwiners [ 94 ]

  -- -------- -- ---------
     @xmath      (10.60)
  -- -------- -- ---------

Starting with the resolution of identity on the space @xmath in terms of
the states @xmath , it is immediate to see that the identity operator on
the @xmath -valent intertwiner space @xmath can be resolved in terms of
the intertwiners ( 10.60 ) as

  -- -------- -- ---------
     @xmath      (10.61)
  -- -------- -- ---------

In principle, Eq. ( 10.61 ) could be taken as a starting point for
constructing coherent state operators representing geometrical
quantities described by functions of the vectors @xmath . However, it
would again be difficult to define a reasonable volume operator in this
way, since the integral in Eq. ( 10.61 ) is taken unrestricted over all
configurations of the vectors @xmath .

On the other hand, in the article [ 59 ] Conrady and Freidel obtained
the remarkable and certainly not obvious result that the unit operator
on the four-valent ²⁰ ²⁰ 20 Even though Conrady and Freidel proved Eq. (
10.62 ) only for four-valent intertwiners, it seems reasonable to expect
that a similar result would hold in the @xmath -valent case as well.
intertwiner space @xmath can be expressed in the alternate form

  -- -------- -- ---------
     @xmath      (10.62)
  -- -------- -- ---------

where the integration measure @xmath is a non-trivial function of the
@xmath ’s and @xmath ’s. The key feature of the result ( 10.62 ) is the
delta function, which ensures that the identity operator is resolved
entirely in terms of coherent intertwiners satisfying the so-called
closure condition @xmath . When the closure condition is satisfied, the
vectors @xmath can be interpreted as the unit normals of an @xmath
-faced polyhedron, while the spins @xmath are interpreted as the areas
of the faces. It is then clear how a coherent state volume operator
consistent with the geometrical interpretation of a spin network node
could be constructed from Eq. ( 10.62 ), and in fact such an operator
has been considered in [ 37 ] .

In the same way, it seems that in order to obtain a satisfactory volume
operator from Thiemann’s complexifier coherent states, one would likely
have to start by deriving a resolution of identity analogous to Eq. (
10.62 ), where a closure condition for the @xmath -vectors would be
implemented at every node of the graph, rather than trying to construct
a volume operator from the simple resolution of identity which was used
to write down Eq. ( 10.3 ).

### 10.6 Discussion

In all the examples considered in this chapter, the analysis of a given
coherent state operator has been significantly more complicated than
that of the corresponding canonical operator. Therefore one might be
inclined to write off the idea of considering coherent state operators
altogether as unpromising, and unlikely to lead to anything practically
useful. However, in the author’s opinion, the apparent complexity of
coherent state operators is most of all a reflection of the fact that
the technology associated with coherent states in loop quantum gravity
is still relatively poorly developed. In particular, the problem of
devising effective tools for computations involving Thiemann’s coherent
states has not received very much attention in the literature, whereas
the proper techniques for performing calculations in the usual spin
network basis are already well known.

Some of the limitations of the construction of coherent state operators
given in this chapter can likewise be attributed to the analogous
limitations of the coherent states taken as the starting point for the
construction. For instance, the operators constructed in this chapter
are restricted to the Hilbert space of a fixed graph. In general, they
cannot even be consistently extended to operators defined on the entire
(kinematical) Hilbert space of loop quantum gravity, as shown very
clearly by the example of the area operator, which associates a non-zero
area even to a spin network edge carrying spin zero. However, it is not
very surprising that this is the best one can do, if the coherent states
from which the operators are constructed are themselves defined on a
fixed graph. Once coherent states defined over a superposition of graphs
are developed, we expect that they could be used to construct coherent
state operators which are not restricted to a fixed graph, and which
could act on spin network states in a graph-changing manner. For now the
utility of coherent state operators in loop quantum gravity is certainly
limited by the mediocre selection of coherent states available to be
used in their construction.

So far we have studied coherent state operators by deriving exact
expressions for their action on the spin network basis, essentially
considering the coherent state operators as fundamental operators
alternative to the ones obtained through canonical quantization. A
potentially more fruitful point of view, suggested by the fact that
coherent state operators seem to converge to the corresponding canonical
operators in the limit of large spins, could be to consider coherent
state operators merely as a technical tool providing some sort of a
semiclassical approximation to the fundamental canonical operators. On a
technical level, the action of the (for now hypothetical) coherent state
volume operator on a suitable semiclassical state might well be easier
to handle than that of the canonical volume operator, since the
integrations involved in the matrix elements of the coherent state
operator could possibly be dealt with by saddle point techniques based
on the peakedness properties of the semiclassical state, whereas
computing the matrix elements of the canonical operator would a priori
involve extracting the square root of a large matrix.

@xmath

Part 2

Dynamics of loop quantum gravity
with scalar field as a physical time variable

  Some people are so much impressed by the difficulties of passing over
  from Hamiltonian classical mechanics to quantum mechanics that they
  think that maybe the whole method of working from Hamiltonian
  classical theory is a bad method. Particularly in the last few years
  people have been setting up alternative methods for getting quantum
  field theories. They have made quite considerable progress on these
  lines. (…) Still I feel that these alternative methods (…) will not
  lead to a final solution to the problem. I feel that there will always
  be something missing from them which we can only get by working from a
  Hamiltonian, or maybe from some generalization of the concept of a
  Hamiltonian. So I take the point of view that the Hamiltonian is
  really very important for quantum theory.

  – P. A. M. Dirac

## 11 Dynamics in loop quantum gravity

### 11.1 The problem of time

The spin network states of loop quantum gravity provide a mathematically
consistent and physically appealing kinematical description of the
quantized gravitational field. The physical picture associated to spin
network states describes a quantum state of the gravitational field as a
state of discrete, quantized spatial geometry, formed by elementary
quanta of volume which are separated from each other by elementary
quanta of area. This is a compelling realization of the idea,
fundamental to general relativity, that the gravitational field and the
geometry of spacetime are essentially the same physical object.

Before the structure of the quantum theory can be considered complete,
the crucial element which must still be introduced is a prescription
which specifies the dynamics of the quantum states of the theory. Aside
from any possible technical difficulties which might be involved in the
definition of dynamics, the issue is made conceptually complicated by
the so-called ”problem of time” in general relativity. In general
relativity, there is no time variable possessing any absolute,
physically distinguished meaning. Consequently, in the canonical
formulation of the theory, there is no Hamiltonian which would govern
the dynamics of the theory by generating time evolution with respect to
such a time variable. Instead, the canonical Hamiltonian is merely a
linear combination of constraints, so all physical (gauge-invariant)
observables simply commute with the Hamiltonian. At a first sight, it
would therefore seem that the observables are ”frozen” and there is no
dynamics, nor any notion of ”time”, in the formalism.

The resolution of this apparent paradox is that in general relativity,
as in any generally covariant theory, the physically significant
information which can be extracted from the theory is not contained in
the dependence of a physically measurable quantity on the spacetime
coordinates, which are in general essentially arbitrary and physically
meaningless. Rather, it is contained in the relations between a
measurable quantity and other measurable quantities. In particular, the
dynamics of the theory is not revealed by the way in which a single
measurable quantity changes with respect to an arbitrary time
coordinate, but in the way in which the different measurable quantities
of the theory change in relation to one another.

As an example (adapted from the examples discussed in [ 105 ] ),
consider some measurable physical quantity in general relativity, such
as the angular position of the Sun in the sky (say, relative to the
telescope of a certain observatory). Once a specific choice of
coordinates is made, the angles @xmath can (at least in principle) be
computed from the Einstein equations as a function of the chosen time
coordinate. However, such a result cannot really be regarded as a
physical prediction, considering that the choice of @xmath is
practically arbitrary, and in general a procedure by which the value of
the time coordinate could be measured might not be available.

In order to obtain a genuine prediction about measurable physics from
the formalism of general relativity, we must extend our considerations
to include another physical quantity, such as the angular position of
the Moon in the sky. After the angles @xmath as a function of @xmath
have been computed, the time coordinate can be eliminated (at least
locally, within a certain range of values of @xmath ) to express the
position of one of the celestial bodies as a (possibly implicit)
function of the position of the other.

The relation between the position of the Sun and that of the Moon is
therefore a quantity which can be determined from the equations of
general relativity. In other words, a valid physical question, whose
answer can be predicted by the theory, is: What will be the position of
the Sun, given that the position of the Moon is observed to have a
certain value? ²¹ ²¹ 21 In Rovelli’s terminology [ 106 , 105 ] ,
quantities which can be measured but whose value cannot be predicted
(such as the position of the Sun or the Moon) are called partial
observables. Measurable quantities which can be predicted from the
theory (such as the position of the Sun relative to the position of the
Moon) are called complete observables. This prediction can naturally be
formulated in a way which makes no reference to any arbitrarily chosen
system of spacetime coordinates. The only role of the coordinates is to
serve as an auxiliary bookkeeping device, facilitating the derivation of
the eventual coordinate-free prediction.

### 11.2 Dynamics in the fully constrained theory

Coming back to the issue of dynamics in the quantum theory, the approach
most in line with Dirac’s ideas on quantizing a generally covariant
theory would begin with trying to promote the Hamiltonian constraint
into an operator on a suitable Hilbert space of loop quantum gravity.
The constraint operator serves a dual purpose: On one hand, the states
which are annihilated by the constraint form the Hilbert space of
physical states; on the other hand, the constraint operator also selects
the physical (i.e. gauge invariant) observables of the theory. If the
physical Hilbert space can be constructed, information about dynamics
will be encoded in the scalar product on this space, which defines
transition amplitudes between physical states.

As an example illustrating how dynamical information can be contained in
transition amplitudes, let us consider the setting of a calculation
which has been performed in the spin foam formulation of loop quantum
gravity [ 40 , 38 ] . Suppose we have a family of semiclassical states
@xmath , each of which is peaked on a homogeneous and isotropic spatial
geometry characterized by certain values of the scale factor @xmath and
the ”velocity” @xmath . Denoting by @xmath the operator defining
transition amplitudes, the amplitude

  -- -------- -- --------
     @xmath      (11.1)
  -- -------- -- --------

describes the probability of obtaining a state peaked on the values
@xmath from an initial state which is peaked on the values @xmath .
Considering @xmath as a function of @xmath and @xmath for fixed values
of @xmath and @xmath , one could argue that the classical dynamics of a
homogeneous and isotropic spatial geometry is correctly recovered from
the quantum theory if the magnitude of @xmath is suppressed unless the
point @xmath is on (or at least very close to) the classical trajectory
resulting from the evolution of the initial values @xmath . (This is the
conclusion which was found in [ 38 ] .)

In the above example, information about dynamics is again given by the
relation of the variables @xmath and @xmath to one another, as opposed
to the evolution of these variables with respect to a physically
meaningless time parameter; in fact, such a time parameter is entirely
absent from the calculation.

In loop quantum gravity, the construction of the Hamiltonian constraint
as a concrete and well-defined operator has been accomplished originally
by Thiemann [ 117 ] , and later by other authors [ B , 8 , 75 , 129 ]
following the example set by Thiemann in varying degrees of closeness
(see Chapters 13 and 15 ). This is already a considerable achievement,
in light of the complicated form of the classical Hamiltonian constraint
as a function of the Ashtekar variables. However, the complexity of the
classical constraint functional is invariably reflected in the
complexity of the corresponding quantum operator, and consequently the
task of deriving solutions of the constraint operator in explicit form,
not to mention uncovering the physical interpretation of the resulting
states, has proven to be extremely challenging. In fully concrete terms,
very little is known about the physical Hilbert space (or the physical
scalar product thereon) defined by the kernel of any of the constraint
operators available in the literature, even though the structure of the
kernel of a given constraint operator can often be described to some
extent on a qualitative level.

### 11.3 Deparametrization

The practical difficulties encountered with the Hamiltonian constraint
operator have motivated the search for alternative ways to deal with the
problem of dynamics in loop quantum gravity. Within the canonical
formalism, one of the main alternatives to working with the Hamiltonian
constraint is the so-called method of deparametrization, in which one of
the degrees of freedom contained in the theory is assigned the role of a
physical, relational time variable, with respect to which the dynamics
of the remaining degrees of freedom is described.

It is possible to deparametrize general relativity ”intrinsically”, in
terms of geometric quantities such as proper distances and angles (see
e.g. [ 70 , 71 , 42 ] ), but the resulting formalism is rather
cumbersome and difficult to handle in practice. A more tractable
approach is to consider gravity coupled with a matter field – in
practice, a suitable scalar field – which is used as a physical time
variable for the dynamics of the gravitational field.

In a deparametrized model of gravity, the Hamiltonian constraint is
essentially traded for a physical Hamiltonian, which generates time
evolution with respect to the time variable provided by the scalar
field. After the scalar field has been singled out as the time variable,
reparametrization of the time coordinate is no longer a gauge invariance
of the theory. In the quantum theory, the physical Hilbert space is
therefore the space of diffeomorphism invariant states, and the dynamics
of states in @xmath is governed by the Schrödinger equation

  -- -------- -- --------
     @xmath      (11.2)
  -- -------- -- --------

in which @xmath is the time defined by the scalar field, and a physical
Hamiltonian operator acts as the generator of time evolution. The issues
of extracting solutions of the Hamiltonian constraint and interpreting
them physically, and determining the scalar product on the physical
Hilbert space, are entirely bypassed in models of loop quantum gravity
where the dynamics is defined through deparametrization.

The use of scalar fields as reference fields for general relativity was
first considered in a series of articles by Kuchař and collaborators [
54 , 41 , 88 , 89 ] . In the context of loop quantum gravity, a model in
which a massless Klein–Gordon field is used as a physical time variable
was proposed by Rovelli and Smolin [ 108 ] . The quantum theory of the
model has been developed in more detail in [ 69 ] and [ A ] , while the
classical structure of the model was studied by Kuchař and Romano in [
87 ] . In addition, a non-rotational dust field as a time variable for
loop quantum gravity has been considered by Husain and Pawłowski [ 81 ,
82 ] . A comprehensive catalog of deparametrized models, including
models where three additional scalar fields are introduced to serve as a
spatial reference system, is given by Giesel and Thiemann in [ 77 ] .

In this work, deparametrization by means of a scalar field will be
considered as the main approach for tackling the problem of dynamics in
loop quantum gravity. Since this point of view is motivated entirely by
practical considerations, we will focus our entire attention on specific
models containing a single scalar field, whose purpose is to act a
physical time variable. These are the free scalar field model proposed
by Rovelli and Smolin, and the non-rotational dust model due to Brown
and Kuchař, and Husain and Pawłowski. Models in which four scalar fields
are used to deparametrize the entire spacetime will not be considered in
this work.

### 11.4 Other approaches to dynamics

To conclude this chapter, we will briefly mention some of the other
approaches that have been developed in an attempt to give an adequate
definition of the dynamics for loop quantum gravity. Staying within the
context of the canonical theory, Thiemann has proposed the so-called
master constraint programme [ 121 ] , in which the infinite number of
Hamiltonian constraints @xmath are replaced with the single ”master
constraint”

  -- -------- -- --------
     @xmath      (11.3)
  -- -------- -- --------

the vanishing of which is equivalent to all the constraints @xmath
vanishing one-by-one. The master constraint carries no dependence on the
lapse function, and its constraint algebra is significantly simpler than
the algebra of the standard Hamiltonian constraint. Due to these
features, the introduction of the master constraint can potentially
clear up some issues of a formal, mathematical nature. However, it seems
unlikely that the practical problems one faces when trying to extract
solutions of the Hamiltonian constraint would be any less severe in the
case of the master constraint.

A notable and highly prominent framework for the dynamics of loop
quantum gravity is the spin foam formalism, also often referred to as
covariant loop quantum gravity (see [ 100 , 107 , 111 ] and references
therein). The dynamics of the covariant theory is defined, broadly
speaking, by performing a concrete implementation of a particular
version of the path integral for general relativity, thereby providing a
prescription for associating transition amplitudes to spin network
states.

Technically, the spin foam formalism assigns an amplitude to every
colored two-complex (the faces and edges of the two-complex being
”colored” respectively with spins and intertwiners). The two-complex
arises as the dual of a simplicial decomposition of the spacetime
manifold, which is introduced as a tool for regularizing the path
integral. If the boundary of the two-complex consists of two disjoint
graphs, the corresponding amplitude can be interpreted as a transition
amplitude between the spin network states defined by the two boundary
graphs together with the associated spins and intertwiners. The
two-complex itself can then be interpreted as a sort of Feynman diagram
describing a particular ”history” of a spin network state (in the same
sense in which a Feynman diagram in conventional quantum field theory
describes a history of particles).

The group field theory approach [ 97 ] pioneered by Oriti represents a
more significant departure from the conventional framework of loop
quantum gravity. On the kinematical level, the state space considered in
this approach is similar to the kinematical Hilbert space of loop
quantum gravity, but there are a number of significant differences. The
dynamics is specified by using a Feynman expansion of the group field
theory to assign transition amplitudes to the kinematical states.

## 12 Classical theory of deparametrized models

In this chapter we venture briefly into the classical theory of the
deparametrized models of general relativity which will be used later in
this work to provide a definition of the dynamics for loop quantum
gravity. The two models which will be considered are the free scalar
field model proposed by Rovelli and Smolin [ 108 ] (and developed
further in [ 69 ] and [ A ] ), and the non-rotational dust model, which
was introduced classically by Brown and Kuchař [ 54 ] , and first
studied in the context of loop quantum gravity by Husain and Pawłowski [
81 ] . Here we do not attempt to give a comprehensive discussion of the
classical theory of these models; the only goal of this chapter is to
establish the form of the physical Hamiltonian which generates the
dynamics of the gravitational field with respect to the relational time
provided by the reference scalar field, and whose quantization will lead
to the operator governing the dynamics in the quantum theory.

### 12.1 Free scalar field model

The system formed by the gravitational field and a minimally coupled
massless Klein–Gordon field is described by the action

  -- -------- -- --------
     @xmath      (12.1)
  -- -------- -- --------

After a standard 3+1 decomposition in the ADM variables is performed,
the action takes the form

  -- -------- -- --------
     @xmath      (12.2)
  -- -------- -- --------

where @xmath is the canonical momentum of the scalar field. Here the
diffeomorphism and Hamiltonian constraints are

  -- -------- -- --------
     @xmath      (12.3)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (12.4)
  -- -------- -- --------

with @xmath and @xmath denoting the gravitational contributions to the
constraints, as given by Eqs. ( 1.25 ) and ( 1.26 ).

In practical terms, the physical Hamiltonian, which generates the
dynamics of the gravitational field with respect to the internal time
provided by the scalar field, is now determined by solving the system of
constraints ( 12.3 )–( 12.4 ) for the momentum of the scalar field, and
taking the resulting expression as the physical Hamiltonian density.
That this procedure indeed correctly gives the physical Hamiltonian can
be justified in various ways. In [ 69 ] , the authors considered the
quantization of the classical theory defined by the diffeomorphism
constraint ( 12.3 ) and the modified Hamiltonian constraint ²² ²² 22 If
the Ashtekar variables are used to describe the gravitational field, the
Gauss constraint must naturally be included in the system of
constraints.

  -- -------- -- --------
     @xmath      (12.5)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (12.6)
  -- -------- -- --------

When taking the square roots in Eq. ( 12.6 ), the signs have been chosen
according to what seems to be the unique choice leading to a
positive-definite and non-trivial Hamiltonian operator in the quantum
theory. In the region of phase space corresponding to the sign choices
made in Eq. ( 12.6 ), the constraint ( 12.5 ) is equivalent to the
original Hamiltonian constraint ( 12.4 ).

It was then shown in [ 69 ] that the quantum observables defined by the
constraint ( 12.5 ) (together with the Gauss and diffeomorphism
constraints) are essentially certain operators on @xmath which are
labeled by values of the scalar field @xmath . If the scalar field is
interpreted as a physical time variable, the dynamics of an observable
@xmath is generated by the Heisenberg-like equation

  -- -------- -- --------
     @xmath      (12.7)
  -- -------- -- --------

where the physical Hamiltonian @xmath is an operator constructed by
quantizing the classical functional ( 12.6 ). In practice, on grounds of
the reasoning that the physical Hamiltonian will act in the
diffeomorphism invariant Hilbert space, the factor involving the
diffeomorphism constraint in the classical expression ( 12.6 ) is
discarded, and

  -- -------- -- --------
     @xmath      (12.8)
  -- -------- -- --------

is taken as the classical functional to be quantized in order to define
the physical Hamiltonian for the free scalar field model.

An alternative way of seeing that ( 12.8 ) is the generator of dynamics
with respect to the scalar field time can be derived by considering the
time evolution of the gravitational variables @xmath under the canonical
Hamiltonian

  -- -------- -- --------
     @xmath      (12.9)
  -- -------- -- --------

which generates evolution with respect to the time coordinate @xmath
corresponding to the foliation defined by the lapse @xmath and the shift
@xmath . Considering first an arbitrary, unspecified foliation, the
evolution of a functional @xmath is given by the equation

  -- -------- -- ---------
     @xmath      (12.10)
  -- -------- -- ---------

Let us now specialize this general result to the case in which the
scalar field is taken as the time variable, by introducing the following
assumptions:

-   The spatial surfaces @xmath are chosen to be the surfaces on which
    the scalar field @xmath takes constant values. (In particular, this
    choice implies that @xmath .)

-   The value of the lapse function is set to @xmath , this value being
    derived from the requirement that the coordinate choice @xmath is
    preserved under time evolution.

-   We also assume the constraints ( 12.3 ) and ( 12.4 ) to be
    satisfied, so that the expression ( 12.6 ) (where now @xmath ) can
    be substituted for the value of the scalar field momentum @xmath .

If we additionally restrict ourselves to a diffeomorphism invariant
observable @xmath , so that @xmath commutes with the diffeomorphism
constraint, then a short calculation shows that Eq. ( 12.10 ) is
equivalent to the equation

  -- -------- -- ---------
     @xmath      (12.11)
  -- -------- -- ---------

where @xmath , and @xmath is the functional given by Eq. ( 12.8 ).

Under the point of view summarized by Eq. ( 12.11 ), the scalar field is
chosen as a time variable already at the classical level, and the
physical Hamiltonian ( 12.8 ) is considered as the generator of time
evolution (for diffeomorphism invariant observables) in the classical
theory. This is to be contrasted with the point of view in which the
classical theory is regarded as a fully constrained theory, with the
Hamiltonian constraint given by Eq. ( 12.5 ). The choice of the scalar
field as a time variable is then introduced at the level of the quantum
theory, and the physical Hamiltonian emerges as the operator governing
the dynamics of the observables selected by the constraint ( 12.5 ). As
the structure of the resulting quantum theory will be exactly the same
in either case, the question of which point of view is preferable is
ultimately a matter of taste, and seems to have little practical
importance.

### 12.2 Non-rotational dust model

The model of gravity coupled to non-rotational dust [ 54 , 81 ] is
described by the action

  -- -------- -- ---------
     @xmath      (12.12)
  -- -------- -- ---------

The variable @xmath acts essentially as a Lagrange multiplier; it
enforces the gradient @xmath to be timelike, i.e. the surfaces of
constant @xmath to be spacelike ²³ ²³ 23 In the dust model, the constant
surfaces of the dust field are therefore guaranteed to be suitable for
use as the spatial surfaces of a 3+1 decomposition of spacetime.
Strictly speaking, no similar guarantee holds for the constant surfaces
of the Klein–Gordon field in the free scalar field model. . The physical
interpretation of the field @xmath as a dust field is revealed by the
energy-momentum tensor of the field,

  -- -------- -- ---------
     @xmath      (12.13)
  -- -------- -- ---------

(with @xmath ), which has the form corresponding to pressureless dust.

Upon a 3+1 decomposition, using again the ADM variables to describe the
gravitational field, the action of the dust field is transformed into

  -- -------- -- ---------
     @xmath      (12.14)
  -- -------- -- ---------

From this we can read off the canonical momentum of the dust field as

  -- -------- -- ---------
     @xmath      (12.15)
  -- -------- -- ---------

The action ( 12.14 ) can then be cast in the form

  -- -------- -- ---------
     @xmath      (12.16)
  -- -------- -- ---------

with the contributions of the dust field to the constraints given by

  -- -------- -- ---------
     @xmath      (12.17)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (12.18)
  -- -------- -- ---------

Before proceeding further with the canonical analysis of the model, we
choose at this point to impose the choice of the dust field as the time
coordinate, following the approach proposed in [ 114 ] as an improvement
over the treatment of [ 81 ] . The coordinate choice @xmath immediately
implies that @xmath and @xmath . Moreover, by requiring that the
condition @xmath is preserved under time evolution, one finds that the
value of the lapse function is fixed to @xmath (while no restriction is
placed on the shift vector). Under these assumptions, the momentum of
the dust field becomes

  -- -------- -- ---------
     @xmath      (12.19)
  -- -------- -- ---------

When this relation is used to eliminate the non-dynamical field @xmath
in favour of @xmath and @xmath , the constraint ( 12.18 ) reduces to
@xmath . (The diffeomorphism constraint ( 12.17 ) vanishes identically
when the value of @xmath is constant on each spatial surface.) Going
then back to the action ( 12.12 ) for the entire model, we obtain

  -- -------- -- ---------
     @xmath      (12.20)
  -- -------- -- ---------

which can be seen as a kind of gauge-fixed action for the gravitational
field, when the role of a physical time variable has been assigned to
the dust field. Since the time variable has been fixed,
reparametrization of the time coordinate is not a gauge symmetry of the
model; rather, @xmath in Eq. ( 12.20 ) is interpreted as a generator of
time evolution for the gravitational variables with respect to the time
defined by the dust field. (Again, one can alternatively come to this
conclusion by implementing the choice @xmath in the analog of Eq. (
12.10 ) in the dust model.)

We have thus found that the physical Hamiltonian for the non-rotational
dust model is given by the functional

  -- -------- -- ---------
     @xmath      (12.21)
  -- -------- -- ---------

From this we see the central advantage of the dust model over the free
scalar field model considered in the previous section: No square root is
involved in the classical expression for the physical Hamiltonian in the
dust model. Accordingly, when it comes to the construction of the
quantum theory, the physical Hamiltonian for the dust model can be
defined as an operator whose action on spin network states can be
computed in explicit form even without knowing anything about the
spectrum of the operator. In contrast, in the case of the scalar field
model the square root in the classical expression ( 12.8 ) carries over
to the Hamiltonian operator in the quantum theory, and so a knowledge of
the spectral decomposition of the Hamiltonian is required in order to
resolve the square root and make the action of the Hamiltonian
explicitly computable.

## 13 Thiemann’s Hamiltonian

This chapter is devoted to a presentation of Thiemann’s construction of
the Hamiltonian constraint operator. The construction of a
mathematically well-defined and explicitly formulated constraint
operator is already a remarkable achievement, considering the
complicated and highly non-polynomial dependence of the classical
constraint functional on the elementary Ashtekar variables. Thiemann’s
work therefore represents an important milestone in the history of loop
quantum gravity.

Our reasons for giving a detailed review of Thiemann’s Hamiltonian are
twofold. Firstly, Thiemann’s work, with its subtle rewritings of
classical expressions in terms of objects which can be consistently
quantized, and its careful construction of a regularization which leads
in the end to a well-defined quantum operator, serves as a prototype and
a model example on how operators can be constructed in loop quantum
gravity. Secondly, we will establish that in spite of its great
importance in the fully constrained theory, Thiemann’s constraint
operator is not a suitable candidate for the physical Hamiltonian in
deparametrized models of loop quantum gravity, and we will therefore
have to search for a more appropriate Hamiltonian in the deparametrized
context. The construction of an adequate physical Hamiltonian is one of
the central results of this work, and will be taken up in the next
chapter.

### 13.1 Classical preparations

Thiemann’s construction [ 117 ] (see also [ 122 ] ) is based on the
classical expression ( 1.67 ) for the constraint. The smeared constraint
@xmath has the form

  -- -------- -- --------
     @xmath      (13.1)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (13.2)
  -- -------- -- --------

is called the Euclidean part of the constraint (since ( 13.2 ) could be
taken as the entire Hamiltonian constraint in the case of general
relativity with Euclidean signature), and the remainder

  -- -------- -- --------
     @xmath      (13.3)
  -- -------- -- --------

is called the Lorentzian part.

At a first sight Eqs. ( 13.1 )–( 13.3 ) may seem to suffer from certain
concrete difficulties, making them a questionable starting point for the
quantization of the Hamiltonian constraint. The inverse volume element
appearing in Eqs. ( 13.2 ) and ( 13.3 ) cannot be quantized in a
straightforward way, unless one is willing to employ a quantization of
the type ( 8.36 ) to circumvent the fact that the volume operator has a
large kernel and is therefore not invertible. Furthermore, even though
the curvature @xmath in the Euclidean part can be quantized by relating
it to a holonomy around a small loop, as indicated by Eq. ( 2.10 ), it
is not immediately clear how to quantize the extrinsic curvature terms
in the Lorentzian part, since no obvious operator corresponding to
@xmath is available in the quantum theory.

An ingenious way to overcome these difficulties was discovered by
Thiemann, who used a series of classical identities – now commonly
referred to as Thiemann’s tricks – to manipulate the expressions ( 13.2
) and ( 13.3 ) into a form suitable for quantization. First of all,
Thiemann observed that the factors of @xmath can be eliminated by means
of the Poisson bracket relation

  -- -------- -- --------
     @xmath      (13.4)
  -- -------- -- --------

Using Eq. ( 13.4 ), the Euclidean part of the constraint can be
rewritten as

  -- -------- -- --------
     @xmath      (13.5)
  -- -------- -- --------

which provides an appropriate starting point for quantization, since all
the elements on the right-hand side now correspond to some definite
operators in loop quantum gravity. In analogy with the quantization of
the curvature of the Ashtekar connection, the connection itself can be
quantized by relating it to the holonomy over a short line segment; then
the Poisson bracket can simply be replaced with the commutator of the
corresponding operators in the quantum theory.

While the inverse volume element can be eliminated also in the
Lorentzian part with the help of Eq. ( 13.4 ), further manipulations are
needed in order to deal with the factor involving the extrinsic
curvature. Thiemann’s treatment of this factor consists of two steps,
the first of which is to observe that the integrated trace of the
extrinsic curvature,

  -- -------- -- --------
     @xmath      (13.6)
  -- -------- -- --------

satisfies the identity

  -- -------- -- --------
     @xmath      (13.7)
  -- -------- -- --------

In verifying this, one should recall from Chapter 1 that the variation
@xmath is a total derivative, from which it follows that @xmath .
Inserting Eqs. ( 13.4 ) and ( 13.7 ) into Eq. ( 13.3 ), the Lorentzian
part takes the form

  -- -------- -- --------
     @xmath      (13.8)
  -- -------- -- --------

and it remains to explain how to promote @xmath into a loop quantum
gravity operator. The last one in Thiemann’s sequence of tricks
accomplishes this by relating @xmath to the Poisson bracket @xmath ,
both of whose arguments are available as operators in loop quantum
gravity (assuming, of course, that the operator corresponding to the
Euclidean constraint has been successfully constructed). We shall take a
moment to derive the precise relation, since several different versions
of it, with varying numerical prefactors, can be found in the
literature.

The Poisson bracket in question is

  -- -------- -- --------
     @xmath      (13.9)
  -- -------- -- --------

From Eq. ( 13.2 ) we compute the first factor of the integrand as

  -- -------- -- ---------
     @xmath      (13.10)
  -- -------- -- ---------

For the present calculation, the functional derivative of the volume,
given by Eq. ( 13.4 ), is better expressed as

  -- -------- -- ---------
     @xmath      (13.11)
  -- -------- -- ---------

where @xmath is the inverse of @xmath (i.e. @xmath ). Then the
contraction of ( 13.11 ) with the second term of Eq. ( 13.10 )
immediately gives @xmath . Inserting ( 13.11 ) and the first term of (
13.10 ) into Eq. ( 13.9 ), and performing an integration by parts, we
obtain

  -- -------- -- ---------
     @xmath      (13.12)
  -- -------- -- ---------

On the other hand, contracting Eq. ( 1.52 ) with @xmath , we see that
@xmath , and so ( 13.12 ) is equal to @xmath . All in all, we therefore
have

  -- -------- -- ---------
     @xmath      (13.13)
  -- -------- -- ---------

which is the relation we were looking to prove. Using it, we finally get
to express the Lorentzian part of the constraint in the form

  -- -------- -- ---------
     @xmath      (13.14)
  -- -------- -- ---------

which carries no essential obstruction against promoting it into a
well-defined operator (though from a practical point of view one might
complain that the form of Eq. ( 13.14 ) is perhaps more complicated than
one would have hoped.)

### 13.2 Regularization and quantization

In order to express the Ashtekar connection and its curvature in Eqs. (
13.5 ) and ( 13.14 ) in terms of holonomies, we (following Thiemann)
consider a tetrahedral triangulation of the spatial manifold @xmath ,
though more general partitions of @xmath could certainly be taken as an
alternative starting point for regularization. For each tetrahedron
@xmath of the triangulation, we pick one of its vertices @xmath , denote
by @xmath @xmath the three edges emerging from @xmath , and let @xmath
denote the triangular loop spanned by the two edges @xmath and @xmath .
Assuming for simplicity that each @xmath has coordinate length @xmath ,
the holonomies associated to the edge @xmath and the loop @xmath can be
expanded as

  -- -------- -------- -- ---------
     @xmath   @xmath      (13.15)
     @xmath   @xmath      (13.16)
  -- -------- -------- -- ---------

Using these, it is straightforward to check that the expression

  -- -------- -- ---------
     @xmath      (13.17)
  -- -------- -- ---------

approximates the Euclidean part ( 13.5 ), in the sense that the sum on
the right-hand side converges to ( 13.5 ) in the limit of an arbitrarily
fine triangulation, independently of the details of the triangulation.
The factor of @xmath arises from the normalization of the @xmath
generators, @xmath , and from the fact that @xmath is 6 times the
coordinate volume of the tetrahedron @xmath . At the classical level,
the factor @xmath plays no role in the convergence of ( 13.17 ) to the
continuum expression ( 13.5 ); it is inserted to ensure that the
operator arising from Eq. ( 13.17 ) will be gauge invariant.

Similarly, the Lorentzian part ( 13.14 ) is approximated by

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (13.18)
  -- -------- -------- -- ---------

where the numerical coefficient is now adjusted to cancel the factor of
@xmath in the relation @xmath . We point out that the regularized
expressions ( 13.17 ) and ( 13.18 ) again have no explicit dependence on
the regularization parameter @xmath .

Before Eqs. ( 13.17 ) and ( 13.18 ) can be promoted into operators, the
triangulation must be adjusted to the graph of the spin network state on
which the operators are to act. By ordering the volume operator (or at
least one factor of the volume operator, in the case of the Lorentzian
part) to the right, the resulting operators can be made to act only on
the nodes of the spin network. It is therefore sufficient to specify the
details of the triangulation only in a neighborhood of each node.

Fixing the node as the point @xmath , for each triple of edges @xmath at
the node one considers a tetrahedron spanned by segments @xmath of the
edges, and constructs seven additional ”virtual” tetrahedra (as
described in great detail in [ 117 ] ) so that the eight tetrahedra
together triangulate a neighborhood of the node. With this choice of
triangulation, the action of the regularized Euclidean constraint on a
state based on a graph @xmath is given by

  -- -------- -- ---------
     @xmath      (13.19)
  -- -------- -- ---------

where the factor of 8 appears because one must sum over the 8 tetrahedra
to cover an entire neighborhood of the node. Furthermore, @xmath , with
@xmath the valence of the node @xmath , is the number of different
triples of edges at @xmath , and the division by @xmath is to compensate
for the fact that an independent triangulation is constructed for each
triple of edges. In the same way, the regularized Lorentzian part acts
as

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (13.20)
  -- -------- -------- -- ---------

where the notation @xmath indicates that the triangulation used to
define the second action of the Euclidean operator should be adapted to
the graph created by the first action of @xmath on the state @xmath .

In Eqs. ( 13.19 ) and ( 13.20 ), we have regularized the connection and
the curvature using holonomies in the fundamental representation, but
there is of course room to generalize the construction in various ways.
For example, one could use holonomies in a higher irreducible
representation (first considered in [ 75 ] ) or linear combinations of
holonomies in different representations [ 95 ] , or even allow the
representation of the holonomy @xmath to depend on the spins carried by
the edges @xmath and @xmath on which the loop @xmath is attached [ 129 ,
133 ] .

As they stand, the operators defined by Eqs. ( 13.19 ) and ( 13.20 )
still depend on the triangulation @xmath . To complete the construction
of a uniquely defined constraint operator, one would therefore like to
remove the regulator by taking the limit @xmath . However, if one
attempts to take this limit in some way in the kinematical Hilbert
space, one immediately encounters the problem already familiar from Eqs.
( 4.3 ) and ( 7.1 ). For example, no meaningful limit of @xmath (or
@xmath ) can be defined by considering limits of matrix elements of the
operator in the spin network basis, since a matrix element of the form
@xmath will be different from zero for at most one value of @xmath .

At a first sight the situation seems to be more promising in the
diffeomorphism invariant Hilbert space, as the triangulations used to
obtain Eqs. ( 13.19 ) and ( 13.20 ) can be constructed in such a way
that the loops @xmath and @xmath , associated to triangulations
characterized by two different values @xmath and @xmath of the
regularization parameter, are diffeomorphically equivalent with each
other. In other words, there always exists a diffeomorphism @xmath such
that @xmath . (See again [ 117 ] for the details on how this can be
achieved.) Then, if @xmath is any diffeomorphism invariant state, the
number @xmath is in fact independent of @xmath , so if understood in
this sense, the limit @xmath becomes completely trivial ²⁴ ²⁴ 24 To be
more precise, the limit @xmath is defined according to the following
criterion [ 122 ] : For a given @xmath , there must exist an @xmath such
that

whenever @xmath . If this requirement is satisfied, the limit operator
can be defined simply as the operator @xmath for an arbitrary but fixed
value of @xmath . This way of defining the limit @xmath is often
referred to as the uniform Rovelli–Smolin topology. . However, due to
the presence of the lapse function, @xmath itself cannot be consistently
defined as an operator on @xmath – at most one can define a
non-diffeomorphism invariant operator @xmath .

Finally, a point of view advocated by Thiemann in [ 122 ] , which
completely bypasses the question of taking the limit @xmath , is to
consider @xmath as a fixed parameter (by choosing once and for all a
triangulation for each possible graph), and view the operator defined by
Eqs. ( 13.19 ) and ( 13.20 ) as a kind of an effective operator. When
evaluated on semiclassical states, the effective operator is supposed to
reproduce the regularized classical expressions ( 13.17 ) and ( 13.18 ),
rather than the continuum expressions ( 13.5 ) and ( 13.14 ). In this
approach the continuum limit would correspond to evaluating the operator
on states based on finer and finer graphs, as opposed to taking the
regularization parameter to zero on a single, fixed graph.

### 13.3 Action of the operator

The operator defined by Eqs. ( 13.19 ) and ( 13.20 ) acts by creating
new nodes and edges around the previously existing nodes of a spin
network state. As an illustration, the action of the Euclidean part (
13.19 ) on a three-valent node has the schematic form

  -- -------- -- ---------
     @xmath      (13.21)
  -- -------- -- ---------

On the segments where the loop inserted by the operator overlaps an edge
of the spin network, the holonomies should be coupled using the
Clebsch–Gordan series ( 4.2 ). For example, if the loop carries spin
@xmath , then the action of the loop on an edge of spin @xmath produces
two terms, in which the edge has spin @xmath and @xmath . Therefore each
drawing on the right-hand side of Eq. ( 13.21 ) actually represents
multiple terms (four, in the case where the loop has spin @xmath ),
corresponding to the different combinations of spins that result from
coupling the overlapping holonomies.

The Lorentzian part ( 13.20 ) contains two factors of the Euclidean
part, and hence acts by creating two loops, producing terms of the form

  -- -------- -- ---------
     @xmath      (13.22)
  -- -------- -- ---------

Since the tetrahedra used to regularize the second factor of @xmath in
Eq. ( 13.20 ) are contained inside the tetrahedra of the first factor of
@xmath , the second action of the Euclidean operator is responsible for
creating the ”smaller” loops in Eq. ( 13.22 ). Both the Euclidean and
Lorentzian operators naturally also act on the intertwiner at the node.
In the case of a three-valent node, the change in intertwiner is of
course rather trivial, but if the valence of the node is higher, the
operators generally act in the intertwiner space in a non-trivial way.

The nodes created by the action of the Hamiltonian constraint are
three-valent and planar. If the constraint operator is acting on a state
which contains such nodes, the operator will not act on them, provided
that the internally regularized Ashtekar–Lewandowski volume operator is
used in Eqs. ( 13.19 ) and ( 13.20 ). This is because both the Euclidean
and the Lorentzian part have a volume operator ordered to the right, and
any planar node is annihilated by the Ashtekar--Lewandowski volume
operator ²⁵ ²⁵ 25 The action of the volume operator does not give zero
just because the node is three-valent, since there are terms in Eqs. (
13.19 ) and ( 13.20 ) in which the volume acts on a non-gauge invariant
node, and the action of the volume on a non-gauge invariant three-valent
node is equivalent to that on a four-valent gauge invariant node. Using
the externally regularized volume operator (which is insensitive to the
differential structure of the node) in Eqs. ( 13.19 ) and ( 13.20 )
would therefore give a constraint operator which does act on the nodes
that it creates. . It follows that if one repeatedly acts with the
Hamiltonian constraint on a given state, each action of the operator
will only act on the nodes present in the original state; the nodes
created by the successive actions of the constraint will remain
untouched. This property turns out to play a crucial role in ensuring
that the commutator of the Hamiltonian constraint with itself is free of
anomalies.

The matrix elements of the Hamiltonian constraint in the spin network
basis, represented by the numbers @xmath and @xmath in Eqs. ( 13.21 )
and ( 13.22 ), can be computed explicitly for nodes of sufficiently low
valence, up to the fact that the matrix elements of the volume operator
are not available in explicit form. The first such computations were
done in [ 51 ] and [ 75 ] , where the action of the Euclidean part on a
three-valent node was derived using a somewhat complicated diagrammatic
formalism. The more powerful graphical methods presented in the Appendix
were utilized to calculate the matrix elements of the Euclidean part for
three- and four-valent nodes in [ 9 ] , and those of the entire
constraint, including the Lorentzian part, for three-valent nodes in [ 7
] .

### 13.4 The constraint algebra

An essential consistency requirement in the quantization of constrained
theories concerns the commutators between the constraint operators in
the quantum theory. Ideally one would like the commutators among the
constraint operators to reproduce the algebra of the corresponding
Poisson brackets between the classical constraints, but at the least the
commutator between any two constraints should again be proportional to
one of the constraints (or possibly a linear combination of them). If
this were not the case, one should still require for consistency that
physical states be annihilated by the commutator. In effect, the
commutator would generate a new, independent constraint, and the space
of solutions could not be consistently determined merely by solving the
original set of constraints. Then one would naturally suspect that the
set of physical states obtained in this way might be too small.

The commutator algebra of Thiemann’s Hamiltonian constraint was
investigated in [ 117 ] and [ 118 ] ; here we will summarize the results
following the discussion in [ 122 ] . Since the infinitesimal generator
of diffeomorphisms is not available, the commutator between a
diffeomorphism constraint and a Hamiltonian constraint should be tested
in its finite, exponentiated form as

  -- -------- -- ---------
     @xmath      (13.23)
  -- -------- -- ---------

However, a straightforward calculation (which can be done on general
grounds, without having to descend down to the detailed action of the
Hamiltonian constraint in the spin network basis) shows that instead of
the expected relation ( 13.23 ), one has

  -- -------- -- ---------
     @xmath      (13.24)
  -- -------- -- ---------

The diffeomorphism operators on the right-hand side compensate for the
fact that action of the operator @xmath on the left-hand side is defined
through a triangulation adapted to the graph @xmath , and in general
this triangulation is not necessarily mapped under @xmath into the
triangulation by which @xmath is supposed to act on a state based on
@xmath (though it certainly can be mapped into the correct triangulation
by applying a further diffeomorphism).

Thus the conclusion is that the relation ( 13.23 ) is not precisely
satisfied – however, the discrepancy is harmless since it is given
solely in terms of diffeomorphism operators, and hence is not visible at
the diffeomorphism invariant level. In particular, Eq. ( 13.23 ) is a
valid equality between operators in the sense of the uniform
Rovelli–Smolin topology of footnote 24 . (Figuratively speaking, we have
here an example of the case where the commutator between two constraints
is again a constraint, but not the exact constraint one would expect
based on the classical algebra of the constraints.)

As to the commutator between two Hamiltonian constraints, a direct
calculation – a central ingredient of which is the property that the
Hamiltonian constraint does not act on the nodes created by a previous
action of the constraint – produces a result of the form

  -- -------- -- ---------
     @xmath      (13.25)
  -- -------- -- ---------

where @xmath denotes the part of the constraint that acts on the node
@xmath , i.e. the coefficient of @xmath in Eqs. ( 13.19 ) and ( 13.20 ).
Since the right-hand side involves the difference between two
diffeomorphism operators, the commutator is identically zero at the
diffeomorphism invariant level (according to the criterion of footnote
24 ). Therefore the algebra of commutators is consistent, provided that
the Ashtekar–Lewandowski volume operator, rather than the Rovelli–Smolin
operator, is used to construct the Hamiltonian constraint.

The appearance of a difference between diffeomorphisms in Eq. ( 13.25 )
further suggests that the right-hand side of ( 13.25 ) might have
something to do with the right-hand side of the classical Poisson
bracket ( 1.34c ). In [ 118 ] it was indeed shown how the right-hand
side of ( 13.25 ) can be interpreted as a quantization of the function
@xmath .

### 13.5 Symmetrizing the constraint operator

The operator considered in this chapter is evidently not symmetric,
since it acts by creating loops, while a symmetric operator should be a
sum (or some other symmetric combination) of an operator that creates
loops and one that removes them. However, as far as the Hamiltonian
constraint is concerned, it is strictly speaking not necessary for the
operator to be symmetric. Even though real-valued classical observables
should normally be promoted to self-adjoint operators upon quantization,
the Hamiltonian constraint is not really an ”observable”, at least in
the literal sense of being a quantity whose value can be observed by
making measurements. In the quantum theory, the Hamiltonian constraint
only plays a role in determining the physical states and physical
observables, and therefore the mathematical consistency of the theory is
not necessarily endangered even if the constraint operator is not
symmetric. From this perspective, a sufficient requirement for a
consistent constraint operator is that the eigenvalue zero be contained
in its spectrum.

It has even been argued in the literature that in the case of
self-adjoint constraint operators, there is a risk of the commutator
algebra of the constraints becoming anomalous, and therefore it is
better for constraint operators to not be symmetric [ 78 , 122 ] .
However, in the author’s opinion it is not clear how seriously such
arguments should be taken in the context of loop quantum gravity. The
usual argument calling for the constraint operators to be non-symmetric
(see e.g. Chapter 30 of [ 122 ] ) assumes that the classical Poisson
brackets @xmath (where the Greek indices enumerate the constraints, and
@xmath are the structure functions of the constraint algebra) are
promoted in the quantum theory into the formally identical commutation
relations @xmath , or if the operators involved in the equation are
self-adjoint,

  -- -------- -- ---------
     @xmath      (13.26)
  -- -------- -- ---------

Here a possible anomaly may clearly arise from the second term on the
right. However, as we have seen, in loop quantum gravity the commutation
relations between the constraints are not exactly identical to the
classical Poisson brackets, especially for relations involving the
diffeomorphism constraint. Therefore it would seem better to try to
resolve the question of anomalies separately in each case, regardless of
whether the constraint operators are symmetric or not, rather than
categorically refuse to consider symmetric constraint operators merely
on grounds of the above formal argument.

On the other hand, the Hamiltonian constraint is relevant not only as a
constraint operator in the fully constrained theory, but also as a
building block for constructing the physical Hamiltonian operator in
deparametrized models. In the deparametrized context it is of course
vitally important for the physical Hamiltonian to be symmetric (and
eventually self-adjoint) in order to ensure that the time evolution
generated by it is unitary. Hence the viability of using Thiemann’s
Hamiltonian as the physical Hamiltonian in a deparametrized model
depends on whether it can be symmetrized. This, in turn, boils down to
the question of whether the adjoint operator of Thiemann’s Hamiltonian
exists as a densely defined operator. If the adjoint operator @xmath
were available, it would act by removing loops, and a symmetric
Hamiltonian could be constructed as @xmath , or @xmath , or any other
symmetric combination of @xmath and its adjoint.

It turns out that any operator which acts by adding loops of fixed spin
in the way indicated by Eqs. ( 13.21 ) and ( 13.22 ) cannot possess a
densely defined adjoint operator, neither on the kinematical Hilbert
space nor at the diffeomorphism invariant level. The problematic
situation is encountered whenever the operator acts on an edge whose
spin matches the spin of the loops created by the operator. When the
holonomies on the segment where the loop overlaps the edge are coupled
using the Clebsch–Gordan series, the total spin zero will appear among
the spins resulting from the coupling. In the corresponding spin network
state, a segment of the edge will effectively have been erased. For
example, when the loop and the edge both carry spin @xmath , the action
of the Euclidean operator has the structure

  -- -------- -- ---------
     @xmath      (13.27)
  -- -------- -- ---------

In the first term on the right-hand side, all information about the
differential relations between the erased edge and the remaining edges
at the node has been lost. The same term also arises from the action of
the Euclidean operator on different states, which differ from each other
only in the way in which the edge whose segment is erased meets the
other edges at the node:

  -- -------- -------- -- ---------
     @xmath   @xmath      (13.28)
     @xmath   @xmath      (13.29)
                          
  -- -------- -------- -- ---------

It follows that the action of the adjoint operator @xmath on the state
in which the edge has been erased is ill-defined, because – so to say –
the adjoint operator ”does not know how it should put back the erased
edge”. If one tries to act with the adjoint operator on this state, one
would obtain an infinite, unnormalizable linear combination of states,
in which the missing edge has been re-inserted in all possible ways:

  -- -------- -- ---------
     @xmath      (13.30)
  -- -------- -- ---------

In the kinematical Hilbert space, there are certainly uncountably
infinite different ways to put back the erased edge. Even in the
diffeomorphism invariant Hilbert space, the number of inequivalent ways
in which the missing edge can be reintroduced is at least countably
infinite, corresponding to the different orders of tangentiality (see
section 14.2 ) between the erased edge and the other edges at the node.
If the valence of the node is sufficiently high, the number of terms on
the right-hand side of Eq. ( 13.30 ) could be uncountably infinite even
at the diffeomorphism invariant level.

These considerations show that the adjoint of Thiemann’s Hamiltonian is
not available as a densely defined operator, since its action is
ill-defined on a large class of spin network states. For this reason, it
is not possible to obtain a symmetric operator from Thiemann’s
construction, and so the operator is not suitable to be used in
constructing physical Hamiltonians for deparametrized models of loop
quantum gravity. For deparametrized models, a loop assignment different
from the one illustrated by Eqs. ( 13.21 ) and ( 13.22 ) is needed in
order to ensure that a satisfactory adjoint operator exists and a
symmetric physical Hamiltonian can be constructed. (On the other hand,
we emphasize that Thiemann’s operator is of course fully adequate as the
Hamiltonian constraint operator, which is the purpose for which it was
originally designed.)

## 14 Physical Hamiltonian for loop quantum gravity coupled to a free
scalar field

In this chapter we will present an explicit construction of a physical
Hamiltonian operator for loop quantum gravity deparametrized with
respect to the free Klein–Gordon field. In comparison to Hamiltonians
proposed in the literature so far, our construction is characterized by
two important, essentially new features:

-   A new regularization is used to quantize the Euclidean part of the
    Hamiltonian. This results in an operator which can be symmetrized,
    and which can therefore be a mathematically consistent candidate for
    the generator of physical time evolution.

-   The usual Lorentzian part of the Hamiltonian is traded for the
    scalar curvature of the spatial surface by using the expression (
    1.68 ) for the Hamiltonian constraint. This leads to a considerable
    practical simplification in the properties of the resulting quantum
    operator.

The work on which this chapter is based was carried out by the author in
collaboration with Emanuele Alesci, Mehdi Assanioussi and Jerzy
Lewandowski, and has been published in the article [ A ] . It can be
regarded as a precise and concrete realization of the model first
proposed by Rovelli and Smolin in [ 108 ] and completed on a partially
formal level in [ 69 ] .

The material in this chapter is organized as follows. The general
strategy which we will adopt to define the physical Hamiltonian operator
is outlined in section 14.1 . Before descending down to the
technicalities involved in constructing the operator, we will explain
the key ideas essential to our construction in sections 14.2 and 14.3 .
The precise details of regularizing the classical expression for the
physical Hamiltonian and constructing the corresponding quantum operator
are then given in sections 14.4 and 14.5 . The outcome of the
construction is summarized in the concluding section 14.6 .

### 14.1 The general strategy

In the classical theory of gravity coupled to a free scalar field,
evolution of diffeomorphism invariant observables with respect to the
relational time provided by the scalar field is generated by the
physical Hamiltonian

  -- -------- -- --------
     @xmath      (14.1)
  -- -------- -- --------

Accordingly, the dynamics of the quantum theory will be governed by an
operator obtained by quantizing the function ( 14.1 ). In principle, the
Hamiltonian ( 14.1 ) could be quantized (roughly speaking) by promoting
the factor @xmath into the volume operator, and using an appropriate
modification of Thiemann’s construction to quantize the factor @xmath .
However, an essential ingredient of our construction is to manipulate
the classical expression ( 14.1 ) in a beneficial way before proceeding
to quantize it. When Eq. ( 1.68 ), instead of the more commonly used
expression ( 1.67 ) for the gravitational Hamiltonian constraint, is
inserted into Eq. ( 14.1 ), the factor inside the square root takes the
form

  -- -------- -- --------
     @xmath      (14.2)
  -- -------- -- --------

We see that the problematic factor of @xmath has been cancelled in the
first term, and in fact a similar cancellation occurs in the second term
after it has been regularized by expressing the Ricci scalar in terms of
the elementary variables of loop quantum gravity.

A few words about terminology: We will keep referring to the first term
on the right-hand side of Eq. ( 14.2 ) as the Euclidean term, or
Euclidean part, since up to a simple multiplicative factor it is
identical to the Euclidean part of the Hamiltonian constraint. The
second term in Eq. ( 14.2 ) will be referred to as the curvature term,
or curvature part, in order to emphasize that it is genuinely different
from the Lorentzian part of the usual expression ( 1.67 ). This
difference is reflected accordingly in the properties of the
corresponding quantum operators, as the curvature term in Eq. ( 14.2 )
can be quantized in such a way that the structure of the resulting
operator is extraordinarily simple in comparison to the Lorentzian part
of Thiemann’s Hamiltonian. Replacing the Lorentzian term with the
curvature term is therefore far from being a mere academic exercise –
rather, it offers a very concrete technical advantage, as measured by
the degree of complexity of the resulting quantum operator.

The function defined by Eqs. ( 14.1 ) and ( 14.2 ) has the form

  -- -------- -- --------
     @xmath      (14.3)
  -- -------- -- --------

where @xmath and @xmath are functions of the elementary fields @xmath
and @xmath . In order to construct the physical Hamiltonian operator, we
must therefore consider how to regularize and quantize an expression of
this type. By making use of a cellular decomposition of the spatial
manifold @xmath , whose cells are denoted by @xmath , the integral (
14.3 ) can be approximated as

  -- -- -- --------
           (14.4)
  -- -- -- --------

This expression suggests how to define an operator corresponding to (
14.3 ), provided that the integrals @xmath and @xmath can be given a
meaning as well-defined operators.

Note, however, that for the square root in Eq. ( 14.3 ) to be
well-defined, it is sufficient that the sum @xmath is positive definite.
The functions @xmath and @xmath do not necessarily have to be separately
positive-definite, even though this might seem to be suggested by the
right-hand side of Eq. ( 14.4 ). Therefore Eq. ( 14.4 ) should be
considered as a partially formal expression, its only purpose being to
schematically indicate the way in which we derive a quantum operator
starting from the classical physical Hamiltonian given by Eqs. ( 14.1 )
and ( 14.2 ).

If the operators @xmath and @xmath are themselves available in the form
²⁶ ²⁶ 26 Even though we have not used such notation so far in this work,
most of the operators one commonly encounters in loop quantum gravity
can nevertheless be expressed in this form. To give a concrete example,
the volume operator associated to a region @xmath can be written as

@xmath

which is formally identical with the classical volume of the region, and
where the ”volume element operator” is

@xmath

with @xmath given by Eq. ( 8.19 ). It is straightforward to check that
when the operator defined above acts on a state based on a given graph,
the more conventional expression

@xmath

for the volume operator is recovered.

  -- -------- -------- -- --------
     @xmath   @xmath      (14.5)
     @xmath   @xmath      (14.6)
  -- -------- -------- -- --------

where @xmath and @xmath act only on the nodes of a spin network state,
then the function ( 14.3 ) can be quantized immediately by inserting
Eqs. ( 14.5 ) and ( 14.6 ) into the right-hand side of Eq. ( 14.4 ).
When deriving the action of the operator on a spin network state, the
cellular decomposition used in Eq. ( 14.4 ) has to be refined only so
far that each cell @xmath contains at most a single node of the spin
network. Any further refinement will not make a difference to the action
of the operator, which is given by

  -- -------- -- --------
     @xmath      (14.7)
  -- -------- -- --------

### 14.2 Special loops

The reason why Thiemann’s Hamiltonian is not a suitable candidate for
the physical Hamiltonian in the deparametrized context is that the
adjoint of the Hamiltonian is not a densely defined operator, making it
impossible to symmetrize Thiemann’s operator and to eventually obtain a
self-adjoint physical Hamiltonian. This is the main obstacle which must
be overcome in our construction of the physical Hamiltonian.

The problems with the adjoint of Thiemann’s Hamiltonian are ultimately
caused by the fact that the loops created by the operator overlap
partially with the edges to which they are attached. In order to avoid
such problems in our construction, we must therefore adopt a loop
assignment in which the loops do not overlap with any edges. However, it
then becomes a non-trivial question whether one can tell apart the loop
from other edges or loops at the node – in particular, whether loops
attached to different pairs of edges at the same node, or successive
loops attached to the same pair of edges by repeated actions of the
Hamiltonian, can be distinguished from each other.

It turns out that all these questions can be answered in the affirmative
by making use of a diffeomorphism invariant notion of order of
tangentiality between two edges sharing a node. This is defined as
follows. Suppose @xmath and @xmath are two (analytic) edges incident at
a node @xmath . Then one can choose coordinates in a neighborhood of
@xmath such that the edges are parametrized as

  -- -------- -------- -- --------
     @xmath   @xmath      (14.8)
     @xmath   @xmath      (14.9)
  -- -------- -------- -- --------

and the node is at @xmath . If the function @xmath and its first @xmath
derivatives vanish at @xmath , while the @xmath -th derivative does not,
we say that @xmath and @xmath are tangent to each other at order @xmath
at the node @xmath .

When defining the Euclidean part of the Hamiltonian, the order of
tangentiality between the loop created by the operator and the edges to
which it is attached is essentially a free parameter in the
construction. By exploiting this freedom, we can define the operator in
such a way that the loop attached to a given pair of edges is perfectly
distinguishable from any other loop which was present at the node before
the new loop was attached. In short, this is done by specifying a
sufficiently high order of tangentiality between a loop @xmath and the
two edges @xmath and @xmath to which it is attached. For example, denote
by @xmath the highest order of tangentiality between an edge @xmath and
the other edges at the node before the new loop was introduced. If the
loop @xmath is tangent to the edges @xmath and @xmath (at least) at
orders @xmath and @xmath respectively, then the loop is clearly
distinguished by the fact that all other edges at the node are tangent
to @xmath and @xmath at a lower order than the loop.

Following the terminology introduced in [ A ] , we refer to loops of the
type described above as special loops, and we will use them to define
the Euclidean part of the physical Hamiltonian. This element of the
construction plays a key role in ensuring that the operator possesses a
satisfactory adjoint. When the Euclidean operator creates loops
according to the special loop assignment, the case never arises where
the operator would remove some structures from a node, causing the
adjoint operator to re-introduce these structures in an infinite number
of inequivalent ways. In fact, by making a suitable choice of the order
of tangentiality between the special loop and the edges to which it is
attached, one can guarantee that in any node containing an arbitrary
number of special loops, there will always be only a single, uniquely
determined loop, which will be removed by the action of the adjoint
operator.

### 14.3 The curvature operator

Our quantization of the curvature term in Eq. ( 14.2 ) is based on the
ideas of [ 1 ] , where a loop quantum gravity operator corresponding to
the integrated scalar curvature of the spatial manifold,

  -- -------- -- ---------
     @xmath      (14.10)
  -- -------- -- ---------

was constructed. The main point behind the construction is that the
integral ( 14.10 ) happens to be the action integral for Euclidean
general relativity in three dimensions. Using the well-known framework
of Regge calculus [ 102 ] , the action integral (for arbitrary spacetime
dimension @xmath ) can be related to the geometric quantities of a
piecewise flat simplicial decomposition of the spacetime manifold, in
which curvature is concentrated on the ”hinges” of the decomposition,
i.e. the @xmath -dimensional ”sub-simplices” at which several @xmath
-dimensional simplices meet.

In the three-dimensional case, the precise relation is

  -- -------- -- ---------
     @xmath      (14.11)
  -- -------- -- ---------

where the integral on the left-hand side is taken over the triangulated,
piecewise flat manifold @xmath , which is regarded as an approximation
of the smooth spatial manifold @xmath . The sum on the right-hand side
runs over the hinges, or the edges of the tetrahedra of the
triangulation. Within the sum, @xmath is the length of the hinge @xmath
, and

  -- -------- -- ---------
     @xmath      (14.12)
  -- -------- -- ---------

is the deficit angle associated to the hinge, with @xmath the dihedral
angle of the tetrahedron @xmath at @xmath . In Regge’s original
formulation, only simplicial decompositions of the spacetime manifold
were considered; however, as argued in [ 1 ] , Eq. ( 14.11 ) is a valid
approximation to the continuum integral ( 14.10 ) also for a certain
class of arbitrary piecewise flat cellular decompositions of @xmath .

The relevance of Regge’s formula to loop quantum gravity arises from the
fact that, as we have seen in Chapter 8 , well-defined operators
describing angles and lengths are available in loop quantum gravity, and
therefore Eq. ( 14.11 ) indicates a very straightforward way in which
the integral ( 14.10 ) can be promoted into an operator in the theory.
To this end, it is convenient to split the sum in Eq. ( 14.11 ) as

  -- -------- -- ---------
     @xmath      (14.13)
  -- -------- -- ---------

where the first sum runs over the cells of a suitable cellular
decomposition of @xmath , the inner sum runs over the hinges of the cell
@xmath , and @xmath denotes the number of cells sharing the hinge @xmath
. Moreover, the dihedral angle is given by

  -- -------- -- ---------
     @xmath      (14.14)
  -- -------- -- ---------

where @xmath is the angle between the two faces of @xmath which
intersect each other at @xmath .

With these preparations, the sum ( 14.13 ) has been expressed entirely
in terms of quantities which are directly analogous to well-known
operators already available in loop quantum gravity. Therefore Eq. (
14.11 ) could be naively quantized simply by placing hats over the
quantities @xmath and @xmath , which clearly correspond to the length
and angle operators described in Chapter 8 . The sums @xmath and @xmath
in Eq. ( 14.13 ) are expected to be replaced with a sum over the nodes
of a spin network state, and one over the pairs of edges at each node,
since the geometric picture associated with a spin network state
suggests that a pair of edges emerging from a node defines a hinge
through the intersection of the elementary surfaces dual to the two
edges.

The result of the naive quantization is confirmed, up to a certain
numerical factor at each node, by the detailed construction of [ 1 ] ,
in which the curvature operator is defined through a careful
regularization of the relevant classical expressions. The resulting
operator acts on a state based on a graph @xmath as

  -- -------- -- ---------
     @xmath      (14.15)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (14.16)
  -- -------- -- ---------

The sum in the above equation runs over all pairs of edges @xmath at the
node, @xmath is the length operator of section 8.5 , and the dihedral
angle operator is

  -- -------- -- ---------
     @xmath      (14.17)
  -- -------- -- ---------

with @xmath the angle operator of section 8.4 . Furthermore, @xmath is a
coefficient which results from an averaging over the cellular structures
involved in the regularization, and whose value depends only on the
valence of the node @xmath . Essentially, @xmath arises to compensate
for the fact that some pairs of edges in the sum of Eq. ( 14.16 )
generally do not correspond to any hinge in the sum ( 14.13 ) (see [ 1 ]
for further details).

In Eq. ( 14.16 ) a straightforward symmetric ordering has been chosen
between the non-commuting operators @xmath and @xmath , following the
choice originally made in [ 1 ] . However, other symmetrizations of this
term could certainly be considered. An alternative symmetrization can be
obtained by recalling from Eq. ( 8.34 ) that the length operator itself
is a product of several factors. By ordering these factors differently
relative to the angle operator, the term @xmath can be symmetrized as

  -- -------- -- ---------
     @xmath      (14.18)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (14.19)
  -- -------- -- ---------

and the operators @xmath and @xmath commute ²⁷ ²⁷ 27 This can be seen
for example from Eqs. ( 8.30 ) and ( 8.38 ), which show that the two
operators share the same set of eigenstates. , so there is no ambiguity
in their relative ordering. Under such a symmetrization, the action of
the curvature operator on a node of a spin network state takes the form

  -- -------- -- ---------
     @xmath      (14.20)
  -- -------- -- ---------

In the author’s opinion, Eq. ( 14.20 ) seems to provide a somewhat
simpler and perhaps more natural definition of the curvature operator.
In particular, this definition guarantees that nodes carrying zero
volume are annihilated by the curvature operator, which is a very
reasonable property in light of the fact that the classical expression (
14.10 ), whose quantization the curvature operator is supposed to be,
certainly vanishes when the integral is taken over a region of zero
volume.

### 14.4 Regularization: Euclidean part

To construct the Euclidean part of the physical Hamiltonian according to
the strategy outlined in section 14.1 and summarized by Eq. ( 14.4 ), we
must consider how to quantize the integral

  -- -------- -- ---------
     @xmath      (14.21)
  -- -------- -- ---------

As always, we should start by expressing the integral in terms of the
elementary variables of loop quantum gravity. To illustrate the way in
which this is done, let us introduce a cubic partition of the spatial
manifold @xmath , in which the edges of the cubes have coordinate length
@xmath . Approximating the integral ( 14.21 ) by the Riemann sum
associated to the partition, and choosing a point @xmath inside each
cube @xmath , we may write

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (14.22)
  -- -------- -------- -- ---------

where on the second line the factors of @xmath have been distributed in
a suggestive way, showing how the triads and the curvature will be
transformed into fluxes and holonomies.

For the factors involving the triads, we will use the parallel
transported flux variable

  -- -------- -- ---------
     @xmath      (14.23)
  -- -------- -- ---------

in which @xmath is either one of the two sides of @xmath on which the
coordinate @xmath Points on the surface are transported to the point
@xmath along a fixed system of paths (for example, along straight lines
in the background coordinates). The expansion of ( 14.23 ) in powers of
@xmath reads

  -- -------- -- ---------
     @xmath      (14.24)
  -- -------- -- ---------

and at leading order in @xmath , @xmath can be evaluated at any point
inside @xmath . Hence the factors @xmath in Eq. ( 14.22 ) can be
regularized simply by replacing them with @xmath .

In order to regularize the factor involving the curvature, let us
specify a set of loops @xmath , one for each surface @xmath , such that
the loop @xmath lies within the corresponding surface @xmath and has
coordinate area @xmath . By Eq. ( 2.10 ), the holonomy around the loop
@xmath is related to the curvature by

  -- -------- -- ---------
     @xmath      (14.25)
  -- -------- -- ---------

where again @xmath can be evaluated at any point inside @xmath . The
factor involving the curvature in Eq. ( 14.22 ) can therefore be
extracted from the holonomy @xmath as

  -- -------- -- ---------
     @xmath      (14.26)
  -- -------- -- ---------

More generally, we may consider regularizing the curvature in terms of a
holonomy carrying an arbitrary spin @xmath . Recalling the normalization
of the @xmath generators in the spin- @xmath representation,

  -- -------- -- ---------
     @xmath      (14.27)
  -- -------- -- ---------

we have

  -- -------- -- ---------
     @xmath      (14.28)
  -- -------- -- ---------

where we introduced the shorthand notation

  -- -------- -- ---------
     @xmath      (14.29)
  -- -------- -- ---------

with @xmath . Using Eq. ( 14.28 ) to replace the factor @xmath in Eq. (
14.22 ), we have managed to express the integral ( 14.21 ) in terms of
holonomies and fluxes as

  -- -------- -- ---------
     @xmath      (14.30)
  -- -------- -- ---------

the sum on the right-hand side converging to the integral in the limit
of an arbitrarily fine partition.

In our article [ A ] , the integral ( 14.21 ) was ultimately regularized
by using a more general partition, in which the spatial manifold @xmath
is decomposed into a family of cells @xmath of coordinate size @xmath .
The boundary of each cell @xmath is subdivided into surfaces @xmath , so
that @xmath . To each cell there is also assigned a family of paths
@xmath , which are labeled by points @xmath , and along which parallel
transports will be defined from the boundary of @xmath to a fixed point
@xmath inside @xmath . We furthermore specify a family of loops @xmath
and a family of coefficients @xmath such that the sum

  -- -------- -- ---------
     @xmath      (14.31)
  -- -------- -- ---------

where the parallel transported flux variables are defined using the
paths @xmath , converges to the integral ( 14.21 ) in the limit where
the coordinate size of the cells is taken to zero.

While each term inside the square root in ( 14.31 ) can be immediately
promoted into an operator on the kinematical Hilbert space @xmath , the
resulting overall operator is highly ambiguous due to the large freedom
available in choosing the structures used to write down the regularized
expression ( 14.31 ). On the other hand, the operator defined by ( 14.31
) carries a dependence on the regularization parameter @xmath , and the
ambiguity involved in the choice of partitions can be significantly
reduced by imposing certain conditions, which guarantee that the dual of
the operator, defined by Eq. ( 7.8 ), converges to a well-defined
operator on the diffeomorphism invariant Hilbert space in the limit
@xmath [ 93 , A ] . (As the size of the loops @xmath depends on @xmath ,
the limit @xmath is certainly not well-defined in the kinematical
Hilbert space.)

Further conditions on the partition can be derived from requiring that
the general structure of the operaror defined by ( 14.31 ) is consistent
with what one would expect on grounds of a naive, formal quantization of
the term @xmath . Applying the quantization rule @xmath , we see that
the action of the formal operator on a cylindrical function has the form

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (14.32)
  -- -------- -------- -- ---------

In general this expression is ill-defined due to the product of delta
functions, but we can nevertheless read off from Eq. ( 14.32 ) the
conditions that must be met in order for the right-hand side to not be
identically zero. If the edges @xmath and @xmath do not intersect each
other, the product of delta functions vanishes for every value of @xmath
. If @xmath and @xmath have a point in common, the factor @xmath will
give zero if the tangent vectors @xmath and @xmath are parallel to each
other at the intersection point. From the formal calculation, we have
therefore collected the following expectations:

-   The action of the operator will receive non-zero contributions only
    from the nodes of a spin network state;

-   The operator acts separately on every pair of edges at the node;

-   The action on a pair of edge is non-zero only if the edges are not
    tangent to each other at the node.

We would also expect that in a proper, regularized quantization, the
factor @xmath will be replaced with a holonomy around a loop lying in
the plane spanned by the vectors @xmath and @xmath at the node.

We are now ready to write down the requirements which we impose on the
structures used in the regularized expression ( 14.31 ). The role of
these requirements is twofold. On one hand, they guarantee that the
resulting operator is diffeomorphism invariant, and that the regulator
can be removed by taking the limit @xmath in the diffeomorphism
invariant Hilbert space; on the other hand, they ensure that the
resulting operator satisfies the expectations formulated above
concerning the general structure of its action.

As is familiar by now, the partition will be adapted to the graph of a
given spin network state. To begin with, we assume that the partition is
sufficiently refined so that each cell @xmath contains at most a single
node of the graph, and each surface @xmath is intersected by at most a
single edge of the graph. If @xmath contains a node, the point @xmath is
taken to coincide with the node, and if @xmath is intersected by an
edge, we assume that the intersection is transversal. The case where
@xmath does not contain a node but contains the segment of an edge is
treated by splitting the edge into two by introducing an ”artificial”
node inside @xmath , thereby transforming it into the case where @xmath
contains a two-valent node.

To each (ordered) pair of non-tangential edges @xmath at a node, we then
assign a loop @xmath . The loop is oriented according to the orientation
of the pair @xmath , i.e. to the pair @xmath there is assigned the loop
@xmath . Since the loop is uniquely specified by the pair @xmath , and
each edge @xmath corresponds to a unique surface @xmath , we denote the
coefficient @xmath more shortly as @xmath . The loops @xmath and the
coefficients @xmath are now required to satisfy the following
conditions:

1.  For a pair of edges @xmath meeting transversally at a node, the
    value of @xmath is non-zero.

2.  For a pair of edges @xmath meeting tangentially at a node, @xmath .

3.  The non-vanishing value of @xmath depends only on the valence of the
    node and is independent of the labels @xmath and @xmath . Hence we
    denote the coefficient by @xmath .

4.  The shape of the loop @xmath depends on @xmath in a diffeomorphism
    covariant manner. In other words, if @xmath and @xmath are the cells
    of two partitions defined by two different values of @xmath , there
    exists a diffeomorphism @xmath which relates the corresponding loops
    to each other: @xmath .

Requirements (i) and (ii) guarantee that the action of the operator is
consistent with the requirements derived from the calculation ( 14.32 ).
Requirement (iii) implies that the action of the operator has the same
form on a pair of edges @xmath at a node @xmath as it does on the
diffeomorphic image @xmath at @xmath , and therefore makes it possible
for the operator to be diffeomorphism invariant. From requirement (iv)
it follows that the operators obtained from partitions defined by
different values of @xmath are diffeomorphically equivalent to each
other, ensuring that the limit @xmath results in a well-defined operator
on @xmath .

Let us then discuss in detail the properties of the loops created by the
action of the operator. First of all, the position of the loop relative
to the graph should be defined in a diffeomorphism invariant way. This
can be accomplished by using a scheme invented by Ashtekar and
Lewandowski [ 16 ] and used by Thiemann in the construction of his
Hamiltonian [ 117 ] . For Thiemann’s operator, it is essential that the
family of edges created by the regularized operators characterized by
different values of @xmath lie in a surface which does not intersect any
other edges of the graph, and is defined in a suitably
diffeomorphism-invariant manner. This requirement ensures that the edge
can be moved arbitrarily close to the node by a diffeomorphism without
it intersecting any other edges along the way. In the case at hand, we
make use of the surface defined in this way, and require that the loops
@xmath , corresponding to different values of @xmath , all lie within
this surface. We refer to [ 117 ] for the details of the construction.

The loop created when the operator acts on the pair of edges @xmath –
denoted from now on by @xmath – is attached to @xmath and @xmath
according to the ”special loops” prescription of section 14.2 . That is,
the loop does not overlap with the edges @xmath and @xmath , but is
tangent to them at the node at a sufficiently high order. As explained
in section 14.2 , this prescription ensures that the edges belonging to
the loop can be distinguished from any other edges that might be tangent
to the edges @xmath and @xmath . In particular, consequtive loops
attached to the same pair of edges by successive actions of the
Hamiltonian will be perfectly distinguishable from each other.

In the article [ A ] , the precise orders of tangentiality between the
loops created by the Hamiltonian and the edges to which they are
attached were specified by the following assumption:

  The special loop @xmath is tangent to @xmath and @xmath respectively
  at orders @xmath and @xmath , where @xmath is the highest order of
  tangentiality between @xmath and the other edges at the node before
  the loop was introduced (and @xmath is defined similarly for @xmath ).

This choice is clearly sufficient to make the edges of the loop
distinguishable from any other edges tangent to @xmath and @xmath on the
basis of their orders of tangentiality. However, it could be
advantageous to consider alternative prescriptions for the order of
tangentiality between the loop @xmath and the edges @xmath and @xmath .

As motivation for a particular alternative prescription, consider acting
repeatedly with the Hamiltonian on a state based on a fixed initial
graph. The result will be a sum of terms based on graphs in which
special loops are attached to the initial graph in various ways. A
feature of the prescription defined above is that the graph
corresponding to a typical term will generally be generated in many
different ways, from many different sequences of actions of the
operator. For example, if one acts with the Hamiltonian twice, the term
where the first Hamiltonian acted on a pair @xmath and the second one
acted on an independent pair @xmath will be based on the same graph as
the term where the first Hamiltonian acted on the pair @xmath and the
second on the pair @xmath . If no edges in the initial state were
tangent to each other, then in both terms the special loops will be
tangent to the edges @xmath and @xmath at order 1. See Fig. 9 for an
illustration.

When making calculations with the Hamiltonian and having to keep track
of the resulting graphs, one might be inclined to consider the above
feature a nuisance (for instance, because several different graphs may
be produced by the action of the adjoint operator on a state based on a
single, fixed graph). If one wishes to eliminate the nuisance, one can
do so by adopting the following, slightly modified prescription:

  The special loop @xmath is tangent to both @xmath and @xmath at order
  @xmath , where @xmath is the highest order of tangentiality between
  any two edges at the node @xmath before the loop was attached.

Under this prescription, @xmath is tangent to @xmath and @xmath at a
higher order than any other special loop already present in the state is
to its corresponding pair of edges. Therefore the order in which the
special loops were created can always be reconstructed from the orders
of tangentiality; the terms in which special loops were attached to the
same pairs of edges in different sequences will always be based on
different graphs. In this work, we will nevertheless follow the choice
originally made in [ A ] for the order of tangentiality between the loop
@xmath and the edges to which it is attached.

As a result of the regularization described in this section, the
function inside the square root in ( 14.31 ) gives rise to an @xmath
-dependent operator on the kinematical Hilbert space. Its action on a
state based on a graph @xmath is given by

  -- -------- -- ---------
     @xmath      (14.33)
  -- -------- -- ---------

where @xmath is the node of @xmath contained inside the cell @xmath ,
and

  -- -------- -- ---------
     @xmath      (14.34)
  -- -------- -- ---------

In Eq. ( 14.33 ) we have chosen what seems to be the simplest possible
ordering of the operators, the holonomy being ordered to the left so
that it will not be acted on by the angular momentum operators.

As a gauge invariant operator, @xmath is also a well-defined operator on
the gauge invariant Hilbert space. While the limit @xmath cannot be
taken at the kinematical level, the situation is different for the dual
operator @xmath , defined on the diffeomorphism invariant Hilbert space
by

  -- -------- -- ---------
     @xmath      (14.35)
  -- -------- -- ---------

where @xmath and @xmath . Since the loops @xmath are shrank in a
diffeomorphism covariant manner as @xmath , the operator @xmath is in
fact independent of @xmath , so ”taking the limit” @xmath simply amounts
to dropping the label @xmath . We have therefore managed to promote the
function ( 14.21 ) into a well-defined operator on @xmath . It acts on a
state @xmath as

  -- -------- -- ---------
     @xmath      (14.36)
  -- -------- -- ---------

with

  -- -- -- ---------
           (14.37)
  -- -- -- ---------

This completes the first half of the quantization program indicated by
Eq. ( 14.4 ).

### 14.5 Regularization: Curvature part

The second half of the construction of the physical Hamiltonian consists
of quantizing the integral

  -- -------- -- ---------
     @xmath      (14.38)
  -- -------- -- ---------

We introduce again a cellular decomposition of the spatial manifold, in
which the size of the cells is controlled by a parameter @xmath . In
order to approximate the integral ( 14.38 ) by a sum over the cells, we
split the determinant under the square root into two factors of @xmath ,
creating two objects of density weight 1 that can be integrated over a
cell. Then we can write

  -- -------- -- ---------
     @xmath      (14.39)
  -- -------- -- ---------

It seems like the quantization could be immediately completed by
quantizing the two integrals inside the square root as the volume
operator and the curvature operator associated to the cell. However, it
proves to be more advantageous to keep manipulating the regularized
classical expression before quantizing it, since in this way one can
bring about a substantial cancellation of factors, which leads to the
volume operator being eliminated entirely from the resulting
quantization of ( 14.38 ).

We therefore proceed by approximating the integrals inside the square
root in Eq. ( 14.39 ) with suitable functions of flux variables, writing

  -- -------- -- ---------
     @xmath      (14.40)
  -- -------- -- ---------

Here @xmath is a regularization of the integral @xmath in terms of
fluxes, and @xmath is a regularized Regge action for the cell @xmath ,
which was used in the construction of the curvature operator in [ 1 ] .
For concreteness, we choose

  -- -------- -- ---------
     @xmath      (14.41)
  -- -------- -- ---------

where, as in the previous section, the boundary of the cell @xmath is
subdivided into the surfaces @xmath , and parallel transports are
defined from these surfaces to a fixed point @xmath inside @xmath .
Morevoer, @xmath is a coefficient whose value depends on the shape of
the cell @xmath .

The function @xmath in Eq. ( 14.40 ) has the form

  -- -------- -- ---------
     @xmath      (14.42)
  -- -------- -- ---------

where the sum runs over the ”hinges” of the cell @xmath , i.e. the
one-dimensional curves at which the surfaces @xmath meet each other.
Denoting by @xmath and @xmath the two surfaces which meet at the hinge
@xmath , the functions @xmath and @xmath are given by

  -- -------- -- ---------
     @xmath      (14.43)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (14.44)
  -- -------- -- ---------

where @xmath is the number of cells sharing the hinge @xmath , and
@xmath .

Now we see that when @xmath is multiplied by @xmath in Eq. ( 14.40 ),
the @xmath is cancelled against the factors of @xmath in the expression
( 14.43 ). We have

  -- -------- -- ---------
     @xmath      (14.45)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (14.46)
  -- -------- -- ---------

Therefore, as advertized, the factors of @xmath have disappeared from
the regularized classical expression. Consequently, the volume operator
will be absent from the resulting quantum operator, which is a
significant practical advantage.

The function @xmath approximates the unregularized function @xmath in
the sense that

  -- -------- -- ---------
     @xmath      (14.47)
  -- -------- -- ---------

where @xmath and @xmath are the coordinate areas of the surfaces @xmath
and @xmath . Before promoting the expression ( 14.45 ) into an operator,
we wish to derive a requirement on the form of the resulting operator by
studying the straightforward formal quantization of @xmath , as we did
in the construction of the Euclidean part. Making the replacement @xmath
, a calculation similar to Eq. ( 14.32 ) produces the factor

  -- -------- -- ---------
     @xmath      (14.48)
  -- -------- -- ---------

which vanishes if the edges @xmath and @xmath do not intersect each
other, or if they share a common node but are tangent to each other at
the node.

In order to pass this property to the operator obtained from Eq. ( 14.45
), we introduce suitable coefficients in the sum over hinges, writing

  -- -------- -- ---------
     @xmath      (14.49)
  -- -------- -- ---------

As in the previous section, this expression can be promoted into a
well-defined operator only if the cellular decomposition is adapted to
the graph of a given spin network state through the requirements which
we repeat here:

-   Each cell @xmath contains at most a single node of the graph.

-   Each surface @xmath is intersected by at most a single edge of the
    graph.

-   If @xmath contains a node, the point @xmath is taken to coincide
    with the node.

-   If @xmath is intersected by an edge, we assume that the intersection
    is transversal.

-   The case where @xmath does not contain a node but contains the
    segment of an edge is treated by splitting the edge into two by
    introducing an ”artificial” node inside @xmath , thereby
    transforming it into the case where @xmath contains a two-valent
    node.

In Eq. ( 14.49 ), we further demand that the coefficient @xmath vanishes
if the two edges defining the hinge @xmath are tangential to each other
at the node inside @xmath . Then, as in the case of the Euclidean part,
diffeomorphism invariance requires that the non-vanishing value of
@xmath depends only on the valence of the node, and is independent of
@xmath and @xmath . The actual value of @xmath is determined through an
averaging procedure which removes the dependence of the operator on the
cellular structures used to construct it, as explained in detail in [ 1
] .

The way in which the integral ( 14.38 ) will be quantized is now
indicated by Eq. ( 14.49 ), in which the factors on the right-hand side
can be readily promoted into operators, together with the approximation

  -- -------- -- ---------
     @xmath      (14.50)
  -- -------- -- ---------

The resulting operator acts on a state @xmath as

  -- -------- -- ---------
     @xmath      (14.51)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (14.52)
  -- -------- -- ---------

Here the operators appearing on the right-hand side are given by

  -- -------- -- ---------
     @xmath      (14.53)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (14.54)
  -- -------- -- ---------

Since the operators @xmath and @xmath commute with each other, there is
no ordering ambiguity in the operator ( 14.52 ).

The operator defined by Eqs. ( 14.51 ) and ( 14.52 ) is gauge invariant,
and therefore it is well-defined not only as an operator on @xmath , but
also on the gauge-invariant Hilbert space @xmath . Moreover, since the
operator @xmath is composed entirely of the operators @xmath , its
action affects only the intertwiners at the nodes of a spin network
state, and leaves the graph of the state unchanged. Hence the dual
operator @xmath is immediately a well-defined operator on @xmath ; in
contrast to the Euclidean part, no discussion concerning the removal of
the regulator is needed. In a sense, the regulator is removed already at
the level of the kinematical Hilbert space.

### 14.6 Summary of the construction

With both steps of the construction completed, we may now summarize our
findings. By quantizing the classical function defined by Eqs. ( 14.1 )
and ( 14.2 ), we obtained the physical Hamiltonian operator

  -- -------- -- ---------
     @xmath      (14.55)
  -- -------- -- ---------

where @xmath indicates that the operator inside the square root should
be symmetrized. Since the adjoint @xmath exists as a densely defined
operator, there is no obstruction against carrying out the
symmetrization. The obvious choice is

  -- -------- -- ---------
     @xmath      (14.56)
  -- -------- -- ---------

however, one could also consider other symmetrizations, based on
symmetrizing a non-symmetric operator @xmath as @xmath , as opposed to
@xmath . Such symmetrizations would have the advantage that the operator
under the square root in Eq. ( 14.55 ) could be made automatically
positive definite, whereas the positive-definiteness of the operator (
14.56 ) is not clear at this stage.

The operators @xmath and @xmath in Eq. ( 14.56 ) have the form

  -- -------- -- ---------
     @xmath      (14.57)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (14.58)
  -- -------- -- ---------

with the operators @xmath and @xmath defined by Eqs. ( 14.53 ) and (
14.54 ). The loop @xmath is attached to the edges @xmath and @xmath
according to the special loop prescription, and the coefficient @xmath
restricts the action of the operators to those pairs of edges which meet
each other transversally at the node @xmath . The task of computing
matrix elements of the operators ( 14.57 ) and ( 14.58 ) in the spin
network basis will be considered in Chapter 16 .

Eqs. ( 14.55 )–( 14.58 ) can be interpreted equally well as equations in
@xmath or in @xmath . In the former case, the Euclidean operator @xmath
carries an implicit dependence on the regularization parameter @xmath .
At the diffeomorphism invariant level, the regularization parameter is
absent, and each of the operators is defined by duality in the way shown
by Eq. ( 14.35 ) (and therefore carries a suppressed @xmath
-superscript). Note that it follows from the definition ( 14.35 ) that
the dual operator @xmath acts by removing loops; in @xmath loops are
created by the adjoint operator @xmath .

In principle, the physical Hamiltonian provided by Eq. ( 14.55 )
completes the definition of a concrete and mathematically consistent
model of quantum gravity. However, from a practical perspective Eq. (
14.55 ) is not fully concrete, since the square root on the right-hand
side cannot be expressed in an explicit form unless a spectral
decomposition of the operator under the square root is available. While
no progress has been made towards deriving an exact, analytic expression
for the spectrum of the operator ( 14.56 ) (or any of its differently
symmetrized variants), under certain conditions an approximate, partial
solution to the eigenvalue problem can be obtained using perturbation
theory, as we will show in section 17.1 .

## 15 A new Hamiltonian constraint operator

The technical ideas introduced in the previous chapter can naturally
also be applied to the quantization of the Hamiltonian constraint, even
though they were primarily developed with a view towards constructing a
satisfactory physical Hamiltonian for loop quantum gravity
deparametrized with respect to a free scalar field. In this way one
would obtain a Hamiltonian constraint operator whose Euclidean part acts
by creating ”special loops”, and whose remaining part is quantized as
the curvature operator of section 14.3 . Most importantly, the
properties of the special loops guarantee that the resulting operator
can be symmetrized. Even if one prefers the point of view that the
Hamiltonian constraint operator should not be symmetric, a quantization
of the constraint as a symmetric operator is nevertheless needed in
order to provide a physical Hamiltonian for deparametrized dust models.

A concrete construction of a Hamiltonian constraint operator of this
type was given by the author together with Mehdi Assanioussi and Jerzy
Lewandowski in the article [ B ] . In this chapter we will display two
slightly modified versions of the construction presented in [ B ] . The
first version differs from the operator defined in [ B ] essentially
only by the way in which we choose to symmetrize the curvature operator,
while in the second version the quantization of the Euclidean part of
the constraint is also modified in comparison to [ B ] .

### 15.1 The vertex Hilbert space

When one considers the quantization of the Hamiltonian constraint, there
arises an additional complication which was not encountered in the case
of the physical Hamiltonian discussed in the previous chapter. Namely,
due to the presence of the lapse function in the functional @xmath , it
is not possible to quantize the Hamiltonian constraint as a
diffeomorphism invariant operator (i.e. as an operator on @xmath which
would map @xmath into itself). A way to deal with this difficulty was
proposed by Lewandowski and Sahlmann, who in [ 93 ] introduced a
suitable intermediate Hilbert space, denoted @xmath , of partially
diffeomorphism-invariant states. As it turns out, the Hamiltonian
constraint can be promoted into a well-defined operator which preserves
the space @xmath , and after solutions of the Hamiltonian constraint on
@xmath are found, they can be turned into solutions of the complete set
of constraints by averaging them over the remaining diffeomorphisms,
which were not accounted for in the construction of the space @xmath .

The general idea for constructing the space @xmath is to start with the
space @xmath of gauge-invariant states ²⁸ ²⁸ 28 Here we are following
the construction presented in [ A ] and [ B ] , rather than the original
construction of [ 93 ] . Thus, the space @xmath defined in this section
corresponds to the space denoted by @xmath in the notation of [ A ] and
[ B ] , and not to the space denoted by @xmath in [ 93 ] . based on a
given graph @xmath , and average the elements of @xmath (in the sense
discussed in Chapter 7 ) with respect to diffeomorphisms which act
trivially on the nodes of the graph @xmath . More precisely, let us
denote by @xmath the set of diffeomorphisms @xmath for which @xmath for
every node @xmath of @xmath and by @xmath the set of diffeomorphisms
acting trivially on elements of @xmath , and consider the averaging of
states in @xmath with respect to the quotient group

  -- -------- -- --------
     @xmath      (15.1)
  -- -------- -- --------

The averaging is again carried out in the dual space @xmath . Given a
state @xmath , we define

  -- -------- -- --------
     @xmath      (15.2)
  -- -------- -- --------

where, as in Chapter 7 , @xmath is the number of symmetries of the graph
@xmath . Eq. ( 15.2 ) defines a linear functional @xmath which is
invariant under the action of @xmath . The state @xmath is gauge
invariant and invariant under diffeomorphisms contained in @xmath , but
it is not invariant under arbitrary diffeomorphisms @xmath . Therefore,
in order to turn the states in @xmath into full solutions of the Gauss
and diffeomorphism constraint, they must be averaged with the remaining
diffeomorphisms, which act non-trivially on the nodes of @xmath .

By linearity, the action of @xmath can be extended into the entire
gauge-invariant Hilbert space, resulting in a functional @xmath . The
space @xmath is then defined as

  -- -------- -- --------
     @xmath      (15.3)
  -- -------- -- --------

the completion being taken with respect to the norm induced by the
natural scalar product

  -- -------- -- --------
     @xmath      (15.4)
  -- -------- -- --------

Any gauge invariant operator @xmath gives rise by duality to an operator
@xmath , which has a well-defined action on @xmath . However, the image
@xmath is generally not contained in @xmath , but is only some subspace
of @xmath . Concerning the conditions for @xmath to be an operator on
@xmath , the following theorem was established in [ 93 ] : Suppose an
operator @xmath has the form

  -- -------- -- --------
     @xmath      (15.5)
  -- -------- -- --------

where the operators @xmath satisfy

  -- -------- -- --------
     @xmath      (15.6)
  -- -------- -- --------

for every diffeomorphism @xmath which preserves the point @xmath , and

  -- -------- -- --------
     @xmath      (15.7)
  -- -------- -- --------

whenever @xmath and @xmath is not a node of @xmath . Then @xmath is an
operator on @xmath , i.e. @xmath . The conditions ( 15.5 )–( 15.7 ) are
met, in particular, by the Hamiltonian constraint operators constructed
in sections 15.2 and 15.3 , and so the above result guarantees that
these operators are indeed well-defined as operators on @xmath .

### 15.2 A Thiemann-like construction

The starting point for the quantization of the Hamiltonian constraint
performed in [ B ] is given by the classical expression ( 1.68 ), in
which the Lorentzian part of the constraint has been traded for the
integral of the Ricci scalar over the spatial manifold. That is,

  -- -------- -- --------
     @xmath      (15.8)
  -- -------- -- --------

where the Euclidean part of the constraint is

  -- -------- -- --------
     @xmath      (15.9)
  -- -------- -- --------

and the remaining term

  -- -------- -- ---------
     @xmath      (15.10)
  -- -------- -- ---------

will be referred to as the curvature part.

To express the Euclidean part in a form suitable for quantization, we
adopt a suitably modified version of the regularization used by Thiemann
in his construction of the constraint operator. Using the notation of
section 13.2 , and allowing the holonomies involved in the
regularization to carry an arbitrary spin @xmath , we have instead of (
13.17 ) the regularized expression ²⁹ ²⁹ 29 The numerical prefactor in
Eq. ( 15.11 ) is adjusted to account for the normalization of the @xmath
generators, which in the spin- @xmath representation is given by

@xmath

  -- -------- -------- -- ---------
     @xmath   @xmath      
                          (15.11)
  -- -------- -------- -- ---------

Here the symbols have the same meaning as in section 13.2 , except for
the loop @xmath , which is now chosen according to the special loop
prescription introduced in section 14.2 . That is, the loop @xmath does
not overlap with the edges @xmath and @xmath , but is tangent to them at
a sufficiently high order, allowing it to be distinguished from any
other loops which may have been present before the loop @xmath was
introduced. However, at the level of the classical regularized
expression ( 15.11 ), we still assume that the shape of the loop @xmath
follows arbitrarily closely the shape of the triangular loop spanned by
the segments @xmath and @xmath . We also require the family of loops
loops @xmath to satisfy the conditions spelled out in section 14.4 . In
particular, we assume that the loop @xmath depends on the regularization
parameter @xmath in a diffeomorphism covariant manner: If @xmath and
@xmath are the cells of two triangulations characterized by two
different values of @xmath , there exists a diffeomorphism @xmath such
that @xmath .

By quantizing the classical expression ( 15.11 ), we obtain a
triangulation-dependent constraint operator, whose action on a state
based on a graph @xmath is given by

  -- -------- -------- -- ---------
     @xmath   @xmath      
                          (15.12)
  -- -------- -------- -- ---------

where, as in Eq. ( 13.19 ), @xmath denotes the number of distinct
triples of edges at the node @xmath . In order to remove the dependence
on the triangulation, we must consider the limit @xmath . As discussed
in the preceding chapters, the operator ( 15.12 ) does not converge into
a well-defined operator on @xmath as @xmath , and therefore the limit
cannot be taken at the level of the kinematical Hilbert space.

On the other hand, the dual operator @xmath is a well-defined operator
on the vertex Hilbert space, and the diffeomorphism covariance of the
loops @xmath ensures that the limit @xmath is trivial on @xmath , and
can be performed simply by dropping the (implicit) label @xmath in Eq. (
15.12 ). Thus, the Euclidean part of the constraint can be defined as an
operator on @xmath as

  -- -------- -- ---------
     @xmath      (15.13)
  -- -------- -- ---------

The action of the operator on a state based on a graph @xmath takes the
form

  -- -------- -- ---------
     @xmath      (15.14)
  -- -------- -- ---------

where the explicit form of the operator @xmath can be read off from Eq.
( 15.12 ).

The quantization of the curvature part ( 15.10 ) is given directly by
the construction outlined in section 14.3 ; the presence of the lapse
function in the integral ( 15.10 ) does not alter the construction in
any essential way. The operator defined by the appropriate modification
of Eq. ( 14.15 ) acts in a graph-preserving way, so it can be
immediately passed to an operator on @xmath The resulting operator acts
on @xmath as

  -- -------- -- ---------
     @xmath      (15.15)
  -- -------- -- ---------

where, choosing the symmetrization suggested in Eq. ( 14.18 ), we have
³⁰ ³⁰ 30 Since @xmath is an operator on @xmath , all the operators on
the right-hand side of Eq. ( 15.16 ) should strictly speaking carry a
@xmath -superscript. However, since each of these operators is symmetric
and acts on the node @xmath merely by modifying the intertwiner, there
is essentially no difference between the action of the operator on
@xmath and that of the corresponding dual operator on @xmath . For such
operators, we omit the @xmath -superscript, using the same notation to
denote the operator on @xmath and its dual on @xmath . The distinction
is more significant in the case of the Euclidean part, since the dual of
the loop-creating operator ( 15.12 ) acts in @xmath by removing loops.

  -- -------- -- ---------
     @xmath      (15.16)
  -- -------- -- ---------

All in all, we have therefore managed to quantize the Hamiltonian
constraint as a well-defined operator on the space @xmath . The action
of the operator on states in @xmath has the form

  -- -------- -- ---------
     @xmath      (15.17)
  -- -------- -- ---------

Some general properties of the operator will be discussed in section
15.4 . However, we will first present an alternative way of quantizing
the Euclidean part of the constraint.

### 15.3 An alternative construction

In the previous section, the Euclidean part of the constraint was
quantized using Thiemann’s trick, which is designed to deal with the
problematic factor of @xmath in the classical expression ( 15.9 ). On
the other hand, in the construction of the curvature operator the same
factor of @xmath (which, as we recall, enters the construction when the
lengths of hinges in Regge’s formula are expressed in terms of fluxes)
was essentially quantized as the regularized ”inverse volume” operator
@xmath . Therefore, once we have decided to quantize the curvature part
of the constraint in this way, there seems to be little reason to avoid
using the operator @xmath in the quantization of the Euclidean part as
well.

In order to derive a suitably regularized classical expression, from
which the Euclidean part can be quantized by means of the operator
@xmath , let us consider a generic cellular decomposition of the spatial
manifold @xmath into cells denoted by @xmath . We may then trivially
rewrite the integral ( 15.9 ) as

  -- -------- -- ---------
     @xmath      (15.18)
  -- -------- -- ---------

Here the integral over a cell can be approximated as

  -- -------- -- ---------
     @xmath      (15.19)
  -- -------- -- ---------

since at leading order in the regularization parameter, both sides of
the above equation reduce to @xmath , where @xmath is the volume of the
cell @xmath .

In the denominator on the right-hand side of Eq. ( 15.19 ), we have the
integral which was already considered in section 14.4 . Assuming that
the cell @xmath contains a single spin network node @xmath , the
denominator of Eq. ( 15.19 ) gives rise upon quantization to the
operator @xmath defined by Eq. ( 14.33 ), while the factor @xmath can be
promoted into the operator @xmath . The relative ordering between the
two operators may in principle be chosen freely, and we fix it by
ordering a square root of @xmath to either side of @xmath (mimicking the
way in which we have chosen to symmetrize the curvature operator).

After passing to the space @xmath , in which it is trivial to remove the
regulator still present in the operator @xmath , we obtain the Euclidean
part of the constraint operator in the form

  -- -------- -- ---------
     @xmath      (15.20)
  -- -------- -- ---------

where we have denoted

  -- -------- -- ---------
     @xmath      (15.21)
  -- -------- -- ---------

The quantization of the curvature part can be carried over without
modification from the previous section. Thus we have quantized the
entire constraint as

  -- -------- -- ---------
     @xmath      (15.22)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (15.23)
  -- -------- -- ---------

and @xmath and @xmath are (the duals of) the operators defined by Eqs. (
14.57 ) and ( 14.58 ).

Besides the operator @xmath , the adjoint operator @xmath can be
considered as an equally good quantization of the classical functional (
14.21 ). Therefore the operator @xmath in Eq. ( 15.23 ) could be
replaced with the adjoint operator @xmath , or with any combination ”of
total weight 1” between @xmath and its adjoint. If a symmetric
combination of @xmath and the adjoint is chosen, the operator between
the factors of @xmath in Eq. ( 15.23 ) is the same as the operator under
the square root in the physical Hamiltonian defined by Eq. ( 14.55 ).

### 15.4 Properties of the constraint operator

The Hamiltonian constraint operators constructed in this chapter are
operators on the space @xmath of partially diffeomorphism-invariant
states. Notably, the space @xmath is preserved by the action of these
operators. The operators can be expressed in a general form, without
reference to any graph, as

  -- -------- -- ---------
     @xmath      (15.24)
  -- -------- -- ---------

where @xmath denotes either the operator @xmath in Eq. ( 15.17 ) or the
operator @xmath of Eq. ( 15.23 ), and it is understood that the action
of @xmath on a state @xmath gives zero whenever the point @xmath does
not coincide with any node of the graph @xmath . Since the adjoint
operator @xmath also exists as a well-defined operator on @xmath , we
are free to define a symmetric constraint operator, such as

  -- -------- -- ---------
     @xmath      (15.25)
  -- -------- -- ---------

which will again be of the general form ( 15.24 ). As shown by the
discussion in Chapter 12 , a quantization of the Hamiltonian constraint
as a symmetric operator (and evaluated at unit lapse function) is needed
as the physical Hamiltonian for deparametrized models in which a dust
field is used as the relational time variable, even if one disapproves
of the proper constraint operator – that is, the operator whose kernel
determines the physical Hilbert space of loop quantum gravity seen as a
fully constrained theory – being symmetric.

Concerning the commutator algebra of the constraint operator ( 15.24 ),
we may begin by noting that the operator is gauge invariant, and
therefore commutes with the Gauss constraint. It is also not difficult
to see that the operator behaves under diffeomorphisms in the expected
way, namely

  -- -------- -- ---------
     @xmath      (15.26)
  -- -------- -- ---------

The commutator between two Hamiltonian constraints can be evaluated with
a straightforward calculation. Using the expression ( 15.24 ), we get

  -- -------- -- ---------
     @xmath      (15.27)
  -- -------- -- ---------

where the summation can be restricted to the points @xmath , since when
@xmath , the commutator @xmath evidently vanishes ³¹ ³¹ 31 However, we
should note that this is the case only because @xmath is a well-defined
operator on @xmath as such, without having an implicit dependence on
some regularization parameter. When calculating the commutator of two
regularized constraint operators at the kinematical level, one would
encounter a commutator of the form @xmath , which does not generally
vanish, because the two operators @xmath are characterized by two
different values of the regularization parameter. . When the commutator
@xmath (with @xmath ) acts on a state based on a graph @xmath , the only
case which does not immediately give zero is when the points @xmath and
@xmath coincide with two nodes @xmath and @xmath of the graph. However,
even in this case we have

  -- -------- -- ---------
     @xmath      (15.28)
  -- -------- -- ---------

since the action of the operator @xmath is local at the node @xmath , in
the sense that the ”quantum numbers” at other nodes of the state @xmath
are not changed by the action of @xmath , and neither does the action on
the node @xmath depend on the values of any quantum numbers outside of
the node @xmath . Hence we have shown that

  -- -------- -- ---------
     @xmath      (15.29)
  -- -------- -- ---------

so we may conclude that the constraint algebra contains no anomalies at
the diffeomorphism invariant level. However, the above calculations are
strictly speaking not sufficient to determine whether the operator (
15.24 ) is truly anomaly-free, since they are carried out in the space
@xmath , and not in the kinematical Hilbert space, where all the
constraint operators have a non-trivial action ³² ³² 32 On the other
hand, in the present work the primary purpose of the operator ( 15.24 )
is to serve as a physical Hamiltonian for the non-rotational dust model,
and in the deparametrized framework the question of anomalies does not
seem to have the same fundamental importance as it does in the case of
the fully constrained theory. .

The different versions of the constraint operator ( 15.24 ) possess a
large number of trivial solutions. Any state whose edges are coplanar
(i.e. the tangent vectors of the edges are coplanar) at every node of
the graph belongs to the kernel of the operator constructed in section
15.2 , while any eigenstate of the volume operator with eigenvalue zero
is also annihilated by the operator of section 15.3

The structure of the non-trivial solutions can be described in a
general, qualitative manner, even though we have not been able to derive
any concrete examples of such solutions. A generic solution of the
constraint ( 15.24 ) will be an infinite linear combination of states
based on different graphs. This linear combination starts with any graph
which does not contain any special loops of the type created by the
Euclidean operator; in the present context, such a graph could be called
a ”seed graph”. The linear combination also includes the graphs where
the nodes of the seed graph are decorated with special loops in all the
possible ways which would be generated by repeated actions of the
Euclidean operator on the seed graph. Since the constraint acts locally
at the nodes of the graph, the problem of deriving solutions boils down
to solving the constraint separately node-by-node. The solution at each
node will be an infinite linear combination having the following
schematic structure:

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (15.30)
  -- -------- -- ---------

If solutions of this kind can be found, they will be states in @xmath .
In order to promote them into solutions of the full set of constraints,
and hence to elements of the physical Hilbert space, each such solution
would still have to be averaged with respect to the diffeomorphisms
which act non-trivially on the nodes of the seed graph from which the
solution was constructed.

## 16 Matrix elements of the Hamiltonian

In this chapter we take up the task of computing matrix elements of the
Hamiltonian operators introduced in the preceding chapters. The
calculations are performed using the graphical formalism which is
introduced in the Appendix, and which is generally an invaluable tool
for analyzing the action of operators in loop quantum gravity in the
spin network basis.

The material in this chapter is divided into three sections. In the
first two sections we consider the Euclidean operator @xmath and the
curvature operator @xmath , defined respectively by Eqs. ( 14.57 ) and (
14.58 ). In the third section we examine the volume operator, which
enters the physical Hamiltonian of the non-rotational dust model. We
will not attempt to calculate the action of any of these operators on a
general spin network state. Rather, we will only derive those matrix
elements of the operators which are needed for the numerical
applications presented in the next chapter. In any case, once the
methods of calculation are known, they can be easily generalized to more
complicated states, should the need ever arise to evaluate the action of
the Hamiltonian on such states.

The calculations presented below have not been previously published
anywhere. They were performed by the author during the course of the
work that eventually lead to the article [ E ] , and they formed the
basis for the numerical computations which were presented in that
article.

### 16.1 Euclidean part

Let us start by considering the Euclidean operator @xmath defined by Eq.
( 14.57 ). The ”elementary” Euclidean operator, out of which the
operator @xmath is composed, is given by ³³ ³³ 33 From now on, we let
@xmath denote the spin of the loop created by the Euclidean operator.
The letter @xmath is reserved to denote an internal spin of the
intertwiner in a state on which the operator @xmath acts.

  -- -------- -- --------
     @xmath      (16.1)
  -- -------- -- --------

and acts on a pair of edges @xmath at the node @xmath .

We will first calculate the action of the operator @xmath on a state of
the form

  -- -------- -- --------
     @xmath      (16.2)
  -- -------- -- --------

Since some orientation of the edges must be chosen in order to
conveniently carry out the calculation, we will assume that the edges
@xmath and @xmath are oriented outwards from the node @xmath . However,
it is not difficult to verify that the matrix elements of the operator
are independent of the orientation of the edges on which it acts, and we
will do so at the end of the calculation.

The action of the angular momentum operators in Eq. ( 16.1 ) on the
corresponding holonomies is given by Eqs. ( C.28 ) and ( C.29 ). In the
case that the edge is oriented away from the node, we have

  -- -------- -- --------
     @xmath      (16.3)
  -- -------- -- --------

The remaining part of the operator ( 16.1 ) may also be expressed in
graphical form. Making use of the graphical representations of @xmath
and @xmath from Eqs. ( C.19 ) and ( C.16 ), we find

  -- -------- -- --------
     @xmath      (16.4)
  -- -------- -- --------

where the free indices @xmath and @xmath are to be contracted against
the indices of the angular momentum operators.

With the help of Eqs. ( 16.3 ) and ( 16.4 ), we can now write down the
action of the operator @xmath on the state ( 16.2 ):

  -- -------- -- --------
     @xmath      (16.5)
  -- -------- -- --------

In order to bring out the matrix elements of the operator with respect
to a particular basis, the intertwiner on the right-hand side must be
expanded in the desired basis. Focusing on the five-valent intertwiner
carrying spins @xmath , @xmath , @xmath , @xmath and 1, we choose to
expand it as

  -- -------- -- --------
     @xmath      (16.6)
  -- -------- -- --------

At the end of the calculation, the loop created by the Euclidean
operator,

  -- -------- -- --------
     @xmath      (16.7)
  -- -------- -- --------

will be attached to the line carrying spin 1 on the right-hand side of
Eq. ( 16.6 ).

The coefficients @xmath in Eq. ( 16.6 ) are obtained by contracting the
intertwiner on the left-hand side of the equation with that on the
right-hand side: ³⁴ ³⁴ 34 For simplicity of notation, we indicate
explicitly only the dependence of @xmath on the variable internal spins
of the intertwiner; however, @xmath is certainly also a function of the
external spins @xmath , @xmath , @xmath and @xmath . The same remark
applies to other similar functions defined later in this chapter, such
as the function @xmath of Eq. ( 16.20 ).

  -- -------- -- --------
     @xmath      (16.8)
  -- -------- -- --------

To deal with this diagram, we appeal to the ”fundamental theorem of
graphical calculus” in the form ( C.47 ). The diagram can be separated
into two disconnected pieces by cutting three lines according to

  -- -------- -- --------
     @xmath      (16.9)
  -- -------- -- --------

Therefore the diagram is equal to the product of the two pieces
resulting from the cutting. The simpler of the two pieces is

  -- -------- -- ---------
     @xmath      (16.10)
  -- -------- -- ---------

where the factor @xmath arises when Eqs. ( C.4 ), ( C.9 ) and ( C.10 )
are used to adjust the arrows and signs in the diagram so that they
agree with Eq. ( C.34 ). Similarly, by comparing the remaining piece of
the diagram ( 16.9 ) with Eq. ( C.38 ), we find

  -- -------- -- ---------
     @xmath      (16.11)
  -- -------- -- ---------

Hence we have shown that

  -- -------- -- ---------
     @xmath      (16.12)
  -- -------- -- ---------

We may now read off the result of our calculation from Eqs. ( 16.5 ) and
( 16.6 ). We see that the action of the Euclidean operator on the state
( 16.2 ) is given by

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (16.13)
  -- -------- -------- -- ---------

The calculation having been completed, let us then address the question
of whether the result depends on the orientation of the edges @xmath and
@xmath in the state ( 16.2 ). If one of the edges, say @xmath , is
oriented into the node, we must consider the action of the operator
@xmath on the state

  -- -------- -- ---------
     @xmath      (16.14)
  -- -------- -- ---------

The action of the angular momentum operator on the first holonomy is now
given by ( C.29 ), namely

  -- -------- -- ---------
     @xmath      (16.15)
  -- -------- -- ---------

We then obtain, instead of Eq. ( 16.5 ),

  -- -------- -- ---------
     @xmath      (16.16)
  -- -------- -- ---------

Compared against Eq. ( 16.5 ), there are three differences on the
right-hand side:

-   The arrow on the line carrying spin @xmath is reversed;

-   The node with spins @xmath , @xmath and @xmath has the opposite
    sign;

-   There is an overall factor of @xmath , due to the absence of @xmath
    in Eq. ( 16.15 ).

By Eqs. ( C.4 ) and ( C.9 ), the first two differences contribute
respectively the factors @xmath and @xmath . Thus the overall factor in
Eq. ( 16.16 ) relative to Eq. ( 16.5 ) is @xmath . This shows that the
matrix elements of not only the Euclidean operator ( 16.1 ), but those
of any operator which acts on holonomies only through the angular
momentum operator, are not sensitive to the orientation of the edges in
the state on which the operator is acting.

The other case which we need to consider for the Euclidean operator is
the action of the operator @xmath on a state of the form

  -- -------- -- ---------
     @xmath      (16.17)
  -- -------- -- ---------

where we again assume that the edges @xmath and @xmath are oriented
outwards from the node @xmath . The calculation naturally proceeds along
the same lines as the calculation that lead from Eq. ( 16.5 ) to ( 16.13
). Applying the graphical representation of the Euclidean operator in
the same way as in Eq. ( 16.5 ), we find

  -- -------- -- ---------
     @xmath      
     @xmath      (16.18)
  -- -------- -- ---------

We now expand the intertwiner on the right-hand side as

  -- -------- -- ---------
     @xmath      
     @xmath      (16.19)
  -- -------- -- ---------

with the coefficients of the expansion given by

  -- -------- -- ---------
     @xmath      (16.20)
  -- -------- -- ---------

While this diagram is more complicated than the analogous diagram ( 16.8
), it can still be reduced into its ”elementary constituents” by
repeated cuts of no more than three lines. Making the cuts indicated by
the dashed red lines in

  -- -------- -- ---------
     @xmath      (16.21)
  -- -------- -- ---------

we find that the diagram splits into a product of four pieces. Three of
the pieces are proportional to 6 @xmath -symbols:

  -- -------- -- ---------
     @xmath      (16.22)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (16.23)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (16.24)
  -- -------- -- ---------

The remaining piece gives a 9 @xmath -symbol:

  -- -------- -- ---------
     @xmath      
     @xmath      (16.25)
  -- -------- -- ---------

Putting all the pieces together in Eq. ( 16.19 ), we obtain the result

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (16.26)
  -- -------- -- ---------

### 16.2 Curvature part

We then move on to consider the curvature operator ³⁵ ³⁵ 35 We will
often refer to the operator of Eq. ( 14.58 ) simply as the ”curvature
operator”, even though strictly speaking it is not the operator
corresponding to the scalar curvature of the spatial surfaces. @xmath of
Eq. ( 14.58 ). The operator @xmath is composed of ”elementary” curvature
operators of the form

  -- -------- -- ---------
     @xmath      (16.27)
  -- -------- -- ---------

where the operators @xmath and @xmath are defined by Eqs. ( 14.53 ) and
( 14.54 ). From the point of view of computing the action of the
operator on a spin network state, the most important difference between
the curvature operator ( 16.27 ) and the Euclidean operator ( 16.1 ) is
that the former is a non-polynomial combination of the angular momentum
operators @xmath . For this reason, the graphical representation of the
action of the angular momentum operator is of little direct use in
calculating matrix elements of the curvature operator, and we must
therefore approach this problem by different, largely non-graphical
means.

The key observation, on which the calculation of the action of the
curvature operator on any spin network state is based, is that the state

  -- -------- -- ---------
     @xmath      (16.28)
  -- -------- -- ---------

is an eigenstate of the operator @xmath . In order to see this, we
recall that we have already discussed the operators @xmath and @xmath in
sections 8.4 and 8.5 . In particular, we found that the operators act
diagonally on the state ( 16.28 ) – see Eqs. ( 8.30 ) and ( 8.38 ).
Regarding @xmath and @xmath as operators acting on the intertwiner space
of the node, we have the eigenvalue equations

  ----- -------- -------- -- ---------
        @xmath   @xmath      (16.29)
  and                        
        @xmath   @xmath      (16.30)
  ----- -------- -------- -- ---------

The eigenvalues are given by Eqs. ( 8.31 ) and ( 8.39 ) as

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (16.31)
  -- -------- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (16.32)
  -- -------- -- ---------

Since the operators @xmath and @xmath act diagonally on the state (
16.28 ), the same is true of the operator @xmath :

  -- -------- -- ---------
     @xmath      (16.33)
  -- -------- -- ---------

From Eq. ( 16.27 ), we see that the eigenvalue is

  -- -- -- ---------
           (16.34)
  -- -- -- ---------

Now the strategy for computing the action of the operator @xmath on any
spin network state will be as follows. If the edges @xmath and @xmath
are coupled together by the intertwiner at the node @xmath , the action
is immediately given by Eq. ( 16.33 ). If the edges are not coupled
together by the intertwiner, the action is calculated in three steps:

-   We perform a suitable change of basis in the intertwiner space of
    the node, expressing the intertwiner at the node in a basis in which
    the edges @xmath and @xmath are coupled together;

-   We apply the operator @xmath , which now acts diagonally on the new
    intertwiner basis;

-   We reverse the change of basis performed in the first step,
    transforming the intertwiner back into the original basis.

For the purposes of this work, it suffices to consider the action of the
operator @xmath on the state

  -- -------- -- ---------
     @xmath      (16.35)
  -- -------- -- ---------

The required change of basis, which brings the intertwiner of Eq. (
16.35 ) into a basis in which the spins @xmath and @xmath are coupled to
a definite total spin, is derived in section C.3 . Applying the
transformation given by Eq. ( C.61 ), we find

  -- -------- -- ---------
     @xmath      
     @xmath      (16.36)
  -- -------- -- ---------

where the intertwiners on the right-hand side are of the type on which
the operator @xmath acts diagonally. Hence, acting with the operator and
then using Eq. ( C.61 ) in reverse to restore the intertwiners in the
resulting state back into the basis of Eq. ( 16.35 ), we obtain

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (16.37)
  -- -------- -- ---------

The sum over @xmath can now be performed using the orthogonality
relation of 6 @xmath -symbols, Eq. ( B.44 ):

  -- -------- -- ---------
     @xmath      (16.38)
  -- -------- -- ---------

This leads to

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (16.39)
  -- -------- -- ---------

In principle, Eq. ( 16.39 ) completes the task of calculating the action
of the curvature operator on the state ( 16.35 ). However, we can still
manipulate the result by performing the sum over the spin @xmath , which
appears only in the two 9 @xmath -symbols – for one thing, by doing so
we will cast the matrix element into a form which is more suitable for
numerical computations.

In order to compute the sum over @xmath in Eq. ( 16.39 ), we use the
identity [ 127 ]

  -- -------- -- ---------
     @xmath      (16.40)
  -- -------- -- ---------

Before applying this identity in Eq. ( 16.39 ), we shuffle the spins in
the 9 @xmath -symbols so that in each symbol the position of the spin
@xmath matches the position of @xmath on the left-hand side of Eq. (
16.40 ), and hence will appear in only one 6 @xmath -symbol on the
right-hand side. In this way, the sum over @xmath becomes

  -- -------- -------- -- ---------
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      
     @xmath   @xmath      (16.41)
  -- -------- -------- -- ---------

By virtue of the orthogonality relation

  -- -------- -- ---------
     @xmath      (16.42)
  -- -------- -- ---------

the expression ( 16.41 ) now reduces to

  -- -------- -- ---------
     @xmath      (16.43)
  -- -------- -- ---------

Going with this back to Eq. ( 16.39 ), and relabeling some of the dummy
spins, we obtain the action of the curvature operator on the state (
16.35 ) in the form

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (16.44)
  -- -------- -- ---------

### 16.3 Volume operator

We then come to the volume operator, which, as we have seen, enters the
Hamiltonian constraint operator (and thus the physical Hamiltonian of
dust models) in addition to the operators @xmath and @xmath . We will
calculate matrix elements of the operator

  -- -------- -- ---------
     @xmath      (16.45)
  -- -------- -- ---------

which is related to the actual volume operator in the way indicated by
Eqs. ( 8.18 ) and ( 8.19 ). In particular, extracting the volume
operator from the operator ( 16.45 ) involves taking a square root,
which must be done numerically in all but the very simplest cases.

Let us first calculate the action of the operator @xmath on the state

  -- -------- -- ---------
     @xmath      (16.46)
  -- -------- -- ---------

where we are again assuming that all the edges are oriented outwards
from the node @xmath , while recalling that the matrix elements of the
operator do not depend on the orientation of the edges. When each of the
angular momentum operators in Eq. ( 16.45 ) acts on the corresponding
holonomy according to Eq. ( 16.3 ), and @xmath is converted into
graphical form while picking up a factor of @xmath , the operator @xmath
effectively acts on the intertwiner of the state ( 16.46 ) as

  -- -------- -- ---------
     @xmath      (16.47)
  -- -------- -- ---------

Now we must expand the intertwiner on the right-hand side in the basis
of intertwiners used in the state ( 16.46 ). We have

  -- -------- -- ---------
     @xmath      
     @xmath      (16.48)
  -- -------- -- ---------

where the coefficients are given by

  -- -------- -- ---------
     @xmath      (16.49)
  -- -------- -- ---------

The diagram ( 16.49 ) can be reduced into 6 @xmath - and 9 @xmath
-symbols by making three cuts of three lines as follows:

  -- -------- -- ---------
     @xmath      (16.50)
  -- -------- -- ---------

The piece on the inner left side of the diagram is a 9 @xmath -symbol,

  -- -------- -- ---------
     @xmath      (16.51)
  -- -------- -- ---------

while each of the remaining pieces gives a 6 @xmath -symbol:

  -- -------- -------- -- ---------
     @xmath   @xmath      (16.52)
     @xmath   @xmath      (16.53)
     @xmath   @xmath      (16.54)
  -- -------- -------- -- ---------

Therefore we conclude that the action of the operator @xmath on the
state ( 16.46 ) reads

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (16.55)
  -- -------- -- ---------

We must also consider the case of the operator @xmath acting on the
state

  -- -------- -- ---------
     @xmath      (16.56)
  -- -------- -- ---------

Letting again the angular momentum operators act on the holonomies in
Eq. ( 16.56 ), and interpreting the resulting expression as an action on
the intertwiner, we have

  -- -------- -- ---------
     @xmath      
     @xmath      (16.57)
  -- -------- -- ---------

As before, the intertwiner on the right-hand side should be expanded
with respect to the appropriate basis. This gives

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (16.58)
  -- -------- -- ---------

where

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (16.59)
  -- -------- -------- -- ---------

This diagram as well can be beaten down into a product of 6 @xmath - and
9 @xmath -symbols by repeatedly splitting off pieces by cutting three
lines. We start by making the cuts shown below:

  -- -------- -- ---------
     @xmath      (16.60)
  -- -------- -- ---------

In this way we cut off three pieces of identical form, each of them
being a 6 @xmath -symbol:

  -- -------- -- ---------
     @xmath      (16.61)
  -- -------- -- ---------

  -- -------- -- ---------
     @xmath      (16.62)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (16.63)
  -- -------- -- ---------

What remains of the diagram ( 16.60 ) can then be cut as follows:

  -- -------- -- ---------
     @xmath      (16.64)
  -- -------- -- ---------

Now the left and right pieces each give a 6 @xmath -symbol,

  -- -------- -- ---------
     @xmath      (16.65)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (16.66)
  -- -------- -- ---------

while the piece in the middle is a 9 @xmath -symbol,

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (16.67)
  -- -------- -------- -- ---------

Collecting all the pieces together, and carefully simplifying the powers
of @xmath , we find the result

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      
     @xmath      (16.68)
  -- -------- -- ---------

## 17 Approximation methods for time evolution in deparametrized models

In deparametrized models of loop quantum gravity, where the role of a
physical time variable is assigned to a scalar field contained in the
model, the dynamics of diffeomorphism invariant states of the
gravitational field is governed by the Schrödinger equation

  -- -------- -- --------
     @xmath      (17.1)
  -- -------- -- --------

with the physical Hamiltonian @xmath generating time evolution with
respect to the time defined by the scalar field. For models in which the
physical time variable is taken to be a free Klein–Gordon field or a
non-rotational dust field, the mathematical structure of the model is
completed by the constructions which are presented in Chapters 14 and 15
, and which provide a concrete proposal for the form of the physical
Hamiltonian.

In the case of the free scalar field model, the physical Hamiltonian is
given by

  -- -------- -- --------
     @xmath      (17.2)
  -- -------- -- --------

where @xmath and @xmath are the operators defined by Eqs. ( 14.57 ) and
( 14.58 ) (here naturally considered as operators on @xmath ). Inside
the square root, @xmath denotes a symmetric ordering of the operator. In
this chapter, we choose the straightforward symmetrization

  -- -- -- --------
           (17.3)
  -- -- -- --------

Furthermore, we are forced to introduce a restriction of the operator
within the square root to the positive part of its spectrum, defined as
@xmath , in order to ensure that Eq. ( 17.2 ) defines a symmetric
physical Hamiltonian.

For the non-rotational dust model, the physical Hamiltonian is obtained
by evaluating the Hamiltonian constraint operator of Chapter 15 at unit
lapse function. In this chapter we consider only the physical
Hamiltonian obtained by symmetrizing the operator defined by Eqs. (
15.22 ) and ( 15.23 ). Thus,

  -- -- -- --------
           (17.4)
  -- -- -- --------

where @xmath and @xmath are the same operators as in Eq. ( 17.2 ), and
@xmath is (the dual of) the operator ( 8.36 ). We emphasize that the
operator ( 17.4 ) is a well-defined operator on @xmath , even though the
constraint operator ( 15.22 ) (for a general lapse function) is only an
operator on @xmath .

In order to study the dynamics generated by a given physical Hamiltonian
through concrete calculations, a knowledge of the spectrum of the
Hamiltonian is a necessary prerequisite. The time evolution operator
@xmath must generally be defined through its spectral decomposition;
moreover, in the case of the free scalar field model, even the action of
the physical Hamiltonian itself can be made explicit only if the
spectral decomposition of the operator under the square root in Eq. (
17.2 ) is available. However, so far no progress has been made towards
obtaining an exact solution of the eigenvalue problem of the operator (
17.2 ) or ( 17.4 ), even within some restricted subspace of the entire
diffeomorphism invariant Hilbert space.

This being the case, it becomes imperative to develop suitable
approximation methods for dealing with the Hamiltonians ( 17.2 ) or (
17.4 ), so that the dynamics contained in them could be understood at
the level of explicit calculations. A first step in this direction was
taken by the author in collaboration with Mehdi Assanioussi and Jerzy
Lewandowski in the article [ E ] , in which we used ideas from
elementary quantum mechanics to introduce methods which make it possible
to approximate the time evolution of a given initial state under the
Hamiltonian ( 17.2 ) or ( 17.4 ). We also gave examples of using our
methods to compute numerically the time evolution of expectation values
of the volume and curvature operators in certain simple initial states.
In this chapter we will review the work carried out in [ E ] .

### 17.1 Perturbation theory

As we have seen, the operator @xmath in Eqs. ( 17.2 ) or ( 17.4 ) is a
graph-preserving operator, and acts only on the intertwiner space of the
node @xmath . The matrix elements of @xmath within a given intertwiner
space can be calculated in the way discussed in section 16.2 , and the
resulting matrix can be diagonalized numerically, at least if the
dimension of the intertwiner space is not unreasonably high. (The same
remarks apply to the operator @xmath in the Hamiltonian of the dust
field model.) The complexity in diagonalizing the Hamiltonian ( 17.2 )
or ( 17.4 ) arises from the Euclidean part, which has non-vanishing
matrix elements between states carrying a different number of special
loops. Consequently, even the simplest subspaces which are preserved by
the action of the Hamiltonian, and within which the Hamiltonian could be
diagonalized, are infinite-dimensional.

A possible way to deal with this situation is suggested by the way we
have written Eqs. ( 17.2 ) and ( 17.4 ), where a factor of @xmath has
been pulled out, so that @xmath appears as a prefactor for the Euclidean
part relative to the curvature part. We see that for sufficiently large
values of @xmath , the factor @xmath plays the role of a small parameter
multiplying the problematic part of the Hamiltonian. In such a
situation, the familiar time-independent perturbation theory of quantum
mechanics can be used to find approximate expressions for the
eigenvalues and eigenstates of the full Hamiltonian in terms of the
known eigenvalues and eigenstates of the ”unperturbed” part of the
Hamiltonian.

In our case we must consider an operator of the form

  -- -------- -- --------
     @xmath      (17.5)
  -- -------- -- --------

which can be either the operator under the square root in the physical
Hamiltonian of the free scalar field model, or the physical Hamiltonian
itself for the non-rotational dust model. In either case the curvature
part @xmath acts in a graph-preserving way, while the Euclidean part
@xmath acts by creating and removing special loops. The perturbation
parameter has the value @xmath . The solution of the perturbative
problem of the operator ( 17.5 ) requires some care due to degeneracies
which are present in the spectrum of the unperturbed operator @xmath ,
and which seem not to be removed by the perturbation @xmath . We will
therefore present the solution in full (up to second order in
perturbation theory) in the following section; here we will summarize
the results of the calculation.

Let us denote the eigenvalues and eigenstates of the unperturbed
operator @xmath by @xmath and @xmath , and those of the entire operator
@xmath by @xmath and @xmath . Then the two operators can be expressed in
terms of their spectral decompositions as

  -- -- -- --------
           (17.6)
  -- -- -- --------

and

  -- -------- -- --------
     @xmath      (17.7)
  -- -------- -- --------

To second order in perturbation theory, the eigenvalues @xmath are given
by

  -- -------- -- --------
     @xmath      (17.8)
  -- -------- -- --------

where the first-order correction vanishes because @xmath changes the
number of special loops, while all the eigenstates corresponding to a
given unperturbed eigenvalue @xmath have the same number of special
loops. For the eigenstates, we have

  -- -------- -------- -- --------
     @xmath   @xmath      
                          
                          (17.9)
  -- -------- -------- -- --------

In general, if the unperturbed eigenstate @xmath has @xmath special
loops, the second-order approximation to the eigenstate @xmath will
contain terms in which the number of special loops ranges from @xmath to
@xmath . In this chapter we will restrict ourselves to considering the
second-order approximations to the eigenvalues and eigenstates, even
though in principle there is nothing to prevent one from including terms
of higher order in Eqs. ( 17.8 ) and ( 17.9 ).

The Hamiltonian @xmath can now be approximated by inserting the
expressions ( 17.8 ) and ( 17.9 ) into the spectral decomposition ( 17.7
) (and discarding terms of higher than second order in @xmath ). The
time evolution operator @xmath can be approximated in the same way. In
particular, for the scalar field model we can write

  -- -------- -- ---------
     @xmath      (17.10)
  -- -------- -- ---------

where @xmath and @xmath are the (approximate) eigenvalues and
eigenstates of the operator ( 17.3 ), and the restriction to the
positive part of the spectrum is accounted for by excluding the negative
eigenvalues from the sum. Naturally a similar expression, but without
the square root and the restriction on the eigenvalues, holds in the
case of the dust model.

In actual calculations it would certainly be impractical to try to use
Eq. ( 17.7 ) as an approximation for the Hamiltonian on the entire
Hilbert space @xmath , by letting the sum run over the whole set of
eigenstates of the unperturbed operator. Instead, the expressions ( 17.7
) and ( 17.10 ) should be viewed as restrictions of the Hamiltonian and
the time evolution operator to a suitable subspace of @xmath which is
sufficiently large for the calculation at hand. For example, consider
using Eq. ( 17.10 ) to compute time evolution of the expectation value
of a graph-preserving operator starting from an initial state which is
based on a single graph containing no special loops. Under the
second-order approximation given by Eqs. ( 17.8 ) and ( 17.9 ), the
Hamiltonian (and hence the evolution operator) has no non-vanishing
matrix elements between the initial state and states in which three or
more special loops have been attached to the graph of the initial state.
Then the summation in Eq. ( 17.10 ) can be restricted to those states in
which the graph of the unperturbed eigenstate is the graph of the
initial state decorated by at most two special loops. (This example is
discussed in more detail in section 17.4 .)

### 17.2 Complete solution of the perturbative problem

In this section we will go through the derivation of the eigenvalues and
eigenstates of the operator ( 17.5 ) up to second order in perturbation
theory. The eigenvalues and eigenstates of the operator @xmath are
assumed to be known, and are denoted by @xmath and @xmath . We look for
approximate expressions for the eigenvalues and eigenstates of the full
operator @xmath in the form

  -- -------- -- ---------
     @xmath      (17.11)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (17.12)
  -- -------- -- ---------

Inserting Eqs. ( 17.11 ) and ( 17.12 ) into Eq. ( 17.5 ), we obtain the
equation

  -- -------- -------- -- ---------
     @xmath               
              @xmath      (17.13)
  -- -------- -------- -- ---------

from which the eigenvalues @xmath and eigenstates @xmath will be
determined iteratively, order-by-order in @xmath .

As is well known, whenever some of the unperturbed eigenvalues @xmath
are degenerate, the corresponding eigenstates @xmath form a correct
starting point for the perturbative expansion only if they are chosen
such that the perturbation @xmath is diagonal in the subspace
corresponding to the degenerate eigenvalue. In our case this requirement
places no restriction on the states @xmath , since all of these states
have the same number of special loops, and the action of the Euclidean
operator @xmath changes the number of special loops by one. In all the
examples we have studied numerically, we have not found any instances of
an eigenvalue of the curvature part being shared between states having a
different number of special loops ³⁶ ³⁶ 36 With the exception that the
eigenvalue zero occurs for every graph in the dust field model. However,
in this case the eigenstates of zero eigenvalue are always annihilated
also by the Euclidean part of the Hamiltonian, so the matrix elements of
the perturbation in the subspace of the unperturbed eigenvalue zero are
still all zeros. .

The derivation of the corrections to the unperturbed eigenvalues then
proceeds according to the textbook treatment, and presents no special
problems. The first-order correction to an eigenvalue is given by the
expectation value of the perturbation in the unperturbed eigenstate, or
by the eigenvalues or the matrix of the perturbation in the degenerate
subspace, depending on whether the unperturbed eigenvalue is degenerate.
In either case, we have

  -- -------- -- ---------
     @xmath      (17.14)
  -- -------- -- ---------

To determine the second-order corrections, we look at the terms of order
@xmath in Eq. ( 17.13 ), and find

  -- -------- -- ---------
     @xmath      (17.15)
  -- -------- -- ---------

where the second equality follows from Eq. ( 17.16 ) together with the
observation that the state @xmath has no non-vanishing components on
unperturbed eigenstates with eigenvalue @xmath .

Moving now on to the eigenstates, the projections of the first- and
second-order corrections @xmath and @xmath onto unperturbed eigenstates
outside of the degenerate subspace of the eigenvalue @xmath are found
easily in the standard way. Considering the terms of first and second
order in Eq. ( 17.13 ), we see that

  -- -- -- ---------
           (17.16)
  -- -- -- ---------

and, recalling that the first-order correction to the eigenvalue
vanishes,

  -- -- -- ---------
           (17.17)
  -- -- -- ---------

Eq. ( 17.24 ), derived below, shows that the correction @xmath has no
non-vanishing components on unperturbed eigenstates having eigenvalue
@xmath . We may therefore use Eq. ( 17.16 ) in Eq. ( 17.17 ), leading to

  -- -- -- ---------
           (17.18)
  -- -- -- ---------

Finding the components of the corrections @xmath and @xmath within the
degenerate subspace turns out to be somewhat more involved. The
projection @xmath is not determined by Eq. ( 17.13 ), but the
requirement that the state ( 17.12 ) should be normalized to 1 up to
first order in @xmath shows that we can set

  -- -------- -- ---------
     @xmath      (17.19)
  -- -------- -- ---------

The terms of first order in Eq. ( 17.5 ) do not contain any information
on the projection @xmath , where @xmath is another unperturbed
eigenstate with eigenvalue @xmath . They merely reproduce

  -- -------- -- ---------
     @xmath      (17.20)
  -- -------- -- ---------

as a consistency condition for the perturbative expansion. As we have
argued above, in our case this condition is satisfied regardless of the
choice of basis in the degenerate subspace.

Because the first-order correction @xmath vanishes, the projection
@xmath is also not determined by the second-order terms of Eq. ( 17.13
). Instead, we obtain another consistency condition,

  -- -------- -- ---------
     @xmath      (17.21)
  -- -------- -- ---------

A numerical evaluation of the sum shows that this condition also seems
to be satisfied for any choice of basis in the degenerate subspace. (See
section 17.4 for the details and the extent of our numerical
calculations.)

We therefore move on to the terms of third order in Eq. ( 17.5 ). We now
find

  -- -- -- ---------
           (17.22)
  -- -- -- ---------

In all the examples we have considered, the second-order corrections
@xmath given by Eq. ( 17.15 ) are all non-vanishing, so the projections
@xmath are indeed determined by the above equation. Furthermore, by
expanding the matrix element on the right-hand side as

  -- -------- -- ---------
     @xmath      (17.23)
  -- -------- -- ---------

and recalling that each action of the Euclidean operator @xmath changes
the number of special loops by one, we see that this matrix element
actually vanishes. (The projections @xmath are given by Eq. ( 17.18 ),
which contains two actions of @xmath , while the states @xmath and
@xmath have the same number of special loops.) Hence we conclude that

  -- -------- -- ---------
     @xmath      (17.24)
  -- -------- -- ---------

As to the second-order correction @xmath , its projection on the
unperturbed eigenstate @xmath can be found by requiring that the state (
17.12 ) is normalized up to second order in @xmath . In this way we
obtain

  -- -------- -- ---------
     @xmath      (17.25)
  -- -------- -- ---------

In an attempt to determine the projection @xmath , we look at the terms
of fourth order in Eq. ( 17.13 ), which give

  -- -- -- ---------
           (17.26)
  -- -- -- ---------

At a first sight, it seems that we have managed to find @xmath , but we
should realize that this projection is also involved in the matrix
element on the right-hand side. By repeatedly inserting resolutions of
identity in terms of the unperturbed eigenstates, we can rewrite the
matrix element as

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
                          (17.27)
  -- -------- -------- -- ---------

where the expression for @xmath has been derived straightforwardly from
the third-order terms in Eq. ( 17.13 ), and we again resorted to
numerics to discover that in all the examples we have considered,

  -- -------- -- ---------
     @xmath      (17.28)
  -- -------- -- ---------

Going now back to Eq. ( 17.27 ), we see that the projection @xmath
indeed appears in the sum over @xmath , the @xmath term of the sum being
equal to

  -- -- -- ---------
           (17.29)
  -- -- -- ---------

In our application, the second-order corrections @xmath and @xmath to a
degenerate eigenvalue @xmath are always equal to each other, at least in
all the cases within the scope of our numerical analysis. Therefore we
see that the projection @xmath cancels out in Eq. ( 17.26 ) and so is
not determined by Eq. ( 17.13 ), apparently due to the fact that the
degeneracy in the eigenvalues of the curvature part is not removed by
the Euclidean part, at least up to second order in perturbation theory.
It also does not seem to be possible to extract the projection @xmath
from terms of even higher order in Eq. ( 17.13 ), nor from any
normalization or orthogonality conditions of the corrected eigenstates.
In order to resolve this situation in some way, we simply set

  -- -------- -- ---------
     @xmath      (17.30)
  -- -------- -- ---------

since this is the simplest possible choice, and it is consistent with
the normalization and orthogonality of the corrected eigenstates up to
second order in @xmath .

### 17.3 Expansion in powers of time

The perturbative treatment introduced in the preceding sections can be
expected to give an accurate approximation for the spectrum of the
physical Hamiltonian for sufficiently large values of @xmath , but we
cannot hope for such an approach to be valid if the value of @xmath is
not particularly large. We are therefore not able to work with the
physical Hamiltonian of the scalar field model with an arbitrary value
of @xmath , since the spectral decomposition of the Hamiltonian is
required in order to resolve the square root in Eq. ( 17.2 ).

The situation is different for the dust model, where an alternative
(even if rather primitive) approach is possible for approximating the
time evolution of a given initial state over a short interval of time,
irrespectively of the value of @xmath . For small values of the time
variable @xmath , we can obtain a good approximation for the evolution
operator @xmath by expanding it in powers of @xmath and truncating the
expansion at some finite power of @xmath . Then each term in the
resulting expansion can be evaluated by repeatedly applying the
Hamiltonian to the initial state, and there is no fundamental
obstruction against performing the required calculations, since the
Hamiltonian of the dust model is available as an explicitly defined
operator.

If one is interested in computing the time dependence of the expectation
value of an operator @xmath starting from a given initial state @xmath ,
the most convenient way to proceed is to evaluate the coefficients in
the (truncated) power series expansion of the expectation value,

  -- -------- -- ---------
     @xmath      (17.31)
  -- -------- -- ---------

Here the coefficients are given by expectation values of repeated
commutators of the operator @xmath with the Hamiltonian in the initial
state:

  -- -------- -- ---------
     @xmath      (17.32)
  -- -------- -- ---------

The advantage of considering directly the expansion of the expectation
value, as opposed to computing the evolved state vector @xmath truncated
at some order @xmath , is that in many situations the expectation value
can be determined up to order @xmath without having to derive all the
components of the truncated state vector. Let us consider again the
example of computing the expectation value of a graph-preserving
operator @xmath , when the initial state is based on a single graph
having no special loops. If we want to find the expectation value @xmath
up to order @xmath , then states in which more than @xmath special loops
have been attached to the initial state do not enter the calculation of
the numbers @xmath , even though the state vector truncated at order
@xmath has components containing up to @xmath special loops.

### 17.4 The setup for numerical analysis

The approximation methods described in this chapter were used in our
article [ E ] to study numerically the time evolution of expectation
values of the volume and curvature operators in certain simple spin
network states. The initial states which we consider are based on a
graph consisting of a single four-valent node. The spins on the edges of
the graph are fixed to a common value @xmath , and the intertwiner at
the node is chosen to be an eigenstate of the volume operator. The node
is assumed to have a non-degenerate tangential structure, in which none
of the four edges are tangent to each other at the node (i.e. the
tangent vectors of the edges are diffeomorphic to the normal vectors of
a regular tetrahedron). Furthermore, we choose @xmath for the spin of
the special loops created by the Euclidean part of the physical
Hamiltonian.

For our choice of the initial graph, there are six different graphs
resulting from the action of the Euclidean operator on the initial
state, corresponding to the six different pairs of edges of a
four-valent node. After a careful counting, and taking into account that
in some cases the same graph is obtained from two different sequences of
acting with the Euclidean operator, one finds that there are 63
different graphs in which two special loops have been attached to the
initial four-valent node by the Euclidean operator. We have not counted
the exact number of graphs resulting from three actions of the Euclidean
operator on the initial state, but this number seems to be of the order
of one thousand, and in any case is so large that it would be infeasible
to try to include the graphs containing three special loops into our
numerical calculations. We must therefore truncate the perturbative
expansion at second order in the parameter @xmath , and the expansion in
powers of the time variable at the fourth power of @xmath .

With these preparations, the main part of our numerical calculations
consists of computing the matrices @xmath and @xmath , as well as the
matrix of the volume operator, in the finite-dimensional space spanned
by the four-valent initial state together with all the states in which
no more than two special loops have been attached to the initial state.
Having the matrix of the volume operator, we can construct the matrix
@xmath , and thereafter the matrix of the physical Hamiltonian for the
dust model. The matrix of the operator under the square root in the
physical Hamiltonian of the scalar field model is given directly in
terms of the matrices @xmath and @xmath .

The matrix elements of the operators are computed from the formulas
derived in Chapter 16 , noting in particular that the intertwiners
appearing in these formulas are not normalized, so the formulas must be
suitably modified in order to obtain the matrix elements with respect to
a basis of normalized states. The cases in which the Euclidean operator
or the curvature operator acts on a pair of edges different from @xmath
or @xmath , or the squared volume operator acts on a triple of edges
different from @xmath or @xmath , can be reduced to the cases given in
Chapter 16 by appropriately using the symmetry relation ( C.9 ).

The matrix elements of the Euclidean operator @xmath and the squared
volume operator are expressed entirely in terms of 6 @xmath -symbols in
which one spin is equal to 1, and 9 @xmath -symbols in which a triple of
spins are all equal to 1. In the computation of the matrix elements, the
values of these symbols are calculated using their explicit algebraic
expressions, which can be found e.g. in [ 127 ] . The matrix elements of
the operator @xmath contain generic 6 @xmath -symbols, in which none of
the spins is equal to a given, fixed value. The values of such symbols
are precalculated and stored in tables in order to speed up the
computation of the matrix elements of the curvature part.

After the matrices required to form the physical Hamiltonian (or the
operator ( 17.3 ) in the case of the scalar field model) have been
computed, the eigenvalues and eigenvectors of the Hamiltonian can be
approximated using Eqs. ( 17.8 ) and ( 17.9 ). Since the curvature part
of the Hamiltonian is a graph-preserving operator, the unperturbed
eigenvalues and eigenstates entering Eqs. ( 17.8 ) and ( 17.9 ) can be
computed separately within the subspace of each graph. To evaluate the
time dependence of an expectation value under our perturbative
approximation, we then use the (approximate) spectral decomposition of
the time evolution operator,

  -- -------- -- ---------
     @xmath      (17.33)
  -- -------- -- ---------

to write the expectation value of an operator @xmath in the state @xmath
as

  -- -------- -- ---------
     @xmath      (17.34)
  -- -------- -- ---------

For the scalar field model, one should keep in mind that perturbation
theory is applied to approximate the spectrum of the operator ( 17.3 ),
from which the evolution operator will be constructed according to Eq. (
17.10 ).

In the examples we are considering, the operator @xmath is
graph-preserving, while the initial state @xmath is based on a single
graph @xmath containing no special loops. Under these assumptions, some
parts of the corrected state vectors ( 17.9 ) can be discarded, since
they do not contribute to the expectation value ( 17.34 ) at second
order in the perturbative parameter @xmath . For unperturbed eigenstates
based on the initial graph @xmath , one has to take the first-order
correction, and the part of the second-order correction which is based
on @xmath . For unperturbed eigenstates whose graph is @xmath decorated
with a single special loop, it is enough to take the part of the
first-order correction which is based on @xmath ; the second-order
correction can be neglected entirely. Unperturbed eigenstates in which
more than one special loop has been attached to the initial graph do not
contribute to the calculation at second order in @xmath .

### 17.5 Numerical results

#### Perturbation theory

Some sample results of expectation values calculated from Eq. ( 17.34 )
are shown in Figs. 10 – 12 for the scalar field model, and in Figs. 13 –
16 for the dust model ³⁷ ³⁷ 37 The plots displayed in this chapter are
used here with the permission of Mehdi Assanioussi, who created them for
the article [ E ] on the basis of our joint calculations. . We consider
expectation values of the volume and curvature operators, starting from
an initial state which is an eigenstate of the volume operator. The spin
@xmath and the volume eigenvalue @xmath in the initial state are
reported in the caption under each figure. The horizontal axis in each
plot is labeled by the physical time variable @xmath which appears in
the Schrödinger equation ( 17.1 ), and which is given by the value of
the scalar field or the dust field (in units where @xmath ). The
vertical axis is scaled by an appropriate factor of @xmath in order to
factor out the @xmath -dependence of the operator whose expectation
value is shown in the plot. Furthermore, the small embedded plots show
the evolution of the expectation values with respect to a rescaled time
variable, which takes into account the fact that as the value of @xmath
changes, the overall scale of time evolution is affected by the @xmath
-dependent multiplicative factor present in the physical Hamiltonian.
Thus, the rescaled time variable is given by

  -- -------- -- ---------
     @xmath      (17.35)
  -- -------- -- ---------

for the scalar field model, and

  -- -------- -- ---------
     @xmath      (17.36)
  -- -------- -- ---------

in the case of the dust model.

Since the initial state is based on a single graph, and the second-order
approximation to the evolution operator has no non-vanishing matrix
elements between the initial state and states in which more than two
special loops have been attached to the initial state, the expectation
values of volume and curvature are bounded throughout the time evolution
of the initial state. (However, we certainly do not expect the
perturbative treatment to give an accurate approximation for the
evolution of the initial state over arbitrarily long time intervals.)
Given that the expectation values must remain bounded, it is not
surprising to see that they exhibit an oscillatory behaviour as a
function of time. It might be possible to obtain unbounded expectation
values under the perturbative approximation by considering initial
states which take the form of an infinite superposition of states based
on different graphs.

Our numerical calculations show that the degeneracies present in the
spectrum of the volume operator are preserved under time evolution, in
the sense that the function @xmath obtained from an initial state
corresponding to a degenerate eigenvalue remains the same regardless of
which state in the degenerate subspace is chosen as the initial state.
The same statement applies to the curvature operator if one considers
the expectation value @xmath , taking a degenerate eigenstate of
curvature as the initial state. This observation seems to indicate that
whichever symmetry is responsible for the degeneracies in the
eigenvalues of volume and curvature is likely to be a symmetry of the
physical Hamiltonian as well.

Looking at Figs. 14 and 16 for the expectation value of the curvature
operator in the dust model, we see that for larger values of @xmath the
expectation value of curvature remains nearly constant in time. This is
as it should be, since in the limit of large @xmath the physical
Hamiltonian of the dust model reduces to just the curvature operator.

#### Time expansion

In the case of the dust model, we have also investigated the expansion
of expectation values in powers of time, as given by Eqs. ( 17.31 ) and
( 17.32 ). The expansion is taken up to fourth order in time, and a
small selection of the results is shown in Figs. 17 – 19 . The
computation of the coefficients of the expansion from Eq. ( 17.32 )
reveals that only even powers of time enter the expansion of the
expectation values of volume and curvature. The coefficients of the odd
powers ( @xmath and @xmath ) vanish up to numerical rounding error. This
seems to suggest the invariance of the operators involved in the
calculation under an appropriate notion of time reversal. We also find
that the degeneracy in the eigenvalues of volume and curvature is again
preserved under time evolution: The function @xmath (or @xmath ) does
not depend on which eigenstate corresponding to a degenerate eigenvalue
is selected as the initial state.

The range of validity of the time expansion can be determined by
estimating the value of @xmath at which the first term discarded from
the expansion (in our examples, the term of order @xmath ) starts being
comparable in magnitude to the terms included in the approximation. This
criterion can be tested in a toy example in which the Hamiltonian
consists only of the curvature part, and the dynamics can be evaluated
exactly. In this case we find that the criterion correctly predicts the
order of magnitude of the time at which an expectation value computed
from the fourth-order time expansion begins to deviate significantly
from the exact expectation value.

In Fig. 20 we show the time expansion of an expectation value of volume
compared against the same expectation value computed within the
perturbative approach when @xmath . We see that at first the two
approximations agree with each other, but around a certain time the time
expansion starts to diverge from the result of the perturbative
calculation. For this value of @xmath , we expect that perturbation
theory provides an accurate description of the dynamics over a longer
time interval than the time expansion does. Hence, at the time when the
time expansion begins to diverge from the perturbative approximation,
the latter presumably still gives a very close approximation to the
exact expectation value, whereas the former has reached the end of its
range of validity.

### 17.6 Discussion

The central result of this chapter is the observation that for large
values of the Barbero–Immirzi parameter, standard time-independent
perturbation theory can be used to approximately evaluate the dynamics
in deparametrized models, even if an exact spectral decomposition of the
physical Hamiltonian cannot be accomplished. As a sort of supplementary
approximation, we also introduced the expansion in powers of time, which
can be used in the dust model to approximate time evolution over a short
interval of time, even if the value of @xmath is too small for
perturbation theory to be applicable.

The results of our numerical analysis contain several hints of the
existence of a symmetry which is shared by the volume and curvature
operators and the Euclidean part of the Hamiltonian. The degeneracies
present in the spectra of volume and curvature are preserved under time
evolution, the degeneracy in the eigenvalues of the curvature operator
is not removed by the perturbation consisting of the Euclidean part (at
least up to second order in perturbation theory), and only even powers
of time appear in the expansion of expectation values of volume and
curvature when the initial state is an eigenstate of one of the
operators. If this symmetry could be identified and its action on spin
network states understood in detail, this knowledge could immediately be
applied to make the numerical computations more efficient, by separating
the states involved in the computations into subspaces which are
characterized by different eigenvalues of the symmetry operator, and
which are not mixed with each other by the Hamiltonian. A thorough
understanding of the symmetry could even turn out to be useful for the
problem of trying to derive exact eigenvalues and eigenstates of the
Hamiltonian.

In the perturbative treatment of the dynamics, the unperturbed
Hamiltonian is essentially the curvature operator, so it is tempting to
speculate that the perturbative approach might be particularly suitable
for obtaining an accurate approximation for the dynamics in physical
situations where the spatial curvature is large compared to the value of
the observable measured by the Euclidean part of the Hamiltonian. Such a
situation could arise, for instance, in the interior of a collapsing
star at late stages of the collapse, when the value of the curvature is
large enough that quantum effects are expected to become relevant for
the dynamics of the collapse.

Before the approximation methods introduced in this chapter – or any
other approximation schemes possibly established in the future – can be
used to truly investigate the physical content of deparametrized models
of loop quantum gravity, the crucial problem which must be dealt with is
the development of coherent states which have a clear physical
interpretation while being compatible with the structure of the model
under investigation. While the complexifier coherent states discussed in
Chapter 9 have good semiclassical properties with respect to a large
class of operators in loop quantum gravity, they are based on a single
graph, and for this reason are unlikely to be suitable coherent states
for a model in which the dynamics is governed by a graph-changing
Hamiltonian.

Consider a state @xmath peaked on a point @xmath of a classical phase
space. A reasonable requirement for @xmath to be regarded as a ”good”
coherent state is that it behaves under time evolution according to

  -- -------- -- ---------
     @xmath      (17.37)
  -- -------- -- ---------

where @xmath is the classical time evolution of the phase space point
@xmath . In general we should certainly not expect Eq. ( 17.37 ) to hold
as an exact equation, but for macroscopic values of @xmath and @xmath ,
it should be valid up to a small quantum correction over a
macroscopically long interval of time.

However, in the case at hand it seems that if the state @xmath is based
on a fixed graph, and the Hamiltonian acts by creating and removing
special loops, then Eq. ( 17.37 ) cannot hold even approximately, since
the state @xmath will not be based on a fixed graph, but has the form of
a superposition of graphs in which arbitrarily high numbers of special
loops have been attached to the graph of the initial state. It also
seems clear, aside from any dynamical considerations, that a state based
on a fixed graph cannot be a good coherent state even at the kinematical
level for a model in which the Euclidean part of the Hamiltonian is a
graph-changing operator, as the expectation value of the Euclidean part
in the prospective coherent state will be identically zero,
independently of the phase space point on which the state is peaked.

On these grounds we are lead to believe that satisfactory coherent
states for the models considered in this work must not be based on a
fixed graph; rather, they must have the structure of an infinite
superposition of graphs. Possibly such a superposition should start with
a loopless ”seed graph”, and include all the graphs generated by
repeated actions of the Hamiltonian on the seed graph, as illustrated by
Eq. ( 15.30 ). A construction which leads to states having the desired
graph structure has recently been proposed in [ 21 ] , but it has not
yet been established whether the resulting states have any peakedness
properties with respect to the standard operators of loop quantum
gravity.

## 18 A new representation for intertwiners from angular momentum
coherent states

When matrix elements of operators in loop quantum gravity are calculated
in the usual way, using the techniques described in the Appendix to
compute the action of the operator on a spin network state, the results
will be expressed in terms of objects of @xmath recoupling theory, such
as the Wigner @xmath -symbols. While such results provide exact
expressions for the action of operators in the spin network basis, and
are well suited for studying the operators through numerics, it is
difficult to develop any intuitive feel for equations such as ( 16.44 ),
which gives the matrix elements of the curvature operator in terms of a
rather complicated combination of 6 @xmath -symbols.

Motivated by thoughts along these lines, an alternative method for
dealing with calculations in loop quantum gravity was proposed in the
article [ D ] by the author in collaboration with Emanuele Alesci and
Jerzy Lewandowski. This method is based on a new representation for
intertwiners, constructed by expressing the standard spin network states
( 6.1 ) in terms of representation matrices and intertwiners projected
onto angular momentum coherent states – which have been used extensively
as a computational tool in spin foam models, but have so far found
little use in the context of canonical loop quantum gravity.

The new representation provides an alternative approach for computing
matrix elements of operators in loop quantum gravity, in which the heavy
use of @xmath recoupling theory can be avoided. Instead, calculations
are formulated in terms of complex variables, which encode (via the
stereographic projection) the polar angles of the unit vectors labeling
the angular momentum coherent states, and the results of the
calculations can be expressed in a geometrical language, in terms of the
unit vectors themselves. However, as we will see, the work performed in
[ D ] and reviewed in this chapter merely amounts to laying down the
foundations of a new and intriguing framework which can be used for
computations in loop quantum gravity, but which still has to be studied
in much more detail in order to bring out its full potential as a useful
practical tool.

We begin this chapter with a review of the angular momentum coherent
states, which are the essential ingredient for everything that follows.
After these preliminaries, we look at intertwiners projected onto the
basis of coherent states, using them to write down a ”coherent
representation” of a spin network state. We also derive explicit
expressions for the components of three- and four-valent intertwiners
with respect to the coherent state basis. We then show how a
representation of an @xmath -valent intertwiner as a polynomial of
@xmath complex variables can be extracted from the expression of the
intertwiner in the basis of coherent states, and how angular momentum
operators acting on the intertwiner can be formulated as differential
operators acting on these complex variables. Finally, we close our
presentation by discussing the possibility of applying the techniques
developed in this chapter to concrete calculations in loop quantum
gravity.

### 18.1 Angular momentum coherent states

The well-known coherent states of angular momentum [ 101 , 98 ] are the
central tool for the work presented in this chapter. In this section we
will therefore give a thorough review of these states and their most
important properties. Following the conventions of [ 99 ] , we construct
the coherent state @xmath by starting with the state of lowest magnetic
number, @xmath , and applying a rotation which rotates the vector @xmath
into the vector @xmath . Thus, denoting the corresponding @xmath group
element by @xmath and introducing the abbreviation @xmath , we have

  -- -------- -- --------
     @xmath      (18.1)
  -- -------- -- --------

Recalling that the state @xmath is a @xmath -fold tensor product of the
states @xmath , we see that the coherent state ( 18.1 ) can also be
expressed in the form

  -- -------- -- --------
     @xmath      (18.2)
  -- -------- -- --------

where @xmath is the coherent state in the spin-1/2 representation.

By construction, the state @xmath is an eigenstate of the operator
@xmath with eigenvalue @xmath . Moreover, the states ( 18.1 ) form a
basis of the Hilbert space @xmath , as indicated by the resolution of
identity

  -- -------- -- --------
     @xmath      (18.3)
  -- -------- -- --------

where @xmath is the standard measure on the unit sphere. The expectation
value of angular momentum in the state @xmath is given by @xmath , while
the relative uncertainty @xmath is small in the limit of large @xmath .
Therefore, for large values of @xmath , the state @xmath has a
semiclassical interpretation, describing a nearly classical angular
momentum having magnitude @xmath and pointing in the direction @xmath .

The form of the group element @xmath in Eq. ( 18.1 ) is not uniquely
determined by the requirement of rotating the vector @xmath into the
vector @xmath . In order to fix the ambiguity, we specify that the axis
of rotation lies in the @xmath -plane. With this choice, the group
element effecting the rotation is uniquely determined as

  -- -------- -- --------
     @xmath      (18.4)
  -- -------- -- --------

where the vector @xmath lies in the @xmath -plane and is orthogonal to
the vector @xmath .

For practical purposes, it is convenient to introduce the complex
parameter

  -- -------- -- --------
     @xmath      (18.5)
  -- -------- -- --------

which can be used instead of the vector @xmath to label the coherent
states ( 18.1 ) (and which is constructed geometrically by projecting
the point @xmath into the complex plane through the stereographic
projection). When expressed in terms of the parameter @xmath , the group
element ( 18.4 ) becomes

  -- -------- -- --------
     @xmath      (18.6)
  -- -------- -- --------

Furthermore, the resolution of identity ( 18.3 ) takes the form

  -- -------- -- --------
     @xmath      (18.7)
  -- -------- -- --------

where the integration measure is

  -- -------- -- --------
     @xmath      (18.8)
  -- -------- -- --------

For later use, let us note some properties of the matrix @xmath .
Firstly, we see that the inverse matrix is obtained simply by reversing
the sign of the parameter, i.e.

  -- -------- -- --------
     @xmath      (18.9)
  -- -------- -- --------

Furthermore, the matrix associated to the vector @xmath is given by

  -- -------- -- ---------
     @xmath      (18.10)
  -- -------- -- ---------

where @xmath is the parameter corresponding to the vector @xmath .
Finally, the composition law of the group elements @xmath (derived
straightforwardly by carrying out the matrix multiplication) reads

  -- -------- -- ---------
     @xmath      (18.11)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (18.12)
  -- -------- -- ---------

Incidentally, this result shows that the action of the matrix @xmath on
an angular momentum coherent state produces another coherent state, but
generally multiplied with a phase factor.

We can derive an alternative expression for the group element ( 18.6 )
by using the fact that a general element of @xmath can be decomposed as
³⁸ ³⁸ 38 Eq. ( 18.13 ) is easily verified by matrix multiplication in
the fundamental representation, in which the components of the angular
momentum operator are represented by

@xmath

Note that in general, none of the matrices on the right-hand side of Eq.
( 18.13 ) belong to @xmath , though they are elements of @xmath .

  -- -------- -- ---------
     @xmath      (18.13)
  -- -------- -- ---------

where the parameters are given by

  -- -------- -- ---------
     @xmath      (18.14)
  -- -------- -- ---------

Applying Eq. ( 18.13 ) to Eq. ( 18.6 ), we obtain

  -- -------- -- ---------
     @xmath      (18.15)
  -- -------- -- ---------

Consequently, since the operator @xmath annihilates the state @xmath ,
we find the expression

  -- -------- -- ---------
     @xmath      (18.16)
  -- -------- -- ---------

for the coherent state @xmath .

Eqs. ( 18.2 ) and ( 18.16 ) are very useful in practical calculations
involving angular momentum coherent states. For example, using the
tensor product property ( 18.2 ), the scalar product between two
coherent states is immediately found to be

  -- -------- -- ---------
     @xmath      (18.17)
  -- -------- -- ---------

In terms of the vectors @xmath , we have

  -- -------- -- ---------
     @xmath      (18.18)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (18.19)
  -- -------- -- ---------

According to [ 99 ] , @xmath has a geometrical interpretation as
one-half of the (oriented) area of the spherical triangle spanned by the
vectors @xmath , @xmath and @xmath .

With the help of Eq. ( 18.16 ), we may also derive the matrix elements
of the angular momentum operator between the states @xmath . For the
calculation, it is convenient to use the unnormalized states

  -- -------- -- ---------
     @xmath      (18.20)
  -- -------- -- ---------

for which we have

  -- -------- -- ---------
     @xmath      (18.21)
  -- -------- -- ---------

To find the matrix element of @xmath , we consider

  -- -------- -- ---------
     @xmath      (18.22)
  -- -------- -- ---------

Expanding both sides to first order in @xmath , we see that

  -- -------- -- ---------
     @xmath      (18.23)
  -- -------- -- ---------

In the same way, we find

  -- -------- -- ---------
     @xmath      (18.24)
  -- -------- -- ---------

The derivation of the matrix element of @xmath is less straightforward,
but can be accomplished by considering the identity

  -- -------- -- ---------
     @xmath      (18.25)
  -- -------- -- ---------

According to the Baker–Campbell–Hausdorff formula, we have

  -- -------- -- ---------
     @xmath      (18.26)
  -- -------- -- ---------

where @xmath and the terms represented by the dots contain the
commutator @xmath and therefore vanish identically. It follows that

  -- -------- -- ---------
     @xmath      (18.27)
  -- -------- -- ---------

from which we deduce

  -- -------- -- ---------
     @xmath      (18.28)
  -- -------- -- ---------

Summarizing our findings, and expressing them in terms of the normalized
states @xmath , we have shown that

  -- -------- -------- -- ----------
                          
     @xmath   @xmath      (18.29a)
     @xmath   @xmath      (18.29b)
     @xmath   @xmath      (18.29c)
  -- -------- -------- -- ----------

### 18.2 Intertwiners in the basis of coherent states

For the remainder of this chapter, our interest will be focused on the
object

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (18.30)
  -- -------- -------- -- ---------

By construction, the complex conjugates of the numbers @xmath give the
projections of the intertwiner @xmath onto the angular momentum coherent
state basis of @xmath . These numbers appear when a spin network state
@xmath of the familiar form ( 6.1 ) is transformed into what could be
called a coherent representation of the spin network, by using the
resolution of identity @xmath on @xmath instead of @xmath to trade each
sum over a magnetic index for an integration over a corresponding
complex variable. In this way, the spin network state becomes expressed
in the form

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (18.31)
  -- -------- -------- -- ---------

where @xmath are the matrix elements of the Wigner matrix with respect
to the coherent state basis of @xmath , and the intertwiner @xmath at
each node of the graph is likewise projected onto the coherent state
basis of the space @xmath .

A secondary interpretation of the object ( 18.30 ) can be brought out by
considering the Livine–Speziale coherent intertwiner

  -- -------- -- ---------
     @xmath      (18.32)
  -- -------- -- ---------

The coherent intertwiner can be expanded in some standard basis @xmath
of the @xmath -valent intertwiner space as

  -- -------- -- ---------
     @xmath      (18.33)
  -- -------- -- ---------

Keeping in mind the identity ( B.40 ), a short calculation shows that
the coefficients of the expansion are given by

  -- -------- -- ---------
     @xmath      (18.34)
  -- -------- -- ---------

Hence @xmath can also be interpreted as the projection of the coherent
intertwiner @xmath onto the intertwiner @xmath . A yet another
interpretation of @xmath will be discussed in section 18.4 .

#### The three-valent intertwiner

We will now derive explicit expressions for the object ( 18.30 ) in the
case of three- and four-valent intertwiners. Let us start with the
three-valent case, where we must consider the object

  -- -------- -- ---------
     @xmath      (18.35)
  -- -------- -- ---------

In order to tackle the calculation indicated by Eq. ( 18.35 ), it is
convenient to pass to the realization of the spin- @xmath representation
of @xmath as a completely symmetrized tensor product of @xmath copies of
the fundamental representation (see sections A.3 and B.6 ). In this
realization, a magnetic index in the spin- @xmath representation
corresponds to a symmetrized group of @xmath spinor indices, @xmath .
The representation matrix @xmath has the form ( A.72 ), namely

  -- -------- -- ---------
     @xmath      (18.36)
  -- -------- -- ---------

In particular, when the second index takes its minimal value,

  -- -------- -- ---------
     @xmath      (18.37)
  -- -------- -- ---------

The components of the three-valent intertwiner with respect to the
magnetic basis are given in explicit form by Eq. ( B.57 ). We have

  -- -------- -- ---------
     @xmath      (18.38)
  -- -------- -- ---------

with

  -- -------- -- ---------
     @xmath      (18.39)
  -- -------- -- ---------

where @xmath , @xmath and @xmath , and the normalization factor @xmath
has the value ( B.59 ).

Using now Eqs. ( 18.37 ) and ( 18.38 ) in Eq. ( 18.35 ), we immediately
obtain

  -- -------- -- ---------
     @xmath      (18.40)
  -- -------- -- ---------

where we have introduced the notation

  -- -------- -- ---------
     @xmath      (18.41)
  -- -------- -- ---------

Recalling the form of the matrix @xmath from Eq. ( 18.6 ), we see that

  -- -------- -- ---------
     @xmath      (18.42)
  -- -------- -- ---------

Hence we have found the expression

  -- -------- -- ---------
     @xmath      (18.43)
  -- -------- -- ---------

for the components of the three-valent intertwiner with respect to the
coherent-state basis.

An important property of the object ( 18.43 ) can be inferred from the
work of Livine and Speziale concerning the behaviour of the coherent
intertwiner ( 18.32 ) in the limit of large spins. As shown in [ 94 ] ,
for large values of @xmath , the norm of the intertwiner ( 18.32 ) is
exponentially small in @xmath , unless the vectors @xmath satisfy the
closure condition @xmath (in which case the norm of the coherent
intertwiner depends on @xmath through a power law). On the other hand,
if we consider ( 18.43 ) as a function of the vectors @xmath
corresponding to the parameters @xmath , then Eqs. ( 18.33 ) and ( 18.34
) show that the absolute value of ( 18.43 ) gives the norm of the
three-valent coherent intertwiner @xmath . Hence it follows that for
large spins, the magnitude of ( 18.43 ) is peaked on configurations
satisfying @xmath , and is exponentially suppressed when the closure
condition is not fulfilled.

#### Four-valent intertwiners

In the case of the four-valent intertwiner, we again start by recalling
the expression of the intertwiner in the symmetric tensor product
representation. From Eq. ( B.60 ),

  -- -------- -- ---------
     @xmath      (18.44)
  -- -------- -- ---------

where the horizontal bar denotes a complete symmetrization of the
internal group of lines. When the above expression is contracted with
@xmath according to Eq. ( 18.30 ), each of the @xmath blue lines
contributes a factor of @xmath , while each of the @xmath red lines
contributes a @xmath . Keeping in mind the symmetrization, the
contribution of the green lines has the form

  -- -------- -- ---------
     @xmath      (18.45)
  -- -------- -- ---------

where @xmath stands for the number of lines running from external spin
@xmath to @xmath , and @xmath is the number of different ways of
arranging the green lines for fixed values of the @xmath . The sum is
taken over those values of the @xmath that satisfy the constraints

  -- -------- -------- -- ----------
                          
     @xmath   @xmath      (18.46a)
     @xmath   @xmath      (18.46b)
     @xmath   @xmath      (18.46c)
     @xmath   @xmath      (18.46d)
  -- -------- -------- -- ----------

which reduce the summation in Eq. ( 18.45 ) to one independent sum.
Finally, the overall normalization factor @xmath should be adjusted so
that the symmetrization over the internal group of lines is performed
with total weight 1. The values of @xmath and @xmath can be determined
by a straightforward combinatorial counting, eventually yielding the
result

  -- -------- -- ---------
     @xmath      (18.47)
  -- -------- -- ---------

where

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (18.48)
  -- -------- -------- -- ---------

the sum running over all values of @xmath for which all the factorials
in the binomial coefficients have non-negative arguments.

In principle, the method described above could be used to derive the
components of an intertwiner of any valence with respect to the coherent
state basis, though the calculations would rapidly become more and more
tedious with increasing valence. However, considering that an
appropriate generalization of Eq. ( 18.44 ) holds for intertwiners of
higher valence as well, it is clear even without any detailed
calculations that the components of the @xmath -valent intertwiner will
always have the general structure

  -- -------- -- ---------
     @xmath      (18.49)
  -- -------- -- ---------

where the function @xmath is a polynomial of order @xmath in each
variable @xmath , and depends on its arguments only through the
differences @xmath .

#### Raising and lowering indices

The calculations which have lead to Eqs. ( 18.43 ), ( 18.47 ) and (
18.49 ) apply as such only to intertwiners having only lower indices. To
complete our discussion of intertwiners in the basis of coherent states,
we must therefore consider how the ”indices” @xmath can be raised and
lowered in this basis. This is necessary, for example, for a consistent
contraction of indices in equations such as ( 18.31 ).

To derive the rule for raising an index in the coherent state basis, we
may compute the projection of

  -- -------- -- ---------
     @xmath      (18.50)
  -- -------- -- ---------

(with @xmath ) onto the state @xmath . In this way we find the expected
result,

  -- -------- -- ---------
     @xmath      (18.51)
  -- -------- -- ---------

where @xmath are the components of the epsilon tensor with respect to
the coherent state basis, i.e.

  -- -------- -- ---------
     @xmath      (18.52)
  -- -------- -- ---------

Inserting the explicit expression ( 18.49 ) for the intertwiner @xmath ,
the integral ( 18.51 ) can now be evaluated using the identity ( 18.58
). This yields the result

  -- -------- -- ---------
     @xmath      (18.53)
  -- -------- -- ---------

which can be alternatively be written in the form

  -- -------- -- ---------
     @xmath      (18.54)
  -- -------- -- ---------

Comparing with Eq. ( 18.10 ), we see that if we consider the object (
18.49 ) as a function of the vectors @xmath , then raising an index
@xmath amounts to replacing the corresponding vector @xmath with @xmath
and adjusting the phase by @xmath .

### 18.3 The complex polynomial representation of @xmath

Our next goal in this chapter will be to explain how the polynomial
@xmath in Eq. ( 18.49 ) can itself be regarded as a representation of
the intertwiner @xmath , and how angular momentum operators acting on
the intertwiner can be formulated as differential operators acting on
the variables @xmath . The key point underlying this interpretation is
the fact that the spin- @xmath representation of @xmath can be realized
on the space of polynomials of degree @xmath in a single complex
variable (see e.g. [ 99 ] ). Below we will recall the main properties of
the polynomial representation of @xmath .

Let @xmath denote the space of polynomials of degree @xmath in a complex
variable @xmath . Thus, a general element of @xmath has the form @xmath
. A scalar product on @xmath can be defined as

  -- -------- -- ---------
     @xmath      (18.55)
  -- -------- -- ---------

where the integration measure is

  -- -------- -- ---------
     @xmath      (18.56)
  -- -------- -- ---------

with @xmath the measure defined by Eq. ( 18.8 ). The monomials

  -- -------- -- ---------
     @xmath      (18.57)
  -- -------- -- ---------

where the label @xmath takes the values @xmath , form a basis on @xmath
, orthonormal under the scalar product ( 18.55 ). As an immediate
consequence of the orthonormality of the functions ( 18.57 ), we have
the useful identity

  -- -------- -- ---------
     @xmath      (18.58)
  -- -------- -- ---------

which holds for all functions @xmath .

A representation of @xmath on the space @xmath can now be defined by
declaring the action of the group element @xmath on a function @xmath to
be

  -- -------- -- ---------
     @xmath      (18.59)
  -- -------- -- ---------

In fact, this definition can be extended to the group @xmath . For
@xmath , the assignment

  -- -------- -- ---------
     @xmath      (18.60)
  -- -------- -- ---------

defines a representation of @xmath on @xmath .

To find the form of the angular momentum operator on the space @xmath ,
we can use Eq. ( 18.60 ) to calculate the action of the @xmath matrices
@xmath on a function @xmath . Considering for example the operator
@xmath , we have

  -- -------- -- ---------
     @xmath      (18.61)
  -- -------- -- ---------

Expanding both sides to first order in @xmath then reveals that

  -- -------- -- ---------
     @xmath      (18.62)
  -- -------- -- ---------

By similar calculations one finds

  -- -------- -- ---------
     @xmath      (18.63)
  -- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (18.64)
  -- -------- -- ---------

We note that the function @xmath of Eq. ( 18.57 ) is an eigenstate of
the operator @xmath with eigenvalue @xmath , and hence corresponds to
the state @xmath in the realization of the spin- @xmath representation
normally used in physics.

Before concluding our review of the polynomial representation of @xmath
, let us write down the angular momentum coherent state @xmath as an
element of the space @xmath . Using Eqs. ( 18.16 ) and ( 18.60 ), and
observing that the state @xmath corresponds to the function @xmath in
@xmath , we see that

  -- -------- -- ---------
     @xmath      (18.65)
  -- -------- -- ---------

Hence the polynomial representing the unnormalized coherent state @xmath
of Eq. ( 18.20 ) is simply @xmath . Furthermore, recalling that the
scalar product between the states @xmath is given by @xmath , the
integration formula ( 18.58 ) may be written as

  -- -------- -- ---------
     @xmath      (18.66)
  -- -------- -- ---------

showing that the scalar product @xmath acts as a so-called ”reproducing
kernel” (see e.g. [ 76 ] ). Finally, by inspecting the matrix elements
of the angular momentum operator in the basis of angular momentum
coherent states, summarized in Eqs. ( 18.29 ), we see that the matrix
elements between the unnormalized states @xmath can be expressed in the
form

  -- -------- -- ---------
     @xmath      (18.67)
  -- -------- -- ---------

where @xmath (with @xmath ) denotes any of the differential operators (
18.62 )–( 18.64 ) acting on the variable @xmath in the function @xmath .

#### Example: A polynomial calculation of the coherent 3@xmath-symbol

As an example of working with the polynomial representation of @xmath ,
we will use it to compute the ”coherent 3 @xmath -symbol” defined by Eq.
( 18.35 ), following a similar calculation made in [ 30 ] for the
Clebsch–Gordan coefficient. Besides serving as an example of using the
polynomial formalism, the calculation given below also provides an
independent derivation of Eq. ( 18.43 ), which is one of the main
results of this chapter.

Using the @xmath -invariance of the standard 3 @xmath -symbol, Eq. (
18.35 ) can be rewritten as

  -- -------- -- ---------
     @xmath      (18.68)
  -- -------- -- ---------

where @xmath is shorthand for @xmath . The products of coherent state
rotations in Eq. ( 18.68 ) can be computed by means of Eqs. ( 18.9 ) and
( 18.11 ). If we then introduce the state

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (18.69)
  -- -------- -------- -- ---------

which (up to a numerical factor) is the state of total angular momentum
@xmath and maximal magnetic number @xmath constructed from the angular
momenta @xmath and @xmath , we can cast Eq. ( 18.68 ) in the form

  -- -------- -- ---------
     @xmath      (18.70)
  -- -------- -- ---------

where

  -- -------- -- ---------
     @xmath      (18.71)
  -- -------- -- ---------

and @xmath and @xmath are defined similarly.

From here on, our strategy will be to express the states @xmath and
@xmath as polynomials in the space @xmath , after which their scalar
product in Eq. ( 18.70 ) can be computed using Eq. ( 18.55 ) for the
scalar product in @xmath . The representation of the coherent states as
polynomials is given by Eq. ( 18.65 ). To find the state @xmath in
polynomial form, we write the defining equations of the state @xmath ,

  -- -------- -- ---------
     @xmath      (18.72)
  -- -------- -- ---------

as differential equations for a function @xmath in @xmath , using the
representation of the angular momentum operators from Eqs. ( 18.62 )–(
18.64 ). These equations are

  -- -------- -- ---------
     @xmath      (18.73)
     @xmath      (18.74)
  -- -------- -- ---------

We look for the solution of these equations by introducing the ansatz

  -- -------- -- ---------
     @xmath      (18.75)
  -- -------- -- ---------

where @xmath is a polynomial of order @xmath in @xmath and @xmath .
Inserting this into Eq. ( 18.73 ), and using the fact that the operator
@xmath annihilates the function @xmath , we find that @xmath satisfies
the equation

  -- -------- -- ---------
     @xmath      (18.76)
  -- -------- -- ---------

or, changing variables from @xmath to @xmath ,

  -- -------- -- ---------
     @xmath      (18.77)
  -- -------- -- ---------

This shows that the function @xmath depends on its arguments only
through their difference, i.e. @xmath . It follows that the function
@xmath has the form

  -- -------- -- ---------
     @xmath      (18.78)
  -- -------- -- ---------

Inserting this into Eq. ( 18.74 ), we obtain

  -- -------- -- ---------
     @xmath      (18.79)
  -- -------- -- ---------

where @xmath denotes the derivative of @xmath with respect to its single
argument. From this we see that @xmath , and so

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (18.80)
  -- -------- -------- -- ---------

By evaluating the integral @xmath , the value of the normalization
constant is determined to be @xmath , with @xmath defined by Eq. ( B.59
). (The phase of the constant is fixed by the Condon–Shortley
convention, according to which the Clebsch–Gordan coefficient @xmath –
equivalently, the coefficient of @xmath in the expansion of the function
@xmath – should be real and positive.)

As a result of the above calculation, we have found that the polynomial
@xmath representing the state @xmath of Eq. ( 18.69 ) as an element of
@xmath is given by

  -- -------- -- ---------
     @xmath      (18.81)
  -- -------- -- ---------

The scalar product @xmath appearing in Eq. ( 18.70 ) can then be
computed as

  -- -------- -- ---------
     @xmath      
     @xmath      
     @xmath      (18.82)
  -- -------- -- ---------

The factor multiplying @xmath in the integrand is a polynomial of order
@xmath and @xmath in @xmath and @xmath . Therefore, after changing the
variables of integration from @xmath and @xmath to @xmath and @xmath ,
the integral can be evaluated immediately by means of Eq. ( 18.58 ),
leading to

  -- -------- -- ---------
     @xmath      (18.83)
  -- -------- -- ---------

When this is inserted into Eq. ( 18.70 ), and the result expressed in
terms of @xmath , @xmath and @xmath using Eq. ( 18.71 ), we reproduce
Eq. ( 18.43 ) for the coherent-state components of the three-valent
intertwiner.

### 18.4 Intertwiners as complex polynomials

With the preliminaries of the previous section, we are now ready to show
how a polynomial representation of an intertwiner can be extracted from
the explicit expression ( 18.49 ) for the components of the intertwiner
with respect to the coherent state basis. We will demonstrate that the
action of the angular momentum operator on the intertwiner can be
formulated as an action on the polynomial @xmath in Eq. ( 18.49 ) by the
differential operators Eqs. ( 18.62 )–( 18.64 ), which represent the
angular momentum operator as an operator on @xmath . On grounds of this
result, the polynomial @xmath can indeed be interpreted as representing
the intertwiner @xmath as an element of @xmath .

For clarity, let us start by considering a single angular momentum
operator acting on the @xmath -th spin of an intertwiner @xmath . The
state @xmath can be expanded in the basis of coherent states on @xmath
as

  -- -------- -- ---------
     @xmath      (18.84)
  -- -------- -- ---------

Letting the operator @xmath act on @xmath , and projecting the resulting
state on the basis element @xmath , we obtain

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      (18.85)
  -- -------- -------- -- ---------

To perform the integral, we rewrite the integrand in terms of the
unnormalized states @xmath , recalling from Eq. ( 18.67 ) that @xmath .
We then write @xmath , and change the variables of integration from
@xmath to their complex conjugates, leading to

  -- -------- -- ---------
     @xmath      
     @xmath      (18.86)
  -- -------- -- ---------

where the integration measure @xmath of Eq. ( 18.56 ) has naturally
appeared. Now, taking into account the ”reproducing kernel” property (
18.66 ), we see immediately that the integral in the above equation is
equal to @xmath . We have therefore found

  -- -------- -- ---------
     @xmath      (18.87)
  -- -------- -- ---------

A similar calculation can be made to show that for any operator @xmath ,
constructed from the angular momentum operators @xmath by a power series
expansion, we have

  -- -------- -- ---------
     @xmath      (18.88)
  -- -------- -- ---------

Thus we have shown that the action of the angular momentum operator on
the state @xmath translates to an action on the polynomial @xmath by the
representation of the angular momentum operator as a differential
operator on the space @xmath . This result guarantees that we can
consistently interpret @xmath as the polynomial representing the
intertwiner @xmath as an element of @xmath . We should note that under
such an interpretation, the variable @xmath is to be regarded merely as
an abstract variable, whose first @xmath powers span the space @xmath ,
and it no longer plays a role as a parameter specifying the direction of
a unit vector @xmath .

### 18.5 Application to calculations in loop quantum gravity

The results developed in this chapter can be used in loop quantum
gravity to set up an alternative approach towards analyzing the matrix
elements of operators (such as the Hamiltonian), in which spin network
states are expressed in the ”coherent representation” of Eq. ( 18.31 ),
and the action of angular momentum operators on intertwiners is
formulated as the action of differential operators on the polynomials
@xmath . This makes it possible to compute matrix elements of operators
in the spin network basis in a way which largely bypasses the use of
@xmath recoupling theory, and to describe the action of the operator
geometrically, in terms of the complex parameters @xmath and the
geometry of the associated unit vectors @xmath – as opposed to
expressions which involve combinations of 6 @xmath - and 9 @xmath
-symbols, and to which it is difficult to assign any immediate geometric
or otherwise intuitive meaning.

As a concrete example of applying the techniques of this chapter to loop
quantum gravity, let us consider the Euclidean operator

  -- -------- -- ---------
     @xmath      (18.89)
  -- -------- -- ---------

The matrix elements of this operator were computed in section 16.1 using
the standard basis of magnetic indices, in which the action of the
operator on an intertwiner @xmath produces a new intertwiner of the form
@xmath . The two new indices of the intertwiner are contracted with the
indices of the holonomy @xmath created by the action of the operator.

Similarly, in the coherent state basis the action of @xmath on an
intertwiner @xmath produces the intertwiner

  -- -------- -- ---------
     @xmath      (18.90)
  -- -------- -- ---------

where the indices @xmath and @xmath are eventually contracted with the
indices of the holonomy @xmath by the integral @xmath . According to Eq.
( 18.49 ) – and recalling from Eq. ( 18.51 ) that the variable
corresponding to an upper index of the intertwiner enters the polynomial
@xmath as a complex conjugate – the intertwiner ( 18.90 ) has the
general form

  -- -------- -- ---------
     @xmath      (18.91)
  -- -------- -- ---------

where @xmath is the polynomial representing the intertwiner @xmath as an
element of the space @xmath .

In order to derive an expression for the polynomial @xmath , we use Eqs.
( 18.62 )–( 18.64 ) for the angular momentum operator, and Eqs. ( 18.29
) for the matrix elements @xmath , to translate the operator ( 18.89 )
into a differential operator acting on the polynomial @xmath .
Introducing the abbreviations @xmath and @xmath , we find

  -- -------- -------- -- ---------
     @xmath   @xmath      
              @xmath      
              @xmath      (18.92)
  -- -------- -------- -- ---------

On a general level, we cannot make the result given by Eqs. ( 18.91 )
and ( 18.92 ) any more explicit, since we lack a general expression for
the polynomial @xmath in the @xmath -valent case. Let us therefore
specialize to consider the action of the operator @xmath on a
three-valent intertwiner. The polynomial @xmath representing the
three-valent intertwiner can be read off from Eq. ( 18.43 ) as

  -- -------- -- ---------
     @xmath      (18.93)
  -- -------- -- ---------

Then, denoting @xmath and @xmath , the derivatives involved in Eq. (
18.92 ) can be written as

  -- -------- -------- -- ---------
     @xmath   @xmath      (18.94)
     @xmath   @xmath      (18.95)
  -- -------- -------- -- ---------

and

  -- -------- -- ---------
     @xmath      (18.96)
  -- -------- -- ---------

The form of these derivatives suggests to express the components of the
intertwiner @xmath , given by Eq. ( 18.91 ), by factoring out the
component of the original intertwiner, @xmath . We can additionally
separate the factor @xmath , which, up to a phase, is equal to @xmath ,
where @xmath and @xmath are the unit vectors corresponding to the
variables @xmath and @xmath . After these factors have been pulled out,
let us denote the remainder on the right-hand side of Eq. ( 18.91 ) as
@xmath . In this way we have expressed the components of the new
intertwiner in the form

  -- -------- -- ---------
     @xmath      (18.97)
  -- -------- -- ---------

The explicit expression of the function @xmath is not particularly
enlightening, but in principle it could be determined by inserting Eqs.
( 18.94 )–( 18.96 ) into the right-hand side of Eq. ( 18.92 ).

In the limit of large spins, the expression ( 18.97 ) has the following
structure in terms of the unit vectors associated to the variables
@xmath and @xmath . As argued in section 18.2 , the coherent 3 @xmath
-symbol in Eq. ( 18.97 ) is exponentially suppressed unless the vectors
@xmath corresponding to the parameters @xmath satisfy the closure
condition @xmath . Similarly, if we also assume the spin @xmath
belonging to the loop created by the Hamiltonian to be large, the factor
@xmath forces the vectors @xmath and @xmath to be parallel to each
other. Hence it follows that the magnitude of the intertwiner ( 18.97 )
is peaked on configurations in which its five vectors satisfy the
closure condition in the form @xmath (in general, each vector associated
to an upper index of the intertwiner should be counted in the closure
condition with a negative sign).

If we assume that the vectors @xmath , @xmath and @xmath close, and that
@xmath , we can look at the function @xmath to determine the preferred
orientation of the vector @xmath relative to the vectors @xmath .
Figuratively speaking, @xmath can be thought of as a sort of probability
amplitude for the vector @xmath to point in a given direction, for a
fixed orientation of the vectors @xmath , @xmath and @xmath .

As a first example, let us consider the case in which the spins @xmath ,
@xmath and @xmath are all equal to a common value @xmath . Choosing
@xmath , @xmath and @xmath , we find that the absolute value of the
function @xmath is given in terms of the polar angles of the vector
@xmath as

  -- -------- -- ---------
     @xmath      (18.98)
  -- -------- -- ---------

We see that this function reaches its maximum value at the points @xmath
and @xmath , corresponding to @xmath and @xmath . In other words, we
have found that the preferred orientation of the vector @xmath is
orthogonal to the plane spanned by the vectors @xmath , @xmath and
@xmath . In the large-spin limit, this conclusion is independent of the
values of the spins @xmath and @xmath , since at leading order the
magnitude of @xmath depends on the spins only through an overall
multiplicative factor.

To give another example, we examine the case @xmath and @xmath . To
satisfy the closure condition of the vectors @xmath , we now fix @xmath
, @xmath and @xmath . The resulting expression for @xmath is rather
complicated and not very easy to study analytically, so we show in Fig.
21 a numerical plot of @xmath (which is independent of @xmath and @xmath
at leading order). Locating the maxima of @xmath in the plot, we see
that the preferred orientation of the vector @xmath is again
perpendicular to the plane of the vectors @xmath , @xmath and @xmath .

When considering the integral

  -- -------- -- ---------
     @xmath      (18.99)
  -- -------- -- ---------

which represents the complete result of acting with the operator ( 18.89
) on a three-valent intertwiner in the coherent representation, it is
important to realize the following: While a distinguished orientation of
the vector @xmath has indeed emerged from the function @xmath in the
above examples, the preference for the distinguished orientation is not
very strong, in the sense that the peak of @xmath around the maximum is
rather wide. Most importantly, the width of the peak is essentially
independent of the spins involved in the calculation, and so the peak
remains wide even in the limit of large spins – in contrast to, say, the
peak in the norm of the Livine–Speziale intertwiner, which becomes more
and more narrow as the value of @xmath increases. Therefore, even if one
of the integrals in Eq. ( 18.99 ) could be dealt with by a suitable
saddle point approximation, based on the observation that the second
factor on the right-hand side of Eq. ( 18.97 ) is peaked on the parallel
configuration of the vectors @xmath and @xmath , it seems unlikely that
the remaining integral could be approximated in a similar way.

It seems reasonable to hope that the situation would be better if one
would use the coherent representation described in this chapter to study
the action of operators on coherent intertwiners, rather than standard
intertwiners which are merely expressed in the coherent representation.
In this way one could potentially see some interesting and non-trivial
interplay between the vectors labeling the coherent intertwiner, and the
vectors associated to the complex variables @xmath of the coherent
representation. Provided that an explicit and sufficiently manageable
expression can be found for the coherent intertwiner in the form ( 18.49
), making a detailed investigation of coherent intertwiners in the
coherent representation would be an interesting topic for future work.

In any case, the work presented in the article [ D ] and reviewed in
this chapter can be seen merely as a demonstration that there exists an
alternative framework, based on projecting intertwiners onto the basis
of angular momentum coherent states, which can be used for performing
calculations with the Hamiltonian and other loop quantum gravity
operators. More work must be done in order to understand the extent to
which this formalism is a useful computational tool for loop quantum
gravity, and whether it can be used to obtain a clear, geometrical
understanding of the action of the Hamiltonian on spin network states,
and consequently to perform a systematic analysis of the dynamics.

@xmath

Conclusions

  Consider, then, the sum total of our accumulated knowledge as
  constituting an island, which I call the ”Island of Knowledge.” (…) A
  vast ocean surrounds the Island of Knowledge, the unexplored ocean of
  the unknown, hiding countless tantalizing mysteries. (…) As the Island
  of Knowledge grows, so do the shores of our ignorance – the boundary
  between the known and the unknown. Learning more about the world
  doesn’t lead to a point closer to a final destination – whose
  existence is nothing but a hopeful assumption anyways – but to more
  questions and mysteries. The more we know, the more exposed we are to
  our ignorance, and the more we know to ask.

  – Marcelo Gleiser

### Summary of results

The central theme of this work has been the issue of finding a
satisfactory formulation of the dynamics for canonical loop quantum
gravity. This problem was considered particularly in the context of
deparametrized models, in which a scalar field is used as a relational
time variable for the dynamics of the quantized gravitational field.
Accordingly, one of the main results presented was the introduction of a
new Hamiltonian operator (more precisely, a class of Hamiltonian
operators) for loop quantum gravity. These operators were constructed
specifically for the purpose of serving as a physical Hamiltonian in the
deparametrized framework, even though it can also be used as the
Hamiltonian constraint operator in the fully constrained theory.

Our construction of the Hamiltonian enjoys two important advantages over
proposals which have been available in the literature so far. Firstly,
by regularizing the Euclidean part of the Hamiltonian in terms of the
so-called special loops, we ensure that the adjoint of the Euclidean
operator is a densely defined operator on the space of diffeomorphism
invariant states, and hence the Hamiltonian can be consistently defined
as a symmetric operator. While the question of the eventual
self-adjointness of the Hamiltonian is still open, having a symmetric
Hamiltonian is of course a necessary requirement for the operator to be
a mathematically consistent candidate for the generator of unitary
physical time evolution.

The other novel feature which characterizes our Hamiltonian is the use
of the scalar curvature of the spatial surface in place of the
traditional Lorentzian part of the Hamiltonian. This leads to a
considerable simplification in the structure of the operator, and
therefore offers a very substantial practical advantage. We recall that
the Lorentzian part of Thiemann’s Hamiltonian is composed of several
factors of holonomies, volume operators and Euclidean operators. In
contrast, the complexity of the curvature operator is not substantially
higher than that of a single volume operator.

Having completed the definition of the Hamiltonian, we moved on to
consider the problem of calculating with the operator. We began by
showing how the matrix elements of the operators out of which the
Hamiltonian is constructed can be computed in explicit form in the spin
network basis, even if it is difficult to develop any intuitive grasp
for the physical significance of the resulting expressions. The
essential tool, which enables us to carry out the calculations with
relatively little difficulty, is the powerful graphical formalism
designed for computations involving @xmath recoupling theory.

As far as working with the Hamiltonian is concerned, an important
element of our work is the development of elementary approximation
methods, which can be used to study the time evolution of spin network
states in deparametrized models even if an exact solution to the
eigenvalue problem of the physical Hamiltonian is not available. In
particular, due to the relatively simple form of the curvature operator,
a viable strategy is to consider the more complicated Euclidean part of
the Hamiltonian as a perturbation over the curvature part. Standard
time-independent perturbation theory can then be used to approximate the
spectrum of the complete Hamiltonian in terms of the eigenvalues and
eigenstates of the curvature operator. (Even if the spectrum of the
curvature operator cannot be accessed analytically, it is
straightforward to compute the eigenvalues and eigenstates numerically
within the intertwiner space of a given, not too complicated node.)

The perturbative treatment of the Hamiltonian seems to require that the
Barbero–Immirzi parameter has a sufficiently large value, since it is
only in this case that the Euclidean part of the Hamiltonian is
multiplied with a small numerical parameter relative to the curvature
part. It seems reasonable to expect that the perturbative approach could
also be used, regardless of the value of @xmath , in physical situations
where the value of the spatial curvature is large in comparison to the
value of the observable corresponding to the Euclidean operator.
However, for now this remark is not a concrete proposition, but merely
an interesting speculation, since we are not able to write down states
which would be peaked on desired values of the curvature operator and
the Euclidean operator.

Even when perturbation theory is not applicable, there is still
available the primitive approach of computing time evolution over a
short time interval simply by expanding the quantity of interest in
powers of the time variable and evaluating the coefficients of the
expansion. However, this method can be used only for the non-rotational
dust model, since the square root present in the physical Hamiltonian of
the free scalar field model makes it impossible to compute the action of
the Hamiltonian unless the spectrum of the operator under the square
root is known.

The last one among the results presented in this thesis was the
introduction of a new description of intertwiners in loop quantum
gravity. The new representation is constructed by projecting
intertwiners onto the basis of angular momentum coherent states, rather
than the conventional basis of magnetic indices. This line of
development leads naturally to a description in which intertwiners are
represented as polynomials of certain complex variables (which originate
from the parametrization of the unit vectors labeling the coherent
states by means of the stereographic projection), and the usual
operators of loop quantum gravity are formulated as differential
operators acting on these complex variables.

The primary motivation behind this work is the possibility that the
formalism could be used to describe the action of the Hamiltonian in a
more transparent, geometric language, in terms of the unit vectors which
parametrize the angular momentum coherent states, and which play the
role of a sort of ”magnetic indices” in the new representation. The
example of the Euclidean operator acting on a three-valent intertwiner
shows that there is indeed a preferred relation between the two vectors
”created” by the action of the operator and the three vectors belonging
to the original intertwiner. However, the matrix element is not very
sharply peaked on the preferred configuration of the vectors, not even
in the limit of large spins, so the result is not as useful as one could
have hoped. The situation might be better if we considered the action of
the Hamiltonian on coherent intertwiners, which themselves contain
geometrical information encoded in spins and unit vectors. However, such
a calculation would require a manageable expression for the coherent
intertwiner as a polynomial, which we currently do not have.

In principle, our construction of the Hamiltonian completes the
definition of a class of mathematically consistent models of loop
quantum gravity, in which each fundamental element of the formalism is
given in explicit form ³⁹ ³⁹ 39 Strictly speaking, one might object that
the physical Hamiltonian of the free scalar field model involves a
square root, and hence is not really explicitly defined unless the
spectral decomposition of the operator under the square root is known.
But in any case the claim is valid at least for the non-rotational dust
model. . While deparametrized models of loop quantum gravity have
already been considered in the literature before, all previous
treatments of the subject have been partially formal, with some
essential ingredients of the theory having been left undefined. Most
importantly, our work provides the first fully concrete proposal for a
satisfactory physical Hamiltonian governing the dynamics in
deparametrized loop quantum gravity.

To conclude, we have shown that deparametrization can be used to
formulate the dynamics of canonical loop quantum gravity in a way which
offers a number of clear advantages, and at least from a practical point
of view is preferable over a fully constrained formulation. In a sense,
this can be regarded as the central claim advocated in this thesis. The
formidable practical difficulties involved in extracting solutions of
the Hamiltonian constraint and uncovering their physical meaning, and
understanding the structure of the physical Hilbert space and the scalar
product thereon, are largely circumvented when a physical time variable
is introduced and the constraint operator is traded for a physical
Hamiltonian. The deparametrized models considered in this work are
nevertheless constructed with sufficient mathematical rigor to ensure
that they are free from any fundamental inconsistencies, and conform to
the high mathematical standards traditionally expected in the context of
canonical loop quantum gravity.

### Some open issues

While the deparametrized models whose definition is completed in this
work by supplying an explicit proposal for the physical Hamiltonian are
mathematically consistent and complete models of loop quantum gravity,
virtually nothing is known yet about the physics contained in them. The
results of the numerical computations presented in Chapter 17 do little
to clarify the issue of the physical viability of these models, since
the initial states used in the calculations do not correspond to any
familiar physical situation, in which one would have a prior expectation
of how the volume or the curvature is supposed to evolve.

Perhaps the main purpose of our numerical calculations is to serve as a
sort of proof of concept, showing that it is possible to perform
explicit calculations concerning the dynamics of deparametrized loop
quantum gravity. Moreover, the results of the calculations display at
least some decidedly interesting features: The degeneracies present in
the spectra of volume and curvature are be preserved under time
evolution, and the time-dependent expectation values of volume and
curvature behave as even functions of time. These observations seem to
point towards the existence of a certain symmetry shared by the
Hamiltonian and the volume and curvature operators. The symmetry might
well be related to some appropriate notion of time reversal in the
theory. Identifying this symmetry and understanding its properties in
detail would be a worthwhile challenge for future study, especially in
order to see whether the symmetry could be used to simplify the analysis
of the Hamiltonian in any way.

The most significant obstacle which prevents us from attempting
physically interesting calculations within the models considered in this
work seems to be the lack of states which would have a clear physical,
semiclassical interpretation, and which would also be compatible with
the structure of the model, particularly its dynamics. Thus, our
inability to obtain any definite, physically significant results using
the methods developed in this work should not be taken as evidence that
the methods themselves are flawed; it should rather be attributed to our
not having been able to identify any suitable states from which such
results could be extracted. All coherent states available in loop
quantum gravity so far are based on a fixed graph, and as we have argued
earlier, such states cannot be good coherent states even kinematically,
let alone at the dynamical level, for a model whose dynamics is defined
by a graph-changing Hamiltonian.

Before the physical content of our models can be tested through concrete
calculations, it therefore seems that one more major challenge must
still be overcome: To write down states describing a specific physical
situation (for example, a homogeneous and isotropic semiclassical
geometry), while also having a chance to behave nicely under the
dynamics of the model, at least over a short interval of time. It is
natural to expect that such states would have the form of an infinite
superposition of graphs, in which the nodes of a given ”seed graph” are
decorated with special loops in all possible ways. The search for
coherent states having an appropriate graph structure is still
essentially fully open, though some preliminary steps have been taken
recently in [ 21 ] . If such states were available, my expectation is
that the methods introduced in this work would be powerful enough to be
able to produce meaningful physical conclusions when used to investigate
the dynamics of these states.

That being said, I think there is a definite possibility that the
computational technology currently available in loop quantum gravity may
not be the optimal one for the problems to which it is being applied.
Imagine an alternative history of physics, in which the formalism of
quantum mechanics was discovered before the theory of differential
equations had become very well developed. The Schrödinger or Heisenberg
of this hypothetical universe might have tried to derive the energy
levels of the harmonic oscillator by computing the matrix elements of
the operator @xmath with respect to some arbitrarily chosen basis of
@xmath and attempting to diagonalize the resulting matrix. While it is
not impossible that he could eventually have found the solution in this
way, we know that it is certainly not the ideal way of attacking the
problem. Sometimes I cannot help but think that this is what we are
doing when we try to analyze a Hamiltonian in loop quantum gravity in
terms of its matrix elements in the spin network basis. It is difficult
to suggest how one should look for alternative methods of calculation,
especially not having in mind any specific difficulty that the new
technology is supposed to solve, but our formalism of intertwiners in
the basis of angular momentum coherent states can be seen as the
beginning of an attempt in this direction.

Our discussion here has been limited to a selection of unresolved issues
directly related to the work presented in this thesis. Looking at loop
quantum gravity as a whole, there are certainly other, even more
substantial open questions, in particular the issue of the continuum
limit, and the crucial challenge of deriving falsifiable physical
predictions from the theory. It is clear that conclusive answers to
these questions must be found before loop quantum gravity can be
considered as a correct theory of physics, and not just a promising
mathematical framework. The work at hand has little to say on these
issues, but what we have accomplished is to have established a class of
coherent, well-defined models of loop quantum gravity, within which
answers to these questions (and others) can be sought.

### Parting thoughts

When compared to most other theories of physics, a distinctive feature
of loop quantum gravity is the exceptionally high level of mathematical
rigor which characterizes a large part of the research on the subject,
and which has been present throughout the history of the theory,
particularly in its canonical formulation. The mathematical groundwork
on which the entire structure of loop quantum gravity is built is
extremely solid, and this is undoubtedly a great strength of the theory.

On the other hand, it is clear that a certain price has been paid for
this strength. Physical applications of canonical loop quantum gravity
are a rarity even now, thirty years after the birth of the theory. In
the development of the theory, the strict requirements of mathematical
rigor have been taken as the foremost consideration so often that not
much room has been left for exploring the theory by trying to use it to
answer concrete questions about physics. However, thorough mathematical
reasoning and heuristic physical exploration are two complementary lines
of research, and it seems unlikely that either of them alone could lead
to a complete theory of physics.

Pushing a tentative physical theory to make calculations about physics
often plays an important role in the development of a consistent
formalism, even if the calculations initially involve several
speculative steps which can be justified only by heuristic physical
arguments, and from the point of view of mathematical precision fall
somewhere on the spectrum between ”dubious” and ”plainly wrong”. (This
is shown by the history of how virtually any now established theory of
physics has grown from a disorganized collection of hypothetical ideas
into a valuable constituent of our knowledge about the physical world.)
A calculation which leads to a physically correct result clearly counts
as evidence that one is on the right track. Even if the result is wrong,
the calculation may still offer valuable insights on how the formalism
can be improved. In the words of John Wheeler, ”We can afford many
mistakes in the search. The main thing is to make them as fast as
possible.”

I think that canonical loop quantum gravity is by now more than ready to
be used to address concrete physical questions. In the recent years, the
canonical theory has indeed seen the emergence of such physically
motivated research programs as the model of quantum-reduced loop gravity
[ 3 , 6 , 4 , 5 , 2 ] and the derivation of effective Hamiltonians for
cosmology [ 60 , 61 , 22 ] . (For comparison, the covariant version of
the theory has been used to study, for instance, the dynamics of
cosmological spacetimes [ 40 , 38 , 103 , 104 , 128 ] and the
hypothesized bounce of a collapsing star [ 112 , 28 , 29 , 58 , 36 ] .)
I have no doubt that such lines of research will eventually turn out to
have a crucial importance in carrying the theory closer to its
completion, by providing us with clues on how to establish the elements
of the formalism which are still missing. I close these concluding
thoughts by invoking the words of another giant among physicists to
express my sentiment:

  We have to take a viewpoint of how to deal with problems where no
  experiments are available. There are two choices. The first choice is
  that of mathematical rigor. (…) However, one can do an enormous amount
  by various approximations which are non-rigorous and unproved
  mathematically, perhaps for the first few years. Historically, the
  rigorous analysis of whether what one says is true or not comes many
  years later after the discovery of what is true. And, the discovery of
  what is true is helped by experiments. The attempt at mathematical
  rigorous solutions without guiding experiments is exactly the reason
  the subject is difficult.
  The second choice of action is to ”play games” by intuition. (…) Make
  up your mind which way it is and calculate without rigor in an
  exploratory way. (…) I think the best viewpoint is to pretend that
  there are experiments and calculate. In this field since we are not
  pushed by experiments we must be pulled by imagination.
  The real challenge is not to find an elegant formalism, but to solve a
  series of problems whose results could be checked. This is a different
  point of view. Don’t be so rigorous or you will not succeed.

  – Richard P. Feynman

@xmath

Appendix

@xmath recoupling theory and
graphical techniques

  Ninety percent of most magic merely consists of knowing one extra
  fact.

  – Terry Pratchett

## Introduction

In this Appendix we give a concise but self-contained presentation of
those aspects of @xmath representation and recoupling theory that form
the indispensable basis for performing practical calculations in loop
quantum gravity. The two central themes of our discussion are the theory
of intertwiners, or invariant tensors of @xmath , from which the spin
network states of loop quantum gravity are constructed; and the
graphical techniques for calculations in @xmath recoupling theory, which
are presented in the last chapter of the Appendix, and which provide an
invaluable computational tool in loop quantum gravity. Another objective
of our presentation is to clearly set down our notation and conventions,
which are probably not in complete agreement with any of the standard
references on the subject.

## Appendix A Representations of @xmath

The first chapter of the Appendix consists of a review of the necessary
elements of the representation theory of @xmath . While the material in
this chapter is elementary and most of it can be found in any good
textbook on quantum mechanics or Lie groups, the chapter nevertheless
serves a number of purposes: to establish notation, to make our
treatment fully self-contained, and to put forward the author’s personal
preference for the quantum-mechanical theory of angular momentum, as
opposed to the formal machinery of mathematical group theory, as the
natural language for discussing the theory of @xmath in the context of
physics.

### a.1 Fundamental representation

A general element of @xmath , the group of unitary @xmath -matrices with
determinant @xmath , has the form

  -- -------- -- -------
     @xmath      (A.1)
  -- -------- -- -------

The fundamental representation of the group is realized by the action of
the matrices @xmath on two-component vectors of the form

  -- -------- -- -------
     @xmath      (A.2)
  -- -------- -- -------

We denote the vector space consisting of such vectors as @xmath . The
natural scalar product on @xmath , defined by

  -- -------- -- -------
     @xmath      (A.3)
  -- -------- -- -------

is invariant under the action of @xmath . The antisymmetric tensors

  -- -------- -- -------
     @xmath      (A.4)
  -- -------- -- -------

are also @xmath -invariant:

  -- -------- -- -------
     @xmath      (A.5)
  -- -------- -- -------

and similarly for @xmath . By manipulating this relation, one can show
that the matrix elements of the inverse matrix @xmath are related to
those of @xmath by

  -- -------- -- -------
     @xmath      (A.6)
  -- -------- -- -------

Since we define both @xmath and @xmath to have the same numerical value,
their contraction gives

  -- -------- -- -------
     @xmath      (A.7)
  -- -------- -- -------

The epsilon tensor can be used for raising and lowering of @xmath
indices. We adopt the convention

  -- -------- -- -------
     @xmath      (A.8)
  -- -------- -- -------

Using @xmath , one may also define the invariant antisymmetric product

  -- -------- -- -------
     @xmath      (A.9)
  -- -------- -- -------

between two vectors in @xmath .

By introducing the Pauli matrices

  -- -------- -- --------
     @xmath      (A.10)
  -- -------- -- --------

a general @xmath -element can be expressed in terms of an angle @xmath
and a unit vector @xmath as

  -- -------- -- --------
     @xmath      (A.11)
  -- -------- -- --------

where the second equality follows from expanding the exponential and
observing that @xmath . The parametrization ( A.11 ) makes it
particularly clear that elements of @xmath can be viewed as representing
rotations in three-dimensional space. Let us give a geometrical argument
to justify this interpretation. Consider the following sequence of
infinitesimal rotations:

-   Around the @xmath -axis by an infinitesimal angle @xmath ;

-   Around the @xmath -axis by another infinitesimal angle @xmath ;

-   Around the @xmath -axis by the angle @xmath ;

-   Around the @xmath -axis by the angle @xmath .

By elementary geometry it is possible to convince oneself that, at
lowest nontrivial order in the angles, the sequence is equivalent to a
single rotation around the @xmath -axis by the angle @xmath .

Suppose that rotations around the coordinate axes are generated by the
operators @xmath , so that the operator

  -- -------- -- --------
     @xmath      (A.12)
  -- -------- -- --------

gives a rotation by an angle @xmath around the @xmath -axis. Then the
rotations involved in the above sequence are given by

  -- -------- -------- -- --------
     @xmath   @xmath      (A.13)
     @xmath   @xmath      (A.14)
  -- -------- -------- -- --------

Now a direct calculation shows that the entire sequence is represented
by the operator

  -- -------- -- --------
     @xmath      (A.15)
  -- -------- -- --------

But this operator is supposed to be @xmath , so we conclude that the
generators must satisfy @xmath . By considering cyclic permutations of
the coordinate axes, we find the complete commutation relation

  -- -------- -- --------
     @xmath      (A.16)
  -- -------- -- --------

Hence we see that this commutation relation has a direct geometrical
significance: it encodes the way in which successive rotations in
three-dimensional space are combined.

The Pauli matrices satisfy the commutation relation

  -- -------- -- --------
     @xmath      (A.17)
  -- -------- -- --------

which shows that they can be interpreted as generators of rotations by
making the identification @xmath . Under this interpretation, @xmath
elements of the form

  -- -------- -- --------
     @xmath      (A.18)
  -- -------- -- --------

describe rotations around the coordinate axes. The general element of
Eq. ( A.11 ) corresponds to a rotation by the angle @xmath around the
direction given by the vector @xmath .

### a.2 The angular momentum operator

In quantum mechanics, any (Hermitian) vector operator @xmath whose
components satisfy the commutation relation

  -- -------- -- --------
     @xmath      (A.19)
  -- -------- -- --------

is called an angular momentum operator. All components of @xmath commute
with the squared angular momentum

  -- -------- -- --------
     @xmath      (A.20)
  -- -------- -- --------

Therefore one can simultaneously diagonalize @xmath and one of the
components, conventionally chosen as @xmath . Let us write the
eigenvalue equations as

  -- -------- -------- -- --------
     @xmath   @xmath      (A.21)
     @xmath   @xmath      (A.22)
  -- -------- -------- -- --------

To derive the solution to the eigenvalue problem, it is useful to define
the raising and lowering operators

  -- -------- -- --------
     @xmath      (A.23)
  -- -------- -- --------

Their commutators with @xmath and @xmath are given by

  -- -------- -- --------
     @xmath      (A.24)
  -- -------- -- --------

These relations imply that the raising and lowering operators indeed
raise and lower the eigenvalue of @xmath by one, while leaving the
eigenvalue of @xmath unchanged:

  -- -------- -------- -- --------
     @xmath   @xmath      (A.25)
     @xmath   @xmath      (A.26)
  -- -------- -------- -- --------

In other words, the states @xmath must be proportional to @xmath :

  -- -------- -- --------
     @xmath      (A.27)
  -- -------- -- --------

This shows that if any one of the eigenstates @xmath is known, then all
the eigenstates for that value of @xmath can be derived by repeatedly
applying @xmath and @xmath .

On the other hand, the inequality

  -- -------- -- --------
     @xmath      (A.28)
  -- -------- -- --------

implies that the eigenvalue @xmath is restricted by

  -- -------- -- --------
     @xmath      (A.29)
  -- -------- -- --------

This condition can be satisfied only if there exists a maximal
eigenvalue @xmath , such that the action of the raising operator on the
state @xmath does not give a new eigenstate, but instead

  -- -------- -- --------
     @xmath      (A.30)
  -- -------- -- --------

Similarly, there must exist a minimal eigenvalue @xmath , such that

  -- -------- -- --------
     @xmath      (A.31)
  -- -------- -- --------

Using the identities

  -- -------- -------- -- --------
     @xmath   @xmath      (A.32)
     @xmath   @xmath      (A.33)
  -- -------- -------- -- --------

in Eqs. ( A.30 ) and ( A.31 ), one finds the relation

  -- -------- -- --------
     @xmath      (A.34)
  -- -------- -- --------

showing that @xmath and @xmath are related to each other by

  -- -------- -- --------
     @xmath      (A.35)
  -- -------- -- --------

Consider now acting repeatedly with @xmath on the state @xmath . After a
certain number of actions, say @xmath , one must arrive at the state
@xmath . Since the eigenvalue @xmath is lowered by one at each step, the
difference @xmath must be equal to @xmath , giving

  -- -------- -- --------
     @xmath      (A.36)
  -- -------- -- --------

The eigenvalue @xmath then is

  -- -- -- --------
           (A.37)
  -- -- -- --------

The possible eigenvalues of the operators @xmath and @xmath have
therefore been determined. The eigenvalue equations ( A.21 ) and ( A.22
) can be written as

  -- -------- -------- -- --------
     @xmath   @xmath      (A.38)
     @xmath   @xmath      (A.39)
  -- -------- -------- -- --------

where @xmath may be any integer or half-integer, and @xmath ranges from
@xmath to @xmath in steps of @xmath .

To complete the solution of the eigenvalue problem, it remains to find
the coefficients @xmath in Eq. ( A.27 ), since this will show how the
angular momentum operator acts on the eigenstates @xmath . By
multiplying the equation with its adjoint, we find

  -- -------- -- --------
     @xmath      (A.40)
  -- -------- -- --------

which determines @xmath up to a phase. In this work we follow the nearly
universally adopted Condon–Shortley phase convention, according to which
@xmath are taken to be real and positive. This leads to

  -- -------- -- --------
     @xmath      (A.41)
  -- -------- -- --------

### a.3 Spin-@xmath representation

The states @xmath with a fixed value of @xmath span the @xmath
-dimensional vector space @xmath . A general element of @xmath has the
form

  -- -------- -- --------
     @xmath      (A.42)
  -- -------- -- --------

the index @xmath taking the values @xmath , @xmath , @xmath , @xmath .
The natural definition

  -- -------- -- --------
     @xmath      (A.43)
  -- -------- -- --------

for a scalar product between elements of @xmath promotes @xmath into a
Hilbert space.

The relevance of the space @xmath to @xmath representation theory is due
to the fact that the matrices representing the operators @xmath on
@xmath define an irreducible representation of @xmath . These matrices,
whose elements are given by

  -- -------- -- --------
     @xmath      (A.44)
  -- -------- -- --------

are known as the Wigner matrices. The great orthogonality theorem of
group theory implies that the Wigner matrices satisfy

  -- -------- -- --------
     @xmath      (A.45)
  -- -------- -- --------

where @xmath is the normalized Haar measure ⁴⁰ ⁴⁰ 40 The Haar measure is
determined uniquely by the conditions

@xmath

where @xmath is an arbitrary, fixed element of @xmath . In the
parametrization ( A.1 ),

@xmath

from which formulas for other parametrizations can be derived by making
the appropriate change of variables and performing one of the integrals
to remove the delta function. For more details, see e.g. [ 126 ] . of
@xmath , and

  -- -------- -- --------
     @xmath      (A.46)
  -- -------- -- --------

is a common shorthand for the dimension of @xmath .

To derive the form of the invariant epsilon tensor in the spin- @xmath
representation, we may consider the problem of constructing a state of
zero total angular momentum on the tensor product space @xmath . Suppose
that the state

  -- -------- -- --------
     @xmath      (A.47)
  -- -------- -- --------

satisfies

  -- -------- -------- -- --------
     @xmath   @xmath      (A.48)
     @xmath   @xmath      (A.49)
  -- -------- -------- -- --------

where each angular momentum operator acts on the corresponding factor of
the tensor product; for example, @xmath stands for @xmath . This is
equivalent to the state being invariant under rotations generated by the
total angular momentum @xmath , which in turn implies that the tensor
defined by the coefficients @xmath is invariant under the action of
@xmath by the matrices @xmath .

The eigenvalue equation for the @xmath -component immediately shows that
the coefficient @xmath unless @xmath . Then, requiring that the state

  -- -------- -- --------
     @xmath      (A.50)
  -- -------- -- --------

is annihilated by either one of @xmath or @xmath leads to the condition
@xmath . Taken together, the two conditions imply that @xmath is
proportional to @xmath . Defining the tensor @xmath so that @xmath , we
therefore have

  -- -------- -- --------
     @xmath      (A.51)
  -- -------- -- --------

We see that @xmath satisfies

  -- -------- -- --------
     @xmath      (A.52)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (A.53)
  -- -------- -- --------

The remaining properties of the epsilon tensor are analogous to those in
the fundamental representation. For the matrix elements of the inverse
matrix, there holds the relation

  -- -------- -- --------
     @xmath      (A.54)
  -- -------- -- --------

and indices are raised and lowered according to the convention

  -- -------- -- --------
     @xmath      (A.55)
  -- -------- -- --------

An antisymmetric, @xmath -invariant product on @xmath can be defined as

  -- -------- -- --------
     @xmath      (A.56)
  -- -------- -- --------

The way in which we introduced the space @xmath does not make it
particularly clear how the spin- @xmath representation of @xmath is
related to the fundamental representation. We will now clarify this
relation by showing how the states @xmath can be constructed from the
states @xmath and @xmath , which span the space @xmath , and are
eigenstates of the angular momentum operator on @xmath with eigenvalues
@xmath and @xmath . To this end, let us consider the state

  -- -------- -- --------
     @xmath      (A.57)
  -- -------- -- --------

which is an element of the @xmath -fold tensor product space @xmath . We
would like to show that the state @xmath is an eigenstate of the total
angular momentum operator

  -- -------- -- --------
     @xmath      (A.58)
  -- -------- -- --------

where each operator @xmath acts on the @xmath -th factor of the tensor
product @xmath , i.e.

  -- -------- -- --------
     @xmath      (A.59)
  -- -------- -- --------

For the @xmath -component of @xmath , we immediately find

  -- -------- -- --------
     @xmath      (A.60)
  -- -------- -- --------

since each state @xmath is an eigenstate of the corresponding operator
@xmath with the eigenvalue @xmath . For the square of the total angular
momentum, we have

  -- -------- -- --------
     @xmath      (A.61)
  -- -------- -- --------

The first sum contains @xmath terms, and in each of them the @xmath acts
on the corresponding state @xmath , producing the eigenvalue @xmath . To
evaluate the cross terms, we note that each of the @xmath terms in the
sum cam be written as

  -- -------- -- --------
     @xmath      (A.62)
  -- -------- -- --------

Here the action of the first term on the state @xmath gives the
eigenvalue @xmath . The action of the other two terms gives zero,
because the state @xmath is annihilated by the raising operator @xmath .
Hence, going back to Eq. ( A.61 ), we conclude that

  -- -------- -- --------
     @xmath      (A.63)
  -- -------- -- --------

Together, Eqs. ( A.60 ) and ( A.63 ) show that @xmath can be identified
with the state @xmath . That is,

  -- -------- -- --------
     @xmath      (A.64)
  -- -------- -- --------

The remaining states @xmath can now be constructed by repeatedly acting
on Eq. ( A.64 ) with the lowering operator

  -- -------- -- --------
     @xmath      (A.65)
  -- -------- -- --------

Recalling Eq. ( A.41 ), we obtain

  -- -------- -- --------
     @xmath      (A.66)
  -- -------- -- --------

In this way we have established a direct relation between the spaces
@xmath and @xmath .

In particular, an explicit expression for the matrix elements @xmath can
be derived from Eq. ( A.66 ) by using the known action of the matrix
@xmath on the states @xmath and @xmath in @xmath . The derivation is
valid not only for elements of @xmath , but extends to elements of the
group @xmath , which have the form

  -- -------- -- --------
     @xmath      (A.67)
  -- -------- -- --------

where @xmath , but the matrix elements are otherwise unrestricted. By
replacing the states @xmath and @xmath on the right-hand side of Eq. (
A.66 ) with

  -- -------- -------- -- --------
     @xmath   @xmath      (A.68)
     @xmath   @xmath      (A.69)
  -- -------- -------- -- --------

one finds, after a somewhat tedious but in principle straightforward
calculation,

  -- -------- -- --------
     @xmath      (A.70)
  -- -------- -- --------

where the sum runs over all the values of @xmath for which the argument
of every factorial is non-negative.

Note that the right-hand side of Eq. ( A.66 ) is a completely symmetric
combination of the states @xmath and @xmath . In other words, the states
@xmath given by Eq. ( A.66 ) belong to the completely symmetric subspace
of the tensor product space @xmath . Indeed, the spin- @xmath
representation of @xmath is often introduced in the literature by
defining the space @xmath as the completely symmetrized part of @xmath ,
or equivalently as the space spanned by objects of the form

  -- -------- -- --------
     @xmath      (A.71)
  -- -------- -- --------

where the ”index” @xmath is a completely symmetric combination of the
spin-1/2 indices @xmath . In other words, only the total number of
@xmath ’s and @xmath ’s among the indices @xmath is relevant to the
value of @xmath . The relation between the symmetrized index @xmath and
the magnetic index @xmath used so far in this chapter is given by @xmath
, where each @xmath takes the value @xmath or @xmath . The
representation matrix of an @xmath element @xmath in the space of the
vectors ( A.71 ) is defined by

  -- -------- -- --------
     @xmath      (A.72)
  -- -------- -- --------

with @xmath the matrix in the fundamental representation.

In practical @xmath calculations it is almost always more convenient to
use the realization of the space @xmath in terms of the magnetic indices
@xmath , rather than the symmetric tensor product indices @xmath . This
is especially true when it comes to the graphical techniques of Chapter
C , which are adapted to the magnetic index representation, the
corresponding graphical calculus of the symmetric tensor product
representation being much more primitive and cumbersome in comparison.
Nevertheless, Chapter 18 contains one example of a calculation which is
the most easily performed in the symmetric tensor product
representation.

## Appendix B Theory of intertwiners

Intertwiners, or invariant tensors of @xmath , lie at the core of the
spin network states of loop quantum gravity. In this chapter we
introduce the Clebsch–Gordan coefficient and the closely related Wigner
3 @xmath -symbol, show how the latter serves as the elementary building
block from which intertwiners can be constructed, and derive the basic
properties of the intertwiners obtained in this way. The material
presented in this chapter provides the essential foundations underlying
the powerful graphical formalism for calculations in @xmath recoupling
theory, which will be introduced in the last chapter of the Appendix.

### b.1 Clebsch–Gordan coefficients

Consider the tensor product space @xmath . An obvious basis on this
space is provided by the tensor product states @xmath , which are
eigenstates of the mutually commuting operators

  -- -------- -- -------
     @xmath      (B.1)
  -- -------- -- -------

Another complete set of commuting operators on @xmath is formed by the
operators

  -- -------- -- -------
     @xmath      (B.2)
  -- -------- -- -------

Let us denote their eigenstates by @xmath . Since both sets of states
span the space @xmath , they must be related to each other by a unitary
transformation of the form

  -- -------- -- -------
     @xmath      (B.3)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (B.4)
  -- -------- -- -------

The coefficients in these expansions are known as the Clebsch–Gordan
coefficients. In the physics literature, a notation such as @xmath is
normally used for them. The notation adopted in this work is designed to
display the tensorial structure of the Clebsch–Gordan coefficient when
interpreted as an @xmath tensor; see Eq. ( B.12 ) below.

A number of properties satisfied by the Clebsch–Gordan coefficients
follow immediately from their definition:

-   The coefficient @xmath is trivially zero unless the conditions

      -- -------- -- -------
         @xmath      (B.5)
      -- -------- -- -------

    are met. These conditions are referred to as the Clebsch–Gordan
    conditions, or the triangular conditions.

-   Moreover, @xmath whenever @xmath .

-   The orthogonality relations of the Clebsch–Gordan coefficients read

      -- -------- -- -------
         @xmath      (B.6)
      -- -------- -- -------

    and

      -- -------- -- -------
         @xmath      (B.7)
      -- -------- -- -------

The Condon–Shortley phase convention fixes the phases of the
Clebsch–Gordan coefficients by requiring that all @xmath are real, and
@xmath ; the relative phases between the coefficients for a fixed value
of @xmath are determined by the choice already made in Eq. ( A.41 ).
Under this convention, the numerical value of the inverse coefficient
@xmath is equal to that of @xmath , and for this reason, @xmath and
@xmath are usually not distinguished from each other in the physics
literature.

Numerical values of the Clebsch–Gordan coefficients can be derived
algebraically, using the properties of the raising and lowering
operators @xmath (though in practice one would of course look up the
coefficients using a tool such as Mathematica). For a given value of the
total angular momentum @xmath , one starts with the state of ”highest
weight” @xmath , in which the magnetic number is equal to its highest
possible value. On grounds of the condition @xmath for the magnetic
numbers in @xmath , this state must have the form

  -- -------- -- -------
     @xmath      (B.8)
  -- -------- -- -------

Applying the raising operator @xmath now gives

  -- -------- -- -------
     @xmath      (B.9)
  -- -------- -- -------

where @xmath is defined by Eq. ( A.41 ). The information contained in
Eq. ( B.9 ) is sufficient to fully determine the state @xmath , since
Eq. ( B.9 ) gives @xmath conditions for the @xmath coefficients @xmath ,
and one more condition is obtained by requiring that the state ( B.8 )
is normalized. The state @xmath having been found, the remaining states
@xmath can then be derived by repeatedly applying the lowering operator.

Let us consider the effect of an @xmath rotation on the equation ( B.3
). On the left-hand side, the rotation acts as @xmath . On the
right-hand side, the terms having a given value of @xmath transform
among themselves according to the matrix @xmath . Thus,

  -- -------- -- --------
     @xmath      (B.10)
  -- -------- -- --------

Taking the product of this equation with the state @xmath and using Eq.
( B.3 ) on the right-hand side, we obtain the so-called Clebsch–Gordan
series

  -- -------- -- --------
     @xmath      (B.11)
  -- -------- -- --------

which is, among other things, the basic rule for computing products of
holonomies in loop quantum gravity. Contracting Eq. ( B.11 ) with a
Clebsch–Gordan coefficient and using the orthogonality relation ( B.7 ),
we further find

  -- -------- -- --------
     @xmath      (B.12)
  -- -------- -- --------

showing how the Clebsch–Gordan coefficient itself behaves under @xmath
transformations, and justifying the index structure used in the notation
@xmath .

### b.2 The 3@xmath-symbol

The Wigner 3 @xmath -symbol is defined by lowering the upper index of
the Clebsch–Gordan coefficient using the epsilon tensor, and multiplying
with a numerical factor (which is inserted in order to optimize the
symmetry properties of the resulting object):

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (B.13)
  -- -------- -------- -- --------

While the 3 @xmath -symbol is often introduced as a more symmetric
version of the Clebsch–Gordan coefficient, its relevance to loop quantum
gravity follows from its behaviour under @xmath transformations.
Starting from Eq. ( B.12 ) and recalling Eq. ( A.54 ) for the elements
of an inverse Wigner matrix, one can show that the 3 @xmath -symbol is
invariant under the action of @xmath :

  -- -------- -- --------
     @xmath      (B.14)
  -- -------- -- --------

In the language of angular momentum, the Clebsch–Gordan coefficient
couples two angular momenta @xmath and @xmath to a total angular
momentum @xmath , whereas the 3 @xmath -symbol couples the three angular
momenta @xmath , @xmath and @xmath to total angular momentum zero. The
@xmath invariance of the 3 @xmath -symbol implies that the state

  -- -------- -- --------
     @xmath      (B.15)
  -- -------- -- --------

is rotationally invariant, and hence is an eigenstate of the total
angular momentum operator @xmath with eigenvalue zero.

The basic properties of the 3 @xmath -symbol follow from the
corresponding properties of the Clebsch–Gordan coefficients:

-   The value of the 3 @xmath -symbol can be non-zero only if the
    triangular conditions

      -- -------- -- --------
         @xmath      (B.16)
      -- -------- -- --------

    as well as the condition

      -- -------- -- --------
         @xmath      (B.17)
      -- -------- -- --------

    are satisfied.

-   The 3 @xmath -symbol satisfies the orthogonality relations

      -- -------- -- --------
         @xmath      (B.18)
      -- -------- -- --------

    and

      -- -------- -- --------
         @xmath      (B.19)
      -- -------- -- --------

When the Condon–Shortley phase convention is followed, the 3 @xmath
-symbol is real-valued, and possesses several convenient symmetry
properties. Interchanging any two columns in the symbol produces the
factor @xmath ; for example,

  -- -------- -- --------
     @xmath      (B.20)
  -- -------- -- --------

This implies in particular that the symbol is invariant under cyclic
permutations of its columns. The same phase factor results from
reversing the sign of all the magnetic numbers:

  -- -------- -- --------
     @xmath      (B.21)
  -- -------- -- --------

The definition of the Clebsch–Gordan coefficient immediately implies
that the coefficient @xmath is equal to @xmath . Using this in Eq. (
B.13 ), we find that when one of the angular momenta in the 3 @xmath
-symbol is zero, the 3 @xmath -symbol reduces to the epsilon tensor:

  -- -------- -- --------
     @xmath      (B.22)
  -- -------- -- --------

Further properties of the 3 @xmath -symbol, relations satisfied by it,
and explicit expressions for its values in particular cases can be found
in any of the standard references on angular momentum theory. The most
comprehensive source of such information is the encyclopedic collection
of formulas by Varshalovich, Moskalev and Khersonskii [ 127 ] .

### b.3 Three-valent intertwiners

Intertwiners, or invariant tensors of @xmath , play a crucial role in
loop quantum gravity, entering the construction of the spin network
states as solutions of the Gauss constraint. Eq. ( B.14 ) shows that the
3 @xmath -symbol can be interpreted as such an invariant tensor. To
emphasize the tensorial character of the 3 @xmath -symbol, we introduce
the notation

  -- -------- -- --------
     @xmath      (B.23)
  -- -------- -- --------

Whenever we want to indicate explicitly the spins entering the 3 @xmath
-symbol, the notation @xmath will be used for the tensor ( B.23 ). The 3
@xmath -symbol is in fact (up to normalization) the only three-valent
invariant tensor with indices in three given representations @xmath ,
@xmath and @xmath . Therefore the 3 @xmath -symbol alone spans the
one-dimensional space of three-valent intertwiners, denoted by @xmath .

By using epsilon to raise an index of the tensor ( B.23 ), we obtain the
tensor

  -- -------- -- --------
     @xmath      (B.24)
  -- -------- -- --------

which spans the intertwiner space @xmath . Up to a numerical factor, the
tensor @xmath is equal to the Clebcsh–Gordan coefficient @xmath .
Elements of a space such as @xmath are invariant under the action of
@xmath in the sense of Eq. ( B.12 ), i.e. when a matrix @xmath acts on
each lower index of the tensor, while an inverse matrix @xmath acts on
each upper index.

The symmetry relation Eq. ( B.21 ) and the condition @xmath imply that
the tensor

  -- -------- -- --------
     @xmath      (B.25)
  -- -------- -- --------

obtained by raising all the indices of @xmath , is numerically equal to
@xmath . The orthogonality relation ( B.18 ) then shows that the
three-valent intertwiner defined by Eq. ( B.23 ) is normalized:

  -- -------- -- --------
     @xmath      (B.26)
  -- -------- -- --------

The @xmath generator @xmath , defined in the spin- @xmath representation
as

  -- -------- -- --------
     @xmath      (B.27)
  -- -------- -- --------

can be interpreted as a three-valent intertwiner between the
representations @xmath , @xmath and @xmath . This follows from the
Wigner--Eckart theorem, which states that the matrix elements of a
spherical tensor operator ⁴¹ ⁴¹ 41 A spherical tensor operator of rank
@xmath is an operator whose @xmath components @xmath ( @xmath )
transform under @xmath rotations in the same way as the states @xmath .
That is,

@xmath

where @xmath is the unitary operator representing the rotation on the
Hilbert space in which @xmath acts. @xmath satisfy

  -- -------- -- --------
     @xmath      (B.28)
  -- -------- -- --------

where the so-called reduced matrix element @xmath is independent of the
magnetic numbers; the dependence on @xmath , @xmath and @xmath is given
by the Clebsch–Gordan coefficient independently of the operator @xmath .
In Eq. ( B.27 ), the vector operator @xmath is a spherical tensor
operator of rank 1; therefore the matrix elements of the generators are
proportional to the Clebsch–Gordan coefficient @xmath . The coefficient
of proportionality can be determined by contracting the equation with
itself, using the orthogonality of the Clebsch–Gordan coefficient on one
side, and

  -- -------- -- --------
     @xmath      (B.29)
  -- -------- -- --------

on the other side. In this way one finds

  -- -------- -- --------
     @xmath      (B.30)
  -- -------- -- --------

Another familiar object which can be expressed in terms of a
three-valent intertwiner is the antisymmetric symbol @xmath . Since the
3 @xmath -symbol with @xmath is completely antisymmetric in its indices
due to the symmetry relation ( B.20 ), one might think that @xmath is
directly proportional to the 3 @xmath -symbol:

  -- -------- -- --------
     @xmath      (B.31)
  -- -------- -- --------

While this is a valid numerical relation, some care should be taken when
using it, since the indices of @xmath usually refer to the Cartesian
basis, in which an index takes the values @xmath , whereas the indices
of the 3 @xmath -symbol take the values @xmath , and hence refer to the
so-called spherical basis. (Strictly speaking, the index @xmath in Eq. (
B.30 ) should also be interpreted as a spherical index, not a Cartesian
index.) The components of a vector with respect to the spherical basis
are defined in terms of the Cartesian components by ⁴² ⁴² 42 Under a
rotation descibed by a matrix @xmath , the Cartesian components of a
vector @xmath transform as @xmath . Under the same rotation, the
spherical components defined by Eq. ( B.32 ) transform according to
@xmath , where @xmath is an @xmath element corresponding to the rotation
@xmath . Thus the spherical components of a vector are a special case of
the definition of a spherical tensor given in the previous footnote.

  -- -------- -- --------
     @xmath      (B.32)
  -- -------- -- --------

Now one can verify by direct calculation that a triple product of the
form @xmath , where the indices @xmath , @xmath , @xmath refer to the
Cartesian basis, is equal to @xmath , where @xmath , @xmath , @xmath
refer to the spherical basis, and the antisymmetric symbol in the
spherical basis is defined so that @xmath . Therefore the correct way to
express the triple product in terms of the 3 @xmath -symbol is given by

  -- -------- -- --------
     @xmath      (B.33)
  -- -------- -- --------

### b.4 Intertwiners of higher valence

The invariant tensors @xmath and @xmath are the basic building blocks
out of which intertwiners of higher valence can be constructed. For
example, by using epsilon to contract two three-valent intertwiners on
one index, we obtain the four-valent intertwiner

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (B.34)
  -- -------- -------- -- --------

The invariance of @xmath and @xmath implies that the intertwiner ( B.34
) is invariant under the action of @xmath on its indices:

  -- -------- -- --------
     @xmath      (B.35)
  -- -------- -- --------

When the internal spin @xmath ranges over all the values allowed by the
Clebsch–Gordan conditions, the tensors ( B.34 ) span the intertwiner
space @xmath . Using the orthogonality relation of the 3 @xmath
-symbols, one finds

  -- -------- -- --------
     @xmath      (B.36)
  -- -------- -- --------

showing that the basis given by the intertwiners ( B.34 ) is orthogonal
but not normalized. To obtain normalized intertwiners, Eq. ( B.34 )
should be multiplied by @xmath .

Another basis on the four-valent intertwiner space is provided by the
intertwiners

  -- -------- -- --------
     @xmath      (B.37)
  -- -------- -- --------

in which the spins @xmath and @xmath have been coupled to the internal
spin. The change of basis between the bases ( B.34 ) and ( B.37 ) will
be discussed in section B.5 .

Intertwiners of arbitrarily high valence can evidently be derived by
continuing to attach three-valent intertwiners to each other by
contraction with epsilon. An @xmath -valent intertwiner constructed
according to this scheme has the form

  -- -------- -------- -- --------
     @xmath               
              @xmath      (B.38)
  -- -------- -------- -- --------

It is labeled by @xmath internal spins, which determine the eigenvalues
of the operators @xmath , @xmath , @xmath , @xmath . The intertwiner (
B.38 ) is not normalized; to normalize it, it should be multiplied by
@xmath . Just as in the three-valent case, the intertwiner @xmath ,
obtained by raising all the indices of the intertwiner ( B.38 ) by means
of the epsilon tensor, is numerically equal to @xmath .

A useful fact of the @xmath -valent intertwiner space concerns the
integral

  -- -------- -- --------
     @xmath      (B.39)
  -- -------- -- --------

The invariance and normalization of the Haar measure imply that the
integral is invariant under the action of @xmath , and satisfies @xmath
. Therefore @xmath , viewed as an operator on @xmath , must be the
projection operator onto the @xmath invariant subspace of @xmath , i.e.
onto the intertwiner space @xmath . Hence the integral can be expressed
as @xmath , or

  -- -------- -- --------
     @xmath      (B.40)
  -- -------- -- --------

where the sum runs over any orthonormal basis of @xmath ; in general the
basis may be complex-valued, although the basis given by the
intertwiners ( B.38 ) is always real.

### b.5 6@xmath- and 9@xmath-symbols

The intertwiners ( B.34 ) and ( B.37 ) provide two inequivalent bases of
the four-valent intertwiner space. One basis is expressed in terms of
the other by the relation

  -- -------- -- --------
     @xmath      (B.41)
  -- -------- -- --------

where the object with curly brackets is the Wigner 6 @xmath -symbol.
From Eq. ( B.41 ) one can derive the expression

  -- -------- -- --------
     @xmath      (B.42)
  -- -------- -- --------

for the 6 @xmath -symbol as a contraction of four three-valent
intertwiners. This shows that the 6 @xmath -symbol vanishes unless the
triples of spins indicated by

  -- -------- -- --------
     @xmath      (B.43)
  -- -------- -- --------

satisfy the Clebsch–Gordan conditions. Furthermore, orthogonality of the
states ( B.41 ) for different values of @xmath implies that the 6 @xmath
-symbol satisfies the orthogonality relation

  -- -------- -- --------
     @xmath      (B.44)
  -- -------- -- --------

Symmetry properties of the 6 @xmath -symbol can be derived from Eq. (
B.42 ), though they are more easily seen using the graphical
representation of the symbol, which will be introduced in the next
chapter. The value of the 6 @xmath -symbol is unchanged by any
permutation of its columns:

  -- -------- -- --------
     @xmath      (B.45)
  -- -------- -- --------

and by interchanging the upper and lower spins simultaneously in any two
columns:

  -- -------- -- --------
     @xmath      (B.46)
  -- -------- -- --------

The Wigner 9 @xmath -symbol arises when changes of basis between
five-valent intertwiners are performed. Two different bases in the
intertwiner space @xmath are provided by the intertwiners

  -- -------- -- --------
     @xmath      (B.47)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (B.48)
  -- -------- -- --------

Elements of one basis are expanded in the other basis as

  -- -- -- --------
           (B.49)
  -- -- -- --------

where the 9 @xmath -symbol appears on the right-hand side. From this
definition it follows that the 6 @xmath -symbol is given by a
contraction of six three-valent intertwiners as

  -- -------- -------- -- --------
     @xmath               
              @xmath      (B.50)
  -- -------- -------- -- --------

Hence the 9 @xmath -symbol can have a non-zero value only if the
Clebsch–Gordan conditions are satisfied by the spins in each row and
each column.

The 9 @xmath -symbol possesses a high degree of symmetry. Transposing
the array of spins in the symbol preserves its value:

  -- -------- -- --------
     @xmath      (B.51)
  -- -------- -- --------

Moreover, interchanging any rows or any two columns produces a sign
factor:

  -- -------- -- --------
     @xmath      (B.52)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (B.53)
  -- -------- -- --------

These symmetry relations again become the most transparent when the 9
@xmath -symbol is expressed in graphical form. A large number of further
properties satisfied by the 6 @xmath - and 9 @xmath -symbols can be
found in any of the standard references, such as [ 127 ] .

### b.6 Intertwiners in the symmetric tensor product representation

When the representation of the space @xmath as a completely symmetrized
tensor product of the spaces @xmath is used, intertwiners can be
expressed directly in terms of the fundamental invariant tensor @xmath ,
which is the only invariant tensor available in the space @xmath . The
basic three-valent intertwiner

  -- -------- -- --------
     @xmath      (B.54)
  -- -------- -- --------

out of which higher intertwiners can be derived, must be constructed
from the object

  -- -------- -- --------
     @xmath      (B.55)
  -- -------- -- --------

which is the only possible combination of epsilons with the correct
index structure. The requirement that the total number of @xmath ,
@xmath and @xmath indices is respectively @xmath , @xmath and @xmath
determines the numbers @xmath , @xmath and @xmath as

  -- -------- -- --------
     @xmath      (B.56)
  -- -------- -- --------

The three-valent intertwiner ( B.54 ) is then obtained from the
expression ( B.55 ) by symmetrizing each group of indices. This gives

  -- -------- -- --------
     @xmath      (B.57)
  -- -------- -- --------

where

  -- -------- -- --------
     @xmath      (B.58)
  -- -------- -- --------

and the normalization factor is

  -- -------- -- --------
     @xmath      (B.59)
  -- -------- -- --------

The three-valent intertwiner having been found, intertwiners of higher
valence can be constructed by contracting several three-valent
intertwiners, in the same way as in Eqs. ( B.34 ) and ( B.38 ). For
example, a four-valent intertwiner is given by

  -- -------- -- --------
     @xmath      (B.60)
  -- -------- -- --------

where the spin-1/2 indices are raised with @xmath according to the
convention ( A.8 ), and the factor @xmath is inserted for normalization.

Intertwiners in the symmetric tensor product representation can be
expressed graphically by introducing a primitive graphical notation, in
which

-   @xmath or @xmath is represented by a line with an arrow pointing
    from index @xmath to @xmath ;

-   @xmath is represented by a line with no arrow;

-   Contraction of an index is represented by connecting two lines at
    the contracted index.

Then we can write the intertwiner ( B.57 ) in the form

  -- -------- -- --------
     @xmath      (B.61)
  -- -------- -- --------

where each external group of lines is understood to be completely
symmetrized. Similarly, the four-valent intertwiner ( B.60 ) is given by

  -- -------- -- --------
     @xmath      (B.62)
  -- -------- -- --------

where we draw the horizontal bar to indicate a complete symmetrization
of the internal group of lines.

## Appendix C The graphical method

We now come to the last and in a sense the most important chapter of the
Appendix, in which we introduce the powerful graphical techniques for
calculations in @xmath recoupling theory. On the surface the graphical
framework may simply seem to consist of adopting a diagrammatic notation
for @xmath calculations. However, in reality the graphical approach
serves a highly efficient computational device, since the visual
graphical diagrams are invariably easier to comprehend and simpler to
work with than the corresponding non-graphical expressions. In loop
quantum gravity, the graphical techniques can be generally used in any
calculation involving intertwiners. In particular, in this work they
have an indispensable role as the technical tools by which we calculate
the matrix elements of our Hamiltonian in the spin network basis (see
Chapter 16 ).

Several closely related but slightly different versions of the graphical
formalism can be found in the literature of quantum angular momentum [
52 , 127 , 132 ] , and in articles in which graphical methods are used
for calculations in loop quantum gravity [ A , C , 9 , 7 , 130 , 131 ] .
In these circumstances it seems preferable (and it certainly requires
less effort) to develop a consistent set of conventions for the
graphical formalism on one’s own, using the available references as a
guide, rather than trying to ensure that one is in full agreement with
the conventions chosen in some previous treatment of the subject. When
compared to conventions available in the literature, the conventions
adopted in this work match the most closely with those of Brink and
Satchler [ 52 ] , which was the main reference used by the author to
learn the graphical techniques in the early stages of his PhD studies.

### c.1 Elements of the graphical formalism

The basic elements of the graphical formalism are provided by the
graphical representations of the elementary objects of @xmath
representation theory: the delta and epsilon tensors, the 3 @xmath
-symbol, and @xmath group elements. The properties satisfied by these
objects lead to graphical rules according to which diagrams appearing in
a graphical calculation can be manipulated. The relation of the
formalism to loop quantum gravity is indicated by Eqs. ( C.26 )–( C.29
), which show how the action of the elementary operators of the theory
can be expressed in graphical form.

#### Delta and epsilon tensors

The unit tensor @xmath is represented graphically by a line which
carries the indices @xmath and @xmath at its two ends:

  -- -------- -- -------
     @xmath      (C.1)
  -- -------- -- -------

If necessary, the line can be labeled with a spin @xmath to indicate the
representation which the indices of @xmath refer to.

The invariant tensor @xmath is represented by a line with an arrow
pointing from index @xmath to index @xmath :

  -- -------- -- -------
     @xmath      (C.2)
  -- -------- -- -------

Since tensor @xmath is numerically equal to @xmath , it is represented
by the same diagram:

  -- -------- -- -------
     @xmath      (C.3)
  -- -------- -- -------

The magnetic indices in graphical diagrams such as ( C.1 )–( C.3 ) are
usually not shown explicitly, if leaving them out is not likely to cause
any confusion. For example, the indices of the epsilon tensor can be
safely omitted, since the direction of the arrow shows which end of the
line corresponds to which index of @xmath . From now on we will follow
this practice and not write out the magnetic indices unless there is a
particular reason for doing so.

Contraction of indices is carried out in the graphical formalism by
connecting the ends of the two lines corresponding to the contracted
index. The relations ( A.52 ) and ( A.53 ) satisfied by the epsilon
tensor then imply that the arrow behaves according to the rules

  -- -------- -- -------
     @xmath      (C.4)
  -- -------- -- -------

and

  -- -------- -- -------
     @xmath      (C.5)
  -- -------- -- -------

Using the first relation, the second relation can be equivalently
written as

  -- -------- -- -------
     @xmath      (C.6)
  -- -------- -- -------

#### The 3@xmath-symbol

The graphical representation of the 3 @xmath -symbol is given by three
lines connected at a node:

  -- -------- -- -------
     @xmath      (C.7)
  -- -------- -- -------

The sign at the node encodes the cyclic order of the spins in the
symbol, a @xmath sign corresponding to the anticlockwise order of Eq. (
C.7 ), while a @xmath sign corresponds to a clockwise order. Thus,

  -- -------- -- -------
     @xmath      (C.8)
  -- -------- -- -------

Eq. ( B.20 ) then implies that reversing the sign produces the factor
@xmath :

  -- -------- -- -------
     @xmath      (C.9)
  -- -------- -- -------

From the other symmetry relation ( B.21 ) it follows that

  -- -------- -- --------
     @xmath      (C.10)
  -- -------- -- --------

which is a graphical representation of the fact that @xmath is
numerically equal to @xmath . Furthermore, the orthogonality relations (
B.18 ) and ( B.19 ) read

  -- -------- -- --------
     @xmath      (C.11)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (C.12)
  -- -------- -- --------

The normalization of the 3 @xmath -symbol, implied by the first
orthogonality relation, gives

  -- -------- -- --------
     @xmath      (C.13)
  -- -------- -- --------

Eq. ( B.22 ), which shows how the 3 @xmath -symbol reduces to the
epsilon tensor when one of the spins is zero, is written graphically as

  -- -------- -- --------
     @xmath      (C.14)
  -- -------- -- --------

In equations such as ( C.12 ) and ( C.14 ), where the relation between
the indices on the two sides of the equation is in principle ambiguous
unless one writes them out explicitly, we follow the convention that the
relative position of the indices is the same on both sides. For example,
if we consider the index at the top left corner on the left-hand side of
Eq. ( C.12 ) as the index @xmath of the corresponding non-graphical
equation ( B.19 ), then @xmath is at the top left corner also on the
right-hand side of Eq. ( C.12 ).

From Eq. ( B.13 ), which defines the 3 @xmath -symbol in terms of the
Clebsch–Gordan coefficient, we find that the graphical representation of
the Clebsch–Gordan coefficient is

  -- -------- -- --------
     @xmath      (C.15)
  -- -------- -- --------

Eq. ( B.30 ) then shows that the matrix elements of the @xmath
generators are given by

  -- -------- -- --------
     @xmath      (C.16)
  -- -------- -- --------

where we used the shorthand notation

  -- -------- -- --------
     @xmath      (C.17)
  -- -------- -- --------

To write the triple product @xmath in graphical form, let us introduce
the diagram

  -- -------- -- --------
     @xmath      (C.18)
  -- -------- -- --------

to represent a vector with an index in the @xmath representation. Then,
according to Eq. ( B.33 ), the triple product can be expressed
graphically as

  -- -------- -- --------
     @xmath      (C.19)
  -- -------- -- --------

#### Group elements

For the matrix elements of the Wigner matrices @xmath , we adopt the
graphical representation

  -- -------- -- --------
     @xmath      (C.20)
  -- -------- -- --------

If the group element @xmath is the holonomy of an edge in a spin network
state, then the transformation law

  -- -------- -- --------
     @xmath      (C.21)
  -- -------- -- --------

of the holonomy under @xmath gauge transformations suggests that the
indices @xmath and @xmath in @xmath are associated respectively to the
endpoint and the beginning point of the edge @xmath . Therefore the
direction of the triangle in Eq. ( C.20 ) is consistent with the
orientation of the edge.

From Eq. ( A.54 ), we see that that the inverse matrix is given by

  -- -------- -- --------
     @xmath      (C.22)
  -- -------- -- --------

The orthogonality theorem for the Wigner matrices can be translated into
graphical form, if we denote the complex conjugate of the matrix
elements by a bar over the group element @xmath inside the triangle in
Eq. ( C.20 ). We then have

  -- -------- -- --------
     @xmath      (C.23)
  -- -------- -- --------

Alternatively, the relation @xmath can be used to eliminate the complex
conjugate. This leads to

  -- -------- -------- -- --------
     @xmath   @xmath      
              @xmath      (C.24)
  -- -------- -------- -- --------

The corresponding graphical equation is

  -- -------- -- --------
     @xmath      (C.25)
  -- -------- -- --------

The Clebsch–Gordan series ( B.11 ) is expressed graphically as

  ------------------------------------------------------------------------------------------ -------- -- --------
                                                                                             @xmath      (C.26)
  Using Eq. ( C.22 ), we can also derive the coupling of a group element with its inverse:               
                                                                                             @xmath      (C.27)
  ------------------------------------------------------------------------------------------ -------- -- --------

Eqs. ( C.26 ) and ( C.27 ) are the basic graphical rules for computing
the action of the holonomy operator on an edge of a spin network state.
The action of the elementary ”momentum operator” @xmath on a holonomy,
given by Eq. ( 4.7 ), takes the graphical form

  ------------------------------------------------------------------------ -------- -------- -- --------
                                                                           @xmath   @xmath      (C.28)
  when the operator acts at the beginning point of the edge @xmath , and                        
                                                                           @xmath   @xmath      (C.29)
  ------------------------------------------------------------------------ -------- -------- -- --------

when the operator acts at the endpoint of @xmath .

### c.2 Intertwiners in graphical form

The graphical representation of the basic three-valent intertwiner
@xmath is given by Eq. ( C.7 ). Intertwiners of higher valence can be
constructed by using the epsilon tensor to attach several three-valent
intertwiners to each other, as discussed in section B.4 . Hence the
four-valent intertwiner of Eq. ( B.34 ) is represented graphically as

  -- -------- -- --------
     @xmath      (C.30)
  -- -------- -- --------

where the epsilon tensor appears as an arrow on the internal line. By
graphical means it is easy to show that the scalar product between two
intertwiners of this form is indeed given by Eq. ( B.36 ). Using Eqs. (
C.11 ) and ( C.6 ), we find

  -- -------- -- --------
     @xmath      (C.31)
  -- -------- -- --------

The intertwiner ( B.37 ), in which the spins @xmath and @xmath have been
coupled to the internal spin, has the graphical form

  -- -------- -- --------
     @xmath      (C.32)
  -- -------- -- --------

The change of basis between the bases ( C.30 ) and ( C.32 ) is given by

  -- -------- -- --------
     @xmath      (C.33)
  -- -------- -- --------

By contracting both sides of this equation with the intertwiner ( C.30
), one can derive the graphical expression

  -- -------- -- --------
     @xmath      (C.34)
  -- -------- -- --------

for the 6 @xmath -symbol. Eq. ( C.34 ) is of course the graphical
equivalent of Eq. ( B.42 ).

The five-valent intertwiners ( B.47 ) and ( B.48 ) are written
graphically as

  ----- -------- -------- -- --------
        @xmath   @xmath      (C.35)
  and                        
        @xmath   @xmath      (C.36)
  ----- -------- -------- -- --------

The intertwiner ( C.36 ) is expressed in the basis ( C.35 ) by the
relation

  -- -------- -- --------
     @xmath      
                 (C.37)
  -- -------- -- --------

Contracting both sides with the intertwiner ( C.35 ), one finds that the
9 @xmath -symbol has the graphical representation

  -- -------- -- --------
     @xmath      (C.38)
  -- -------- -- --------

which is just Eq. ( B.50 ) translated into graphical form.

@xmath -valent intertwiners can be derived by continuing to contract
three-valent intertwiners in the way indicated by Eqs. ( C.30 ) and (
C.35 ), as shown by the non-graphical equation ( B.38 ). However, it can
sometimes be convenient to use a different pattern of contractions to
construct a basis of the @xmath -valent intertwiner space. When
calculating the matrix elements of the Hamiltonian, we use a basis of
the form

  -- -------- -- --------
     @xmath      (C.39)
  -- -------- -- --------

in which the spins of the intertwiner are coupled pairwise to internal
spins. Just as the intertwiners given by Eq. ( B.38 ), the intertwiners
( C.39 ) are not normalized, but intertwiners carrying different
internal spins are orthogonal to each other. To normalize the
intertwiner ( C.39 ), it should be multiplied by the factor

  -- -------- -- --------
     @xmath      (C.40)
  -- -------- -- --------

Note that there is no loss of generality in using intertwiners of the
form ( C.39 ), even though at a first sight it may seem that one is
assuming the valence @xmath to be even. However, to obtain an
intertwiner of odd valence from ( C.39 ), it suffices to set one of the
spins, say @xmath , equal to zero.

### c.3 The fundamental theorem of graphical calculus

The basic rules for working with graphical diagrams are given by Eqs. (
C.4 )–( C.6 ) and ( C.8 )–( C.10 ), which show how the arrows and signs
in a graphical expression can be manipulated. However, the most
essential tool for performing graphical calculations with intertwiners
arises from the seemingly simple observation that an invariant tensor
having @xmath indices can be expanded in a basis of the corresponding
space of @xmath -valent intertwiners. To express the implications of
this observation in graphical form, we will represent a @xmath -valent
invariant tensor graphically as a rectangular block with @xmath lines
attached to it.

A tensor carrying a single index cannot be invariant, unless the index
belongs to the trivial representation. Thus,

  -- -------- -- --------
     @xmath      (C.41)
  -- -------- -- --------

A two-valent tensor @xmath can be invariant only if both of its indices
belong to the same representation. In this case, @xmath must be
proportional to @xmath , which is the only invariant tensor having two
lower indices. The coefficient of proportionality can be determined by
contracting both sides of the equation with the epsilon tensor. Since
the contraction of @xmath with itself gives @xmath , we have the
graphical rule

  -- -------- -- --------
     @xmath      (C.42)
  -- -------- -- --------

A three-valent invariant tensor @xmath belongs to the space @xmath ,
which is again one-dimensional (provided that the spins @xmath , @xmath
and @xmath satisfy the Clebsch–Gordan conditions). Therefore @xmath must
be proportional to the 3 @xmath -symbol, the coefficient of
proportionality again being determined by contracting the equation with
the 3 @xmath -symbol. That is,

  -- -------- -- --------
     @xmath      (C.43)
  -- -------- -- --------

For invariant tensors of valence four or higher, there generally no
longer is a unique intertwiner to which the tensor would have to be
proportional. Nevertheless, an invariant tensor with @xmath indices can
be expanded in any basis of the corresponding @xmath -valent intertwiner
space. For example, expanding a four-valent invariant tensor in the
basis given by the intertwiners ( C.30 ), and recalling that the norm of
the intertwiner ( C.30 ) is @xmath , we obtain

  -- -------- -- --------
     @xmath      (C.44)
  -- -------- -- --------

The relations ( C.41 )–( C.44 ) play such a central role in graphical
calculations that they would fully deserve to be known as the
fundamental theorem of graphical calculus. The last part of the theorem,
given by Eq. ( C.44 ), generalizes in a straightforward way to tensors
carrying more than four indices. Moreover, even though we wrote Eqs. (
C.41 )–( C.44 ) for tensors having only lower indices, similar relations
are naturally valid for tensors having a different index structure. Eqs.
( C.41 )–( C.44 ) can be extended to such tensors simply by using the
epsilon tensor to raise indices, corresponding graphically to attaching
arrows to some lines on both sides of the equation.

An important way in which the fundamental theorem can be used is to
break down a complicated graphical diagram into simpler constituents.
Consider a graphical diagram representing an arbitrary invariant
contraction of 3 @xmath -symbols or other invariant tensors. Suppose
that the diagram contains a subdiagram with @xmath external lines, such
that the subdiagram itself is an @xmath -valent invariant tensor, and
the graph of the entire diagram can be separated into two disconnected
pieces by cutting the @xmath lines of the subdiagram. In this case the
diagram can potentially be simplified by using the fundamental theorem
to expand the subdiagram in a basis of the @xmath -valent intertwiner
space.

If a diagram can be divided into two pieces by cutting one, two or three
lines, then Eqs. ( C.41 )–( C.43 ) imply that the diagram simply splits
into a product of two factors according to the rules

  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -------- -------- -- --------
                                                                                                                                                                                                                               @xmath   @xmath      (C.45)
                                                                                                                                                                                                                               @xmath   @xmath      (C.46)
                                                                                                                                                                                                                               @xmath   @xmath      (C.47)
  In the case of cutting four lines to break a diagram into two, Eq. ( C.44 ) shows that one does not obtain simply a product of two factors, but rather a sum in which each term is a product of two disconnected diagrams:                        
                                                                                                                                                                                                                               @xmath   @xmath      (C.48)
  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -------- -------- -- --------

It is again straightforward to generalize Eq. ( C.48 ) to the case where
a diagram is cut on more than four lines (though it seems that such
generalizations are very rarely needed in practice).

When using the fundamental theorem in the form ( C.45 )–( C.48 ), it is
important to make sure that each of the two blocks actually represents a
proper invariant tensor. If there is doubt as to whether this is the
case, the invariance of the block can be checked by using the following
criterion: A diagram representing a tensor constructed by contracting 3
@xmath -symbols corresponds to an invariant tensor if and only if it is
possible to use Eqs. ( C.6 ) and ( C.10 ) to bring the diagram into a
form in which each internal line of the diagram carries exactly one
arrow.

Let us mention at this point a useful theorem concerning diagrams which
represent invariant scalar contractions of 3 @xmath -symbols, and hence
carry no external, uncontracted lines. The theorem states that the value
of such a diagram remains unchanged if one simultaneously reverses the
direction of every arrow and the sign at every node in the diagram. This
theorem implies, for example, that the 6 @xmath - and 9 @xmath -symbols
of Eqs. ( C.34 ) and ( C.38 ) are equivalently represented by the
diagrams

  -- -------- -- --------
     @xmath      (C.49)
  -- -------- -- --------

and

  -- -------- -- --------
     @xmath      (C.50)
  -- -------- -- --------

To prove the theorem, suppose that we have brought a given invariant
diagram into a form where each line carries precisely one arrow. Since
reversing an arrow on a line carrying spin @xmath produces the factor
@xmath , we see that reversing all the arrows in the diagram multiplies
the diagram by the factor @xmath , where @xmath is the sum of all the
spins appearing in the diagram. Similarly, reversing the sign at a node
where spins @xmath , @xmath and @xmath meet produces the factor @xmath ,
so reversing all the signs in the diagram also multiplies the diagram by
@xmath , because every line in the diagram is connected to two nodes. In
total, the diagram is therefore multiplied by @xmath , since @xmath is
an integer, and so @xmath is even.

While the principal use of Eqs. ( C.45 )–( C.48 ) is to break large
diagrams into smaller pieces, in some cases Eq. ( C.48 ) can be used in
the reverse direction in order to evaluate a sum over an internal spin
in a graphical expression. A very simple example of using the
fundamental theorem in this way is provided by a graphical proof of the
orthogonality relation ( B.44 ) for the 6 @xmath -symbol. Using the
graphical representation ( C.34 ), we can write the sum as

  -- -------- -- --------
     @xmath      (C.51)
  -- -------- -- --------

We see that the form of this expression matches the right-hand side of
Eq. ( C.48 ), the two blocks with four lines being

  -- -------- -- --------
     @xmath      (C.52)
  -- -------- -- --------

Therefore Eq. ( C.48 ) gives

  -- -------- -- --------
     @xmath      (C.53)
  -- -------- -- --------

where Eqs. ( C.6 ), ( C.11 ) and ( C.13 ) were used to evaluate the
resulting diagram.

To conclude our overview of the graphical method, let us consider an
example which illustrates the use of the machinery of graphical
techniques in a practical calculation involving intertwiners. (The
calculations in Chapter 16 provide a large number of further examples.)
The problem consists of expressing the six-valent intertwiner

  -- -------- -- --------
     @xmath      (C.54)
  -- -------- -- --------

in the basis formed by the intertwiners

  -- -------- -- --------
     @xmath      (C.55)
  -- -------- -- --------

The result of this exercise is used in section 16.2 to compute the
action of the curvature operator on a spin network node which contains
an intertwiner of the form ( C.54 ).

According to the generalization of Eq. ( C.44 ) to six-valent invariant
tensors, the intertwiner ( C.54 ) can be expressed in terms of the
intertwiners ( C.55 ) as

  -- -------- -- --------
     @xmath      
     @xmath      (C.56)
  -- -------- -- --------

where the coefficient @xmath is given by the contraction of the
intertwiners ( C.54 ) and ( C.55 ):

  -- -------- -- --------
     @xmath      (C.57)
  -- -------- -- --------

This diagram can be recognized as the so-called 12 @xmath -symbol of the
first kind (see e.g. [ 127 ] or [ 132 ] ), but we can use the
fundamental theorem to break it down to the more familiar 6 @xmath - and
9 @xmath -symbols. The diagram clearly cannot be separated into two
non-trivial pieces by cutting only two or three lines, so we will use
Eq. ( C.48 ) to cut out the part consisting of the four nodes in the
middle of the diagram, as indicated by the red dashed line in Eq. ( C.58
). For convenience, we make use of Eqs. ( C.4 ) and ( C.10 ) to reverse
the direction of the arrows and interchange one pair of signs in Eq. (
C.48 ), leading to

  -- -------- -- --------
     @xmath      (C.58)
  -- -------- -- --------

The first factor in the sum is simply the 9 @xmath -symbol of Eq. ( C.38
),

  -- -------- -- --------
     @xmath      (C.59)
  -- -------- -- --------

since Eq. ( C.10 ) shows that the three arrows at the bottom node can be
removed. In the second factor, we cancel the three arrows in the middle,
and use Eq. ( C.6 ) to introduce oppositely directed arrows on the lines
carrying spins @xmath and @xmath . After this we cut the diagram along
the three vertical lines according to Eq. ( C.47 ). Each of the
resulting pieces is the 6 @xmath -symbol of Eq. ( C.34 ), up to powers
of @xmath , which arise when Eqs. ( C.4 ) and ( C.9 ) are used to adjust
the arrows and the signs so that they agree with Eq. ( C.34 ). In this
way we find

  -- -------- -- --------
     @xmath      (C.60)
  -- -------- -- --------

which completes the calculation. Inserting Eqs. ( C.57 )–( C.60 ) back
into Eq. ( C.56 ), we conclude that the expansion of the intertwiner (
C.54 ) in the basis of the intertwiners ( C.55 ) is given by

  -- -------- -- --------
     @xmath      
     @xmath      (C.61)
  -- -------- -- --------
